{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ2OTY1Mjg0", "number": 9096, "title": "PIP 76: Streaming Offload(Part I)", "bodyText": "This PR contains the new interface and implementation of the offloader in the below PIP\nUnit test is still in progress\n\n StreamingDataBlockHeaderImpl\n StreamingBlobStoreBackedReadHandleImpl\n BufferedOffloadStream\n BlobStoreManagedLedgerOffloader\n StreamingOffloadIndexBlock\n\nPIP 76: https://github.com/apache/pulsar/wiki/PIP-76:-Streaming-Offload", "createdAt": "2020-12-30T14:24:56Z", "url": "https://github.com/apache/pulsar/pull/9096", "merged": true, "mergeCommit": {"oid": "17f399ebebaaf03b969deea971f3320595398c54"}, "closed": true, "closedAt": "2021-01-26T02:29:18Z", "author": {"login": "Renkai"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdutnAUgFqTU2NDgzNTU0MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdzncj6AH2gAyNTQ2OTY1Mjg0OmU0ODM1ZDQzZjFhYmJhNDE4M2YyZTkzODE0NjkwMzA3ZGU3MmQ3ODc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY0ODM1NTQx", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-564835541", "createdAt": "2021-01-10T07:30:11Z", "commit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwNzozMDoxMVrOIQ1ibg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMFQwODoyNToyM1rOIQ14KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNTI5NA==", "bodyText": "Could you please check the format changes related to the .proto? It's better to keep consistent with the current format", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554525294", "createdAt": "2021-01-10T07:30:11Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzM5MQ==", "bodyText": "Do we need this field in the OffloadSegment? A ledger might be offloaded as multiple segments,  it's better to use the bookkeeperDeleted in the OffloadContext", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527391", "createdAt": "2021-01-10T07:51:05Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzQ1Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              optional int64 assignedTs = 5; //epoch millis\n          \n          \n            \n              optional int64 assignedTimestamp = 5; //epoch millis", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527452", "createdAt": "2021-01-10T07:51:51Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzUzNw==", "bodyText": "Please give a meaningful description? epoch millis is confuse here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527537", "createdAt": "2021-01-10T07:53:00Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzQ1Mg=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              optional int64 offloadedTs = 6; //epoch millis\n          \n          \n            \n              optional int64 offloadedTimestamp = 6; //epoch millis", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527605", "createdAt": "2021-01-10T07:53:20Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis\n+  optional int64 offloadedTs = 6; //epoch millis", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYxMg==", "bodyText": "Please give a meaningful description? epoch millis is confuse here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554527612", "createdAt": "2021-01-10T07:53:27Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -28,28 +28,40 @@ message KeyValue {\n \n message OffloadDriverMetadata {\n     required string name = 1;\n-    repeated KeyValue properties = 2;\n+  repeated KeyValue properties = 2;\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 assignedTs = 5; //epoch millis\n+  optional int64 offloadedTs = 6; //epoch millis", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyNzYwNQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA==", "bodyText": "Do we need to expose the SegmentInfo here?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528174", "createdAt": "2021-01-10T07:58:31Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODUyMg==", "bodyText": "Is it possible to check the consecutive in the offloader? I think it's more easy to handle in the managedledger.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528522", "createdAt": "2021-01-10T08:02:10Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                ManagedLedgerException.OffloadNotConsecutiveException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ==", "bodyText": "It's better to also add async method for these 3 methods. Usually, we should implement the sync method based on the async method.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554528979", "createdAt": "2021-01-10T08:06:35Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTIzMw==", "bodyText": "Please check the comment of this method, I think here is not correct, The result just return a future for the OffloadHandle, this does not mean that the data has been persisted", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529233", "createdAt": "2021-01-10T08:09:02Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +161,32 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Offload the passed in ledger to longterm storage.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned future completes, the ledger has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTI4NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                interface OffloaderHandle {\n          \n          \n            \n                interface OffloadHandle {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529284", "createdAt": "2021-01-10T08:09:40Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw==", "bodyText": "UnsupportedOperationException?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529357", "createdAt": "2021-01-10T08:10:19Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTU5Nw==", "bodyText": "maxOffloadSegmentRolloverTimeInSeconds?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529597", "createdAt": "2021-01-10T08:13:22Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTkyNQ==", "bodyText": "We also need to add the minOffloadSegmentRolloverTimeInSeconds to avoid the segments rollover too often.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554529925", "createdAt": "2021-01-10T08:16:28Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,10 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_SEGMENT_TIME_IN_SECOND = \"maxSegmentTimeInSecond\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";\n+    public static final long DEFAULT_MAX_SEGMENT_SIZE_IN_BYTES = 1024 * 1024 * 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA==", "bodyText": "Can we reuse the OffloadIndexBlock? In my opinion, we just add some fields at the index header. Shall we need to introduce a new interface here? I think this will introduce more duplicate code", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530658", "createdAt": "2021-01-10T08:23:43Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDcxMw==", "bodyText": "Please consider reuse the OffloadIndexBlockBuilder", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530713", "createdAt": "2021-01-10T08:24:11Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.StreamingOffloadIndexBlockBuilderImpl;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDg1Nw==", "bodyText": "Why change it to getFirstEntryId? The index always point to one entryId right?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554530857", "createdAt": "2021-01-10T08:25:23Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexEntry.java", "diffHunk": "@@ -33,7 +33,7 @@\n     /**\n      * Get the entryId that this entry contains.\n      */\n-    long getEntryId();\n+    long getFirstEntryId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY1MDYzMTcz", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-565063173", "createdAt": "2021-01-11T04:16:34Z", "commit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoxNjozNFrOIQ_4ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQwNDoyNjo1NlrOIRAU1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NDgxOQ==", "bodyText": "This should be an interface not a class.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554694819", "createdAt": "2021-01-11T04:16:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODE3NA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTIwNw==", "bodyText": "Same question as above. Can we make it an interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695207", "createdAt": "2021-01-11T04:17:02Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NTY2NQ==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554695665", "createdAt": "2021-01-11T04:17:44Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -35,6 +39,78 @@\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    @ToString\n+    class SegmentInfo {\n+        public SegmentInfo(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloaderHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        PositionImpl lastOffered();\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyODk3OQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ==", "bodyText": "Can you explain why do we need this method? Also, add a comment to this method?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554697575", "createdAt": "2021-01-11T04:20:35Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5OTA5Mw==", "bodyText": "I would like to see if we can avoid adding LedgerMetadata here. Because LedgerMetadata is a specific interface for bookkeeper. We should avoid binding the metadata format to bookkeeper's ledger metadata. This would simplify tiered storage integration.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554699093", "createdAt": "2021-01-11T04:22:54Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -594,4 +593,6 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    CompletableFuture<LedgerMetadata> getRawLedgerMetadata(long ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDY5NzU3NQ=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMDI5OA==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554700298", "createdAt": "2021-01-11T04:24:38Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA==", "bodyText": "Can you explain why do you add a \"Mock\" method in the actual implementation?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r554702038", "createdAt": "2021-01-11T04:26:56Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY1NTU1NDY2", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-565555466", "createdAt": "2021-01-11T16:58:21Z", "commit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNjo1ODoyMVrOIRejXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNzozMDozN1rOIRf4XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTE5NzI3Nw==", "bodyText": "Maybe the exception should be UnsupportedOperationException?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555197277", "createdAt": "2021-01-11T16:58:21Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIwOTc4OQ==", "bodyText": "The indent could be consistent with others.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555209789", "createdAt": "2021-01-11T17:16:28Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -32,12 +32,23 @@ message OffloadDriverMetadata {\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional int64 assignedTimestamp = 5; //timestamp in millisecond\n+  optional int64 offloadedTimestamp = 6; //timestamp in millisecond\n+  optional int64 endEntryId = 7;\n+  optional OffloadDriverMetadata driverMetadata = 8;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxMDc2OQ==", "bodyText": "The filed number is not continuous.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555210769", "createdAt": "2021-01-11T17:17:57Z", "author": {"login": "gaoran10"}, "path": "managed-ledger/src/main/proto/MLDataFormats.proto", "diffHunk": "@@ -32,12 +32,23 @@ message OffloadDriverMetadata {\n }\n \n message OffloadContext {\n-    optional int64 uidMsb = 1;\n-    optional int64 uidLsb = 2;\n-    optional bool complete = 3;\n-    optional bool bookkeeperDeleted = 4;\n-    optional int64 timestamp = 5;\n-    optional OffloadDriverMetadata driverMetadata = 6;\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional bool bookkeeperDeleted = 4;\n+  optional int64 timestamp = 5;\n+  optional OffloadDriverMetadata driverMetadata = 6;\n+  repeated OffloadSegment offloadSegment = 7;\n+}\n+\n+message OffloadSegment {\n+  optional int64 uidMsb = 1;\n+  optional int64 uidLsb = 2;\n+  optional bool complete = 3;\n+  optional int64 assignedTimestamp = 5; //timestamp in millisecond", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTIxOTAzNg==", "bodyText": "Does one StreamingOffloadIndexBlock will contain multiple ledgers indexes?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555219036", "createdAt": "2021-01-11T17:30:37Z", "author": {"login": "gaoran10"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     */\n+    Map<Long, LedgerMetadata> getLedgerMetadata();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY1NDI1ODM1", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-565425835", "createdAt": "2021-01-11T14:51:58Z", "commit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1MTo1OFrOIRYqEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xMVQxNDo1ODoyOFrOIRY8nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMDY4OA==", "bodyText": "typo: uid", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555100688", "createdAt": "2021-01-11T14:51:58Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMTMxMQ==", "bodyText": "what happens if I call this method for the same ManagedLedger more times, with overlapping intervals ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555101311", "createdAt": "2021-01-11T14:52:54Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds\n+     * a uid in the metadata, it will attempt to cleanup this attempt with a call\n+     * to #deleteOffloaded(ReadHandle,UUID). Once the offload attempt completes,\n+     * the managed ledger will update its metadata again, to record the completion,\n+     * ensuring that subsequent calls will not attempt to offload the same ledger\n+     * again.\n+     *\n+     * @return an OffloaderHandle, which when `completeFuture()` completed, denotes that the offload has been successful.\n+     */\n+    default CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                              long beginEntry,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjE2MA==", "bodyText": "you should return a CompletableFuture that reports the UnsupportedOperationException\nthe caller of a method that returns a Future does not expect the method to throw exceptions.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102160", "createdAt": "2021-01-11T14:54:03Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +217,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUyOTM1Nw=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwMjIzNg==", "bodyText": "the same here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555102236", "createdAt": "2021-01-11T14:54:09Z", "author": {"login": "eolivelli"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -115,6 +239,16 @@\n     CompletableFuture<Void> deleteOffloaded(long ledgerId, UUID uid,\n                                             Map<String, String> offloadDriverMetadata);\n \n+    default CompletableFuture<ReadHandle> readOffloaded(long ledgerId, MLDataFormats.OffloadContext ledgerContext,\n+                                                        Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedClassVersionError();\n+    }\n+\n+    default CompletableFuture<Void> deleteOffloaded(UUID uid,\n+                                                    Map<String, String> offloadDriverMetadata) {\n+        throw new UnsupportedOperationException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDUwOA==", "bodyText": "should not we perform this operation only after the end of the loop above ?\nwhat happens if the streamingOffloadLoop does not complete in time ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104508", "createdAt": "2021-01-11T14:57:11Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw==", "bodyText": "we can provide more information here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555104683", "createdAt": "2021-01-11T14:57:26Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNTQzOQ==", "bodyText": "nit: static ?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r555105439", "createdAt": "2021-01-11T14:58:28Z", "author": {"login": "eolivelli"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.build();\n+                final StreamingOffloadIndexBlock.IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+        } else {\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+            OffloadNotConsecutiveException {\n+        if (segmentInfo.isClosed()) {\n+            throw new OffloadSegmentClosedException(\"Segment already closed \" + segmentInfo);\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition, entry.getPosition())) {\n+                throw new OffloadNotConsecutiveException(\n+                        Strings.lenientFormat(\"position %s and %s are not consecutive\", lastOfferedPosition,\n+                                entry.getPosition()));\n+            }\n+            entry.retain();\n+            offloadBuffer.add(entry);\n+            bufferLength.getAndAdd(entry.getLength());\n+            segmentLength.getAndAdd(entry.getLength());\n+            lastOfferedPosition = entry.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength) {\n+                closeSegment();\n+            }\n+            return true;\n+        }\n+    }\n+\n+    private synchronized void closeSegment() {\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+    }\n+\n+    private boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 251}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5ec03f7e6e2348e71f597f32f6ccb2ac5e9f7006", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/5ec03f7e6e2348e71f597f32f6ccb2ac5e9f7006", "committedDate": "2021-01-13T07:36:27Z", "message": "revert unnecessary change\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}, "afterCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a", "committedDate": "2021-01-13T09:01:22Z", "message": "implement streaming offloader\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDc1Njcy", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-568475672", "createdAt": "2021-01-14T17:44:51Z", "commit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzo0NDo1MVrOITv1mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQyMTo0MjozNFrOIT4WRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3NzYyNw==", "bodyText": "Can you move the implementation outside of an interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557577627", "createdAt": "2021-01-14T17:44:51Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODA3OQ==", "bodyText": "What does \"create one per second\" mean?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578079", "createdAt": "2021-01-14T17:45:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw==", "bodyText": "It is a bit strange to implement an async method over a sync method. We usually implement the other way around.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557578717", "createdAt": "2021-01-14T17:46:32Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3OTIzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * loadterm storage, so it is safe to delete the original copy in bookkeeper.\n          \n          \n            \n                 * longterm storage, so it is safe to delete the original copy in bookkeeper.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557579238", "createdAt": "2021-01-14T17:47:24Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +181,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * loadterm storage, so it is safe to delete the original copy in bookkeeper.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MTU2MA==", "bodyText": "If this interface is designed to be an async method, the exception should be returned from the CompletableFuture. The interface seems to be mix async semantic with sync semantic together.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557581560", "createdAt": "2021-01-14T17:51:07Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MjgwMQ==", "bodyText": "What happens if the ledger is closed with zero entries?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557582801", "createdAt": "2021-01-14T17:53:20Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,20 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) throws ManagedLedgerException {\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            throw new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+        } else if (ledgerInfo.getSize() == 0 || ledgerInfo.getEntries() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4MzI5NQ==", "bodyText": "okay works for me.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583295", "createdAt": "2021-01-14T17:54:10Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4Mzk4Ng==", "bodyText": "Can we move implementation out of this interface?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557583986", "createdAt": "2021-01-14T17:55:26Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {\n+\n+    /**\n+     * Get the content of the index block as InputStream.\n+     * Read out in format:\n+     *   | index_magic_header | index_block_len | index_entry_count |\n+     *   | data_object_size | segment_metadata_length | segment metadata | index entries ... |\n+     */\n+    IndexInputStream toStream() throws IOException;\n+\n+    /**\n+     * Get the related OffloadIndexEntry that contains the given messageEntryId.\n+     *\n+     * @param messageEntryId\n+     *                      the entry id of message\n+     * @return the offload index entry\n+     */\n+    OffloadIndexEntry getIndexEntryForEntry(long ledgerId, long messageEntryId) throws IOException;\n+\n+    public long getStartEntryId(long ledgerId);\n+\n+    /**\n+     * Get the entry count that contained in this index Block.\n+     */\n+    int getEntryCount();\n+\n+    /**\n+     * Get LedgerMetadata.\n+     * @return\n+     */\n+    LedgerMetadata getLedgerMetadata(long ledgerId);\n+\n+    /**\n+     * Get the total size of the data object.\n+     */\n+    long getDataObjectLength();\n+\n+    /**\n+     * Get the length of the header in the blocks in the data object.\n+     */\n+    long getDataBlockHeaderLength();\n+\n+    /**\n+     * An input stream which knows the size of the stream upfront.\n+     */\n+    class IndexInputStream extends FilterInputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA==", "bodyText": "Put log.debug into if (log.isDebugEnabled()) { ... }", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557585554", "createdAt": "2021-01-14T17:57:59Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NjQyOA==", "bodyText": "Please address all the occurrences.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557586428", "createdAt": "2021-01-14T17:59:21Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4NTU1NA=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODI0OA==", "bodyText": "Can you rename it to maxOffloadSegmentSizeInBytes?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588248", "createdAt": "2021-01-14T18:02:07Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/provider/TieredStorageConfiguration.java", "diffHunk": "@@ -63,6 +63,12 @@\n     public static final String METADATA_FIELD_MAX_BLOCK_SIZE = \"maxBlockSizeInBytes\";\n     public static final String METADATA_FIELD_READ_BUFFER_SIZE = \"readBufferSizeInBytes\";\n     public static final String OFFLOADER_PROPERTY_PREFIX = \"managedLedgerOffload\";\n+    public static final String MAX_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"maxOffloadSegmentRolloverTimeInSeconds\";\n+    public static final String MIN_OFFLOAD_SEGMENT_ROLLOVER_TIME_SEC = \"minOffloadSegmentRolloverTimeInSeconds\";\n+    public static final long DEFAULT_MAX_SEGMENT_TIME_IN_SECOND = 600;\n+    public static final long DEFAULT_MIN_SEGMENT_TIME_IN_SECOND = 0;\n+    public static final String MAX_SEGMENT_SIZE_IN_BYTES = \"maxSegmentSizeInBytes\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4ODU5Mg==", "bodyText": "Make sense now.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557588592", "createdAt": "2021-01-14T18:02:45Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/test/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloaderBase.java", "diffHunk": "@@ -82,7 +71,11 @@ protected static MockZooKeeper createMockZooKeeper() throws Exception {\n                 CreateMode.PERSISTENT);\n         return zk;\n     }\n-    \n+\n+    protected static MockManagedLedger createMockManagedLedger() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcwMjAzOA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxMzY2NA==", "bodyText": "Should this be info or debug?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557713664", "createdAt": "2021-01-14T21:35:45Z", "author": {"login": "sijie"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {\n+                long entriesToRead = (groupedReader.lastEntry - groupedReader.firstEntry) + 1;\n+                long nextExpectedId = groupedReader.firstEntry;\n+                try {\n+                    while (entriesToRead > 0) {\n+                        int length = groupedReader.dataStream.readInt();\n+                        if (length < 0) { // hit padding or new block\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        }\n+                        long entryId = groupedReader.dataStream.readLong();\n+\n+                        if (entryId == nextExpectedId) {\n+                            ByteBuf buf = PulsarByteBufAllocator.DEFAULT.buffer(length, length);\n+                            entries.add(LedgerEntryImpl.create(ledgerId, entryId, length, buf));\n+                            int toWrite = length;\n+                            while (toWrite > 0) {\n+                                toWrite -= buf.writeBytes(groupedReader.dataStream, toWrite);\n+                            }\n+                            entriesToRead--;\n+                            nextExpectedId++;\n+                        } else if (entryId > nextExpectedId) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId < nextExpectedId\n+                                && !groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                .equals(\n+                                        groupedReader.index.getIndexEntryForEntry(groupedReader.ledgerId, entryId))) {\n+                            groupedReader.inputStream\n+                                    .seek(groupedReader.index\n+                                            .getIndexEntryForEntry(groupedReader.ledgerId, nextExpectedId)\n+                                            .getDataOffset());\n+                            continue;\n+                        } else if (entryId > groupedReader.lastEntry) {\n+                            log.info(\"Expected to read {}, but read {}, which is greater than last entry {}\",\n+                                    nextExpectedId, entryId, groupedReader.lastEntry);\n+                            throw new BKException.BKUnexpectedConditionException();\n+                        } else {\n+                            val skipped = groupedReader.inputStream.skip(length);\n+                            log.info(\"Skipped {} bytes.\", skipped);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg==", "bodyText": "PositionImpl is an implementation. Should this be Position?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715312", "createdAt": "2021-01-14T21:39:00Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTkzNg==", "bodyText": "Should this be EntryImpl or Entry?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557715936", "createdAt": "2021-01-14T21:40:16Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNzA2MA==", "bodyText": "Don't we need a close method to seal the offloaded segment?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r557717060", "createdAt": "2021-01-14T21:42:34Z", "author": {"login": "sijie"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 85}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c708626dd98c10998402359234d55da04d2e382e", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/c708626dd98c10998402359234d55da04d2e382e", "committedDate": "2021-01-15T09:03:08Z", "message": "polish offerEntry method\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}, "afterCommit": {"oid": "bb0c55b637e9622ed22306b9236d8a874c03a187", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/bb0c55b637e9622ed22306b9236d8a874c03a187", "committedDate": "2021-01-15T09:16:53Z", "message": "polish offerEntry method\nadd async close\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwOTkyOTI3", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-570992927", "createdAt": "2021-01-19T08:16:10Z", "commit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "state": "COMMENTED", "comments": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwODoxNjoxMVrOIWCyNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQxMToyMzowOFrOIWKJHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk4NTIwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    default CompletableFuture<Boolean> asyncCanOffer(long size) {\n          \n          \n            \n                    default CompletableFuture<Boolean> canOfferAsync(long size) {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559985205", "createdAt": "2021-01-19T08:16:11Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MDE3MA==", "bodyText": "You can't assume the canOffer always \"efficient\", it depends on the implementations. From the interface perspective, this is not the right way.\nuse default for the interface method, this means it's not required for the implementation to implement this method, so an implementation can only implement the sync method. If the sync method need some time-consuming operations, This destroys the original intention of the interface", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559990170", "createdAt": "2021-01-19T08:24:59Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU3ODcxNw=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MTA3MQ==", "bodyText": "From the interface perspective, we should use Position", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559991071", "createdAt": "2021-01-19T08:26:15Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,115 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n+import lombok.ToString;\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadNotConsecutiveException;\n+import org.apache.bookkeeper.mledger.ManagedLedgerException.OffloadSegmentClosedException;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    @ToString\n+    class SegmentInfoImpl implements SegmentInfo {\n+        public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                               Map<String, String> driverMetadata) {\n+            this.uuid = uuid;\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.driverName = driverName;\n+            this.driverMetadata = driverMetadata;\n+        }\n+\n+\n+        public final UUID uuid;\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final String driverName;\n+        volatile private long endLedger;\n+        volatile private long endEntry;\n+        volatile boolean closed = false;\n+        public final Map<String, String> driverMetadata;\n+\n+        public boolean isClosed() {\n+            return closed;\n+        }\n+\n+        public void closeSegment(long endLedger, long endEntry) {\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+            this.closed = true;\n+        }\n+\n+        public OffloadResult result() {\n+            return new OffloadResult(beginLedger, beginEntry, endLedger, endEntry);\n+        }\n+    }\n+\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per second.\n+     */\n+    interface OffloadHandle {\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzcxNTMxMg=="}, "originalCommit": {"oid": "d3a6a8c2744733d00e6dfa30c0cac2f06eb1386a"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzM3OA==", "bodyText": "same as the above comment, you can remove the default implementation from the interface.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993378", "createdAt": "2021-01-19T08:30:08Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzUxNQ==", "bodyText": "Same as above comment.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993515", "createdAt": "2021-01-19T08:30:22Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTk5MzY5Mw==", "bodyText": "Same as the above comment", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r559993693", "createdAt": "2021-01-19T08:30:43Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {\n+        boolean isClosed();\n+\n+        OffloadResult result();\n+    }\n+\n+    class OffloadResult {\n+        public final long beginLedger;\n+        public final long beginEntry;\n+        public final long endLedger;\n+        public final long endEntry;\n+\n+        public OffloadResult(long beginLedger, long beginEntry, long endLedger, long endEntry) {\n+            this.beginLedger = beginLedger;\n+            this.beginEntry = beginEntry;\n+            this.endLedger = endLedger;\n+            this.endEntry = endEntry;\n+        }\n+    }\n+\n+    /**\n+     * Used to store driver info, buffer entries, mark progress, etc.\n+     * Create one per segment.\n+     */\n+    interface OffloadHandle {\n+        enum OfferEntryResult {\n+            SUCCESS,\n+            FAIL_BUFFER_FULL,\n+            FAIL_SEGMENT_CLOSED,\n+            FAIL_NOT_CONSECUTIVE\n+        }\n+\n+        /**\n+         * return true when both buffer have enough size and ledger/entry id is next to the current one.\n+         * @param size\n+         * @return\n+         */\n+        boolean canOffer(long size);\n+\n+        default CompletableFuture<Boolean> asyncCanOffer(long size) {\n+            return CompletableFuture.completedFuture(canOffer(size));\n+        }\n+\n+        PositionImpl lastOffered();\n+\n+        default CompletableFuture<PositionImpl> asyncLastOffered() {\n+            return CompletableFuture.completedFuture(lastOffered());\n+        }\n+\n+        /**\n+         * The caller should manually release entry no matter what the offer result is.\n+         */\n+        OfferEntryResult offerEntry(Entry entry);\n+\n+        default CompletableFuture<OfferEntryResult> asyncOfferEntry(EntryImpl entry) {\n+            return CompletableFuture.completedFuture(offerEntry(entry));\n+        }\n+\n+        CompletableFuture<OffloadResult> getOffloadResultAsync();\n+\n+        /**\n+         * Manually close current offloading segment\n+         * @return true if the segment is not already closed\n+         */\n+        boolean close();\n+\n+        default CompletableFuture<Boolean> AsyncClose() {\n+            return CompletableFuture.completedFuture(close());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwMzU5OQ==", "bodyText": "Do we need this exception? As I mentioned before, there are some markers in the managed ledger, this will affect the continuity of entry id when offload data to the tiered storage", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560003599", "createdAt": "2021-01-19T08:46:57Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedgerException.java", "diffHunk": "@@ -151,6 +151,18 @@ public OffloadInProgressException(String msg) {\n         }\n     }\n \n+    public static class OffloadSegmentClosedException extends ManagedLedgerException {\n+        public OffloadSegmentClosedException(String msg) {\n+            super(msg);\n+        }\n+    }\n+\n+    public static class OffloadNotConsecutiveException extends ManagedLedgerException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwNTU0NA==", "bodyText": "Is it better to named getLedgerInfo? and does not distinguish whether it is closed. The closed state should contains in the LedgerInfo(Now I think we use the entries=0 to determine the ledger close or not)", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560005544", "createdAt": "2021-01-19T08:49:52Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/ManagedLedger.java", "diffHunk": "@@ -595,4 +594,10 @@ void asyncSetProperties(Map<String, String> properties, final AsyncCallbacks.Upd\n      * Get the ManagedLedgerInterceptor for ManagedLedger.\n      * */\n     ManagedLedgerInterceptor getManagedLedgerInterceptor();\n+\n+    /**\n+     * Get basic ledger summary after the ledger is closed.\n+     * will got exception if corresponding ledger was not closed when the method called.\n+     */\n+    CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAwOTg5NQ==", "bodyText": "It's better to define the result as CompletableFuture<Optional>? If use exception, it's better to define a specific exception because we need a way to determine if the exception is ledger not found exception? Use ManagedLedgerException to determine if the ledger is existed or not seem a bit confuse.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560009895", "createdAt": "2021-01-19T08:56:20Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1686,23 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getClosedLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);\n+        if (ledgerInfo == null) {\n+            final ManagedLedgerException exception = new ManagedLedgerException(\n+                    Strings.lenientFormat(\"ledger with id %s not found\", ledgerId));\n+            result.completeExceptionally(exception);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxMzQ2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public final long beginLedger;\n          \n          \n            \n                public final long beginLedgerId;\n          \n      \n    \n    \n  \n\nPlease check all.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560013468", "createdAt": "2021-01-19T09:01:49Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n+    public SegmentInfoImpl(UUID uuid, long beginLedger, long beginEntry, String driverName,\n+                           Map<String, String> driverMetadata) {\n+        this.uuid = uuid;\n+        this.beginLedger = beginLedger;\n+        this.beginEntry = beginEntry;\n+        this.driverName = driverName;\n+        this.driverMetadata = driverMetadata;\n+    }\n+\n+\n+    public final UUID uuid;\n+    public final long beginLedger;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAxNDAxMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {\n          \n          \n            \n            public class OffloadSegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560014013", "createdAt": "2021-01-19T09:02:43Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/SegmentInfoImpl.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.impl;\n+\n+\n+import java.util.Map;\n+import java.util.UUID;\n+import lombok.ToString;\n+import org.apache.bookkeeper.mledger.LedgerOffloader;\n+\n+@ToString\n+public class SegmentInfoImpl implements LedgerOffloader.SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNTIzNA==", "bodyText": "Is it used for managed ledger or any other component? If it only for offload internal, we don't need to expose it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560025234", "createdAt": "2021-01-19T09:19:32Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -22,19 +22,92 @@\n import java.util.Map;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n-\n import org.apache.bookkeeper.client.api.ReadHandle;\n import org.apache.bookkeeper.common.annotation.InterfaceAudience;\n import org.apache.bookkeeper.common.annotation.InterfaceStability;\n+import org.apache.bookkeeper.mledger.impl.EntryImpl;\n+import org.apache.bookkeeper.mledger.impl.PositionImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats;\n import org.apache.pulsar.common.policies.data.OffloadPolicies;\n \n /**\n- * Interface for offloading ledgers to long-term storage\n+ * Interface for offloading ledgers to long-term storage.\n  */\n @InterfaceAudience.LimitedPrivate\n @InterfaceStability.Evolving\n public interface LedgerOffloader {\n \n+    interface SegmentInfo {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAyNjQyOQ==", "bodyText": "Any reason to modify this method?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560026429", "createdAt": "2021-01-19T09:21:19Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/OffloadIndexBlockBuilder.java", "diffHunk": "@@ -71,7 +71,7 @@\n     /**\n      * Construct OffloadIndex from an InputStream.\n      */\n-    OffloadIndexBlock fromStream(InputStream is) throws IOException;\n+    OffloadIndexBlock indexFromStream(InputStream is) throws IOException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzMzQxMQ==", "bodyText": "@Renkai, we are talking about the interface, not the implementation. From the OffloadIndexBlock interface, most of the methods are the same as the StreamingOffloadIndexBlock  right?\nAnother unreasonable place is the index block is format concept, Not only streaming offload can use this format right? If we want a new offloaded that offload based on the time window or data size but not streaming offloaded, this new version IndexBlock also can be used?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560033411", "createdAt": "2021-01-19T09:30:58Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlock.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.Closeable;\n+import java.io.FilterInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Map;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+\n+/**\n+ * The Index block abstraction used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+public interface StreamingOffloadIndexBlock extends Closeable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDUzMDY1OA=="}, "originalCommit": {"oid": "527b319ebe57b41bd087e757637a2bf787d22584"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDAzOTE5Mw==", "bodyText": "It's not correct here, because might skip all messages of a ledger. As I mentioned before, it's hard to determine the Consecutive at the offloader. And the marker also will affect this behavior in the future.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560039193", "createdAt": "2021-01-19T09:39:10Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MDM3Ng==", "bodyText": "If the segment closed return false, the buffer fills up return false, how to determine at the managed ledger?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560040376", "createdAt": "2021-01-19T09:40:49Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));\n+        }\n+    }\n+\n+    private CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+        return this.offloadResult;\n+    }\n+\n+    private synchronized OfferEntryResult offerEntry(Entry entry) {\n+\n+        if (segmentInfo.isClosed()) {\n+            log.debug(\"Segment already closed {}\", segmentInfo);\n+            return OfferEntryResult.FAIL_SEGMENT_CLOSED;\n+        } else if (maxBufferLength >= bufferLength.get() + entry.getLength()\n+                //if single message size larger than full buffer size, then ok to offer when buffer is empty\n+                && !(entry.getLength() > maxBufferLength && offloadBuffer.isEmpty())) {\n+            return OfferEntryResult.FAIL_BUFFER_FULL;\n+        } else {\n+            if (!naiveCheckConsecutive(lastOfferedPosition,\n+                    PositionImpl.get(entry.getLedgerId(), entry.getEntryId()))) {\n+                log.error(\"position {} and {} are not consecutive\", lastOfferedPosition,\n+                        entry.getPosition());\n+                return OfferEntryResult.FAIL_NOT_CONSECUTIVE;\n+            }\n+            final EntryImpl entryImpl = EntryImpl\n+                    .create(entry.getLedgerId(), entry.getEntryId(), entry.getDataBuffer());\n+            offloadBuffer.add(entryImpl);\n+            bufferLength.getAndAdd(entryImpl.getLength());\n+            segmentLength.getAndAdd(entryImpl.getLength());\n+            lastOfferedPosition = entryImpl.getPosition();\n+            if (segmentLength.get() >= maxSegmentLength\n+                    && System.currentTimeMillis() - segmentBeginTimeMillis >= minSegmentCloseTimeMillis) {\n+                closeSegment();\n+            }\n+            return OfferEntryResult.SUCCESS;\n+        }\n+    }\n+\n+    private synchronized boolean closeSegment() {\n+        final boolean result = !segmentInfo.isClosed();\n+        log.debug(\"close segment {} {}\", lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        this.segmentInfo.closeSegment(lastOfferedPosition.getLedgerId(), lastOfferedPosition.getEntryId());\n+        return result;\n+    }\n+\n+    private static boolean naiveCheckConsecutive(PositionImpl lastOfferedPosition, PositionImpl offeringPosition) {\n+        if (offeringPosition.getLedgerId() == lastOfferedPosition.getLedgerId()\n+                && offeringPosition.getEntryId() == lastOfferedPosition.getEntryId() + 1) {\n+            return true;\n+        } else if (offeringPosition.getEntryId() == 0) {\n+            return true;\n+        } else {\n+            // lastOfferedPosition not initialized\n+            return lastOfferedPosition.equals(PositionImpl.latest);\n+        }\n+    }\n+\n+    private PositionImpl lastOffered() {\n+        return lastOfferedPosition;\n+    }\n+\n+    private boolean canOffer(long size) {\n+        if (segmentInfo.isClosed()) {\n+            return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MzU3Nw==", "bodyText": "+1", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560043577", "createdAt": "2021-01-19T09:45:26Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +260,183 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = new StreamingOffloadIndexBlockBuilderImpl();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, segmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public boolean offerEntry(EntryImpl entry) throws OffloadSegmentClosedException,\n+                    OffloadNotConsecutiveException {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getRawLedgerMetadata(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTEwNDY4Mw=="}, "originalCommit": {"oid": "8c48c61b4d825783a9743fd56f4e0bab65805e88"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0NjMzOA==", "bodyText": "we can provide more information here", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560046338", "createdAt": "2021-01-19T09:49:19Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ==", "bodyText": "StreamingDataBlockHeaderImpl -> DataBlockHeaderImplV2? @Renkai @sijie The header format can be used by different offload implementations, I think coupling with streaming offload is not a good choice.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560061575", "createdAt": "2021-01-19T10:11:54Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2ODU0OQ==", "bodyText": "Is the BufferedOffloadStream need to be close after offload complete? I notice during the offload loop, the BufferedOffloadStream is created for each loop, but can't find where to close it.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560068549", "createdAt": "2021-01-19T10:22:31Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3NTk3Mw==", "bodyText": "final?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560075973", "createdAt": "2021-01-19T10:34:30Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4MjAyNg==", "bodyText": "Should peek first? If the next entry exceeds the max block size, what the behavior?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560082026", "createdAt": "2021-01-19T10:44:02Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4NzI5MQ==", "bodyText": "is the streamingParts clear automatically after complete the upload? I can't find any places to clear the streamingParts. BTW, the streamingParts seems can be a local variable", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560087291", "createdAt": "2021-01-19T10:52:12Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODI1Ng==", "bodyText": "Is it need to close?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088256", "createdAt": "2021-01-19T10:53:50Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4ODk2NA==", "bodyText": "Please provide more information, if you have many topics, the debug log can't help find any thing here.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560088964", "createdAt": "2021-01-19T10:55:05Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 240}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA4OTA2Mw==", "bodyText": "Same as above comment", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560089063", "createdAt": "2021-01-19T10:55:15Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 242}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NDcyNg==", "bodyText": "here will be a serious problem because the streaming offload will retry to get entry from the queue for every 100ms, if a topic does not write any messages, the thread will available for other topic offloading until the offload segment timeout(closed) right?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560094726", "createdAt": "2021-01-19T11:04:34Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +265,202 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new SegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(), driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore\n+                .initiateMultipartUpload(config.getBucket(), blob.getMetadata(), new PutOptions());\n+\n+        scheduler.chooseThread(segmentInfo).execute(() -> {\n+            log.info(\"start offloading segment: {}\", segmentInfo);\n+            streamingOffloadLoop(1, 0);\n+        });\n+        scheduler.schedule(this::closeSegment, maxSegmentCloseTime.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        return CompletableFuture.completedFuture(new OffloadHandle() {\n+            @Override\n+            public boolean canOffer(long size) {\n+                return BlobStoreManagedLedgerOffloader.this.canOffer(size);\n+            }\n+\n+            @Override\n+            public PositionImpl lastOffered() {\n+                return BlobStoreManagedLedgerOffloader.this.lastOffered();\n+            }\n+\n+            @Override\n+            public OfferEntryResult offerEntry(Entry entry) {\n+                return BlobStoreManagedLedgerOffloader.this.offerEntry(entry);\n+            }\n+\n+            @Override\n+            public CompletableFuture<OffloadResult> getOffloadResultAsync() {\n+                return BlobStoreManagedLedgerOffloader.this.getOffloadResultAsync();\n+            }\n+\n+            @Override\n+            public boolean close() {\n+                return BlobStoreManagedLedgerOffloader.this.closeSegment();\n+            }\n+        });\n+    }\n+\n+    private void streamingOffloadLoop(int partId, int dataObjectLength) {\n+        log.debug(\"streaming offload loop {} {}\", partId, dataObjectLength);\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            offloadResult.complete(segmentInfo.result());\n+            return;\n+        }\n+        final BufferedOffloadStream payloadStream;\n+\n+        while (offloadBuffer.isEmpty()) {\n+            if (segmentInfo.isClosed()) {\n+                offloadResult.complete(segmentInfo.result());\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    e.printStackTrace();\n+                }\n+            }\n+        }\n+        final Entry peek = offloadBuffer.peek();\n+        //initialize payload when there is at least one entry\n+        final long blockLedgerId = peek.getLedgerId();\n+        final long blockEntryId = peek.getEntryId();\n+        payloadStream = new BufferedOffloadStream(streamingBlockSize, offloadBuffer, segmentInfo,\n+                blockLedgerId, blockEntryId, bufferLength);\n+        try {\n+            streamingIndexBuilder.addLedgerMeta(blockLedgerId, ml.getClosedLedgerInfo(blockLedgerId).get());\n+            streamingIndexBuilder.withDataBlockHeaderLength(StreamingDataBlockHeaderImpl.getDataStartOffset());\n+        } catch (InterruptedException | ExecutionException e) {\n+            offloadResult.completeExceptionally(e);\n+            return;\n+        }\n+        log.debug(\"begin upload payload\");\n+        Payload partPayload = Payloads.newInputStreamPayload(payloadStream);\n+        partPayload.getContentMetadata().setContentType(\"application/octet-stream\");\n+        streamingParts.add(blobStore.uploadMultipartPart(streamingMpu, partId, partPayload));\n+        streamingIndexBuilder.addBlock(blockLedgerId, blockEntryId, partId, streamingBlockSize);\n+\n+        log.debug(\"UploadMultipartPart. container: {}, blobName: {}, partId: {}, mpu: {}\",\n+                config.getBucket(), streamingDataBlockKey, partId, streamingMpu.id());\n+        if (segmentInfo.isClosed() && offloadBuffer.isEmpty()) {\n+            log.debug(\"segment closed, buffer is empty\");\n+            try {\n+                blobStore.completeMultipartUpload(streamingMpu, streamingParts);\n+                streamingIndexBuilder.withDataObjectLength(dataObjectLength + streamingBlockSize);\n+                final StreamingOffloadIndexBlock index = streamingIndexBuilder.buildStreaming();\n+                final IndexInputStream indexStream = index.toStream();\n+                final BlobBuilder indexBlobBuilder = blobStore.blobBuilder(streamingDataIndexKey);\n+                DataBlockUtils.addVersionInfo(indexBlobBuilder, userMetadata);\n+                final InputStreamPayload indexPayLoad = Payloads.newInputStreamPayload(indexStream);\n+                indexPayLoad.getContentMetadata().setContentLength(indexStream.getStreamSize());\n+                indexPayLoad.getContentMetadata().setContentType(\"application/octet-stream\");\n+                final Blob indexBlob = indexBlobBuilder.payload(indexPayLoad)\n+                        .contentLength(indexStream.getStreamSize())\n+                        .build();\n+                blobStore.putBlob(config.getBucket(), indexBlob);\n+\n+                offloadResult.complete(segmentInfo.result());\n+            } catch (Exception e) {\n+                log.error(\"streaming offload failed\", e);\n+                offloadResult.completeExceptionally(e);\n+            }\n+            log.debug(\"offload done\");\n+        } else {\n+            log.debug(\"continue offload loop\");\n+            scheduler.chooseThread(segmentInfo)\n+                    .execute(() -> streamingOffloadLoop(partId + 1, dataObjectLength + streamingBlockSize));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA5NjA3OQ==", "bodyText": "We should to recycle the entries after read complete?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560096079", "createdAt": "2021-01-19T11:06:54Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BufferedOffloadStream.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.CompositeByteBuf;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.bookkeeper.mledger.Entry;\n+import org.apache.bookkeeper.mledger.impl.SegmentInfoImpl;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+@Slf4j\n+public class BufferedOffloadStream extends InputStream {\n+    static final int[] BLOCK_END_PADDING = BlockAwareSegmentInputStreamImpl.BLOCK_END_PADDING;\n+    private final SegmentInfoImpl segmentInfo;\n+\n+    private final long ledgerId;\n+    private final long beginEntryId;\n+    private AtomicLong bufferLength;\n+    static final int ENTRY_HEADER_SIZE = 4 /* entry size */ + 8 /* entry id */;\n+    private final long blockSize;\n+    private final ConcurrentLinkedQueue<Entry> entryBuffer;\n+    private final InputStream blockHead;\n+    int offset = 0;\n+    static int NOT_INITIALIZED = -1;\n+    int validDataOffset = NOT_INITIALIZED;\n+    CompositeByteBuf currentEntry;\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getBeginEntryId() {\n+        return beginEntryId;\n+    }\n+\n+    public long getBlockSize() {\n+        return blockSize;\n+    }\n+\n+\n+    public BufferedOffloadStream(int blockSize,\n+                                 ConcurrentLinkedQueue<Entry> entryBuffer,\n+                                 SegmentInfoImpl segmentInfo,\n+                                 long ledgerId,\n+                                 long beginEntryId,\n+                                 AtomicLong bufferLength) {\n+        this.ledgerId = ledgerId;\n+        this.beginEntryId = beginEntryId;\n+        this.blockSize = blockSize;\n+        this.segmentInfo = segmentInfo;\n+        this.entryBuffer = entryBuffer;\n+        this.bufferLength = bufferLength;\n+        this.blockHead = StreamingDataBlockHeaderImpl.of(blockSize, ledgerId, beginEntryId)\n+                .toStream();\n+    }\n+\n+\n+    @Override\n+    public int read() throws IOException {\n+        if (blockHead.available() > 0) {\n+            offset++;\n+            return blockHead.read();\n+        }\n+        //if current exists, use current first\n+        if (currentEntry != null) {\n+            if (currentEntry.readableBytes() > 0) {\n+                offset += 1;\n+                return currentEntry.readUnsignedByte();\n+            } else {\n+                currentEntry.release();\n+                currentEntry = null;\n+            }\n+        }\n+\n+        if (blockSize <= offset) {\n+            return -1;\n+        } else if (validDataOffset != NOT_INITIALIZED) {\n+            return BLOCK_END_PADDING[(offset++ - validDataOffset) % BLOCK_END_PADDING.length];\n+        }\n+\n+        Entry headEntry;\n+\n+        while ((headEntry = entryBuffer.peek()) == null) {\n+            if (segmentInfo.isClosed()) {\n+                if (validDataOffset == NOT_INITIALIZED) {\n+                    validDataOffset = offset;\n+                }\n+                return read();\n+            } else {\n+                try {\n+                    Thread.sleep(100);\n+                } catch (InterruptedException e) {\n+                    log.error(\"sleep failed\", e);\n+                }\n+            }\n+        }\n+\n+        //create new block when a ledger end\n+        if (headEntry.getLedgerId() != this.ledgerId) {\n+            if (validDataOffset == NOT_INITIALIZED) {\n+                validDataOffset = offset;\n+            }\n+            return read();\n+        }\n+\n+        if (blockSize >= offset\n+                + ENTRY_HEADER_SIZE\n+                + headEntry.getLength()) {\n+            entryBuffer.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMDc4NA==", "bodyText": "also close the dataStreams?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560100784", "createdAt": "2021-01-19T11:14:28Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwMTc5NA==", "bodyText": "Why throw bk exception here? does IllegalArgumentException works?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560101794", "createdAt": "2021-01-19T11:16:15Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEwNTc1Ng==", "bodyText": "Please double confirm the groupedReaders are sorted by ledger Id, entry id, Otherwise, this will bread the entry read in order guarantee", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560105756", "createdAt": "2021-01-19T11:23:08Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingBlobStoreBackedReadHandleImpl.java", "diffHunk": "@@ -0,0 +1,283 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.base.Preconditions;\n+import io.netty.buffer.ByteBuf;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.ScheduledExecutorService;\n+import lombok.val;\n+import org.apache.bookkeeper.client.BKException;\n+import org.apache.bookkeeper.client.api.LastConfirmedAndEntry;\n+import org.apache.bookkeeper.client.api.LedgerEntries;\n+import org.apache.bookkeeper.client.api.LedgerEntry;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.client.api.ReadHandle;\n+import org.apache.bookkeeper.client.impl.LedgerEntriesImpl;\n+import org.apache.bookkeeper.client.impl.LedgerEntryImpl;\n+import org.apache.bookkeeper.mledger.offload.jcloud.BackedInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlock;\n+import org.apache.bookkeeper.mledger.offload.jcloud.StreamingOffloadIndexBlockBuilder;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.DataBlockUtils.VersionCheck;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.jclouds.blobstore.BlobStore;\n+import org.jclouds.blobstore.domain.Blob;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingBlobStoreBackedReadHandleImpl implements ReadHandle {\n+    private static final Logger log = LoggerFactory.getLogger(StreamingBlobStoreBackedReadHandleImpl.class);\n+\n+    private final long ledgerId;\n+    private final List<StreamingOffloadIndexBlock> indices;\n+    private final List<BackedInputStream> inputStreams;\n+    private final List<DataInputStream> dataStreams;\n+    private final ExecutorService executor;\n+\n+    static class GroupedReader {\n+        long ledgerId;\n+        long firstEntry;\n+        long lastEntry;\n+        StreamingOffloadIndexBlock index;\n+        BackedInputStream inputStream;\n+        DataInputStream dataStream;\n+\n+        public GroupedReader(long ledgerId, long firstEntry, long lastEntry,\n+                             StreamingOffloadIndexBlock index,\n+                             BackedInputStream inputStream, DataInputStream dataStream) {\n+            this.ledgerId = ledgerId;\n+            this.firstEntry = firstEntry;\n+            this.lastEntry = lastEntry;\n+            this.index = index;\n+            this.inputStream = inputStream;\n+            this.dataStream = dataStream;\n+        }\n+    }\n+\n+    private StreamingBlobStoreBackedReadHandleImpl(long ledgerId, List<StreamingOffloadIndexBlock> indices,\n+                                                   List<BackedInputStream> inputStreams,\n+                                                   ExecutorService executor) {\n+        this.ledgerId = ledgerId;\n+        this.indices = indices;\n+        this.inputStreams = inputStreams;\n+        this.dataStreams = new LinkedList<>();\n+        for (BackedInputStream inputStream : inputStreams) {\n+            dataStreams.add(new DataInputStream(inputStream));\n+        }\n+        this.executor = executor;\n+    }\n+\n+    @Override\n+    public long getId() {\n+        return ledgerId;\n+    }\n+\n+    @Override\n+    public LedgerMetadata getLedgerMetadata() {\n+        return indices.get(0).getLedgerMetadata(ledgerId);\n+    }\n+\n+    @Override\n+    public CompletableFuture<Void> closeAsync() {\n+        CompletableFuture<Void> promise = new CompletableFuture<>();\n+        executor.submit(() -> {\n+            try {\n+                for (StreamingOffloadIndexBlock indexBlock : indices) {\n+                    indexBlock.close();\n+                }\n+                for (BackedInputStream inputStream : inputStreams) {\n+                    inputStream.close();\n+                }\n+                promise.complete(null);\n+            } catch (IOException t) {\n+                promise.completeExceptionally(t);\n+            }\n+        });\n+        return promise;\n+    }\n+\n+    @Override\n+    public CompletableFuture<LedgerEntries> readAsync(long firstEntry, long lastEntry) {\n+        log.debug(\"Ledger {}: reading {} - {}\", getId(), firstEntry, lastEntry);\n+        CompletableFuture<LedgerEntries> promise = new CompletableFuture<>();\n+        if (firstEntry > lastEntry\n+                || firstEntry < 0\n+                || lastEntry > getLastAddConfirmed()) {\n+            promise.completeExceptionally(new BKException.BKIncorrectParameterException());\n+            return promise;\n+        }\n+        executor.submit(() -> {\n+            List<LedgerEntry> entries = new ArrayList<LedgerEntry>();\n+            List<GroupedReader> groupedReaders = null;\n+            try {\n+                groupedReaders = getGroupedReader(firstEntry, lastEntry);\n+            } catch (Exception e) {\n+                promise.completeExceptionally(e);\n+                return;\n+            }\n+\n+            for (GroupedReader groupedReader : groupedReaders) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 141}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/45d435c5bd42e5206f714a2f349cebb81ba1b575", "committedDate": "2021-01-20T02:52:49Z", "message": "snapshot 20210120\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "44109dce6062ed27adb49ea70db3192c871c2a7d", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/44109dce6062ed27adb49ea70db3192c871c2a7d", "committedDate": "2021-01-20T00:08:28Z", "message": "change for review comment\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}, "afterCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/45d435c5bd42e5206f714a2f349cebb81ba1b575", "committedDate": "2021-01-20T02:52:49Z", "message": "snapshot 20210120\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f59f16a32888538a15ee9ee6189372f556f795f", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/3f59f16a32888538a15ee9ee6189372f556f795f", "committedDate": "2021-01-20T03:07:09Z", "message": "remove interface segmentInfo\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/7692f8aa778daa63dc83be84ebe5547e8a6c2fd6", "committedDate": "2021-01-20T04:09:32Z", "message": "use auto-close to streams\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9faedd44431de79bfc761fb20ee565f728dbd09d", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/9faedd44431de79bfc761fb20ee565f728dbd09d", "committedDate": "2021-01-20T04:23:06Z", "message": "use throwable instead of Exception\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcxODQ5ODQx", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-571849841", "createdAt": "2021-01-20T03:55:20Z", "commit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzo1NToyMFrOIWr2Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwNDozNjoxN1rOIWsx3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1Nzk1OQ==", "bodyText": "streamingoffload()?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560657959", "createdAt": "2021-01-20T03:55:20Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/LedgerOffloader.java", "diffHunk": "@@ -85,6 +150,34 @@\n                                     UUID uid,\n                                     Map<String, String> extraMetadata);\n \n+    /**\n+     * Begin offload the passed in ledgers to longterm storage, it will finish\n+     * when a segment reached it's size or time.\n+     * Metadata passed in is for inspection purposes only and should be stored\n+     * alongside the segment data.\n+     *\n+     * When the returned OffloaderHandle.getOffloadResultAsync completes, the corresponding\n+     * ledgers has been persisted to the\n+     * longterm storage, so it is safe to delete the original copy in bookkeeper.\n+     *\n+     * The uid is used to identify an attempt to offload. The implementation should\n+     * use this to deterministically generate a unique name for the offloaded object.\n+     * This uid will be stored in the managed ledger metadata before attempting the\n+     * call to offload(). If a subsequent or concurrent call to streamingOffload() finds", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ==", "bodyText": "Do we need to check the returned value? It's might be null.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560659329", "createdAt": "2021-01-20T03:59:59Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY2MDc4MA==", "bodyText": "any() should be any type, why we need to cast it to the UUID?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560660780", "createdAt": "2021-01-20T04:05:24Z", "author": {"login": "zymap"}, "path": "managed-ledger/src/test/java/org/apache/bookkeeper/mledger/impl/OffloadPrefixReadTest.java", "diffHunk": "@@ -97,21 +97,21 @@ public void testOffloadRead() throws Exception {\n             assertEquals(new String(e.getData()), \"entry-\" + i++);\n         }\n         verify(offloader, times(1))\n-            .readOffloaded(anyLong(), any(), anyMap());\n+                .readOffloaded(anyLong(), (UUID) any(), anyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzE0Mg==", "bodyText": "If we have another call for the streamingOffloading, do those variables will impact the previous offload process? Because the following offload loop still uses the same variables.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673142", "createdAt": "2021-01-20T04:35:58Z", "author": {"login": "zymap"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY3MzI0Nw==", "bodyText": "same above.", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r560673247", "createdAt": "2021-01-20T04:36:17Z", "author": {"login": "zymap"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/BlobStoreManagedLedgerOffloader.java", "diffHunk": "@@ -230,6 +266,213 @@ public String getOffloadDriverName() {\n         return promise;\n     }\n \n+    BlobStore blobStore;\n+    String streamingDataBlockKey;\n+    String streamingDataIndexKey;\n+    MultipartUpload streamingMpu = null;\n+    List<MultipartPart> streamingParts = Lists.newArrayList();\n+\n+    @Override\n+    public CompletableFuture<OffloadHandle> streamingOffload(ManagedLedger ml, UUID uuid, long beginLedger,\n+                                                             long beginEntry,\n+                                                             Map<String, String> driverMetadata) {\n+        this.ml = ml;\n+        this.segmentInfo = new OffloadSegmentInfoImpl(uuid, beginLedger, beginEntry, config.getDriver(),\n+                driverMetadata);\n+        log.debug(\"begin offload with {}:{}\", beginLedger, beginEntry);\n+        this.offloadResult = new CompletableFuture<>();\n+        blobStore = blobStores.get(config.getBlobStoreLocation());\n+        streamingIndexBuilder = StreamingOffloadIndexBlockBuilder.create();\n+        streamingDataBlockKey = segmentInfo.uuid.toString();\n+        streamingDataIndexKey = String.format(\"%s-index\", segmentInfo.uuid);\n+        BlobBuilder blobBuilder = blobStore.blobBuilder(streamingDataBlockKey);\n+        DataBlockUtils.addVersionInfo(blobBuilder, userMetadata);\n+        Blob blob = blobBuilder.build();\n+        streamingMpu = blobStore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 143}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f4510a2c868dc905d41081a8119be14adb686bb", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/8f4510a2c868dc905d41081a8119be14adb686bb", "committedDate": "2021-01-20T06:20:13Z", "message": "fix bug to pass tests\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/b8b53dcc1f0787176f66f7533dcb13df1a05b586", "committedDate": "2021-01-20T07:51:16Z", "message": "merge the from stream method of two version index\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4e4d766baee9c391d477422e5ba980cd20757484", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/4e4d766baee9c391d477422e5ba980cd20757484", "committedDate": "2021-01-20T07:48:13Z", "message": "merge the from stream method of two version index\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}, "afterCommit": {"oid": "b8b53dcc1f0787176f66f7533dcb13df1a05b586", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/b8b53dcc1f0787176f66f7533dcb13df1a05b586", "committedDate": "2021-01-20T07:51:16Z", "message": "merge the from stream method of two version index\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26cdd20e099dd6a3b56d9e38947c962ae32feec7", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/26cdd20e099dd6a3b56d9e38947c962ae32feec7", "committedDate": "2021-01-20T08:12:52Z", "message": "add info to prevent offload multi times\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce767aef96654be789c265600ad1f3a1065a08fe", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/ce767aef96654be789c265600ad1f3a1065a08fe", "committedDate": "2021-01-20T13:26:34Z", "message": "reduce sleep time\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ecde448b62b5e4336f98c72bdd194fe06d41401", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/6ecde448b62b5e4336f98c72bdd194fe06d41401", "committedDate": "2021-01-21T03:47:11Z", "message": "put blob after buffer reaches threshold\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/7794e184a56fd7ac007a1180e2263563d060d364", "committedDate": "2021-01-22T09:05:40Z", "message": "Merge branch 'master' into new-offloader"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc0ODM5MjA4", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-574839208", "createdAt": "2021-01-23T11:03:56Z", "commit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMTowMzo1NlrOIZA71A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QxMzozMzozNVrOIZEJlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzEwMDYyOA==", "bodyText": "And please consider returns a copy of LedgerInfo to void be modified from external?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563100628", "createdAt": "2021-01-23T11:03:56Z", "author": {"login": "codelipenghui"}, "path": "managed-ledger/src/main/java/org/apache/bookkeeper/mledger/impl/ManagedLedgerImpl.java", "diffHunk": "@@ -1685,6 +1685,14 @@ void asyncReadEntries(OpReadEntry opReadEntry) {\n         return getLedgerHandle(ledgerId).thenApply(rh -> rh.getLedgerMetadata().toSafeString());\n     }\n \n+    @Override\n+    public CompletableFuture<LedgerInfo> getLedgerInfo(long ledgerId) {\n+        CompletableFuture<LedgerInfo> result = new CompletableFuture<>();\n+        final LedgerInfo ledgerInfo = ledgers.get(ledgerId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY1OTMyOQ=="}, "originalCommit": {"oid": "45d435c5bd42e5206f714a2f349cebb81ba1b575"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzA3Mw==", "bodyText": "This should be OffloadIndexBlockV2Builder?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153073", "createdAt": "2021-01-23T13:30:22Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/StreamingOffloadIndexBlockBuilder.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.common.annotation.InterfaceAudience.LimitedPrivate;\n+import org.apache.bookkeeper.common.annotation.InterfaceStability.Unstable;\n+import org.apache.bookkeeper.mledger.offload.jcloud.impl.OffloadIndexBlockBuilderImpl;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+\n+/**\n+ * Interface for builder of index block used for offload a ledger to long term storage.\n+ */\n+@Unstable\n+@LimitedPrivate\n+public interface StreamingOffloadIndexBlockBuilder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzE5Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {\n          \n          \n            \n            public class OffloadIndexBlockV2Impl implements OffloadIndexBlockV2 {", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153197", "createdAt": "2021-01-23T13:32:11Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingOffloadIndexBlockImpl.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.Maps;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import io.netty.util.Recycler;\n+import io.netty.util.Recycler.Handle;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableMap;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+import org.apache.bookkeeper.client.api.DigestType;\n+import org.apache.bookkeeper.client.api.LedgerMetadata;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlock.IndexInputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexBlockV2;\n+import org.apache.bookkeeper.mledger.offload.jcloud.OffloadIndexEntry;\n+import org.apache.bookkeeper.mledger.proto.MLDataFormats.ManagedLedgerInfo.LedgerInfo;\n+import org.apache.bookkeeper.net.BookieId;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class StreamingOffloadIndexBlockImpl implements OffloadIndexBlockV2 {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7794e184a56fd7ac007a1180e2263563d060d364"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzE1MzMwMw==", "bodyText": "Have you checked this comment @Renkai?", "url": "https://github.com/apache/pulsar/pull/9096#discussion_r563153303", "createdAt": "2021-01-23T13:33:35Z", "author": {"login": "codelipenghui"}, "path": "tiered-storage/jcloud/src/main/java/org/apache/bookkeeper/mledger/offload/jcloud/impl/StreamingDataBlockHeaderImpl.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.bookkeeper.mledger.offload.jcloud.impl;\n+\n+import com.google.common.io.CountingInputStream;\n+import io.netty.buffer.ByteBuf;\n+import io.netty.buffer.ByteBufInputStream;\n+import java.io.DataInputStream;\n+import java.io.EOFException;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import org.apache.bookkeeper.mledger.offload.jcloud.DataBlockHeader;\n+import org.apache.pulsar.common.allocator.PulsarByteBufAllocator;\n+\n+/**\n+ * The data block header in code storage for each data block.\n+ */\n+public class StreamingDataBlockHeaderImpl implements DataBlockHeader {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2MTU3NQ=="}, "originalCommit": {"oid": "acc18e061a2437b69f05b30c021a9fd911711bcd"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82c6cb1b9fce171dee3907d7fbb6fbf207b3640d", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/82c6cb1b9fce171dee3907d7fbb6fbf207b3640d", "committedDate": "2021-01-24T14:23:58Z", "message": "Merge branch 'master' into new-offloader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c622056775a8a3fd0b165341618b0ee644ccc922", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/c622056775a8a3fd0b165341618b0ee644ccc922", "committedDate": "2021-01-24T14:31:53Z", "message": "polish\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e9b1c6fff551d949e5aba17894efc60ed7e05a2", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/9e9b1c6fff551d949e5aba17894efc60ed7e05a2", "committedDate": "2021-01-25T01:01:59Z", "message": "change streaming to v2\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea69a1df3cb22f90bd93a1db601db012908be42e", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/ea69a1df3cb22f90bd93a1db601db012908be42e", "committedDate": "2021-01-25T01:18:59Z", "message": "rename streaming to v2\n\nSigned-off-by: Renkai <gaelookair@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MDU2MjM5", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-575056239", "createdAt": "2021-01-25T04:13:42Z", "commit": {"oid": "ea69a1df3cb22f90bd93a1db601db012908be42e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc1MDYyOTQ3", "url": "https://github.com/apache/pulsar/pull/9096#pullrequestreview-575062947", "createdAt": "2021-01-25T04:42:06Z", "commit": {"oid": "ea69a1df3cb22f90bd93a1db601db012908be42e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4835d43f1abba4183f2e93814690307de72d787", "author": {"user": {"login": "Renkai", "name": "Renkai Ge"}}, "url": "https://github.com/apache/pulsar/commit/e4835d43f1abba4183f2e93814690307de72d787", "committedDate": "2021-01-25T14:04:52Z", "message": "Merge branch 'master' into new-offloader"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 876, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}