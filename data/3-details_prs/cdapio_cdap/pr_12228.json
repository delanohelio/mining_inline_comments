{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI1MjQ2Mjk5", "number": 12228, "title": "CDAP-16709 implemented auto-join for spark streaming", "bodyText": "Implemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory.", "createdAt": "2020-05-29T18:01:31Z", "url": "https://github.com/cdapio/cdap/pull/12228", "merged": true, "mergeCommit": {"oid": "8c2bb2d5e1d55c2dc19c948f0798b911768635e8"}, "closed": true, "closedAt": "2020-05-29T23:10:10Z", "author": {"login": "albertshau"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcmHsC9gFqTQyMTIyNzQxMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcmKnHngBqjMzODkwOTg5Mjc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMjI3NDEx", "url": "https://github.com/cdapio/cdap/pull/12228#pullrequestreview-421227411", "createdAt": "2020-05-29T19:29:24Z", "commit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxOToyOToyNFrOGcpW2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxOTozMTo1MVrOGcpa7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MDkwNg==", "bodyText": "Any reason we changed this? Since AutoJoin only supports StructuredRecord, it is cleaner to just keep it here to avoid the unnecessary type cast changes in the class", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432690906", "createdAt": "2020-05-29T19:29:24Z", "author": {"login": "yaojiefeng"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-core/src/main/java/io/cdap/cdap/etl/common/plugin/JoinerBridge.java", "diffHunk": "@@ -38,8 +38,10 @@\n \n /**\n  * An implementation of {@link BatchJoiner} using a {@link BatchAutoJoiner}.\n+ *\n+ * @param <INPUT_RECORD> type of input record\n  */\n-public class JoinerBridge extends BatchJoiner<StructuredRecord, StructuredRecord, StructuredRecord> {\n+public class JoinerBridge<INPUT_RECORD> extends BatchJoiner<StructuredRecord, INPUT_RECORD, StructuredRecord> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTE0NQ==", "bodyText": "nit - extra line", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691145", "createdAt": "2020-05-29T19:29:58Z", "author": {"login": "yaojiefeng"}, "path": "cdap-app-templates/cdap-etl/hydrator-spark-core-base/src/main/java/io/cdap/cdap/etl/spark/SparkPipelineRunner.java", "diffHunk": "@@ -359,6 +332,39 @@ public void runPipeline(PipelinePhase pipelinePhase, String sourcePluginType,\n     }\n   }\n \n+  protected SparkCollection<Object> handleJoin(Map<String, SparkCollection<Object>> inputDataCollections,\n+                                               PipelinePhase pipelinePhase, PluginFunctionContext pluginFunctionContext,\n+                                               StageSpec stageSpec, Object plugin, Integer numPartitions,\n+                                               StageStatisticsCollector collector) throws Exception {\n+    String stageName = stageSpec.getName();\n+    if (plugin instanceof BatchJoiner) {\n+      BatchJoiner<Object, Object, Object> joiner = (BatchJoiner<Object, Object, Object>) plugin;\n+      BatchJoinerRuntimeContext joinerRuntimeContext = pluginFunctionContext.createBatchRuntimeContext();\n+      joiner.initialize(joinerRuntimeContext);\n+\n+      return handleJoin(joiner, inputDataCollections, stageSpec, numPartitions, collector).cache();\n+    } else if (plugin instanceof AutoJoiner) {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTUwOA==", "bodyText": "Do we need the check here? I remember we have some earlier validation before we get here", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691508", "createdAt": "2020-05-29T19:30:46Z", "author": {"login": "yaojiefeng"}, "path": "cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/SparkStreamingPipelineRunner.java", "diffHunk": "@@ -123,4 +135,43 @@ public SparkStreamingPipelineRunner(JavaSparkExecutionContext sec, JavaStreaming\n     JavaDStream<Object> result = pairDStream.transform(new DynamicJoinMerge<>(dynamicDriverContext));\n     return new DStreamCollection<>(sec, result);\n   }\n+\n+  @Override\n+  protected SparkCollection<Object> handleJoin(Map<String, SparkCollection<Object>> inputDataCollections,\n+                                               PipelinePhase pipelinePhase, PluginFunctionContext pluginFunctionContext,\n+                                               StageSpec stageSpec, Object plugin, Integer numPartitions,\n+                                               StageStatisticsCollector collector) throws Exception {\n+    String stageName = stageSpec.getName();\n+    BatchJoiner<?, ?, ?> joiner;\n+    if (plugin instanceof BatchAutoJoiner) {\n+      BatchAutoJoiner autoJoiner = (BatchAutoJoiner) plugin;\n+\n+      Map<String, JoinStage> inputStages = new HashMap<>();\n+      for (String inputStageName : pipelinePhase.getStageInputs(stageName)) {\n+        StageSpec inputStageSpec = pipelinePhase.getStage(inputStageName);\n+        inputStages.put(inputStageName,\n+                        JoinStage.builder(inputStageName, inputStageSpec.getOutputSchema()).build());\n+      }\n+      AutoJoinerContext autoJoinerContext = new DefaultAutoJoinerContext(inputStages);\n+\n+      JoinDefinition joinDefinition = autoJoiner.define(autoJoinerContext);\n+      if (joinDefinition == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTk1MQ==", "bodyText": "Have seen this logic in multiple places, do you think it is possible to have an utility class for this logic?", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691951", "createdAt": "2020-05-29T19:31:51Z", "author": {"login": "yaojiefeng"}, "path": "cdap-app-templates/cdap-etl/hydrator-spark-core-base/src/main/java/io/cdap/cdap/etl/spark/function/JoinMergeFunction.java", "diffHunk": "@@ -64,6 +66,28 @@ public JoinMergeFunction(PluginFunctionContext pluginFunctionContext) {\n     return emitter.getEntries();\n   }\n \n+  private <K, V, O> BatchJoiner<K, V, O> createInitializedJoiner() throws Exception {\n+    Object plugin = pluginFunctionContext.createPlugin();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMzA4OTcz", "url": "https://github.com/cdapio/cdap/pull/12228#pullrequestreview-421308973", "createdAt": "2020-05-29T21:40:08Z", "commit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "497ac3623dc87f25716970cb495dcc1d926ad2b9", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/497ac3623dc87f25716970cb495dcc1d926ad2b9", "committedDate": "2020-05-29T22:56:43Z", "message": "CDAP-16709 implemented auto-join for spark streaming\n\nImplemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\n\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4d363e78eb0372e797cd8a28e4850183ef142819", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/4d363e78eb0372e797cd8a28e4850183ef142819", "committedDate": "2020-05-29T17:57:15Z", "message": "CDAP-16709 implemented auto-join for spark streaming\n\nImplemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\n\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory."}, "afterCommit": {"oid": "497ac3623dc87f25716970cb495dcc1d926ad2b9", "author": {"user": {"login": "albertshau", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/497ac3623dc87f25716970cb495dcc1d926ad2b9", "committedDate": "2020-05-29T22:56:43Z", "message": "CDAP-16709 implemented auto-join for spark streaming\n\nImplemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\n\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2103, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}