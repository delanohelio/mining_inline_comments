{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzOTY5MTgw", "number": 12209, "title": "Feature release/cdap 16855 spark impl aggregator1", "bodyText": "JIRA: https://issues.cask.co/browse/CDAP-16855\nbuild: https://builds.cask.co/browse/CDAP-RUT1786-1\nReopen #12204  with conflicts resolved\nImplemented reducer as aggregator improvement for batch spark pipelines. This changes the use of groupByKey to reduceByKey which will do a map side reduce before do the aggregation. A reduce function will need to be provided to achieve this", "createdAt": "2020-05-27T16:24:47Z", "url": "https://github.com/cdapio/cdap/pull/12209", "merged": true, "mergeCommit": {"oid": "0000d65ed69f1f7b56d00a7b8af17c2d145a5d25"}, "closed": true, "closedAt": "2020-05-29T17:24:48Z", "author": {"login": "yaojiefeng"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcldjmsgFqTQxOTQ4NDM0NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcmFqd_gBqjMzODgwNzkxNzY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NDg0MzQ1", "url": "https://github.com/cdapio/cdap/pull/12209#pullrequestreview-419484345", "createdAt": "2020-05-27T18:08:07Z", "commit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODowODowOFrOGbXJUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxODoyNzoxNlrOGbXzpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0Mzk1Mg==", "bodyText": "this isn't needed anymore", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431343952", "createdAt": "2020-05-27T18:08:08Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-api/src/main/java/io/cdap/cdap/etl/api/Aggregator.java", "diffHunk": "@@ -45,7 +45,7 @@\n    * Aggregate all objects in the same group into zero or more output objects.\n    *\n    * @param groupKey the key for the group\n-   * @param groupValues an iterator over all input objects that have the same group key\n+   * @param groupValues an iterator contains the group values associated with the group key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0NDQ2NA==", "bodyText": "collections, and -> collections and", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431344464", "createdAt": "2020-05-27T18:09:04Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-api/src/main/java/io/cdap/cdap/etl/api/ReduceAggregator.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.api;\n+\n+import io.cdap.cdap.api.annotation.Beta;\n+\n+/**\n+ * Groups all input objects into collections, and performs an aggregation on the entire group.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0Njg0Ng==", "bodyText": "When possible, this interface should be used over the {@link Aggregator} interface because this performs better. \nAn {@link Aggregator} will shuffle all data across the cluster before aggregating, whereas\nthis will aggregate both before and after the shuffle.\nThis reduces the amount of data that needs to be sent over the network, as well as reducing the amount\nof memory required to perform the aggregation.", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431346846", "createdAt": "2020-05-27T18:13:13Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-api/src/main/java/io/cdap/cdap/etl/api/ReduceAggregator.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.api;\n+\n+import io.cdap.cdap.api.annotation.Beta;\n+\n+/**\n+ * Groups all input objects into collections, and performs an aggregation on the entire group.\n+ * Objects that have the same group key are placed into the same group for aggregation.\n+ * It has better performance than {@link Aggregator} since the number of group values is reduced in each split before", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1MDA0MA==", "bodyText": "Data is then shuffled across the cluster such that records with the same key are handled by the same executor:\nSplit 4: (key1, sum: 6, count: 3), (key1, sum:9, count:3), (key1, sum:12, count:3)\nSplit 5: (key2, sum:4, count:1), (key2, sum:4, count:1), (key2, sum:4, count:1)\nThe reduce function is called again to generate:\nSplit 4: (key1, sum:27, count:9)\nSplit 5: (key2, sum:12, count:3)\nFinally, the transform method is called to generate the final output value(s):\nSplit 4: (key1, avg: 3)\nSplit 5: (key2, avg: 3)", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431350040", "createdAt": "2020-05-27T18:18:47Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-api/src/main/java/io/cdap/cdap/etl/api/ReduceAggregator.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.api;\n+\n+import io.cdap.cdap.api.annotation.Beta;\n+\n+/**\n+ * Groups all input objects into collections, and performs an aggregation on the entire group.\n+ * Objects that have the same group key are placed into the same group for aggregation.\n+ * It has better performance than {@link Aggregator} since the number of group values is reduced in each split before\n+ * grouping all the values for the group key.\n+ *\n+ * For example, to aggregate and compute the average for the values, the plugin will first group all the values based\n+ * on the group key, considering it generates following splits:\n+ * Split 1: (key1, 1), (key1, 2), (key1, 3), (key2, 4)\n+ * Split 2: (key1, 2), (key1, 3), (key1, 4), (key2, 4)\n+ * Split 3: (key1, 3), (key1, 4), (key1, 5), (key2, 4)\n+ * The reduce function will be called in each split to generate following:\n+ * Split 1: (key1, sum: 6, count: 3), (key2, sum: 4, count: 1)\n+ * Split 2: (key1, sum: 9, count: 3), (key2, sum: 4, count: 1)\n+ * Split 3: (key1, sum: 12, count: 3), (key2, sum: 4, count: 1)\n+ * Then reduce function is called when grouping all values in the split:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1MDY2MQ==", "bodyText": "aggregate is a misleading name now because nothing is really being aggregated. transform(), or finalize() or some other name would be more appropriate.", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431350661", "createdAt": "2020-05-27T18:19:58Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-api/src/main/java/io/cdap/cdap/etl/api/ReduceAggregator.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.api;\n+\n+import io.cdap.cdap.api.annotation.Beta;\n+\n+/**\n+ * Groups all input objects into collections, and performs an aggregation on the entire group.\n+ * Objects that have the same group key are placed into the same group for aggregation.\n+ * It has better performance than {@link Aggregator} since the number of group values is reduced in each split before\n+ * grouping all the values for the group key.\n+ *\n+ * For example, to aggregate and compute the average for the values, the plugin will first group all the values based\n+ * on the group key, considering it generates following splits:\n+ * Split 1: (key1, 1), (key1, 2), (key1, 3), (key2, 4)\n+ * Split 2: (key1, 2), (key1, 3), (key1, 4), (key2, 4)\n+ * Split 3: (key1, 3), (key1, 4), (key1, 5), (key2, 4)\n+ * The reduce function will be called in each split to generate following:\n+ * Split 1: (key1, sum: 6, count: 3), (key2, sum: 4, count: 1)\n+ * Split 2: (key1, sum: 9, count: 3), (key2, sum: 4, count: 1)\n+ * Split 3: (key1, sum: 12, count: 3), (key2, sum: 4, count: 1)\n+ * Then reduce function is called when grouping all values in the split:\n+ * Grouped result 1: (key1, sum: 27, count: 9)\n+ * Grouped result 2: (key2, sum: 12, count: 3)\n+ * At last, aggregate function is called to generate final result:\n+ * Final: (key1, avg: 3), (key2, avg: 4)\n+ *\n+ * @param <GROUP_KEY> Type of group key\n+ * @param <GROUP_VALUE> Type of values to group\n+ * @param <OUT> Type of output object\n+ */\n+@Beta\n+public interface ReduceAggregator<GROUP_KEY, GROUP_VALUE, OUT> {\n+\n+  /**\n+   * Emit the group key(s) for a given input value. If no group key is emitted, the input value\n+   * is filtered out. If multiple group keys are emitted, the input value will be present in multiple groups.\n+   *\n+   * @param groupValue the value to group\n+   * @param emitter the emitter to emit zero or more group keys for the input\n+   * @throws Exception if there is some error getting the group\n+   */\n+  void groupBy(GROUP_VALUE groupValue, Emitter<GROUP_KEY> emitter) throws Exception;\n+\n+  /**\n+   * Reduce the given values to a single value. This method is called before and after grouping of the keys.\n+   * For example, to compute the sum, the returned value will be the sum of two given values.\n+   * To compute average, the returned value will contain the sum and count for the two given values.\n+   *\n+   * @param value1 the value to reduce\n+   * @param value2 the value to reduce\n+   * @return the aggregated value of two given values\n+   */\n+  GROUP_VALUE reduce(GROUP_VALUE value1, GROUP_VALUE value2) throws Exception;\n+\n+  /**\n+   * Aggregate the grouped object for the group key into zero or more output objects.\n+   * The group value will only contain one value which contains the aggregated stats for\n+   * all the values, this method can use this stat to compute the desired result, i.e, average, standard deviation\n+   *\n+   * @param groupKey the key for the group\n+   * @param groupValue the group value associated with the group key\n+   * @param emitter the emitter to emit aggregate values for the group\n+   * @throws Exception if there is some error aggregating\n+   */\n+  void aggregate(GROUP_KEY groupKey, GROUP_VALUE groupValue, Emitter<OUT> emitter) throws Exception;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1MTU1OA==", "bodyText": "is this any different than createAggregator? can they be combined somehow? Or maybe the closure be made into a single class that gets re-used?", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431351558", "createdAt": "2020-05-27T18:21:38Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-batch/src/main/java/io/cdap/cdap/etl/batch/mapreduce/MapReducePreparer.java", "diffHunk": "@@ -188,6 +189,32 @@ protected SubmitterPlugin createAggregator(BatchAggregator<?, ?, ?> aggregator,\n     });\n   }\n \n+  @Override\n+  protected SubmitterPlugin createReduceAggregator(BatchReduceAggregator<?, ?, ?> aggregator, StageSpec stageSpec) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1MjM1Nw==", "bodyText": "timer should be started for this too, this is where most of the work is happening.", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431352357", "createdAt": "2020-05-27T18:23:05Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/cdap-etl-core/src/main/java/io/cdap/cdap/etl/common/plugin/WrappedReduceAggregator.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.common.plugin;\n+\n+import io.cdap.cdap.etl.api.Emitter;\n+import io.cdap.cdap.etl.api.PipelineConfigurer;\n+import io.cdap.cdap.etl.api.batch.BatchAggregatorContext;\n+import io.cdap.cdap.etl.api.batch.BatchReduceAggregator;\n+import io.cdap.cdap.etl.api.batch.BatchRuntimeContext;\n+import io.cdap.cdap.etl.common.TypeChecker;\n+\n+import java.util.concurrent.Callable;\n+\n+/**\n+ * Wrapper around {@link BatchReduceAggregator} that makes sure logging, classloading, and other pipeline capabilities\n+ * are setup correctly.\n+ *\n+ * @param <GROUP_KEY> group key type. Must be a supported type\n+ * @param <GROUP_VALUE> group value type. Must be a supported type\n+ * @param <OUT> output object type\n+ */\n+public class WrappedReduceAggregator<GROUP_KEY, GROUP_VALUE, OUT>\n+  extends BatchReduceAggregator<GROUP_KEY, GROUP_VALUE, OUT>  {\n+  private final BatchReduceAggregator<GROUP_KEY, GROUP_VALUE, OUT> aggregator;\n+  private final Caller caller;\n+  private final OperationTimer operationTimer;\n+\n+  public WrappedReduceAggregator(BatchReduceAggregator<GROUP_KEY, GROUP_VALUE, OUT> aggregator, Caller caller,\n+                                 OperationTimer operationTimer) {\n+    this.aggregator = aggregator;\n+    this.caller = caller;\n+    this.operationTimer = operationTimer;\n+  }\n+\n+  @Override\n+  public void configurePipeline(PipelineConfigurer pipelineConfigurer) {\n+    caller.callUnchecked((Callable<Void>) () -> {\n+      aggregator.configurePipeline(pipelineConfigurer);\n+      return null;\n+    });\n+  }\n+\n+  @Override\n+  public void initialize(BatchRuntimeContext context) throws Exception {\n+    caller.call((Callable<Void>) () -> {\n+      aggregator.initialize(context);\n+      return null;\n+    });\n+  }\n+\n+  @Override\n+  public void destroy() {\n+    caller.callUnchecked((Callable<Void>) () -> {\n+      aggregator.destroy();\n+      return null;\n+    });\n+  }\n+\n+  @Override\n+  public void prepareRun(BatchAggregatorContext context) throws Exception {\n+    context.setGroupKeyClass(TypeChecker.getGroupKeyClass(aggregator));\n+    context.setGroupValueClass(TypeChecker.getGroupValueClass(aggregator));\n+    caller.call((Callable<Void>) () -> {\n+      aggregator.prepareRun(context);\n+      return null;\n+    });\n+  }\n+\n+  @Override\n+  public void onRunFinish(boolean succeeded, BatchAggregatorContext context) {\n+    caller.callUnchecked((Callable<Void>) () -> {\n+      aggregator.onRunFinish(succeeded, context);\n+      return null;\n+    });\n+  }\n+\n+  @Override\n+  public void groupBy(GROUP_VALUE groupValue, Emitter<GROUP_KEY> emitter) throws Exception {\n+    operationTimer.start();\n+    try {\n+      caller.call((Callable<Void>) () -> {\n+        aggregator.groupBy(groupValue, new UntimedEmitter<>(emitter, operationTimer));\n+        return null;\n+      });\n+    } finally {\n+      operationTimer.reset();\n+    }\n+  }\n+\n+  @Override\n+  public void aggregate(GROUP_KEY groupKey, GROUP_VALUE groupValues,\n+                        Emitter<OUT> emitter) throws Exception {\n+    operationTimer.start();\n+    try {\n+      caller.call((Callable<Void>) () -> {\n+        aggregator.aggregate(groupKey, groupValues, new UntimedEmitter<>(emitter, operationTimer));\n+        return null;\n+      });\n+    } finally {\n+      operationTimer.reset();\n+    }\n+  }\n+\n+  @Override\n+  public GROUP_VALUE reduce(GROUP_VALUE value1, GROUP_VALUE value2) throws Exception {\n+    return caller.call(() -> aggregator.reduce(value1, value2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1MzcyNg==", "bodyText": "nit: fix error message", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431353726", "createdAt": "2020-05-27T18:25:20Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/hydrator-spark-core-base/src/main/java/io/cdap/cdap/etl/spark/streaming/DStreamCollection.java", "diffHunk": "@@ -131,6 +131,14 @@ public DStreamCollection(JavaSparkExecutionContext sec, JavaDStream<T> stream) {\n     return wrap(groupedCollection.transform(new DynamicAggregatorAggregate<Object, T, Object>(dynamicDriverContext)));\n   }\n \n+  @Override\n+  public SparkCollection<RecordInfo<Object>> reduceAggregate(StageSpec stageSpec, @Nullable Integer partitions,\n+                                                             StageStatisticsCollector collector) {\n+    // TODO: implement\n+    throw new UnsupportedOperationException(\"auto join not supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1NDY0Mw==", "bodyText": "nit: reduceaggregator is pretty verbose, I think it's fine to just put it in aggregator", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431354643", "createdAt": "2020-05-27T18:27:03Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/hydrator-test/src/main/java/io/cdap/cdap/etl/mock/batch/reduceaggregator/FieldCountReduceAggregator.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.mock.batch.reduceaggregator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM1NDc4OQ==", "bodyText": "nit: reduceaggregator is pretty verbose, I think it's fine to just put it in aggregator", "url": "https://github.com/cdapio/cdap/pull/12209#discussion_r431354789", "createdAt": "2020-05-27T18:27:16Z", "author": {"login": "albertshau"}, "path": "cdap-app-templates/cdap-etl/hydrator-test/src/main/java/io/cdap/cdap/etl/mock/batch/reduceaggregator/DistinctReduceAggregator.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.etl.mock.batch.reduceaggregator;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5166932c2e0c3b2aec49b137fd4314faaba56680"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NjI2MzQx", "url": "https://github.com/cdapio/cdap/pull/12209#pullrequestreview-419626341", "createdAt": "2020-05-27T21:35:37Z", "commit": {"oid": "258f80606502d375338395cf25903df83a30f634"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "119679b19b9e13a95005e8fc9961243fe3003dc1", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/119679b19b9e13a95005e8fc9961243fe3003dc1", "committedDate": "2020-05-29T04:24:08Z", "message": "make api more generic"}, "afterCommit": {"oid": "cbeb04aa2e0704f61614cb8884eec611e5fdcf2b", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/cbeb04aa2e0704f61614cb8884eec611e5fdcf2b", "committedDate": "2020-05-29T15:48:07Z", "message": "make api more generic"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMTIxNTg2", "url": "https://github.com/cdapio/cdap/pull/12209#pullrequestreview-421121586", "createdAt": "2020-05-29T16:50:46Z", "commit": {"oid": "cbeb04aa2e0704f61614cb8884eec611e5fdcf2b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cbeb04aa2e0704f61614cb8884eec611e5fdcf2b", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/cbeb04aa2e0704f61614cb8884eec611e5fdcf2b", "committedDate": "2020-05-29T15:48:07Z", "message": "make api more generic"}, "afterCommit": {"oid": "cffad4769e83c94ab5a3b7d09ab25d01cdfe4382", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/cffad4769e83c94ab5a3b7d09ab25d01cdfe4382", "committedDate": "2020-05-29T16:52:05Z", "message": "CDAP-16855 aggregator spark impl"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "153d697e6e33185cd0a45d4d89d1fc371c137edf", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/153d697e6e33185cd0a45d4d89d1fc371c137edf", "committedDate": "2020-05-29T17:10:41Z", "message": "CDAP-16855 aggregator spark implementation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cffad4769e83c94ab5a3b7d09ab25d01cdfe4382", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/cffad4769e83c94ab5a3b7d09ab25d01cdfe4382", "committedDate": "2020-05-29T16:52:05Z", "message": "CDAP-16855 aggregator spark impl"}, "afterCommit": {"oid": "153d697e6e33185cd0a45d4d89d1fc371c137edf", "author": {"user": {"login": "yaojiefeng", "name": null}}, "url": "https://github.com/cdapio/cdap/commit/153d697e6e33185cd0a45d4d89d1fc371c137edf", "committedDate": "2020-05-29T17:10:41Z", "message": "CDAP-16855 aggregator spark implementation"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2074, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}