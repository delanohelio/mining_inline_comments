{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkxNTcxNzE0", "number": 12782, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNjo1MVrOEmxRYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMTozNToyMFrOEmynrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDg4NjExOnYy", "diffSide": "RIGHT", "path": "cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/monitor/RuntimeHandler.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNjo1MVrOHW_sog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNjo1MVrOHW_sog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDMzOA==", "bodyText": "Maybe we can use javax.ws.rs.core.MediaType.APPLICATION_OCTET_STREAM?", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493874338", "createdAt": "2020-09-23T20:26:51Z", "author": {"login": "dli357"}, "path": "cdap-app-fabric/src/main/java/io/cdap/cdap/internal/app/runtime/monitor/RuntimeHandler.java", "diffHunk": "@@ -135,14 +153,77 @@ public BodyConsumer writeMessages(HttpRequest request, HttpResponder responder,\n     });\n   }\n \n+  /**\n+   * Handles call for Spark event logs upload.\n+   */\n+  @Path(\"/spark-event-logs/{id}\")\n+  @POST\n+  public BodyConsumer writeSparkEventLogs(HttpRequest request, HttpResponder responder,\n+                                          @PathParam(\"namespace\") String namespace,\n+                                          @PathParam(\"app\") String app,\n+                                          @PathParam(\"version\") String version,\n+                                          @PathParam(\"program-type\") String programType,\n+                                          @PathParam(\"program\") String program,\n+                                          @PathParam(\"run\") String run,\n+                                          @PathParam(\"id\") String id) throws Exception {\n+    if (!eventLogsEnabled) {\n+      throw new UnsupportedOperationException(\"Spark event logs collection is not enabled\");\n+    }\n+\n+    if (!\"application/octet-stream\".equals(request.headers().get(HttpHeaderNames.CONTENT_TYPE))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDg4Njc0OnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNzowNFrOHW_tFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMToxMjo0OVrOHXBLQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDQ1NQ==", "bodyText": "nit: \"refer back\" instead of \"rely back\"", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493874455", "createdAt": "2020-09-23T20:27:04Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Adds a {@link EventLoggingListener} to the Spark context.\n+   *\n+   * @param runtimeContext the {@link SparkRuntimeContext} for connecting to CDAP services\n+   * @return A {@link Closeable} which should be called when the Spark application completed\n+   */\n+  public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeContext) throws IOException {\n+    // If upload event logs is not enabled, just return a dummy closeable\n+    if (!runtimeContext.getCConfiguration().getBoolean(Constants.AppFabric.SPARK_EVENT_LOGS_ENABLED)) {\n+      return () -> { };\n+    }\n+\n+    SparkConf sparkConf = new SparkConf();\n+    sparkConf.set(\"spark.eventLog.enabled\", Boolean.toString(true));\n+    sparkConf.set(\"spark.eventLog.compress\", Boolean.toString(true));\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n+    LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n+\n+    // EvevntLogginginListener is Scala package private[spark] class.\n+    // However, since JVM bytecode doesn't really have this type of cross package private support, the class\n+    // is actually public class. This is why we can access it in Java code.\n+    EventLoggingListener listener = new EventLoggingListener(Long.toString(System.currentTimeMillis()), Option.empty(),\n+                                                             eventLogDir.toURI(), sparkConf) {\n+      @Override\n+      public void onApplicationStart(SparkListenerApplicationStart event) {\n+        // Rewrite the application start event with identifiable names based on the program run id such that\n+        // it can rely back to the program run.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg5ODU2MA==", "bodyText": "fixed", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493898560", "createdAt": "2020-09-23T21:12:49Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Adds a {@link EventLoggingListener} to the Spark context.\n+   *\n+   * @param runtimeContext the {@link SparkRuntimeContext} for connecting to CDAP services\n+   * @return A {@link Closeable} which should be called when the Spark application completed\n+   */\n+  public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeContext) throws IOException {\n+    // If upload event logs is not enabled, just return a dummy closeable\n+    if (!runtimeContext.getCConfiguration().getBoolean(Constants.AppFabric.SPARK_EVENT_LOGS_ENABLED)) {\n+      return () -> { };\n+    }\n+\n+    SparkConf sparkConf = new SparkConf();\n+    sparkConf.set(\"spark.eventLog.enabled\", Boolean.toString(true));\n+    sparkConf.set(\"spark.eventLog.compress\", Boolean.toString(true));\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n+    LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n+\n+    // EvevntLogginginListener is Scala package private[spark] class.\n+    // However, since JVM bytecode doesn't really have this type of cross package private support, the class\n+    // is actually public class. This is why we can access it in Java code.\n+    EventLoggingListener listener = new EventLoggingListener(Long.toString(System.currentTimeMillis()), Option.empty(),\n+                                                             eventLogDir.toURI(), sparkConf) {\n+      @Override\n+      public void onApplicationStart(SparkListenerApplicationStart event) {\n+        // Rewrite the application start event with identifiable names based on the program run id such that\n+        // it can rely back to the program run.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDQ1NQ=="}, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDg4Njg4OnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNzowN1rOHW_tLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMToxMjo1M1rOHXBLZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDQ3OQ==", "bodyText": "Looks like NullPointerException will be thrown if the log directory is empty. Can we expect there to always be exactly one log file?", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493874479", "createdAt": "2020-09-23T20:27:07Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -262,4 +346,54 @@ protected void doStop() {\n       }\n     };\n   }\n+\n+  /**\n+   * Uploads the spark event logs through the runtime service.\n+   */\n+  private static void uploadEventLogs(File eventLogDir, SparkRuntimeContext runtimeContext) throws IOException {\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    // Find the event file to upload. There should only be one for the current application.\n+    File eventFile = Optional.ofNullable(eventLogDir.listFiles())\n+      .map(Arrays::stream)\n+      .flatMap(Stream::findFirst)\n+      .orElse(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg5ODU5OA==", "bodyText": "fixed", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493898598", "createdAt": "2020-09-23T21:12:53Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -262,4 +346,54 @@ protected void doStop() {\n       }\n     };\n   }\n+\n+  /**\n+   * Uploads the spark event logs through the runtime service.\n+   */\n+  private static void uploadEventLogs(File eventLogDir, SparkRuntimeContext runtimeContext) throws IOException {\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    // Find the event file to upload. There should only be one for the current application.\n+    File eventFile = Optional.ofNullable(eventLogDir.listFiles())\n+      .map(Arrays::stream)\n+      .flatMap(Stream::findFirst)\n+      .orElse(null);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDQ3OQ=="}, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDg4NzAzOnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNzoxMVrOHW_tTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMToxMjo1NlrOHXBLew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDUwOQ==", "bodyText": "Maybe we can use javax.ws.rs.core.MediaType.APPLICATION_OCTET_STREAM?", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493874509", "createdAt": "2020-09-23T20:27:11Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -262,4 +346,54 @@ protected void doStop() {\n       }\n     };\n   }\n+\n+  /**\n+   * Uploads the spark event logs through the runtime service.\n+   */\n+  private static void uploadEventLogs(File eventLogDir, SparkRuntimeContext runtimeContext) throws IOException {\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    // Find the event file to upload. There should only be one for the current application.\n+    File eventFile = Optional.ofNullable(eventLogDir.listFiles())\n+      .map(Arrays::stream)\n+      .flatMap(Stream::findFirst)\n+      .orElse(null);\n+    LOG.debug(\"Uploading event file {} for program run {}\", eventFile, programRunId);\n+\n+    RemoteClient remoteClient = new RemoteClient(runtimeContext.getDiscoveryServiceClient(), Constants.Service.RUNTIME,\n+                                                 new DefaultHttpRequestConfig(false),\n+                                                 Constants.Gateway.INTERNAL_API_VERSION_3 + \"/runtime/namespaces/\");\n+    String path = String.format(\"%s/apps/%s/versions/%s/%s/%s/runs/%s/spark-event-logs/%s\",\n+                                programRunId.getNamespace(),\n+                                programRunId.getApplication(),\n+                                programRunId.getVersion(),\n+                                programRunId.getType().getCategoryName(),\n+                                programRunId.getProgram(),\n+                                programRunId.getRun(),\n+                                eventFile.getName());\n+\n+    Retries.runWithRetries(() -> {\n+      // Stream out the messages\n+      HttpURLConnection urlConn = remoteClient.openConnection(HttpMethod.POST, path);\n+      try {\n+        urlConn.setChunkedStreamingMode(CHUNK_SIZE);\n+        urlConn.setRequestProperty(HttpHeaders.CONTENT_TYPE, \"application/octet-stream\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 226}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg5ODYxOQ==", "bodyText": "fixed", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493898619", "createdAt": "2020-09-23T21:12:56Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -262,4 +346,54 @@ protected void doStop() {\n       }\n     };\n   }\n+\n+  /**\n+   * Uploads the spark event logs through the runtime service.\n+   */\n+  private static void uploadEventLogs(File eventLogDir, SparkRuntimeContext runtimeContext) throws IOException {\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    // Find the event file to upload. There should only be one for the current application.\n+    File eventFile = Optional.ofNullable(eventLogDir.listFiles())\n+      .map(Arrays::stream)\n+      .flatMap(Stream::findFirst)\n+      .orElse(null);\n+    LOG.debug(\"Uploading event file {} for program run {}\", eventFile, programRunId);\n+\n+    RemoteClient remoteClient = new RemoteClient(runtimeContext.getDiscoveryServiceClient(), Constants.Service.RUNTIME,\n+                                                 new DefaultHttpRequestConfig(false),\n+                                                 Constants.Gateway.INTERNAL_API_VERSION_3 + \"/runtime/namespaces/\");\n+    String path = String.format(\"%s/apps/%s/versions/%s/%s/%s/runs/%s/spark-event-logs/%s\",\n+                                programRunId.getNamespace(),\n+                                programRunId.getApplication(),\n+                                programRunId.getVersion(),\n+                                programRunId.getType().getCategoryName(),\n+                                programRunId.getProgram(),\n+                                programRunId.getRun(),\n+                                eventFile.getName());\n+\n+    Retries.runWithRetries(() -> {\n+      // Stream out the messages\n+      HttpURLConnection urlConn = remoteClient.openConnection(HttpMethod.POST, path);\n+      try {\n+        urlConn.setChunkedStreamingMode(CHUNK_SIZE);\n+        urlConn.setRequestProperty(HttpHeaders.CONTENT_TYPE, \"application/octet-stream\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDUwOQ=="}, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 226}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDg4NzI3OnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDoyNzoxNVrOHW_tdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMToxMjo0NVrOHXBLJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDU1MA==", "bodyText": "nit: EventLoggingListener", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493874550", "createdAt": "2020-09-23T20:27:15Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Adds a {@link EventLoggingListener} to the Spark context.\n+   *\n+   * @param runtimeContext the {@link SparkRuntimeContext} for connecting to CDAP services\n+   * @return A {@link Closeable} which should be called when the Spark application completed\n+   */\n+  public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeContext) throws IOException {\n+    // If upload event logs is not enabled, just return a dummy closeable\n+    if (!runtimeContext.getCConfiguration().getBoolean(Constants.AppFabric.SPARK_EVENT_LOGS_ENABLED)) {\n+      return () -> { };\n+    }\n+\n+    SparkConf sparkConf = new SparkConf();\n+    sparkConf.set(\"spark.eventLog.enabled\", Boolean.toString(true));\n+    sparkConf.set(\"spark.eventLog.compress\", Boolean.toString(true));\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n+    LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n+\n+    // EvevntLogginginListener is Scala package private[spark] class.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg5ODUzMg==", "bodyText": "fixed", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493898532", "createdAt": "2020-09-23T21:12:45Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Adds a {@link EventLoggingListener} to the Spark context.\n+   *\n+   * @param runtimeContext the {@link SparkRuntimeContext} for connecting to CDAP services\n+   * @return A {@link Closeable} which should be called when the Spark application completed\n+   */\n+  public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeContext) throws IOException {\n+    // If upload event logs is not enabled, just return a dummy closeable\n+    if (!runtimeContext.getCConfiguration().getBoolean(Constants.AppFabric.SPARK_EVENT_LOGS_ENABLED)) {\n+      return () -> { };\n+    }\n+\n+    SparkConf sparkConf = new SparkConf();\n+    sparkConf.set(\"spark.eventLog.enabled\", Boolean.toString(true));\n+    sparkConf.set(\"spark.eventLog.compress\", Boolean.toString(true));\n+\n+    ProgramRunId programRunId = runtimeContext.getProgramRunId();\n+\n+    File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n+    LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n+\n+    // EvevntLogginginListener is Scala package private[spark] class.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NDU1MA=="}, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MDkwNDUwOnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDozMjoxN1rOHW_35g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMToxMjo0MVrOHXBK8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NzIyMg==", "bodyText": "Should we log a warning if the wait times out? That way if logs are missing we can easily tell that is was due to the timeout or some other reason.", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493877222", "createdAt": "2020-09-23T20:32:17Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg5ODQ4Mw==", "bodyText": "Added a log", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493898483", "createdAt": "2020-09-23T21:12:41Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -232,10 +258,68 @@ private void handleCompleted(boolean failure) {\n         if (failure && driverService instanceof SparkDriverService) {\n           ((SparkDriverService) driverService).stopWithoutComplete();\n         } else {\n-          driverService.stopAndWait();\n+          driverService.stop();\n         }\n+\n+        // Wait for the spark execution context to stop to make sure everything related\n+        // to the spark execution is shutdown properly before returning.\n+        // When this method returns, the driver's main thread returns, which will have system services shutdown\n+        // and process terminated. If system services stopped concurrently with the execution context, we may have some\n+        // logs and tasks missing.\n+        Uninterruptibles.awaitUninterruptibly(secStopLatch, 30, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NzIyMg=="}, "originalCommit": {"oid": "57e89749873dcd4d106a7b9e51f5259ddfbefb52"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA5MTEwNzAxOnYy", "diffSide": "RIGHT", "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMTozNToyMFrOHXBz6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMjowOTowNVrOHXCscw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzkwODk3MQ==", "bodyText": "nit: EventLoggingListener instead of EvevntLoggingListener", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493908971", "createdAt": "2020-09-23T21:35:20Z", "author": {"login": "dli357"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -292,15 +295,15 @@ public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeConte\n     File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n     LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n \n-    // EvevntLogginginListener is Scala package private[spark] class.\n+    // EvevntLoggingListener is Scala package private[spark] class.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c65437c6416a142acb171443babf21f591e0c16"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzkyMzQ0Mw==", "bodyText": "fixed", "url": "https://github.com/cdapio/cdap/pull/12782#discussion_r493923443", "createdAt": "2020-09-23T22:09:05Z", "author": {"login": "chtyim"}, "path": "cdap-spark-core-base/src/main/java/io/cdap/cdap/app/runtime/spark/SparkRuntimeUtils.java", "diffHunk": "@@ -292,15 +295,15 @@ public static Closeable addEventLoggingListener(SparkRuntimeContext runtimeConte\n     File eventLogDir = Files.createTempDirectory(\"spark-events\").toFile();\n     LOG.debug(\"Spark events log directory for {} is {}\", programRunId, eventLogDir);\n \n-    // EvevntLogginginListener is Scala package private[spark] class.\n+    // EvevntLoggingListener is Scala package private[spark] class.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzkwODk3MQ=="}, "originalCommit": {"oid": "5c65437c6416a142acb171443babf21f591e0c16"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3043, "cost": 1, "resetAt": "2021-11-12T18:49:56Z"}}}