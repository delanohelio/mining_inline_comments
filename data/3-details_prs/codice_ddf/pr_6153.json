{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQwMzA0ODcz", "number": 6153, "title": "DDF-6152 Added standalone solr gazetteer", "bodyText": "What does this PR do?\nAdds a standalone solr gazetteer\nGood writeup in comment below\nWho is reviewing it?\n@pklinef\n@Lambeaux\nHow should this be tested?\n\n\nBuild PR\n\n\nUnzip and start distribution\n2a. ./bin/ddf\n2b. profile:install standard\n\n\nInstall standalone solr gazetteer feature, feature:install catalog-solr-offline-gazetteer\n\n\nIf you don't have a working version of catalog-ui , build and then install (ddf-ui master should be working with codice/ddf/master (2.26.0-SNAPSHOT))\n4a. install catalog-ui, feature:repo-add mvn:org.codice.ddf.search/intrigue-ui-app/3.7.0-SNAPSHOT/xml/features && feature:repo-add mvn:org.codice.ddf.search/ui-frontend/3.7.0-SNAPSHOT/xml/features && feature:install catalog-ui-app ui-frontend\n\n\nGo to admin settings and configure catalog-ui to use offline gazetteer\n5a. https://localhost:8993/admin\n5b. click system tab on top of page\n5c. search for catalog ui\n5d. edit config and uncheck the box labeled Use online gazetteer service\n\n\nIngest gazetteer data\n6a. feature:install offline-gazetteer-index\n6b. It may take 5-20 minutes for all ~70k records to install\n\n\nEnsure the data has been picked up by the catalog plugin and placed into the core\n7a. visit https://localhost:8994/solr.\n7b. Select gazetteer core > query > run the default query and ensure there is ~70k items in the core\n\n\nBuild the suggester  by running the offline-solr-gazetteer:build-suggester-index command\n8a. You can also build the suggester from the solr dashboard (https://localhost:8994/solr). Go to gazetteer core >  query > change request handler (qt) to /gazetteer and inside Raw Query Parameters place suggest.build=true&suggest.dictionary=gazetteerSuggest\n\n\nGo to intrigue https://localhost:8993/search/catalog\n9a. Use the gazetteer search in top right corner of 3d map and ensure searching works\n\n\nUse the advanced search of intrigue to search for gazetteer records in the catalog\n10a. New Search > (triple dot overflow menu) > Advanced Search > Attribute= metacard-tags and value= gazetteer\n10b. Modify one item to have a new title with easily searchable text, eg itworks.\n10c. Rebuild the suggester (See step 8 and 8a)\n10d. Use gazetteer search (See step 9) and ensure you can find itworks with gazetteer\n\n\nUse the advanced search (see step 10a) to find a gazetteer record and delete it\n11a. Rebuild the suggester (see steps 8 and 8a)\n11b. ensure that item does not appear in the gazetteer.\n\n\nuse the offline-solr-gazetteer:removeall command and wait to make sure it removes all items.\n12a. wait at least 30 seconds for the index to flush\n12b. rebuild the suggester index (see step 8)\n12c. ensure no records are in gazetteer by searching with gazetteer\n12d. use the offline-solr-gazetteer:synccatalog to sync the catalog with the gazetteer core.\n12e. wait at least 30 seconds for the index to flush\n12f. rebuild the suggester index (see step 8)\n12g. ensure gazetteer in intrigue works and gets results.\n\n\nAny background context you want to provide?\nWhat are the relevant tickets?\nFixes: #6152\nChecklist:\n\n Documentation Updated\n Update / Add Threat Dragon models\n Update / Add Unit Tests\n Update / Add Integration Tests\n\nNotes on Review Process\nPlease see Notes on Review Process for further guidance on requirements for merging and abbreviated reviews.\nReview Comment Legend:\n\n\u270f\ufe0f (Pencil) This comment is a nitpick or style suggestion, no action required for approval. This comment should provide a suggestion either as an in line code snippet or a gist.\n\u2753 (Question Mark) This comment is to gain a clearer understanding of design or code choices, clarification is required but action may not be necessary for approval.\n\u2757 (Exclamation Mark) This comment is critical and requires clarification or action before approval.", "createdAt": "2020-06-25T23:23:13Z", "url": "https://github.com/codice/ddf/pull/6153", "merged": true, "mergeCommit": {"oid": "f8c83b8ad4c6e7d10ee4fadf995f1ca5f6c31961"}, "closed": true, "closedAt": "2020-08-12T00:53:07Z", "author": {"login": "rzwiefel"}, "timelineItems": {"totalCount": 44, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwIYl-gBqjM0OTQ3NTA2MzQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc6INWrgFqTQ1ODgyODc2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "343aae3ee24f31db5a8562ecd7abf74081c3fc01", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/343aae3ee24f31db5a8562ecd7abf74081c3fc01", "committedDate": "2020-06-25T23:19:38Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "3d7b2b05b2443c407fb7c2a16395eca1ccbe53f8", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/3d7b2b05b2443c407fb7c2a16395eca1ccbe53f8", "committedDate": "2020-06-29T22:00:15Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3d7b2b05b2443c407fb7c2a16395eca1ccbe53f8", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/3d7b2b05b2443c407fb7c2a16395eca1ccbe53f8", "committedDate": "2020-06-29T22:00:15Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "d0d3ce3d1325fabd1b65e6953f678e19e75329cf", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/d0d3ce3d1325fabd1b65e6953f678e19e75329cf", "committedDate": "2020-06-29T22:30:13Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d0d3ce3d1325fabd1b65e6953f678e19e75329cf", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/d0d3ce3d1325fabd1b65e6953f678e19e75329cf", "committedDate": "2020-06-29T22:30:13Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/cc7d19c20f926c1b37a7b3926608b9f97d5d66f9", "committedDate": "2020-06-30T17:11:05Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMjY4NTQx", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-440268541", "createdAt": "2020-06-30T18:11:31Z", "commit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxMTozMVrOGrIqwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxMTozMVrOGrIqwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4Mzk2OA==", "bodyText": "remove", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447883968", "createdAt": "2020-06-30T18:11:31Z", "author": {"login": "rzwiefel"}, "path": "catalog/spatial/spatial-app/src/main/resources/features.xml", "diffHunk": "@@ -147,6 +147,8 @@\n         <bundle>mvn:org.codice.ddf.spatial/spatial-geocoding-plugin/${project.version}</bundle>\n     </feature>\n \n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMjcwNzI3", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-440270727", "createdAt": "2020-06-30T18:14:39Z", "commit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxNDozOVrOGrIyjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxNDozOVrOGrIyjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NTk2NA==", "bodyText": "This fixes an existing issue (that was caused by a previous dependency upgrade if i recall correctly)", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447885964", "createdAt": "2020-06-30T18:14:39Z", "author": {"login": "rzwiefel"}, "path": "catalog/spatial/geocoding/spatial-geocoding-offline-index/pom.xml", "diffHunk": "@@ -116,6 +116,7 @@\n                         </Embed-Dependency>\n                         <Import-Package>\n                             !com.fasterxml.jackson*,\n+                            !org.noggit,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQwMjc0Mzky", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-440274392", "createdAt": "2020-06-30T18:19:50Z", "commit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODoxOTo1MFrOGrI-9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0zMFQxODozNTo0M1rOGrJh9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4OTE0Mg==", "bodyText": "remove", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447889142", "createdAt": "2020-06-30T18:19:50Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,344 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import org.locationtech.jts.io.WKTReader\n+import spock.lang.Specification\n+\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+\n+    void setup() {\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        results.size() == 1\n+        results.first().with {\n+            name == \"title\"\n+            population == 1337\n+        }\n+\n+    }\n+\n+    def \"Test query max results\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.\n+                query(*_) >> {\n+            SolrQuery params, SolrRequest.METHOD method ->\n+                assert params.getRows() == GazetteerQueryOfflineSolr.MAX_RESULTS\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> { Stream.empty() }\n+                    }\n+                }\n+        }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        notThrown(Exception)\n+\n+    }\n+\n+    def \"Test query solrclient exception\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test queryById normal\"() {\n+        setup:\n+        1 * solrClient.query(*_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        result.name == \"title\"\n+    }\n+\n+    def \"test queryById exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test getSuggestedNames normal\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${maxResults}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames maxResults\"() {\n+        setup:\n+        int maxResults = 101\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${GazetteerQueryOfflineSolr.MAX_RESULTS}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames solrclient exception\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"exception\") }\n+\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"getNearestCities\"() {\n+        setup:\n+        String locationWkt = \"POINT (-98.86253 29.18968)\"\n+        String pointAbout42kmAway = \"POINT (-98.496708 29.418376)\"\n+        int radiusInKm = 50\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+\n+\n+            // TODO (RCZ) - I really don't like extracting the polygon from the solr query. its\n+            // risky logic and closely coupling to the implementation. But I also don't want to\n+            // open access and have a @VisibleForTesting..\n+\n+            // A point about 42km away should fall well within searching for cities within 50miles\n+            WKTReader reader = new WKTReader()\n+            String WKTPolygon = extractIntersectsPolygon(query.getQuery())\n+            assert reader.read(WKTPolygon).contains(reader.read(pointAbout42kmAway))\n+\n+            Mock(QueryResponse) {\n+                getResults() >> Mock(SolrDocumentList) {\n+                    stream() >> {\n+                        Stream.of(Mock(SolrDocument) {\n+                            get(\"title_txt\") >> [\"title\"]\n+                            get(\"location_geo\") >> [pointAbout42kmAway]\n+                        })\n+                    }\n+                }\n+            }\n+        }\n+\n+        when:\n+        List<NearbyLocation> results = testedClass.\n+                getNearestCities(locationWkt, radiusInKm, maxResults)\n+\n+        then:\n+        results.size() == 1\n+        with(results.first()) {\n+            cardinalDirection == \"NE\"\n+            40 <= it.distance && it.distance <= 45\n+            it.name == \"title\"\n+        }\n+    }\n+\n+    String extractIntersectsPolygon(String query) {\n+        String[] arr = query.split(\":\", 2)\n+        assert arr.length == 2\n+        List<String> queryNodes = Arrays.asList(\n+                arr[1].\n+                        replace(\"\\\"\", \"\").\n+                        split(\"AND|OR\"))\n+        String intersectsQuery = queryNodes.find { it.contains(\"POLYGON\") }\n+        String WKTPolygon = intersectsQuery.\n+                replace(\"Intersects(\", \"\").\n+                trim()[0..-2].\n+                replace(\"\\\\\", \"\")\n+\n+        WKTPolygon\n+    }\n+\n+    def \"getNearestCities wkt parse exception\"() {\n+        when:\n+        testedClass.getNearestCities(\"POINT( !! INVALID WKT \", 50, 10)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+\n+    }\n+    def \"getNearestCities solr query exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            throw new SolrServerException(\"Exception\")\n+        }\n+        when:\n+        testedClass.getNearestCities(\"POINT (-98.86253 29.18968)\", 50, 10)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+\n+    }\n+\n+    def \"getCountryCode normal\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+            assert query.rows == 1\n+\n+            Mock(QueryResponse) {\n+                getResults() >> Mock(SolrDocumentList) {\n+                    stream() >> {\n+                        Stream.of(Mock(SolrDocument) {\n+                            get(\"title_txt\") >> [\"title\"]\n+                            get(\"location.country-code_txt\") >> [\"USA\"]\n+                        })\n+                    }\n+                }\n+            }\n+        }\n+\n+        when:\n+        Optional<String> result = testedClass.getCountryCode(\"POINT (-98.86253 29.18968)\", 50)\n+\n+        then:\n+        result.isPresent()\n+        result.get() == \"USA\"\n+\n+    }\n+\n+    def \"getCountryCode with exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            throw new SolrServerException(\"exception\")\n+        }\n+\n+        when:\n+        Optional<String> result = testedClass.getCountryCode(\"POINT (-98.86253 29.18968)\", 50)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+\n+    }\n+\n+    def \"getCountryCode no results\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+            assert query.rows == 1\n+\n+            Mock(QueryResponse) {\n+                getResults() >> Mock(SolrDocumentList) {\n+                    stream() >> {\n+                        Stream.empty()\n+                    }\n+                }\n+            }\n+        }\n+\n+        when:\n+        Optional<String> result = testedClass.getCountryCode(\"POINT (-98.86253 29.18968)\", 50)\n+\n+        then:\n+        !result.isPresent()\n+\n+    }\n+\n+    def \"getCountryCode invalid wkt\"() {\n+        setup:\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 334}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTAyNw==", "bodyText": "to resolve -- any reviewers opinions on this?  you can see the specific logic inside of extractIntersectsPolygon", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447891027", "createdAt": "2020-06-30T18:23:12Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,344 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import org.locationtech.jts.io.WKTReader\n+import spock.lang.Specification\n+\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+\n+    void setup() {\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        results.size() == 1\n+        results.first().with {\n+            name == \"title\"\n+            population == 1337\n+        }\n+\n+    }\n+\n+    def \"Test query max results\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.\n+                query(*_) >> {\n+            SolrQuery params, SolrRequest.METHOD method ->\n+                assert params.getRows() == GazetteerQueryOfflineSolr.MAX_RESULTS\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> { Stream.empty() }\n+                    }\n+                }\n+        }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        notThrown(Exception)\n+\n+    }\n+\n+    def \"Test query solrclient exception\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test queryById normal\"() {\n+        setup:\n+        1 * solrClient.query(*_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        result.name == \"title\"\n+    }\n+\n+    def \"test queryById exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test getSuggestedNames normal\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${maxResults}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames maxResults\"() {\n+        setup:\n+        int maxResults = 101\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${GazetteerQueryOfflineSolr.MAX_RESULTS}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames solrclient exception\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"exception\") }\n+\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"getNearestCities\"() {\n+        setup:\n+        String locationWkt = \"POINT (-98.86253 29.18968)\"\n+        String pointAbout42kmAway = \"POINT (-98.496708 29.418376)\"\n+        int radiusInKm = 50\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+\n+\n+            // TODO (RCZ) - I really don't like extracting the polygon from the solr query. its\n+            // risky logic and closely coupling to the implementation. But I also don't want to\n+            // open access and have a @VisibleForTesting..", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTQ2NA==", "bodyText": "@rzwiefel this should probably look for contains 'Intersects' (or intersects and polygon) since we do the replace on polygon... that is if we keep this logic at all.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447891464", "createdAt": "2020-06-30T18:24:06Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,344 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import org.locationtech.jts.io.WKTReader\n+import spock.lang.Specification\n+\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+\n+    void setup() {\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        results.size() == 1\n+        results.first().with {\n+            name == \"title\"\n+            population == 1337\n+        }\n+\n+    }\n+\n+    def \"Test query max results\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.\n+                query(*_) >> {\n+            SolrQuery params, SolrRequest.METHOD method ->\n+                assert params.getRows() == GazetteerQueryOfflineSolr.MAX_RESULTS\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> { Stream.empty() }\n+                    }\n+                }\n+        }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        notThrown(Exception)\n+\n+    }\n+\n+    def \"Test query solrclient exception\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test queryById normal\"() {\n+        setup:\n+        1 * solrClient.query(*_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        result.name == \"title\"\n+    }\n+\n+    def \"test queryById exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test getSuggestedNames normal\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${maxResults}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames maxResults\"() {\n+        setup:\n+        int maxResults = 101\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${GazetteerQueryOfflineSolr.MAX_RESULTS}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames solrclient exception\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"exception\") }\n+\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"getNearestCities\"() {\n+        setup:\n+        String locationWkt = \"POINT (-98.86253 29.18968)\"\n+        String pointAbout42kmAway = \"POINT (-98.496708 29.418376)\"\n+        int radiusInKm = 50\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+\n+\n+            // TODO (RCZ) - I really don't like extracting the polygon from the solr query. its\n+            // risky logic and closely coupling to the implementation. But I also don't want to\n+            // open access and have a @VisibleForTesting..\n+\n+            // A point about 42km away should fall well within searching for cities within 50miles\n+            WKTReader reader = new WKTReader()\n+            String WKTPolygon = extractIntersectsPolygon(query.getQuery())\n+            assert reader.read(WKTPolygon).contains(reader.read(pointAbout42kmAway))\n+\n+            Mock(QueryResponse) {\n+                getResults() >> Mock(SolrDocumentList) {\n+                    stream() >> {\n+                        Stream.of(Mock(SolrDocument) {\n+                            get(\"title_txt\") >> [\"title\"]\n+                            get(\"location_geo\") >> [pointAbout42kmAway]\n+                        })\n+                    }\n+                }\n+            }\n+        }\n+\n+        when:\n+        List<NearbyLocation> results = testedClass.\n+                getNearestCities(locationWkt, radiusInKm, maxResults)\n+\n+        then:\n+        results.size() == 1\n+        with(results.first()) {\n+            cardinalDirection == \"NE\"\n+            40 <= it.distance && it.distance <= 45\n+            it.name == \"title\"\n+        }\n+    }\n+\n+    String extractIntersectsPolygon(String query) {\n+        String[] arr = query.split(\":\", 2)\n+        assert arr.length == 2\n+        List<String> queryNodes = Arrays.asList(\n+                arr[1].\n+                        replace(\"\\\"\", \"\").\n+                        split(\"AND|OR\"))\n+        String intersectsQuery = queryNodes.find { it.contains(\"POLYGON\") }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5NTAwNw==", "bodyText": "This is the only change in these configs -- highlight set to false so the payload of suggestion is not marked up with hypertext", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447895007", "createdAt": "2020-06-30T18:29:51Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/resources/solrconfig.xml", "diffHunk": "@@ -0,0 +1,1307 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/\n+-->\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+\n+<!--\n+     For more details about configurations options that may appear in\n+     this file, see http://wiki.apache.org/solr/SolrConfigXml.\n+-->\n+<config>\n+  <!-- In all configuration below, a prefix of \"solr.\" for class names\n+       is an alias that causes solr to search appropriate packages,\n+       including org.apache.solr.(search|update|request|core|analysis)\n+\n+       You may also specify a fully qualified Java classname if you\n+       have your own custom plugins.\n+    -->\n+\n+  <!-- Controls what version of Lucene various components of Solr\n+       adhere to.  Generally, you want to use the latest version to\n+       get all bug fixes and improvements. It is highly recommended\n+       that you fully re-index after changing this setting as it can\n+       affect both how text is indexed and queried.\n+  -->\n+  <luceneMatchVersion>8.5.0</luceneMatchVersion>\n+\n+  <!-- <lib/> directives can be used to instruct Solr to load any Jars\n+       identified and use them to resolve any \"plugins\" specified in\n+       your solrconfig.xml or schema.xml (ie: Analyzers, Request\n+       Handlers, etc...).\n+\n+       All directories and paths are resolved relative to the\n+       instanceDir.\n+\n+       Please note that <lib/> directives are processed in the order\n+       that they appear in your solrconfig.xml file, and are \"stacked\"\n+       on top of each other when building a ClassLoader - so if you have\n+       plugin jars with dependencies on other jars, the \"lower level\"\n+       dependency jars should be loaded first.\n+\n+       If a \"./lib\" directory exists in your instanceDir, all files\n+       found in it are included as if you had used the following\n+       syntax...\n+\n+              <lib dir=\"./lib\" />\n+    -->\n+\n+  <!-- A 'dir' option by itself adds any files found in the directory\n+       to the classpath, this is useful for including all jars in a\n+       directory.\n+\n+       When a 'regex' is specified in addition to a 'dir', only the\n+       files in that directory which completely match the regex\n+       (anchored on both ends) will be included.\n+\n+       If a 'dir' option (with or without a regex) is used and nothing\n+       is found that matches, a warning will be logged.\n+\n+       The examples below can be used to load some solr-contribs along\n+       with their external dependencies.\n+    -->\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/extraction/lib\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-cell-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/clustering/lib/\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-clustering-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/langid/lib/\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-langid-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/velocity/lib\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-velocity-\\d.*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/plugins/\" regex=\".*\\.jar\" />\n+  <!-- an exact 'path' can be used instead of a 'dir' to specify a\n+       specific jar file.  This will cause a serious error to be logged\n+       if it can't be loaded.\n+    -->\n+  <!--\n+     <lib path=\"../a-jar-that-does-not-exist.jar\" />\n+  -->\n+\n+  <!-- Data Directory\n+\n+       Used to specify an alternate directory to hold all index data\n+       other than the default ./data under the Solr home.  If\n+       replication is in use, this should match the replication\n+       configuration.\n+    -->\n+  <dataDir>${solr.data.dir:}</dataDir>\n+\n+\n+  <!-- The DirectoryFactory to use for indexes.\n+\n+       solr.StandardDirectoryFactory is filesystem\n+       based and tries to pick the best implementation for the current\n+       JVM and platform.  solr.NRTCachingDirectoryFactory, the default,\n+       wraps solr.StandardDirectoryFactory and caches small files in memory\n+       for better NRT performance.\n+\n+       One can force a particular implementation via solr.MMapDirectoryFactory,\n+       solr.NIOFSDirectoryFactory, or solr.SimpleFSDirectoryFactory.\n+\n+       solr.RAMDirectoryFactory is memory based and not persistent.\n+    -->\n+  <directoryFactory name=\"DirectoryFactory\"\n+                    class=\"${solr.directoryFactory:solr.NRTCachingDirectoryFactory}\"/>\n+\n+  <!-- The CodecFactory for defining the format of the inverted index.\n+       The default implementation is SchemaCodecFactory, which is the official Lucene\n+       index format, but hooks into the schema to provide per-field customization of\n+       the postings lists and per-document values in the fieldType element\n+       (postingsFormat/docValuesFormat). Note that most of the alternative implementations\n+       are experimental, so if you choose to customize the index format, it's a good\n+       idea to convert back to the official format e.g. via IndexWriter.addIndexes(IndexReader)\n+       before upgrading to a newer version to avoid unnecessary reindexing.\n+       A \"compressionMode\" string element can be added to <codecFactory> to choose\n+       between the existing compression modes in the default codec: \"BEST_SPEED\" (default)\n+       or \"BEST_COMPRESSION\".\n+  -->\n+  <codecFactory class=\"solr.SchemaCodecFactory\"/>\n+\n+  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+       Index Config - These settings control low-level behavior of indexing\n+       Most example settings here show the default value, but are commented\n+       out, to more easily see where customizations have been made.\n+\n+       Note: This replaces <indexDefaults> and <mainIndex> from older versions\n+       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n+  <indexConfig>\n+    <!-- maxFieldLength was removed in 4.0. To get similar behavior, include a\n+         LimitTokenCountFilterFactory in your fieldType definition. E.g.\n+     <filter class=\"solr.LimitTokenCountFilterFactory\" maxTokenCount=\"10000\"/>\n+    -->\n+    <!-- Maximum time to wait for a write lock (ms) for an IndexWriter. Default: 1000 -->\n+    <!-- <writeLockTimeout>1000</writeLockTimeout>  -->\n+\n+    <!-- Expert: Enabling compound file will use less files for the index,\n+         using fewer file descriptors on the expense of performance decrease.\n+         Default in Lucene is \"true\". Default in Solr is \"false\" (since 3.6) -->\n+    <!-- <useCompoundFile>false</useCompoundFile> -->\n+\n+    <!-- ramBufferSizeMB sets the amount of RAM that may be used by Lucene\n+         indexing for buffering added documents and deletions before they are\n+         flushed to the Directory.\n+         maxBufferedDocs sets a limit on the number of documents buffered\n+         before flushing.\n+         If both ramBufferSizeMB and maxBufferedDocs is set, then\n+         Lucene will flush based on whichever limit is hit first.  -->\n+    <!-- <ramBufferSizeMB>100</ramBufferSizeMB> -->\n+    <!-- <maxBufferedDocs>1000</maxBufferedDocs> -->\n+\n+    <!-- Expert: Merge Policy\n+         The Merge Policy in Lucene controls how merging of segments is done.\n+         The default since Solr/Lucene 3.3 is TieredMergePolicy.\n+         The default since Lucene 2.3 was the LogByteSizeMergePolicy,\n+         Even older versions of Lucene used LogDocMergePolicy.\n+      -->\n+    <!--\n+        <mergePolicyFactory class=\"org.apache.solr.index.TieredMergePolicyFactory\">\n+          <int name=\"maxMergeAtOnce\">10</int>\n+          <int name=\"segmentsPerTier\">10</int>\n+          <double name=\"noCFSRatio\">0.1</double>\n+        </mergePolicyFactory>\n+      -->\n+\n+    <!-- Expert: Merge Scheduler\n+         The Merge Scheduler in Lucene controls how merges are\n+         performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)\n+         can perform merges in the background using separate threads.\n+         The SerialMergeScheduler (Lucene 2.2 default) does not.\n+     -->\n+    <!--\n+       <mergeScheduler class=\"org.apache.lucene.index.ConcurrentMergeScheduler\"/>\n+       -->\n+\n+    <!-- LockFactory\n+\n+         This option specifies which Lucene LockFactory implementation\n+         to use.\n+\n+         single = SingleInstanceLockFactory - suggested for a\n+                  read-only index or when there is no possibility of\n+                  another process trying to modify the index.\n+         native = NativeFSLockFactory - uses OS native file locking.\n+                  Do not use when multiple solr webapps in the same\n+                  JVM are attempting to share a single index.\n+         simple = SimpleFSLockFactory  - uses a plain file for locking\n+\n+         Defaults: 'native' is default for Solr3.6 and later, otherwise\n+                   'simple' is the default\n+\n+         More details on the nuances of each LockFactory...\n+         http://wiki.apache.org/lucene-java/AvailableLockFactories\n+    -->\n+    <lockType>${solr.lock.type:native}</lockType>\n+\n+    <!-- Commit Deletion Policy\n+         Custom deletion policies can be specified here. The class must\n+         implement org.apache.lucene.index.IndexDeletionPolicy.\n+\n+         The default Solr IndexDeletionPolicy implementation supports\n+         deleting index commit points on number of commits, age of\n+         commit point and optimized status.\n+\n+         The latest commit point should always be preserved regardless\n+         of the criteria.\n+    -->\n+    <!--\n+    <deletionPolicy class=\"solr.SolrDeletionPolicy\">\n+    -->\n+    <!-- The number of commit points to be kept -->\n+    <!-- <str name=\"maxCommitsToKeep\">1</str> -->\n+    <!-- The number of optimized commit points to be kept -->\n+    <!-- <str name=\"maxOptimizedCommitsToKeep\">0</str> -->\n+    <!--\n+        Delete all commit points once they have reached the given age.\n+        Supports DateMathParser syntax e.g.\n+      -->\n+    <!--\n+       <str name=\"maxCommitAge\">30MINUTES</str>\n+       <str name=\"maxCommitAge\">1DAY</str>\n+    -->\n+    <!--\n+    </deletionPolicy>\n+    -->\n+\n+    <!-- Lucene Infostream\n+\n+         To aid in advanced debugging, Lucene provides an \"InfoStream\"\n+         of detailed information when indexing.\n+\n+         Setting The value to true will instruct the underlying Lucene\n+         IndexWriter to write its debugging info the specified file\n+      -->\n+    <!-- <infoStream file=\"INFOSTREAM.txt\">false</infoStream> -->\n+  </indexConfig>\n+\n+\n+  <!-- JMX\n+\n+       This example enables JMX if and only if an existing MBeanServer\n+       is found, use this if you want to configure JMX through JVM\n+       parameters. Remove this to disable exposing Solr configuration\n+       and statistics to JMX.\n+\n+       For more details see http://wiki.apache.org/solr/SolrJmx\n+    -->\n+  <jmx />\n+  <!-- If you want to connect to a particular server, specify the\n+       agentId\n+    -->\n+  <!-- <jmx agentId=\"myAgent\" /> -->\n+  <!-- If you want to start a new MBeanServer, specify the serviceUrl -->\n+  <!-- <jmx serviceUrl=\"service:jmx:rmi:///jndi/rmi://localhost:9999/solr\"/>\n+    -->\n+\n+  <!-- The default high-performance update handler -->\n+  <updateHandler class=\"solr.DirectUpdateHandler2\">\n+\n+    <!-- Enables a transaction log, used for real-time get, durability, and\n+         and solr cloud replica recovery.  The log can grow as big as\n+         uncommitted changes to the index, so use of a hard autoCommit\n+         is recommended (see below).\n+         \"dir\" - the target directory for transaction logs, defaults to the\n+                solr data directory.\n+         \"numVersionBuckets\" - sets the number of buckets used to keep\n+                track of max version values when checking for re-ordered\n+                updates; increase this value to reduce the cost of\n+                synchronizing access to version buckets during high-volume\n+                indexing, this requires 8 bytes (long) * numVersionBuckets\n+                of heap space per Solr core.\n+    -->\n+    <updateLog>\n+      <str name=\"dir\">${solr.ulog.dir:}</str>\n+      <int name=\"numRecordsToKeep\">${solr.ulog.numRecordsToKeep:100}</int>\n+      <int name=\"maxNumLogsToKeep\">${solr.ulog.maxNumLogsToKeep:10}</int>\n+      <int name=\"numVersionBuckets\">${solr.ulog.numVersionBuckets:65536}</int>\n+    </updateLog>\n+\n+    <!-- AutoCommit\n+\n+         Perform a hard commit automatically under certain conditions.\n+         Instead of enabling autoCommit, consider using \"commitWithin\"\n+         when adding documents.\n+\n+         http://wiki.apache.org/solr/UpdateXmlMessages\n+\n+         maxDocs - Maximum number of documents to add since the last\n+                   commit before automatically triggering a new commit.\n+\n+         maxTime - Maximum amount of time in ms that is allowed to pass\n+                   since a document was added before automatically\n+                   triggering a new commit.\n+         openSearcher - if false, the commit causes recent index changes\n+           to be flushed to stable storage, but does not cause a new\n+           searcher to be opened to make those changes visible.\n+\n+         If the updateLog is enabled, then it's highly recommended to\n+         have some sort of hard autoCommit to limit the log size.\n+      -->\n+    <autoCommit>\n+      <maxTime>${solr.autoCommit.maxTime:60000}</maxTime>\n+      <maxDocs>${solr.autoCommit.maxDocs:10000}</maxDocs>\n+      <maxSize>${solr.autoCommit.maxSize:128m}</maxSize>\n+      <openSearcher>false</openSearcher>\n+    </autoCommit>\n+\n+    <!-- softAutoCommit is like autoCommit except it causes a\n+         'soft' commit which only ensures that changes are visible\n+         but does not ensure that data is synced to disk.  This is\n+         faster and more near-realtime friendly than a hard commit.\n+      -->\n+\n+    <autoSoftCommit>\n+      <maxTime>${solr.autoSoftCommit.maxTime:30000}</maxTime>\n+    </autoSoftCommit>\n+\n+    <!-- Update Related Event Listeners\n+\n+         Various IndexWriter related events can trigger Listeners to\n+         take actions.\n+\n+         postCommit - fired after every commit or optimize command\n+         postOptimize - fired after every optimize command\n+      -->\n+\n+  </updateHandler>\n+\n+  <!-- IndexReaderFactory\n+\n+       Use the following format to specify a custom IndexReaderFactory,\n+       which allows for alternate IndexReader implementations.\n+\n+       ** Experimental Feature **\n+\n+       Please note - Using a custom IndexReaderFactory may prevent\n+       certain other features from working. The API to\n+       IndexReaderFactory may change without warning or may even be\n+       removed from future releases if the problems cannot be\n+       resolved.\n+\n+\n+       ** Features that may not work with custom IndexReaderFactory **\n+\n+       The ReplicationHandler assumes a disk-resident index. Using a\n+       custom IndexReader implementation may cause incompatibility\n+       with ReplicationHandler and may cause replication to not work\n+       correctly. See SOLR-1366 for details.\n+\n+    -->\n+  <!--\n+  <indexReaderFactory name=\"IndexReaderFactory\" class=\"package.class\">\n+    <str name=\"someArg\">Some Value</str>\n+  </indexReaderFactory >\n+  -->\n+\n+  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+       Query section - these settings control query time things like caches\n+       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n+  <query>\n+\n+    <!-- Maximum number of clauses in each BooleanQuery,  an exception\n+         is thrown if exceeded.  It is safe to increase or remove this setting,\n+         since it is purely an arbitrary limit to try and catch user errors where\n+         large boolean queries may not be the best implementation choice.\n+      -->\n+    <maxBooleanClauses>1024</maxBooleanClauses>\n+\n+    <!-- Solr Internal Query Caches\n+\n+         There are two implementations of cache available for Solr,\n+         LRUCache, based on a synchronized LinkedHashMap, and\n+         FastLRUCache, based on a ConcurrentHashMap.\n+\n+         FastLRUCache has faster gets and slower puts in single\n+         threaded operation and thus is generally faster than LRUCache\n+         when the hit ratio of the cache is high (> 75%), and may be\n+         faster under other scenarios on multi-cpu systems.\n+    -->\n+\n+    <!-- Filter Cache\n+\n+         Cache used by SolrIndexSearcher for filters (DocSets),\n+         unordered sets of *all* documents that match a query.  When a\n+         new searcher is opened, its caches may be prepopulated or\n+         \"autowarmed\" using data from caches in the old searcher.\n+         autowarmCount is the number of items to prepopulate.  For\n+         LRUCache, the autowarmed items will be the most recently\n+         accessed items.\n+\n+         Parameters:\n+           class - the SolrCache implementation LRUCache or\n+               (LRUCache or FastLRUCache)\n+           size - the maximum number of entries in the cache\n+           initialSize - the initial capacity (number of entries) of\n+               the cache.  (see java.util.HashMap)\n+           autowarmCount - the number of entries to prepopulate from\n+               and old cache.\n+           maxRamMB - the maximum amount of RAM (in MB) that this cache is allowed\n+                      to occupy. Note that when this option is specified, the size\n+                      and initialSize parameters are ignored.\n+      -->\n+    <filterCache class=\"solr.FastLRUCache\"\n+                 size=\"512\"\n+                 initialSize=\"512\"\n+                 autowarmCount=\"0\"/>\n+\n+    <!-- Query Result Cache\n+\n+         Caches results of searches - ordered lists of document ids\n+         (DocList) based on a query, a sort, and the range of documents requested.\n+         Additional supported parameter by LRUCache:\n+            maxRamMB - the maximum amount of RAM (in MB) that this cache is allowed\n+                       to occupy\n+      -->\n+    <queryResultCache class=\"solr.LRUCache\"\n+                      size=\"512\"\n+                      initialSize=\"512\"\n+                      autowarmCount=\"0\"/>\n+\n+    <!-- Document Cache\n+\n+         Caches Lucene Document objects (the stored fields for each\n+         document).  Since Lucene internal document ids are transient,\n+         this cache will not be autowarmed.\n+      -->\n+    <documentCache class=\"solr.LRUCache\"\n+                   size=\"512\"\n+                   initialSize=\"512\"\n+                   autowarmCount=\"0\"/>\n+\n+    <!-- custom cache currently used by block join -->\n+    <cache name=\"perSegFilter\"\n+           class=\"solr.search.LRUCache\"\n+           size=\"10\"\n+           initialSize=\"0\"\n+           autowarmCount=\"10\"\n+           regenerator=\"solr.NoOpRegenerator\" />\n+\n+    <!-- Field Value Cache\n+\n+         Cache used to hold field values that are quickly accessible\n+         by document id.  The fieldValueCache is created by default\n+         even if not configured here.\n+      -->\n+    <!--\n+       <fieldValueCache class=\"solr.FastLRUCache\"\n+                        size=\"512\"\n+                        autowarmCount=\"128\"\n+                        showItems=\"32\" />\n+      -->\n+\n+    <!-- Custom Cache\n+\n+         Example of a generic cache.  These caches may be accessed by\n+         name through SolrIndexSearcher.getCache(),cacheLookup(), and\n+         cacheInsert().  The purpose is to enable easy caching of\n+         user/application level data.  The regenerator argument should\n+         be specified as an implementation of solr.CacheRegenerator\n+         if autowarming is desired.\n+      -->\n+    <!--\n+       <cache name=\"myUserCache\"\n+              class=\"solr.LRUCache\"\n+              size=\"4096\"\n+              initialSize=\"1024\"\n+              autowarmCount=\"1024\"\n+              regenerator=\"com.mycompany.MyRegenerator\"\n+              />\n+      -->\n+\n+\n+    <!-- Lazy Field Loading\n+\n+         If true, stored fields that are not requested will be loaded\n+         lazily.  This can result in a significant speed improvement\n+         if the usual case is to not load all stored fields,\n+         especially if the skipped fields are large compressed text\n+         fields.\n+    -->\n+    <enableLazyFieldLoading>true</enableLazyFieldLoading>\n+\n+    <!-- Use Filter For Sorted Query\n+\n+         A possible optimization that attempts to use a filter to\n+         satisfy a search.  If the requested sort does not include\n+         score, then the filterCache will be checked for a filter\n+         matching the query. If found, the filter will be used as the\n+         source of document ids, and then the sort will be applied to\n+         that.\n+\n+         For most situations, this will not be useful unless you\n+         frequently get the same search repeatedly with different sort\n+         options, and none of them ever use \"score\"\n+      -->\n+    <!--\n+       <useFilterForSortedQuery>true</useFilterForSortedQuery>\n+      -->\n+\n+    <!-- Result Window Size\n+\n+         An optimization for use with the queryResultCache.  When a search\n+         is requested, a superset of the requested number of document ids\n+         are collected.  For example, if a search for a particular query\n+         requests matching documents 10 through 19, and queryWindowSize is 50,\n+         then documents 0 through 49 will be collected and cached.  Any further\n+         requests in that range can be satisfied via the cache.\n+      -->\n+    <queryResultWindowSize>20</queryResultWindowSize>\n+\n+    <!-- Maximum number of documents to cache for any entry in the\n+         queryResultCache.\n+      -->\n+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>\n+\n+    <!-- Query Related Event Listeners\n+\n+         Various IndexSearcher related events can trigger Listeners to\n+         take actions.\n+\n+         newSearcher - fired whenever a new searcher is being prepared\n+         and there is a current searcher handling requests (aka\n+         registered).  It can be used to prime certain caches to\n+         prevent long request times for certain requests.\n+\n+         firstSearcher - fired whenever a new searcher is being\n+         prepared but there is no current registered searcher to handle\n+         requests or to gain autowarming data from.\n+\n+\n+      -->\n+    <!-- QuerySenderListener takes an array of NamedList and executes a\n+         local query request for each NamedList in sequence.\n+      -->\n+    <listener event=\"newSearcher\" class=\"solr.QuerySenderListener\">\n+      <arr name=\"queries\">\n+        <!--\n+           <lst><str name=\"q\">solr</str><str name=\"sort\">price asc</str></lst>\n+           <lst><str name=\"q\">rocks</str><str name=\"sort\">weight asc</str></lst>\n+          -->\n+      </arr>\n+    </listener>\n+    <listener event=\"firstSearcher\" class=\"solr.QuerySenderListener\">\n+      <arr name=\"queries\">\n+        <!--\n+        <lst>\n+          <str name=\"q\">static firstSearcher warming in solrconfig.xml</str>\n+        </lst>\n+        -->\n+      </arr>\n+    </listener>\n+\n+    <!-- Use Cold Searcher\n+\n+         If a search request comes in and there is no current\n+         registered searcher, then immediately register the still\n+         warming searcher and use it.  If \"false\" then all requests\n+         will block until the first searcher is done warming.\n+      -->\n+    <useColdSearcher>false</useColdSearcher>\n+\n+  </query>\n+\n+\n+  <!-- Request Dispatcher\n+\n+       This section contains instructions for how the SolrDispatchFilter\n+       should behave when processing requests for this SolrCore.\n+\n+    -->\n+  <requestDispatcher>\n+    <!-- Request Parsing\n+\n+         These settings indicate how Solr Requests may be parsed, and\n+         what restrictions may be placed on the ContentStreams from\n+         those requests\n+\n+         enableRemoteStreaming - enables use of the stream.file\n+         and stream.url parameters for specifying remote streams.\n+\n+         multipartUploadLimitInKB - specifies the max size (in KiB) of\n+         Multipart File Uploads that Solr will allow in a Request.\n+\n+         formdataUploadLimitInKB - specifies the max size (in KiB) of\n+         form data (application/x-www-form-urlencoded) sent via\n+         POST. You can use POST to pass request parameters not\n+         fitting into the URL.\n+\n+         addHttpRequestToContext - if set to true, it will instruct\n+         the requestParsers to include the original HttpServletRequest\n+         object in the context map of the SolrQueryRequest under the\n+         key \"httpRequest\". It will not be used by any of the existing\n+         Solr components, but may be useful when developing custom\n+         plugins.\n+\n+         *** WARNING ***\n+         Before enabling remote streaming, you should make sure your\n+         system has authentication enabled.\n+\n+    <requestParsers enableRemoteStreaming=\"false\"\n+                    multipartUploadLimitInKB=\"-1\"\n+                    formdataUploadLimitInKB=\"-1\"\n+                    addHttpRequestToContext=\"false\"/>\n+      -->\n+\n+    <!-- HTTP Caching\n+\n+         Set HTTP caching related parameters (for proxy caches and clients).\n+\n+         The options below instruct Solr not to output any HTTP Caching\n+         related headers\n+      -->\n+    <httpCaching never304=\"true\" />\n+    <!-- If you include a <cacheControl> directive, it will be used to\n+         generate a Cache-Control header (as well as an Expires header\n+         if the value contains \"max-age=\")\n+\n+         By default, no Cache-Control header is generated.\n+\n+         You can use the <cacheControl> option even if you have set\n+         never304=\"true\"\n+      -->\n+    <!--\n+       <httpCaching never304=\"true\" >\n+         <cacheControl>max-age=30, public</cacheControl>\n+       </httpCaching>\n+      -->\n+    <!-- To enable Solr to respond with automatically generated HTTP\n+         Caching headers, and to response to Cache Validation requests\n+         correctly, set the value of never304=\"false\"\n+\n+         This will cause Solr to generate Last-Modified and ETag\n+         headers based on the properties of the Index.\n+\n+         The following options can also be specified to affect the\n+         values of these headers...\n+\n+         lastModFrom - the default value is \"openTime\" which means the\n+         Last-Modified value (and validation against If-Modified-Since\n+         requests) will all be relative to when the current Searcher\n+         was opened.  You can change it to lastModFrom=\"dirLastMod\" if\n+         you want the value to exactly correspond to when the physical\n+         index was last modified.\n+\n+         etagSeed=\"...\" is an option you can change to force the ETag\n+         header (and validation against If-None-Match requests) to be\n+         different even if the index has not changed (ie: when making\n+         significant changes to your config file)\n+\n+         (lastModifiedFrom and etagSeed are both ignored if you use\n+         the never304=\"true\" option)\n+      -->\n+    <!--\n+       <httpCaching lastModifiedFrom=\"openTime\"\n+                    etagSeed=\"Solr\">\n+         <cacheControl>max-age=30, public</cacheControl>\n+       </httpCaching>\n+      -->\n+  </requestDispatcher>\n+\n+  <!-- Request Handlers\n+\n+       http://wiki.apache.org/solr/SolrRequestHandler\n+\n+       Incoming queries will be dispatched to a specific handler by name\n+       based on the path specified in the request.\n+\n+       If a Request Handler is declared with startup=\"lazy\", then it will\n+       not be initialized until the first request that uses it.\n+\n+    -->\n+  <!-- SearchHandler\n+\n+       http://wiki.apache.org/solr/SearchHandler\n+\n+       For processing Search Queries, the primary Request Handler\n+       provided with Solr is \"SearchHandler\" It delegates to a sequent\n+       of SearchComponents (see below) and supports distributed\n+       queries across multiple shards\n+    -->\n+  <requestHandler name=\"/select\" class=\"solr.SearchHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+      <str name=\"spellcheck\">false</str>\n+      <str name=\"spellcheck.dictionary\">filebased</str>\n+      <str name=\"spellcheck.extendedResults\">true</str>\n+      <str name=\"spellcheck.count\">10</str>\n+      <str name=\"spellcheck.alternativeTermCount\">5</str>\n+      <str name=\"spellcheck.maxResultsForSuggest\">5</str>\n+      <str name=\"spellcheck.collate\">true</str>\n+      <str name=\"spellcheck.collateExtendedResults\">true</str>\n+      <str name=\"spellcheck.maxCollationTries\">100</str>\n+      <str name=\"spellcheck.maxCollations\">5</str>\n+      <str name=\"spellcheck.onlyMorePopular\">true</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>spellcheck</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- A request handler that returns indented JSON by default -->\n+  <requestHandler name=\"/query\" class=\"solr.SearchHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+      <str name=\"wt\">json</str>\n+      <str name=\"indent\">true</str>\n+    </lst>\n+  </requestHandler>\n+\n+\n+  <!-- A Robust Example\n+\n+       This example SearchHandler declaration shows off usage of the\n+       SearchHandler with many defaults declared\n+\n+       Note that multiple instances of the same Request Handler\n+       (SearchHandler) can be registered multiple times with different\n+       names (and different init parameters)\n+    -->\n+  <requestHandler name=\"/browse\" class=\"solr.SearchHandler\" useParams=\"query,facets,velocity,browse\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <initParams path=\"/update/**,/query,/select,/tvrh,/elevate,/spell,/browse\">\n+    <lst name=\"defaults\">\n+      <str name=\"df\">_text_</str>\n+    </lst>\n+  </initParams>\n+\n+  <!-- Solr Cell Update Request Handler\n+\n+       http://wiki.apache.org/solr/ExtractingRequestHandler\n+\n+    -->\n+  <requestHandler name=\"/update/extract\"\n+                  startup=\"lazy\"\n+                  class=\"solr.extraction.ExtractingRequestHandler\" >\n+    <lst name=\"defaults\">\n+      <str name=\"lowernames\">true</str>\n+      <str name=\"fmap.meta\">ignored_</str>\n+      <str name=\"fmap.content\">_text_</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <!-- Search Components\n+\n+       Search components are registered to SolrCore and used by\n+       instances of SearchHandler (which can access them by name)\n+\n+       By default, the following components are available:\n+\n+       <searchComponent name=\"query\"     class=\"solr.QueryComponent\" />\n+       <searchComponent name=\"facet\"     class=\"solr.FacetComponent\" />\n+       <searchComponent name=\"mlt\"       class=\"solr.MoreLikeThisComponent\" />\n+       <searchComponent name=\"highlight\" class=\"solr.HighlightComponent\" />\n+       <searchComponent name=\"stats\"     class=\"solr.StatsComponent\" />\n+       <searchComponent name=\"debug\"     class=\"solr.DebugComponent\" />\n+\n+       Default configuration in a requestHandler would look like:\n+\n+       <arr name=\"components\">\n+         <str>query</str>\n+         <str>facet</str>\n+         <str>mlt</str>\n+         <str>highlight</str>\n+         <str>stats</str>\n+         <str>debug</str>\n+       </arr>\n+\n+       If you register a searchComponent to one of the standard names,\n+       that will be used instead of the default.\n+\n+       To insert components before or after the 'standard' components, use:\n+\n+       <arr name=\"first-components\">\n+         <str>myFirstComponentName</str>\n+       </arr>\n+\n+       <arr name=\"last-components\">\n+         <str>myLastComponentName</str>\n+       </arr>\n+\n+       NOTE: The component registered with the name \"debug\" will\n+       always be executed after the \"last-components\"\n+\n+     -->\n+\n+  <!-- Spell Check\n+\n+       The spell check component can return a list of alternative spelling\n+       suggestions.\n+\n+       http://wiki.apache.org/solr/SpellCheckComponent\n+    -->\n+  <searchComponent name=\"spellcheck\" class=\"solr.SpellCheckComponent\">\n+\n+    <str name=\"queryAnalyzerFieldType\">text_suggest</str>\n+\n+    <lst name=\"spellchecker\">\n+      <!-- The spellcheck index will need to be built once for this dictionary before it will work -->\n+      <str name=\"name\">filebased</str>\n+      <str name=\"classname\">solr.FileBasedSpellChecker</str>\n+      <str name=\"sourceLocation\">dictionary.txt</str>\n+      <str name=\"spellcheckIndexDir\">./spellcheckerFile</str>\n+      <str name=\"characterEncoding\">UTF-8</str>\n+    </lst>\n+  </searchComponent>\n+\n+  <!-- A request handler for demonstrating the spellcheck component.\n+\n+       NOTE: This is purely as an example.  The whole purpose of the\n+       SpellCheckComponent is to hook it into the request handler that\n+       handles your normal user queries so that a separate request is\n+       not needed to get suggestions.\n+\n+       IN OTHER WORDS, THERE IS REALLY GOOD CHANCE THE SETUP BELOW IS\n+       NOT WHAT YOU WANT FOR YOUR PRODUCTION SYSTEM!\n+\n+       See http://wiki.apache.org/solr/SpellCheckComponent for details\n+       on the request parameters.\n+    -->\n+  <requestHandler name=\"/spell\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <!-- Solr will use suggestions from both the 'default' spellchecker\n+           and from the 'wordbreak' spellchecker and combine them.\n+           collations (re-written queries) can include a combination of\n+           corrections from both spellcheckers -->\n+      <str name=\"spellcheck.dictionary\">filebased</str>\n+      <str name=\"spellcheck\">on</str>\n+      <str name=\"spellcheck.extendedResults\">true</str>\n+      <str name=\"spellcheck.count\">10</str>\n+      <str name=\"spellcheck.alternativeTermCount\">5</str>\n+      <str name=\"spellcheck.maxResultsForSuggest\">5</str>\n+      <str name=\"spellcheck.collate\">true</str>\n+      <str name=\"spellcheck.collateExtendedResults\">true</str>\n+      <str name=\"spellcheck.maxCollationTries\">10</str>\n+      <str name=\"spellcheck.maxCollations\">5</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>spellcheck</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Term Vector Component\n+\n+       http://wiki.apache.org/solr/TermVectorComponent\n+    -->\n+  <searchComponent name=\"tvComponent\" class=\"solr.TermVectorComponent\"/>\n+\n+  <!-- A request handler for demonstrating the term vector component\n+\n+       This is purely as an example.\n+\n+       In reality you will likely want to add the component to your\n+       already specified request handlers.\n+    -->\n+  <requestHandler name=\"/tvrh\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <bool name=\"tv\">true</bool>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>tvComponent</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Clustering Component. (Omitted here. See the default Solr example for a typical configuration.) -->\n+\n+  <!-- Terms Component\n+\n+       http://wiki.apache.org/solr/TermsComponent\n+\n+       A component to return terms and document frequency of those\n+       terms\n+    -->\n+  <searchComponent name=\"terms\" class=\"solr.TermsComponent\"/>\n+\n+  <!-- A request handler for demonstrating the terms component -->\n+  <requestHandler name=\"/terms\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <bool name=\"terms\">true</bool>\n+      <bool name=\"distrib\">false</bool>\n+    </lst>\n+    <arr name=\"components\">\n+      <str>terms</str>\n+    </arr>\n+  </requestHandler>\n+\n+\n+  <!-- Query Elevation Component\n+\n+       http://wiki.apache.org/solr/QueryElevationComponent\n+\n+       a search component that enables you to configure the top\n+       results for a given query regardless of the normal lucene\n+       scoring.\n+    -->\n+  <searchComponent name=\"elevator\" class=\"solr.QueryElevationComponent\" >\n+    <!-- pick a fieldType to analyze queries -->\n+    <str name=\"queryFieldType\">string</str>\n+  </searchComponent>\n+\n+  <!-- A request handler for demonstrating the elevator component -->\n+  <requestHandler name=\"/elevate\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>elevator</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Highlighting Component\n+\n+       http://wiki.apache.org/solr/HighlightingParameters\n+    -->\n+  <searchComponent class=\"solr.HighlightComponent\" name=\"highlight\">\n+    <highlighting>\n+      <!-- Configure the standard fragmenter -->\n+      <!-- This could most likely be commented out in the \"default\" case -->\n+      <fragmenter name=\"gap\"\n+                  default=\"true\"\n+                  class=\"solr.highlight.GapFragmenter\">\n+        <lst name=\"defaults\">\n+          <int name=\"hl.fragsize\">100</int>\n+        </lst>\n+      </fragmenter>\n+\n+      <!-- A regular-expression-based fragmenter\n+           (for sentence extraction)\n+        -->\n+      <fragmenter name=\"regex\"\n+                  class=\"solr.highlight.RegexFragmenter\">\n+        <lst name=\"defaults\">\n+          <!-- slightly smaller fragsizes work better because of slop -->\n+          <int name=\"hl.fragsize\">70</int>\n+          <!-- allow 50% slop on fragment sizes -->\n+          <float name=\"hl.regex.slop\">0.5</float>\n+          <!-- a basic sentence pattern -->\n+          <str name=\"hl.regex.pattern\">[-\\w ,/\\n\\&quot;&apos;]{20,200}</str>\n+        </lst>\n+      </fragmenter>\n+\n+      <!-- Configure the standard formatter -->\n+      <formatter name=\"html\"\n+                 default=\"true\"\n+                 class=\"solr.highlight.HtmlFormatter\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.simple.pre\"><![CDATA[<em>]]></str>\n+          <str name=\"hl.simple.post\"><![CDATA[</em>]]></str>\n+        </lst>\n+      </formatter>\n+\n+      <!-- Configure the standard encoder -->\n+      <encoder name=\"html\"\n+               class=\"solr.highlight.HtmlEncoder\" />\n+\n+      <!-- Configure the standard fragListBuilder -->\n+      <fragListBuilder name=\"simple\"\n+                       class=\"solr.highlight.SimpleFragListBuilder\"/>\n+\n+      <!-- Configure the single fragListBuilder -->\n+      <fragListBuilder name=\"single\"\n+                       class=\"solr.highlight.SingleFragListBuilder\"/>\n+\n+      <!-- Configure the weighted fragListBuilder -->\n+      <fragListBuilder name=\"weighted\"\n+                       default=\"true\"\n+                       class=\"solr.highlight.WeightedFragListBuilder\"/>\n+\n+      <!-- default tag FragmentsBuilder -->\n+      <fragmentsBuilder name=\"default\"\n+                        default=\"true\"\n+                        class=\"solr.highlight.ScoreOrderFragmentsBuilder\">\n+        <!--\n+        <lst name=\"defaults\">\n+          <str name=\"hl.multiValuedSeparatorChar\">/</str>\n+        </lst>\n+        -->\n+      </fragmentsBuilder>\n+\n+      <!-- multi-colored tag FragmentsBuilder -->\n+      <fragmentsBuilder name=\"colored\"\n+                        class=\"solr.highlight.ScoreOrderFragmentsBuilder\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.tag.pre\"><![CDATA[\n+               <b style=\"background:yellow\">,<b style=\"background:lawgreen\">,\n+               <b style=\"background:aquamarine\">,<b style=\"background:magenta\">,\n+               <b style=\"background:palegreen\">,<b style=\"background:coral\">,\n+               <b style=\"background:wheat\">,<b style=\"background:khaki\">,\n+               <b style=\"background:lime\">,<b style=\"background:deepskyblue\">]]></str>\n+          <str name=\"hl.tag.post\"><![CDATA[</b>]]></str>\n+        </lst>\n+      </fragmentsBuilder>\n+\n+      <boundaryScanner name=\"default\"\n+                       default=\"true\"\n+                       class=\"solr.highlight.SimpleBoundaryScanner\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.bs.maxScan\">10</str>\n+          <str name=\"hl.bs.chars\">.,!? &#9;&#10;&#13;</str>\n+        </lst>\n+      </boundaryScanner>\n+\n+      <boundaryScanner name=\"breakIterator\"\n+                       class=\"solr.highlight.BreakIteratorBoundaryScanner\">\n+        <lst name=\"defaults\">\n+          <!-- type should be one of CHARACTER, WORD(default), LINE and SENTENCE -->\n+          <str name=\"hl.bs.type\">WORD</str>\n+          <!-- language and country are used when constructing Locale object.  -->\n+          <!-- And the Locale object will be used when getting instance of BreakIterator -->\n+          <str name=\"hl.bs.language\">en</str>\n+          <str name=\"hl.bs.country\">US</str>\n+        </lst>\n+      </boundaryScanner>\n+    </highlighting>\n+  </searchComponent>\n+\n+  <!-- Update Processors\n+\n+       Chains of Update Processor Factories for dealing with Update\n+       Requests can be declared, and then used by name in Update\n+       Request Processors\n+\n+       http://wiki.apache.org/solr/UpdateRequestProcessor\n+\n+    -->\n+\n+  <!-- Add unknown fields to the schema\n+\n+       Field type guessing update processors that will\n+       attempt to parse string-typed field values as Booleans, Longs,\n+       Doubles, or Dates, and then add schema fields with the guessed\n+       field types. Text content will be indexed as \"text_general\" as\n+       well as a copy to a plain string version in *_str.\n+\n+       These require that the schema is both managed and mutable, by\n+       declaring schemaFactory as ManagedIndexSchemaFactory, with\n+       mutable specified as true.\n+\n+       See http://wiki.apache.org/solr/GuessingFieldTypes\n+    -->\n+  <updateProcessor class=\"solr.UUIDUpdateProcessorFactory\" name=\"uuid\"/>\n+  <updateProcessor class=\"solr.RemoveBlankFieldUpdateProcessorFactory\" name=\"remove-blank\"/>\n+  <updateProcessor class=\"solr.FieldNameMutatingUpdateProcessorFactory\" name=\"field-name-mutating\">\n+    <str name=\"pattern\">[^\\w-\\.]</str>\n+    <str name=\"replacement\">_</str>\n+  </updateProcessor>\n+  <updateProcessor class=\"solr.ParseBooleanFieldUpdateProcessorFactory\" name=\"parse-boolean\"/>\n+  <updateProcessor class=\"solr.ParseLongFieldUpdateProcessorFactory\" name=\"parse-long\"/>\n+  <updateProcessor class=\"solr.ParseDoubleFieldUpdateProcessorFactory\" name=\"parse-double\"/>\n+  <updateProcessor class=\"solr.ParseDateFieldUpdateProcessorFactory\" name=\"parse-date\">\n+    <arr name=\"format\">\n+      <str>yyyy-MM-dd'T'HH:mm:ss.SSSZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss,SSSZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss.SSS</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss,SSS</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ssZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss</str>\n+      <str>yyyy-MM-dd'T'HH:mmZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm</str>\n+      <str>yyyy-MM-dd HH:mm:ss.SSSZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss,SSSZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss.SSS</str>\n+      <str>yyyy-MM-dd HH:mm:ss,SSS</str>\n+      <str>yyyy-MM-dd HH:mm:ssZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss</str>\n+      <str>yyyy-MM-dd HH:mmZ</str>\n+      <str>yyyy-MM-dd HH:mm</str>\n+      <str>yyyy-MM-dd</str>\n+    </arr>\n+  </updateProcessor>\n+\n+  <!-- The update.autoCreateFields property can be turned to false to disable schemaless mode -->\n+  <updateRequestProcessorChain name=\"add-unknown-fields-to-the-schema\" default=\"${update.autoCreateFields:true}\"\n+                               processor=\"uuid,remove-blank,field-name-mutating,parse-boolean,parse-long,parse-double,parse-date\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\"/>\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\"/>\n+    <processor class=\"solr.RunUpdateProcessorFactory\"/>\n+  </updateRequestProcessorChain>\n+\n+  <!-- Deduplication\n+\n+       An example dedup update processor that creates the \"id\" field\n+       on the fly based on the hash code of some other fields.  This\n+       example has overwriteDupes set to false since we are using the\n+       id field as the signatureField and Solr will maintain\n+       uniqueness based on that anyway.\n+\n+    -->\n+  <!--\n+     <updateRequestProcessorChain name=\"dedupe\">\n+       <processor class=\"solr.processor.SignatureUpdateProcessorFactory\">\n+         <bool name=\"enabled\">true</bool>\n+         <str name=\"signatureField\">id</str>\n+         <bool name=\"overwriteDupes\">false</bool>\n+         <str name=\"fields\">name,features,cat</str>\n+         <str name=\"signatureClass\">solr.processor.Lookup3Signature</str>\n+       </processor>\n+       <processor class=\"solr.LogUpdateProcessorFactory\" />\n+       <processor class=\"solr.RunUpdateProcessorFactory\" />\n+     </updateRequestProcessorChain>\n+    -->\n+\n+  <!-- Language identification\n+\n+       This example update chain identifies the language of the incoming\n+       documents using the langid contrib. The detected language is\n+       written to field language_s. No field name mapping is done.\n+       The fields used for detection are text, title, subject and description,\n+       making this example suitable for detecting languages form full-text\n+       rich documents injected via ExtractingRequestHandler.\n+       See more about langId at http://wiki.apache.org/solr/LanguageDetection\n+    -->\n+  <!--\n+  <updateRequestProcessorChain name=\"langid\">\n+    <processor class=\"org.apache.solr.update.processor.TikaLanguageIdentifierUpdateProcessorFactory\">\n+      <str name=\"langid.fl\">_text_,title_txt,description_txt</str>\n+      <str name=\"langid.langField\">language_detected</str>\n+      <str name=\"langid.fallback\">en</str>\n+    </processor>\n+    <processor class=\"solr.LogUpdateProcessorFactory\" />\n+    <processor class=\"solr.RunUpdateProcessorFactory\" />\n+  </updateRequestProcessorChain>\n+  -->\n+  <!-- Script update processor\n+\n+    This example hooks in an update processor implemented using JavaScript.\n+\n+    See more about the script update processor at http://wiki.apache.org/solr/ScriptUpdateProcessor\n+  -->\n+  <!--\n+    <updateRequestProcessorChain name=\"script\">\n+      <processor class=\"solr.StatelessScriptUpdateProcessorFactory\">\n+        <str name=\"script\">update-script.js</str>\n+        <lst name=\"params\">\n+          <str name=\"config_param\">example config parameter</str>\n+        </lst>\n+      </processor>\n+      <processor class=\"solr.RunUpdateProcessorFactory\" />\n+    </updateRequestProcessorChain>\n+  -->\n+\n+  <!-- Response Writers\n+\n+       http://wiki.apache.org/solr/QueryResponseWriter\n+\n+       Request responses will be written using the writer specified by\n+       the 'wt' request parameter matching the name of a registered\n+       writer.\n+\n+       The \"default\" writer is the default and will be used if 'wt' is\n+       not specified in the request.\n+    -->\n+  <!-- The following response writers are implicitly configured unless\n+       overridden...\n+    -->\n+  <!--\n+     <queryResponseWriter name=\"xml\"\n+                          default=\"true\"\n+                          class=\"solr.XMLResponseWriter\" />\n+     <queryResponseWriter name=\"json\" class=\"solr.JSONResponseWriter\"/>\n+     <queryResponseWriter name=\"python\" class=\"solr.PythonResponseWriter\"/>\n+     <queryResponseWriter name=\"ruby\" class=\"solr.RubyResponseWriter\"/>\n+     <queryResponseWriter name=\"php\" class=\"solr.PHPResponseWriter\"/>\n+     <queryResponseWriter name=\"phps\" class=\"solr.PHPSerializedResponseWriter\"/>\n+     <queryResponseWriter name=\"csv\" class=\"solr.CSVResponseWriter\"/>\n+     <queryResponseWriter name=\"schema.xml\" class=\"solr.SchemaXmlResponseWriter\"/>\n+    -->\n+\n+  <queryResponseWriter name=\"json\" class=\"solr.JSONResponseWriter\">\n+    <!-- For the purposes of the tutorial, JSON responses are written as\n+     plain text so that they are easy to read in *any* browser.\n+     If you expect a MIME type of \"application/json\" just remove this override.\n+    -->\n+    <str name=\"content-type\">text/plain; charset=UTF-8</str>\n+  </queryResponseWriter>\n+\n+  <!--\n+     Custom response writers can be declared as needed...\n+    -->\n+  <queryResponseWriter name=\"velocity\" class=\"solr.VelocityResponseWriter\" startup=\"lazy\">\n+    <str name=\"template.base.dir\">${velocity.template.base.dir:}</str>\n+    <str name=\"solr.resource.loader.enabled\">${velocity.solr.resource.loader.enabled:true}</str>\n+    <str name=\"params.resource.loader.enabled\">${velocity.params.resource.loader.enabled:false}</str>\n+  </queryResponseWriter>\n+\n+  <!-- XSLT response writer transforms the XML output by any xslt file found\n+       in Solr's conf/xslt directory.  Changes to xslt files are checked for\n+       every xsltCacheLifetimeSeconds.\n+    -->\n+  <queryResponseWriter name=\"xslt\" class=\"solr.XSLTResponseWriter\">\n+    <int name=\"xsltCacheLifetimeSeconds\">5</int>\n+  </queryResponseWriter>\n+\n+  <!-- Query Parsers\n+\n+       https://lucene.apache.org/solr/guide/query-syntax-and-parsing.html\n+\n+       Multiple QParserPlugins can be registered by name, and then\n+       used in either the \"defType\" param for the QueryComponent (used\n+       by SearchHandler) or in LocalParams\n+    -->\n+  <!-- example of registering a query parser -->\n+  <!--\n+     <queryParser name=\"myparser\" class=\"com.mycompany.MyQParserPlugin\"/>\n+    -->\n+\n+  <!-- Function Parsers\n+\n+       http://wiki.apache.org/solr/FunctionQuery\n+\n+       Multiple ValueSourceParsers can be registered by name, and then\n+       used as function names when using the \"func\" QParser.\n+    -->\n+  <!-- example of registering a custom function parser  -->\n+  <!--\n+     <valueSourceParser name=\"myfunc\"\n+                        class=\"com.mycompany.MyValueSourceParser\" />\n+    -->\n+\n+\n+  <!-- Document Transformers\n+       http://wiki.apache.org/solr/DocTransformers\n+    -->\n+  <!--\n+     Could be something like:\n+     <transformer name=\"db\" class=\"com.mycompany.LoadFromDatabaseTransformer\" >\n+       <int name=\"connection\">jdbc://....</int>\n+     </transformer>\n+\n+     To add a constant value to all docs, use:\n+     <transformer name=\"mytrans2\" class=\"org.apache.solr.response.transform.ValueAugmenterFactory\" >\n+       <int name=\"value\">5</int>\n+     </transformer>\n+\n+     If you want the user to still be able to change it with _value:something_ use this:\n+     <transformer name=\"mytrans3\" class=\"org.apache.solr.response.transform.ValueAugmenterFactory\" >\n+       <double name=\"defaultValue\">5</double>\n+     </transformer>\n+\n+      If you are using the QueryElevationComponent, you may wish to mark documents that get boosted.  The\n+      EditorialMarkerFactory will do exactly that:\n+     <transformer name=\"qecBooster\" class=\"org.apache.solr.response.transform.EditorialMarkerFactory\" />\n+    -->\n+\n+\n+  <!-- Placename Suggestion Component\n+\n+  This component can return a list of auto-complete suggestions\n+  when entering placenames.\n+  -->\n+  <searchComponent name=\"suggest\" class=\"solr.SuggestComponent\">\n+    <lst name=\"suggester\">\n+      <str name=\"name\">suggestPlace</str>\n+      <str name=\"lookupImpl\">BlendedInfixLookupFactory</str>\n+      <str name=\"indexPath\">place_suggest_index</str>\n+      <str name=\"dictionaryImpl\">DocumentDictionaryFactory</str>\n+      <str name=\"suggestAnalyzerFieldType\">lowercase</str>\n+      <str name=\"field\">title_txt</str>\n+      <!-- Only real change is here, changing highlight to false -->\n+      <str name=\"highlight\">false</str>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 1289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5NTkzMA==", "bodyText": "Ranking set to 80 in case the GazetteerQueryCatalog is installed it will outrank it.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447895930", "createdAt": "2020-06-30T18:31:33Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/resources/OSGI-INF/blueprint/blueprint.xml", "diffHunk": "@@ -0,0 +1,35 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!-- /**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/ -->\n+<blueprint xmlns=\"http://www.osgi.org/xmlns/blueprint/v1.0.0\">\n+\n+  <reference id=\"solrFactory\" interface=\"org.codice.solr.factory.SolrClientFactory\"/>\n+\n+\n+  <bean id=\"offlineGazetteerPlugin\"\n+    class=\"ddf.catalog.solr.offlinegazetteer.OfflineGazetteerPlugin\">\n+    <argument ref=\"solrFactory\"/>\n+  </bean>\n+  <service ref=\"offlineGazetteerPlugin\">\n+    <interfaces>\n+      <value>ddf.catalog.plugin.PostIngestPlugin</value>\n+      <value>ddf.catalog.plugin.PreQueryPlugin</value>\n+    </interfaces>\n+  </service>\n+\n+  <bean id=\"gazetteerQueryOfflineSolr\" class=\"ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\">\n+    <argument ref=\"solrFactory\"/>\n+  </bean>\n+  <service ref=\"gazetteerQueryOfflineSolr\" interface=\"org.codice.ddf.spatial.geocoding.GeoEntryQueryable\" ranking=\"80\" />", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODEwMg==", "bodyText": "@paouelle may be interested in this -- It seems that with this karaf command (and the other here) if i attempted to use the solrClient returned by clientFactory.newClient too 'quickly' , it would throw a SolrServerException because the client had not connected yet. Hence, I added the retry to have it retry a few times to give it a chance to connect (which did seem to alleviate the issue).", "url": "https://github.com/codice/ddf/pull/6153#discussion_r447898102", "createdAt": "2020-06-30T18:35:43Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 78}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/cc7d19c20f926c1b37a7b3926608b9f97d5d66f9", "committedDate": "2020-06-30T17:11:05Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "65fc73ff76bd9e398c6031a454a6c8dd592ee4c7", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/65fc73ff76bd9e398c6031a454a6c8dd592ee4c7", "committedDate": "2020-06-30T20:50:25Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "65fc73ff76bd9e398c6031a454a6c8dd592ee4c7", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/65fc73ff76bd9e398c6031a454a6c8dd592ee4c7", "committedDate": "2020-06-30T20:50:25Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "efb03e911a482cafa6c5f88d21322c3b031c8a27", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/efb03e911a482cafa6c5f88d21322c3b031c8a27", "committedDate": "2020-06-30T20:51:45Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "efb03e911a482cafa6c5f88d21322c3b031c8a27", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/efb03e911a482cafa6c5f88d21322c3b031c8a27", "committedDate": "2020-06-30T20:51:45Z", "message": "DDF-6152 Added standalone solr gazetteer"}, "afterCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/88f357102c5f89f5b129ad7e7cdb633387426b7e", "committedDate": "2020-06-30T20:52:40Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMTI3NDE5", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-441127419", "createdAt": "2020-07-01T19:05:56Z", "commit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxOTowNTo1N1rOGryBkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMzowNjoxN1rOGsfSDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODU2MTU1Mg==", "bodyText": "Add override=false for these config files that way they can be overridden by placing the file in the downstream distribution if necessary.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r448561552", "createdAt": "2020-07-01T19:05:57Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-app/src/main/resources/features.xml", "diffHunk": "@@ -49,6 +49,38 @@\n         <bundle>mvn:ddf.catalog.solr/catalog-solr-solrclient/${project.version}</bundle>\n     </feature>\n \n+    <feature name=\"catalog-solr-offline-gazetteer\" version=\"${project.version}\" description=\"Offline gazetteer service utilizing a geonames index stored within a unique solr core (not within the catalog)\">\n+        <feature>solr-core</feature>\n+        <feature>catalog-core</feature>\n+        <feature>guava</feature>\n+        <bundle>mvn:ddf.catalog.solr/catalog-solr-offline-gazetteer/${project.version}</bundle>\n+\n+        <configfile finalname=\"${ddf.etc}/solr/configsets/standalone-solr-gazetteer/conf/solrconfig.xml\">", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTExMzM5Mg==", "bodyText": "\u2757  Sadly RetryPolicy is not thread safe.  Looks like only the constructor uses it currently.  I would suggest moving this to the constructor so no one accidentally reuses it in the future.\nfailsafe-lib/failsafe#47", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449113392", "createdAt": "2020-07-02T15:53:07Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE0MTgwNA==", "bodyText": "\u2753 Why couple the gazetteer collection fields to the catalog attribute taxonomy?\nWhile rare, if any of these attribute names change then the gazetteer collection would need to be re-indexed as well.  If the gazetteer had its own independent field names, then this plugin would be the only one that has to know about the mapping of catalog attribute names to gazetteer field names.  Then this plugin could be extracted later making the bundle with GazetteerQueryOfflineSolr able to remove any direct dependencies on the Catalog API (currently spatial-geocoding-api still has a dependency on the catalog core API but that can be fixed eventually).", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449141804", "createdAt": "2020-07-02T16:39:59Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  @Override\n+  public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getUpdatedMetacards()\n+            .stream()\n+            .map(Update::getNewMetacard)\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+    return input;\n+  }\n+\n+  @Override\n+  public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n+    List<String> ids =\n+        input\n+            .getDeletedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .map(Metacard::getId)\n+            .collect(Collectors.toList());\n+    if (ids.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.deleteById(ids);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  protected static SolrInputDocument convert(Metacard metacard) {\n+    SolrInputDocument solrDoc = new SolrInputDocument();\n+    Consumer<String> getAttrAndAdd =\n+        (attribute) ->\n+            Optional.ofNullable(getStringAttribute(metacard, attribute))\n+                .ifPresent(attr -> solrDoc.addField(attribute + \"_txt\", attr));\n+\n+    getAttrAndAdd.accept(Metacard.DESCRIPTION);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3NjkyMA==", "bodyText": "\u270f\ufe0f Maybe mention it was a query by id.  Something like Error while querying by ID. Nice to have the sanity check instead of relying fully on stacktrace line number.  It also help differentiate this exception from the one thrown in the other query method.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449176920", "createdAt": "2020-07-02T17:46:02Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3ODMyMw==", "bodyText": "\u2753 Why the log and throw here?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449178323", "createdAt": "2020-07-02T17:48:56Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3OTY0NA==", "bodyText": "\u270f\ufe0f Could be final too.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449179644", "createdAt": "2020-07-02T17:51:30Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MDkxMQ==", "bodyText": "\u270f\ufe0f conver to convert\nCould extract these lines to a method named something like convertKilometerToDegree and remove the comment instead.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449180911", "createdAt": "2020-07-02T17:54:02Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MTcwNg==", "bodyText": "\u270f\ufe0f Another log and throw.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449181706", "createdAt": "2020-07-02T17:55:41Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 234}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NTczOA==", "bodyText": "\u270f\ufe0f .filter(s -> !s.isEmpty())\nhttps://docs.oracle.com/javase/7/docs/api/java/lang/String.html#isEmpty()", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449185738", "createdAt": "2020-07-02T18:03:10Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI4OTQyOA==", "bodyText": "\u2753 Wonder if we need to worry about self intersecting geometries here too.  I think we might have to.\n\n  \n    \n      ddf/catalog/solr/catalog-solr-core/src/main/java/ddf/catalog/source/solr/SolrFilterDelegate.java\n    \n    \n        Lines 738 to 763\n      in\n      21ddc98\n    \n    \n    \n    \n\n        \n          \n           private Geometry getGeometry(String wkt) { \n        \n\n        \n          \n             WKTReader reader = new WKTReader(GEOMETRY_FACTORY); \n        \n\n        \n          \n            \n        \n\n        \n          \n             Geometry geo = null; \n        \n\n        \n          \n             try { \n        \n\n        \n          \n               geo = reader.read(fixSelfIntersectingGeometry(wkt)); \n        \n\n        \n          \n             } catch (ParseException e) { \n        \n\n        \n          \n               LOGGER.info(\"Failed to read WKT: {}\", wkt, e); \n        \n\n        \n          \n             } \n        \n\n        \n          \n             return geo; \n        \n\n        \n          \n           } \n        \n\n        \n          \n            \n        \n\n        \n          \n           private String fixSelfIntersectingGeometry(String wkt) { \n        \n\n        \n          \n             try { \n        \n\n        \n          \n               Shape wktShape = WKT_READER.read(wkt); \n        \n\n        \n          \n               // All polygons will be an instance of JtsGeometry. If it is not a polygon we don't need \n        \n\n        \n          \n               // to do anything with it so just return the original wkt string. \n        \n\n        \n          \n               if (!(wktShape instanceof JtsGeometry)) { \n        \n\n        \n          \n                 return wkt; \n        \n\n        \n          \n               } \n        \n\n        \n          \n               return SPATIAL_CONTEXT.getFormats().getWktWriter().toString(wktShape); \n        \n\n        \n          \n             } catch (IOException | java.text.ParseException | InvalidShapeException e) { \n        \n\n        \n          \n               LOGGER.info(\"Failed to fix or read WKT: {}\", wkt, e); \n        \n\n        \n          \n             } \n        \n\n        \n          \n             return wkt; \n        \n\n        \n          \n           }", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449289428", "createdAt": "2020-07-02T22:15:48Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))\n+            .orElse(\"NO TITLE\");\n+\n+    String cardinalDirection = \"\";\n+    double distance = 0;\n+    try {\n+      Geometry geo = WKT_READER_THREAD_LOCAL.get().read(location);\n+      cardinalDirection =\n+          bearingToCardinalDirection(getBearing(originalLocation.getCentroid(), geo.getCentroid()));\n+      // convert distance to KM\n+      distance = originalLocation.distance(geo.getCentroid()) * KM_PER_DEGREE;\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      LOGGER.debug(\"Could not parse location for item (object: {})\", doc.toString(), e);\n+    }\n+\n+    return new NearbyLocationImpl(title, cardinalDirection, distance);\n+  }\n+\n+  public static class NearbyLocationImpl implements NearbyLocation {\n+    private final String name;\n+    private final String cardinalDirection;\n+    private final double distance;\n+\n+    public NearbyLocationImpl(String name, String cardinalDirection, double distance) {\n+      this.name = name;\n+      this.cardinalDirection = cardinalDirection;\n+      this.distance = distance;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+\n+    @Override\n+    public String getCardinalDirection() {\n+      return cardinalDirection;\n+    }\n+\n+    @Override\n+    public double getDistance() {\n+      return distance;\n+    }\n+  }\n+  /**\n+   * Calculates the bearing from the start point to the end point (i.e., the <em>initial bearing\n+   * </em>) in degrees.\n+   *\n+   * @param startPoint the point from which to start\n+   * @param endPoint the point at which to end\n+   * @return the bearing from {@code startPoint} to {@code endPoint}, in degrees\n+   */\n+  private static double getBearing(final Point startPoint, final Point endPoint) {\n+    final double lat1 = startPoint.getY();\n+    final double lon1 = startPoint.getX();\n+\n+    final double lat2 = endPoint.getY();\n+    final double lon2 = endPoint.getX();\n+\n+    final double lonDiffRads = Math.toRadians(lon2 - lon1);\n+    final double lat1Rads = Math.toRadians(lat1);\n+    final double lat2Rads = Math.toRadians(lat2);\n+    final double y = Math.sin(lonDiffRads) * Math.cos(lat2Rads);\n+    final double x =\n+        Math.cos(lat1Rads) * Math.sin(lat2Rads)\n+            - Math.sin(lat1Rads) * Math.cos(lat2Rads) * Math.cos(lonDiffRads);\n+\n+    return (Math.toDegrees(Math.atan2(y, x)) + 360) % 360;\n+  }\n+\n+  /**\n+   * Takes a bearing in degrees and returns the corresponding cardinal direction as a string.\n+   *\n+   * @param bearing the bearing, in degrees\n+   * @return the cardinal direction corresponding to {@code bearing} (N, NE, E, SE, S, SW, W, NW)\n+   */\n+  private static String bearingToCardinalDirection(final double bearing) {\n+    final String[] directions = {\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\", \"N\"};\n+    return directions[(int) Math.round(bearing / 45)];\n+  }\n+\n+  @Override\n+  public Optional<String> getCountryCode(String wktLocation, int radius)\n+      throws GeoEntryQueryException, ParseException {\n+    String wkt;\n+    try {\n+      Point center = WKT_READER_THREAD_LOCAL.get().read(wktLocation).getCentroid();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 336}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI5MzE4MQ==", "bodyText": "\u270f\ufe0f More log and throw to remove in this class.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449293181", "createdAt": "2020-07-02T22:29:19Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI5NjkyNg==", "bodyText": "\u2757 Since this suggester is only used for gazetteer data based on the weight and sort fields, I think it would be safe to change this value in the default solrconfig.xml.  Or we should fix the default suggester to use more meaningful default fields for suggestion weighting and sorting.  Though it would be nice to minimize the number of solrconfig files to one in the default system if possible.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449296926", "createdAt": "2020-07-02T22:42:33Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/resources/solrconfig.xml", "diffHunk": "@@ -0,0 +1,1307 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n+<!--\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/\n+-->\n+<!--\n+ Licensed to the Apache Software Foundation (ASF) under one or more\n+ contributor license agreements.  See the NOTICE file distributed with\n+ this work for additional information regarding copyright ownership.\n+ The ASF licenses this file to You under the Apache License, Version 2.0\n+ (the \"License\"); you may not use this file except in compliance with\n+ the License.  You may obtain a copy of the License at\n+\n+     http://www.apache.org/licenses/LICENSE-2.0\n+\n+ Unless required by applicable law or agreed to in writing, software\n+ distributed under the License is distributed on an \"AS IS\" BASIS,\n+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ See the License for the specific language governing permissions and\n+ limitations under the License.\n+-->\n+\n+<!--\n+     For more details about configurations options that may appear in\n+     this file, see http://wiki.apache.org/solr/SolrConfigXml.\n+-->\n+<config>\n+  <!-- In all configuration below, a prefix of \"solr.\" for class names\n+       is an alias that causes solr to search appropriate packages,\n+       including org.apache.solr.(search|update|request|core|analysis)\n+\n+       You may also specify a fully qualified Java classname if you\n+       have your own custom plugins.\n+    -->\n+\n+  <!-- Controls what version of Lucene various components of Solr\n+       adhere to.  Generally, you want to use the latest version to\n+       get all bug fixes and improvements. It is highly recommended\n+       that you fully re-index after changing this setting as it can\n+       affect both how text is indexed and queried.\n+  -->\n+  <luceneMatchVersion>8.5.0</luceneMatchVersion>\n+\n+  <!-- <lib/> directives can be used to instruct Solr to load any Jars\n+       identified and use them to resolve any \"plugins\" specified in\n+       your solrconfig.xml or schema.xml (ie: Analyzers, Request\n+       Handlers, etc...).\n+\n+       All directories and paths are resolved relative to the\n+       instanceDir.\n+\n+       Please note that <lib/> directives are processed in the order\n+       that they appear in your solrconfig.xml file, and are \"stacked\"\n+       on top of each other when building a ClassLoader - so if you have\n+       plugin jars with dependencies on other jars, the \"lower level\"\n+       dependency jars should be loaded first.\n+\n+       If a \"./lib\" directory exists in your instanceDir, all files\n+       found in it are included as if you had used the following\n+       syntax...\n+\n+              <lib dir=\"./lib\" />\n+    -->\n+\n+  <!-- A 'dir' option by itself adds any files found in the directory\n+       to the classpath, this is useful for including all jars in a\n+       directory.\n+\n+       When a 'regex' is specified in addition to a 'dir', only the\n+       files in that directory which completely match the regex\n+       (anchored on both ends) will be included.\n+\n+       If a 'dir' option (with or without a regex) is used and nothing\n+       is found that matches, a warning will be logged.\n+\n+       The examples below can be used to load some solr-contribs along\n+       with their external dependencies.\n+    -->\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/extraction/lib\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-cell-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/clustering/lib/\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-clustering-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/langid/lib/\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-langid-\\d.*\\.jar\" />\n+\n+  <lib dir=\"${solr.install.dir:../../../..}/contrib/velocity/lib\" regex=\".*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-velocity-\\d.*\\.jar\" />\n+  <lib dir=\"${solr.install.dir:../../../..}/plugins/\" regex=\".*\\.jar\" />\n+  <!-- an exact 'path' can be used instead of a 'dir' to specify a\n+       specific jar file.  This will cause a serious error to be logged\n+       if it can't be loaded.\n+    -->\n+  <!--\n+     <lib path=\"../a-jar-that-does-not-exist.jar\" />\n+  -->\n+\n+  <!-- Data Directory\n+\n+       Used to specify an alternate directory to hold all index data\n+       other than the default ./data under the Solr home.  If\n+       replication is in use, this should match the replication\n+       configuration.\n+    -->\n+  <dataDir>${solr.data.dir:}</dataDir>\n+\n+\n+  <!-- The DirectoryFactory to use for indexes.\n+\n+       solr.StandardDirectoryFactory is filesystem\n+       based and tries to pick the best implementation for the current\n+       JVM and platform.  solr.NRTCachingDirectoryFactory, the default,\n+       wraps solr.StandardDirectoryFactory and caches small files in memory\n+       for better NRT performance.\n+\n+       One can force a particular implementation via solr.MMapDirectoryFactory,\n+       solr.NIOFSDirectoryFactory, or solr.SimpleFSDirectoryFactory.\n+\n+       solr.RAMDirectoryFactory is memory based and not persistent.\n+    -->\n+  <directoryFactory name=\"DirectoryFactory\"\n+                    class=\"${solr.directoryFactory:solr.NRTCachingDirectoryFactory}\"/>\n+\n+  <!-- The CodecFactory for defining the format of the inverted index.\n+       The default implementation is SchemaCodecFactory, which is the official Lucene\n+       index format, but hooks into the schema to provide per-field customization of\n+       the postings lists and per-document values in the fieldType element\n+       (postingsFormat/docValuesFormat). Note that most of the alternative implementations\n+       are experimental, so if you choose to customize the index format, it's a good\n+       idea to convert back to the official format e.g. via IndexWriter.addIndexes(IndexReader)\n+       before upgrading to a newer version to avoid unnecessary reindexing.\n+       A \"compressionMode\" string element can be added to <codecFactory> to choose\n+       between the existing compression modes in the default codec: \"BEST_SPEED\" (default)\n+       or \"BEST_COMPRESSION\".\n+  -->\n+  <codecFactory class=\"solr.SchemaCodecFactory\"/>\n+\n+  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+       Index Config - These settings control low-level behavior of indexing\n+       Most example settings here show the default value, but are commented\n+       out, to more easily see where customizations have been made.\n+\n+       Note: This replaces <indexDefaults> and <mainIndex> from older versions\n+       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n+  <indexConfig>\n+    <!-- maxFieldLength was removed in 4.0. To get similar behavior, include a\n+         LimitTokenCountFilterFactory in your fieldType definition. E.g.\n+     <filter class=\"solr.LimitTokenCountFilterFactory\" maxTokenCount=\"10000\"/>\n+    -->\n+    <!-- Maximum time to wait for a write lock (ms) for an IndexWriter. Default: 1000 -->\n+    <!-- <writeLockTimeout>1000</writeLockTimeout>  -->\n+\n+    <!-- Expert: Enabling compound file will use less files for the index,\n+         using fewer file descriptors on the expense of performance decrease.\n+         Default in Lucene is \"true\". Default in Solr is \"false\" (since 3.6) -->\n+    <!-- <useCompoundFile>false</useCompoundFile> -->\n+\n+    <!-- ramBufferSizeMB sets the amount of RAM that may be used by Lucene\n+         indexing for buffering added documents and deletions before they are\n+         flushed to the Directory.\n+         maxBufferedDocs sets a limit on the number of documents buffered\n+         before flushing.\n+         If both ramBufferSizeMB and maxBufferedDocs is set, then\n+         Lucene will flush based on whichever limit is hit first.  -->\n+    <!-- <ramBufferSizeMB>100</ramBufferSizeMB> -->\n+    <!-- <maxBufferedDocs>1000</maxBufferedDocs> -->\n+\n+    <!-- Expert: Merge Policy\n+         The Merge Policy in Lucene controls how merging of segments is done.\n+         The default since Solr/Lucene 3.3 is TieredMergePolicy.\n+         The default since Lucene 2.3 was the LogByteSizeMergePolicy,\n+         Even older versions of Lucene used LogDocMergePolicy.\n+      -->\n+    <!--\n+        <mergePolicyFactory class=\"org.apache.solr.index.TieredMergePolicyFactory\">\n+          <int name=\"maxMergeAtOnce\">10</int>\n+          <int name=\"segmentsPerTier\">10</int>\n+          <double name=\"noCFSRatio\">0.1</double>\n+        </mergePolicyFactory>\n+      -->\n+\n+    <!-- Expert: Merge Scheduler\n+         The Merge Scheduler in Lucene controls how merges are\n+         performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)\n+         can perform merges in the background using separate threads.\n+         The SerialMergeScheduler (Lucene 2.2 default) does not.\n+     -->\n+    <!--\n+       <mergeScheduler class=\"org.apache.lucene.index.ConcurrentMergeScheduler\"/>\n+       -->\n+\n+    <!-- LockFactory\n+\n+         This option specifies which Lucene LockFactory implementation\n+         to use.\n+\n+         single = SingleInstanceLockFactory - suggested for a\n+                  read-only index or when there is no possibility of\n+                  another process trying to modify the index.\n+         native = NativeFSLockFactory - uses OS native file locking.\n+                  Do not use when multiple solr webapps in the same\n+                  JVM are attempting to share a single index.\n+         simple = SimpleFSLockFactory  - uses a plain file for locking\n+\n+         Defaults: 'native' is default for Solr3.6 and later, otherwise\n+                   'simple' is the default\n+\n+         More details on the nuances of each LockFactory...\n+         http://wiki.apache.org/lucene-java/AvailableLockFactories\n+    -->\n+    <lockType>${solr.lock.type:native}</lockType>\n+\n+    <!-- Commit Deletion Policy\n+         Custom deletion policies can be specified here. The class must\n+         implement org.apache.lucene.index.IndexDeletionPolicy.\n+\n+         The default Solr IndexDeletionPolicy implementation supports\n+         deleting index commit points on number of commits, age of\n+         commit point and optimized status.\n+\n+         The latest commit point should always be preserved regardless\n+         of the criteria.\n+    -->\n+    <!--\n+    <deletionPolicy class=\"solr.SolrDeletionPolicy\">\n+    -->\n+    <!-- The number of commit points to be kept -->\n+    <!-- <str name=\"maxCommitsToKeep\">1</str> -->\n+    <!-- The number of optimized commit points to be kept -->\n+    <!-- <str name=\"maxOptimizedCommitsToKeep\">0</str> -->\n+    <!--\n+        Delete all commit points once they have reached the given age.\n+        Supports DateMathParser syntax e.g.\n+      -->\n+    <!--\n+       <str name=\"maxCommitAge\">30MINUTES</str>\n+       <str name=\"maxCommitAge\">1DAY</str>\n+    -->\n+    <!--\n+    </deletionPolicy>\n+    -->\n+\n+    <!-- Lucene Infostream\n+\n+         To aid in advanced debugging, Lucene provides an \"InfoStream\"\n+         of detailed information when indexing.\n+\n+         Setting The value to true will instruct the underlying Lucene\n+         IndexWriter to write its debugging info the specified file\n+      -->\n+    <!-- <infoStream file=\"INFOSTREAM.txt\">false</infoStream> -->\n+  </indexConfig>\n+\n+\n+  <!-- JMX\n+\n+       This example enables JMX if and only if an existing MBeanServer\n+       is found, use this if you want to configure JMX through JVM\n+       parameters. Remove this to disable exposing Solr configuration\n+       and statistics to JMX.\n+\n+       For more details see http://wiki.apache.org/solr/SolrJmx\n+    -->\n+  <jmx />\n+  <!-- If you want to connect to a particular server, specify the\n+       agentId\n+    -->\n+  <!-- <jmx agentId=\"myAgent\" /> -->\n+  <!-- If you want to start a new MBeanServer, specify the serviceUrl -->\n+  <!-- <jmx serviceUrl=\"service:jmx:rmi:///jndi/rmi://localhost:9999/solr\"/>\n+    -->\n+\n+  <!-- The default high-performance update handler -->\n+  <updateHandler class=\"solr.DirectUpdateHandler2\">\n+\n+    <!-- Enables a transaction log, used for real-time get, durability, and\n+         and solr cloud replica recovery.  The log can grow as big as\n+         uncommitted changes to the index, so use of a hard autoCommit\n+         is recommended (see below).\n+         \"dir\" - the target directory for transaction logs, defaults to the\n+                solr data directory.\n+         \"numVersionBuckets\" - sets the number of buckets used to keep\n+                track of max version values when checking for re-ordered\n+                updates; increase this value to reduce the cost of\n+                synchronizing access to version buckets during high-volume\n+                indexing, this requires 8 bytes (long) * numVersionBuckets\n+                of heap space per Solr core.\n+    -->\n+    <updateLog>\n+      <str name=\"dir\">${solr.ulog.dir:}</str>\n+      <int name=\"numRecordsToKeep\">${solr.ulog.numRecordsToKeep:100}</int>\n+      <int name=\"maxNumLogsToKeep\">${solr.ulog.maxNumLogsToKeep:10}</int>\n+      <int name=\"numVersionBuckets\">${solr.ulog.numVersionBuckets:65536}</int>\n+    </updateLog>\n+\n+    <!-- AutoCommit\n+\n+         Perform a hard commit automatically under certain conditions.\n+         Instead of enabling autoCommit, consider using \"commitWithin\"\n+         when adding documents.\n+\n+         http://wiki.apache.org/solr/UpdateXmlMessages\n+\n+         maxDocs - Maximum number of documents to add since the last\n+                   commit before automatically triggering a new commit.\n+\n+         maxTime - Maximum amount of time in ms that is allowed to pass\n+                   since a document was added before automatically\n+                   triggering a new commit.\n+         openSearcher - if false, the commit causes recent index changes\n+           to be flushed to stable storage, but does not cause a new\n+           searcher to be opened to make those changes visible.\n+\n+         If the updateLog is enabled, then it's highly recommended to\n+         have some sort of hard autoCommit to limit the log size.\n+      -->\n+    <autoCommit>\n+      <maxTime>${solr.autoCommit.maxTime:60000}</maxTime>\n+      <maxDocs>${solr.autoCommit.maxDocs:10000}</maxDocs>\n+      <maxSize>${solr.autoCommit.maxSize:128m}</maxSize>\n+      <openSearcher>false</openSearcher>\n+    </autoCommit>\n+\n+    <!-- softAutoCommit is like autoCommit except it causes a\n+         'soft' commit which only ensures that changes are visible\n+         but does not ensure that data is synced to disk.  This is\n+         faster and more near-realtime friendly than a hard commit.\n+      -->\n+\n+    <autoSoftCommit>\n+      <maxTime>${solr.autoSoftCommit.maxTime:30000}</maxTime>\n+    </autoSoftCommit>\n+\n+    <!-- Update Related Event Listeners\n+\n+         Various IndexWriter related events can trigger Listeners to\n+         take actions.\n+\n+         postCommit - fired after every commit or optimize command\n+         postOptimize - fired after every optimize command\n+      -->\n+\n+  </updateHandler>\n+\n+  <!-- IndexReaderFactory\n+\n+       Use the following format to specify a custom IndexReaderFactory,\n+       which allows for alternate IndexReader implementations.\n+\n+       ** Experimental Feature **\n+\n+       Please note - Using a custom IndexReaderFactory may prevent\n+       certain other features from working. The API to\n+       IndexReaderFactory may change without warning or may even be\n+       removed from future releases if the problems cannot be\n+       resolved.\n+\n+\n+       ** Features that may not work with custom IndexReaderFactory **\n+\n+       The ReplicationHandler assumes a disk-resident index. Using a\n+       custom IndexReader implementation may cause incompatibility\n+       with ReplicationHandler and may cause replication to not work\n+       correctly. See SOLR-1366 for details.\n+\n+    -->\n+  <!--\n+  <indexReaderFactory name=\"IndexReaderFactory\" class=\"package.class\">\n+    <str name=\"someArg\">Some Value</str>\n+  </indexReaderFactory >\n+  -->\n+\n+  <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+       Query section - these settings control query time things like caches\n+       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n+  <query>\n+\n+    <!-- Maximum number of clauses in each BooleanQuery,  an exception\n+         is thrown if exceeded.  It is safe to increase or remove this setting,\n+         since it is purely an arbitrary limit to try and catch user errors where\n+         large boolean queries may not be the best implementation choice.\n+      -->\n+    <maxBooleanClauses>1024</maxBooleanClauses>\n+\n+    <!-- Solr Internal Query Caches\n+\n+         There are two implementations of cache available for Solr,\n+         LRUCache, based on a synchronized LinkedHashMap, and\n+         FastLRUCache, based on a ConcurrentHashMap.\n+\n+         FastLRUCache has faster gets and slower puts in single\n+         threaded operation and thus is generally faster than LRUCache\n+         when the hit ratio of the cache is high (> 75%), and may be\n+         faster under other scenarios on multi-cpu systems.\n+    -->\n+\n+    <!-- Filter Cache\n+\n+         Cache used by SolrIndexSearcher for filters (DocSets),\n+         unordered sets of *all* documents that match a query.  When a\n+         new searcher is opened, its caches may be prepopulated or\n+         \"autowarmed\" using data from caches in the old searcher.\n+         autowarmCount is the number of items to prepopulate.  For\n+         LRUCache, the autowarmed items will be the most recently\n+         accessed items.\n+\n+         Parameters:\n+           class - the SolrCache implementation LRUCache or\n+               (LRUCache or FastLRUCache)\n+           size - the maximum number of entries in the cache\n+           initialSize - the initial capacity (number of entries) of\n+               the cache.  (see java.util.HashMap)\n+           autowarmCount - the number of entries to prepopulate from\n+               and old cache.\n+           maxRamMB - the maximum amount of RAM (in MB) that this cache is allowed\n+                      to occupy. Note that when this option is specified, the size\n+                      and initialSize parameters are ignored.\n+      -->\n+    <filterCache class=\"solr.FastLRUCache\"\n+                 size=\"512\"\n+                 initialSize=\"512\"\n+                 autowarmCount=\"0\"/>\n+\n+    <!-- Query Result Cache\n+\n+         Caches results of searches - ordered lists of document ids\n+         (DocList) based on a query, a sort, and the range of documents requested.\n+         Additional supported parameter by LRUCache:\n+            maxRamMB - the maximum amount of RAM (in MB) that this cache is allowed\n+                       to occupy\n+      -->\n+    <queryResultCache class=\"solr.LRUCache\"\n+                      size=\"512\"\n+                      initialSize=\"512\"\n+                      autowarmCount=\"0\"/>\n+\n+    <!-- Document Cache\n+\n+         Caches Lucene Document objects (the stored fields for each\n+         document).  Since Lucene internal document ids are transient,\n+         this cache will not be autowarmed.\n+      -->\n+    <documentCache class=\"solr.LRUCache\"\n+                   size=\"512\"\n+                   initialSize=\"512\"\n+                   autowarmCount=\"0\"/>\n+\n+    <!-- custom cache currently used by block join -->\n+    <cache name=\"perSegFilter\"\n+           class=\"solr.search.LRUCache\"\n+           size=\"10\"\n+           initialSize=\"0\"\n+           autowarmCount=\"10\"\n+           regenerator=\"solr.NoOpRegenerator\" />\n+\n+    <!-- Field Value Cache\n+\n+         Cache used to hold field values that are quickly accessible\n+         by document id.  The fieldValueCache is created by default\n+         even if not configured here.\n+      -->\n+    <!--\n+       <fieldValueCache class=\"solr.FastLRUCache\"\n+                        size=\"512\"\n+                        autowarmCount=\"128\"\n+                        showItems=\"32\" />\n+      -->\n+\n+    <!-- Custom Cache\n+\n+         Example of a generic cache.  These caches may be accessed by\n+         name through SolrIndexSearcher.getCache(),cacheLookup(), and\n+         cacheInsert().  The purpose is to enable easy caching of\n+         user/application level data.  The regenerator argument should\n+         be specified as an implementation of solr.CacheRegenerator\n+         if autowarming is desired.\n+      -->\n+    <!--\n+       <cache name=\"myUserCache\"\n+              class=\"solr.LRUCache\"\n+              size=\"4096\"\n+              initialSize=\"1024\"\n+              autowarmCount=\"1024\"\n+              regenerator=\"com.mycompany.MyRegenerator\"\n+              />\n+      -->\n+\n+\n+    <!-- Lazy Field Loading\n+\n+         If true, stored fields that are not requested will be loaded\n+         lazily.  This can result in a significant speed improvement\n+         if the usual case is to not load all stored fields,\n+         especially if the skipped fields are large compressed text\n+         fields.\n+    -->\n+    <enableLazyFieldLoading>true</enableLazyFieldLoading>\n+\n+    <!-- Use Filter For Sorted Query\n+\n+         A possible optimization that attempts to use a filter to\n+         satisfy a search.  If the requested sort does not include\n+         score, then the filterCache will be checked for a filter\n+         matching the query. If found, the filter will be used as the\n+         source of document ids, and then the sort will be applied to\n+         that.\n+\n+         For most situations, this will not be useful unless you\n+         frequently get the same search repeatedly with different sort\n+         options, and none of them ever use \"score\"\n+      -->\n+    <!--\n+       <useFilterForSortedQuery>true</useFilterForSortedQuery>\n+      -->\n+\n+    <!-- Result Window Size\n+\n+         An optimization for use with the queryResultCache.  When a search\n+         is requested, a superset of the requested number of document ids\n+         are collected.  For example, if a search for a particular query\n+         requests matching documents 10 through 19, and queryWindowSize is 50,\n+         then documents 0 through 49 will be collected and cached.  Any further\n+         requests in that range can be satisfied via the cache.\n+      -->\n+    <queryResultWindowSize>20</queryResultWindowSize>\n+\n+    <!-- Maximum number of documents to cache for any entry in the\n+         queryResultCache.\n+      -->\n+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>\n+\n+    <!-- Query Related Event Listeners\n+\n+         Various IndexSearcher related events can trigger Listeners to\n+         take actions.\n+\n+         newSearcher - fired whenever a new searcher is being prepared\n+         and there is a current searcher handling requests (aka\n+         registered).  It can be used to prime certain caches to\n+         prevent long request times for certain requests.\n+\n+         firstSearcher - fired whenever a new searcher is being\n+         prepared but there is no current registered searcher to handle\n+         requests or to gain autowarming data from.\n+\n+\n+      -->\n+    <!-- QuerySenderListener takes an array of NamedList and executes a\n+         local query request for each NamedList in sequence.\n+      -->\n+    <listener event=\"newSearcher\" class=\"solr.QuerySenderListener\">\n+      <arr name=\"queries\">\n+        <!--\n+           <lst><str name=\"q\">solr</str><str name=\"sort\">price asc</str></lst>\n+           <lst><str name=\"q\">rocks</str><str name=\"sort\">weight asc</str></lst>\n+          -->\n+      </arr>\n+    </listener>\n+    <listener event=\"firstSearcher\" class=\"solr.QuerySenderListener\">\n+      <arr name=\"queries\">\n+        <!--\n+        <lst>\n+          <str name=\"q\">static firstSearcher warming in solrconfig.xml</str>\n+        </lst>\n+        -->\n+      </arr>\n+    </listener>\n+\n+    <!-- Use Cold Searcher\n+\n+         If a search request comes in and there is no current\n+         registered searcher, then immediately register the still\n+         warming searcher and use it.  If \"false\" then all requests\n+         will block until the first searcher is done warming.\n+      -->\n+    <useColdSearcher>false</useColdSearcher>\n+\n+  </query>\n+\n+\n+  <!-- Request Dispatcher\n+\n+       This section contains instructions for how the SolrDispatchFilter\n+       should behave when processing requests for this SolrCore.\n+\n+    -->\n+  <requestDispatcher>\n+    <!-- Request Parsing\n+\n+         These settings indicate how Solr Requests may be parsed, and\n+         what restrictions may be placed on the ContentStreams from\n+         those requests\n+\n+         enableRemoteStreaming - enables use of the stream.file\n+         and stream.url parameters for specifying remote streams.\n+\n+         multipartUploadLimitInKB - specifies the max size (in KiB) of\n+         Multipart File Uploads that Solr will allow in a Request.\n+\n+         formdataUploadLimitInKB - specifies the max size (in KiB) of\n+         form data (application/x-www-form-urlencoded) sent via\n+         POST. You can use POST to pass request parameters not\n+         fitting into the URL.\n+\n+         addHttpRequestToContext - if set to true, it will instruct\n+         the requestParsers to include the original HttpServletRequest\n+         object in the context map of the SolrQueryRequest under the\n+         key \"httpRequest\". It will not be used by any of the existing\n+         Solr components, but may be useful when developing custom\n+         plugins.\n+\n+         *** WARNING ***\n+         Before enabling remote streaming, you should make sure your\n+         system has authentication enabled.\n+\n+    <requestParsers enableRemoteStreaming=\"false\"\n+                    multipartUploadLimitInKB=\"-1\"\n+                    formdataUploadLimitInKB=\"-1\"\n+                    addHttpRequestToContext=\"false\"/>\n+      -->\n+\n+    <!-- HTTP Caching\n+\n+         Set HTTP caching related parameters (for proxy caches and clients).\n+\n+         The options below instruct Solr not to output any HTTP Caching\n+         related headers\n+      -->\n+    <httpCaching never304=\"true\" />\n+    <!-- If you include a <cacheControl> directive, it will be used to\n+         generate a Cache-Control header (as well as an Expires header\n+         if the value contains \"max-age=\")\n+\n+         By default, no Cache-Control header is generated.\n+\n+         You can use the <cacheControl> option even if you have set\n+         never304=\"true\"\n+      -->\n+    <!--\n+       <httpCaching never304=\"true\" >\n+         <cacheControl>max-age=30, public</cacheControl>\n+       </httpCaching>\n+      -->\n+    <!-- To enable Solr to respond with automatically generated HTTP\n+         Caching headers, and to response to Cache Validation requests\n+         correctly, set the value of never304=\"false\"\n+\n+         This will cause Solr to generate Last-Modified and ETag\n+         headers based on the properties of the Index.\n+\n+         The following options can also be specified to affect the\n+         values of these headers...\n+\n+         lastModFrom - the default value is \"openTime\" which means the\n+         Last-Modified value (and validation against If-Modified-Since\n+         requests) will all be relative to when the current Searcher\n+         was opened.  You can change it to lastModFrom=\"dirLastMod\" if\n+         you want the value to exactly correspond to when the physical\n+         index was last modified.\n+\n+         etagSeed=\"...\" is an option you can change to force the ETag\n+         header (and validation against If-None-Match requests) to be\n+         different even if the index has not changed (ie: when making\n+         significant changes to your config file)\n+\n+         (lastModifiedFrom and etagSeed are both ignored if you use\n+         the never304=\"true\" option)\n+      -->\n+    <!--\n+       <httpCaching lastModifiedFrom=\"openTime\"\n+                    etagSeed=\"Solr\">\n+         <cacheControl>max-age=30, public</cacheControl>\n+       </httpCaching>\n+      -->\n+  </requestDispatcher>\n+\n+  <!-- Request Handlers\n+\n+       http://wiki.apache.org/solr/SolrRequestHandler\n+\n+       Incoming queries will be dispatched to a specific handler by name\n+       based on the path specified in the request.\n+\n+       If a Request Handler is declared with startup=\"lazy\", then it will\n+       not be initialized until the first request that uses it.\n+\n+    -->\n+  <!-- SearchHandler\n+\n+       http://wiki.apache.org/solr/SearchHandler\n+\n+       For processing Search Queries, the primary Request Handler\n+       provided with Solr is \"SearchHandler\" It delegates to a sequent\n+       of SearchComponents (see below) and supports distributed\n+       queries across multiple shards\n+    -->\n+  <requestHandler name=\"/select\" class=\"solr.SearchHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+      <str name=\"spellcheck\">false</str>\n+      <str name=\"spellcheck.dictionary\">filebased</str>\n+      <str name=\"spellcheck.extendedResults\">true</str>\n+      <str name=\"spellcheck.count\">10</str>\n+      <str name=\"spellcheck.alternativeTermCount\">5</str>\n+      <str name=\"spellcheck.maxResultsForSuggest\">5</str>\n+      <str name=\"spellcheck.collate\">true</str>\n+      <str name=\"spellcheck.collateExtendedResults\">true</str>\n+      <str name=\"spellcheck.maxCollationTries\">100</str>\n+      <str name=\"spellcheck.maxCollations\">5</str>\n+      <str name=\"spellcheck.onlyMorePopular\">true</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>spellcheck</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- A request handler that returns indented JSON by default -->\n+  <requestHandler name=\"/query\" class=\"solr.SearchHandler\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+      <str name=\"wt\">json</str>\n+      <str name=\"indent\">true</str>\n+    </lst>\n+  </requestHandler>\n+\n+\n+  <!-- A Robust Example\n+\n+       This example SearchHandler declaration shows off usage of the\n+       SearchHandler with many defaults declared\n+\n+       Note that multiple instances of the same Request Handler\n+       (SearchHandler) can be registered multiple times with different\n+       names (and different init parameters)\n+    -->\n+  <requestHandler name=\"/browse\" class=\"solr.SearchHandler\" useParams=\"query,facets,velocity,browse\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <initParams path=\"/update/**,/query,/select,/tvrh,/elevate,/spell,/browse\">\n+    <lst name=\"defaults\">\n+      <str name=\"df\">_text_</str>\n+    </lst>\n+  </initParams>\n+\n+  <!-- Solr Cell Update Request Handler\n+\n+       http://wiki.apache.org/solr/ExtractingRequestHandler\n+\n+    -->\n+  <requestHandler name=\"/update/extract\"\n+                  startup=\"lazy\"\n+                  class=\"solr.extraction.ExtractingRequestHandler\" >\n+    <lst name=\"defaults\">\n+      <str name=\"lowernames\">true</str>\n+      <str name=\"fmap.meta\">ignored_</str>\n+      <str name=\"fmap.content\">_text_</str>\n+    </lst>\n+  </requestHandler>\n+\n+  <!-- Search Components\n+\n+       Search components are registered to SolrCore and used by\n+       instances of SearchHandler (which can access them by name)\n+\n+       By default, the following components are available:\n+\n+       <searchComponent name=\"query\"     class=\"solr.QueryComponent\" />\n+       <searchComponent name=\"facet\"     class=\"solr.FacetComponent\" />\n+       <searchComponent name=\"mlt\"       class=\"solr.MoreLikeThisComponent\" />\n+       <searchComponent name=\"highlight\" class=\"solr.HighlightComponent\" />\n+       <searchComponent name=\"stats\"     class=\"solr.StatsComponent\" />\n+       <searchComponent name=\"debug\"     class=\"solr.DebugComponent\" />\n+\n+       Default configuration in a requestHandler would look like:\n+\n+       <arr name=\"components\">\n+         <str>query</str>\n+         <str>facet</str>\n+         <str>mlt</str>\n+         <str>highlight</str>\n+         <str>stats</str>\n+         <str>debug</str>\n+       </arr>\n+\n+       If you register a searchComponent to one of the standard names,\n+       that will be used instead of the default.\n+\n+       To insert components before or after the 'standard' components, use:\n+\n+       <arr name=\"first-components\">\n+         <str>myFirstComponentName</str>\n+       </arr>\n+\n+       <arr name=\"last-components\">\n+         <str>myLastComponentName</str>\n+       </arr>\n+\n+       NOTE: The component registered with the name \"debug\" will\n+       always be executed after the \"last-components\"\n+\n+     -->\n+\n+  <!-- Spell Check\n+\n+       The spell check component can return a list of alternative spelling\n+       suggestions.\n+\n+       http://wiki.apache.org/solr/SpellCheckComponent\n+    -->\n+  <searchComponent name=\"spellcheck\" class=\"solr.SpellCheckComponent\">\n+\n+    <str name=\"queryAnalyzerFieldType\">text_suggest</str>\n+\n+    <lst name=\"spellchecker\">\n+      <!-- The spellcheck index will need to be built once for this dictionary before it will work -->\n+      <str name=\"name\">filebased</str>\n+      <str name=\"classname\">solr.FileBasedSpellChecker</str>\n+      <str name=\"sourceLocation\">dictionary.txt</str>\n+      <str name=\"spellcheckIndexDir\">./spellcheckerFile</str>\n+      <str name=\"characterEncoding\">UTF-8</str>\n+    </lst>\n+  </searchComponent>\n+\n+  <!-- A request handler for demonstrating the spellcheck component.\n+\n+       NOTE: This is purely as an example.  The whole purpose of the\n+       SpellCheckComponent is to hook it into the request handler that\n+       handles your normal user queries so that a separate request is\n+       not needed to get suggestions.\n+\n+       IN OTHER WORDS, THERE IS REALLY GOOD CHANCE THE SETUP BELOW IS\n+       NOT WHAT YOU WANT FOR YOUR PRODUCTION SYSTEM!\n+\n+       See http://wiki.apache.org/solr/SpellCheckComponent for details\n+       on the request parameters.\n+    -->\n+  <requestHandler name=\"/spell\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <!-- Solr will use suggestions from both the 'default' spellchecker\n+           and from the 'wordbreak' spellchecker and combine them.\n+           collations (re-written queries) can include a combination of\n+           corrections from both spellcheckers -->\n+      <str name=\"spellcheck.dictionary\">filebased</str>\n+      <str name=\"spellcheck\">on</str>\n+      <str name=\"spellcheck.extendedResults\">true</str>\n+      <str name=\"spellcheck.count\">10</str>\n+      <str name=\"spellcheck.alternativeTermCount\">5</str>\n+      <str name=\"spellcheck.maxResultsForSuggest\">5</str>\n+      <str name=\"spellcheck.collate\">true</str>\n+      <str name=\"spellcheck.collateExtendedResults\">true</str>\n+      <str name=\"spellcheck.maxCollationTries\">10</str>\n+      <str name=\"spellcheck.maxCollations\">5</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>spellcheck</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Term Vector Component\n+\n+       http://wiki.apache.org/solr/TermVectorComponent\n+    -->\n+  <searchComponent name=\"tvComponent\" class=\"solr.TermVectorComponent\"/>\n+\n+  <!-- A request handler for demonstrating the term vector component\n+\n+       This is purely as an example.\n+\n+       In reality you will likely want to add the component to your\n+       already specified request handlers.\n+    -->\n+  <requestHandler name=\"/tvrh\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <bool name=\"tv\">true</bool>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>tvComponent</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Clustering Component. (Omitted here. See the default Solr example for a typical configuration.) -->\n+\n+  <!-- Terms Component\n+\n+       http://wiki.apache.org/solr/TermsComponent\n+\n+       A component to return terms and document frequency of those\n+       terms\n+    -->\n+  <searchComponent name=\"terms\" class=\"solr.TermsComponent\"/>\n+\n+  <!-- A request handler for demonstrating the terms component -->\n+  <requestHandler name=\"/terms\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <bool name=\"terms\">true</bool>\n+      <bool name=\"distrib\">false</bool>\n+    </lst>\n+    <arr name=\"components\">\n+      <str>terms</str>\n+    </arr>\n+  </requestHandler>\n+\n+\n+  <!-- Query Elevation Component\n+\n+       http://wiki.apache.org/solr/QueryElevationComponent\n+\n+       a search component that enables you to configure the top\n+       results for a given query regardless of the normal lucene\n+       scoring.\n+    -->\n+  <searchComponent name=\"elevator\" class=\"solr.QueryElevationComponent\" >\n+    <!-- pick a fieldType to analyze queries -->\n+    <str name=\"queryFieldType\">string</str>\n+  </searchComponent>\n+\n+  <!-- A request handler for demonstrating the elevator component -->\n+  <requestHandler name=\"/elevate\" class=\"solr.SearchHandler\" startup=\"lazy\">\n+    <lst name=\"defaults\">\n+      <str name=\"echoParams\">explicit</str>\n+    </lst>\n+    <arr name=\"last-components\">\n+      <str>elevator</str>\n+    </arr>\n+  </requestHandler>\n+\n+  <!-- Highlighting Component\n+\n+       http://wiki.apache.org/solr/HighlightingParameters\n+    -->\n+  <searchComponent class=\"solr.HighlightComponent\" name=\"highlight\">\n+    <highlighting>\n+      <!-- Configure the standard fragmenter -->\n+      <!-- This could most likely be commented out in the \"default\" case -->\n+      <fragmenter name=\"gap\"\n+                  default=\"true\"\n+                  class=\"solr.highlight.GapFragmenter\">\n+        <lst name=\"defaults\">\n+          <int name=\"hl.fragsize\">100</int>\n+        </lst>\n+      </fragmenter>\n+\n+      <!-- A regular-expression-based fragmenter\n+           (for sentence extraction)\n+        -->\n+      <fragmenter name=\"regex\"\n+                  class=\"solr.highlight.RegexFragmenter\">\n+        <lst name=\"defaults\">\n+          <!-- slightly smaller fragsizes work better because of slop -->\n+          <int name=\"hl.fragsize\">70</int>\n+          <!-- allow 50% slop on fragment sizes -->\n+          <float name=\"hl.regex.slop\">0.5</float>\n+          <!-- a basic sentence pattern -->\n+          <str name=\"hl.regex.pattern\">[-\\w ,/\\n\\&quot;&apos;]{20,200}</str>\n+        </lst>\n+      </fragmenter>\n+\n+      <!-- Configure the standard formatter -->\n+      <formatter name=\"html\"\n+                 default=\"true\"\n+                 class=\"solr.highlight.HtmlFormatter\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.simple.pre\"><![CDATA[<em>]]></str>\n+          <str name=\"hl.simple.post\"><![CDATA[</em>]]></str>\n+        </lst>\n+      </formatter>\n+\n+      <!-- Configure the standard encoder -->\n+      <encoder name=\"html\"\n+               class=\"solr.highlight.HtmlEncoder\" />\n+\n+      <!-- Configure the standard fragListBuilder -->\n+      <fragListBuilder name=\"simple\"\n+                       class=\"solr.highlight.SimpleFragListBuilder\"/>\n+\n+      <!-- Configure the single fragListBuilder -->\n+      <fragListBuilder name=\"single\"\n+                       class=\"solr.highlight.SingleFragListBuilder\"/>\n+\n+      <!-- Configure the weighted fragListBuilder -->\n+      <fragListBuilder name=\"weighted\"\n+                       default=\"true\"\n+                       class=\"solr.highlight.WeightedFragListBuilder\"/>\n+\n+      <!-- default tag FragmentsBuilder -->\n+      <fragmentsBuilder name=\"default\"\n+                        default=\"true\"\n+                        class=\"solr.highlight.ScoreOrderFragmentsBuilder\">\n+        <!--\n+        <lst name=\"defaults\">\n+          <str name=\"hl.multiValuedSeparatorChar\">/</str>\n+        </lst>\n+        -->\n+      </fragmentsBuilder>\n+\n+      <!-- multi-colored tag FragmentsBuilder -->\n+      <fragmentsBuilder name=\"colored\"\n+                        class=\"solr.highlight.ScoreOrderFragmentsBuilder\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.tag.pre\"><![CDATA[\n+               <b style=\"background:yellow\">,<b style=\"background:lawgreen\">,\n+               <b style=\"background:aquamarine\">,<b style=\"background:magenta\">,\n+               <b style=\"background:palegreen\">,<b style=\"background:coral\">,\n+               <b style=\"background:wheat\">,<b style=\"background:khaki\">,\n+               <b style=\"background:lime\">,<b style=\"background:deepskyblue\">]]></str>\n+          <str name=\"hl.tag.post\"><![CDATA[</b>]]></str>\n+        </lst>\n+      </fragmentsBuilder>\n+\n+      <boundaryScanner name=\"default\"\n+                       default=\"true\"\n+                       class=\"solr.highlight.SimpleBoundaryScanner\">\n+        <lst name=\"defaults\">\n+          <str name=\"hl.bs.maxScan\">10</str>\n+          <str name=\"hl.bs.chars\">.,!? &#9;&#10;&#13;</str>\n+        </lst>\n+      </boundaryScanner>\n+\n+      <boundaryScanner name=\"breakIterator\"\n+                       class=\"solr.highlight.BreakIteratorBoundaryScanner\">\n+        <lst name=\"defaults\">\n+          <!-- type should be one of CHARACTER, WORD(default), LINE and SENTENCE -->\n+          <str name=\"hl.bs.type\">WORD</str>\n+          <!-- language and country are used when constructing Locale object.  -->\n+          <!-- And the Locale object will be used when getting instance of BreakIterator -->\n+          <str name=\"hl.bs.language\">en</str>\n+          <str name=\"hl.bs.country\">US</str>\n+        </lst>\n+      </boundaryScanner>\n+    </highlighting>\n+  </searchComponent>\n+\n+  <!-- Update Processors\n+\n+       Chains of Update Processor Factories for dealing with Update\n+       Requests can be declared, and then used by name in Update\n+       Request Processors\n+\n+       http://wiki.apache.org/solr/UpdateRequestProcessor\n+\n+    -->\n+\n+  <!-- Add unknown fields to the schema\n+\n+       Field type guessing update processors that will\n+       attempt to parse string-typed field values as Booleans, Longs,\n+       Doubles, or Dates, and then add schema fields with the guessed\n+       field types. Text content will be indexed as \"text_general\" as\n+       well as a copy to a plain string version in *_str.\n+\n+       These require that the schema is both managed and mutable, by\n+       declaring schemaFactory as ManagedIndexSchemaFactory, with\n+       mutable specified as true.\n+\n+       See http://wiki.apache.org/solr/GuessingFieldTypes\n+    -->\n+  <updateProcessor class=\"solr.UUIDUpdateProcessorFactory\" name=\"uuid\"/>\n+  <updateProcessor class=\"solr.RemoveBlankFieldUpdateProcessorFactory\" name=\"remove-blank\"/>\n+  <updateProcessor class=\"solr.FieldNameMutatingUpdateProcessorFactory\" name=\"field-name-mutating\">\n+    <str name=\"pattern\">[^\\w-\\.]</str>\n+    <str name=\"replacement\">_</str>\n+  </updateProcessor>\n+  <updateProcessor class=\"solr.ParseBooleanFieldUpdateProcessorFactory\" name=\"parse-boolean\"/>\n+  <updateProcessor class=\"solr.ParseLongFieldUpdateProcessorFactory\" name=\"parse-long\"/>\n+  <updateProcessor class=\"solr.ParseDoubleFieldUpdateProcessorFactory\" name=\"parse-double\"/>\n+  <updateProcessor class=\"solr.ParseDateFieldUpdateProcessorFactory\" name=\"parse-date\">\n+    <arr name=\"format\">\n+      <str>yyyy-MM-dd'T'HH:mm:ss.SSSZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss,SSSZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss.SSS</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss,SSS</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ssZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm:ss</str>\n+      <str>yyyy-MM-dd'T'HH:mmZ</str>\n+      <str>yyyy-MM-dd'T'HH:mm</str>\n+      <str>yyyy-MM-dd HH:mm:ss.SSSZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss,SSSZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss.SSS</str>\n+      <str>yyyy-MM-dd HH:mm:ss,SSS</str>\n+      <str>yyyy-MM-dd HH:mm:ssZ</str>\n+      <str>yyyy-MM-dd HH:mm:ss</str>\n+      <str>yyyy-MM-dd HH:mmZ</str>\n+      <str>yyyy-MM-dd HH:mm</str>\n+      <str>yyyy-MM-dd</str>\n+    </arr>\n+  </updateProcessor>\n+\n+  <!-- The update.autoCreateFields property can be turned to false to disable schemaless mode -->\n+  <updateRequestProcessorChain name=\"add-unknown-fields-to-the-schema\" default=\"${update.autoCreateFields:true}\"\n+                               processor=\"uuid,remove-blank,field-name-mutating,parse-boolean,parse-long,parse-double,parse-date\">\n+    <processor class=\"solr.LogUpdateProcessorFactory\"/>\n+    <processor class=\"solr.DistributedUpdateProcessorFactory\"/>\n+    <processor class=\"solr.RunUpdateProcessorFactory\"/>\n+  </updateRequestProcessorChain>\n+\n+  <!-- Deduplication\n+\n+       An example dedup update processor that creates the \"id\" field\n+       on the fly based on the hash code of some other fields.  This\n+       example has overwriteDupes set to false since we are using the\n+       id field as the signatureField and Solr will maintain\n+       uniqueness based on that anyway.\n+\n+    -->\n+  <!--\n+     <updateRequestProcessorChain name=\"dedupe\">\n+       <processor class=\"solr.processor.SignatureUpdateProcessorFactory\">\n+         <bool name=\"enabled\">true</bool>\n+         <str name=\"signatureField\">id</str>\n+         <bool name=\"overwriteDupes\">false</bool>\n+         <str name=\"fields\">name,features,cat</str>\n+         <str name=\"signatureClass\">solr.processor.Lookup3Signature</str>\n+       </processor>\n+       <processor class=\"solr.LogUpdateProcessorFactory\" />\n+       <processor class=\"solr.RunUpdateProcessorFactory\" />\n+     </updateRequestProcessorChain>\n+    -->\n+\n+  <!-- Language identification\n+\n+       This example update chain identifies the language of the incoming\n+       documents using the langid contrib. The detected language is\n+       written to field language_s. No field name mapping is done.\n+       The fields used for detection are text, title, subject and description,\n+       making this example suitable for detecting languages form full-text\n+       rich documents injected via ExtractingRequestHandler.\n+       See more about langId at http://wiki.apache.org/solr/LanguageDetection\n+    -->\n+  <!--\n+  <updateRequestProcessorChain name=\"langid\">\n+    <processor class=\"org.apache.solr.update.processor.TikaLanguageIdentifierUpdateProcessorFactory\">\n+      <str name=\"langid.fl\">_text_,title_txt,description_txt</str>\n+      <str name=\"langid.langField\">language_detected</str>\n+      <str name=\"langid.fallback\">en</str>\n+    </processor>\n+    <processor class=\"solr.LogUpdateProcessorFactory\" />\n+    <processor class=\"solr.RunUpdateProcessorFactory\" />\n+  </updateRequestProcessorChain>\n+  -->\n+  <!-- Script update processor\n+\n+    This example hooks in an update processor implemented using JavaScript.\n+\n+    See more about the script update processor at http://wiki.apache.org/solr/ScriptUpdateProcessor\n+  -->\n+  <!--\n+    <updateRequestProcessorChain name=\"script\">\n+      <processor class=\"solr.StatelessScriptUpdateProcessorFactory\">\n+        <str name=\"script\">update-script.js</str>\n+        <lst name=\"params\">\n+          <str name=\"config_param\">example config parameter</str>\n+        </lst>\n+      </processor>\n+      <processor class=\"solr.RunUpdateProcessorFactory\" />\n+    </updateRequestProcessorChain>\n+  -->\n+\n+  <!-- Response Writers\n+\n+       http://wiki.apache.org/solr/QueryResponseWriter\n+\n+       Request responses will be written using the writer specified by\n+       the 'wt' request parameter matching the name of a registered\n+       writer.\n+\n+       The \"default\" writer is the default and will be used if 'wt' is\n+       not specified in the request.\n+    -->\n+  <!-- The following response writers are implicitly configured unless\n+       overridden...\n+    -->\n+  <!--\n+     <queryResponseWriter name=\"xml\"\n+                          default=\"true\"\n+                          class=\"solr.XMLResponseWriter\" />\n+     <queryResponseWriter name=\"json\" class=\"solr.JSONResponseWriter\"/>\n+     <queryResponseWriter name=\"python\" class=\"solr.PythonResponseWriter\"/>\n+     <queryResponseWriter name=\"ruby\" class=\"solr.RubyResponseWriter\"/>\n+     <queryResponseWriter name=\"php\" class=\"solr.PHPResponseWriter\"/>\n+     <queryResponseWriter name=\"phps\" class=\"solr.PHPSerializedResponseWriter\"/>\n+     <queryResponseWriter name=\"csv\" class=\"solr.CSVResponseWriter\"/>\n+     <queryResponseWriter name=\"schema.xml\" class=\"solr.SchemaXmlResponseWriter\"/>\n+    -->\n+\n+  <queryResponseWriter name=\"json\" class=\"solr.JSONResponseWriter\">\n+    <!-- For the purposes of the tutorial, JSON responses are written as\n+     plain text so that they are easy to read in *any* browser.\n+     If you expect a MIME type of \"application/json\" just remove this override.\n+    -->\n+    <str name=\"content-type\">text/plain; charset=UTF-8</str>\n+  </queryResponseWriter>\n+\n+  <!--\n+     Custom response writers can be declared as needed...\n+    -->\n+  <queryResponseWriter name=\"velocity\" class=\"solr.VelocityResponseWriter\" startup=\"lazy\">\n+    <str name=\"template.base.dir\">${velocity.template.base.dir:}</str>\n+    <str name=\"solr.resource.loader.enabled\">${velocity.solr.resource.loader.enabled:true}</str>\n+    <str name=\"params.resource.loader.enabled\">${velocity.params.resource.loader.enabled:false}</str>\n+  </queryResponseWriter>\n+\n+  <!-- XSLT response writer transforms the XML output by any xslt file found\n+       in Solr's conf/xslt directory.  Changes to xslt files are checked for\n+       every xsltCacheLifetimeSeconds.\n+    -->\n+  <queryResponseWriter name=\"xslt\" class=\"solr.XSLTResponseWriter\">\n+    <int name=\"xsltCacheLifetimeSeconds\">5</int>\n+  </queryResponseWriter>\n+\n+  <!-- Query Parsers\n+\n+       https://lucene.apache.org/solr/guide/query-syntax-and-parsing.html\n+\n+       Multiple QParserPlugins can be registered by name, and then\n+       used in either the \"defType\" param for the QueryComponent (used\n+       by SearchHandler) or in LocalParams\n+    -->\n+  <!-- example of registering a query parser -->\n+  <!--\n+     <queryParser name=\"myparser\" class=\"com.mycompany.MyQParserPlugin\"/>\n+    -->\n+\n+  <!-- Function Parsers\n+\n+       http://wiki.apache.org/solr/FunctionQuery\n+\n+       Multiple ValueSourceParsers can be registered by name, and then\n+       used as function names when using the \"func\" QParser.\n+    -->\n+  <!-- example of registering a custom function parser  -->\n+  <!--\n+     <valueSourceParser name=\"myfunc\"\n+                        class=\"com.mycompany.MyValueSourceParser\" />\n+    -->\n+\n+\n+  <!-- Document Transformers\n+       http://wiki.apache.org/solr/DocTransformers\n+    -->\n+  <!--\n+     Could be something like:\n+     <transformer name=\"db\" class=\"com.mycompany.LoadFromDatabaseTransformer\" >\n+       <int name=\"connection\">jdbc://....</int>\n+     </transformer>\n+\n+     To add a constant value to all docs, use:\n+     <transformer name=\"mytrans2\" class=\"org.apache.solr.response.transform.ValueAugmenterFactory\" >\n+       <int name=\"value\">5</int>\n+     </transformer>\n+\n+     If you want the user to still be able to change it with _value:something_ use this:\n+     <transformer name=\"mytrans3\" class=\"org.apache.solr.response.transform.ValueAugmenterFactory\" >\n+       <double name=\"defaultValue\">5</double>\n+     </transformer>\n+\n+      If you are using the QueryElevationComponent, you may wish to mark documents that get boosted.  The\n+      EditorialMarkerFactory will do exactly that:\n+     <transformer name=\"qecBooster\" class=\"org.apache.solr.response.transform.EditorialMarkerFactory\" />\n+    -->\n+\n+\n+  <!-- Placename Suggestion Component\n+\n+  This component can return a list of auto-complete suggestions\n+  when entering placenames.\n+  -->\n+  <searchComponent name=\"suggest\" class=\"solr.SuggestComponent\">\n+    <lst name=\"suggester\">\n+      <str name=\"name\">suggestPlace</str>\n+      <str name=\"lookupImpl\">BlendedInfixLookupFactory</str>\n+      <str name=\"indexPath\">place_suggest_index</str>\n+      <str name=\"dictionaryImpl\">DocumentDictionaryFactory</str>\n+      <str name=\"suggestAnalyzerFieldType\">lowercase</str>\n+      <str name=\"field\">title_txt</str>\n+      <!-- Only real change is here, changing highlight to false -->\n+      <str name=\"highlight\">false</str>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5NTAwNw=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 1289}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI5OTMxNg==", "bodyText": "I like the 42 and 1337 but I cannot figure out if this intersection in Natalia, TX is suppose to be significant.  \ud83e\udd14", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449299316", "createdAt": "2020-07-02T22:51:42Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,379 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import org.locationtech.jts.io.WKTReader\n+import spock.lang.Specification\n+\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+\n+    void setup() {\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                                get(\"location_geo\") >> [\"POINT (-98.86253 29.18968)\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMwMDM5Mg==", "bodyText": "One idea that is slightly more coupled but it could be clearer is to just see if the query string equals an expected query string.  It would be easy to update if someone changed the formatting and you would be able to remove all parsing code.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449300392", "createdAt": "2020-07-02T22:55:52Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,344 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import org.locationtech.jts.io.WKTReader\n+import spock.lang.Specification\n+\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+\n+    void setup() {\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        results.size() == 1\n+        results.first().with {\n+            name == \"title\"\n+            population == 1337\n+        }\n+\n+    }\n+\n+    def \"Test query max results\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.\n+                query(*_) >> {\n+            SolrQuery params, SolrRequest.METHOD method ->\n+                assert params.getRows() == GazetteerQueryOfflineSolr.MAX_RESULTS\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> { Stream.empty() }\n+                    }\n+                }\n+        }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        notThrown(Exception)\n+\n+    }\n+\n+    def \"Test query solrclient exception\"() {\n+        setup:\n+        int numResults = 101\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test queryById normal\"() {\n+        setup:\n+        1 * solrClient.query(*_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                            })\n+                        }\n+                    }\n+                }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        result.name == \"title\"\n+    }\n+\n+    def \"test queryById exception\"() {\n+        setup:\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"solr exception\") }\n+        when:\n+        GeoEntry result = testedClass.queryById(\"test\")\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"test getSuggestedNames normal\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${maxResults}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames maxResults\"() {\n+        setup:\n+        int maxResults = 101\n+        1 * solrClient.query(*_) >> { SolrQuery query ->\n+            assert query.get(\"suggest.count\") == \"${GazetteerQueryOfflineSolr.MAX_RESULTS}\"\n+            assert query.requestHandler == \"/suggest\"\n+            Mock(QueryResponse) {\n+                getSuggesterResponse() >> Mock(SuggesterResponse) {\n+                    getSuggestions() >>\n+                            [(GazetteerQueryOfflineSolr.SUGGEST_PLACE_KEY): [Mock(Suggestion) {\n+                                getPayload() >> \"id\"\n+                                getTerm() >> \"title\"\n+\n+                            }]]\n+                }\n+            }\n+        }\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        results.size() == 1\n+    }\n+\n+    def \"test getSuggestedNames solrclient exception\"() {\n+        setup:\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { throw new SolrServerException(\"exception\") }\n+\n+        when:\n+        List<Suggestion> results = testedClass.getSuggestedNames(\"place\", maxResults)\n+\n+        then:\n+        GeoEntryQueryException e = thrown()\n+    }\n+\n+    def \"getNearestCities\"() {\n+        setup:\n+        String locationWkt = \"POINT (-98.86253 29.18968)\"\n+        String pointAbout42kmAway = \"POINT (-98.496708 29.418376)\"\n+        int radiusInKm = 50\n+        int maxResults = 10\n+        1 * solrClient.query(*_) >> { SolrQuery query, METHOD method ->\n+            assert METHOD.POST == method\n+\n+\n+            // TODO (RCZ) - I really don't like extracting the polygon from the solr query. its\n+            // risky logic and closely coupling to the implementation. But I also don't want to\n+            // open access and have a @VisibleForTesting..", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTAyNw=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMwMzA1NQ==", "bodyText": "I think this got inlined into Solrj.  Looks like I forgot to export it from solr-dependencies since most places were excluding it like this.\nhttps://github.com/apache/lucene-solr/blob/62f969403ae445910b580079d40f6abf714705aa/solr/solrj/src/java/org/noggit/package-info.java", "url": "https://github.com/codice/ddf/pull/6153#discussion_r449303055", "createdAt": "2020-07-02T23:06:17Z", "author": {"login": "pklinef"}, "path": "catalog/spatial/geocoding/spatial-geocoding-offline-index/pom.xml", "diffHunk": "@@ -116,6 +116,7 @@\n                         </Embed-Dependency>\n                         <Import-Package>\n                             !com.fasterxml.jackson*,\n+                            !org.noggit,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4NTk2NA=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0MjcxODQw", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-444271840", "createdAt": "2020-07-07T21:44:14Z", "commit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "state": "COMMENTED", "comments": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QyMTo0NDoxNFrOGuQtIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQwMjo0OTowM1rOGuWMkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTE2MTM3OQ==", "bodyText": "I appreciate the little things \ud83d\udcaf", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451161379", "createdAt": "2020-07-07T21:44:14Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/pom.xml", "diffHunk": "@@ -0,0 +1,180 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/\n+\n+ -->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+\n+    <parent>\n+        <groupId>ddf.catalog.solr</groupId>\n+        <artifactId>catalog-solr</artifactId>\n+        <version>2.25.0-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>catalog-solr-offline-gazetteer</artifactId>\n+    <version>2.25.0-SNAPSHOT</version>\n+    <packaging>bundle</packaging>\n+    <name>DDF :: Catalog :: Solr :: Offline Gazetteer</name>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>ddf.catalog.core</groupId>\n+            <artifactId>catalog-core-api</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>ddf.security.core</groupId>\n+            <artifactId>security-core-api</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>ddf.catalog.core</groupId>\n+            <artifactId>catalog-core-api-impl</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.codice.ddf.spatial</groupId>\n+            <artifactId>spatial-geocoding-api</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>ddf.platform.solr</groupId>\n+            <artifactId>solr-factory</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>ddf.platform.util</groupId>\n+            <artifactId>platform-util</artifactId>\n+            <version>${project.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.solr</groupId>\n+            <artifactId>solr-solrj</artifactId>\n+            <version>${solr.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.locationtech.jts</groupId>\n+            <artifactId>jts-core</artifactId>\n+            <version>${jts.spatial4j.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.karaf.shell</groupId>\n+            <artifactId>org.apache.karaf.shell.console</artifactId>\n+            <version>${karaf.version}</version>\n+        </dependency>\n+      <dependency>\n+        <groupId>com.google.guava</groupId>\n+        <artifactId>guava</artifactId>\n+      </dependency>\n+      <dependency>\n+        <groupId>net.jodah</groupId>\n+        <artifactId>failsafe</artifactId>\n+        <version>${jodah-failsafe.version}</version>\n+      </dependency>\n+\n+      <!-- no-op slf4j impl so the tests expected exceptions don't puke to the logs -->\n+      <dependency>\n+        <groupId>org.slf4j</groupId>\n+        <artifactId>slf4j-nop</artifactId>\n+        <scope>test</scope>\n+      </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTE2Nzc1OQ==", "bodyText": "\u270f\ufe0f  Are these all expected to be used as keys? If so, why is SUGGEST_PLACE the only one suffixed as such?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451167759", "createdAt": "2020-07-07T21:58:37Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxMDE0MA==", "bodyText": "\u270f\ufe0f  I agree it's not worth making a constants class for these, but I would add a line comment briefly describing why the values are useful to share within this module. Something along the lines that the same calculations made here need to occur in the plugin as well.\nAlternatively, if they are similar enough, I would extract the operations into a new class and move these constants there, and make them private.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451210140", "createdAt": "2020-07-08T00:06:06Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxNDY3OQ==", "bodyText": "\u2757 final - I didn't see this getting reassigned anywhere.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451214679", "createdAt": "2020-07-08T00:23:49Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxNDY5Ng==", "bodyText": "\u2757 final - I didn't see this getting reassigned anywhere.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451214696", "createdAt": "2020-07-08T00:23:54Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxNzkyNw==", "bodyText": "\u2753 Can we use a method reference instead? There's a lot going on here. I think the following would be cleaner:\nexecutor.submit(this::pingSuggester);\n\nAlso there seems to be some room for more idiomatic Java IMHO:\nRetryPolicy retryPolicy = defaultRetryPolicy();\nSolrPingResponse ping = Failsafe.with(retryPolicy).onFailure(this:handleInitialError).get(() -> client.ping());\n...", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451217927", "createdAt": "2020-07-08T00:36:47Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxODI3NQ==", "bodyText": "\u2753  If we need to refresh the bundle anyway in order to fix this issue, shouldn't we just let the exception propagate instead of logging manually? Let blueprint log it for us. The constructor would have to declare it throws the exception.\nIf we don't need to refresh the bundle and can gracefully recover from this, do we have a way to invoke this initialization code a subsequent time? Will it auto retry like the Solr client itself does?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451218275", "createdAt": "2020-07-08T00:38:08Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(\n+        () -> {\n+          RetryPolicy retryPolicy =\n+              new RetryPolicy()\n+                  .retryOn(Collections.singletonList(Exception.class))\n+                  .withMaxDuration(20, TimeUnit.SECONDS)\n+                  .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+          SolrPingResponse ping =\n+              Failsafe.with(retryPolicy)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxODU3Mg==", "bodyText": "\u2753  See above comment - are these exceptions worth propagating instead of handling here?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451218572", "createdAt": "2020-07-08T00:39:28Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(\n+        () -> {\n+          RetryPolicy retryPolicy =\n+              new RetryPolicy()\n+                  .retryOn(Collections.singletonList(Exception.class))\n+                  .withMaxDuration(20, TimeUnit.SECONDS)\n+                  .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+          SolrPingResponse ping =\n+              Failsafe.with(retryPolicy)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query, METHOD.POST);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyMjY2Mw==", "bodyText": "I think these are parts of the computation I mentioned earlier that you could extract into a separate class and test separately - then some constants needn't be public and shared anymore but the class that does the computation would just be injected instead.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451222663", "createdAt": "2020-07-08T00:55:21Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MDkxMQ=="}, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyMzY5Ng==", "bodyText": "Because of the .filter(Objects::nonNull) I agree with @pklinef otherwise yeah I see why you did this.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451223696", "createdAt": "2020-07-08T00:59:45Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,425 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private static final RetryPolicy RETRY_POLICY =\n+      new RetryPolicy()\n+          .withMaxDuration(20, TimeUnit.SECONDS)\n+          .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private ExecutorService executor = Executors.newSingleThreadExecutor();\n+\n+  public GazetteerQueryOfflineSolr(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    executor.submit(\n+        () -> {\n+          SolrPingResponse ping =\n+              Failsafe.with(RETRY_POLICY)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NTczOA=="}, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 250}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNTQ4OQ==", "bodyText": "\u2753 Am I seeing the cohesion correctly? Do the public constants, math calculations, and WKT operations all belong together in a separate thing?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451225489", "createdAt": "2020-07-08T01:06:34Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(\n+        () -> {\n+          RetryPolicy retryPolicy =\n+              new RetryPolicy()\n+                  .retryOn(Collections.singletonList(Exception.class))\n+                  .withMaxDuration(20, TimeUnit.SECONDS)\n+                  .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+          SolrPingResponse ping =\n+              Failsafe.with(retryPolicy)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query, METHOD.POST);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))\n+            .orElse(\"NO TITLE\");\n+\n+    String cardinalDirection = \"\";\n+    double distance = 0;\n+    try {\n+      Geometry geo = WKT_READER_THREAD_LOCAL.get().read(location);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzEyMA==", "bodyText": "\u2753 Should we TRACE log the original Solr document and the result of geoEntryBuilder.build(), assuming they both toString() correctly?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451227120", "createdAt": "2020-07-08T01:13:13Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(\n+        () -> {\n+          RetryPolicy retryPolicy =\n+              new RetryPolicy()\n+                  .retryOn(Collections.singletonList(Exception.class))\n+                  .withMaxDuration(20, TimeUnit.SECONDS)\n+                  .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+          SolrPingResponse ping =\n+              Failsafe.with(retryPolicy)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query, METHOD.POST);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))\n+            .orElse(\"NO TITLE\");\n+\n+    String cardinalDirection = \"\";\n+    double distance = 0;\n+    try {\n+      Geometry geo = WKT_READER_THREAD_LOCAL.get().read(location);\n+      cardinalDirection =\n+          bearingToCardinalDirection(getBearing(originalLocation.getCentroid(), geo.getCentroid()));\n+      // convert distance to KM\n+      distance = originalLocation.distance(geo.getCentroid()) * KM_PER_DEGREE;\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      LOGGER.debug(\"Could not parse location for item (object: {})\", doc.toString(), e);\n+    }\n+\n+    return new NearbyLocationImpl(title, cardinalDirection, distance);\n+  }\n+\n+  public static class NearbyLocationImpl implements NearbyLocation {\n+    private final String name;\n+    private final String cardinalDirection;\n+    private final double distance;\n+\n+    public NearbyLocationImpl(String name, String cardinalDirection, double distance) {\n+      this.name = name;\n+      this.cardinalDirection = cardinalDirection;\n+      this.distance = distance;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+\n+    @Override\n+    public String getCardinalDirection() {\n+      return cardinalDirection;\n+    }\n+\n+    @Override\n+    public double getDistance() {\n+      return distance;\n+    }\n+  }\n+  /**\n+   * Calculates the bearing from the start point to the end point (i.e., the <em>initial bearing\n+   * </em>) in degrees.\n+   *\n+   * @param startPoint the point from which to start\n+   * @param endPoint the point at which to end\n+   * @return the bearing from {@code startPoint} to {@code endPoint}, in degrees\n+   */\n+  private static double getBearing(final Point startPoint, final Point endPoint) {\n+    final double lat1 = startPoint.getY();\n+    final double lon1 = startPoint.getX();\n+\n+    final double lat2 = endPoint.getY();\n+    final double lon2 = endPoint.getX();\n+\n+    final double lonDiffRads = Math.toRadians(lon2 - lon1);\n+    final double lat1Rads = Math.toRadians(lat1);\n+    final double lat2Rads = Math.toRadians(lat2);\n+    final double y = Math.sin(lonDiffRads) * Math.cos(lat2Rads);\n+    final double x =\n+        Math.cos(lat1Rads) * Math.sin(lat2Rads)\n+            - Math.sin(lat1Rads) * Math.cos(lat2Rads) * Math.cos(lonDiffRads);\n+\n+    return (Math.toDegrees(Math.atan2(y, x)) + 360) % 360;\n+  }\n+\n+  /**\n+   * Takes a bearing in degrees and returns the corresponding cardinal direction as a string.\n+   *\n+   * @param bearing the bearing, in degrees\n+   * @return the cardinal direction corresponding to {@code bearing} (N, NE, E, SE, S, SW, W, NW)\n+   */\n+  private static String bearingToCardinalDirection(final double bearing) {\n+    final String[] directions = {\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\", \"N\"};\n+    return directions[(int) Math.round(bearing / 45)];\n+  }\n+\n+  @Override\n+  public Optional<String> getCountryCode(String wktLocation, int radius)\n+      throws GeoEntryQueryException, ParseException {\n+    String wkt;\n+    try {\n+      Point center = WKT_READER_THREAD_LOCAL.get().read(wktLocation).getCentroid();\n+      wkt = WKT_WRITER_THREAD_LOCAL.get().write(center.buffer(radius / KM_PER_DEGREE));\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      LOGGER.debug(\"Could not parse wkt: {}\", wktLocation, e);\n+      throw new GeoEntryQueryException(\"Could not parse wkt\", e);\n+    }\n+\n+    SolrQuery solrQuery =\n+        new SolrQuery(\n+            String.format(\n+                \"location_geo_index:\\\"Intersects( %s )\\\"\", ClientUtils.escapeQueryChars(wkt)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Could not query for country code ({})\", wktLocation, e);\n+      throw new GeoEntryQueryException(\"Error encountered when querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .findFirst()\n+        .map(doc -> getField(doc, Location.COUNTRY_CODE + \"_txt\", String.class));\n+  }\n+\n+  private GeoEntry transformMetacardToGeoEntry(SolrDocument document) {\n+    GeoEntry.Builder geoEntryBuilder = new GeoEntry.Builder();\n+    String featureCode =\n+        getField(document, GeoEntryAttributes.FEATURE_CODE_ATTRIBUTE_NAME + \"_txt\", String.class);\n+\n+    if (StringUtils.isNotBlank(featureCode)) {\n+      geoEntryBuilder.featureCode(featureCode);\n+    }\n+\n+    String countryCode = getField(document, Location.COUNTRY_CODE + \"_txt\", String.class);\n+    if (StringUtils.isNotBlank(countryCode)) {\n+      geoEntryBuilder.countryCode(countryCode);\n+    }\n+\n+    String name = getField(document, Core.TITLE + \"_txt\", String.class);\n+    if (StringUtils.isNotBlank(name)) {\n+      geoEntryBuilder.name(name);\n+    }\n+\n+    Long population =\n+        getField(document, GeoEntryAttributes.POPULATION_ATTRIBUTE_NAME + \"_lng\", Long.class);\n+    if (population != null) {\n+      geoEntryBuilder.population(population);\n+    }\n+\n+    Integer sortValue =\n+        getField(document, GeoEntryAttributes.GAZETTEER_SORT_VALUE + \"_int\", Integer.class);\n+    if (sortValue != null) {\n+      geoEntryBuilder.gazetteerSort(sortValue);\n+    }\n+\n+    String location = getField(document, Core.LOCATION + \"_geo\", String.class);\n+    if (StringUtils.isNotBlank(location)) {\n+      try {\n+        Geometry geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+        Point coordinate = geometry.getCentroid();\n+        if (!coordinate.isEmpty()) {\n+          Double lat = coordinate.getY();\n+          Double lon = coordinate.getX();\n+          geoEntryBuilder.latitude(lat);\n+          geoEntryBuilder.longitude(lon);\n+        }\n+      } catch (org.locationtech.jts.io.ParseException e) {\n+        LOGGER.debug(\"GeoEntry metacard does not contain (readable) location attribute.\");\n+      }\n+    }\n+    return geoEntryBuilder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 411}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyNzUwMQ==", "bodyText": "\u2753 Is it a valid assumption that all attributes will be multi-valued?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451227501", "createdAt": "2020-07-08T01:14:54Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;\n+\n+  private SolrClient client;\n+\n+  private final ExecutorService executor;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+    this.clientFactory = clientFactory;\n+    this.client = clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+    this.executor = startupBuilderExecutor;\n+    executor.submit(\n+        () -> {\n+          RetryPolicy retryPolicy =\n+              new RetryPolicy()\n+                  .retryOn(Collections.singletonList(Exception.class))\n+                  .withMaxDuration(20, TimeUnit.SECONDS)\n+                  .withBackoff(100, 1_000, TimeUnit.MILLISECONDS);\n+          SolrPingResponse ping =\n+              Failsafe.with(retryPolicy)\n+                  .onFailure(\n+                      e ->\n+                          LOGGER.error(\n+                              \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                              OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                              e))\n+                  .get(() -> client.ping());\n+          SolrQuery query = new SolrQuery();\n+          query.setRequestHandler(\"/suggest\");\n+          query.setParam(\"suggest.build\", true);\n+          query.setParam(\"suggest.q\", \"GQOSInitialSuggesterBuild\");\n+          query.setParam(\"suggest.dictionary\", \"suggestPlace\");\n+          try {\n+            QueryResponse response = client.query(query, METHOD.POST);\n+            LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+          } catch (SolrServerException | IOException e) {\n+            LOGGER.error(\n+                \"Error while trying to build initial suggester for {}\",\n+                OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME,\n+                e);\n+          }\n+        });\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_PLACE_KEY);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Something went wrong when querying\", e);\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_PLACE_KEY))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  public static class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    // conver km to rough degree measurement, approximately 111km per degree\n+    double distanceInDegrees = radiusInKm / KM_PER_DEGREE;\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(distanceInDegrees, 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error executing query for nearest cities\", e);\n+      throw new GeoEntryQueryException(\"Error executing query\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !\"\".equals(s))\n+            .orElse(\"NO TITLE\");\n+\n+    String cardinalDirection = \"\";\n+    double distance = 0;\n+    try {\n+      Geometry geo = WKT_READER_THREAD_LOCAL.get().read(location);\n+      cardinalDirection =\n+          bearingToCardinalDirection(getBearing(originalLocation.getCentroid(), geo.getCentroid()));\n+      // convert distance to KM\n+      distance = originalLocation.distance(geo.getCentroid()) * KM_PER_DEGREE;\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      LOGGER.debug(\"Could not parse location for item (object: {})\", doc.toString(), e);\n+    }\n+\n+    return new NearbyLocationImpl(title, cardinalDirection, distance);\n+  }\n+\n+  public static class NearbyLocationImpl implements NearbyLocation {\n+    private final String name;\n+    private final String cardinalDirection;\n+    private final double distance;\n+\n+    public NearbyLocationImpl(String name, String cardinalDirection, double distance) {\n+      this.name = name;\n+      this.cardinalDirection = cardinalDirection;\n+      this.distance = distance;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+\n+    @Override\n+    public String getCardinalDirection() {\n+      return cardinalDirection;\n+    }\n+\n+    @Override\n+    public double getDistance() {\n+      return distance;\n+    }\n+  }\n+  /**\n+   * Calculates the bearing from the start point to the end point (i.e., the <em>initial bearing\n+   * </em>) in degrees.\n+   *\n+   * @param startPoint the point from which to start\n+   * @param endPoint the point at which to end\n+   * @return the bearing from {@code startPoint} to {@code endPoint}, in degrees\n+   */\n+  private static double getBearing(final Point startPoint, final Point endPoint) {\n+    final double lat1 = startPoint.getY();\n+    final double lon1 = startPoint.getX();\n+\n+    final double lat2 = endPoint.getY();\n+    final double lon2 = endPoint.getX();\n+\n+    final double lonDiffRads = Math.toRadians(lon2 - lon1);\n+    final double lat1Rads = Math.toRadians(lat1);\n+    final double lat2Rads = Math.toRadians(lat2);\n+    final double y = Math.sin(lonDiffRads) * Math.cos(lat2Rads);\n+    final double x =\n+        Math.cos(lat1Rads) * Math.sin(lat2Rads)\n+            - Math.sin(lat1Rads) * Math.cos(lat2Rads) * Math.cos(lonDiffRads);\n+\n+    return (Math.toDegrees(Math.atan2(y, x)) + 360) % 360;\n+  }\n+\n+  /**\n+   * Takes a bearing in degrees and returns the corresponding cardinal direction as a string.\n+   *\n+   * @param bearing the bearing, in degrees\n+   * @return the cardinal direction corresponding to {@code bearing} (N, NE, E, SE, S, SW, W, NW)\n+   */\n+  private static String bearingToCardinalDirection(final double bearing) {\n+    final String[] directions = {\"N\", \"NE\", \"E\", \"SE\", \"S\", \"SW\", \"W\", \"NW\", \"N\"};\n+    return directions[(int) Math.round(bearing / 45)];\n+  }\n+\n+  @Override\n+  public Optional<String> getCountryCode(String wktLocation, int radius)\n+      throws GeoEntryQueryException, ParseException {\n+    String wkt;\n+    try {\n+      Point center = WKT_READER_THREAD_LOCAL.get().read(wktLocation).getCentroid();\n+      wkt = WKT_WRITER_THREAD_LOCAL.get().write(center.buffer(radius / KM_PER_DEGREE));\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      LOGGER.debug(\"Could not parse wkt: {}\", wktLocation, e);\n+      throw new GeoEntryQueryException(\"Could not parse wkt\", e);\n+    }\n+\n+    SolrQuery solrQuery =\n+        new SolrQuery(\n+            String.format(\n+                \"location_geo_index:\\\"Intersects( %s )\\\"\", ClientUtils.escapeQueryChars(wkt)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Could not query for country code ({})\", wktLocation, e);\n+      throw new GeoEntryQueryException(\"Error encountered when querying\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .findFirst()\n+        .map(doc -> getField(doc, Location.COUNTRY_CODE + \"_txt\", String.class));\n+  }\n+\n+  private GeoEntry transformMetacardToGeoEntry(SolrDocument document) {\n+    GeoEntry.Builder geoEntryBuilder = new GeoEntry.Builder();\n+    String featureCode =\n+        getField(document, GeoEntryAttributes.FEATURE_CODE_ATTRIBUTE_NAME + \"_txt\", String.class);\n+\n+    if (StringUtils.isNotBlank(featureCode)) {\n+      geoEntryBuilder.featureCode(featureCode);\n+    }\n+\n+    String countryCode = getField(document, Location.COUNTRY_CODE + \"_txt\", String.class);\n+    if (StringUtils.isNotBlank(countryCode)) {\n+      geoEntryBuilder.countryCode(countryCode);\n+    }\n+\n+    String name = getField(document, Core.TITLE + \"_txt\", String.class);\n+    if (StringUtils.isNotBlank(name)) {\n+      geoEntryBuilder.name(name);\n+    }\n+\n+    Long population =\n+        getField(document, GeoEntryAttributes.POPULATION_ATTRIBUTE_NAME + \"_lng\", Long.class);\n+    if (population != null) {\n+      geoEntryBuilder.population(population);\n+    }\n+\n+    Integer sortValue =\n+        getField(document, GeoEntryAttributes.GAZETTEER_SORT_VALUE + \"_int\", Integer.class);\n+    if (sortValue != null) {\n+      geoEntryBuilder.gazetteerSort(sortValue);\n+    }\n+\n+    String location = getField(document, Core.LOCATION + \"_geo\", String.class);\n+    if (StringUtils.isNotBlank(location)) {\n+      try {\n+        Geometry geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+        Point coordinate = geometry.getCentroid();\n+        if (!coordinate.isEmpty()) {\n+          Double lat = coordinate.getY();\n+          Double lon = coordinate.getX();\n+          geoEntryBuilder.latitude(lat);\n+          geoEntryBuilder.longitude(lon);\n+        }\n+      } catch (org.locationtech.jts.io.ParseException e) {\n+        LOGGER.debug(\"GeoEntry metacard does not contain (readable) location attribute.\");\n+      }\n+    }\n+    return geoEntryBuilder.build();\n+  }\n+\n+  private <T> T getField(SolrDocument document, String attribute, Class<T> clazz) {\n+    return Optional.of(document)\n+        .map(d -> d.get(attribute))\n+        .filter(List.class::isInstance)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 417}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIyOTU5Ng==", "bodyText": "\u270f\ufe0f  Why is this public and why does it live in the plugin and not in the solr object? If you have public static constants in both classes then I would reconsider and pull them out into a constants class (or some other local abstraction).", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451229596", "createdAt": "2020-07-08T01:23:14Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzMDM5MA==", "bodyText": "\u2753 Is this done synchronously and if it's not how do we handle async failure since there are parallel paths where side effects occur? I'm referring to the persistence of the separate records in the separate cores in Solr.\nThis comment applies to all other calls to the Solr client in this class.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451230390", "createdAt": "2020-07-08T01:26:12Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzMTA5MA==", "bodyText": "\u2753 Will this overwrite existing records with the same ID or does it behave immutably? I ask because this is a catalog update.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451231090", "createdAt": "2020-07-08T01:29:00Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  @Override\n+  public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getUpdatedMetacards()\n+            .stream()\n+            .map(Update::getNewMetacard)\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzMjIyMA==", "bodyText": "\u2753 Using attribute and attr tells me nothing, how about attrName and attrVal instead?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451232220", "createdAt": "2020-07-08T01:33:24Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  @Override\n+  public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getUpdatedMetacards()\n+            .stream()\n+            .map(Update::getNewMetacard)\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+    return input;\n+  }\n+\n+  @Override\n+  public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n+    List<String> ids =\n+        input\n+            .getDeletedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .map(Metacard::getId)\n+            .collect(Collectors.toList());\n+    if (ids.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.deleteById(ids);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  protected static SolrInputDocument convert(Metacard metacard) {\n+    SolrInputDocument solrDoc = new SolrInputDocument();\n+    Consumer<String> getAttrAndAdd =\n+        (attribute) ->\n+            Optional.ofNullable(getStringAttribute(metacard, attribute))\n+                .ifPresent(attr -> solrDoc.addField(attribute + \"_txt\", attr));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzNDUzNw==", "bodyText": "\u2753 @pklinef Are you suggesting to just hardcode the catalog attribute strings locally? Isn't that still pseudo coupling? I'm not sure how else you could establish this mapping.\nUnless you're suggesting to operate on attributes in a more generic fashion instead of coding your control flow around specific ones. So iterating and mapping based off of metacard type and not specific attribute would insulate this logic from changes, I think.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451234537", "createdAt": "2020-07-08T01:42:25Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  @Override\n+  public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getUpdatedMetacards()\n+            .stream()\n+            .map(Update::getNewMetacard)\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+    return input;\n+  }\n+\n+  @Override\n+  public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n+    List<String> ids =\n+        input\n+            .getDeletedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .map(Metacard::getId)\n+            .collect(Collectors.toList());\n+    if (ids.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.deleteById(ids);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  protected static SolrInputDocument convert(Metacard metacard) {\n+    SolrInputDocument solrDoc = new SolrInputDocument();\n+    Consumer<String> getAttrAndAdd =\n+        (attribute) ->\n+            Optional.ofNullable(getStringAttribute(metacard, attribute))\n+                .ifPresent(attr -> solrDoc.addField(attribute + \"_txt\", attr));\n+\n+    getAttrAndAdd.accept(Metacard.DESCRIPTION);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE0MTgwNA=="}, "originalCommit": {"oid": "88f357102c5f89f5b129ad7e7cdb633387426b7e"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzNDc3MA==", "bodyText": "\u270f\ufe0f  Let's annotate with @Nullable", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451234770", "createdAt": "2020-07-08T01:43:21Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";\n+\n+  private final SolrClientFactory clientFactory;\n+  private final SolrClient solrClient;\n+\n+  public OfflineGazetteerPlugin(SolrClientFactory clientFactory) {\n+    this.clientFactory = clientFactory;\n+    this.solrClient = clientFactory.newClient(STANDALONE_GAZETTEER_CORE_NAME);\n+  }\n+\n+  @Override\n+  public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getCreatedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  @Override\n+  public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n+    List<Metacard> gazetteerMetacards =\n+        input\n+            .getUpdatedMetacards()\n+            .stream()\n+            .map(Update::getNewMetacard)\n+            .filter(this::isGazetteerMetacard)\n+            .collect(Collectors.toList());\n+\n+    if (gazetteerMetacards.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.add(\n+          STANDALONE_GAZETTEER_CORE_NAME,\n+          gazetteerMetacards\n+              .stream()\n+              .map(OfflineGazetteerPlugin::convert)\n+              .collect(Collectors.toList()));\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+    return input;\n+  }\n+\n+  @Override\n+  public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n+    List<String> ids =\n+        input\n+            .getDeletedMetacards()\n+            .stream()\n+            .filter(this::isGazetteerMetacard)\n+            .map(Metacard::getId)\n+            .collect(Collectors.toList());\n+    if (ids.isEmpty()) {\n+      return input;\n+    }\n+\n+    try {\n+      solrClient.deleteById(ids);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.debug(\"Error while processing gazetteer data\", e);\n+      throw new PluginExecutionException(e);\n+    }\n+\n+    return input;\n+  }\n+\n+  protected static SolrInputDocument convert(Metacard metacard) {\n+    SolrInputDocument solrDoc = new SolrInputDocument();\n+    Consumer<String> getAttrAndAdd =\n+        (attribute) ->\n+            Optional.ofNullable(getStringAttribute(metacard, attribute))\n+                .ifPresent(attr -> solrDoc.addField(attribute + \"_txt\", attr));\n+\n+    getAttrAndAdd.accept(Metacard.DESCRIPTION);\n+    getAttrAndAdd.accept(GeoEntryAttributes.FEATURE_CODE_ATTRIBUTE_NAME);\n+    getAttrAndAdd.accept(Core.TITLE);\n+    getAttrAndAdd.accept(Core.ID);\n+    getAttrAndAdd.accept(Location.COUNTRY_CODE);\n+\n+    Optional.of(metacard)\n+        .map(m -> getStringAttribute(m, Core.LOCATION))\n+        .ifPresent(v -> solrDoc.addField(Core.LOCATION + \"_geo\", v));\n+\n+    Optional.of(metacard)\n+        .map(m -> m.getAttribute(GeoEntryAttributes.POPULATION_ATTRIBUTE_NAME))\n+        .map(Attribute::getValue)\n+        .filter(Long.class::isInstance)\n+        .map(Long.class::cast)\n+        .ifPresent(v -> solrDoc.addField(GeoEntryAttributes.POPULATION_ATTRIBUTE_NAME + \"_lng\", v));\n+\n+    Optional.of(metacard)\n+        .map(m -> m.getAttribute(GeoEntryAttributes.GAZETTEER_SORT_VALUE))\n+        .map(Attribute::getValue)\n+        .filter(Integer.class::isInstance)\n+        .map(Integer.class::cast)\n+        .ifPresent(v -> solrDoc.addField(GeoEntryAttributes.GAZETTEER_SORT_VALUE + \"_int\", v));\n+\n+    return solrDoc;\n+  }\n+\n+  private static String getStringAttribute(Metacard metacard, String attributeName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzNzM5OA==", "bodyText": "Here's an alternative to save you the trouble.\nhttps://github.com/codice/ddf/blob/master/platform/solr/solr-factory/src/main/java/org/codice/solr/client/solrj/SolrClient.java#L118-L133", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451237398", "createdAt": "2020-07-08T01:53:47Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODEwMg=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzNzc1MQ==", "bodyText": "Another option for you in the event you prefer to manage things yourself, with Failsafe, to preserve more synchronous behavior.\nhttps://github.com/codice/ddf/blob/master/platform/solr/solr-factory/src/main/java/org/codice/solr/client/solrj/SolrClient.java#L65-L76", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451237751", "createdAt": "2020-07-08T01:55:06Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODEwMg=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzOTY5Ng==", "bodyText": "\u2753 I don't remember if Karaf supports constructor injection for commands. I think there are issues with it. I know we have tried to do it in the past but hit issues and had to resort to bundle context manipulation:\nhttps://github.com/codice/ddf-ui/blob/master/ui-backend/catalog-ui-search/src/main/java/org/codice/ddf/catalog/ui/forms/commands/SearchFormsManageCommand.java#L77\nhttps://github.com/codice/ddf-ui/blob/master/ui-backend/catalog-ui-search/src/main/java/org/codice/ddf/catalog/ui/forms/commands/SearchFormsLoaderCommand.java#L75\nThat being said do we need this setter?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451239696", "createdAt": "2020-07-08T02:02:29Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));\n+    } catch (Exception e) {\n+      LOGGER.info(\"Error while executing\", e);\n+      session.getConsole().println(\"Error while submitting remove all, exiting.\");\n+      throw e;\n+    }\n+    session.getConsole().println(\"Removeall submitted successfully.\");\n+    return null;\n+  }\n+\n+  public void setClientFactory(SolrClientFactory clientFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzOTkxMw==", "bodyText": "\u270f\ufe0f   wrong class - should be SyncCatalogCommand.class", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451239913", "createdAt": "2020-07-08T02:03:18Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/SyncCatalogCommand.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import ddf.catalog.CatalogFramework;\n+import ddf.catalog.data.Result;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.filter.FilterBuilder;\n+import ddf.catalog.filter.impl.SortByImpl;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.impl.QueryImpl;\n+import ddf.catalog.operation.impl.QueryRequestImpl;\n+import ddf.catalog.util.impl.ResultIterable;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.ddf.security.Security;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.opengis.filter.sort.SortOrder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"synccatalog\",\n+  description = \"Syncs all catalog items to the offline solr gazetteer core\"\n+)\n+public class SyncCatalogCommand implements Action {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MTUzMg==", "bodyText": "\ud83d\udc4d  Yes. Absolutely.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451241532", "createdAt": "2020-07-08T02:09:42Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/SyncCatalogCommand.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import ddf.catalog.CatalogFramework;\n+import ddf.catalog.data.Result;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.filter.FilterBuilder;\n+import ddf.catalog.filter.impl.SortByImpl;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.impl.QueryImpl;\n+import ddf.catalog.operation.impl.QueryRequestImpl;\n+import ddf.catalog.util.impl.ResultIterable;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.ddf.security.Security;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.opengis.filter.sort.SortOrder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"synccatalog\",\n+  description = \"Syncs all catalog items to the offline solr gazetteer core\"\n+)\n+public class SyncCatalogCommand implements Action {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+  public static final int PARTITION_SIZE = 256;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Reference private Session session;\n+\n+  @Reference private CatalogFramework catalogFramework;\n+  @Reference private FilterBuilder filterBuilder;\n+  @Reference private Security security;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(50, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    return security.runWithSubjectOrElevate(this::executeWithSubject);\n+  }\n+\n+  public Object executeWithSubject() throws Exception {\n+    SolrClient solrClient =\n+        clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+    Failsafe.with(retryPolicy).get(() -> solrClient.ping());\n+\n+    Iterable<Result> iterable =\n+        ResultIterable.resultIterable(catalogFramework, getGazetteerFilter());\n+\n+    session.getConsole().println(\"Starting sync...\");\n+    long counter = 0;\n+    Instant start = Instant.now();\n+\n+    for (List<Result> results : Iterables.partition(iterable, PARTITION_SIZE)) {\n+      if (Thread.interrupted()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0Mjc1NQ==", "bodyText": "\u2753  Is there a way to output the call order for catalog plugins, or any OSGi service for that matter, to rule out service ranking as a possible issue? Might want to tag in @pklinef for this question as well.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451242755", "createdAt": "2020-07-08T02:14:32Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/resources/OSGI-INF/blueprint/blueprint.xml", "diffHunk": "@@ -0,0 +1,35 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!-- /**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/ -->\n+<blueprint xmlns=\"http://www.osgi.org/xmlns/blueprint/v1.0.0\">\n+\n+  <reference id=\"solrFactory\" interface=\"org.codice.solr.factory.SolrClientFactory\"/>\n+\n+\n+  <bean id=\"offlineGazetteerPlugin\"\n+    class=\"ddf.catalog.solr.offlinegazetteer.OfflineGazetteerPlugin\">\n+    <argument ref=\"solrFactory\"/>\n+  </bean>\n+  <service ref=\"offlineGazetteerPlugin\">\n+    <interfaces>\n+      <value>ddf.catalog.plugin.PostIngestPlugin</value>\n+      <value>ddf.catalog.plugin.PreQueryPlugin</value>\n+    </interfaces>\n+  </service>\n+\n+  <bean id=\"gazetteerQueryOfflineSolr\" class=\"ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\">\n+    <argument ref=\"solrFactory\"/>\n+  </bean>\n+  <service ref=\"gazetteerQueryOfflineSolr\" interface=\"org.codice.ddf.spatial.geocoding.GeoEntryQueryable\" ranking=\"80\" />", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5NTkzMA=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0NjcxNw==", "bodyText": "\u2757 I don't expect it to get fixed in this PR but I didn't want to ignore it. Something that really bothers me is our systemic use of separate, single-threaded executors across the entire system.\n\nThe biggest drawback is likely increased startup time since bootstrapping threads aren't cheap.\nIt makes instrumenting all the separate utility threads a real pain especially if you want a cohesive view of what your system is doing.\nIt may be trivial but most of the time the executor just lingers around when it's done, and while the cost is minimal it would be beneficial and in keeping with a clean runtime to shutdown resources we no longer use or need.\n\nSome resources:\n\nSO discussion\nJavadoc but note just from the descriptions that there are more effective options for what we're doing, for example the cached thread pool option, which consumes zero resources when no activity is occurring.\nI think even a fixed thread pool initialized early with ~2 threads would be sufficient for all our different \"one off executor\" operations but that can be allowed to vary on a case-by-case basis.\n\nJust wondering if we want to re-evaluate the tradeoffs here and in the future consider registering executor services with OSGi service properties and sharing them in their respective contexts. This would also allow for improved centralized tuning and configuration of the system's threading resources.\nAlso problematic is if I wanted to override this executor downstream I have no way of doing that unless I rewrite the blueprint, embed the jar, and build a bundle myself.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451246717", "createdAt": "2020-07-08T02:30:30Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/resources/OSGI-INF/blueprint/blueprint.xml", "diffHunk": "@@ -0,0 +1,39 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!-- /**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * This is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation, either\n+ * version 3 of the License, or any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n+ * See the GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ *\n+ **/ -->\n+<blueprint xmlns=\"http://www.osgi.org/xmlns/blueprint/v1.0.0\">\n+\n+  <reference id=\"solrFactory\" interface=\"org.codice.solr.factory.SolrClientFactory\"/>\n+\n+\n+  <bean id=\"offlineGazetteerPlugin\"\n+    class=\"ddf.catalog.solr.offlinegazetteer.OfflineGazetteerPlugin\">\n+    <argument ref=\"solrFactory\"/>\n+  </bean>\n+  <service ref=\"offlineGazetteerPlugin\">\n+    <interfaces>\n+      <value>ddf.catalog.plugin.PostIngestPlugin</value>\n+      <value>ddf.catalog.plugin.PreQueryPlugin</value>\n+    </interfaces>\n+  </service>\n+\n+  <bean id=\"executorService\" class=\"java.util.concurrent.Executors\"\n+    factory-method=\"newSingleThreadExecutor\">\n+  </bean>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI1MTM0NQ==", "bodyText": "\u2753  This is just one higher than max results right? So our max should kick in and correct the issue, only returning 100 results instead?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451251345", "createdAt": "2020-07-08T02:49:03Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/test/groovy/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolrSpec.groovy", "diffHunk": "@@ -0,0 +1,402 @@\n+package ddf.catalog.solr.offlinegazetteer\n+\n+import ddf.catalog.solr.offlinegazetteer.GazetteerQueryOfflineSolr\n+import org.apache.solr.client.solrj.SolrQuery\n+import org.apache.solr.client.solrj.SolrRequest\n+import org.apache.solr.client.solrj.SolrRequest.METHOD\n+import org.apache.solr.client.solrj.SolrServerException\n+import org.apache.solr.client.solrj.response.QueryResponse\n+import org.apache.solr.client.solrj.response.SolrPingResponse\n+import org.apache.solr.client.solrj.response.SuggesterResponse\n+import org.apache.solr.client.solrj.response.Suggestion\n+import org.apache.solr.common.SolrDocument\n+import org.apache.solr.common.SolrDocumentList\n+import org.codice.ddf.spatial.geocoding.GeoEntry\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation\n+import org.codice.solr.client.solrj.SolrClient\n+import org.codice.solr.factory.SolrClientFactory\n+import spock.lang.Specification\n+\n+import java.util.concurrent.ExecutorService\n+import java.util.stream.Stream\n+\n+class GazetteerQueryOfflineSolrSpec extends Specification {\n+    GazetteerQueryOfflineSolr testedClass\n+    SolrClientFactory solrClientFactory\n+    SolrClient solrClient\n+    ExecutorService executorService\n+\n+    void setup() {\n+        executorService = Mock(ExecutorService)\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory, executorService)\n+    }\n+\n+    def \"Test normal startup ping and suggester build\"() {\n+        setup:\n+        executorService = Mock(ExecutorService) {\n+            submit(_ as Runnable) >> {Runnable task -> task.run()}\n+        }\n+        solrClient = Mock(SolrClient)\n+        solrClientFactory = Mock(SolrClientFactory) {\n+            newClient(_) >> solrClient\n+        }\n+\n+        2 * solrClient.ping() >> { throw new SolrServerException(\"exception\") } >> Mock(\n+                SolrPingResponse)\n+\n+        1 * solrClient.query(*_) >> { SolrQuery query , METHOD method ->\n+            assert query.requestHandler == \"/suggest\"\n+            assert query.get(\"suggest.build\") == \"true\"\n+            assert query.get(\"suggest.dictionary\") == \"suggestPlace\"\n+        }\n+\n+        when:\n+        testedClass = new GazetteerQueryOfflineSolr(solrClientFactory, executorService)\n+\n+        then:\n+        notThrown(Exception)\n+    }\n+\n+    def \"Test normal query\"() {\n+        setup:\n+        int numResults = 10\n+        1 * solrClient.query({ SolrQuery it -> it.getRows() == numResults }, *_) >>\n+                Mock(QueryResponse) {\n+                    getResults() >> Mock(SolrDocumentList) {\n+                        stream() >> {\n+                            Stream.of(Mock(SolrDocument) {\n+                                get(\"title_txt\") >> [\"title\"]\n+                                get(\"ext.population_lng\") >> [1337l]\n+                                get(\"location_geo\") >> [\"POINT (-98.86253 29.18968)\"]\n+                                get(\"ext.feature-code_txt\") >> [\"PPL\"]\n+                                get(\"location.country-code_txt\") >> [\"USA\"]\n+                                get(\"ext.gazetteer-sort-value_int\") >> [42i]\n+                            })\n+                        }\n+                    }\n+                }\n+\n+        when:\n+        List<GeoEntry> results = testedClass.query(\"sample\", numResults)\n+\n+        then:\n+        results.size() == 1\n+        with(results.first()) {\n+            name == \"title\"\n+            population == 1337\n+            29.18 <= latitude && latitude <= 29.19\n+            -98.9 <= longitude && longitude <= -98.8\n+            featureCode == \"PPL\"\n+            countryCode == \"USA\"\n+        }\n+\n+    }\n+\n+    def \"Test query max results\"() {\n+        setup:\n+        int numResults = 101", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 102}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0ODc3MDIz", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-444877023", "createdAt": "2020-07-08T15:23:15Z", "commit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNToyMzoxNVrOGutR2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNjowNTowOVrOGuvBtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyOTUzMQ==", "bodyText": "might not need to be a class variable. look like it is assigned and used in the constructor", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451629531", "createdAt": "2020-07-08T15:23:15Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SolrPingResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"ext.feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  protected static final String SUGGEST_Q = \"suggest.q\";\n+  protected static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  protected static final String SUGGEST_PLACE_KEY = \"suggestPlace\";\n+\n+  public static final int MAX_RESULTS = 100;\n+  public static final double KM_PER_DEGREE = 111.139;\n+\n+  private SolrClientFactory clientFactory;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIxNDY3OQ=="}, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MTIxNA==", "bodyText": "Should this be not public and be annotated as VisibleForTesting", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451641214", "createdAt": "2020-07-08T15:39:59Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));\n+    } catch (Exception e) {\n+      LOGGER.info(\"Error while executing\", e);\n+      session.getConsole().println(\"Error while submitting remove all, exiting.\");\n+      throw e;\n+    }\n+    session.getConsole().println(\"Removeall submitted successfully.\");\n+    return null;\n+  }\n+\n+  public void setClientFactory(SolrClientFactory clientFactory) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0ODM2Mg==", "bodyText": "would be nice to print some kind of progress bar. similar to this? https://github.com/codice/ddf/blob/master/catalog/core/catalog-core-commands/src/main/java/org/codice/ddf/commands/catalog/CommandSupport.java#L68", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451648362", "createdAt": "2020-07-08T15:50:37Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/SyncCatalogCommand.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import ddf.catalog.CatalogFramework;\n+import ddf.catalog.data.Result;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.filter.FilterBuilder;\n+import ddf.catalog.filter.impl.SortByImpl;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.impl.QueryImpl;\n+import ddf.catalog.operation.impl.QueryRequestImpl;\n+import ddf.catalog.util.impl.ResultIterable;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.ddf.security.Security;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.opengis.filter.sort.SortOrder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"synccatalog\",\n+  description = \"Syncs all catalog items to the offline solr gazetteer core\"\n+)\n+public class SyncCatalogCommand implements Action {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+  public static final int PARTITION_SIZE = 256;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Reference private Session session;\n+\n+  @Reference private CatalogFramework catalogFramework;\n+  @Reference private FilterBuilder filterBuilder;\n+  @Reference private Security security;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(50, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    return security.runWithSubjectOrElevate(this::executeWithSubject);\n+  }\n+\n+  public Object executeWithSubject() throws Exception {\n+    SolrClient solrClient =\n+        clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+    Failsafe.with(retryPolicy).get(() -> solrClient.ping());\n+\n+    Iterable<Result> iterable =\n+        ResultIterable.resultIterable(catalogFramework, getGazetteerFilter());\n+\n+    session.getConsole().println(\"Starting sync...\");\n+    long counter = 0;\n+    Instant start = Instant.now();\n+\n+    for (List<Result> results : Iterables.partition(iterable, PARTITION_SIZE)) {\n+      if (Thread.interrupted()) {\n+        LOGGER.info(\"Catalog sync interrupted early, exiting\");\n+        session.getConsole().println(\"Catalog sync interrupted, exiting\");\n+        Thread.currentThread().interrupt();\n+        throw new InterruptedException();\n+      }\n+\n+      try {\n+        solrClient.add(\n+            results\n+                .stream()\n+                .map(Result::getMetacard)\n+                .map(OfflineGazetteerPlugin::convert)\n+                .collect(Collectors.toList()));\n+      } catch (SolrServerException | IOException e) {\n+        LOGGER.info(\"error while adding items to solr\", e);\n+        session.getConsole().printf(\"An error occured while syncing: %s\", e.getMessage());\n+        throw e;\n+      }\n+      counter += results.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0OTIwOA==", "bodyText": "\u270f\ufe0f   SyncCatalogCommand", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451649208", "createdAt": "2020-07-08T15:51:46Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/SyncCatalogCommand.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import ddf.catalog.CatalogFramework;\n+import ddf.catalog.data.Result;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.filter.FilterBuilder;\n+import ddf.catalog.filter.impl.SortByImpl;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.impl.QueryImpl;\n+import ddf.catalog.operation.impl.QueryRequestImpl;\n+import ddf.catalog.util.impl.ResultIterable;\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.ddf.security.Security;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.opengis.filter.sort.SortOrder;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"synccatalog\",\n+  description = \"Syncs all catalog items to the offline solr gazetteer core\"\n+)\n+public class SyncCatalogCommand implements Action {\n+\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY1MTc2Mw==", "bodyText": "make this public or package level to be used here as well https://github.com/codice/ddf/pull/6153/files?file-filters%5B%5D=.java&file-filters%5B%5D=.xml#diff-ff075cf175bf24a6e17cb56229d23edfR128", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451651763", "createdAt": "2020-07-08T15:55:23Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/OfflineGazetteerPlugin.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.Constants.SUGGESTION_BUILD_KEY;\n+\n+import ddf.catalog.data.Attribute;\n+import ddf.catalog.data.Metacard;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteResponse;\n+import ddf.catalog.operation.QueryRequest;\n+import ddf.catalog.operation.Update;\n+import ddf.catalog.operation.UpdateResponse;\n+import ddf.catalog.plugin.PluginExecutionException;\n+import ddf.catalog.plugin.PostIngestPlugin;\n+import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.StopProcessingException;\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.common.SolrInputDocument;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class OfflineGazetteerPlugin implements PostIngestPlugin, PreQueryPlugin {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(OfflineGazetteerPlugin.class);\n+  private static final String GAZETTEER_METACARD_TAG = \"gazetteer\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da7f3def8635d75cf1d73988ed479c2def44f589"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY1ODE2Nw==", "bodyText": "i have seen this as well on the splitcatalogprovider. should newClient bake in the logic to check/wait with timeout before returning?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r451658167", "createdAt": "2020-07-08T16:05:09Z", "author": {"login": "lamhuy"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/RemoveAllOfflineSolrGazetteerCommand.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.concurrent.TimeUnit;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.karaf.shell.api.action.Action;\n+import org.apache.karaf.shell.api.action.Command;\n+import org.apache.karaf.shell.api.action.Option;\n+import org.apache.karaf.shell.api.action.lifecycle.Reference;\n+import org.apache.karaf.shell.api.action.lifecycle.Service;\n+import org.apache.karaf.shell.api.console.Session;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.client.solrj.UnavailableSolrException;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Service\n+@Command(\n+  scope = \"offline-solr-gazetteer\",\n+  name = \"removeall\",\n+  description = \"Deletes all items in the offline solr gazetteer solr core\"\n+)\n+public class RemoveAllOfflineSolrGazetteerCommand implements Action {\n+  private static final Logger LOGGER =\n+      LoggerFactory.getLogger(RemoveAllOfflineSolrGazetteerCommand.class);\n+\n+  @Reference protected Session session;\n+\n+  @Reference private SolrClientFactory clientFactory;\n+\n+  @Option(\n+    name = \"--force\",\n+    aliases = {\"-f\"},\n+    description = \"Force the removal without a confirmation message.\"\n+  )\n+  boolean force = false;\n+\n+  private final RetryPolicy retryPolicy =\n+      new RetryPolicy()\n+          .retryOn(ImmutableList.of(UnavailableSolrException.class, SolrServerException.class))\n+          .withMaxDuration(5, TimeUnit.SECONDS)\n+          .withBackoff(25, 1_000, TimeUnit.MILLISECONDS);\n+\n+  @Override\n+  public Object execute() throws Exception {\n+    if (!force) {\n+      String answer =\n+          session\n+              .readLine(\n+                  \"Are you sure you want to remove all gazetteer entries inside of the offline solr gazetteer core?(y/n)\",\n+                  ' ')\n+              .toLowerCase();\n+      if (!(\"y\".equals(answer) || \"yes\".equals(answer))) {\n+        session.getConsole().println(\"Aborting.\");\n+        return null;\n+      }\n+    }\n+    try {\n+      SolrClient solrClient =\n+          clientFactory.newClient(OfflineGazetteerPlugin.STANDALONE_GAZETTEER_CORE_NAME);\n+\n+      Failsafe.with(retryPolicy).get(() -> solrClient.deleteByQuery(\"*:*\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5ODEwMg=="}, "originalCommit": {"oid": "cc7d19c20f926c1b37a7b3926608b9f97d5d66f9"}, "originalPosition": 78}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "659865ea8742b5b008cc390599fc8fd27a7120ca", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/659865ea8742b5b008cc390599fc8fd27a7120ca", "committedDate": "2020-07-13T23:15:34Z", "message": "Added Gazetteer Constants, new solrclient ping logic, other minor updates"}, "afterCommit": {"oid": "f4467176b2793575eedef0d8ea716a082e6ff244", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/f4467176b2793575eedef0d8ea716a082e6ff244", "committedDate": "2020-07-13T23:16:28Z", "message": "Added Gazetteer Constants, new solrclient ping logic, other minor updates"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3Njc1MTI0", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-447675124", "createdAt": "2020-07-13T23:18:56Z", "commit": {"oid": "f4467176b2793575eedef0d8ea716a082e6ff244"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzoxODo1NlrOGw-Atw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzoxODo1NlrOGw-Atw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwMDgyMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  // convert distance to KM", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454000823", "createdAt": "2020-07-13T23:18:56Z", "author": {"login": "rzwiefel"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.NAMES;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT_VALUE;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_Q;\n+\n+import com.google.common.collect.ImmutableMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.locationtech.spatial4j.context.SpatialContext;\n+import org.locationtech.spatial4j.context.SpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.JtsSpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.ValidationRule;\n+import org.locationtech.spatial4j.exception.InvalidShapeException;\n+import org.locationtech.spatial4j.shape.Shape;\n+import org.locationtech.spatial4j.shape.jts.JtsGeometry;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final int MAX_RESULTS = 100;\n+  private static final double KM_PER_DEGREE = 111.139;\n+\n+  private static final Map<String, String> SPATIAL_CONTEXT_ARGUMENTS =\n+      ImmutableMap.of(\n+          \"spatialContextFactory\",\n+          JtsSpatialContextFactory.class.getName(),\n+          \"validationRule\",\n+          ValidationRule.repairConvexHull.name());\n+\n+  private static final SpatialContext SPATIAL_CONTEXT =\n+      SpatialContextFactory.makeSpatialContext(SPATIAL_CONTEXT_ARGUMENTS, null);\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private final SolrClient client;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+\n+    this.client = clientFactory.newClient(GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME);\n+    startupBuilderExecutor.submit(this::pingAndInitializeSuggester);\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying by ID\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_DICT_VALUE))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private void pingAndInitializeSuggester() {\n+    Failsafe.with(\n+            new RetryPolicy()\n+                .retryWhen(false)\n+                .withMaxDuration(5, TimeUnit.MINUTES)\n+                .withBackoff(100, 3_000, TimeUnit.MILLISECONDS))\n+        .onFailure(\n+            e ->\n+                LOGGER.error(\n+                    \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                    GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME,\n+                    e))\n+        .get(() -> client.isAvailable());\n+\n+    SolrQuery query = new SolrQuery();\n+    query.setRequestHandler(\"/suggest\");\n+    query.setParam(\"suggest.build\", true);\n+    query.setParam(SUGGEST_Q, \"GQOSInitialSuggesterBuild\");\n+    query.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    try {\n+      QueryResponse response = client.query(query, METHOD.POST);\n+      LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.error(\n+          \"Error while trying to build initial suggester for {}\",\n+          GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME,\n+          e);\n+    }\n+  }\n+\n+  public static final class SuggestionImpl implements Suggestion {\n+    private final String id;\n+    private final String name;\n+\n+    public SuggestionImpl(String id, String name) {\n+      this.id = id;\n+      this.name = name;\n+    }\n+\n+    @Override\n+    public String getId() {\n+      return id;\n+    }\n+\n+    @Override\n+    public String getName() {\n+      return name;\n+    }\n+  }\n+\n+  @Override\n+  public List<NearbyLocation> getNearestCities(String location, int radiusInKm, int maxResults)\n+      throws ParseException, GeoEntryQueryException {\n+    Geometry geometry;\n+    try {\n+      geometry = WKT_READER_THREAD_LOCAL.get().read(location);\n+    } catch (org.locationtech.jts.io.ParseException e) {\n+      throw new GeoEntryQueryException(\"Could not parse location\");\n+    }\n+    final Geometry originalGeometry = geometry;\n+    Geometry bufferedGeo = originalGeometry.buffer(convertKilometerToDegree(radiusInKm), 14);\n+    String wkt = WKT_WRITER_THREAD_LOCAL.get().write(bufferedGeo);\n+\n+    String q =\n+        String.format(\n+            \"location_geo_index:\\\"Intersects( %s ) AND %s\\\"\",\n+            ClientUtils.escapeQueryChars(wkt), CITY_SOLR_QUERY);\n+\n+    SolrQuery solrQuery = new SolrQuery(q);\n+    solrQuery.setRows(Math.min(maxResults, MAX_RESULTS));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error executing query for nearest cities\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(result -> convert(result, originalGeometry))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private NearbyLocation convert(SolrDocument doc, Geometry originalLocation) {\n+    String location = getField(doc, \"location_geo\", String.class);\n+    String title =\n+        Optional.ofNullable(getField(doc, \"title_txt\", String.class))\n+            .filter(Objects::nonNull)\n+            .filter(s -> !s.isEmpty())\n+            .orElse(\"NO TITLE\");\n+\n+    String cardinalDirection = \"\";\n+    double distance = 0;\n+    try {\n+      Geometry geo = WKT_READER_THREAD_LOCAL.get().read(location);\n+      cardinalDirection =\n+          bearingToCardinalDirection(getBearing(originalLocation.getCentroid(), geo.getCentroid()));\n+      // convert distance to KM", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f4467176b2793575eedef0d8ea716a082e6ff244"}, "originalPosition": 270}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4NDk2NzM4", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-448496738", "createdAt": "2020-07-14T22:00:04Z", "commit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQyMjowMDowNFrOGxm5Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQyMjowNTo0NlrOGxnCZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MDYwMw==", "bodyText": "\u270f\ufe0f is meant to be or is?", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454670603", "createdAt": "2020-07-14T22:00:04Z", "author": {"login": "ricklarsen"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,47 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is meant to to be a reflection of the gazetteer data stored", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MTI1OA==", "bodyText": "\ud83d\udcdd this might read clearer as gazetteer data stored in the catalog but separated from other data", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454671258", "createdAt": "2020-07-14T22:01:31Z", "author": {"login": "ricklarsen"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,47 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is meant to to be a reflection of the gazetteer data stored\n+in the catalog while not being mixed in with all the other data. This allows the core to be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MjE3Mw==", "bodyText": "\u270f\ufe0f lowercase e.g. or better yet, for example", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454672173", "createdAt": "2020-07-14T22:03:45Z", "author": {"login": "ricklarsen"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,47 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is meant to to be a reflection of the gazetteer data stored\n+in the catalog while not being mixed in with all the other data. This allows the core to be\n+separately reindexed much quicker than the the entire catalog core.\n+\n+====  Installing Standalone Solr Offline Gazetteer\n+\n+The Standalone Solr Offline Gazetteer is not installed by default but can be installed by running\n+`feature:install catalog-solr-offline-gazetteer`. This will install:\n+\n+* The plugin that intercepts gazetteer metacard creates/updates/deletes to the catalog core\n+(and stores them in the standalone solr gazetteer core)\n+* The gazetteer query service which registers the Query component that responds to requests from\n+the UI gazetteer search box\n+* The `offline-solr-gazetteer:removeall` command which will delete all records in the standalone\n+solr gazetteer core\n+* The `offline-solr-gazetteer:synccatalog` command which will sync with the catalog and update all\n+records in the standalone solr gazetteer core to reflect it (or add them if they are not yet\n+created)\n+\n+==== Special Note Regarding Installation\n+\n+If the Spatial Geocoding Offline Catalog bundle and the bundle using the Gazetteer query service\n+(EG, Intrigue) are both already running, you will need to restart the bundles consuming the service", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3MjgwOA==", "bodyText": "I might cut this sentence as the service ranking seems a little low-level-implementation-detail-y, but I could be persuaded otherwise.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454672808", "createdAt": "2020-07-14T22:05:15Z", "author": {"login": "ricklarsen"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,47 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is meant to to be a reflection of the gazetteer data stored\n+in the catalog while not being mixed in with all the other data. This allows the core to be\n+separately reindexed much quicker than the the entire catalog core.\n+\n+====  Installing Standalone Solr Offline Gazetteer\n+\n+The Standalone Solr Offline Gazetteer is not installed by default but can be installed by running\n+`feature:install catalog-solr-offline-gazetteer`. This will install:\n+\n+* The plugin that intercepts gazetteer metacard creates/updates/deletes to the catalog core\n+(and stores them in the standalone solr gazetteer core)\n+* The gazetteer query service which registers the Query component that responds to requests from\n+the UI gazetteer search box\n+* The `offline-solr-gazetteer:removeall` command which will delete all records in the standalone\n+solr gazetteer core\n+* The `offline-solr-gazetteer:synccatalog` command which will sync with the catalog and update all\n+records in the standalone solr gazetteer core to reflect it (or add them if they are not yet\n+created)\n+\n+==== Special Note Regarding Installation\n+\n+If the Spatial Geocoding Offline Catalog bundle and the bundle using the Gazetteer query service\n+(EG, Intrigue) are both already running, you will need to restart the bundles consuming the service\n+(EG, Intrigue) in order to pick up the correct one. The Standalone Solr Offline Gazetteer has a\n+service ranking of 80, which should win against the catalog gazetteer query service (with ranking", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDY3Mjk5OA==", "bodyText": "\u270f\ufe0f are run", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454672998", "createdAt": "2020-07-14T22:05:46Z", "author": {"login": "ricklarsen"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,47 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is meant to to be a reflection of the gazetteer data stored\n+in the catalog while not being mixed in with all the other data. This allows the core to be\n+separately reindexed much quicker than the the entire catalog core.\n+\n+====  Installing Standalone Solr Offline Gazetteer\n+\n+The Standalone Solr Offline Gazetteer is not installed by default but can be installed by running\n+`feature:install catalog-solr-offline-gazetteer`. This will install:\n+\n+* The plugin that intercepts gazetteer metacard creates/updates/deletes to the catalog core\n+(and stores them in the standalone solr gazetteer core)\n+* The gazetteer query service which registers the Query component that responds to requests from\n+the UI gazetteer search box\n+* The `offline-solr-gazetteer:removeall` command which will delete all records in the standalone\n+solr gazetteer core\n+* The `offline-solr-gazetteer:synccatalog` command which will sync with the catalog and update all\n+records in the standalone solr gazetteer core to reflect it (or add them if they are not yet\n+created)\n+\n+==== Special Note Regarding Installation\n+\n+If the Spatial Geocoding Offline Catalog bundle and the bundle using the Gazetteer query service\n+(EG, Intrigue) are both already running, you will need to restart the bundles consuming the service\n+(EG, Intrigue) in order to pick up the correct one. The Standalone Solr Offline Gazetteer has a\n+service ranking of 80, which should win against the catalog gazetteer query service (with ranking\n+50).\n+\n+==== Building the suggester index on Standalone Solr Offline Gazetteer\n+\n+The suggester index will be built when any of the other methods of building the catalog gazetteer\n+are ran, along with on initial install. So you can run `gazetteer:build-suggester-index` to build", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e97c8f49e8e93dd397f50fbc25f0201114bbe31"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4NTUzMzYy", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-448553362", "createdAt": "2020-07-15T00:32:56Z", "commit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMDozMjo1NlrOGxp_aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMDo1NToyNFrOGxqW-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMTM4Nw==", "bodyText": "\u270f\ufe0f The fact that these field names match the catalog metacard attributes is now an incidental implementation detail of how the default suggestor is configured in the schema.  I would recommend removing the use of these attributes since these are not actually metacard attributes.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454721387", "createdAt": "2020-07-15T00:32:56Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,465 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.NAMES;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT_VALUE;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_Q;\n+\n+import com.google.common.collect.ImmutableMap;\n+import ddf.catalog.data.types.Core;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMjA4OA==", "bodyText": "\u270f\ufe0f Really it is more of a Collection name than a Core name.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454722088", "createdAt": "2020-07-15T00:35:21Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerConstants.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableBiMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+\n+public class GazetteerConstants {\n+  /* Solr Requests */\n+  public static final String SUGGEST_Q = \"suggest.q\";\n+  public static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  public static final String SUGGEST_DICT_VALUE = \"suggestPlace\";\n+\n+  /* Naming */\n+  public static final String GAZETTEER_METACARD_TAG = GeoCodingConstants.GAZETTEER_METACARD_TAG;\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMzE4Mw==", "bodyText": "\u2757 It seems very odd to mention Solr in the name of a Solr collection name.  I am also not sure what standalone means in this context.\nI think we can name this collection just gazetteer now that we are not planning on doing the Solr collection routing any time soon.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454723183", "createdAt": "2020-07-15T00:39:45Z", "author": {"login": "pklinef"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerConstants.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableBiMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+\n+public class GazetteerConstants {\n+  /* Solr Requests */\n+  public static final String SUGGEST_Q = \"suggest.q\";\n+  public static final String SUGGEST_DICT = \"suggest.dictionary\";\n+  public static final String SUGGEST_DICT_VALUE = \"suggestPlace\";\n+\n+  /* Naming */\n+  public static final String GAZETTEER_METACARD_TAG = GeoCodingConstants.GAZETTEER_METACARD_TAG;\n+  public static final String STANDALONE_GAZETTEER_CORE_NAME = \"standalone-solr-gazetteer\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyNzQxNw==", "bodyText": "\u2757 I think this suggest component can only be used for gazetteer suggestions as it is.  Since this PR is changing how that works, I think it would be safe to completely re-purpose this suggest component for the gazetteer collection. The request handler below could be mapped to /gazetteer.  The serachComponent name could be changed from suggest to gazetteer. The field, contextField, weightField, and sortField could all be updated to use gazetteer specific field names.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454727417", "createdAt": "2020-07-15T00:55:24Z", "author": {"login": "pklinef"}, "path": "platform/solr/solr-schema/src/main/resources/solr/conf/solrconfig.xml", "diffHunk": "@@ -1290,6 +1290,7 @@\n       <str name=\"sortField\">ext.population_lng</str>\n       <str name=\"payloadField\">id_txt</str>\n       <str name=\"buildOnStartup\">false</str>\n+      <str name=\"highlight\">false</str>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4NTc4NjE4", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-448578618", "createdAt": "2020-07-15T01:59:30Z", "commit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMTo1OTozMFrOGxrbPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwMjozMjo1N1rOGxr-CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc0NDg5Mw==", "bodyText": "\u2753 I'm torn between making this a WARN log or leaving it as-is at ERROR. Here's why.\nI like to attach synchronous system validity to the bundle states. I do that because if a bundle successfully starts but something else failed, now there's more than one state in play and that fragmentation contributes to system complexity.\nThe system either started successfully or didn't. When shipping a system, external factors should impact synchronous start as little as possible. Are these exceptions indicative of a failed system start? Or is suggester initialization considered an optional start task?\nWhat are optional start tasks? Can they be skipped and the system should work fine out of the box? Do we have a way to iterate them besides logs, or the absence of logs?\nTakeaway: I'm not sure what to make of this because I'm pretty sure if this async task fails our system is not in a valid state, but if we booted successfully, I think it should have been.\nAlso note that we don't have a good way to track async startup tasks' pass/fail/in-progress states across the system short of logging. That's probably good enough for this PR but something we should consider going forward. It would help alleviate the previous fragmentation of \"am I in a good state\" that I mentioned earlier. It also gives an admin a point of synchronization so that, from their perspective, a \"successful start\" can be bounded back into their synchronous question - did my system start such that all default features will work correctly?\nCentralizing long-running start tasks can also get tied back into waitForReady or other mechanisms.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454744893", "createdAt": "2020-07-15T01:59:30Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,465 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.NAMES;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT_VALUE;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_Q;\n+\n+import com.google.common.collect.ImmutableMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.locationtech.spatial4j.context.SpatialContext;\n+import org.locationtech.spatial4j.context.SpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.JtsSpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.ValidationRule;\n+import org.locationtech.spatial4j.exception.InvalidShapeException;\n+import org.locationtech.spatial4j.shape.Shape;\n+import org.locationtech.spatial4j.shape.jts.JtsGeometry;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final int MAX_RESULTS = 100;\n+  private static final double KM_PER_DEGREE = 111.139;\n+\n+  private static final Map<String, String> SPATIAL_CONTEXT_ARGUMENTS =\n+      ImmutableMap.of(\n+          \"spatialContextFactory\",\n+          JtsSpatialContextFactory.class.getName(),\n+          \"validationRule\",\n+          ValidationRule.repairConvexHull.name());\n+\n+  private static final SpatialContext SPATIAL_CONTEXT =\n+      SpatialContextFactory.makeSpatialContext(SPATIAL_CONTEXT_ARGUMENTS, null);\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private final SolrClient client;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+\n+    this.client = clientFactory.newClient(GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME);\n+    startupBuilderExecutor.submit(this::pingAndInitializeSuggester);\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying by ID\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_DICT_VALUE))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private void pingAndInitializeSuggester() {\n+    Failsafe.with(\n+            new RetryPolicy()\n+                .retryWhen(false)\n+                .withMaxDuration(5, TimeUnit.MINUTES)\n+                .withBackoff(100, 3_000, TimeUnit.MILLISECONDS))\n+        .onFailure(\n+            e ->\n+                LOGGER.error(\n+                    \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",\n+                    GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME,\n+                    e))\n+        .get(() -> client.isAvailable());\n+\n+    SolrQuery query = new SolrQuery();\n+    query.setRequestHandler(\"/suggest\");\n+    query.setParam(\"suggest.build\", true);\n+    query.setParam(SUGGEST_Q, \"GQOSInitialSuggesterBuild\");\n+    query.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    try {\n+      QueryResponse response = client.query(query, METHOD.POST);\n+      LOGGER.debug(\"Initial Suggester build response: {}\", response);\n+    } catch (SolrServerException | IOException e) {\n+      LOGGER.error(\n+          \"Error while trying to build initial suggester for {}\",\n+          GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME,\n+          e);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc0NTgzNg==", "bodyText": "\ud83d\udc4d   Okay we can build the index manually. Perfect.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454745836", "createdAt": "2020-07-15T02:03:19Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,465 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.NAMES;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT_VALUE;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_Q;\n+\n+import com.google.common.collect.ImmutableMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.locationtech.spatial4j.context.SpatialContext;\n+import org.locationtech.spatial4j.context.SpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.JtsSpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.ValidationRule;\n+import org.locationtech.spatial4j.exception.InvalidShapeException;\n+import org.locationtech.spatial4j.shape.Shape;\n+import org.locationtech.spatial4j.shape.jts.JtsGeometry;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final int MAX_RESULTS = 100;\n+  private static final double KM_PER_DEGREE = 111.139;\n+\n+  private static final Map<String, String> SPATIAL_CONTEXT_ARGUMENTS =\n+      ImmutableMap.of(\n+          \"spatialContextFactory\",\n+          JtsSpatialContextFactory.class.getName(),\n+          \"validationRule\",\n+          ValidationRule.repairConvexHull.name());\n+\n+  private static final SpatialContext SPATIAL_CONTEXT =\n+      SpatialContextFactory.makeSpatialContext(SPATIAL_CONTEXT_ARGUMENTS, null);\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private final SolrClient client;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+\n+    this.client = clientFactory.newClient(GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME);\n+    startupBuilderExecutor.submit(this::pingAndInitializeSuggester);\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying by ID\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_DICT_VALUE))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private void pingAndInitializeSuggester() {\n+    Failsafe.with(\n+            new RetryPolicy()\n+                .retryWhen(false)\n+                .withMaxDuration(5, TimeUnit.MINUTES)\n+                .withBackoff(100, 3_000, TimeUnit.MILLISECONDS))\n+        .onFailure(\n+            e ->\n+                LOGGER.error(\n+                    \"Could not get solrclient to start initial suggester build for {} core. Please try to start a build manually with the `build-suggester-index` karaf command or by sending a request to solr with the property `suggest.build=true`\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc0NzIxMA==", "bodyText": "\u2753 This is probably exhaustively fine which means when flakiness occurs, this failure will be a very rare sight. Would it be an improvement to use whenAvailable and an Initializer instead?\nhttps://github.com/codice/ddf/blob/master/platform/solr/solr-factory/src/main/java/org/codice/solr/client/solrj/SolrClient.java#L133\nDrawback there is that, if it turns out Solr isn't available for awhile, we will never log a \"timeout\" message claiming our \"initialization\" (if you include async tasks) didn't \"finish\" (it technically did because we booted up) unless we can provide a timeout. So I'm not sure.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454747210", "createdAt": "2020-07-15T02:08:25Z", "author": {"login": "Lambeaux"}, "path": "catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java", "diffHunk": "@@ -0,0 +1,465 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package ddf.catalog.solr.offlinegazetteer;\n+\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.NAMES;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_DICT_VALUE;\n+import static ddf.catalog.solr.offlinegazetteer.GazetteerConstants.SUGGEST_Q;\n+\n+import com.google.common.collect.ImmutableMap;\n+import ddf.catalog.data.types.Core;\n+import ddf.catalog.data.types.Location;\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import net.jodah.failsafe.Failsafe;\n+import net.jodah.failsafe.RetryPolicy;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.solr.client.solrj.SolrQuery;\n+import org.apache.solr.client.solrj.SolrRequest.METHOD;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.response.QueryResponse;\n+import org.apache.solr.client.solrj.response.SuggesterResponse;\n+import org.apache.solr.client.solrj.util.ClientUtils;\n+import org.apache.solr.common.SolrDocument;\n+import org.codice.ddf.spatial.geocoding.GeoCodingConstants;\n+import org.codice.ddf.spatial.geocoding.GeoEntry;\n+import org.codice.ddf.spatial.geocoding.GeoEntryAttributes;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryException;\n+import org.codice.ddf.spatial.geocoding.GeoEntryQueryable;\n+import org.codice.ddf.spatial.geocoding.Suggestion;\n+import org.codice.ddf.spatial.geocoding.context.NearbyLocation;\n+import org.codice.solr.client.solrj.SolrClient;\n+import org.codice.solr.factory.SolrClientFactory;\n+import org.locationtech.jts.geom.Geometry;\n+import org.locationtech.jts.geom.Point;\n+import org.locationtech.jts.io.WKTReader;\n+import org.locationtech.jts.io.WKTWriter;\n+import org.locationtech.spatial4j.context.SpatialContext;\n+import org.locationtech.spatial4j.context.SpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.JtsSpatialContextFactory;\n+import org.locationtech.spatial4j.context.jts.ValidationRule;\n+import org.locationtech.spatial4j.exception.InvalidShapeException;\n+import org.locationtech.spatial4j.shape.Shape;\n+import org.locationtech.spatial4j.shape.jts.JtsGeometry;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class GazetteerQueryOfflineSolr implements GeoEntryQueryable {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(GazetteerQueryOfflineSolr.class);\n+\n+  private static final String CITY_SOLR_QUERY =\n+      GeoCodingConstants.CITY_FEATURE_CODES\n+          .stream()\n+          .map(fc -> String.format(\"feature-code_txt:%s\", fc))\n+          .collect(Collectors.joining(\" OR \", \"(\", \")\"));\n+\n+  private static final int MAX_RESULTS = 100;\n+  private static final double KM_PER_DEGREE = 111.139;\n+\n+  private static final Map<String, String> SPATIAL_CONTEXT_ARGUMENTS =\n+      ImmutableMap.of(\n+          \"spatialContextFactory\",\n+          JtsSpatialContextFactory.class.getName(),\n+          \"validationRule\",\n+          ValidationRule.repairConvexHull.name());\n+\n+  private static final SpatialContext SPATIAL_CONTEXT =\n+      SpatialContextFactory.makeSpatialContext(SPATIAL_CONTEXT_ARGUMENTS, null);\n+\n+  private static final ThreadLocal<WKTWriter> WKT_WRITER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTWriter::new);\n+\n+  private static final ThreadLocal<WKTReader> WKT_READER_THREAD_LOCAL =\n+      ThreadLocal.withInitial(WKTReader::new);\n+\n+  private final SolrClient client;\n+\n+  public GazetteerQueryOfflineSolr(\n+      SolrClientFactory clientFactory, ExecutorService startupBuilderExecutor) {\n+\n+    this.client = clientFactory.newClient(GazetteerConstants.STANDALONE_GAZETTEER_CORE_NAME);\n+    startupBuilderExecutor.submit(this::pingAndInitializeSuggester);\n+  }\n+\n+  @Override\n+  public List<GeoEntry> query(String queryString, int maxResults) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"title_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(queryString)));\n+    solrQuery.setRows(Math.min(maxResults, GazetteerQueryOfflineSolr.MAX_RESULTS));\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public GeoEntry queryById(String id) throws GeoEntryQueryException {\n+    SolrQuery solrQuery =\n+        new SolrQuery(String.format(\"id_txt:\\\"%s\\\"\", ClientUtils.escapeQueryChars(id)));\n+    solrQuery.setRows(1);\n+\n+    QueryResponse response = null;\n+    try {\n+      response = client.query(solrQuery, METHOD.POST);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying by ID\", e);\n+    }\n+\n+    return response\n+        .getResults()\n+        .stream()\n+        .map(this::transformMetacardToGeoEntry)\n+        .findFirst()\n+        .orElseThrow(() -> new GeoEntryQueryException(\"Could not find id\"));\n+  }\n+\n+  @Override\n+  public List<Suggestion> getSuggestedNames(String queryString, int maxResults)\n+      throws GeoEntryQueryException {\n+    SolrQuery solrQuery = new SolrQuery();\n+    solrQuery.setRequestHandler(\"/suggest\");\n+    solrQuery.setParam(SUGGEST_Q, ClientUtils.escapeQueryChars(queryString));\n+    solrQuery.setParam(SUGGEST_DICT, SUGGEST_DICT_VALUE);\n+    solrQuery.setParam(\"suggest.count\", Integer.toString(Math.min(maxResults, MAX_RESULTS)));\n+\n+    QueryResponse response;\n+    try {\n+      response = client.query(solrQuery);\n+    } catch (SolrServerException | IOException e) {\n+      throw new GeoEntryQueryException(\"Error while querying\", e);\n+    }\n+\n+    return Optional.ofNullable(response)\n+        .map(QueryResponse::getSuggesterResponse)\n+        .map(SuggesterResponse::getSuggestions)\n+        .map(suggestionsPerDict -> suggestionsPerDict.get(SUGGEST_DICT_VALUE))\n+        .orElse(Collections.emptyList())\n+        .stream()\n+        .map(suggestion -> new SuggestionImpl(suggestion.getPayload(), suggestion.getTerm()))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private void pingAndInitializeSuggester() {\n+    Failsafe.with(\n+            new RetryPolicy()\n+                .retryWhen(false)\n+                .withMaxDuration(5, TimeUnit.MINUTES)\n+                .withBackoff(100, 3_000, TimeUnit.MILLISECONDS))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc1MzgwMQ==", "bodyText": "\ud83d\udc4d   Okay this alleviates my rant about async and optional startup tasks. Originally I thought this was part of profile:install standard and not optional.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r454753801", "createdAt": "2020-07-15T02:32:57Z", "author": {"login": "Lambeaux"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,45 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is a reflection of the gazetteer data stored\n+in the catalog but separated from other data. This allows the core to be\n+separately reindexed much quicker than the the entire catalog core.\n+\n+====  Installing Standalone Solr Offline Gazetteer\n+\n+The Standalone Solr Offline Gazetteer is not installed by default but can be installed by running\n+`feature:install catalog-solr-offline-gazetteer`. This will install:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "906d14a9baaa01702256cc849f605c48bf43f934"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxODkzNDEx", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-451893411", "createdAt": "2020-07-20T19:24:08Z", "commit": {"oid": "91155fd7508c80bac621308e078d3ca8c98af74c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxOToyNDowOFrOG0cFKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxOToyNjo0NFrOG0cKjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYzOTIwOQ==", "bodyText": "\u2757 This has been an problem in production before since it can delay how quickly Solr nodes can recover from restarts.  It should be faster with the smaller focused collection but it is probably safer to continue to decouple the suggester rebuilds from Solr node restarts.\n\nSome lookup implementations may take a long time to build, especially with large indexes. In such cases, using buildOnCommit or buildOnOptimize, particularly with a high frequency of softCommits is not recommended; it\u2019s recommended instead to build the suggester at a lower frequency by manually issuing requests with suggest.build=true.\nhttps://lucene.apache.org/solr/guide/8_5/suggester.html#suggester-search-component-parameters", "url": "https://github.com/codice/ddf/pull/6153#discussion_r457639209", "createdAt": "2020-07-20T19:24:08Z", "author": {"login": "pklinef"}, "path": "platform/solr/solr-schema/src/main/resources/solr/conf/solrconfig.xml", "diffHunk": "@@ -1303,6 +1304,32 @@\n     </arr>\n   </requestHandler>\n \n+  <searchComponent name=\"gazetteer\" class=\"solr.SuggestComponent\">\n+    <lst name=\"suggester\">\n+      <str name=\"name\">gazetteerSuggest</str>\n+      <str name=\"lookupImpl\">BlendedInfixLookupFactory</str>\n+      <str name=\"indexPath\">gazetteer_index</str>\n+      <str name=\"dictionaryImpl\">DocumentDictionaryFactory</str>\n+      <str name=\"suggestAnalyzerFieldType\">lowercase</str>\n+      <str name=\"field\">name_txt</str>\n+      <str name=\"weightField\">sort-value_int</str>\n+      <str name=\"sortField\">population_lng</str>\n+      <str name=\"payloadField\">id_txt</str>\n+      <str name=\"buildOnStartup\">true</str>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91155fd7508c80bac621308e078d3ca8c98af74c"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYzOTk5NQ==", "bodyText": "\u270f\ufe0f This allows the suggester to be separately rebuilt much quicker than for the entire catalog collection.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r457639995", "createdAt": "2020-07-20T19:25:36Z", "author": {"login": "pklinef"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,45 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is a reflection of the gazetteer data stored\n+in the catalog but separated from other data. This allows the core to be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91155fd7508c80bac621308e078d3ca8c98af74c"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY0MDU5MA==", "bodyText": "\u270f\ufe0f Replace mentions to core to collection.", "url": "https://github.com/codice/ddf/pull/6153#discussion_r457640590", "createdAt": "2020-07-20T19:26:44Z", "author": {"login": "pklinef"}, "path": "distribution/docs/src/main/resources/content/_reference/_appReferences/mg-spatial.adoc", "diffHunk": "@@ -47,6 +47,45 @@ index again.\n \n |===\n \n+=== Standalone Solr Offline Gazetteer Feature\n+\n+The Standalone Solr Offline Gazetteer is a reflection of the gazetteer data stored\n+in the catalog but separated from other data. This allows the core to be\n+separately reindexed much quicker than the the entire catalog core.\n+\n+====  Installing Standalone Solr Offline Gazetteer\n+\n+The Standalone Solr Offline Gazetteer is not installed by default but can be installed by running\n+`feature:install catalog-solr-offline-gazetteer`. This will install:\n+\n+* The plugin that intercepts gazetteer metacard creates/updates/deletes to the catalog core", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91155fd7508c80bac621308e078d3ca8c98af74c"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bbcd74268f626a81e265ba562283cfa41708d07", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/8bbcd74268f626a81e265ba562283cfa41708d07", "committedDate": "2020-07-20T21:01:09Z", "message": "DDF-6152 Added standalone solr gazetteer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63ebfda7fd66d9d326dfe57b9f5f1c8518a1f94c", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/63ebfda7fd66d9d326dfe57b9f5f1c8518a1f94c", "committedDate": "2020-07-20T21:01:09Z", "message": "Removed schema files and updated default, fixed retryPolicy threadsafety"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1d366f93d4af5120c0ecae2e71dd9fb60280ba2", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/f1d366f93d4af5120c0ecae2e71dd9fb60280ba2", "committedDate": "2020-07-20T21:01:09Z", "message": "Added Gazetteer Constants, new solrclient ping logic, other minor updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "13e8a0f5082c55bd3d71d2b140d1737f23d2b478", "author": {"user": {"login": "rzwiefel", "name": "Ryan Zwiefelhofer"}}, "url": "https://github.com/codice/ddf/commit/13e8a0f5082c55bd3d71d2b140d1737f23d2b478", "committedDate": "2020-07-20T21:01:09Z", "message": "Update catalog/solr/catalog-solr-offline-gazetteer/src/main/java/ddf/catalog/solr/offlinegazetteer/GazetteerQueryOfflineSolr.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "276f7f7363de14fef57659175551b67c91dd8a50", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/276f7f7363de14fef57659175551b67c91dd8a50", "committedDate": "2020-07-20T21:01:09Z", "message": "Added tostring methods with correct formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "708dde3083807f084741693b181bff032fbe2ee6", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/708dde3083807f084741693b181bff032fbe2ee6", "committedDate": "2020-07-20T21:01:09Z", "message": "Added docs for standalone solr offline gazetteer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ec10a752f2780dcf91d25df1292cba1c85fc3dc", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/1ec10a752f2780dcf91d25df1292cba1c85fc3dc", "committedDate": "2020-07-20T21:01:09Z", "message": "docs phrasing updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dcc6c81cbac0a31abbe0da03dfe5e84ac87847d", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/4dcc6c81cbac0a31abbe0da03dfe5e84ac87847d", "committedDate": "2020-07-20T21:01:09Z", "message": "Extracted Request Handler constant"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "724215e39cd46ef3df1f151895d47fd3c3dbc5f8", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/724215e39cd46ef3df1f151895d47fd3c3dbc5f8", "committedDate": "2020-07-20T21:01:09Z", "message": "Extracted suggest dictionary constant"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8d9d9c6ffc88a615488238493e0f1bc5082ba5b", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/a8d9d9c6ffc88a615488238493e0f1bc5082ba5b", "committedDate": "2020-07-20T21:01:09Z", "message": "Extracted suggest dict key"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58f361fbda47b70d0b405f544474fd3537716755", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/58f361fbda47b70d0b405f544474fd3537716755", "committedDate": "2020-07-20T21:01:09Z", "message": "Optimized constants to static imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e34b98a212cfcf21cb86d8fdb2b0f8214a35d551", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/e34b98a212cfcf21cb86d8fdb2b0f8214a35d551", "committedDate": "2020-07-20T21:01:09Z", "message": "extracted more constants and renamed some things"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9562ecf9a4e44eb8f108671a0a94da4e2288ca3", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/b9562ecf9a4e44eb8f108671a0a94da4e2288ca3", "committedDate": "2020-07-20T21:01:09Z", "message": "Formatting fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c31f993abd2bb79310b42a8a58e2ff1259545b66", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/c31f993abd2bb79310b42a8a58e2ff1259545b66", "committedDate": "2020-07-20T21:01:09Z", "message": "Initial Build Gazetteer Suggester Command"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4165b616115bef75344ea29f4ee66d7ea39f99ed", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/4165b616115bef75344ea29f4ee66d7ea39f99ed", "committedDate": "2020-07-20T21:01:09Z", "message": "updated error messages and trycatch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9d6ad15d22ff9ff9261ec5cd910deacefd14915", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/c9d6ad15d22ff9ff9261ec5cd910deacefd14915", "committedDate": "2020-07-20T21:01:09Z", "message": "Updated gazetteer collection name and value"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "33595c3e282f70bddee0ee3cac9956a516cc027a", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/33595c3e282f70bddee0ee3cac9956a516cc027a", "committedDate": "2020-07-20T21:01:09Z", "message": "Added independant suggester config for gazetteer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6c2cb6bf5cee174d41efd82f5f3e58bb8ce649a", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/b6c2cb6bf5cee174d41efd82f5f3e58bb8ce649a", "committedDate": "2020-07-20T21:01:09Z", "message": "Finalized name/key migrations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1764e2bf8eab2cba2dee03bd65d3eda6fb1a2e1", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/d1764e2bf8eab2cba2dee03bd65d3eda6fb1a2e1", "committedDate": "2020-07-20T21:01:09Z", "message": "Docs updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "339f18a15df1d2a66056497182185289555f175d", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/339f18a15df1d2a66056497182185289555f175d", "committedDate": "2020-07-20T21:01:09Z", "message": "Set gazetteer suggester to not build on startup"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxOTU4OTMw", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-451958930", "createdAt": "2020-07-20T21:05:30Z", "commit": {"oid": "4e95feeda2bb6490c4c931475e98f4dfa2ca0437"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4e95feeda2bb6490c4c931475e98f4dfa2ca0437", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/4e95feeda2bb6490c4c931475e98f4dfa2ca0437", "committedDate": "2020-07-20T20:16:23Z", "message": "Set gazetteer suggester to not build on startup"}, "afterCommit": {"oid": "339f18a15df1d2a66056497182185289555f175d", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/339f18a15df1d2a66056497182185289555f175d", "committedDate": "2020-07-20T21:01:09Z", "message": "Set gazetteer suggester to not build on startup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a2de7c5b946ee027020bed71b0c8dadf4298d06", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/7a2de7c5b946ee027020bed71b0c8dadf4298d06", "committedDate": "2020-07-20T21:09:43Z", "message": "Eradicated all remaining references to core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c575837f5cade78717f3f507f7e746d69d10e704", "author": {"user": null}, "url": "https://github.com/codice/ddf/commit/c575837f5cade78717f3f507f7e746d69d10e704", "committedDate": "2020-07-20T22:20:44Z", "message": "updates pom version"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1OTk4MTk2", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-455998196", "createdAt": "2020-07-27T17:40:54Z", "commit": {"oid": "c575837f5cade78717f3f507f7e746d69d10e704"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4ODI4NzYw", "url": "https://github.com/codice/ddf/pull/6153#pullrequestreview-458828760", "createdAt": "2020-07-30T23:27:31Z", "commit": {"oid": "c575837f5cade78717f3f507f7e746d69d10e704"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 963, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}