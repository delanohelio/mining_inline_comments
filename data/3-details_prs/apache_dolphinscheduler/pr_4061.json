{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE5NzIyMzAw", "number": 4061, "title": "[Feature-4050][server] Spark task support udv inject", "bodyText": "What is the purpose of the pull request\n#4050 Spark Task support user define vars inject\nBrief change log\n\nModify SparkTask & SparkArgsUtils\n\nVerify this pull request\n\nworker/SparkTaskTest", "createdAt": "2020-11-12T08:46:31Z", "url": "https://github.com/apache/dolphinscheduler/pull/4061", "merged": true, "mergeCommit": {"oid": "1c5be9acf18cd66e4424194e7f148eac68e8ac86"}, "closed": true, "closedAt": "2020-11-17T07:24:56Z", "author": {"login": "Eights-Li"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbucSJgH2gAyNTE5NzIyMzAwOmJhZmQ5NjA5MmI3MmQwZjIzYTA0MjVhM2JkZTk3NTQ4OWE0YjY1NDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABddUXVvAFqTUzMjA3ODExNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bafd96092b72d0f23a0425a3bde975489a4b6545", "author": {"user": {"login": "Eights-Li", "name": "Yelli"}}, "url": "https://github.com/apache/dolphinscheduler/commit/bafd96092b72d0f23a0425a3bde975489a4b6545", "committedDate": "2020-11-12T08:39:43Z", "message": "#4050 spark task support udv inject"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3301fa09992aca70ada1215a703f766f96933d95", "author": {"user": {"login": "Eights-Li", "name": "Yelli"}}, "url": "https://github.com/apache/dolphinscheduler/commit/3301fa09992aca70ada1215a703f766f96933d95", "committedDate": "2020-11-12T13:25:13Z", "message": "modify spark task UT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577", "author": {"user": {"login": "Eights-Li", "name": "Yelli"}}, "url": "https://github.com/apache/dolphinscheduler/commit/749e0ae559532f8813492b2b2ce36cbc86ee3577", "committedDate": "2020-11-13T08:38:10Z", "message": "modify sparkTaskExecutionCtx"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMwNzcyMTE1", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-530772115", "createdAt": "2020-11-15T07:02:30Z", "commit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxMTkxNzgz", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-531191783", "createdAt": "2020-11-16T10:27:03Z", "commit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxMDoyNzowNFrOHzzvQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxMDoyNzowNFrOHzzvQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA4NzEwNw==", "bodyText": "magic number", "url": "https://github.com/apache/dolphinscheduler/pull/4061#discussion_r524087107", "createdAt": "2020-11-16T10:27:04Z", "author": {"login": "lenboo"}, "path": "dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/SparkArgsUtils.java", "diffHunk": "@@ -43,11 +42,11 @@\n         String deployMode = \"cluster\";\n \n         args.add(Constants.MASTER);\n-        if(StringUtils.isNotEmpty(param.getDeployMode())){\n+        if (StringUtils.isNotEmpty(param.getDeployMode())) {\n             deployMode = param.getDeployMode();\n \n         }\n-        if(!\"local\".equals(deployMode)){\n+        if (!\"local\".equals(deployMode)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxMTk1NTI0", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-531195524", "createdAt": "2020-11-16T10:31:56Z", "commit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxMDozMTo1NlrOHz0EKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxMDozMTo1NlrOHz0EKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDA5MjQ1OQ==", "bodyText": "i think it's better to return void or throw ex if null.", "url": "https://github.com/apache/dolphinscheduler/pull/4061#discussion_r524092459", "createdAt": "2020-11-16T10:31:56Z", "author": {"login": "lenboo"}, "path": "dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/spark/SparkTask.java", "diffHunk": "@@ -22,133 +23,132 @@\n import org.apache.dolphinscheduler.common.process.ResourceInfo;\n import org.apache.dolphinscheduler.common.task.AbstractParameters;\n import org.apache.dolphinscheduler.common.task.spark.SparkParameters;\n-import org.apache.dolphinscheduler.common.utils.*;\n+import org.apache.dolphinscheduler.common.utils.JSONUtils;\n import org.apache.dolphinscheduler.common.utils.ParameterUtils;\n-import org.apache.dolphinscheduler.common.utils.StringUtils;\n-import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;\n import org.apache.dolphinscheduler.dao.entity.Resource;\n+import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;\n import org.apache.dolphinscheduler.server.utils.ParamUtils;\n import org.apache.dolphinscheduler.server.utils.SparkArgsUtils;\n import org.apache.dolphinscheduler.server.worker.task.AbstractYarnTask;\n-import org.slf4j.Logger;\n \n import java.util.ArrayList;\n import java.util.List;\n import java.util.Map;\n \n+import org.slf4j.Logger;\n+\n /**\n  * spark task\n  */\n public class SparkTask extends AbstractYarnTask {\n \n-  /**\n-   * spark1 command\n-   */\n-  private static final String SPARK1_COMMAND = \"${SPARK_HOME1}/bin/spark-submit\";\n+    /**\n+     * spark1 command\n+     */\n+    private static final String SPARK1_COMMAND = \"${SPARK_HOME1}/bin/spark-submit\";\n+\n+    /**\n+     * spark2 command\n+     */\n+    private static final String SPARK2_COMMAND = \"${SPARK_HOME2}/bin/spark-submit\";\n+\n+    /**\n+     * spark parameters\n+     */\n+    private SparkParameters sparkParameters;\n+\n+    /**\n+     * taskExecutionContext\n+     */\n+    private final TaskExecutionContext sparkTaskExecutionContext;\n+\n+    public SparkTask(TaskExecutionContext taskExecutionContext, Logger logger) {\n+        super(taskExecutionContext, logger);\n+        this.sparkTaskExecutionContext = taskExecutionContext;\n+    }\n \n-  /**\n-   * spark2 command\n-   */\n-  private static final String SPARK2_COMMAND = \"${SPARK_HOME2}/bin/spark-submit\";\n+    @Override\n+    public void init() {\n \n-  /**\n-   *  spark parameters\n-   */\n-  private SparkParameters sparkParameters;\n+        logger.info(\"spark task params {}\", sparkTaskExecutionContext.getTaskParams());\n \n-  /**\n-   * taskExecutionContext\n-   */\n-  private TaskExecutionContext taskExecutionContext;\n+        sparkParameters = JSONUtils.parseObject(sparkTaskExecutionContext.getTaskParams(), SparkParameters.class);\n \n-  public SparkTask(TaskExecutionContext taskExecutionContext, Logger logger) {\n-    super(taskExecutionContext, logger);\n-    this.taskExecutionContext = taskExecutionContext;\n-  }\n+        if (null == sparkParameters) {\n+            logger.error(\"Spark params is null\");\n+            return;\n+        }\n \n-  @Override\n-  public void init() {\n+        if (!sparkParameters.checkParameters()) {\n+            throw new RuntimeException(\"spark task params is not valid\");\n+        }\n+        sparkParameters.setQueue(sparkTaskExecutionContext.getQueue());\n+        setMainJarName();\n+    }\n \n-    logger.info(\"spark task params {}\", taskExecutionContext.getTaskParams());\n+    /**\n+     * create command\n+     *\n+     * @return command\n+     */\n+    @Override\n+    protected String buildCommand() {\n+        List<String> args = new ArrayList<>();\n \n-    sparkParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), SparkParameters.class);\n+        //spark version\n+        String sparkCommand = SPARK2_COMMAND;\n \n-    if (!sparkParameters.checkParameters()) {\n-      throw new RuntimeException(\"spark task params is not valid\");\n-    }\n-    sparkParameters.setQueue(taskExecutionContext.getQueue());\n+        if (SparkVersion.SPARK1.name().equals(sparkParameters.getSparkVersion())) {\n+            sparkCommand = SPARK1_COMMAND;\n+        }\n \n-    setMainJarName();\n+        args.add(sparkCommand);\n \n-    if (StringUtils.isNotEmpty(sparkParameters.getMainArgs())) {\n-      String args = sparkParameters.getMainArgs();\n+        // other parameters\n+        args.addAll(SparkArgsUtils.buildArgs(sparkParameters));\n \n-      // replace placeholder\n-      Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams()),\n-              taskExecutionContext.getDefinedParams(),\n-              sparkParameters.getLocalParametersMap(),\n-              CommandType.of(taskExecutionContext.getCmdTypeIfComplement()),\n-              taskExecutionContext.getScheduleTime());\n+        // replace placeholder\n+        Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(sparkTaskExecutionContext.getDefinedParams()),\n+            sparkTaskExecutionContext.getDefinedParams(),\n+            sparkParameters.getLocalParametersMap(),\n+            CommandType.of(sparkTaskExecutionContext.getCmdTypeIfComplement()),\n+            sparkTaskExecutionContext.getScheduleTime());\n \n-      if (paramsMap != null ){\n-        args = ParameterUtils.convertParameterPlaceholders(args, ParamUtils.convert(paramsMap));\n-      }\n-      sparkParameters.setMainArgs(args);\n-    }\n-  }\n+        String command = null;\n \n-  /**\n-   * create command\n-   * @return command\n-   */\n-  @Override\n-  protected String buildCommand() {\n-    List<String> args = new ArrayList<>();\n+        if (null != paramsMap) {\n+            command = ParameterUtils.convertParameterPlaceholders(String.join(\" \", args), ParamUtils.convert(paramsMap));\n+        }\n \n-    //spark version\n-    String sparkCommand = SPARK2_COMMAND;\n+        logger.info(\"spark task command: {}\", command);\n \n-    if (SparkVersion.SPARK1.name().equals(sparkParameters.getSparkVersion())) {\n-      sparkCommand = SPARK1_COMMAND;\n+        return command;\n     }\n \n-    args.add(sparkCommand);\n-\n-    // other parameters\n-    args.addAll(SparkArgsUtils.buildArgs(sparkParameters));\n-\n-    String command = ParameterUtils\n-            .convertParameterPlaceholders(String.join(\" \", args), taskExecutionContext.getDefinedParams());\n-\n-    logger.info(\"spark task command : {}\", command);\n-\n-    return command;\n-  }\n-\n-  @Override\n-  protected void setMainJarName() {\n-    // main jar\n-    ResourceInfo mainJar = sparkParameters.getMainJar();\n-    if (mainJar != null) {\n-      int resourceId = mainJar.getId();\n-      String resourceName;\n-      if (resourceId == 0) {\n-        resourceName = mainJar.getRes();\n-      } else {\n-        Resource resource = processService.getResourceById(sparkParameters.getMainJar().getId());\n-        if (resource == null) {\n-          logger.error(\"resource id: {} not exist\", resourceId);\n-          throw new RuntimeException(String.format(\"resource id: %d not exist\", resourceId));\n+    @Override\n+    protected void setMainJarName() {\n+        // main jar\n+        ResourceInfo mainJar = sparkParameters.getMainJar();\n+        if (mainJar != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "originalPosition": 203}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxMTk4MjUw", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-531198250", "createdAt": "2020-11-16T10:35:32Z", "commit": {"oid": "749e0ae559532f8813492b2b2ce36cbc86ee3577"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f8250cbc6f91e113efa8413156e5c0c1b3827f5", "author": {"user": {"login": "Eights-Li", "name": "Yelli"}}, "url": "https://github.com/apache/dolphinscheduler/commit/9f8250cbc6f91e113efa8413156e5c0c1b3827f5", "committedDate": "2020-11-16T12:21:57Z", "message": "add exp for spark task get main jar method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyMDQ2MTk0", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-532046194", "createdAt": "2020-11-17T06:10:41Z", "commit": {"oid": "9f8250cbc6f91e113efa8413156e5c0c1b3827f5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyMDc4MTE0", "url": "https://github.com/apache/dolphinscheduler/pull/4061#pullrequestreview-532078114", "createdAt": "2020-11-17T07:24:38Z", "commit": {"oid": "9f8250cbc6f91e113efa8413156e5c0c1b3827f5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2356, "cost": 1, "resetAt": "2021-10-29T17:30:11Z"}}}