{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgxMDkwNTEz", "number": 1952, "title": "GH-232 RIO HDT Parser", "bodyText": "GitHub issue resolved: #232 \nBriefly describe the changes proposed in this PR:\n\nInitial (experimental, non-optimized) HDT parser\n\nThe specification itself is slightly out of date and incomplete, the goal is to be able to read files generated by HDT-It 1.0 (see also http://www.rdfhdt.org/development/)\nBasically this binary format tries to greatly reduce file size by creating dictionaries of subjects, predicates and objects, and using arrays of numeric references to encode triples.\nThe assumptions are that a) the number of different predicates are small but repeated very often, and b) objects of triples are often subject(s) of other triples (so these repetitive parts only need to be stored once)\nCurrently limited to in PlainFrontEncoded dictionaries, in SPO order, with Bitmap and Log64 arrays.\nNumber of entries probably limited to 512 M (due to reading unsigned int number of bytes, with max 4 bytes per entry), and limited by amount of memory.", "createdAt": "2020-02-27T21:48:54Z", "url": "https://github.com/eclipse/rdf4j/pull/1952", "merged": true, "mergeCommit": {"oid": "a6caa632eefeb43062da5c4ef6dc0da7c10f3fdd"}, "closed": true, "closedAt": "2020-03-03T12:14:10Z", "author": {"login": "barthanssens"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcIj03lAFqTM2NjA2NjYwMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcKAtncgBqjMwOTE3ODM4OTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDY2NjAx", "url": "https://github.com/eclipse/rdf4j/pull/1952#pullrequestreview-366066601", "createdAt": "2020-02-27T23:15:52Z", "commit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzoxNTo1M1rOFvkhOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzoyMDoyN1rOFvknCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNTcyMA==", "bodyText": "Instead of sticking these components in a separate package and making them public, can we just stick them in the rio.hdt package and make them package-private instead? If I understand correctly, they're meant for internal use only, so I'd rather not have them be part of the public API if we can avoid it.\nFWIW I'm aware that in other places of the code we do have a lot of sub-packages in these kinds of situations, but I'm personally considering this a legacy burden that we have to live with rather than a desirable pattern.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385425720", "createdAt": "2020-02-27T23:15:53Z", "author": {"login": "jeenbroekstra"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTArray.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ * HDT Array\n+ * \n+ * This part starts with a byte indicating the type of the array, followed by a byte containing the number of bits used\n+ * to encode an entry in the array, and the VByte-encoded number of entries.\n+ *\n+ * Then the 8-bit CRC, followed by the array data itself.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+--------+---------+------+------...\n+ * | type | nrbits | entries | CRC8 | data \n+ * +------+--------+---------+------+------...\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTArray extends HDTPart {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNjgyMw==", "bodyText": "Needs an extra indent :)", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385426823", "createdAt": "2020-02-27T23:19:08Z", "author": {"login": "jeenbroekstra"}, "path": "core/rio/pom.xml", "diffHunk": "@@ -24,5 +24,6 @@\n \t\t<module>trix</module>\n \t\t<module>turtle</module>\n \t\t<module>trig</module>\n+\t <module>hdt</module>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNzAyMQ==", "bodyText": "Do these three methods need to be public?", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385427021", "createdAt": "2020-02-27T23:19:51Z", "author": {"login": "jeenbroekstra"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source\n+ * reference implementation HDT-It seems to implement a slightly different version. This parser tries to be compatible\n+ * with HDT-It 1.0.\n+ * \n+ * The most important parts are the Dictionaries containing the actual values (S, P, O part of a triple), and the\n+ * Triples containing the numeric references to construct the triples.\n+ * \n+ * Since objects in one triple are often subjects in another triple, these \"shared\" parts are stored in a shared\n+ * Dictionary, which may significantly reduce the file size.\n+ * \n+ * File structure:\n+ * \n+ * <pre>\n+ * +---------------------+\n+ * | Global              |\n+ * | Header              |\n+ * | Dictionary (Shared) |\n+ * | Dictionary (S)      |\n+ * | Dictionary (P)      |\n+ * | Dictionary (O)      |    \n+ * | Triples             |\n+ * +---------------------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ * \n+ * @see <a href=\"http://www.rdfhdt.org/hdt-binary-format/\">HDT draft (2015)</a>\n+ * @see <a href=\"https://www.w3.org/Submission/2011/03/\">W3C Member Submission (2011)</a>\n+ */\n+public class HDTParser extends AbstractRDFParser {\n+\t// buffer for input stream\n+\tprivate final static int BUFLEN = 16384;\n+\n+\tprivate Map<String, String> globalProps;\n+\tprivate Map<String, String> headerProps;\n+\tprivate byte[] headerData;\n+\n+\t/**\n+\t * Creates a new HDTParser that will use a {@link SimpleValueFactory} to create RDF model objects.\n+\t */\n+\tpublic HDTParser() {\n+\t\tsuper();\n+\t}\n+\n+\t/**\n+\t * Creates a new HDTParser that will use the supplied ValueFactory to create RDF model objects.\n+\t *\n+\t * @param valueFactory A ValueFactory.\n+\t */\n+\tpublic HDTParser(ValueFactory valueFactory) {\n+\t\tsuper(valueFactory);\n+\t}\n+\n+\t@Override\n+\tpublic RDFFormat getRDFFormat() {\n+\t\treturn RDFFormat.HDT;\n+\t}\n+\n+\t@Override\n+\tpublic Collection<RioSetting<?>> getSupportedSettings() {\n+\t\tSet<RioSetting<?>> result = new HashSet<>();\n+\t\treturn result;\n+\t}\n+\n+\t/**\n+\t * Get global properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getGlobalProperties() {\n+\t\treturn globalProps;\n+\t}\n+\n+\t/**\n+\t * Get header properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getHeaderProperties() {\n+\t\treturn headerProps;\n+\t}\n+\n+\t/**\n+\t * Get header data as raw byte stream. This often includes a series of triples (in N-Triple) with additional\n+\t * metadata and statistics.\n+\t * \n+\t * @return bytes\n+\t */\n+\tpublic byte[] getHeaderData() {\n+\t\treturn headerData;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyNzIxMQ==", "bodyText": "Can these be private?", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385427211", "createdAt": "2020-02-27T23:20:27Z", "author": {"login": "jeenbroekstra"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTArray.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ * HDT Array\n+ * \n+ * This part starts with a byte indicating the type of the array, followed by a byte containing the number of bits used\n+ * to encode an entry in the array, and the VByte-encoded number of entries.\n+ *\n+ * Then the 8-bit CRC, followed by the array data itself.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+--------+---------+------+------...\n+ * | type | nrbits | entries | CRC8 | data \n+ * +------+--------+---------+------+------...\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTArray extends HDTPart {\n+\tpublic enum Type {\n+\t\tLOG64(1),\n+\t\tUINT32(2),\n+\t\tUINT64(3);\n+\t\tprivate final int value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic int getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(int value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tprotected int nrbits;\n+\tprotected int entries;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDgyMTgw", "url": "https://github.com/eclipse/rdf4j/pull/1952#pullrequestreview-366082180", "createdAt": "2020-02-27T23:57:56Z", "commit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzo1Nzo1NlrOFvlUZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwMDo0Mzo0NVrOFvmHlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzODgyMA==", "bodyText": "getBytes should include the charset to avoid relying on the user locale.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385438820", "createdAt": "2020-02-27T23:57:56Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTGlobal.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC16;\n+\n+/**\n+ * HDT Global Part.\n+ * \n+ * This part starts with <code>$HDT</code>, followed by a byte indicating the type of the part, the NULL-terminated URI\n+ * string for the format, and optionally one or more <code>key=value;</code> properties.\n+ * \n+ * These properties may include a base URI, and the name of the software that produced the HDT file.\n+ * \n+ * Then a <code>NULL</code> byte, followed by the 16-bit CRC (<code>$HDT</code> and <code>NULL</code> included)\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+--------+------+------------+------+-------+\n+ * | $HDT | type | format | NULL | key=value; | NULL | CRC16 |\n+ * +------+------+--------+------+------------+------+-------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTGlobal extends HDTPart {\n+\tpublic final static byte[] GLOBAL_FORMAT = \"<http://purl.org/HDT/hdt#HDTv1>\".getBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzODk3MQ==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385438971", "createdAt": "2020-02-27T23:58:24Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTHeader.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC16;\n+\n+/**\n+ * HDT Header Part.\n+ * \n+ * This part starts with <code>$HDT</code>, followed by a byte indicating the type of the part, the NULL-terminated\n+ * string for the format, and optionally one or more <code>key=value;</code> properties.\n+ * \n+ * Then a <code>NULL</code> byte, followed by the 16-bit CRC (<code>$HDT</code> and <code>NULL</code> included).\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+--------+------+------------+------+-------+\n+ * | $HDT | type | format | NULL | key=value; | NULL | CRC16 |\n+ * +------+------+--------+------+------------+------+-------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTHeader extends HDTPart {\n+\n+\tpublic final static byte[] HEADER_FORMAT = \"ntriples\".getBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTEwMw==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439103", "createdAt": "2020-02-27T23:58:47Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTPart.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.zip.CheckedInputStream;\n+\n+/**\n+ * Helper class for different HDT parts.\n+ * \n+ * Each part starts with <code>$HDT</code>, followed by a byte indicating the type of the part.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+\n+ * | $HDT | type |\n+ * +------+------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTPart {\n+\tpublic enum Type {\n+\t\tGLOBAL((byte) 1),\n+\t\tHEADER((byte) 2),\n+\t\tDICTIONARY((byte) 3),\n+\t\tTRIPLES((byte) 4);\n+\t\tprivate final byte value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic byte getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(byte value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] COOKIE = \"$HDT\".getBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTIxMA==", "bodyText": "getBytes should include the charset. (Ditto for the following line)", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439210", "createdAt": "2020-02-27T23:59:06Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTTriples.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC16;\n+\n+/**\n+ * HDT Triples Part.\n+ * \n+ * This part starts with <code>$HDT</code>, followed by a byte indicating the type of the part, the NULL-terminated URI\n+ * string for the format, and optionally one or more <code>key=value;</code> properties.\n+ * \n+ * These properties may include the order (SPO, SOP...), and the number of triples.\n+ * \n+ * Then a <code>NULL</code> byte, followed by the 16-bit CRC (<code>$HDT</code> and <code>NULL</code> included)\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+-----+------+------------+------+-------+\n+ * | $HDT | type | URI | NULL | key=value; | NULL | CRC16 |\n+ * +------+------+-----+------+------------+------+-------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTTriples extends HDTPart {\n+\tpublic enum Order {\n+\t\tUNKNOWN(0),\n+\t\tSPO(1),\n+\t\tSOP(2),\n+\t\tPSO(3),\n+\t\tPOS(4),\n+\t\tOSP(5),\n+\t\tOPS(6);\n+\t\tprivate final int value;\n+\n+\t\tpublic int getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Order(int value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] FORMAT_LIST = \"<http://purl.org/HDT/hdt#triplesList>\".getBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTI2Ng==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439266", "createdAt": "2020-02-27T23:59:18Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC16Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class CRC16Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC16 crc = new CRC16();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTMxMg==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439312", "createdAt": "2020-02-27T23:59:26Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC16Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class CRC16Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC16 crc = new CRC16();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());\n+\t\tassertEquals(\"CRC hello world not correct\", 0xF96A, crc.getValue());\n+\t}\n+\n+\t@Test\n+\tpublic void testHelloPerByte() {\n+\t\tCRC16 crc = new CRC16();\n+\t\tfor (byte b : \"Hello world\".getBytes()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTM1MA==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439350", "createdAt": "2020-02-27T23:59:34Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC32Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class CRC32Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC32 crc = new CRC32();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTM3OA==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439378", "createdAt": "2020-02-27T23:59:41Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC32Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class CRC32Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC32 crc = new CRC32();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());\n+\t\tassertEquals(\"CRC hello world not correct\", 0x72B51F78, crc.getValue());\n+\t}\n+\n+\t@Test\n+\tpublic void testHelloPerByte() {\n+\t\tCRC32 crc = new CRC32();\n+\t\tfor (byte b : \"Hello world\".getBytes()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTcxMA==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439710", "createdAt": "2020-02-28T00:00:47Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC8Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart.Hanssens\n+ */\n+public class CRC8Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC8 crc = new CRC8();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzOTczMw==", "bodyText": "getBytes should include the charset.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385439733", "createdAt": "2020-02-28T00:00:53Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/util/CRC8Test.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.util;\n+\n+import static org.junit.Assert.assertEquals;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart.Hanssens\n+ */\n+public class CRC8Test {\n+\t@Test\n+\tpublic void testHello() {\n+\t\tCRC8 crc = new CRC8();\n+\t\tcrc.update(\"Hello world\".getBytes(), 0, \"Hello world\".length());\n+\t\tassertEquals(\"CRC hello world not correct\", 0x41, crc.getValue());\n+\t}\n+\n+\t@Test\n+\tpublic void testHelloPerByte() {\n+\t\tCRC8 crc = new CRC8();\n+\t\tfor (byte b : \"Hello world\".getBytes()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0MDE4Ng==", "bodyText": "This seems to be the only reference to this field other than its unused accessor. Is it necessary to make this a field and not a local variable inside of this method?", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385440186", "createdAt": "2020-02-28T00:02:26Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source\n+ * reference implementation HDT-It seems to implement a slightly different version. This parser tries to be compatible\n+ * with HDT-It 1.0.\n+ * \n+ * The most important parts are the Dictionaries containing the actual values (S, P, O part of a triple), and the\n+ * Triples containing the numeric references to construct the triples.\n+ * \n+ * Since objects in one triple are often subjects in another triple, these \"shared\" parts are stored in a shared\n+ * Dictionary, which may significantly reduce the file size.\n+ * \n+ * File structure:\n+ * \n+ * <pre>\n+ * +---------------------+\n+ * | Global              |\n+ * | Header              |\n+ * | Dictionary (Shared) |\n+ * | Dictionary (S)      |\n+ * | Dictionary (P)      |\n+ * | Dictionary (O)      |    \n+ * | Triples             |\n+ * +---------------------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ * \n+ * @see <a href=\"http://www.rdfhdt.org/hdt-binary-format/\">HDT draft (2015)</a>\n+ * @see <a href=\"https://www.w3.org/Submission/2011/03/\">W3C Member Submission (2011)</a>\n+ */\n+public class HDTParser extends AbstractRDFParser {\n+\t// buffer for input stream\n+\tprivate final static int BUFLEN = 16384;\n+\n+\tprivate Map<String, String> globalProps;\n+\tprivate Map<String, String> headerProps;\n+\tprivate byte[] headerData;\n+\n+\t/**\n+\t * Creates a new HDTParser that will use a {@link SimpleValueFactory} to create RDF model objects.\n+\t */\n+\tpublic HDTParser() {\n+\t\tsuper();\n+\t}\n+\n+\t/**\n+\t * Creates a new HDTParser that will use the supplied ValueFactory to create RDF model objects.\n+\t *\n+\t * @param valueFactory A ValueFactory.\n+\t */\n+\tpublic HDTParser(ValueFactory valueFactory) {\n+\t\tsuper(valueFactory);\n+\t}\n+\n+\t@Override\n+\tpublic RDFFormat getRDFFormat() {\n+\t\treturn RDFFormat.HDT;\n+\t}\n+\n+\t@Override\n+\tpublic Collection<RioSetting<?>> getSupportedSettings() {\n+\t\tSet<RioSetting<?>> result = new HashSet<>();\n+\t\treturn result;\n+\t}\n+\n+\t/**\n+\t * Get global properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getGlobalProperties() {\n+\t\treturn globalProps;\n+\t}\n+\n+\t/**\n+\t * Get header properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getHeaderProperties() {\n+\t\treturn headerProps;\n+\t}\n+\n+\t/**\n+\t * Get header data as raw byte stream. This often includes a series of triples (in N-Triple) with additional\n+\t * metadata and statistics.\n+\t * \n+\t * @return bytes\n+\t */\n+\tpublic byte[] getHeaderData() {\n+\t\treturn headerData;\n+\t}\n+\n+\t/**\n+\t * Implementation of the <tt>parse(InputStream, String)</tt> method defined in the RDFParser interface.\n+\t *\n+\t * @param in      The InputStream from which to read the data, must not be <tt>null</tt>.\n+\t * @param baseURI The URI associated with the data in the InputStream, must not be <tt>null</tt>.\n+\t * @throws IOException              If an I/O error occurred while data was read from the InputStream.\n+\t * @throws RDFParseException        If the parser has found an unrecoverable parse error.\n+\t * @throws RDFHandlerException      If the configured statement handler encountered an unrecoverable error.\n+\t * @throws IllegalArgumentException If the supplied input stream or base URI is <tt>null</tt>.\n+\t */\n+\t@Override\n+\tpublic synchronized void parse(InputStream in, String baseURI)\n+\t\t\tthrows IOException, RDFParseException, RDFHandlerException {\n+\t\tif (in == null) {\n+\t\t\tthrow new IllegalArgumentException(\"Input stream must not be 'null'\");\n+\t\t}\n+\n+\t\tif (in instanceof FileInputStream) {\n+\t\t\t// \"TODO: use more optimized way to parse the file, eg. filechannel / membuffer\"\n+\t\t}\n+\n+\t\tHDTDictionarySection shared = null;\n+\t\tHDTDictionarySection subjects = null;\n+\t\tHDTDictionarySection predicates = null;\n+\t\tHDTDictionarySection objects = null;\n+\t\tHDTTriplesSection section = null;\n+\n+\t\t// not using try-with-resources, since the counter is needed in the catch clause (JDK8)\n+\t\tCountingInputStream bis = new CountingInputStream(new BufferedInputStream(in, BUFLEN));\n+\t\ttry {\n+\t\t\treportLocation(0, -1);\n+\t\t\tHDTGlobal global = new HDTGlobal();\n+\t\t\tglobal.parse(bis);\n+\t\t\tglobalProps = global.getProperties();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 174}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0MDQ5MA==", "bodyText": "This is the only reference, read or write, to this field.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385440490", "createdAt": "2020-02-28T00:03:35Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source\n+ * reference implementation HDT-It seems to implement a slightly different version. This parser tries to be compatible\n+ * with HDT-It 1.0.\n+ * \n+ * The most important parts are the Dictionaries containing the actual values (S, P, O part of a triple), and the\n+ * Triples containing the numeric references to construct the triples.\n+ * \n+ * Since objects in one triple are often subjects in another triple, these \"shared\" parts are stored in a shared\n+ * Dictionary, which may significantly reduce the file size.\n+ * \n+ * File structure:\n+ * \n+ * <pre>\n+ * +---------------------+\n+ * | Global              |\n+ * | Header              |\n+ * | Dictionary (Shared) |\n+ * | Dictionary (S)      |\n+ * | Dictionary (P)      |\n+ * | Dictionary (O)      |    \n+ * | Triples             |\n+ * +---------------------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ * \n+ * @see <a href=\"http://www.rdfhdt.org/hdt-binary-format/\">HDT draft (2015)</a>\n+ * @see <a href=\"https://www.w3.org/Submission/2011/03/\">W3C Member Submission (2011)</a>\n+ */\n+public class HDTParser extends AbstractRDFParser {\n+\t// buffer for input stream\n+\tprivate final static int BUFLEN = 16384;\n+\n+\tprivate Map<String, String> globalProps;\n+\tprivate Map<String, String> headerProps;\n+\tprivate byte[] headerData;\n+\n+\t/**\n+\t * Creates a new HDTParser that will use a {@link SimpleValueFactory} to create RDF model objects.\n+\t */\n+\tpublic HDTParser() {\n+\t\tsuper();\n+\t}\n+\n+\t/**\n+\t * Creates a new HDTParser that will use the supplied ValueFactory to create RDF model objects.\n+\t *\n+\t * @param valueFactory A ValueFactory.\n+\t */\n+\tpublic HDTParser(ValueFactory valueFactory) {\n+\t\tsuper(valueFactory);\n+\t}\n+\n+\t@Override\n+\tpublic RDFFormat getRDFFormat() {\n+\t\treturn RDFFormat.HDT;\n+\t}\n+\n+\t@Override\n+\tpublic Collection<RioSetting<?>> getSupportedSettings() {\n+\t\tSet<RioSetting<?>> result = new HashSet<>();\n+\t\treturn result;\n+\t}\n+\n+\t/**\n+\t * Get global properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getGlobalProperties() {\n+\t\treturn globalProps;\n+\t}\n+\n+\t/**\n+\t * Get header properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getHeaderProperties() {\n+\t\treturn headerProps;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0MDkzNA==", "bodyText": "It looks like the thread-safety issues (three publicised fields) are not necessary currently and this could infact be a thread-safe class with minimal changes.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385440934", "createdAt": "2020-02-28T00:05:07Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0MTU4NQ==", "bodyText": "It would be nice to document what is expected in terms of file contents at a fairly low level at least where it is customised and we can't directly refer to a published or draft specification as the definitive documentation for the binary format.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385441585", "createdAt": "2020-02-28T00:07:07Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NDAwMA==", "bodyText": "getBytes should have a charset specified.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385444000", "createdAt": "2020-02-28T00:15:21Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTDictionary.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC16;\n+\n+/**\n+ * HDT Dictionary Part.\n+ * \n+ * This part starts with <code>$HDT</code>, followed by a byte indicating the type of the part, the NULL-terminated URI\n+ * string for the format, and optionally one or more <code>key=value;</code> properties.\n+ * \n+ * Then a <code>NULL</code> byte, followed by the 16-bit CRC (<code>$HDT</code> and <code>NULL</code> included).\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+-----+------+------------+------+-------+\n+ * | $HDT | type | URI | NULL | key=value; | NULL | CRC16 |\n+ * +------+------+-----+------+------------+------+-------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTDictionary extends HDTPart {\n+\tpublic final static byte[] DICT_FORMAT = \"<http://purl.org/HDT/hdt#dictionaryFour>\".getBytes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NDQ2Mw==", "bodyText": "It would be useful to add to this message the dtype value that was found (for debugging purposes)", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385444463", "createdAt": "2020-02-28T00:16:48Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTDictionarySectionFactory.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * HDT DictionarySection factory.\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTDictionarySectionFactory {\n+\tpublic static HDTDictionarySection parse(InputStream is) throws IOException {\n+\t\tint dtype = is.read();\n+\t\tif (dtype != HDTDictionarySection.Type.FRONT.getValue()) {\n+\t\t\tthrow new UnsupportedOperationException(\"Dictionary section: only front encoding is supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NTI0Mg==", "bodyText": "The String(bytes, Charset) constructor should be used here to specify which Charset to use when interpreting the bytes.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385445242", "createdAt": "2020-02-28T00:19:37Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTPart.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.zip.CheckedInputStream;\n+\n+/**\n+ * Helper class for different HDT parts.\n+ * \n+ * Each part starts with <code>$HDT</code>, followed by a byte indicating the type of the part.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+\n+ * | $HDT | type |\n+ * +------+------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTPart {\n+\tpublic enum Type {\n+\t\tGLOBAL((byte) 1),\n+\t\tHEADER((byte) 2),\n+\t\tDICTIONARY((byte) 3),\n+\t\tTRIPLES((byte) 4);\n+\t\tprivate final byte value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic byte getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(byte value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] COOKIE = \"$HDT\".getBytes();\n+\n+\tprotected Map<String, String> properties;\n+\n+\t// TODO: make configurable, buffer for reading object values\n+\tprivate final static int BUFLEN = 1 * 1024 * 1024;\n+\n+\t/**\n+\t * Parse from input stream\n+\t * \n+\t * @param is\n+\t * @throws IOException\n+\t */\n+\tpublic abstract void parse(InputStream is) throws IOException;\n+\n+\t/**\n+\t * Get properties, if any.\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getProperties() {\n+\t\treturn properties;\n+\t}\n+\n+\t/**\n+\t * Check start of part for <code>$HDT</code> and the byte indicating the type\n+\t * \n+\t * @param is    input stream\n+\t * @param ctype control type\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkControl(InputStream is, HDTPart.Type ctype) throws IOException {\n+\t\tbyte[] cookie = new byte[COOKIE.length];\n+\t\tis.read(cookie);\n+\t\tif (!Arrays.equals(cookie, COOKIE)) {\n+\t\t\tthrow new IOException(\"$HDT marker not found\");\n+\t\t}\n+\n+\t\tbyte b = (byte) is.read();\n+\t\tif (b != ctype.getValue()) {\n+\t\t\tthrow new IOException(\"Expected different control info type\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Check for <code>null</code> terminated format string.\n+\t * \n+\t * @param is\n+\t * @param format\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkFormat(InputStream is, byte[] format) throws IOException {\n+\t\tbyte[] b = new byte[format.length];\n+\t\tis.read(b);\n+\t\tif (!Arrays.equals(b, format)) {\n+\t\t\tthrow new IOException(\"Unknown format, expected \" + new String(format));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NTM5Mg==", "bodyText": "The version of this String constructor with a Charset should be used.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385445392", "createdAt": "2020-02-28T00:20:09Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTPart.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.zip.CheckedInputStream;\n+\n+/**\n+ * Helper class for different HDT parts.\n+ * \n+ * Each part starts with <code>$HDT</code>, followed by a byte indicating the type of the part.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+\n+ * | $HDT | type |\n+ * +------+------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTPart {\n+\tpublic enum Type {\n+\t\tGLOBAL((byte) 1),\n+\t\tHEADER((byte) 2),\n+\t\tDICTIONARY((byte) 3),\n+\t\tTRIPLES((byte) 4);\n+\t\tprivate final byte value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic byte getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(byte value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] COOKIE = \"$HDT\".getBytes();\n+\n+\tprotected Map<String, String> properties;\n+\n+\t// TODO: make configurable, buffer for reading object values\n+\tprivate final static int BUFLEN = 1 * 1024 * 1024;\n+\n+\t/**\n+\t * Parse from input stream\n+\t * \n+\t * @param is\n+\t * @throws IOException\n+\t */\n+\tpublic abstract void parse(InputStream is) throws IOException;\n+\n+\t/**\n+\t * Get properties, if any.\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getProperties() {\n+\t\treturn properties;\n+\t}\n+\n+\t/**\n+\t * Check start of part for <code>$HDT</code> and the byte indicating the type\n+\t * \n+\t * @param is    input stream\n+\t * @param ctype control type\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkControl(InputStream is, HDTPart.Type ctype) throws IOException {\n+\t\tbyte[] cookie = new byte[COOKIE.length];\n+\t\tis.read(cookie);\n+\t\tif (!Arrays.equals(cookie, COOKIE)) {\n+\t\t\tthrow new IOException(\"$HDT marker not found\");\n+\t\t}\n+\n+\t\tbyte b = (byte) is.read();\n+\t\tif (b != ctype.getValue()) {\n+\t\t\tthrow new IOException(\"Expected different control info type\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Check for <code>null</code> terminated format string.\n+\t * \n+\t * @param is\n+\t * @param format\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkFormat(InputStream is, byte[] format) throws IOException {\n+\t\tbyte[] b = new byte[format.length];\n+\t\tis.read(b);\n+\t\tif (!Arrays.equals(b, format)) {\n+\t\t\tthrow new IOException(\"Unknown format, expected \" + new String(format));\n+\t\t}\n+\t\tis.read(); // also read null byte\n+\t}\n+\n+\t/**\n+\t * Read null terminated series of bytes\n+\t * \n+\t * @param is input stream\n+\t * @return\n+\t * @throws IOException\n+\t */\n+\tprotected static byte[] readToNull(InputStream is) throws IOException {\n+\t\tbyte[] buf = new byte[BUFLEN];\n+\t\tint len = 0;\n+\n+\t\tdo {\n+\t\t\tbuf[len] = (byte) is.read();\n+\t\t} while (buf[len] != 0b00 && ++len < BUFLEN);\n+\n+\t\tif (len == BUFLEN) {\n+\t\t\tthrow new IOException(\"Buffer for reading properties exceeded\");\n+\t\t}\n+\t\treturn Arrays.copyOf(buf, len + 1);\n+\t}\n+\n+\t/**\n+\t * Get the properties from the input stream, reading at most BUFLEN bytes. The properties are encoded as a\n+\t * <code>key=value;</code> string and must be <code>null</code> terminated.\n+\t * \n+\t * @param is input stream\n+\t * @return key,value map\n+\t * @throws IOException\n+\t */\n+\tprotected static Map<String, String> getProperties(InputStream is) throws IOException {\n+\t\treturn mapProperties(readToNull(is));\n+\t}\n+\n+\t/**\n+\t * Get properties as a key, value map\n+\t * \n+\t * @param props\n+\t * @return\n+\t */\n+\tprotected static Map<String, String> mapProperties(byte[] props) {\n+\t\tMap<String, String> map = new HashMap<>();\n+\t\tif (props == null || props.length == 0) {\n+\t\t\treturn map;\n+\t\t}\n+\n+\t\tString strs[] = new String(props, 0, props.length).split(\";\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NTc5MQ==", "bodyText": "Would be best to leave this code out of the file rather than commented until the writer is implemented (if it is used at that point)", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385445791", "createdAt": "2020-02-28T00:21:27Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTPart.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.zip.CheckedInputStream;\n+\n+/**\n+ * Helper class for different HDT parts.\n+ * \n+ * Each part starts with <code>$HDT</code>, followed by a byte indicating the type of the part.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+\n+ * | $HDT | type |\n+ * +------+------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTPart {\n+\tpublic enum Type {\n+\t\tGLOBAL((byte) 1),\n+\t\tHEADER((byte) 2),\n+\t\tDICTIONARY((byte) 3),\n+\t\tTRIPLES((byte) 4);\n+\t\tprivate final byte value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic byte getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(byte value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] COOKIE = \"$HDT\".getBytes();\n+\n+\tprotected Map<String, String> properties;\n+\n+\t// TODO: make configurable, buffer for reading object values\n+\tprivate final static int BUFLEN = 1 * 1024 * 1024;\n+\n+\t/**\n+\t * Parse from input stream\n+\t * \n+\t * @param is\n+\t * @throws IOException\n+\t */\n+\tpublic abstract void parse(InputStream is) throws IOException;\n+\n+\t/**\n+\t * Get properties, if any.\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getProperties() {\n+\t\treturn properties;\n+\t}\n+\n+\t/**\n+\t * Check start of part for <code>$HDT</code> and the byte indicating the type\n+\t * \n+\t * @param is    input stream\n+\t * @param ctype control type\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkControl(InputStream is, HDTPart.Type ctype) throws IOException {\n+\t\tbyte[] cookie = new byte[COOKIE.length];\n+\t\tis.read(cookie);\n+\t\tif (!Arrays.equals(cookie, COOKIE)) {\n+\t\t\tthrow new IOException(\"$HDT marker not found\");\n+\t\t}\n+\n+\t\tbyte b = (byte) is.read();\n+\t\tif (b != ctype.getValue()) {\n+\t\t\tthrow new IOException(\"Expected different control info type\");\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Check for <code>null</code> terminated format string.\n+\t * \n+\t * @param is\n+\t * @param format\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkFormat(InputStream is, byte[] format) throws IOException {\n+\t\tbyte[] b = new byte[format.length];\n+\t\tis.read(b);\n+\t\tif (!Arrays.equals(b, format)) {\n+\t\t\tthrow new IOException(\"Unknown format, expected \" + new String(format));\n+\t\t}\n+\t\tis.read(); // also read null byte\n+\t}\n+\n+\t/**\n+\t * Read null terminated series of bytes\n+\t * \n+\t * @param is input stream\n+\t * @return\n+\t * @throws IOException\n+\t */\n+\tprotected static byte[] readToNull(InputStream is) throws IOException {\n+\t\tbyte[] buf = new byte[BUFLEN];\n+\t\tint len = 0;\n+\n+\t\tdo {\n+\t\t\tbuf[len] = (byte) is.read();\n+\t\t} while (buf[len] != 0b00 && ++len < BUFLEN);\n+\n+\t\tif (len == BUFLEN) {\n+\t\t\tthrow new IOException(\"Buffer for reading properties exceeded\");\n+\t\t}\n+\t\treturn Arrays.copyOf(buf, len + 1);\n+\t}\n+\n+\t/**\n+\t * Get the properties from the input stream, reading at most BUFLEN bytes. The properties are encoded as a\n+\t * <code>key=value;</code> string and must be <code>null</code> terminated.\n+\t * \n+\t * @param is input stream\n+\t * @return key,value map\n+\t * @throws IOException\n+\t */\n+\tprotected static Map<String, String> getProperties(InputStream is) throws IOException {\n+\t\treturn mapProperties(readToNull(is));\n+\t}\n+\n+\t/**\n+\t * Get properties as a key, value map\n+\t * \n+\t * @param props\n+\t * @return\n+\t */\n+\tprotected static Map<String, String> mapProperties(byte[] props) {\n+\t\tMap<String, String> map = new HashMap<>();\n+\t\tif (props == null || props.length == 0) {\n+\t\t\treturn map;\n+\t\t}\n+\n+\t\tString strs[] = new String(props, 0, props.length).split(\";\");\n+\t\tfor (String str : strs) {\n+\t\t\tString prop[] = str.split(\"=\");\n+\t\t\tif (prop.length == 2) {\n+\t\t\t\tmap.put(prop[0], prop[1]);\n+\t\t\t}\n+\t\t}\n+\t\treturn map;\n+\t}\n+\n+\t/**\n+\t * Get the positive integer value from a property map. Throw an exception when the property is missing, or less than\n+\t * 1.\n+\t * \n+\t * @param props property map\n+\t * @param prop  name of the property\n+\t * @param name  display name of the property\n+\t * @return positive integer\n+\t * @throws IOException\n+\t */\n+\tprotected int getIntegerProperty(Map<String, String> props, String prop, String name) throws IOException {\n+\t\tint len = 0;\n+\n+\t\tString str = props.getOrDefault(prop, \"0\");\n+\t\ttry {\n+\t\t\tlen = Integer.parseInt(str);\n+\t\t} catch (NumberFormatException nfe) {\n+\t\t\tthrow new IOException(name + \" is not an integer: \" + str);\n+\t\t}\n+\t\tif (len < 1) {\n+\t\t\tthrow new IOException(name + \" is less than 1: \" + len);\n+\t\t}\n+\t\treturn len;\n+\t}\n+\n+\t/**\n+\t * Compare the calculated checksum to the expected one.\n+\t * \n+\t * @param cis checked input stream\n+\t * @param is  (unchecked) input stream\n+\t * @param len number of bytes of the checksum\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkCRC(CheckedInputStream cis, InputStream is, int len) throws IOException {\n+\t\tlong calc = cis.getChecksum().getValue();\n+\n+\t\tbyte[] checksum = new byte[len];\n+\t\tis.read(checksum);\n+\n+\t\tlong expect = 0L;\n+\t\t// little-endian to big-endian, e.g. HDT-It stores checksum 7635 as 0x35 0x76 (at least on x86)\n+\t\tfor (int i = len - 1; i >= 0; i--) {\n+\t\t\texpect <<= 8;\n+\t\t\texpect |= checksum[i] & 0xFF;\n+\t\t}\n+\n+\t\tif (calc != expect) {\n+\t\t\tthrow new IOException(\"CRC does not match: calculated \" +\n+\t\t\t\t\tLong.toHexString(calc) + \" instead of \" + Long.toHexString(expect));\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Writes the CRC to the output stream\n+\t * \n+\t * @param cos checked output stream\n+\t * @param os  output stream\n+\t * @param len number of bytes of the checksum\n+\t * @throws IOException\n+\t */\n+\t/*\n+\t * protected static void writeCRC(CheckedOutputStream cos, OutputStream os, int len) throws IOException { long calc", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NjMwNw==", "bodyText": "Was this intended to be a @Test?", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385446307", "createdAt": "2020-02-28T00:23:12Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/test/java/org/eclipse/rdf4j/rio/hdt/HDTParserTest.java", "diffHunk": "@@ -0,0 +1,59 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+\n+import org.eclipse.rdf4j.model.Model;\n+import org.eclipse.rdf4j.model.impl.LinkedHashModel;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFParser;\n+import org.eclipse.rdf4j.rio.Rio;\n+import org.eclipse.rdf4j.rio.helpers.StatementCollector;\n+\n+import static org.junit.Assert.*;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class HDTParserTest {\n+\tprivate RDFParser parser;\n+\n+\t@Before\n+\tpublic void setUp() throws Exception {\n+\t\tparser = Rio.createParser(RDFFormat.HDT);\n+\t\tparser.setParseLocationListener((line, col) -> System.err.println(\"byte \" + line));\n+\t}\n+\n+\t@Test\n+\tpublic void parseSimple() {\n+\t\tModel m = new LinkedHashModel();\n+\n+\t\ttry (InputStream is = HDTParserTest.class.getResourceAsStream(\"/test.hdt\")) {\n+\t\t\tparser.setRDFHandler(new StatementCollector(m));\n+\t\t\tparser.parse(is, \"\");\n+\t\t\tassertEquals(\"Number of statements does not match\", 43, m.size());\n+\t\t} catch (Exception e) {\n+\t\t\tfail(e.getMessage());\n+\t\t}\n+\t}\n+\n+\tpublic void parseSimpleHeaderData() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0NzIwOA==", "bodyText": "The generics type or diamond-syntax is missing here. Can use ArrayList<>(nrstrings) rather than actually putting the type in.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385447208", "createdAt": "2020-02-28T00:26:23Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTDictionarySectionPFC.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC32;\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ * HDT DictionarySection Plain Front Coding.\n+ * \n+ * This part starts with a byte indicating the type of the dictionary section, followed by the VByte-encoded number of\n+ * strings, the VByte-encoded buffer size and the VByte-encoded buffer length.\n+ *\n+ * Then the 8-bit CRC.\n+ * \n+ * Followed by an array and one or more buffers, and the 32-bit CRC calculated over the index and the buffers.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+-----------+---------+-------+------+-------+--------+...+-------+\n+ * | type | nrstrings | bufsize | array | CRC8 | index | buffer |...| CRC32 | \n+ * +------+-----------+---------+-------+------+-------+--------+...+-------+\n+ * </pre>\n+ * \n+ * Each buffer starts with a full string, followed by a maximum of <code>bufsize</code> - 1 pair of a VByte-encoded\n+ * number of characters this string has in common with the _previous_ string, and the (different) suffix.\n+ * \n+ * E.g. <code>abcdef 2 gh 3 ij</code> will result in <code>abcde, abgh, abgij</code>.\n+ * \n+ * Buffer structure:\n+ * \n+ * <pre>\n+ * +--------+--------+--------+...+--------+--------+\n+ * | string | common | suffix |...| common | suffix |\n+ * +--------+--------+--------+...+--------+--------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTDictionarySectionPFC extends HDTDictionarySection {\n+\tprivate ArrayList<byte[]> arr;\n+\tprivate int nrstrings;\n+\tprivate long buflen;\n+\tprivate int bufsize;\n+\n+\t@Override\n+\tpublic int size() {\n+\t\treturn nrstrings;\n+\t}\n+\n+\t@Override\n+\tpublic byte[] get(int i) {\n+\t\treturn arr.get(i - 1);\n+\t}\n+\n+\t@Override\n+\tpublic void parse(InputStream is) throws IOException {\n+\t\tCRC8 crc8 = new CRC8();\n+\t\tcrc8.update((byte) HDTDictionarySection.Type.FRONT.getValue());\n+\t\tCheckedInputStream cis = new CheckedInputStream(is, crc8);\n+\n+\t\tlong val = VByte.decode(cis);\n+\t\tif (nrstrings > Integer.MAX_VALUE) {\n+\t\t\tthrow new UnsupportedOperationException(\"Maximum number of strings in dictionary exceeded: \" + val);\n+\t\t}\n+\t\tnrstrings = (int) val;\n+\n+\t\tbuflen = VByte.decode(cis);\n+\n+\t\tval = VByte.decode(cis);\n+\t\tif (val > Integer.MAX_VALUE) {\n+\t\t\tthrow new UnsupportedOperationException(\"Maximum number of bufsize in dictionary exceeded: \" + val);\n+\t\t}\n+\t\tbufsize = (int) val;\n+\n+\t\tcheckCRC(cis, is, 1);\n+\n+\t\tHDTArray ha = HDTArrayFactory.parse(is);\n+\t\tha.parse(is);\n+\n+\t\tcis = new CheckedInputStream(is, new CRC32());\n+\t\tarr = new ArrayList(nrstrings);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0ODU1Mw==", "bodyText": "You can fix this by wrapping the InputStream in a non-closeable wrapper. Not familiar with CheckedInputStream to know what the implications of not closing it are.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385448553", "createdAt": "2020-02-28T00:31:26Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTArray.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ * HDT Array\n+ * \n+ * This part starts with a byte indicating the type of the array, followed by a byte containing the number of bits used\n+ * to encode an entry in the array, and the VByte-encoded number of entries.\n+ *\n+ * Then the 8-bit CRC, followed by the array data itself.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+--------+---------+------+------...\n+ * | type | nrbits | entries | CRC8 | data \n+ * +------+--------+---------+------+------...\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTArray extends HDTPart {\n+\tpublic enum Type {\n+\t\tLOG64(1),\n+\t\tUINT32(2),\n+\t\tUINT64(3);\n+\t\tprivate final int value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic int getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(int value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tprotected int nrbits;\n+\tprotected int entries;\n+\n+\t/**\n+\t * Get the type of the array\n+\t * \n+\t * @return byte\n+\t */\n+\tpublic abstract int getType();\n+\n+\t/**\n+\t * Get number of bits used to encode an entry\n+\t * \n+\t * @return positive integer value\n+\t */\n+\tpublic int getNrBits() {\n+\t\treturn nrbits;\n+\t}\n+\n+\t/**\n+\t * Get number of entries in this array\n+\t * \n+\t * @return positive integer value\n+\t */\n+\tpublic int size() {\n+\t\treturn entries;\n+\t}\n+\n+\t/**\n+\t * Get entry from this array\n+\t * \n+\t * @param i zero-based index\n+\t * @return entry\n+\t */\n+\tpublic abstract int get(int i);\n+\n+\t@Override\n+\tpublic void parse(InputStream is) throws IOException {\n+\t\tCRC8 crc8 = new CRC8();\n+\t\tcrc8.update(getType());\n+\t\tCheckedInputStream cis = new CheckedInputStream(is, crc8);\n+\n+\t\tnrbits = cis.read();\n+\t\tlong l = VByte.decode(cis);\n+\t\tif (l > Integer.MAX_VALUE) {\n+\t\t\tthrow new UnsupportedOperationException(\"Maximum number of bytes in array exceeded: \" + l);\n+\t\t}\n+\t\tentries = (int) l;\n+\n+\t\tcheckCRC(cis, is, 1);\n+\t\t// don't close CheckedInputStream, or it will close the underlying inputstream", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0ODgyOA==", "bodyText": "The Charset version of this constructor should be used here (even if lang tags are always assumed to be simple-ASCII, we shouldn't leave these things to the users locale)", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385448828", "createdAt": "2020-02-28T00:32:35Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source\n+ * reference implementation HDT-It seems to implement a slightly different version. This parser tries to be compatible\n+ * with HDT-It 1.0.\n+ * \n+ * The most important parts are the Dictionaries containing the actual values (S, P, O part of a triple), and the\n+ * Triples containing the numeric references to construct the triples.\n+ * \n+ * Since objects in one triple are often subjects in another triple, these \"shared\" parts are stored in a shared\n+ * Dictionary, which may significantly reduce the file size.\n+ * \n+ * File structure:\n+ * \n+ * <pre>\n+ * +---------------------+\n+ * | Global              |\n+ * | Header              |\n+ * | Dictionary (Shared) |\n+ * | Dictionary (S)      |\n+ * | Dictionary (P)      |\n+ * | Dictionary (O)      |    \n+ * | Triples             |\n+ * +---------------------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ * \n+ * @see <a href=\"http://www.rdfhdt.org/hdt-binary-format/\">HDT draft (2015)</a>\n+ * @see <a href=\"https://www.w3.org/Submission/2011/03/\">W3C Member Submission (2011)</a>\n+ */\n+public class HDTParser extends AbstractRDFParser {\n+\t// buffer for input stream\n+\tprivate final static int BUFLEN = 16384;\n+\n+\tprivate Map<String, String> globalProps;\n+\tprivate Map<String, String> headerProps;\n+\tprivate byte[] headerData;\n+\n+\t/**\n+\t * Creates a new HDTParser that will use a {@link SimpleValueFactory} to create RDF model objects.\n+\t */\n+\tpublic HDTParser() {\n+\t\tsuper();\n+\t}\n+\n+\t/**\n+\t * Creates a new HDTParser that will use the supplied ValueFactory to create RDF model objects.\n+\t *\n+\t * @param valueFactory A ValueFactory.\n+\t */\n+\tpublic HDTParser(ValueFactory valueFactory) {\n+\t\tsuper(valueFactory);\n+\t}\n+\n+\t@Override\n+\tpublic RDFFormat getRDFFormat() {\n+\t\treturn RDFFormat.HDT;\n+\t}\n+\n+\t@Override\n+\tpublic Collection<RioSetting<?>> getSupportedSettings() {\n+\t\tSet<RioSetting<?>> result = new HashSet<>();\n+\t\treturn result;\n+\t}\n+\n+\t/**\n+\t * Get global properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getGlobalProperties() {\n+\t\treturn globalProps;\n+\t}\n+\n+\t/**\n+\t * Get header properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getHeaderProperties() {\n+\t\treturn headerProps;\n+\t}\n+\n+\t/**\n+\t * Get header data as raw byte stream. This often includes a series of triples (in N-Triple) with additional\n+\t * metadata and statistics.\n+\t * \n+\t * @return bytes\n+\t */\n+\tpublic byte[] getHeaderData() {\n+\t\treturn headerData;\n+\t}\n+\n+\t/**\n+\t * Implementation of the <tt>parse(InputStream, String)</tt> method defined in the RDFParser interface.\n+\t *\n+\t * @param in      The InputStream from which to read the data, must not be <tt>null</tt>.\n+\t * @param baseURI The URI associated with the data in the InputStream, must not be <tt>null</tt>.\n+\t * @throws IOException              If an I/O error occurred while data was read from the InputStream.\n+\t * @throws RDFParseException        If the parser has found an unrecoverable parse error.\n+\t * @throws RDFHandlerException      If the configured statement handler encountered an unrecoverable error.\n+\t * @throws IllegalArgumentException If the supplied input stream or base URI is <tt>null</tt>.\n+\t */\n+\t@Override\n+\tpublic synchronized void parse(InputStream in, String baseURI)\n+\t\t\tthrows IOException, RDFParseException, RDFHandlerException {\n+\t\tif (in == null) {\n+\t\t\tthrow new IllegalArgumentException(\"Input stream must not be 'null'\");\n+\t\t}\n+\n+\t\tif (in instanceof FileInputStream) {\n+\t\t\t// \"TODO: use more optimized way to parse the file, eg. filechannel / membuffer\"\n+\t\t}\n+\n+\t\tHDTDictionarySection shared = null;\n+\t\tHDTDictionarySection subjects = null;\n+\t\tHDTDictionarySection predicates = null;\n+\t\tHDTDictionarySection objects = null;\n+\t\tHDTTriplesSection section = null;\n+\n+\t\t// not using try-with-resources, since the counter is needed in the catch clause (JDK8)\n+\t\tCountingInputStream bis = new CountingInputStream(new BufferedInputStream(in, BUFLEN));\n+\t\ttry {\n+\t\t\treportLocation(0, -1);\n+\t\t\tHDTGlobal global = new HDTGlobal();\n+\t\t\tglobal.parse(bis);\n+\t\t\tglobalProps = global.getProperties();\n+\t\t\tString base = globalProps.getOrDefault(HDTGlobal.GLOBAL_BASEURI, \"\");\n+\t\t\tif (!base.isEmpty()) {\n+\t\t\t\tsetBaseURI(base);\n+\t\t\t}\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tHDTHeader header = new HDTHeader();\n+\t\t\theader.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tnew HDTDictionary().parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tshared = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tshared.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tsubjects = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tsubjects.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tpredicates = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tpredicates.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tobjects = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tobjects.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tHDTTriples triples = new HDTTriples();\n+\t\t\ttriples.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tsection = HDTTriplesSectionFactory.parse(new String(HDTTriples.FORMAT_BITMAP));\n+\t\t\tsection.parse(bis);\n+\t\t} catch (IOException ioe) {\n+\t\t\treportFatalError(ioe.getMessage(), bis.getCount(), -1);\n+\t\t} finally {\n+\t\t\tbis.close();\n+\t\t}\n+\n+\t\tif (rdfHandler != null) {\n+\t\t\trdfHandler.startRDF();\n+\t\t}\n+\n+\t\tint cnt = 0;\n+\t\tint size = shared.size();\n+\n+\t\twhile (section.hasNext()) {\n+\t\t\tint[] t = section.next();\n+\t\t\tbyte[] s = getSO(t[0], size, shared, subjects);\n+\t\t\tbyte[] p = predicates.get(t[1]);\n+\t\t\tbyte[] o = getSO(t[2], size, shared, objects);\n+\n+\t\t\tStatement stmt = valueFactory.createStatement(createSubject(s), createPredicate(p), createObject(o));\n+\n+\t\t\tif (rdfHandler != null) {\n+\t\t\t\trdfHandler.handleStatement(stmt);\n+\t\t\t}\n+\t\t}\n+\t\tif (rdfHandler != null) {\n+\t\t\trdfHandler.endRDF();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Not supported, since HDT is a binary format.\n+\t */\n+\t@Override\n+\tpublic synchronized void parse(Reader reader, String baseURI)\n+\t\t\tthrows IOException, RDFParseException, RDFHandlerException {\n+\t\tthrow new UnsupportedOperationException(\"HDT is binary, text readers not supported.\");\n+\t}\n+\n+\t/**\n+\t * Get part of triple from shared HDT Dictionary or (if not found) from specific HDT Dictionary\n+\t * \n+\t * @param pos    position\n+\t * @param size   size of shared Dictionary\n+\t * @param shared shared Dictionary\n+\t * @param other  specific Dictionary\n+\t * @return subject or object\n+\t */\n+\tprivate byte[] getSO(int pos, int size, HDTDictionarySection shared, HDTDictionarySection other) {\n+\t\treturn (pos <= size) ? shared.get(pos) : other.get(pos - size);\n+\t}\n+\n+\tprivate boolean isBNodeID(byte[] b) {\n+\t\t// HDT-It generates \"genid\" for blank nodes in RDF/XML\n+\t\treturn (b[0] == '_' || (b.length > 5 && b[0] == 'g' && b[1] == 'e'));\n+\t}\n+\n+\t/**\n+\t * Create subject IRI or blank node\n+\t * \n+\t * @param b byte buffer\n+\t * @return IRI or blank node\n+\t */\n+\tprivate Resource createSubject(byte[] b) {\n+\t\tString str = new String(b, StandardCharsets.UTF_8);\n+\t\treturn isBNodeID(b) ? valueFactory.createBNode(str) : valueFactory.createIRI(str);\n+\t}\n+\n+\t/**\n+\t * Create predicate IRI\n+\t * \n+\t * @param b byte buffer\n+\t * @return IRI\n+\t */\n+\tprivate IRI createPredicate(byte[] b) {\n+\t\treturn valueFactory.createIRI(new String(b, StandardCharsets.UTF_8));\n+\t}\n+\n+\t/**\n+\t * Create object (typed) literal, IRI or blank node\n+\t * \n+\t * @param b byte buffer\n+\t * @return literal, IRI or blank node\n+\t */\n+\tprivate Value createObject(byte[] b) {\n+\t\tif (b[0] == '\"') {\n+\t\t\tint i = b.length - 1;\n+\t\t\tfor (; i > 1 && b[i] != '\"'; i--) {\n+\t\t\t\tif (b[i] == '@') {\n+\t\t\t\t\tString lang = new String(b, i + 1, b.length - i - 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 299}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ0ODk0NQ==", "bodyText": "The Charset version of this constructor should be used here.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385448945", "createdAt": "2020-02-28T00:33:03Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/HDTParser.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt;\n+\n+import java.io.BufferedInputStream;\n+import java.io.FileInputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.commons.io.input.CountingInputStream;\n+\n+import org.eclipse.rdf4j.model.IRI;\n+import org.eclipse.rdf4j.model.Resource;\n+import org.eclipse.rdf4j.model.Statement;\n+import org.eclipse.rdf4j.model.Value;\n+import org.eclipse.rdf4j.model.ValueFactory;\n+import org.eclipse.rdf4j.model.impl.SimpleValueFactory;\n+\n+import org.eclipse.rdf4j.rio.RDFFormat;\n+import org.eclipse.rdf4j.rio.RDFHandlerException;\n+import org.eclipse.rdf4j.rio.RDFParseException;\n+import org.eclipse.rdf4j.rio.RioSetting;\n+\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionary;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTDictionarySectionFactory;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTGlobal;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTHeader;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriples;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSection;\n+import org.eclipse.rdf4j.rio.hdt.part.HDTTriplesSectionFactory;\n+\n+import org.eclipse.rdf4j.rio.helpers.AbstractRDFParser;\n+\n+/**\n+ * RDF parser for HDT v1.0 files. This parser is not thread-safe, therefore its public methods are synchronized.\n+ * \n+ * Unfortunately the draft specification is not entirely clear and probably slightly out of date, since the open source\n+ * reference implementation HDT-It seems to implement a slightly different version. This parser tries to be compatible\n+ * with HDT-It 1.0.\n+ * \n+ * The most important parts are the Dictionaries containing the actual values (S, P, O part of a triple), and the\n+ * Triples containing the numeric references to construct the triples.\n+ * \n+ * Since objects in one triple are often subjects in another triple, these \"shared\" parts are stored in a shared\n+ * Dictionary, which may significantly reduce the file size.\n+ * \n+ * File structure:\n+ * \n+ * <pre>\n+ * +---------------------+\n+ * | Global              |\n+ * | Header              |\n+ * | Dictionary (Shared) |\n+ * | Dictionary (S)      |\n+ * | Dictionary (P)      |\n+ * | Dictionary (O)      |    \n+ * | Triples             |\n+ * +---------------------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ * \n+ * @see <a href=\"http://www.rdfhdt.org/hdt-binary-format/\">HDT draft (2015)</a>\n+ * @see <a href=\"https://www.w3.org/Submission/2011/03/\">W3C Member Submission (2011)</a>\n+ */\n+public class HDTParser extends AbstractRDFParser {\n+\t// buffer for input stream\n+\tprivate final static int BUFLEN = 16384;\n+\n+\tprivate Map<String, String> globalProps;\n+\tprivate Map<String, String> headerProps;\n+\tprivate byte[] headerData;\n+\n+\t/**\n+\t * Creates a new HDTParser that will use a {@link SimpleValueFactory} to create RDF model objects.\n+\t */\n+\tpublic HDTParser() {\n+\t\tsuper();\n+\t}\n+\n+\t/**\n+\t * Creates a new HDTParser that will use the supplied ValueFactory to create RDF model objects.\n+\t *\n+\t * @param valueFactory A ValueFactory.\n+\t */\n+\tpublic HDTParser(ValueFactory valueFactory) {\n+\t\tsuper(valueFactory);\n+\t}\n+\n+\t@Override\n+\tpublic RDFFormat getRDFFormat() {\n+\t\treturn RDFFormat.HDT;\n+\t}\n+\n+\t@Override\n+\tpublic Collection<RioSetting<?>> getSupportedSettings() {\n+\t\tSet<RioSetting<?>> result = new HashSet<>();\n+\t\treturn result;\n+\t}\n+\n+\t/**\n+\t * Get global properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getGlobalProperties() {\n+\t\treturn globalProps;\n+\t}\n+\n+\t/**\n+\t * Get header properties\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getHeaderProperties() {\n+\t\treturn headerProps;\n+\t}\n+\n+\t/**\n+\t * Get header data as raw byte stream. This often includes a series of triples (in N-Triple) with additional\n+\t * metadata and statistics.\n+\t * \n+\t * @return bytes\n+\t */\n+\tpublic byte[] getHeaderData() {\n+\t\treturn headerData;\n+\t}\n+\n+\t/**\n+\t * Implementation of the <tt>parse(InputStream, String)</tt> method defined in the RDFParser interface.\n+\t *\n+\t * @param in      The InputStream from which to read the data, must not be <tt>null</tt>.\n+\t * @param baseURI The URI associated with the data in the InputStream, must not be <tt>null</tt>.\n+\t * @throws IOException              If an I/O error occurred while data was read from the InputStream.\n+\t * @throws RDFParseException        If the parser has found an unrecoverable parse error.\n+\t * @throws RDFHandlerException      If the configured statement handler encountered an unrecoverable error.\n+\t * @throws IllegalArgumentException If the supplied input stream or base URI is <tt>null</tt>.\n+\t */\n+\t@Override\n+\tpublic synchronized void parse(InputStream in, String baseURI)\n+\t\t\tthrows IOException, RDFParseException, RDFHandlerException {\n+\t\tif (in == null) {\n+\t\t\tthrow new IllegalArgumentException(\"Input stream must not be 'null'\");\n+\t\t}\n+\n+\t\tif (in instanceof FileInputStream) {\n+\t\t\t// \"TODO: use more optimized way to parse the file, eg. filechannel / membuffer\"\n+\t\t}\n+\n+\t\tHDTDictionarySection shared = null;\n+\t\tHDTDictionarySection subjects = null;\n+\t\tHDTDictionarySection predicates = null;\n+\t\tHDTDictionarySection objects = null;\n+\t\tHDTTriplesSection section = null;\n+\n+\t\t// not using try-with-resources, since the counter is needed in the catch clause (JDK8)\n+\t\tCountingInputStream bis = new CountingInputStream(new BufferedInputStream(in, BUFLEN));\n+\t\ttry {\n+\t\t\treportLocation(0, -1);\n+\t\t\tHDTGlobal global = new HDTGlobal();\n+\t\t\tglobal.parse(bis);\n+\t\t\tglobalProps = global.getProperties();\n+\t\t\tString base = globalProps.getOrDefault(HDTGlobal.GLOBAL_BASEURI, \"\");\n+\t\t\tif (!base.isEmpty()) {\n+\t\t\t\tsetBaseURI(base);\n+\t\t\t}\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tHDTHeader header = new HDTHeader();\n+\t\t\theader.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tnew HDTDictionary().parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tshared = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tshared.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tsubjects = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tsubjects.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tpredicates = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tpredicates.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tobjects = HDTDictionarySectionFactory.parse(bis);\n+\t\t\tobjects.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tHDTTriples triples = new HDTTriples();\n+\t\t\ttriples.parse(bis);\n+\n+\t\t\treportLocation(bis.getByteCount(), -1);\n+\t\t\tsection = HDTTriplesSectionFactory.parse(new String(HDTTriples.FORMAT_BITMAP));\n+\t\t\tsection.parse(bis);\n+\t\t} catch (IOException ioe) {\n+\t\t\treportFatalError(ioe.getMessage(), bis.getCount(), -1);\n+\t\t} finally {\n+\t\t\tbis.close();\n+\t\t}\n+\n+\t\tif (rdfHandler != null) {\n+\t\t\trdfHandler.startRDF();\n+\t\t}\n+\n+\t\tint cnt = 0;\n+\t\tint size = shared.size();\n+\n+\t\twhile (section.hasNext()) {\n+\t\t\tint[] t = section.next();\n+\t\t\tbyte[] s = getSO(t[0], size, shared, subjects);\n+\t\t\tbyte[] p = predicates.get(t[1]);\n+\t\t\tbyte[] o = getSO(t[2], size, shared, objects);\n+\n+\t\t\tStatement stmt = valueFactory.createStatement(createSubject(s), createPredicate(p), createObject(o));\n+\n+\t\t\tif (rdfHandler != null) {\n+\t\t\t\trdfHandler.handleStatement(stmt);\n+\t\t\t}\n+\t\t}\n+\t\tif (rdfHandler != null) {\n+\t\t\trdfHandler.endRDF();\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Not supported, since HDT is a binary format.\n+\t */\n+\t@Override\n+\tpublic synchronized void parse(Reader reader, String baseURI)\n+\t\t\tthrows IOException, RDFParseException, RDFHandlerException {\n+\t\tthrow new UnsupportedOperationException(\"HDT is binary, text readers not supported.\");\n+\t}\n+\n+\t/**\n+\t * Get part of triple from shared HDT Dictionary or (if not found) from specific HDT Dictionary\n+\t * \n+\t * @param pos    position\n+\t * @param size   size of shared Dictionary\n+\t * @param shared shared Dictionary\n+\t * @param other  specific Dictionary\n+\t * @return subject or object\n+\t */\n+\tprivate byte[] getSO(int pos, int size, HDTDictionarySection shared, HDTDictionarySection other) {\n+\t\treturn (pos <= size) ? shared.get(pos) : other.get(pos - size);\n+\t}\n+\n+\tprivate boolean isBNodeID(byte[] b) {\n+\t\t// HDT-It generates \"genid\" for blank nodes in RDF/XML\n+\t\treturn (b[0] == '_' || (b.length > 5 && b[0] == 'g' && b[1] == 'e'));\n+\t}\n+\n+\t/**\n+\t * Create subject IRI or blank node\n+\t * \n+\t * @param b byte buffer\n+\t * @return IRI or blank node\n+\t */\n+\tprivate Resource createSubject(byte[] b) {\n+\t\tString str = new String(b, StandardCharsets.UTF_8);\n+\t\treturn isBNodeID(b) ? valueFactory.createBNode(str) : valueFactory.createIRI(str);\n+\t}\n+\n+\t/**\n+\t * Create predicate IRI\n+\t * \n+\t * @param b byte buffer\n+\t * @return IRI\n+\t */\n+\tprivate IRI createPredicate(byte[] b) {\n+\t\treturn valueFactory.createIRI(new String(b, StandardCharsets.UTF_8));\n+\t}\n+\n+\t/**\n+\t * Create object (typed) literal, IRI or blank node\n+\t * \n+\t * @param b byte buffer\n+\t * @return literal, IRI or blank node\n+\t */\n+\tprivate Value createObject(byte[] b) {\n+\t\tif (b[0] == '\"') {\n+\t\t\tint i = b.length - 1;\n+\t\t\tfor (; i > 1 && b[i] != '\"'; i--) {\n+\t\t\t\tif (b[i] == '@') {\n+\t\t\t\t\tString lang = new String(b, i + 1, b.length - i - 1);\n+\t\t\t\t\tvalueFactory.createLiteral(new String(b, 1, i - 2, StandardCharsets.UTF_8), lang);\n+\t\t\t\t} else if (b[i] == '^') {\n+\t\t\t\t\tIRI datatype = valueFactory.createIRI(new String(b, i + i, b.length - i - 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 302}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MDIyNQ==", "bodyText": "Not clear why this is being round-tripped. There should be another variable with the String version to directly compare to.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385450225", "createdAt": "2020-02-28T00:37:53Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTTriplesSectionFactory.java", "diffHunk": "@@ -0,0 +1,25 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+\n+/**\n+ * HDT Array factory.\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTTriplesSectionFactory {\n+\n+\tpublic static HDTTriplesSection parse(String str) throws IOException {\n+\t\tif (!str.equals(new String(HDTTriples.FORMAT_BITMAP))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MDQwMQ==", "bodyText": "The str variable should be included in this exception message for debugging.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385450401", "createdAt": "2020-02-28T00:38:17Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTTriplesSectionFactory.java", "diffHunk": "@@ -0,0 +1,25 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+\n+/**\n+ * HDT Array factory.\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTTriplesSectionFactory {\n+\n+\tpublic static HDTTriplesSection parse(String str) throws IOException {\n+\t\tif (!str.equals(new String(HDTTriples.FORMAT_BITMAP))) {\n+\t\t\tthrow new UnsupportedOperationException(\"Triples section: only bitmap encoding is supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MDc1Nw==", "bodyText": "The byte value that was found should be included in this message.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385450757", "createdAt": "2020-02-28T00:39:28Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTPart.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.zip.CheckedInputStream;\n+\n+/**\n+ * Helper class for different HDT parts.\n+ * \n+ * Each part starts with <code>$HDT</code>, followed by a byte indicating the type of the part.\n+ * \n+ * Structure:\n+ * \n+ * <pre>\n+ * +------+------+\n+ * | $HDT | type |\n+ * +------+------+\n+ * </pre>\n+ * \n+ * @author Bart Hanssens\n+ */\n+public abstract class HDTPart {\n+\tpublic enum Type {\n+\t\tGLOBAL((byte) 1),\n+\t\tHEADER((byte) 2),\n+\t\tDICTIONARY((byte) 3),\n+\t\tTRIPLES((byte) 4);\n+\t\tprivate final byte value;\n+\n+\t\t/**\n+\t\t * Get value associated with this type\n+\t\t * \n+\t\t * @return value 1,2 or 3\n+\t\t */\n+\t\tpublic byte getValue() {\n+\t\t\treturn value;\n+\t\t}\n+\n+\t\tprivate Type(byte value) {\n+\t\t\tthis.value = value;\n+\t\t}\n+\t}\n+\n+\tpublic final static byte[] COOKIE = \"$HDT\".getBytes();\n+\n+\tprotected Map<String, String> properties;\n+\n+\t// TODO: make configurable, buffer for reading object values\n+\tprivate final static int BUFLEN = 1 * 1024 * 1024;\n+\n+\t/**\n+\t * Parse from input stream\n+\t * \n+\t * @param is\n+\t * @throws IOException\n+\t */\n+\tpublic abstract void parse(InputStream is) throws IOException;\n+\n+\t/**\n+\t * Get properties, if any.\n+\t * \n+\t * @return key,value map\n+\t */\n+\tpublic Map<String, String> getProperties() {\n+\t\treturn properties;\n+\t}\n+\n+\t/**\n+\t * Check start of part for <code>$HDT</code> and the byte indicating the type\n+\t * \n+\t * @param is    input stream\n+\t * @param ctype control type\n+\t * @throws IOException\n+\t */\n+\tprotected static void checkControl(InputStream is, HDTPart.Type ctype) throws IOException {\n+\t\tbyte[] cookie = new byte[COOKIE.length];\n+\t\tis.read(cookie);\n+\t\tif (!Arrays.equals(cookie, COOKIE)) {\n+\t\t\tthrow new IOException(\"$HDT marker not found\");\n+\t\t}\n+\n+\t\tbyte b = (byte) is.read();\n+\t\tif (b != ctype.getValue()) {\n+\t\t\tthrow new IOException(\"Expected different control info type\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MTEwNQ==", "bodyText": "dtype should be included in this message for debugging purposes.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385451105", "createdAt": "2020-02-28T00:40:44Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTBitmap.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC32;\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class HDTBitmap extends HDTPart {\n+\tpublic final static int BITMAP1 = 1;\n+\n+\tprivate int bits;\n+\tprivate byte[] buffer;\n+\n+\t/**\n+\t * Get bit\n+\t * \n+\t * @param i\n+\t * @return 0 or 1\n+\t */\n+\tpublic int get(int i) {\n+\t\tassert i < bits : \"Bitmap out of range\";\n+\n+\t\tint bytePos = i / 8;\n+\t\tint bitPos = i % 8;\n+\n+\t\tbyte b = buffer[bytePos];\n+\t\treturn ((b & 0xFF) >> bitPos) & 1;\n+\t}\n+\n+\t/**\n+\t * Get number of entries in this bitmap\n+\t * \n+\t * @return positive integer value\n+\t */\n+\tpublic int size() {\n+\t\treturn bits;\n+\t}\n+\n+\t@Override\n+\tpublic void parse(InputStream is) throws IOException {\n+\t\tCheckedInputStream cis = new CheckedInputStream(is, new CRC8());\n+\n+\t\tint dtype = cis.read();\n+\t\tif (dtype != BITMAP1) {\n+\t\t\tthrow new UnsupportedOperationException(\"Only bitmap v1 is supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MTY2Mw==", "bodyText": "How important is this assertion? Not familiar with recent RDF4J coding standards, but using an always-on check and exception rather than a variable assertion is more generally accepted.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385451663", "createdAt": "2020-02-28T00:42:43Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTBitmap.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC32;\n+import org.eclipse.rdf4j.rio.hdt.util.CRC8;\n+import org.eclipse.rdf4j.rio.hdt.util.VByte;\n+\n+/**\n+ *\n+ * @author Bart Hanssens\n+ */\n+public class HDTBitmap extends HDTPart {\n+\tpublic final static int BITMAP1 = 1;\n+\n+\tprivate int bits;\n+\tprivate byte[] buffer;\n+\n+\t/**\n+\t * Get bit\n+\t * \n+\t * @param i\n+\t * @return 0 or 1\n+\t */\n+\tpublic int get(int i) {\n+\t\tassert i < bits : \"Bitmap out of range\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MTgzNQ==", "bodyText": "How important is this assertion? Should it be a full, always-on guard?", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385451835", "createdAt": "2020-02-28T00:43:21Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTArrayLog64.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.zip.CheckedInputStream;\n+\n+import org.eclipse.rdf4j.rio.hdt.util.CRC32;\n+\n+/**\n+ * Log64\n+ * \n+ * It contains the data part of the {@link HDTArray}, followed by the 32-bit CRC calculated over this data.\n+ * \n+ * Data structure:\n+ * \n+ * <pre>\n+ * ...+---------+-------+\n+ *    | entries | CRC32 |\n+ * ...+---------+-------+\n+ * </pre>\n+ * \n+ * Entries are stored little-endian, with each entry using <code>nrbits</code> bits\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTArrayLog64 extends HDTArray {\n+\tprivate byte buffer[];\n+\n+\t@Override\n+\tpublic int getType() {\n+\t\treturn HDTArray.Type.LOG64.getValue();\n+\t}\n+\n+\t@Override\n+\tpublic int get(int i) {\n+\t\tassert i < entries : \"Entries out of range\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1MTkyNA==", "bodyText": "Adding dtype to the exception message here would be useful for debugging.", "url": "https://github.com/eclipse/rdf4j/pull/1952#discussion_r385451924", "createdAt": "2020-02-28T00:43:45Z", "author": {"login": "ansell"}, "path": "core/rio/hdt/src/main/java/org/eclipse/rdf4j/rio/hdt/part/HDTArrayFactory.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*******************************************************************************\n+ * Copyright (c) 2020 Eclipse RDF4J contributors.\n+ * All rights reserved. This program and the accompanying materials\n+ * are made available under the terms of the Eclipse Distribution License v1.0\n+ * which accompanies this distribution, and is available at\n+ * http://www.eclipse.org/org/documents/edl-v10.php.\n+ *******************************************************************************/\n+package org.eclipse.rdf4j.rio.hdt.part;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+/**\n+ * HDT Array factory.\n+ * \n+ * @author Bart Hanssens\n+ */\n+public class HDTArrayFactory {\n+\n+\tpublic static HDTArray parse(InputStream is) throws IOException {\n+\t\tint dtype = is.read();\n+\t\tif (dtype != HDTArray.Type.LOG64.getValue()) {\n+\t\t\tthrow new UnsupportedOperationException(\"Array section: only Log64 encoding is supported\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5411d7f975fc33fe4b0363e78d18beccb1822f71"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY3NTUyMzQ4", "url": "https://github.com/eclipse/rdf4j/pull/1952#pullrequestreview-367552348", "createdAt": "2020-03-02T21:47:06Z", "commit": {"oid": "9993bd4f39b5c00e516deb025f0c756c2c25393c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b90eb588c1049e71acbe29e5597d4b365505deb9", "author": {"user": {"login": "barthanssens", "name": "Bart Hanssens"}}, "url": "https://github.com/eclipse/rdf4j/commit/b90eb588c1049e71acbe29e5597d4b365505deb9", "committedDate": "2020-03-03T11:34:17Z", "message": "GH-232 inital experimental HDT parser\n\nSigned-off-by: Bart Hanssens <bart.hanssens@bosa.fgov.be>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f675358ec2528a73f424e8ebff1fa9fbc7717aa0", "author": {"user": {"login": "barthanssens", "name": "Bart Hanssens"}}, "url": "https://github.com/eclipse/rdf4j/commit/f675358ec2528a73f424e8ebff1fa9fbc7717aa0", "committedDate": "2020-03-02T22:08:23Z", "message": "GH-232 explicit charsets when creating new strings\nSigned-off-by:Bart Hanssens <bart.hanssens@bosa.fgov.be>"}, "afterCommit": {"oid": "b90eb588c1049e71acbe29e5597d4b365505deb9", "author": {"user": {"login": "barthanssens", "name": "Bart Hanssens"}}, "url": "https://github.com/eclipse/rdf4j/commit/b90eb588c1049e71acbe29e5597d4b365505deb9", "committedDate": "2020-03-03T11:34:17Z", "message": "GH-232 inital experimental HDT parser\n\nSigned-off-by: Bart Hanssens <bart.hanssens@bosa.fgov.be>"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 72, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}