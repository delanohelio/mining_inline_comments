{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4MjY1MzQ5", "number": 2126, "title": "GH-2121 group adds/removes together in sparql update sequence", "bodyText": "GitHub issue resolved: #2121 \nBriefly describe the changes proposed in this PR:\n\nSPARQLConnection internally keeps tracks of pending adds / removals. When either commit is called or an add is interleaved with remove (vice versa) the pendings adds/removals get flushed into a single INSERT/DELETE DATA operation\nadded one or two unit tests to check content and sequence of update operations in the produced SPARQL string.\n\n\nPR Author Checklist:\n\n my pull request is self-contained\n I've added tests for the changes I made\n every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\n every commit has been signed off\n\nNote: we merge all feature pull requests using squash and merge. See RDF4J git merge strategy for more details.", "createdAt": "2020-04-24T00:24:48Z", "url": "https://github.com/eclipse/rdf4j/pull/2126", "merged": true, "mergeCommit": {"oid": "c4b15d09e3ebdac9672b037e40506c7491550cce"}, "closed": true, "closedAt": "2020-04-25T04:57:53Z", "author": {"login": "jeenbroekstra"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcamJxpgH2gAyNDA4MjY1MzQ5OjJjY2IxYWQxMjc2NGJkZDhhOTY4YTU5NzViNTYzZDlmY2QxMmEyYWU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABca8KyaAH2gAyNDA4MjY1MzQ5OmMyZTFmZjQ2Y2M4OGMyOWRkMTQ2NTA0ZDljZmE5OGViYzVjYzY3YmE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2ccb1ad12764bdd8a968a5975b563d9fcd12a2ae", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/2ccb1ad12764bdd8a968a5975b563d9fcd12a2ae", "committedDate": "2020-04-24T00:15:11Z", "message": "GH-2121 single INSERT/DELETE DATA per add/remove block"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/3001f68987c2610d3cab6063818cd0c3e6c63490", "committedDate": "2020-04-24T00:26:45Z", "message": "GH-2121 create single INSERT/DELETE DATA per batch of triples\n\n- avoid having a INSERT/DELETE operation for each individual triple"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "73e3c856b25523fbdecab1e0edb40a29266cdab8", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/73e3c856b25523fbdecab1e0edb40a29266cdab8", "committedDate": "2020-04-24T00:20:41Z", "message": "GH-2121 create single INSERT/DELETE DATA per batch of triples\n\n- avoid having a INSERT/DELETE operation for each individual triple"}, "afterCommit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/3001f68987c2610d3cab6063818cd0c3e6c63490", "committedDate": "2020-04-24T00:26:45Z", "message": "GH-2121 create single INSERT/DELETE DATA per batch of triples\n\n- avoid having a INSERT/DELETE operation for each individual triple"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5Njc3Mjg4", "url": "https://github.com/eclipse/rdf4j/pull/2126#pullrequestreview-399677288", "createdAt": "2020-04-24T06:41:17Z", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0MToxN1rOGLI2lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0MToxN1rOGLI2lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzMjU2Ng==", "bodyText": "I think .contexts() upgrades the DynamicModel to a HashModel. This is probably not going to be what is performance critical in this situation though. I'm also unsure if .clear() downgrades the model again.", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414332566", "createdAt": "2020-04-24T06:41:17Z", "author": {"login": "hmottestad"}, "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -827,39 +819,71 @@ public boolean isActive() throws UnknownTransactionStateException, RepositoryExc\n \t\t}\n \t}\n \n+\t@Override\n+\tprotected void addWithoutCommit(Statement st, Resource... contexts)\n+\t\t\tthrows RepositoryException {\n+\t\tflushPendingRemoves();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingAdds.add(st);\n+\t\t} else {\n+\t\t\tpendingAdds.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n+\t}\n+\n \t@Override\n \tprotected void addWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tValueFactory f = getValueFactory();\n+\t\tflushPendingRemoves();\n+\t\tpendingAdds.add(subject, predicate, object, contexts);\n+\t}\n \n-\t\tStatement st = f.createStatement(subject, predicate, object);\n+\tprivate void flushPendingRemoves() {\n+\t\tif (!pendingRemoves.isEmpty()) {\n+\t\t\tfor (Resource context : pendingRemoves.contexts()) {\n+\t\t\t\tString sparqlCommand = createDeleteDataCommand(pendingRemoves.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingRemoves.clear();\n+\t\t}\n+\t}\n \n-\t\tList<Statement> list = new ArrayList<>(1);\n-\t\tlist.add(st);\n-\t\tString sparqlCommand = createInsertDataCommand(list, contexts);\n+\tprivate void flushPendingAdds() {\n+\t\tif (!pendingAdds.isEmpty()) {\n+\t\t\tfor (Resource context : pendingAdds.contexts()) {\n+\t\t\t\tString sparqlCommand = createInsertDataCommand(pendingAdds.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingAdds.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "originalPosition": 177}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5Njc4NzEy", "url": "https://github.com/eclipse/rdf4j/pull/2126#pullrequestreview-399678712", "createdAt": "2020-04-24T06:44:17Z", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5Njc5NzI5", "url": "https://github.com/eclipse/rdf4j/pull/2126#pullrequestreview-399679729", "createdAt": "2020-04-24T06:46:30Z", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0NjozMFrOGLJAgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0NjozMFrOGLJAgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTEwNw==", "bodyText": "Bit hazy in the morning but I wonder how you handle removing from all contexts (implicitly).", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414335107", "createdAt": "2020-04-24T06:46:30Z", "author": {"login": "hmottestad"}, "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -827,39 +819,71 @@ public boolean isActive() throws UnknownTransactionStateException, RepositoryExc\n \t\t}\n \t}\n \n+\t@Override\n+\tprotected void addWithoutCommit(Statement st, Resource... contexts)\n+\t\t\tthrows RepositoryException {\n+\t\tflushPendingRemoves();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingAdds.add(st);\n+\t\t} else {\n+\t\t\tpendingAdds.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n+\t}\n+\n \t@Override\n \tprotected void addWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tValueFactory f = getValueFactory();\n+\t\tflushPendingRemoves();\n+\t\tpendingAdds.add(subject, predicate, object, contexts);\n+\t}\n \n-\t\tStatement st = f.createStatement(subject, predicate, object);\n+\tprivate void flushPendingRemoves() {\n+\t\tif (!pendingRemoves.isEmpty()) {\n+\t\t\tfor (Resource context : pendingRemoves.contexts()) {\n+\t\t\t\tString sparqlCommand = createDeleteDataCommand(pendingRemoves.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingRemoves.clear();\n+\t\t}\n+\t}\n \n-\t\tList<Statement> list = new ArrayList<>(1);\n-\t\tlist.add(st);\n-\t\tString sparqlCommand = createInsertDataCommand(list, contexts);\n+\tprivate void flushPendingAdds() {\n+\t\tif (!pendingAdds.isEmpty()) {\n+\t\t\tfor (Resource context : pendingAdds.contexts()) {\n+\t\t\t\tString sparqlCommand = createInsertDataCommand(pendingAdds.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingAdds.clear();\n+\t\t}\n+\t}\n \n-\t\tsparqlTransaction.append(sparqlCommand);\n-\t\tsparqlTransaction.append(\"; \");\n+\t@Override\n+\tprotected void removeWithoutCommit(Statement st, Resource... contexts) throws RepositoryException {\n+\t\tflushPendingAdds();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingRemoves.add(st);\n+\t\t} else {\n+\t\t\tpendingRemoves.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n \t}\n \n \t@Override\n \tprotected void removeWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tString sparqlCommand = \"\";\n-\t\tif (subject != null && predicate != null && object != null) {\n-\t\t\tValueFactory f = getValueFactory();\n-\n-\t\t\tStatement st = f.createStatement(subject, predicate, object);\n+\t\tflushPendingAdds();\n \n-\t\t\tList<Statement> list = new ArrayList<>(1);\n-\t\t\tlist.add(st);\n-\t\t\tsparqlCommand = createDeleteDataCommand(list, contexts);\n+\t\tif (subject != null && predicate != null && object != null) {\n+\t\t\tpendingRemoves.add(subject, predicate, object, contexts);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "originalPosition": 207}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjgwMDA1", "url": "https://github.com/eclipse/rdf4j/pull/2126#pullrequestreview-399680005", "createdAt": "2020-04-24T06:47:06Z", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0NzowNlrOGLJBnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo0NzowNlrOGLJBnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTM4OA==", "bodyText": "Do we need a private getter?", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414335388", "createdAt": "2020-04-24T06:47:06Z", "author": {"login": "hmottestad"}, "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -972,4 +996,8 @@ protected Statement convert(BindingSet b) throws QueryEvaluationException {\n \t\t};\n \t}\n \n+\tprivate ModelFactory getModelFactory() {\n+\t\treturn modelFactory;\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "originalPosition": 227}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk5NjgxNTMw", "url": "https://github.com/eclipse/rdf4j/pull/2126#pullrequestreview-399681530", "createdAt": "2020-04-24T06:50:13Z", "commit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo1MDoxM1rOGLJHIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQwNjo1MDoxM1rOGLJHIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNjgwMA==", "bodyText": "Good we have some tests. Do we have any integration tests that would cover this too? Benchmarks would also be great, so we don't have a regression of this some time in the future.", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414336800", "createdAt": "2020-04-24T06:50:13Z", "author": {"login": "hmottestad"}, "path": "core/repository/sparql/src/test/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnectionTest.java", "diffHunk": "@@ -48,4 +53,52 @@ public void commitOnEmptyTxnDoesNothing() throws Exception {\n \t\tverify(client, never()).sendUpdate(any(), any(), any(), any(), anyBoolean(), anyInt(), any());\n \t\tverify(client, never()).sendUpdate(any(), any(), any(), any(), anyBoolean(), any());\n \t}\n+\n+\t@Test\n+\tpublic void testGroupingAddsInInsert() throws Exception {\n+\t\tArgumentCaptor<String> sparqlUpdateCaptor = ArgumentCaptor.forClass(String.class);\n+\n+\t\tsubject.begin();\n+\t\tsubject.add(FOAF.PERSON, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.add(FOAF.AGENT, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.commit();\n+\n+\t\tverify(client).sendUpdate(any(), sparqlUpdateCaptor.capture(), any(), any(), anyBoolean(), anyInt(), any());\n+\n+\t\tString sparqlUpdate = sparqlUpdateCaptor.getValue();\n+\t\tString expectedTriple1 = \"<\" + FOAF.PERSON + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \">\";\n+\t\tString expectedTriple2 = \"<\" + FOAF.AGENT + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \">\";\n+\n+\t\tassertThat(sparqlUpdate).containsOnlyOnce(\"INSERT DATA\").contains(expectedTriple1).contains(expectedTriple2);\n+\t}\n+\n+\t@Test\n+\tpublic void testHandlingAddsRemoves() throws Exception {\n+\t\tArgumentCaptor<String> sparqlUpdateCaptor = ArgumentCaptor.forClass(String.class);\n+\n+\t\tsubject.begin();\n+\t\tsubject.add(FOAF.PERSON, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.add(FOAF.AGENT, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.remove(FOAF.BIRTHDAY, RDF.TYPE, RDF.PROPERTY);\n+\t\tsubject.add(FOAF.AGE, RDF.TYPE, RDF.PROPERTY);\n+\t\tsubject.commit();\n+\n+\t\tverify(client).sendUpdate(any(), sparqlUpdateCaptor.capture(), any(), any(), anyBoolean(), anyInt(), any());\n+\n+\t\tString sparqlUpdate = sparqlUpdateCaptor.getValue();\n+\n+\t\tString expectedAddedTriple1 = \"<\" + FOAF.PERSON + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \"> .\";\n+\t\tString expectedAddedTriple2 = \"<\" + FOAF.AGENT + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \"> .\";\n+\t\tString expectedAddedTriple3 = \"<\" + FOAF.AGE + \"> <\" + RDF.TYPE + \"> <\" + RDF.PROPERTY + \"> \";\n+\t\tString expectedRemovedTriple1 = \"<\" + FOAF.BIRTHDAY + \"> <\" + RDF.TYPE + \"> <\" + RDF.PROPERTY + \"> .\";\n+\n+\t\tString expectedSequence = \"INSERT DATA[^{]*\\\\{[^}]*\\\\}[^D]+DELETE DATA[^{]*\\\\{[^}]*\\\\}[^I]+INSERT DATA.*\";\n+\n+\t\tassertThat(sparqlUpdate).containsPattern(expectedSequence);\n+\t\tassertThat(sparqlUpdate).contains(expectedAddedTriple1)\n+\t\t\t\t.contains(expectedAddedTriple2)\n+\t\t\t\t.contains(expectedAddedTriple3)\n+\t\t\t\t.contains(expectedRemovedTriple1);\n+\n+\t}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490"}, "originalPosition": 73}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9cfe1870743694186018cbfcc1e4e9e92eb8233", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/c9cfe1870743694186018cbfcc1e4e9e92eb8233", "committedDate": "2020-04-25T01:30:09Z", "message": "GH-2121 test cases for handling of adding/removal with context"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2e1ff46cc88c29dd146504d9cfa98ebc5cc67ba", "author": {"user": {"login": "jeenbroekstra", "name": "Jeen Broekstra"}}, "url": "https://github.com/eclipse/rdf4j/commit/c2e1ff46cc88c29dd146504d9cfa98ebc5cc67ba", "committedDate": "2020-04-25T01:54:12Z", "message": "GH-2121 force flush if pending stmt size reaches 1M\n\n- cleaned up integration test for SPARQLRepository by re-enabling\n  certain test cases we now support"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 46, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}