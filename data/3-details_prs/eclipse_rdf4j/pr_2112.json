{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA2MDA0MDI5", "number": 2112, "title": "GH-2111 cache IDFile", "bodyText": "GitHub issue resolved: #2111 \nBriefly describe the changes proposed in this PR:\nCache and read ahead in the IDFile to reduce number of IO opertions.\n\nPR Author Checklist:\n\n my pull request is self-contained\n I've added tests for the changes I made\n every commit message starts with the issue number (GH-xxxx) followed by a meaningful description of the change\n every commit has been signed off\n\nNote: we merge all feature pull requests using squash and merge. See RDF4J git merge strategy for more details.", "createdAt": "2020-04-20T11:27:16Z", "url": "https://github.com/eclipse/rdf4j/pull/2112", "merged": true, "mergeCommit": {"oid": "8b2082386c6439e6a513ff81bb964aa4d0554ee8"}, "closed": true, "closedAt": "2020-04-22T09:54:22Z", "author": {"login": "hmottestad"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcZoeIPAFqTM5NjkwNjg3OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcaEFR5AH2gAyNDA2MDA0MDI5OmU0OTI4OTU2ZGE4YzhiODkxYzk4MDdlMjAwYjA5OWI4YzBlY2U1MTc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2OTA2ODc5", "url": "https://github.com/eclipse/rdf4j/pull/2112#pullrequestreview-396906879", "createdAt": "2020-04-21T00:23:18Z", "commit": {"oid": "e4279ee6c6523179acf4abe7c36187c497e59271"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "262e6ccf9453e84daede3cc884a487b4b9ac90ee", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/262e6ccf9453e84daede3cc884a487b4b9ac90ee", "committedDate": "2020-04-21T07:27:30Z", "message": "GH-2111 adjusted read size and also added synchronization\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}, "afterCommit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/8dce0457a6e964ff5e5ae78405e6762e20618621", "committedDate": "2020-04-21T09:11:40Z", "message": "GH-2111 adjusted read size and also added synchronization\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3ODgyMzg3", "url": "https://github.com/eclipse/rdf4j/pull/2112#pullrequestreview-397882387", "createdAt": "2020-04-22T06:37:13Z", "commit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozNzoxNFrOGJlvtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozNzoxNFrOGJlvtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwODc4OA==", "bodyText": "Should probably synchronise this too.", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412708788", "createdAt": "2020-04-22T06:37:14Z", "author": {"login": "hmottestad"}, "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost\n+\t\t// never be cached. This simplifies the code since we don't have to deal with partial lines.\n+\t\tif (getMaxID() > cacheLineSize && id < getMaxID() - cacheLineSize) {\n+\n+\t\t\t// doing one big read is considerably faster than doing a single read per id\n+\t\t\tbyte[] bytes = nioFile.readBytes(ITEM_SIZE * (cacheLookupIndex << cacheLineShift),\n+\t\t\t\t\t(int) (ITEM_SIZE * cacheLineSize));\n+\n+\t\t\tcacheLine = convertBytesToLongs(bytes);\n+\n+\t\t\tsynchronized (this) {\n+\t\t\t\t// we try not to overwrite an existing cache line\n+\t\t\t\tif (!cache.containsKey(cacheLineLookupIndex)) {\n+\t\t\t\t\tcache.put(cacheLookupIndex, cacheLine);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tgcReducingCache = cacheLine;\n+\t\t\tgcReducingCacheIndex = cacheLookupIndex;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "originalPosition": 165}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3ODgyNjky", "url": "https://github.com/eclipse/rdf4j/pull/2112#pullrequestreview-397882692", "createdAt": "2020-04-22T06:37:45Z", "commit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozNzo0NlrOGJlwyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozNzo0NlrOGJlwyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwOTA2NA==", "bodyText": "Typo og=of", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412709064", "createdAt": "2020-04-22T06:37:46Z", "author": {"login": "hmottestad"}, "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3ODgzMTk1", "url": "https://github.com/eclipse/rdf4j/pull/2112#pullrequestreview-397883195", "createdAt": "2020-04-22T06:38:42Z", "commit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozODo0MlrOGJlypA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQwNjozODo0MlrOGJlypA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwOTU0MA==", "bodyText": "Clear Cache!", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412709540", "createdAt": "2020-04-22T06:38:42Z", "author": {"login": "hmottestad"}, "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost\n+\t\t// never be cached. This simplifies the code since we don't have to deal with partial lines.\n+\t\tif (getMaxID() > cacheLineSize && id < getMaxID() - cacheLineSize) {\n+\n+\t\t\t// doing one big read is considerably faster than doing a single read per id\n+\t\t\tbyte[] bytes = nioFile.readBytes(ITEM_SIZE * (cacheLookupIndex << cacheLineShift),\n+\t\t\t\t\t(int) (ITEM_SIZE * cacheLineSize));\n+\n+\t\t\tcacheLine = convertBytesToLongs(bytes);\n+\n+\t\t\tsynchronized (this) {\n+\t\t\t\t// we try not to overwrite an existing cache line\n+\t\t\t\tif (!cache.containsKey(cacheLineLookupIndex)) {\n+\t\t\t\t\tcache.put(cacheLookupIndex, cacheLine);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tgcReducingCache = cacheLine;\n+\t\t\tgcReducingCacheIndex = cacheLookupIndex;\n+\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\n+\t\t}\n+\n+\t\t// we did not find a cached value and we did not create a new cache line\n \t\treturn nioFile.readLong(ITEM_SIZE * id);\n \t}\n \n \t/**\n \t * Discards all stored data.\n-\t * \n+\t *\n \t * @throws IOException If an I/O error occurred.\n \t */\n \tpublic void clear() throws IOException {\n \t\tnioFile.truncate(HEADER_LENGTH);\n+\t\tnioFileSize = nioFile.size();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "originalPosition": 183}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3OTI1OTY3", "url": "https://github.com/eclipse/rdf4j/pull/2112#pullrequestreview-397925967", "createdAt": "2020-04-22T07:44:59Z", "commit": {"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b42e7f32a2cc8eb25010996699d4782eb0e56b51", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/b42e7f32a2cc8eb25010996699d4782eb0e56b51", "committedDate": "2020-04-22T08:32:24Z", "message": "GH-2111 Use a ReferenceMap to create a memory aware cache in IDFile\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bccf5949afcc18640e0554415570b827a150cb47", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/bccf5949afcc18640e0554415570b827a150cb47", "committedDate": "2020-04-22T08:32:24Z", "message": "Shared and synchronized java object is more costly than just creating a new one every time, especially due to escape analysis\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ab97c2d3958a98dff039b15c772b8ffad0d0889", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/5ab97c2d3958a98dff039b15c772b8ffad0d0889", "committedDate": "2020-04-22T08:32:24Z", "message": "GH-2111 minor code cleanup\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f628aca5d4385d70682dd657fce5190291f6371e", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/f628aca5d4385d70682dd657fce5190291f6371e", "committedDate": "2020-04-22T08:32:24Z", "message": "GH-2111 adjusted read size and also added synchronization\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2b0e72c9682ec793c57069aa523d37c301cc4a7", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/e2b0e72c9682ec793c57069aa523d37c301cc4a7", "committedDate": "2020-04-22T08:32:24Z", "message": "review fixes\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e55d1494cf8731dfb729b3c46ba25cc835c4c7c9", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/e55d1494cf8731dfb729b3c46ba25cc835c4c7c9", "committedDate": "2020-04-22T08:27:59Z", "message": "review fixes\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}, "afterCommit": {"oid": "e2b0e72c9682ec793c57069aa523d37c301cc4a7", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/e2b0e72c9682ec793c57069aa523d37c301cc4a7", "committedDate": "2020-04-22T08:32:24Z", "message": "review fixes\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4928956da8c8b891c9807e200b099b8c0ece517", "author": {"user": {"login": "hmottestad", "name": null}}, "url": "https://github.com/eclipse/rdf4j/commit/e4928956da8c8b891c9807e200b099b8c0ece517", "committedDate": "2020-04-22T08:33:30Z", "message": "sort imports\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 45, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}