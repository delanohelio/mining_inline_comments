{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4NDI5MTky", "number": 1339, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo0ODoyM1rODvpohQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToyNjo1NlrODvzKqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjkxNzgxOnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo0ODoyNFrOGCMxsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMzoyNjowM1rOGCZs6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1OTY2NQ==", "bodyText": "Can this be package private? Also, add a unit tests as well.", "url": "https://github.com/apache/samza/pull/1339#discussion_r404959665", "createdAt": "2020-04-07T16:48:24Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "diffHunk": "@@ -298,24 +298,78 @@ public BoxedUnit apply(Exception exception, ExponentialSleepStrategy.RetryLoop l\n   @Override\n   public Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> getSSPMetadata(\n       Set<SystemStreamPartition> ssps) {\n+    return getSSPMetadata(ssps,\n+        new ExponentialSleepStrategy(DEFAULT_EXPONENTIAL_SLEEP_BACK_OFF_MULTIPLIER,\n+            DEFAULT_EXPONENTIAL_SLEEP_INITIAL_DELAY_MS, DEFAULT_EXPONENTIAL_SLEEP_MAX_DELAY_MS));\n+  }\n+\n+  /**\n+   * Given a set of SystemStreamPartition, fetch metadata from Kafka for each\n+   * of them, and return a map from ssp to SystemStreamPartitionMetadata for\n+   * each of them. This method will return null for oldest and newest offsets\n+   * if a given SystemStreamPartition is empty. This method will block and\n+   * retry indefinitely until it gets a successful response from Kafka.\n+   * @param ssps a set of strings of SSP\n+   * @param retryBackoff retry backoff strategy\n+   * @return a map from ssp to sspMetadata which has offsets\n+   */\n+  public Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> getSSPMetadata(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67c10152052753eb1e2de171078e671865603de0"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE3MTQzNA==", "bodyText": "Modified it to a private one and added unite test to test retry.", "url": "https://github.com/apache/samza/pull/1339#discussion_r405171434", "createdAt": "2020-04-07T23:26:03Z", "author": {"login": "MabelYC"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "diffHunk": "@@ -298,24 +298,78 @@ public BoxedUnit apply(Exception exception, ExponentialSleepStrategy.RetryLoop l\n   @Override\n   public Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> getSSPMetadata(\n       Set<SystemStreamPartition> ssps) {\n+    return getSSPMetadata(ssps,\n+        new ExponentialSleepStrategy(DEFAULT_EXPONENTIAL_SLEEP_BACK_OFF_MULTIPLIER,\n+            DEFAULT_EXPONENTIAL_SLEEP_INITIAL_DELAY_MS, DEFAULT_EXPONENTIAL_SLEEP_MAX_DELAY_MS));\n+  }\n+\n+  /**\n+   * Given a set of SystemStreamPartition, fetch metadata from Kafka for each\n+   * of them, and return a map from ssp to SystemStreamPartitionMetadata for\n+   * each of them. This method will return null for oldest and newest offsets\n+   * if a given SystemStreamPartition is empty. This method will block and\n+   * retry indefinitely until it gets a successful response from Kafka.\n+   * @param ssps a set of strings of SSP\n+   * @param retryBackoff retry backoff strategy\n+   * @return a map from ssp to sspMetadata which has offsets\n+   */\n+  public Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> getSSPMetadata(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1OTY2NQ=="}, "originalCommit": {"oid": "67c10152052753eb1e2de171078e671865603de0"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxMjkyMTM1OnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxNjo0OToxMlrOGCMz-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QyMzoyNjoxMFrOGCZtAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2MDI1MQ==", "bodyText": "nit: revert", "url": "https://github.com/apache/samza/pull/1339#discussion_r404960251", "createdAt": "2020-04-07T16:49:12Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "diffHunk": "@@ -599,7 +653,7 @@ public void deleteMessages(Map<SystemStreamPartition, String> offsets) {\n       Map<TopicPartition, RecordsToDelete> recordsToDelete = offsets.entrySet()\n           .stream()\n           .collect(Collectors.toMap(entry ->\n-              new TopicPartition(entry.getKey().getStream(), entry.getKey().getPartition().getPartitionId()),\n+                  new TopicPartition(entry.getKey().getStream(), entry.getKey().getPartition().getPartitionId()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67c10152052753eb1e2de171078e671865603de0"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE3MTQ1Nw==", "bodyText": "Done", "url": "https://github.com/apache/samza/pull/1339#discussion_r405171457", "createdAt": "2020-04-07T23:26:10Z", "author": {"login": "MabelYC"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaSystemAdmin.java", "diffHunk": "@@ -599,7 +653,7 @@ public void deleteMessages(Map<SystemStreamPartition, String> offsets) {\n       Map<TopicPartition, RecordsToDelete> recordsToDelete = offsets.entrySet()\n           .stream()\n           .collect(Collectors.toMap(entry ->\n-              new TopicPartition(entry.getKey().getStream(), entry.getKey().getPartition().getPartitionId()),\n+                  new TopicPartition(entry.getKey().getStream(), entry.getKey().getPartition().getPartitionId()),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2MDI1MQ=="}, "originalCommit": {"oid": "67c10152052753eb1e2de171078e671865603de0"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUxNDQ3OTc5OnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaSystemAdminWithMock.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToyNjo1NlrOGCb0tQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMToyNjo1NlrOGCb0tQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIwNjE5Nw==", "bodyText": "The reason why I suggested to make the retry method package private and write tests against it is because you can override the policy for tests. With the current setup, this test is going to always take ~ 16 seconds regardless.\nGiven our builds are already impacted due to tests, I'd suggest to override defaults to smaller multipliers and values for tests.", "url": "https://github.com/apache/samza/pull/1339#discussion_r405206197", "createdAt": "2020-04-08T01:26:56Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaSystemAdminWithMock.java", "diffHunk": "@@ -308,4 +309,46 @@ public void testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesO\n \n     kafkaSystemAdmin.getSystemStreamPartitionCounts(streamNames, cacheTTL);\n   }\n+\n+  @Test\n+  public void testGetSSPMetadataWithRetry() {\n+    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));\n+    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, \"otherTopic\", new Partition(1));\n+    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);\n+    List<TopicPartition> topicPartitions = ssps.stream()\n+        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))\n+        .collect(Collectors.toList());\n+    Map<TopicPartition, Long> testBeginningOffsets =\n+        ImmutableMap.of(testTopicPartition0, KAFKA_BEGINNING_OFFSET_FOR_PARTITION0, testTopicPartition1,\n+            KAFKA_BEGINNING_OFFSET_FOR_PARTITION1);\n+\n+    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())\n+        .thenReturn(testBeginningOffsets);\n+    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> sspMetadata =\n+        kafkaSystemAdmin.getSSPMetadata(ssps);\n+\n+    assertEquals(\"metadata should return for 2 topics\", sspMetadata.size(), 2);\n+\n+    // retried twice because the first fails and the second succeeds\n+    Mockito.verify(mockKafkaConsumer, Mockito.times(2)).beginningOffsets(topicPartitions);\n+  }\n+\n+  @Test(expected = SamzaException.class)\n+  public void testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException() throws Exception{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "793f1d3b624cf4a1579265427a17ac4784a42a8f"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1628, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}