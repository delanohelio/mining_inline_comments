{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4MzQxMzA5", "number": 1351, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDo0ODo0OFrOD2TMZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxOToxNFrOD24OJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4MjY0MTY3OnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDo0ODo0OFrOGMCqjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxODo0OFrOGM164w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3OTc1OA==", "bodyText": "I think its good idea to fail with meaningful errors instead of a potential NPE. Although, is this new contract necessary as part of this change?\n\nIs it possible for kafkaConsmer.endOffsets(...) to return null in the first place?\nIf yes to above, have we seen any issues around NPE before or is this purely from the standpoint of defensive programming?", "url": "https://github.com/apache/samza/pull/1351#discussion_r415279758", "createdAt": "2020-04-26T10:48:48Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {\n     // This is expensive, so only do it once at the beginning. After the first poll, we can rely on metrics for lag.\n-    Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+\n+    Map<TopicPartition, Long> endOffsets;\n+    // Synchronize, in case the consumer is used in some other thread (metadata or something else)\n+    synchronized (kafkaConsumer) {\n+      endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+    }\n+    if (endOffsets == null) {\n+      throw new SamzaException(\"Failed to fetch kafka consumer endoffsets for system \" + systemName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg1NDY1NA==", "bodyText": "actually, KafkaConsumer.endOffset does not make a promise that it will be non-null. If i keep digging into implementation details, it looks like it returns an empty hashmap.. but thats an impl detail not an api promise. hence added this.\ni agree, for this change (to deal with the sync issue), dealing with this NPE is not needed. but thought it will be a nice to do.", "url": "https://github.com/apache/samza/pull/1351#discussion_r415854654", "createdAt": "2020-04-27T14:21:22Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {\n     // This is expensive, so only do it once at the beginning. After the first poll, we can rely on metrics for lag.\n-    Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+\n+    Map<TopicPartition, Long> endOffsets;\n+    // Synchronize, in case the consumer is used in some other thread (metadata or something else)\n+    synchronized (kafkaConsumer) {\n+      endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+    }\n+    if (endOffsets == null) {\n+      throw new SamzaException(\"Failed to fetch kafka consumer endoffsets for system \" + systemName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3OTc1OA=="}, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjExOTUyMw==", "bodyText": "sounds good \ud83d\udc4d", "url": "https://github.com/apache/samza/pull/1351#discussion_r416119523", "createdAt": "2020-04-27T20:18:48Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {\n     // This is expensive, so only do it once at the beginning. After the first poll, we can rely on metrics for lag.\n-    Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+\n+    Map<TopicPartition, Long> endOffsets;\n+    // Synchronize, in case the consumer is used in some other thread (metadata or something else)\n+    synchronized (kafkaConsumer) {\n+      endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+    }\n+    if (endOffsets == null) {\n+      throw new SamzaException(\"Failed to fetch kafka consumer endoffsets for system \" + systemName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3OTc1OA=="}, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4Mjc0NTU3OnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaConsumerProxy.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMTo1MjowMlrOGMDZ-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxNDoyNToyMVrOGMl9Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI5MTg5Nw==", "bodyText": "I see we don't have tests at all for consumer proxy and thanks for adding one :) However, I have few observations/questions\n\nThe test still does have some indeterminism and doesn't necessarily tests synchronized access as it claims all the time as it is possible that t1 & t2 run exclusively.\nIs the intent here to test java synchronized or prevent accidental changes to initializeLags making it no longer synchronize on the consumer?\n\n\nIf it is the former, it is going to be hard to test consistently and deterministically unless you do complex gimmicks with latches & Thread.holdsLock(...). IMO, it should be okay to assume Java synchronized works as expected\nIf it the latter, it is still undoubtedly hard but we can enforce them through other means with useful explicit comments around the code blocks & diligent reviews.\n\nTLDR; I am fine with not having a test for this scenario instead of having one that is indeterministic in what it tests. If you prefer to have a test, then it will be nice to have it do what it claims to do.", "url": "https://github.com/apache/samza/pull/1351#discussion_r415291897", "createdAt": "2020-04-26T11:52:02Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaConsumerProxy.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.system.kafka;\n+\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.junit.Test;\n+\n+import static org.mockito.Mockito.anyCollection;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+\n+\n+public class TestKafkaConsumerProxy {\n+\n+  @Test\n+  public void testSynchronizedAccessOfKafkaConsumer() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTg1Nzk1MQ==", "bodyText": "haha, i debated for a good deal of time about this test and even having a test for this scenario :D\nI agree that this test can not really \"test/simulate\" the real issue we are solving. I wonder if there can be a test which can really test this scenario. I will remove this test.", "url": "https://github.com/apache/samza/pull/1351#discussion_r415857951", "createdAt": "2020-04-27T14:25:21Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaConsumerProxy.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.system.kafka;\n+\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.junit.Test;\n+\n+import static org.mockito.Mockito.anyCollection;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+\n+\n+public class TestKafkaConsumerProxy {\n+\n+  @Test\n+  public void testSynchronizedAccessOfKafkaConsumer() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI5MTg5Nw=="}, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU4ODcwODIxOnYy", "diffSide": "RIGHT", "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxOToxNFrOGM177g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxOToxNFrOGM177g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjExOTc5MA==", "bodyText": "revert this to private?", "url": "https://github.com/apache/samza/pull/1351#discussion_r416119790", "createdAt": "2020-04-27T20:19:14Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ae3155fbaaca3401fc98076f57018bbb6983fd7"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1403, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}