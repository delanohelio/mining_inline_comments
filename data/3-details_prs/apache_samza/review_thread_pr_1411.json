{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY1Nzc2NDEw", "number": 1411, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMDozNlrOEXYVcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMzo0NlrOEXYZOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTUxNDA4OnYy", "diffSide": "RIGHT", "path": "samza-log4j2/src/main/java/org/apache/samza/logging/log4j2/StreamAppender.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMDozNlrOG_JEzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMDozNlrOG_JEzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MjE1Nw==", "bodyText": "Now that you have cached keyBytes at the instance level, can we get rid of the local keyBytes byte array?", "url": "https://github.com/apache/samza/pull/1411#discussion_r468862157", "createdAt": "2020-08-11T21:00:36Z", "author": {"login": "mynameborat"}, "path": "samza-log4j2/src/main/java/org/apache/samza/logging/log4j2/StreamAppender.java", "diffHunk": "@@ -397,15 +425,7 @@ private void startTransferThread() {\n       Runnable transferFromQueueToSystem = () -> {\n         while (!Thread.currentThread().isInterrupted()) {\n           try {\n-            byte[] serializedLogEvent = logQueue.take();\n-\n-            metrics.logMessagesBytesSent.inc(serializedLogEvent.length);\n-            metrics.logMessagesCountSent.inc();\n-\n-            OutgoingMessageEnvelope outgoingMessageEnvelope =\n-                new OutgoingMessageEnvelope(systemStream, keyBytes, serializedLogEvent);\n-            systemProducer.send(SOURCE, outgoingMessageEnvelope);\n-\n+            sendEventToSystemProducer(logQueue.take());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd9fbb3571d1e6fad66b665c6e6e53e37f9ac6f"}, "originalPosition": 176}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyOTUyMzc2OnYy", "diffSide": "RIGHT", "path": "samza-log4j2/src/main/java/org/apache/samza/logging/log4j2/StreamAppender.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMzo0NlrOG_JK1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMzo0NlrOG_JK1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MzcwMw==", "bodyText": "Capturing our offline conversation - \"We will need this to replaced with System.err as the recursion will drop this message in the event of not able to acquire the lock within the timeout\"", "url": "https://github.com/apache/samza/pull/1411#discussion_r468863703", "createdAt": "2020-08-11T21:03:46Z", "author": {"login": "mynameborat"}, "path": "samza-log4j2/src/main/java/org/apache/samza/logging/log4j2/StreamAppender.java", "diffHunk": "@@ -239,6 +227,46 @@ public void append(LogEvent event) {\n     }\n   }\n \n+  /**\n+   * If async-Logger is enabled, the log-event is sent directly to the systemProducer. Else, the event is serialized\n+   * and added to a bounded blocking queue, before returning to the \"synchronous\" caller.\n+   * @param event the log event to append\n+   * @throws InterruptedException\n+   */\n+  private void handleEvent(LogEvent event) throws InterruptedException {\n+    if (usingAsyncLogger) {\n+      sendEventToSystemProducer(encodeLogEventToBytes(event));\n+      return;\n+    }\n+\n+    // Serialize the event before adding to the queue to leverage the caller thread\n+    // and ensure that the transferThread can keep up.\n+    if (!logQueue.offer(encodeLogEventToBytes(event), queueTimeoutS, TimeUnit.SECONDS)) {\n+      // Do NOT retry adding system to the queue. Dropping the event allows us to alleviate the unlikely\n+      // possibility of a deadlock, which can arise due to a circular dependency between the SystemProducer\n+      // which is used for StreamAppender and the log, which uses StreamAppender. Any locks held in the callstack\n+      // of those two code paths can cause a deadlock. Dropping the event allows us to proceed.\n+\n+      // Scenario:\n+      // T1: holds L1 and is waiting for L2\n+      // T2: holds L2 and is waiting to produce to BQ1 which is drained by T3 (SystemProducer) which is waiting for L1\n+\n+      // This has happened due to locks in Kafka and log4j (see SAMZA-1537), which are both out of our control,\n+      // so dropping events in the StreamAppender is our best recourse.\n+\n+      // Drain the queue instead of dropping one message just to reduce the frequency of warn logs above.\n+      int messagesDropped = logQueue.drainTo(new ArrayList<>()) + 1; // +1 because of the current log event\n+      log.warn(String.format(\"Exceeded timeout %ss while trying to log to %s. Dropping %d log messages.\",\n+          queueTimeoutS,\n+          systemStream.toString(),\n+          messagesDropped));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1dd9fbb3571d1e6fad66b665c6e6e53e37f9ac6f"}, "originalPosition": 152}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1486, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}