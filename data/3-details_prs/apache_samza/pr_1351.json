{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4MzQxMzA5", "number": 1351, "title": "SAMZA-2515: Kafka consumer synchronized", "bodyText": "Symptom: containers dying with ConcurrentModificationException thrown from KafkaConsumer\nlike org.apache.samza.SamzaException: java.util.ConcurrentModificationException: KafkaConsumer is not safe for multi-threaded access... Caused by: java.util.ConcurrentModificationException: KafkaConsumer is not safe for multi-threaded access at org.apache.kafka.clients.consumer.KafkaConsumer.acquire(KafkaConsumer.java:2204) at org.apache.kafka.clients.consumer.KafkaConsumer.acquireAndEnsureOpen(KafkaConsumer.java:2188)  at org.apache.kafka.clients.consumer.KafkaConsumer.commitAsync(KafkaConsumer.java:1475)...\nCause:  The root cause is accessing KafkaConsumer inside KafkaConsumerProxy.initializeLags without a synchronized block.\nHow it was root caused: From KafkaConsumer.acquire code: KafkaConsumer tracks the current thread accessing the object. If another thread tries to access before the current thread has released then this ConcurrentModificationException is thrown. Checking logs of the failed container, KafkaConsumerProxy thread (say P) had started prior to this exception. Another thread  (say C) on which KafkaConsumer.commitAsync was invoked, actually accesses the shared consumer inside a synchronized block (like synchronized(consumer)). Thus, it was clear that though exception was thrown in C's code, it was a thread other than C (P in this case) which was holding access but had not entered a sync block prior to that. And of all the methods in P which access the consumer, this is the only method which does not have sync block.\nChanges: Add a synchronized block around kafkaConsumer access in initializeLags method.\nTests: unit test can not simulate this issue", "createdAt": "2020-04-24T05:37:59Z", "url": "https://github.com/apache/samza/pull/1351", "merged": true, "mergeCommit": {"oid": "a97f24985dc6074601b84c9980fc90f5f0ec2728"}, "closed": true, "closedAt": "2020-04-28T01:06:05Z", "author": {"login": "lakshmi-manasa-g"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcaptrlgH2gAyNDA4MzQxMzA5OjU3M2NmODQyMGEwZTQ5ZDlkMWZiZDZhMzg1Yjk1YTU2ODRlYzk0NGE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcb1uWdAH2gAyNDA4MzQxMzA5OjExMzY1YjljNTFlNjNkMWRhZWRhNjUwYWJiODBiMDgxMWQzOTI5Y2Y=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "573cf8420a0e49d9d1fbd6a385b95a5684ec944a", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/573cf8420a0e49d9d1fbd6a385b95a5684ec944a", "committedDate": "2020-04-24T04:24:07Z", "message": "SAMZA-2515 - Thread safety for KafkaConsumer in KafkaConsumerProxy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec9fca2578a0640cea7b1317507b41baa79244bb", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/ec9fca2578a0640cea7b1317507b41baa79244bb", "committedDate": "2020-04-24T04:26:20Z", "message": "fix exception message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/d9685b94643cdc2f162f52348037df967c8d03d0", "committedDate": "2020-04-24T05:24:18Z", "message": "add unit test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAwNDg4OTY0", "url": "https://github.com/apache/samza/pull/1351#pullrequestreview-400488964", "createdAt": "2020-04-26T10:48:48Z", "commit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMDo0ODo0OFrOGMCqjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNlQxMTo1MjowMlrOGMDZ-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3OTc1OA==", "bodyText": "I think its good idea to fail with meaningful errors instead of a potential NPE. Although, is this new contract necessary as part of this change?\n\nIs it possible for kafkaConsmer.endOffsets(...) to return null in the first place?\nIf yes to above, have we seen any issues around NPE before or is this purely from the standpoint of defensive programming?", "url": "https://github.com/apache/samza/pull/1351#discussion_r415279758", "createdAt": "2020-04-26T10:48:48Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {\n     // This is expensive, so only do it once at the beginning. After the first poll, we can rely on metrics for lag.\n-    Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+\n+    Map<TopicPartition, Long> endOffsets;\n+    // Synchronize, in case the consumer is used in some other thread (metadata or something else)\n+    synchronized (kafkaConsumer) {\n+      endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+    }\n+    if (endOffsets == null) {\n+      throw new SamzaException(\"Failed to fetch kafka consumer endoffsets for system \" + systemName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI5MTg5Nw==", "bodyText": "I see we don't have tests at all for consumer proxy and thanks for adding one :) However, I have few observations/questions\n\nThe test still does have some indeterminism and doesn't necessarily tests synchronized access as it claims all the time as it is possible that t1 & t2 run exclusively.\nIs the intent here to test java synchronized or prevent accidental changes to initializeLags making it no longer synchronize on the consumer?\n\n\nIf it is the former, it is going to be hard to test consistently and deterministically unless you do complex gimmicks with latches & Thread.holdsLock(...). IMO, it should be okay to assume Java synchronized works as expected\nIf it the latter, it is still undoubtedly hard but we can enforce them through other means with useful explicit comments around the code blocks & diligent reviews.\n\nTLDR; I am fine with not having a test for this scenario instead of having one that is indeterministic in what it tests. If you prefer to have a test, then it will be nice to have it do what it claims to do.", "url": "https://github.com/apache/samza/pull/1351#discussion_r415291897", "createdAt": "2020-04-26T11:52:02Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/test/java/org/apache/samza/system/kafka/TestKafkaConsumerProxy.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.samza.system.kafka;\n+\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.junit.Test;\n+\n+import static org.mockito.Mockito.anyCollection;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+\n+\n+public class TestKafkaConsumerProxy {\n+\n+  @Test\n+  public void testSynchronizedAccessOfKafkaConsumer() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 36}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ae3155fbaaca3401fc98076f57018bbb6983fd7", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/8ae3155fbaaca3401fc98076f57018bbb6983fd7", "committedDate": "2020-04-27T14:27:27Z", "message": "remove unit test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxMjk0NjM4", "url": "https://github.com/apache/samza/pull/1351#pullrequestreview-401294638", "createdAt": "2020-04-27T20:18:48Z", "commit": {"oid": "8ae3155fbaaca3401fc98076f57018bbb6983fd7"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxODo0OFrOGM164w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMDoxOToxNFrOGM177g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjExOTUyMw==", "bodyText": "sounds good \ud83d\udc4d", "url": "https://github.com/apache/samza/pull/1351#discussion_r416119523", "createdAt": "2020-04-27T20:18:48Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {\n     // This is expensive, so only do it once at the beginning. After the first poll, we can rely on metrics for lag.\n-    Map<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+\n+    Map<TopicPartition, Long> endOffsets;\n+    // Synchronize, in case the consumer is used in some other thread (metadata or something else)\n+    synchronized (kafkaConsumer) {\n+      endOffsets = kafkaConsumer.endOffsets(topicPartitionToSSP.keySet());\n+    }\n+    if (endOffsets == null) {\n+      throw new SamzaException(\"Failed to fetch kafka consumer endoffsets for system \" + systemName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTI3OTc1OA=="}, "originalCommit": {"oid": "d9685b94643cdc2f162f52348037df967c8d03d0"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjExOTc5MA==", "bodyText": "revert this to private?", "url": "https://github.com/apache/samza/pull/1351#discussion_r416119790", "createdAt": "2020-04-27T20:19:14Z", "author": {"login": "mynameborat"}, "path": "samza-kafka/src/main/java/org/apache/samza/system/kafka/KafkaConsumerProxy.java", "diffHunk": "@@ -170,9 +171,18 @@ Throwable getFailureCause() {\n     return failureCause;\n   }\n \n-  private void initializeLags() {\n+  @VisibleForTesting\n+  void initializeLags() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ae3155fbaaca3401fc98076f57018bbb6983fd7"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "571c112f5a80dc36e7315d04bc6974ccbe19cf82", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/571c112f5a80dc36e7315d04bc6974ccbe19cf82", "committedDate": "2020-04-27T20:55:38Z", "message": "remove visibileForTesting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11365b9c51e63d1daeda650abb80b0811d3929cf", "author": {"user": {"login": "lakshmi-manasa-g", "name": null}}, "url": "https://github.com/apache/samza/commit/11365b9c51e63d1daeda650abb80b0811d3929cf", "committedDate": "2020-04-27T20:57:38Z", "message": "remove visibileForTesting from imports"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4576, "cost": 1, "resetAt": "2021-11-01T11:59:11Z"}}}