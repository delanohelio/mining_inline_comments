{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2NTg5MzUy", "number": 1259, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzowMjozMlrODa8-oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOTo0Mjo0OFrODbWScg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5NTg4NjQxOnYy", "diffSide": "RIGHT", "path": "samza-api/src/main/java/org/apache/samza/metadatastore/MetadataStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzowMjozMlrOFiKSiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzowMjozMlrOFiKSiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM2NDQ4OA==", "bodyText": "Is this operation meant to be atomic? Does an impl of MetadataStore ensure that either all or none of this map is deleted?\nIs this operation meant to be idempotent?", "url": "https://github.com/apache/samza/pull/1259#discussion_r371364488", "createdAt": "2020-01-27T17:02:32Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-api/src/main/java/org/apache/samza/metadatastore/MetadataStore.java", "diffHunk": "@@ -67,6 +68,16 @@ default void putAll(Map<String, byte[]> entries) {\n    */\n   void delete(String key);\n \n+  /**\n+   * Deletes the mapping with the specified set.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd0aaac214f31cb1e77f812d3af2015e9eb6e7fc"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5NjAyNTgyOnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzo0NToxMVrOFiLoyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzo0NToxMVrOFiLoyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NjU2OQ==", "bodyText": "minor: might be good to add {@inheritdoc}", "url": "https://github.com/apache/samza/pull/1259#discussion_r371386569", "createdAt": "2020-01-27T17:45:11Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "diffHunk": "@@ -155,6 +156,15 @@ public void delete(String namespacedKey) {\n     put(namespacedKey, null);\n   }\n \n+  @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd0aaac214f31cb1e77f812d3af2015e9eb6e7fc"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5NjAzNTM5OnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzo0ODoxNFrOFiLuwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxNzo0ODoxNFrOFiLuwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4ODA5Ng==", "bodyText": "this is not atomic right. cause, theflush() is when the entries are guaranteed to be persisted on the coordinator stream and putAll does flush only at the end of all put. So if this is the expectation, then the MetadataStore interface should allow it.", "url": "https://github.com/apache/samza/pull/1259#discussion_r371388096", "createdAt": "2020-01-27T17:48:14Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "diffHunk": "@@ -155,6 +156,15 @@ public void delete(String namespacedKey) {\n     put(namespacedKey, null);\n   }\n \n+  @Override\n+  public void deleteAll(Collection<String> namespacedKeys) {\n+    Map<String, byte[]> entries = new HashMap<>(namespacedKeys.size());\n+    for (String namespacedKey : namespacedKeys) {\n+      entries.put(namespacedKey, null);\n+    }\n+    putAll(entries);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd0aaac214f31cb1e77f812d3af2015e9eb6e7fc"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5NjA4Njk2OnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskAssignmentManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxODowNTozMFrOFiMPVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yN1QxODowNTozMFrOFiMPVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM5NjQzNw==", "bodyText": "would it be good to replace wirteTaskContainerMapping with the new wirteTaskContainerMappings altogether?\nthere seems to be only one usage of this method and that has been replaced to use the new one in JobModelManager.\nis there a reason to keep this old method?", "url": "https://github.com/apache/samza/pull/1259#discussion_r371396437", "createdAt": "2020-01-27T18:05:30Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskAssignmentManager.java", "diffHunk": "@@ -103,21 +106,53 @@ public TaskAssignmentManager(MetadataStore taskContainerMappingMetadataStore, Me\n    * @param taskMode the mode of the task\n    */\n   public void writeTaskContainerMapping(String taskName, String containerId, TaskMode taskMode) {\n-    String existingContainerId = taskNameToContainerId.get(taskName);\n-    if (existingContainerId != null && !existingContainerId.equals(containerId)) {\n-      LOG.info(\"Task \\\"{}\\\" in mode {} moved from container {} to container {}\", new Object[]{taskName, taskMode, existingContainerId, containerId});\n-    } else {\n-      LOG.debug(\"Task \\\"{}\\\" in mode {} assigned to container {}\", taskName, taskMode, containerId);\n-    }\n+    writeTaskContainerMappings(ImmutableMap.of(containerId, ImmutableMap.of(taskName, taskMode)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd0aaac214f31cb1e77f812d3af2015e9eb6e7fc"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5OTk1NTA5OnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxODowMFrOFixVmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQyMTowMDoxMlrOFi0Snw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI0OQ==", "bodyText": "why do we catch only exceptions from metadatstore.put and not from its delete or flush?", "url": "https://github.com/apache/samza/pull/1259#discussion_r372004249", "createdAt": "2020-01-28T19:18:00Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "diffHunk": "@@ -66,28 +66,33 @@ public TaskPartitionAssignmentManager(MetadataStore metadataStore) {\n   }\n \n   /**\n-   * Stores the task to partition assignments to the metadata store.\n-   * @param partition the system stream partition.\n-   * @param taskNames the task names to which the partition is assigned to.\n+   * Stores the task names to {@link SystemStreamPartition} assignments to the metadata store.\n+   * @param sspToTaskNameMapping the mapped assignments to write to the metadata store. If the task name list is empty,\n+   *                             then the entry is deleted from the metadata store.\n    */\n-  public void writeTaskPartitionAssignment(SystemStreamPartition partition, List<String> taskNames) {\n-    // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n-    // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n-    // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n-    String serializedSSPAsJson = serializeSSPToJson(partition);\n-    if (taskNames == null || taskNames.isEmpty()) {\n-      LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n-      metadataStore.delete(serializedSSPAsJson);\n-    } else {\n-      try {\n-        String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames);\n-        byte[] taskNamesAsBytes = valueSerde.toBytes(taskNamesAsString);\n-        LOG.info(\"Storing the partition: {} and taskNames: {} into the metadata store.\", serializedSSPAsJson, taskNames);\n-        metadataStore.put(serializedSSPAsJson, taskNamesAsBytes);\n-      } catch (Exception e) {\n-        throw new SamzaException(\"Exception occurred when writing task to partition assignment.\", e);\n+  public void writeTaskPartitionAssignments(Map<SystemStreamPartition, List<String>> sspToTaskNameMapping) {\n+    for (SystemStreamPartition partition: sspToTaskNameMapping.keySet()) {\n+      List<String> taskNames = sspToTaskNameMapping.get(partition);\n+      LOG.info(\"Storing ssp: {} and task: {} into metadata store\", partition, taskNames);\n+      // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n+      // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n+      // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n+      String serializedSSPAsJson = serializeSSPToJson(partition);\n+      if (taskNames == null || taskNames.isEmpty()) {\n+        LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n+        metadataStore.delete(serializedSSPAsJson);\n+      } else {\n+        try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA1MTIxOA==", "bodyText": "In order to not break anything here, I just move the whole code block to the new function.\nThe statement String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames) throws exceptions explicitly, so exception need to be catched explicitly. I think original idea is not for metadatstore.put method.", "url": "https://github.com/apache/samza/pull/1259#discussion_r372051218", "createdAt": "2020-01-28T20:57:05Z", "author": {"login": "alnzng"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "diffHunk": "@@ -66,28 +66,33 @@ public TaskPartitionAssignmentManager(MetadataStore metadataStore) {\n   }\n \n   /**\n-   * Stores the task to partition assignments to the metadata store.\n-   * @param partition the system stream partition.\n-   * @param taskNames the task names to which the partition is assigned to.\n+   * Stores the task names to {@link SystemStreamPartition} assignments to the metadata store.\n+   * @param sspToTaskNameMapping the mapped assignments to write to the metadata store. If the task name list is empty,\n+   *                             then the entry is deleted from the metadata store.\n    */\n-  public void writeTaskPartitionAssignment(SystemStreamPartition partition, List<String> taskNames) {\n-    // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n-    // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n-    // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n-    String serializedSSPAsJson = serializeSSPToJson(partition);\n-    if (taskNames == null || taskNames.isEmpty()) {\n-      LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n-      metadataStore.delete(serializedSSPAsJson);\n-    } else {\n-      try {\n-        String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames);\n-        byte[] taskNamesAsBytes = valueSerde.toBytes(taskNamesAsString);\n-        LOG.info(\"Storing the partition: {} and taskNames: {} into the metadata store.\", serializedSSPAsJson, taskNames);\n-        metadataStore.put(serializedSSPAsJson, taskNamesAsBytes);\n-      } catch (Exception e) {\n-        throw new SamzaException(\"Exception occurred when writing task to partition assignment.\", e);\n+  public void writeTaskPartitionAssignments(Map<SystemStreamPartition, List<String>> sspToTaskNameMapping) {\n+    for (SystemStreamPartition partition: sspToTaskNameMapping.keySet()) {\n+      List<String> taskNames = sspToTaskNameMapping.get(partition);\n+      LOG.info(\"Storing ssp: {} and task: {} into metadata store\", partition, taskNames);\n+      // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n+      // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n+      // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n+      String serializedSSPAsJson = serializeSSPToJson(partition);\n+      if (taskNames == null || taskNames.isEmpty()) {\n+        LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n+        metadataStore.delete(serializedSSPAsJson);\n+      } else {\n+        try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI0OQ=="}, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA1MjYzOQ==", "bodyText": "ah, got it. thanks!", "url": "https://github.com/apache/samza/pull/1259#discussion_r372052639", "createdAt": "2020-01-28T21:00:12Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "diffHunk": "@@ -66,28 +66,33 @@ public TaskPartitionAssignmentManager(MetadataStore metadataStore) {\n   }\n \n   /**\n-   * Stores the task to partition assignments to the metadata store.\n-   * @param partition the system stream partition.\n-   * @param taskNames the task names to which the partition is assigned to.\n+   * Stores the task names to {@link SystemStreamPartition} assignments to the metadata store.\n+   * @param sspToTaskNameMapping the mapped assignments to write to the metadata store. If the task name list is empty,\n+   *                             then the entry is deleted from the metadata store.\n    */\n-  public void writeTaskPartitionAssignment(SystemStreamPartition partition, List<String> taskNames) {\n-    // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n-    // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n-    // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n-    String serializedSSPAsJson = serializeSSPToJson(partition);\n-    if (taskNames == null || taskNames.isEmpty()) {\n-      LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n-      metadataStore.delete(serializedSSPAsJson);\n-    } else {\n-      try {\n-        String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames);\n-        byte[] taskNamesAsBytes = valueSerde.toBytes(taskNamesAsString);\n-        LOG.info(\"Storing the partition: {} and taskNames: {} into the metadata store.\", serializedSSPAsJson, taskNames);\n-        metadataStore.put(serializedSSPAsJson, taskNamesAsBytes);\n-      } catch (Exception e) {\n-        throw new SamzaException(\"Exception occurred when writing task to partition assignment.\", e);\n+  public void writeTaskPartitionAssignments(Map<SystemStreamPartition, List<String>> sspToTaskNameMapping) {\n+    for (SystemStreamPartition partition: sspToTaskNameMapping.keySet()) {\n+      List<String> taskNames = sspToTaskNameMapping.get(partition);\n+      LOG.info(\"Storing ssp: {} and task: {} into metadata store\", partition, taskNames);\n+      // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n+      // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n+      // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n+      String serializedSSPAsJson = serializeSSPToJson(partition);\n+      if (taskNames == null || taskNames.isEmpty()) {\n+        LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n+        metadataStore.delete(serializedSSPAsJson);\n+      } else {\n+        try {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI0OQ=="}, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI5OTk2NjgxOnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToyMTo0OFrOFixdDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQyMDo0OToxN1rOFiz--Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNjE1Nw==", "bodyText": "do we need this impl of putAll because MetadataStore.putAll default impl in the interface MetadatStore is the same?", "url": "https://github.com/apache/samza/pull/1259#discussion_r372006157", "createdAt": "2020-01-28T19:21:48Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "diffHunk": "@@ -149,6 +136,13 @@ private void putWithoutFlush(String namespacedKey, byte[] value) {\n     systemProducer.send(SOURCE, envelope);\n   }\n \n+  @Override\n+  public void putAll(Map<String, byte[]> entries) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA0NzYwOQ==", "bodyText": "Good catch @lakshmi-manasa-g . This function is duplicated with the one in MetadataStore, I will delete it.", "url": "https://github.com/apache/samza/pull/1259#discussion_r372047609", "createdAt": "2020-01-28T20:49:17Z", "author": {"login": "alnzng"}, "path": "samza-core/src/main/java/org/apache/samza/coordinator/metadatastore/CoordinatorStreamStore.java", "diffHunk": "@@ -149,6 +136,13 @@ private void putWithoutFlush(String namespacedKey, byte[] value) {\n     systemProducer.send(SOURCE, envelope);\n   }\n \n+  @Override\n+  public void putAll(Map<String, byte[]> entries) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNjE1Nw=="}, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDAzMzE0OnYy", "diffSide": "RIGHT", "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOTo0Mjo0OFrOFiyG4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQyMTowMjo1NFrOFi0X1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAxNjg2NA==", "bodyText": "minor: is this log statement really needed? Because it will be followed by another log statement immediately that says either the key is being deleted or partition is being stored (only that the SSP is a JSON in the storing log statement).", "url": "https://github.com/apache/samza/pull/1259#discussion_r372016864", "createdAt": "2020-01-28T19:42:48Z", "author": {"login": "lakshmi-manasa-g"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "diffHunk": "@@ -66,28 +66,33 @@ public TaskPartitionAssignmentManager(MetadataStore metadataStore) {\n   }\n \n   /**\n-   * Stores the task to partition assignments to the metadata store.\n-   * @param partition the system stream partition.\n-   * @param taskNames the task names to which the partition is assigned to.\n+   * Stores the task names to {@link SystemStreamPartition} assignments to the metadata store.\n+   * @param sspToTaskNameMapping the mapped assignments to write to the metadata store. If the task name list is empty,\n+   *                             then the entry is deleted from the metadata store.\n    */\n-  public void writeTaskPartitionAssignment(SystemStreamPartition partition, List<String> taskNames) {\n-    // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n-    // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n-    // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n-    String serializedSSPAsJson = serializeSSPToJson(partition);\n-    if (taskNames == null || taskNames.isEmpty()) {\n-      LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n-      metadataStore.delete(serializedSSPAsJson);\n-    } else {\n-      try {\n-        String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames);\n-        byte[] taskNamesAsBytes = valueSerde.toBytes(taskNamesAsString);\n-        LOG.info(\"Storing the partition: {} and taskNames: {} into the metadata store.\", serializedSSPAsJson, taskNames);\n-        metadataStore.put(serializedSSPAsJson, taskNamesAsBytes);\n-      } catch (Exception e) {\n-        throw new SamzaException(\"Exception occurred when writing task to partition assignment.\", e);\n+  public void writeTaskPartitionAssignments(Map<SystemStreamPartition, List<String>> sspToTaskNameMapping) {\n+    for (SystemStreamPartition partition: sspToTaskNameMapping.keySet()) {\n+      List<String> taskNames = sspToTaskNameMapping.get(partition);\n+      LOG.info(\"Storing ssp: {} and task: {} into metadata store\", partition, taskNames);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA1Mzk3NA==", "bodyText": "Hmm, I think you are right. Let me remove this log line. Thanks.", "url": "https://github.com/apache/samza/pull/1259#discussion_r372053974", "createdAt": "2020-01-28T21:02:54Z", "author": {"login": "alnzng"}, "path": "samza-core/src/main/java/org/apache/samza/container/grouper/task/TaskPartitionAssignmentManager.java", "diffHunk": "@@ -66,28 +66,33 @@ public TaskPartitionAssignmentManager(MetadataStore metadataStore) {\n   }\n \n   /**\n-   * Stores the task to partition assignments to the metadata store.\n-   * @param partition the system stream partition.\n-   * @param taskNames the task names to which the partition is assigned to.\n+   * Stores the task names to {@link SystemStreamPartition} assignments to the metadata store.\n+   * @param sspToTaskNameMapping the mapped assignments to write to the metadata store. If the task name list is empty,\n+   *                             then the entry is deleted from the metadata store.\n    */\n-  public void writeTaskPartitionAssignment(SystemStreamPartition partition, List<String> taskNames) {\n-    // For broadcast streams, a input system stream partition will be mapped to more than one tasks in a\n-    // SamzaContainer. Rather than storing taskName to list of SystemStreamPartitions in metadata store, here\n-    // systemStreamPartition to list of taskNames is stored. This was done due to 1 MB limit on value size in kafka.\n-    String serializedSSPAsJson = serializeSSPToJson(partition);\n-    if (taskNames == null || taskNames.isEmpty()) {\n-      LOG.info(\"Deleting the key: {} from the metadata store.\", partition);\n-      metadataStore.delete(serializedSSPAsJson);\n-    } else {\n-      try {\n-        String taskNamesAsString = taskNamesMapper.writeValueAsString(taskNames);\n-        byte[] taskNamesAsBytes = valueSerde.toBytes(taskNamesAsString);\n-        LOG.info(\"Storing the partition: {} and taskNames: {} into the metadata store.\", serializedSSPAsJson, taskNames);\n-        metadataStore.put(serializedSSPAsJson, taskNamesAsBytes);\n-      } catch (Exception e) {\n-        throw new SamzaException(\"Exception occurred when writing task to partition assignment.\", e);\n+  public void writeTaskPartitionAssignments(Map<SystemStreamPartition, List<String>> sspToTaskNameMapping) {\n+    for (SystemStreamPartition partition: sspToTaskNameMapping.keySet()) {\n+      List<String> taskNames = sspToTaskNameMapping.get(partition);\n+      LOG.info(\"Storing ssp: {} and task: {} into metadata store\", partition, taskNames);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAxNjg2NA=="}, "originalCommit": {"oid": "e34e917e499c143841ca0bb588dc1323de9dbb17"}, "originalPosition": 30}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1555, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}