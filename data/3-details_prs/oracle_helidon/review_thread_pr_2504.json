{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1ODE1ODg3", "number": 2504, "reviewThreads": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwOToxMToyMVrOE3nkuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMDoyNDoxOVrOFCDmOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NzU1NTEzOnYy", "diffSide": "RIGHT", "path": "docs/mp/graphql/01_mp_graphql.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwOToxMToyMVrOHxEhyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjowNzowOVrOHxryrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIxNjQ1OQ==", "bodyText": "name x names getAllCustomers(name)", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r521216459", "createdAt": "2020-11-11T09:11:21Z", "author": {"login": "danielkec"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.\n+The spec prescribes how applications can be built to expose an endpoint for GraphQL.\n+GraphQL is an open-source data query and manipulation language for APIs,\n+and a runtime for fulfilling queries with existing data.\n+It provides an alternative, though not necessarily a replacement for REST.\n+\n+For more information on GraphQL see https://graphql.org/.\n+\n+== Maven Coordinates\n+\n+The <<about/04_managing-dependencies.adoc, Managing Dependencies>> page describes how you\n+should declare dependency management for Helidon applications. Then declare the following dependency in your project:\n+\n+[source,xml]\n+----\n+<dependency>\n+    <groupId>io.helidon.microprofile.graphql</groupId>\n+    <artifactId>helidon-microprofile-graphql-server</artifactId>\n+</dependency>\n+----\n+\n+== Getting Started\n+\n+=== Defining your API\n+\n+The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint:\n+\n+* `@GraphQLApi` - identifies a CDI Bean as a GraphQL Endpoint\n+* `@Query` - identifies a method as returning specified fields for an object or collection of entities\n+* `@Mutation` - identifies a method which creates, deletes or updates entities\n+\n+NOTE: Please see the link:https://github.com/eclipse/microprofile-graphql[Microprofile GraphQL spec] for the full list of available annotations.\n+\n+For example, the following defines a GraphQL endpoint with a number of queries and mutations that work\n+against a fictional `CustomerService` service and `Customer` class.\n+\n+[source,java]\n+.Simple ContactGraphQLApi\n+----\n+@ApplicationScoped\n+@org.eclipse.microprofile.graphql.GraphQLApi\n+public class ContactGraphQLApi {\n+\n+    @Inject\n+    private CustomerService customerService;\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findAllCustomers() {  <1>\n+        return customerService.getAllCustomers();\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Customer findCustomer(@Name(\"customerId\") int id) {  <2>\n+        return customerService.getCustomer(id);\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findCustomersByName(@Name(\"name\") String name) {  <3>\n+        return customerService.getAllCustomers(names);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b205814d1751d8eb38ea3d1a1bd1f8a2ce1f9bf"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg1OTc1OQ==", "bodyText": "Thanks. Have fixed.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r521859759", "createdAt": "2020-11-12T06:07:09Z", "author": {"login": "tmiddlet2666"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.\n+The spec prescribes how applications can be built to expose an endpoint for GraphQL.\n+GraphQL is an open-source data query and manipulation language for APIs,\n+and a runtime for fulfilling queries with existing data.\n+It provides an alternative, though not necessarily a replacement for REST.\n+\n+For more information on GraphQL see https://graphql.org/.\n+\n+== Maven Coordinates\n+\n+The <<about/04_managing-dependencies.adoc, Managing Dependencies>> page describes how you\n+should declare dependency management for Helidon applications. Then declare the following dependency in your project:\n+\n+[source,xml]\n+----\n+<dependency>\n+    <groupId>io.helidon.microprofile.graphql</groupId>\n+    <artifactId>helidon-microprofile-graphql-server</artifactId>\n+</dependency>\n+----\n+\n+== Getting Started\n+\n+=== Defining your API\n+\n+The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint:\n+\n+* `@GraphQLApi` - identifies a CDI Bean as a GraphQL Endpoint\n+* `@Query` - identifies a method as returning specified fields for an object or collection of entities\n+* `@Mutation` - identifies a method which creates, deletes or updates entities\n+\n+NOTE: Please see the link:https://github.com/eclipse/microprofile-graphql[Microprofile GraphQL spec] for the full list of available annotations.\n+\n+For example, the following defines a GraphQL endpoint with a number of queries and mutations that work\n+against a fictional `CustomerService` service and `Customer` class.\n+\n+[source,java]\n+.Simple ContactGraphQLApi\n+----\n+@ApplicationScoped\n+@org.eclipse.microprofile.graphql.GraphQLApi\n+public class ContactGraphQLApi {\n+\n+    @Inject\n+    private CustomerService customerService;\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findAllCustomers() {  <1>\n+        return customerService.getAllCustomers();\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Customer findCustomer(@Name(\"customerId\") int id) {  <2>\n+        return customerService.getCustomer(id);\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findCustomersByName(@Name(\"name\") String name) {  <3>\n+        return customerService.getAllCustomers(names);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIxNjQ1OQ=="}, "originalCommit": {"oid": "2b205814d1751d8eb38ea3d1a1bd1f8a2ce1f9bf"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzQ3MjY5OnYy", "diffSide": "RIGHT", "path": "docs/mp/graphql/01_mp_graphql.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNDoyMDo0M1rOHx88Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNDoyMDo0M1rOHx88Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE0MDcyMg==", "bodyText": "Tiny possible change: \"It provides an alternative to, though not necessarily a replacement for, REST.\"", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522140722", "createdAt": "2020-11-12T14:20:43Z", "author": {"login": "tjquinno"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.\n+The spec prescribes how applications can be built to expose an endpoint for GraphQL.\n+GraphQL is an open-source data query and manipulation language for APIs,\n+and a runtime for fulfilling queries with existing data.\n+It provides an alternative, though not necessarily a replacement for REST.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3Mzc3MDM3OnYy", "diffSide": "RIGHT", "path": "docs/mp/graphql/01_mp_graphql.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToyMjozMlrOHx_2pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMToxNTo0NFrOHyVwoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4ODQ1NA==", "bodyText": "Do we need to be explicit about the version here in the doc? If we have to, maybe parameterize it? Either with an attribute setting at the top of this .adoc file (which we'd need to change from time to time) or -- for nicer automation -- by adding a definition to docs/sitegen.yaml to propagate the maven property value for the version as an AsciiDoctor attribute usable in the .adoc file?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522188454", "createdAt": "2020-11-12T15:22:32Z", "author": {"login": "tjquinno"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU0NzM2MA==", "bodyText": "Version 1.0.3 is the first version we were able to certify against. I can put an attribute in docs/sitegen.yaml which points to the version we are using in the pom.xml so this will be automatic and clear.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522547360", "createdAt": "2020-11-13T01:15:44Z", "author": {"login": "tmiddlet2666"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4ODQ1NA=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3Mzc3ODgzOnYy", "diffSide": "RIGHT", "path": "docs/mp/graphql/01_mp_graphql.adoc", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToyNDoyMVrOHx_75Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToyNDoyMVrOHx_75Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE4OTc5Nw==", "bodyText": "If the developer parents the pom to the Helidon applications parent, then the version is specified in the inherited dependency management section and doesn't need to be specified here. (As you can tell, I get nervous about explicit versions that will need to be updated someday!)", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522189797", "createdAt": "2020-11-12T15:24:21Z", "author": {"login": "tjquinno"}, "path": "docs/mp/graphql/01_mp_graphql.adoc", "diffHunk": "@@ -0,0 +1,223 @@\n+///////////////////////////////////////////////////////////////////////////////\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+\n+    Licensed under the Apache License, Version 2.0 (the \"License\");\n+    you may not use this file except in compliance with the License.\n+    You may obtain a copy of the License at\n+\n+        http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+\n+///////////////////////////////////////////////////////////////////////////////\n+\n+= MicroProfile GraphQL\n+:h1Prefix: MP\n+:pagename: microprofile-graphql\n+:description: Helidon GraphQL MicroProfile\n+:keywords: helidon, graphql, microprofile, micro-profile\n+\n+\n+The Microprofile GraphQL APIs are an extension to <<microprofile/01_introduction.adoc, Helidon MP>>\n+to allow building of applications that can expose a GraphQL endpoint and optionally a link:https://github.com/graphql/graphiql[GraphiQL] API.\n+\n+== About the MicroProfile GraphQL Specification\n+Helidon MP implements the MicroProfile GraphQL\n+link:https://github.com/eclipse/microprofile-graphql[spec] version 1.0.3.\n+The spec prescribes how applications can be built to expose an endpoint for GraphQL.\n+GraphQL is an open-source data query and manipulation language for APIs,\n+and a runtime for fulfilling queries with existing data.\n+It provides an alternative, though not necessarily a replacement for REST.\n+\n+For more information on GraphQL see https://graphql.org/.\n+\n+== Maven Coordinates\n+\n+The <<about/04_managing-dependencies.adoc, Managing Dependencies>> page describes how you\n+should declare dependency management for Helidon applications. Then declare the following dependency in your project:\n+\n+[source,xml]\n+----\n+<dependency>\n+    <groupId>io.helidon.microprofile.graphql</groupId>\n+    <artifactId>helidon-microprofile-graphql-server</artifactId>\n+</dependency>\n+----\n+\n+== Getting Started\n+\n+=== Defining your API\n+\n+The MicroProfile GraphQL specification defines a number of key annotations to be used when writing a GraphQL endpoint:\n+\n+* `@GraphQLApi` - identifies a CDI Bean as a GraphQL Endpoint\n+* `@Query` - identifies a method as returning specified fields for an object or collection of entities\n+* `@Mutation` - identifies a method which creates, deletes or updates entities\n+\n+NOTE: Please see the link:https://github.com/eclipse/microprofile-graphql[Microprofile GraphQL spec] for the full list of available annotations.\n+\n+For example, the following defines a GraphQL endpoint with a number of queries and mutations that work\n+against a fictional `CustomerService` service and `Customer` class.\n+\n+[source,java]\n+.Simple ContactGraphQLApi\n+----\n+@ApplicationScoped\n+@org.eclipse.microprofile.graphql.GraphQLApi\n+public class ContactGraphQLApi {\n+\n+    @Inject\n+    private CustomerService customerService;\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findAllCustomers() {  <1>\n+        return customerService.getAllCustomers();\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Customer findCustomer(@Name(\"customerId\") int id) {  <2>\n+        return customerService.getCustomer(id);\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Query\n+    public Collection<Customer> findCustomersByName(@Name(\"name\") String name) {  <3>\n+        return customerService.getAllCustomers(name);\n+    }\n+\n+    @org.eclipse.microprofile.graphql.Mutation\n+    public Contact createCustomer(@Name(\"customerId\") int id,  <4>\n+                                  @Name(\"name\") String name,\n+                                  @Name(\"balance\") float balance) {\n+        return customerService.createCustomer(id, name, balance);\n+    }\n+}\n+\n+public class customer {\n+    private int id;\n+    @NonNull\n+    private String name;\n+    private float balance;\n+\n+    // getters and setters omitted for brevity\n+}\n+----\n+\n+<1> a query with no-arguments that will return all Customers\n+<2> a query that takes an argument to return a specific Customer\n+<3> a query that optionally takes a name and returns a collection of Customers\n+<4> a mutation that creates a Customer and returns the newly created Customer\n+\n+The above would generate a GraphQL schema as shown below:\n+[source,graphql]\n+.Sample GraphQL Schema\n+----\n+type Query {\n+   findAllCustomers: [Customer]\n+   findCustomer(customerId: Int!): Customer\n+   findCustomersByName(name: String): [Customers]\n+}\n+\n+type Mutation {\n+   createCustomer(customerId: Int!, name: String!, balance: Float!): Customer\n+}\n+\n+type Customer {\n+   id: Int!\n+   name: String!\n+   balance: Float\n+}\n+----\n+\n+After application startup, a GraphQL schema will be generated from your annotated API classes\n+and POJO's and you will be able to access these via the URL's described below.\n+\n+=== Creating your entry-point\n+\n+As per the instructions <<mp/introduction/02_microprofile.adoc, here>> ensure you have added a\n+`src/main/resources/META-INF/beans.xml` file, so the CDI implementation can pick up your classes.\n+\n+A `Main` class is not needed, you can configure `io.helidon.microprofile.cdi.Main` as the entry point.\n+\n+Optionally, you can configure a custom entry point (such as when you need custom configuration setup).\n+\n+[source,java]\n+.Sample Entry-point\n+----\n+public class MyMain {\n+    public static void main(String[] args) {\n+        io.helidon.microprofile.cdi.Main.main(args);\n+    }\n+}\n+----\n+\n+=== Building your application\n+\n+As part of building your application, you must create a Jandex index\n+using the `jandex-maven-plugin` for all API and POJO classes that are used.\n+\n+[source,xml]\n+.Generate Jandex index\n+----\n+<plugin>\n+<groupId>org.jboss.jandex</groupId>\n+<artifactId>jandex-maven-plugin</artifactId>\n+<version>1.0.8</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3Mzc4Nzg3OnYy", "diffSide": "RIGHT", "path": "docs/mp/introduction/01_introduction.adoc", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNToyNjoxN1rOHyABpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMDozODoyM1rOHyUqtg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5MTI3MQ==", "bodyText": "We don't want to change the health glyph to the same one as for GraphQL, do we?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522191271", "createdAt": "2020-11-12T15:26:17Z", "author": {"login": "tjquinno"}, "path": "docs/mp/introduction/01_introduction.adoc", "diffHunk": "@@ -85,17 +85,26 @@ Add support for CORS to your application using a Helidon module.\n Defines annotations that improve applications by providing support to handle error conditions (faults). \n --\n \n+//GraphQL\n+[CARD]\n+.GraphQL\n+[icon=graphic_eq,link=mp/graphql/01_mp_graphql.adoc]\n+--\n+Expose GraphQL API using Microprofile GraphQL.\n+--\n+\n //gRPC\n [CARD]\n .gRPC\n [icon=swap_horiz,link=mp/grpc/01_mp_server_side_services.adoc]\n --\n Build gRPC servers and clients.\n --\n+\n //Health Checks\n [CARD]\n .Health Checks\n-[icon=favorite_outline,link=mp/health/01_introduction.adoc]\n+[icon=graphic_eq,link=mp/health/01_introduction.adoc]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUyOTQ2Mg==", "bodyText": "My mistake..", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522529462", "createdAt": "2020-11-13T00:38:23Z", "author": {"login": "tmiddlet2666"}, "path": "docs/mp/introduction/01_introduction.adoc", "diffHunk": "@@ -85,17 +85,26 @@ Add support for CORS to your application using a Helidon module.\n Defines annotations that improve applications by providing support to handle error conditions (faults). \n --\n \n+//GraphQL\n+[CARD]\n+.GraphQL\n+[icon=graphic_eq,link=mp/graphql/01_mp_graphql.adoc]\n+--\n+Expose GraphQL API using Microprofile GraphQL.\n+--\n+\n //gRPC\n [CARD]\n .gRPC\n [icon=swap_horiz,link=mp/grpc/01_mp_server_side_services.adoc]\n --\n Build gRPC servers and clients.\n --\n+\n //Health Checks\n [CARD]\n .Health Checks\n-[icon=favorite_outline,link=mp/health/01_introduction.adoc]\n+[icon=graphic_eq,link=mp/health/01_introduction.adoc]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5MTI3MQ=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzgwNzkxOnYy", "diffSide": "RIGHT", "path": "examples/microprofile/graphql/README.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTozMDoxNlrOHyAOTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTozMDoxNlrOHyAOTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5NDUwOQ==", "bodyText": "Again my concern with hardcoded versions in the doc.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522194509", "createdAt": "2020-11-12T15:30:16Z", "author": {"login": "tjquinno"}, "path": "examples/microprofile/graphql/README.md", "diffHunk": "@@ -0,0 +1,116 @@\n+# Microprofile GraphQL Example\n+\n+This example creates a simple Task API using Helidon's implementation of the Microprofile GraphQL API Specification (1.0.3)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzgxNzQ5OnYy", "diffSide": "RIGHT", "path": "examples/microprofile/graphql/README.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTozMjowNFrOHyAUEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMzoyNTo0MVrOH9ybLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5NTk4NQ==", "bodyText": "Typo: GraphiQL -> GraphQL", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522195985", "createdAt": "2020-11-12T15:32:04Z", "author": {"login": "tjquinno"}, "path": "examples/microprofile/graphql/README.md", "diffHunk": "@@ -0,0 +1,116 @@\n+# Microprofile GraphQL Example\n+\n+This example creates a simple Task API using Helidon's implementation of the Microprofile GraphQL API Specification (1.0.3)\n+\n+See [here](https://github.com/eclipse/microprofile-graphql) for more information on the \n+Microprofile GraphQL Specification as well as the [Helidon documentation](https://helidon.io/docs/v2/#/mp/introduction/01_introduction)\n+for an introduction to using GraphQL in Helidon MP.\n+\n+## Running the example\n+\n+1. Build\n+\n+```bash\n+mvn clean install\n+```              \n+\n+2. Run the example\n+\n+```bash\n+java -jar target/helidon-examples-microprofile-graphql.jar\n+```\n+\n+## Issuing GraphQL requests \n+\n+1. Access the GraphiQL UI via the following URL: http://127.0.0.1:7001/ui.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1MTM0Mg==", "bodyText": "This has been fixed", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534551342", "createdAt": "2020-12-02T23:25:41Z", "author": {"login": "tmiddlet2666"}, "path": "examples/microprofile/graphql/README.md", "diffHunk": "@@ -0,0 +1,116 @@\n+# Microprofile GraphQL Example\n+\n+This example creates a simple Task API using Helidon's implementation of the Microprofile GraphQL API Specification (1.0.3)\n+\n+See [here](https://github.com/eclipse/microprofile-graphql) for more information on the \n+Microprofile GraphQL Specification as well as the [Helidon documentation](https://helidon.io/docs/v2/#/mp/introduction/01_introduction)\n+for an introduction to using GraphQL in Helidon MP.\n+\n+## Running the example\n+\n+1. Build\n+\n+```bash\n+mvn clean install\n+```              \n+\n+2. Run the example\n+\n+```bash\n+java -jar target/helidon-examples-microprofile-graphql.jar\n+```\n+\n+## Issuing GraphQL requests \n+\n+1. Access the GraphiQL UI via the following URL: http://127.0.0.1:7001/ui.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5NTk4NQ=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzgzMjI3OnYy", "diffSide": "RIGHT", "path": "examples/microprofile/graphql/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTozNToxNVrOHyAdcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMzoyNjoxNFrOH9ycEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5ODM4NQ==", "bodyText": "Remove \"All rights reserved.\" We're trying to remember to do that when we update earlier files.\nAlso, isn't this a new file? The notice shouldn't include 2018.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522198385", "createdAt": "2020-11-12T15:35:15Z", "author": {"login": "tjquinno"}, "path": "examples/microprofile/graphql/pom.xml", "diffHunk": "@@ -0,0 +1,68 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  Copyright (c) 2018, 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1MTU3MA==", "bodyText": "resolved", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534551570", "createdAt": "2020-12-02T23:26:14Z", "author": {"login": "tmiddlet2666"}, "path": "examples/microprofile/graphql/pom.xml", "diffHunk": "@@ -0,0 +1,68 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  Copyright (c) 2018, 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE5ODM4NQ=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzkxNDIxOnYy", "diffSide": "RIGHT", "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1MToxOFrOHyBQLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1MToxOFrOHyBQLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxMTM3NQ==", "bodyText": "Should the server be shut down at the end of the test?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522211375", "createdAt": "2020-11-12T15:51:18Z", "author": {"login": "tjquinno"}, "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.graphql.server;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import io.helidon.media.jsonb.JsonbSupport;\n+import io.helidon.webclient.WebClient;\n+import io.helidon.webserver.Routing;\n+import io.helidon.webserver.WebServer;\n+\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.StaticDataFetcher;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaGenerator;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.notNullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+class GraphQlSupportTest {\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    void testHelloWorld() {\n+        WebServer server = WebServer.builder()\n+                .routing(Routing.builder()\n+                                 .register(GraphQlSupport.create(buildSchema()))\n+                                 .build())\n+                .build()\n+                .start()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzkyODkxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/AbstractDescriptiveElement.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1NDoxNVrOHyBZVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1NDoxNVrOHyBZVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxMzcxNw==", "bodyText": "New file. Remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522213717", "createdAt": "2020-11-12T15:54:15Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/AbstractDescriptiveElement.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MzkzMDgzOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1NDozNFrOHyBafA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1NDozNFrOHyBafA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxNDAxMg==", "bodyText": "New file. Remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522214012", "createdAt": "2020-11-12T15:54:34Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3Mzk0NDY5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNTo1NzoyOFrOHyBjHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMzozMDo1MFrOH9yjhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxNjIyMA==", "bodyText": "Casting to String is harmless here, but it surprised me given the method's return type is Object anyway.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522216220", "createdAt": "2020-11-12T15:57:28Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+\n+import graphql.Scalars;\n+import graphql.language.StringValue;\n+import graphql.scalars.ExtendedScalars;\n+import graphql.schema.Coercing;\n+import graphql.schema.CoercingParseLiteralException;\n+import graphql.schema.CoercingParseValueException;\n+import graphql.schema.CoercingSerializeException;\n+import graphql.schema.GraphQLScalarType;\n+\n+import static graphql.Scalars.GraphQLBigInteger;\n+import static graphql.Scalars.GraphQLFloat;\n+import static graphql.Scalars.GraphQLInt;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+\n+/**\n+ * Custom scalars.\n+ */\n+class CustomScalars {\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private CustomScalars() {\n+    }\n+\n+    /**\n+     * An instance of a custome BigDecimal Scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGDECIMAL_SCALAR = newCustomBigDecimalScalar();\n+\n+    /**\n+     * An instance of a custom Int scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_INT_SCALAR = newCustomGraphQLInt();\n+\n+    /**\n+     * An instance of a custom Float scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_FLOAT_SCALAR = newCustomGraphQLFloat();\n+\n+    /**\n+     * An instance of a custom BigInteger scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGINTEGER_SCALAR = newCustomGraphQLBigInteger();\n+\n+    /**\n+     * An instance of a custom formatted date/time scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(FORMATTED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted time scalar.\n+     */\n+     static final GraphQLScalarType FORMATTED_CUSTOM_TIME_SCALAR = newTimeScalar(FORMATTED_TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted date scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_SCALAR = newDateScalar(FORMATTED_DATE_SCALAR);\n+\n+    /**\n+     * An instance of a custom date/time scalar (with default formatting).\n+     */\n+    static final GraphQLScalarType CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_OFFSET_DATE_TIME_SCALAR =\n+            newOffsetDateTimeScalar(FORMATTED_OFFSET_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_ZONED_DATE_TIME_SCALAR =\n+            newZonedDateTimeScalar(FORMATTED_ZONED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_TIME_SCALAR = newTimeScalar(TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom date scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_DATE_SCALAR = newDateScalar(DATE_SCALAR);\n+\n+    /**\n+     * Return a new custom date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+     static GraphQLScalarType newDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom offset date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newOffsetDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom zoned date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newZonedDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom time scalar\n+     */\n+     static GraphQLScalarType newTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Time;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new TimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom date scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date scalar\n+     */\n+     static GraphQLScalarType newDateScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Date;\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigDecimal scalar.\n+     *\n+     * @return a new custom BigDecimal scalar\n+     */\n+    private static GraphQLScalarType newCustomBigDecimalScalar() {\n+        GraphQLScalarType originalScalar = Scalars.GraphQLBigDecimal;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigDecimal>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Int scalar.\n+     *\n+     * @return a new custom Int scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLInt() {\n+        GraphQLScalarType originalScalar = GraphQLInt;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Integer>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Float scalar.\n+     *\n+     * @return a new custom Float scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLFloat() {\n+        GraphQLScalarType originalScalar = GraphQLFloat;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Double>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigInteger scalar.\n+     *\n+     * @return a new custom BigInteger scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLBigInteger() {\n+        GraphQLScalarType originalScalar = GraphQLBigInteger;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigInteger>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Abstract implementation of {@link Coercing} interface for given classes.\n+     */\n+     abstract static class AbstractDateTimeCoercing implements Coercing {\n+\n+        /**\n+         * {@link Class}es that can be coerced.\n+         */\n+        private final Class<?>[] clazzes;\n+\n+        /**\n+         * Construct a {@link AbstractDateTimeCoercing}.\n+         *\n+         * @param clazzes {@link Class}es to coerce\n+         */\n+         AbstractDateTimeCoercing(Class<?>... clazzes) {\n+            this.clazzes = clazzes;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return convert(dataFetcherResult);\n+        }\n+\n+        @Override\n+        public Object parseValue(Object input) throws CoercingParseValueException {\n+            return convert(input);\n+        }\n+\n+        @Override\n+        public Object parseLiteral(Object input) throws CoercingParseLiteralException {\n+            return parseStringLiteral(input);\n+        }\n+\n+        /**\n+         * Convert the given input to the type of if a String then leave it be.\n+         *\n+         * @param input input to coerce\n+         * @return the coerced value\n+         * @throws CoercingParseLiteralException if any exceptions converting\n+         */\n+        private Object convert(Object input) throws CoercingParseLiteralException {\n+            if (input instanceof String) {\n+                return (String) input;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1MzQ3Ng==", "bodyText": "fair enough.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534553476", "createdAt": "2020-12-02T23:30:50Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+\n+import graphql.Scalars;\n+import graphql.language.StringValue;\n+import graphql.scalars.ExtendedScalars;\n+import graphql.schema.Coercing;\n+import graphql.schema.CoercingParseLiteralException;\n+import graphql.schema.CoercingParseValueException;\n+import graphql.schema.CoercingSerializeException;\n+import graphql.schema.GraphQLScalarType;\n+\n+import static graphql.Scalars.GraphQLBigInteger;\n+import static graphql.Scalars.GraphQLFloat;\n+import static graphql.Scalars.GraphQLInt;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+\n+/**\n+ * Custom scalars.\n+ */\n+class CustomScalars {\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private CustomScalars() {\n+    }\n+\n+    /**\n+     * An instance of a custome BigDecimal Scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGDECIMAL_SCALAR = newCustomBigDecimalScalar();\n+\n+    /**\n+     * An instance of a custom Int scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_INT_SCALAR = newCustomGraphQLInt();\n+\n+    /**\n+     * An instance of a custom Float scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_FLOAT_SCALAR = newCustomGraphQLFloat();\n+\n+    /**\n+     * An instance of a custom BigInteger scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGINTEGER_SCALAR = newCustomGraphQLBigInteger();\n+\n+    /**\n+     * An instance of a custom formatted date/time scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(FORMATTED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted time scalar.\n+     */\n+     static final GraphQLScalarType FORMATTED_CUSTOM_TIME_SCALAR = newTimeScalar(FORMATTED_TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted date scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_SCALAR = newDateScalar(FORMATTED_DATE_SCALAR);\n+\n+    /**\n+     * An instance of a custom date/time scalar (with default formatting).\n+     */\n+    static final GraphQLScalarType CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_OFFSET_DATE_TIME_SCALAR =\n+            newOffsetDateTimeScalar(FORMATTED_OFFSET_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_ZONED_DATE_TIME_SCALAR =\n+            newZonedDateTimeScalar(FORMATTED_ZONED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_TIME_SCALAR = newTimeScalar(TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom date scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_DATE_SCALAR = newDateScalar(DATE_SCALAR);\n+\n+    /**\n+     * Return a new custom date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+     static GraphQLScalarType newDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom offset date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newOffsetDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom zoned date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newZonedDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom time scalar\n+     */\n+     static GraphQLScalarType newTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Time;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new TimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom date scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date scalar\n+     */\n+     static GraphQLScalarType newDateScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Date;\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigDecimal scalar.\n+     *\n+     * @return a new custom BigDecimal scalar\n+     */\n+    private static GraphQLScalarType newCustomBigDecimalScalar() {\n+        GraphQLScalarType originalScalar = Scalars.GraphQLBigDecimal;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigDecimal>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Int scalar.\n+     *\n+     * @return a new custom Int scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLInt() {\n+        GraphQLScalarType originalScalar = GraphQLInt;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Integer>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Float scalar.\n+     *\n+     * @return a new custom Float scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLFloat() {\n+        GraphQLScalarType originalScalar = GraphQLFloat;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Double>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigInteger scalar.\n+     *\n+     * @return a new custom BigInteger scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLBigInteger() {\n+        GraphQLScalarType originalScalar = GraphQLBigInteger;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigInteger>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Abstract implementation of {@link Coercing} interface for given classes.\n+     */\n+     abstract static class AbstractDateTimeCoercing implements Coercing {\n+\n+        /**\n+         * {@link Class}es that can be coerced.\n+         */\n+        private final Class<?>[] clazzes;\n+\n+        /**\n+         * Construct a {@link AbstractDateTimeCoercing}.\n+         *\n+         * @param clazzes {@link Class}es to coerce\n+         */\n+         AbstractDateTimeCoercing(Class<?>... clazzes) {\n+            this.clazzes = clazzes;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return convert(dataFetcherResult);\n+        }\n+\n+        @Override\n+        public Object parseValue(Object input) throws CoercingParseValueException {\n+            return convert(input);\n+        }\n+\n+        @Override\n+        public Object parseLiteral(Object input) throws CoercingParseLiteralException {\n+            return parseStringLiteral(input);\n+        }\n+\n+        /**\n+         * Convert the given input to the type of if a String then leave it be.\n+         *\n+         * @param input input to coerce\n+         * @return the coerced value\n+         * @throws CoercingParseLiteralException if any exceptions converting\n+         */\n+        private Object convert(Object input) throws CoercingParseLiteralException {\n+            if (input instanceof String) {\n+                return (String) input;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxNjIyMA=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 306}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3Mzk3MjU1OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaDirective.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjowMjo1NlrOHyB0YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMDo1NTo0MlrOHyVL7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIyMDY0MQ==", "bodyText": "String delim = isFirst.getAndSet(false) ? \"\" : \", \"; But do we need AtomicBoolean at all?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522220641", "createdAt": "2020-11-12T16:02:56Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaDirective.java", "diffHunk": "@@ -0,0 +1,219 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The representation of a GraphQL directive.\n+ */\n+class SchemaDirective implements ElementGenerator {\n+\n+    /**\n+     * The name of the directive.\n+     */\n+    private final String name;\n+\n+    /**\n+     * The list of arguments for the directive.\n+     */\n+    private final List<SchemaArgument> listSchemaArguments;\n+\n+    /**\n+     * The locations the directive applies to.\n+     */\n+    private final Set<String> setLocations;\n+\n+    /**\n+     * Construct a {@link SchemaDirective}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private SchemaDirective(Builder builder) {\n+        this.name = builder.name;\n+        this.listSchemaArguments = builder.listSchemaArguments;\n+        this.setLocations = builder.setLocations;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link SchemaDirective}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder(\"directive @\" + name());\n+\n+        if (listSchemaArguments.size() > 0) {\n+            sb.append(\"(\");\n+            AtomicBoolean isFirst = new AtomicBoolean(true);\n+            listSchemaArguments.forEach(a -> {\n+                String delim = isFirst.get() ? \"\" : \", \";\n+                isFirst.set(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUzNzk2Ng==", "bodyText": "Isfirst needs to be (effectivly) final as referenced in lambda, so cannot be boolean or Boolean.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522537966", "createdAt": "2020-11-13T00:55:42Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaDirective.java", "diffHunk": "@@ -0,0 +1,219 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * The representation of a GraphQL directive.\n+ */\n+class SchemaDirective implements ElementGenerator {\n+\n+    /**\n+     * The name of the directive.\n+     */\n+    private final String name;\n+\n+    /**\n+     * The list of arguments for the directive.\n+     */\n+    private final List<SchemaArgument> listSchemaArguments;\n+\n+    /**\n+     * The locations the directive applies to.\n+     */\n+    private final Set<String> setLocations;\n+\n+    /**\n+     * Construct a {@link SchemaDirective}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private SchemaDirective(Builder builder) {\n+        this.name = builder.name;\n+        this.listSchemaArguments = builder.listSchemaArguments;\n+        this.setLocations = builder.setLocations;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link SchemaDirective}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder(\"directive @\" + name());\n+\n+        if (listSchemaArguments.size() > 0) {\n+            sb.append(\"(\");\n+            AtomicBoolean isFirst = new AtomicBoolean(true);\n+            listSchemaArguments.forEach(a -> {\n+                String delim = isFirst.get() ? \"\" : \", \";\n+                isFirst.set(false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIyMDY0MQ=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDAwNDcyOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjowOTo0OFrOHyCIpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjowOTo0OFrOHyCIpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIyNTgzMQ==", "bodyText": "single", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522225831", "createdAt": "2020-11-12T16:09:48Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.reflect.Modifier;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Enumeration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+import org.jboss.jandex.ClassInfo;\n+import org.jboss.jandex.DotName;\n+import org.jboss.jandex.Index;\n+import org.jboss.jandex.IndexReader;\n+\n+/**\n+ * Utilities for working with Jandex indexes.\n+ */\n+class JandexUtils {\n+\n+    private static final Logger LOGGER = Logger.getLogger(JandexUtils.class.getName());\n+\n+    /**\n+     * Default Jandex index file.\n+     */\n+    protected static final String DEFAULT_INDEX_FILE = \"META-INF/jandex.idx\";\n+\n+    /**\n+     * Property to override the default index file. (Normally used for functional tests)\n+     */\n+    public static final String PROP_INDEX_FILE = \"io.helidon.microprofile.graphql.indexfile\";\n+\n+    /**\n+     * The {@link Set} of loaded indexes.\n+     */\n+    private Set<Index> setIndexes = new HashSet<>();\n+\n+    /**\n+     * The file used to load the index.\n+     */\n+    private String indexFile;\n+\n+    /**\n+     * Construct an instance of the utilities class..\n+     */\n+    private JandexUtils() {\n+        indexFile = System.getProperty(PROP_INDEX_FILE, DEFAULT_INDEX_FILE);\n+    }\n+\n+    /**\n+     * Create a new {@link JandexUtils}.\n+     * @return a new {@link JandexUtils}\n+     */\n+    public static JandexUtils create() {\n+         return new JandexUtils();\n+    }\n+\n+    /**\n+     * Load all the index files of the given name.\n+     */\n+    public void loadIndexes() {\n+        try {\n+            List<URL> listUrls = findIndexFiles(indexFile);\n+\n+            // loop through each URL and load the index\n+            for (URL url : listUrls) {\n+                try (InputStream input = url.openStream()) {\n+                    setIndexes.add(new IndexReader(input).read());\n+                } catch (Exception e) {\n+                    LOGGER.warning(\"Unable to load default Jandex index file: \" + url\n+                                           + \" : \" + e.getMessage());\n+                }\n+            }\n+        } catch (IOException ignore) {\n+            // any Exception coming from getResources() or toURL() is ignored and\n+            // the Map of indexes remain empty\n+        }\n+    }\n+\n+    /**\n+     * Return all the Jandex index files with the given name. If the name is absolute then\n+     * return the singl file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA0MTYyOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxNzoyMlrOHyCflA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxNzoyMlrOHyCflA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzMTcwMA==", "bodyText": "anyMatch could save few iterations, what if there is more than one SchemaType with the same name?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522231700", "createdAt": "2020-11-12T16:17:22Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "diffHunk": "@@ -0,0 +1,562 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.GraphQLObjectType;\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.TypeResolver;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import graphql.schema.idl.TypeRuntimeWiring;\n+\n+import static graphql.schema.idl.RuntimeWiring.newRuntimeWiring;\n+import static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSafeClass;\n+\n+/**\n+ * The representation of a GraphQL Schema.\n+ */\n+class Schema implements ElementGenerator {\n+\n+    private static final Logger LOGGER = Logger.getLogger(Schema.class.getName());\n+\n+    /**\n+     * Default query name.\n+     */\n+    public static final String QUERY = \"Query\";\n+\n+    /**\n+     * Default mutation name.\n+     */\n+    public static final String MUTATION = \"Mutation\";\n+\n+    /**\n+     * Default subscription name.\n+     */\n+    public static final String SUBSCRIPTION = \"Subscription\";\n+\n+    /**\n+     * The top level query name.\n+     */\n+    private String queryName;\n+\n+    /**\n+     * The top level mutation name.\n+     */\n+    private String mutationName;\n+\n+    /**\n+     * The top level subscription name.\n+     */\n+    private String subscriptionName;\n+\n+    /**\n+     * List of {@link SchemaType}s for this schema. This includes the standard schema types and other types.\n+     */\n+    private final List<SchemaType> listSchemaTypes;\n+\n+    /**\n+     * List of {@link SchemaScalar}s that should be included in the schema.\n+     */\n+    private final List<SchemaScalar> listSchemaScalars;\n+\n+    /**\n+     * List of {@link SchemaDirective}s that should be included in the schema.\n+     */\n+    private final List<SchemaDirective> listSchemaDirectives;\n+\n+    /**\n+     * List of {@link SchemaInputType}s that should be included in the schema.\n+     */\n+    private final List<SchemaInputType> listInputTypes;\n+\n+    /**\n+     * List of {@link SchemaEnum}s that should be included in the schema.\n+     */\n+    private final List<SchemaEnum> listSchemaEnums;\n+\n+    /**\n+     * Construct a {@link Schema}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private Schema(Builder builder) {\n+        this.listSchemaTypes = new ArrayList<>();\n+        this.listSchemaScalars = new ArrayList<>();\n+        this.listSchemaDirectives = new ArrayList<>();\n+        this.listInputTypes = new ArrayList<>();\n+        this.listSchemaEnums = new ArrayList<>();\n+        this.queryName = builder.queryName;\n+        this.subscriptionName = builder.subscriptionName;\n+        this.mutationName = builder.mutationName;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link Schema}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Build a new {@link Schema}.\n+     *\n+     * @return a new {@link Schema}\n+     */\n+    public static Schema create() {\n+        return builder().build();\n+    }\n+\n+    /**\n+     * Generates a {@link GraphQLSchema} from the current discovered schema.\n+     *\n+     * @return {@link GraphQLSchema}\n+     */\n+    public GraphQLSchema generateGraphQLSchema() {\n+        SchemaParser schemaParser = new SchemaParser();\n+        TypeDefinitionRegistry typeDefinitionRegistry;\n+\n+        try {\n+            typeDefinitionRegistry = schemaParser.parse(getSchemaAsString());\n+            return new graphql.schema.idl.SchemaGenerator().makeExecutableSchema(typeDefinitionRegistry, getRuntimeWiring());\n+        } catch (Exception e) {\n+            String message = \"Unable to parse the generated schema\";\n+            LOGGER.warning(message + \"\\n\" + getSchemaAsString());\n+            throw new GraphQLException(message, e);\n+        }\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder();\n+\n+        listSchemaDirectives.forEach(d -> sb.append(d.getSchemaAsString()).append('\\n'));\n+        if (listSchemaDirectives.size() > 0) {\n+            sb.append('\\n');\n+        }\n+\n+        sb.append(\"schema \").append(OPEN_CURLY).append(NEWLINE);\n+\n+        // only output \"query\" if we have a query type\n+        if (containsTypeWithName(queryName)) {\n+            sb.append(SPACER).append(\"query: \").append(queryName).append('\\n');\n+        }\n+        if (containsTypeWithName(mutationName)) {\n+            sb.append(SPACER).append(\"mutation: \").append(mutationName).append('\\n');\n+        }\n+        if (containsTypeWithName(subscriptionName)) {\n+            sb.append(SPACER).append(\"subscription: \").append(subscriptionName).append('\\n');\n+        }\n+\n+        sb.append(CLOSE_CURLY).append(NEWLINE).append(NEWLINE);\n+\n+        listSchemaTypes.forEach(t -> sb.append(t.getSchemaAsString()).append(\"\\n\"));\n+\n+        listInputTypes.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaEnums.forEach(e -> sb.append(e.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaScalars.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        return sb.toString();\n+    }\n+\n+    /**\n+     * Return the {@link RuntimeWiring} for the given auto-generated schema.\n+     *\n+     * @return the {@link RuntimeWiring}\n+     */\n+    @SuppressWarnings(\"checkstyle:RegexpSinglelineJava\")\n+    public RuntimeWiring getRuntimeWiring() {\n+        RuntimeWiring.Builder builder = newRuntimeWiring();\n+\n+        //  Create the top level Query Runtime Wiring.\n+        SchemaType querySchemaType = getTypeByName(getQueryName());\n+\n+        if (querySchemaType == null) {\n+            throw new GraphQLException(\"No type exists for query of name \" + getQueryName());\n+        }\n+\n+        final TypeRuntimeWiring.Builder typeRuntimeBuilder = newTypeWiring(getQueryName());\n+\n+        // register a type resolver for any interfaces if we have at least one\n+        Set<SchemaType> setInterfaces = getTypes().stream().filter(SchemaType::isInterface).collect(Collectors.toSet());\n+        if (setInterfaces.size() > 0) {\n+            final Map<String, String> mapTypes = new HashMap<>();\n+\n+            getTypes().stream().filter(t -> !t.isInterface()).forEach(t -> mapTypes.put(t.name(), t.valueClassName()));\n+\n+            // generate a TypeResolver for all types that are not interfaces\n+            TypeResolver typeResolver = env -> {\n+                Object o = env.getObject();\n+                for (Map.Entry<String, String> entry : mapTypes.entrySet()) {\n+                    String valueClass = entry.getValue();\n+                    if (valueClass != null) {\n+                        Class<?> typeClass = getSafeClass(entry.getValue());\n+                        if (typeClass != null && typeClass.isAssignableFrom(o.getClass())) {\n+                            return (GraphQLObjectType) env.getSchema().getType(entry.getKey());\n+                        }\n+                    }\n+                }\n+                return null;\n+            };\n+\n+            // add the type resolver to all interfaces and the Query object\n+            setInterfaces.forEach(t -> builder.type(t.name(), tr -> tr.typeResolver(typeResolver)));\n+            builder.type(getQueryName(), tr -> tr.typeResolver(typeResolver));\n+        }\n+\n+        // register the scalars\n+        getScalars().forEach(s -> {\n+            LOGGER.finest(\"Register Scalar: \" + s);\n+            builder.scalar(s.graphQLScalarType());\n+        });\n+\n+        // we should now have the query runtime binding\n+        builder.type(typeRuntimeBuilder);\n+\n+        // search for any types that have field definitions with DataFetchers\n+        getTypes().forEach(t -> {\n+            boolean hasDataFetchers = t.fieldDefinitions().stream().anyMatch(fd -> fd.dataFetcher() != null);\n+            if (hasDataFetchers) {\n+                final TypeRuntimeWiring.Builder runtimeBuilder = newTypeWiring(t.name());\n+                t.fieldDefinitions().stream()\n+                        .filter(fd -> fd.dataFetcher() != null)\n+                        .forEach(fd -> runtimeBuilder.dataFetcher(fd.name(), fd.dataFetcher()));\n+                builder.type(runtimeBuilder);\n+            }\n+        });\n+\n+        return builder.build();\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the type name.\n+     *\n+     * @param typeName type name to match\n+     * @return a {@link SchemaType} that matches the type name or null if none found\n+     */\n+    public SchemaType getTypeByName(String typeName) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (schemaType.name().equals(typeName)) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaInputType} that matches the type name.\n+     *\n+     * @param inputTypeName type name to match\n+     * @return a {@link SchemaInputType} that matches the type name or null if none found\n+     */\n+    public SchemaInputType getInputTypeByName(String inputTypeName) {\n+        for (SchemaInputType schemaInputType : listInputTypes) {\n+            if (schemaInputType.name().equals(inputTypeName)) {\n+                return schemaInputType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the given class.\n+     *\n+     * @param clazz the class to find\n+     * @return a {@link SchemaType} that matches the given class or null if none found\n+     */\n+    public SchemaType getTypeByClass(String clazz) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (clazz.equals(schemaType.valueClassName())) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaEnum} that matches the enum name.\n+     *\n+     * @param enumName type name to match\n+     * @return a {@link SchemaEnum} that matches the enum name or null if none found\n+     */\n+    public SchemaEnum getEnumByName(String enumName) {\n+        for (SchemaEnum schemaEnum1 : listSchemaEnums) {\n+            if (schemaEnum1.name().equals(enumName)) {\n+                return schemaEnum1;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided class name.\n+     *\n+     * @param actualClazz the class name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByActualClass(String actualClazz) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.actualClass().equals(actualClazz)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided scalar name.\n+     *\n+     * @param scalarName the scalar name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByName(String scalarName) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.name().equals(scalarName)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the type list\n+     */\n+    public boolean containsTypeWithName(String type) {\n+        return listSchemaTypes.stream().filter(t -> t.name().equals(type)).count() == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 361}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA0NDE3OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxNzo1NFrOHyChKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxNzo1NFrOHyChKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzMjEwNg==", "bodyText": "anyMatch", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522232106", "createdAt": "2020-11-12T16:17:54Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "diffHunk": "@@ -0,0 +1,562 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.GraphQLObjectType;\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.TypeResolver;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import graphql.schema.idl.TypeRuntimeWiring;\n+\n+import static graphql.schema.idl.RuntimeWiring.newRuntimeWiring;\n+import static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSafeClass;\n+\n+/**\n+ * The representation of a GraphQL Schema.\n+ */\n+class Schema implements ElementGenerator {\n+\n+    private static final Logger LOGGER = Logger.getLogger(Schema.class.getName());\n+\n+    /**\n+     * Default query name.\n+     */\n+    public static final String QUERY = \"Query\";\n+\n+    /**\n+     * Default mutation name.\n+     */\n+    public static final String MUTATION = \"Mutation\";\n+\n+    /**\n+     * Default subscription name.\n+     */\n+    public static final String SUBSCRIPTION = \"Subscription\";\n+\n+    /**\n+     * The top level query name.\n+     */\n+    private String queryName;\n+\n+    /**\n+     * The top level mutation name.\n+     */\n+    private String mutationName;\n+\n+    /**\n+     * The top level subscription name.\n+     */\n+    private String subscriptionName;\n+\n+    /**\n+     * List of {@link SchemaType}s for this schema. This includes the standard schema types and other types.\n+     */\n+    private final List<SchemaType> listSchemaTypes;\n+\n+    /**\n+     * List of {@link SchemaScalar}s that should be included in the schema.\n+     */\n+    private final List<SchemaScalar> listSchemaScalars;\n+\n+    /**\n+     * List of {@link SchemaDirective}s that should be included in the schema.\n+     */\n+    private final List<SchemaDirective> listSchemaDirectives;\n+\n+    /**\n+     * List of {@link SchemaInputType}s that should be included in the schema.\n+     */\n+    private final List<SchemaInputType> listInputTypes;\n+\n+    /**\n+     * List of {@link SchemaEnum}s that should be included in the schema.\n+     */\n+    private final List<SchemaEnum> listSchemaEnums;\n+\n+    /**\n+     * Construct a {@link Schema}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private Schema(Builder builder) {\n+        this.listSchemaTypes = new ArrayList<>();\n+        this.listSchemaScalars = new ArrayList<>();\n+        this.listSchemaDirectives = new ArrayList<>();\n+        this.listInputTypes = new ArrayList<>();\n+        this.listSchemaEnums = new ArrayList<>();\n+        this.queryName = builder.queryName;\n+        this.subscriptionName = builder.subscriptionName;\n+        this.mutationName = builder.mutationName;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link Schema}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Build a new {@link Schema}.\n+     *\n+     * @return a new {@link Schema}\n+     */\n+    public static Schema create() {\n+        return builder().build();\n+    }\n+\n+    /**\n+     * Generates a {@link GraphQLSchema} from the current discovered schema.\n+     *\n+     * @return {@link GraphQLSchema}\n+     */\n+    public GraphQLSchema generateGraphQLSchema() {\n+        SchemaParser schemaParser = new SchemaParser();\n+        TypeDefinitionRegistry typeDefinitionRegistry;\n+\n+        try {\n+            typeDefinitionRegistry = schemaParser.parse(getSchemaAsString());\n+            return new graphql.schema.idl.SchemaGenerator().makeExecutableSchema(typeDefinitionRegistry, getRuntimeWiring());\n+        } catch (Exception e) {\n+            String message = \"Unable to parse the generated schema\";\n+            LOGGER.warning(message + \"\\n\" + getSchemaAsString());\n+            throw new GraphQLException(message, e);\n+        }\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder();\n+\n+        listSchemaDirectives.forEach(d -> sb.append(d.getSchemaAsString()).append('\\n'));\n+        if (listSchemaDirectives.size() > 0) {\n+            sb.append('\\n');\n+        }\n+\n+        sb.append(\"schema \").append(OPEN_CURLY).append(NEWLINE);\n+\n+        // only output \"query\" if we have a query type\n+        if (containsTypeWithName(queryName)) {\n+            sb.append(SPACER).append(\"query: \").append(queryName).append('\\n');\n+        }\n+        if (containsTypeWithName(mutationName)) {\n+            sb.append(SPACER).append(\"mutation: \").append(mutationName).append('\\n');\n+        }\n+        if (containsTypeWithName(subscriptionName)) {\n+            sb.append(SPACER).append(\"subscription: \").append(subscriptionName).append('\\n');\n+        }\n+\n+        sb.append(CLOSE_CURLY).append(NEWLINE).append(NEWLINE);\n+\n+        listSchemaTypes.forEach(t -> sb.append(t.getSchemaAsString()).append(\"\\n\"));\n+\n+        listInputTypes.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaEnums.forEach(e -> sb.append(e.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaScalars.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        return sb.toString();\n+    }\n+\n+    /**\n+     * Return the {@link RuntimeWiring} for the given auto-generated schema.\n+     *\n+     * @return the {@link RuntimeWiring}\n+     */\n+    @SuppressWarnings(\"checkstyle:RegexpSinglelineJava\")\n+    public RuntimeWiring getRuntimeWiring() {\n+        RuntimeWiring.Builder builder = newRuntimeWiring();\n+\n+        //  Create the top level Query Runtime Wiring.\n+        SchemaType querySchemaType = getTypeByName(getQueryName());\n+\n+        if (querySchemaType == null) {\n+            throw new GraphQLException(\"No type exists for query of name \" + getQueryName());\n+        }\n+\n+        final TypeRuntimeWiring.Builder typeRuntimeBuilder = newTypeWiring(getQueryName());\n+\n+        // register a type resolver for any interfaces if we have at least one\n+        Set<SchemaType> setInterfaces = getTypes().stream().filter(SchemaType::isInterface).collect(Collectors.toSet());\n+        if (setInterfaces.size() > 0) {\n+            final Map<String, String> mapTypes = new HashMap<>();\n+\n+            getTypes().stream().filter(t -> !t.isInterface()).forEach(t -> mapTypes.put(t.name(), t.valueClassName()));\n+\n+            // generate a TypeResolver for all types that are not interfaces\n+            TypeResolver typeResolver = env -> {\n+                Object o = env.getObject();\n+                for (Map.Entry<String, String> entry : mapTypes.entrySet()) {\n+                    String valueClass = entry.getValue();\n+                    if (valueClass != null) {\n+                        Class<?> typeClass = getSafeClass(entry.getValue());\n+                        if (typeClass != null && typeClass.isAssignableFrom(o.getClass())) {\n+                            return (GraphQLObjectType) env.getSchema().getType(entry.getKey());\n+                        }\n+                    }\n+                }\n+                return null;\n+            };\n+\n+            // add the type resolver to all interfaces and the Query object\n+            setInterfaces.forEach(t -> builder.type(t.name(), tr -> tr.typeResolver(typeResolver)));\n+            builder.type(getQueryName(), tr -> tr.typeResolver(typeResolver));\n+        }\n+\n+        // register the scalars\n+        getScalars().forEach(s -> {\n+            LOGGER.finest(\"Register Scalar: \" + s);\n+            builder.scalar(s.graphQLScalarType());\n+        });\n+\n+        // we should now have the query runtime binding\n+        builder.type(typeRuntimeBuilder);\n+\n+        // search for any types that have field definitions with DataFetchers\n+        getTypes().forEach(t -> {\n+            boolean hasDataFetchers = t.fieldDefinitions().stream().anyMatch(fd -> fd.dataFetcher() != null);\n+            if (hasDataFetchers) {\n+                final TypeRuntimeWiring.Builder runtimeBuilder = newTypeWiring(t.name());\n+                t.fieldDefinitions().stream()\n+                        .filter(fd -> fd.dataFetcher() != null)\n+                        .forEach(fd -> runtimeBuilder.dataFetcher(fd.name(), fd.dataFetcher()));\n+                builder.type(runtimeBuilder);\n+            }\n+        });\n+\n+        return builder.build();\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the type name.\n+     *\n+     * @param typeName type name to match\n+     * @return a {@link SchemaType} that matches the type name or null if none found\n+     */\n+    public SchemaType getTypeByName(String typeName) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (schemaType.name().equals(typeName)) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaInputType} that matches the type name.\n+     *\n+     * @param inputTypeName type name to match\n+     * @return a {@link SchemaInputType} that matches the type name or null if none found\n+     */\n+    public SchemaInputType getInputTypeByName(String inputTypeName) {\n+        for (SchemaInputType schemaInputType : listInputTypes) {\n+            if (schemaInputType.name().equals(inputTypeName)) {\n+                return schemaInputType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the given class.\n+     *\n+     * @param clazz the class to find\n+     * @return a {@link SchemaType} that matches the given class or null if none found\n+     */\n+    public SchemaType getTypeByClass(String clazz) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (clazz.equals(schemaType.valueClassName())) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaEnum} that matches the enum name.\n+     *\n+     * @param enumName type name to match\n+     * @return a {@link SchemaEnum} that matches the enum name or null if none found\n+     */\n+    public SchemaEnum getEnumByName(String enumName) {\n+        for (SchemaEnum schemaEnum1 : listSchemaEnums) {\n+            if (schemaEnum1.name().equals(enumName)) {\n+                return schemaEnum1;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided class name.\n+     *\n+     * @param actualClazz the class name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByActualClass(String actualClazz) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.actualClass().equals(actualClazz)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided scalar name.\n+     *\n+     * @param scalarName the scalar name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByName(String scalarName) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.name().equals(scalarName)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the type list\n+     */\n+    public boolean containsTypeWithName(String type) {\n+        return listSchemaTypes.stream().filter(t -> t.name().equals(type)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaInputType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the input type list\n+     */\n+    public boolean containsInputTypeWithName(String type) {\n+        return listInputTypes.stream().filter(t -> t.name().equals(type)).count() == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 371}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA0NTU2OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxODowNlrOHyCh6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxODowNlrOHyCh6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzMjI5OA==", "bodyText": "anyMatch", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522232298", "createdAt": "2020-11-12T16:18:06Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "diffHunk": "@@ -0,0 +1,562 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.GraphQLObjectType;\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.TypeResolver;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import graphql.schema.idl.TypeRuntimeWiring;\n+\n+import static graphql.schema.idl.RuntimeWiring.newRuntimeWiring;\n+import static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSafeClass;\n+\n+/**\n+ * The representation of a GraphQL Schema.\n+ */\n+class Schema implements ElementGenerator {\n+\n+    private static final Logger LOGGER = Logger.getLogger(Schema.class.getName());\n+\n+    /**\n+     * Default query name.\n+     */\n+    public static final String QUERY = \"Query\";\n+\n+    /**\n+     * Default mutation name.\n+     */\n+    public static final String MUTATION = \"Mutation\";\n+\n+    /**\n+     * Default subscription name.\n+     */\n+    public static final String SUBSCRIPTION = \"Subscription\";\n+\n+    /**\n+     * The top level query name.\n+     */\n+    private String queryName;\n+\n+    /**\n+     * The top level mutation name.\n+     */\n+    private String mutationName;\n+\n+    /**\n+     * The top level subscription name.\n+     */\n+    private String subscriptionName;\n+\n+    /**\n+     * List of {@link SchemaType}s for this schema. This includes the standard schema types and other types.\n+     */\n+    private final List<SchemaType> listSchemaTypes;\n+\n+    /**\n+     * List of {@link SchemaScalar}s that should be included in the schema.\n+     */\n+    private final List<SchemaScalar> listSchemaScalars;\n+\n+    /**\n+     * List of {@link SchemaDirective}s that should be included in the schema.\n+     */\n+    private final List<SchemaDirective> listSchemaDirectives;\n+\n+    /**\n+     * List of {@link SchemaInputType}s that should be included in the schema.\n+     */\n+    private final List<SchemaInputType> listInputTypes;\n+\n+    /**\n+     * List of {@link SchemaEnum}s that should be included in the schema.\n+     */\n+    private final List<SchemaEnum> listSchemaEnums;\n+\n+    /**\n+     * Construct a {@link Schema}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private Schema(Builder builder) {\n+        this.listSchemaTypes = new ArrayList<>();\n+        this.listSchemaScalars = new ArrayList<>();\n+        this.listSchemaDirectives = new ArrayList<>();\n+        this.listInputTypes = new ArrayList<>();\n+        this.listSchemaEnums = new ArrayList<>();\n+        this.queryName = builder.queryName;\n+        this.subscriptionName = builder.subscriptionName;\n+        this.mutationName = builder.mutationName;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link Schema}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Build a new {@link Schema}.\n+     *\n+     * @return a new {@link Schema}\n+     */\n+    public static Schema create() {\n+        return builder().build();\n+    }\n+\n+    /**\n+     * Generates a {@link GraphQLSchema} from the current discovered schema.\n+     *\n+     * @return {@link GraphQLSchema}\n+     */\n+    public GraphQLSchema generateGraphQLSchema() {\n+        SchemaParser schemaParser = new SchemaParser();\n+        TypeDefinitionRegistry typeDefinitionRegistry;\n+\n+        try {\n+            typeDefinitionRegistry = schemaParser.parse(getSchemaAsString());\n+            return new graphql.schema.idl.SchemaGenerator().makeExecutableSchema(typeDefinitionRegistry, getRuntimeWiring());\n+        } catch (Exception e) {\n+            String message = \"Unable to parse the generated schema\";\n+            LOGGER.warning(message + \"\\n\" + getSchemaAsString());\n+            throw new GraphQLException(message, e);\n+        }\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder();\n+\n+        listSchemaDirectives.forEach(d -> sb.append(d.getSchemaAsString()).append('\\n'));\n+        if (listSchemaDirectives.size() > 0) {\n+            sb.append('\\n');\n+        }\n+\n+        sb.append(\"schema \").append(OPEN_CURLY).append(NEWLINE);\n+\n+        // only output \"query\" if we have a query type\n+        if (containsTypeWithName(queryName)) {\n+            sb.append(SPACER).append(\"query: \").append(queryName).append('\\n');\n+        }\n+        if (containsTypeWithName(mutationName)) {\n+            sb.append(SPACER).append(\"mutation: \").append(mutationName).append('\\n');\n+        }\n+        if (containsTypeWithName(subscriptionName)) {\n+            sb.append(SPACER).append(\"subscription: \").append(subscriptionName).append('\\n');\n+        }\n+\n+        sb.append(CLOSE_CURLY).append(NEWLINE).append(NEWLINE);\n+\n+        listSchemaTypes.forEach(t -> sb.append(t.getSchemaAsString()).append(\"\\n\"));\n+\n+        listInputTypes.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaEnums.forEach(e -> sb.append(e.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaScalars.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        return sb.toString();\n+    }\n+\n+    /**\n+     * Return the {@link RuntimeWiring} for the given auto-generated schema.\n+     *\n+     * @return the {@link RuntimeWiring}\n+     */\n+    @SuppressWarnings(\"checkstyle:RegexpSinglelineJava\")\n+    public RuntimeWiring getRuntimeWiring() {\n+        RuntimeWiring.Builder builder = newRuntimeWiring();\n+\n+        //  Create the top level Query Runtime Wiring.\n+        SchemaType querySchemaType = getTypeByName(getQueryName());\n+\n+        if (querySchemaType == null) {\n+            throw new GraphQLException(\"No type exists for query of name \" + getQueryName());\n+        }\n+\n+        final TypeRuntimeWiring.Builder typeRuntimeBuilder = newTypeWiring(getQueryName());\n+\n+        // register a type resolver for any interfaces if we have at least one\n+        Set<SchemaType> setInterfaces = getTypes().stream().filter(SchemaType::isInterface).collect(Collectors.toSet());\n+        if (setInterfaces.size() > 0) {\n+            final Map<String, String> mapTypes = new HashMap<>();\n+\n+            getTypes().stream().filter(t -> !t.isInterface()).forEach(t -> mapTypes.put(t.name(), t.valueClassName()));\n+\n+            // generate a TypeResolver for all types that are not interfaces\n+            TypeResolver typeResolver = env -> {\n+                Object o = env.getObject();\n+                for (Map.Entry<String, String> entry : mapTypes.entrySet()) {\n+                    String valueClass = entry.getValue();\n+                    if (valueClass != null) {\n+                        Class<?> typeClass = getSafeClass(entry.getValue());\n+                        if (typeClass != null && typeClass.isAssignableFrom(o.getClass())) {\n+                            return (GraphQLObjectType) env.getSchema().getType(entry.getKey());\n+                        }\n+                    }\n+                }\n+                return null;\n+            };\n+\n+            // add the type resolver to all interfaces and the Query object\n+            setInterfaces.forEach(t -> builder.type(t.name(), tr -> tr.typeResolver(typeResolver)));\n+            builder.type(getQueryName(), tr -> tr.typeResolver(typeResolver));\n+        }\n+\n+        // register the scalars\n+        getScalars().forEach(s -> {\n+            LOGGER.finest(\"Register Scalar: \" + s);\n+            builder.scalar(s.graphQLScalarType());\n+        });\n+\n+        // we should now have the query runtime binding\n+        builder.type(typeRuntimeBuilder);\n+\n+        // search for any types that have field definitions with DataFetchers\n+        getTypes().forEach(t -> {\n+            boolean hasDataFetchers = t.fieldDefinitions().stream().anyMatch(fd -> fd.dataFetcher() != null);\n+            if (hasDataFetchers) {\n+                final TypeRuntimeWiring.Builder runtimeBuilder = newTypeWiring(t.name());\n+                t.fieldDefinitions().stream()\n+                        .filter(fd -> fd.dataFetcher() != null)\n+                        .forEach(fd -> runtimeBuilder.dataFetcher(fd.name(), fd.dataFetcher()));\n+                builder.type(runtimeBuilder);\n+            }\n+        });\n+\n+        return builder.build();\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the type name.\n+     *\n+     * @param typeName type name to match\n+     * @return a {@link SchemaType} that matches the type name or null if none found\n+     */\n+    public SchemaType getTypeByName(String typeName) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (schemaType.name().equals(typeName)) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaInputType} that matches the type name.\n+     *\n+     * @param inputTypeName type name to match\n+     * @return a {@link SchemaInputType} that matches the type name or null if none found\n+     */\n+    public SchemaInputType getInputTypeByName(String inputTypeName) {\n+        for (SchemaInputType schemaInputType : listInputTypes) {\n+            if (schemaInputType.name().equals(inputTypeName)) {\n+                return schemaInputType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the given class.\n+     *\n+     * @param clazz the class to find\n+     * @return a {@link SchemaType} that matches the given class or null if none found\n+     */\n+    public SchemaType getTypeByClass(String clazz) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (clazz.equals(schemaType.valueClassName())) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaEnum} that matches the enum name.\n+     *\n+     * @param enumName type name to match\n+     * @return a {@link SchemaEnum} that matches the enum name or null if none found\n+     */\n+    public SchemaEnum getEnumByName(String enumName) {\n+        for (SchemaEnum schemaEnum1 : listSchemaEnums) {\n+            if (schemaEnum1.name().equals(enumName)) {\n+                return schemaEnum1;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided class name.\n+     *\n+     * @param actualClazz the class name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByActualClass(String actualClazz) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.actualClass().equals(actualClazz)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided scalar name.\n+     *\n+     * @param scalarName the scalar name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByName(String scalarName) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.name().equals(scalarName)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the type list\n+     */\n+    public boolean containsTypeWithName(String type) {\n+        return listSchemaTypes.stream().filter(t -> t.name().equals(type)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaInputType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the input type list\n+     */\n+    public boolean containsInputTypeWithName(String type) {\n+        return listInputTypes.stream().filter(t -> t.name().equals(type)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaScalar} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param scalar the scalar name to search for\n+     * @return true if the scalar name is contained within the scalar list\n+     */\n+    public boolean containsScalarWithName(String scalar) {\n+        return listSchemaScalars.stream().filter(s -> s.name().equals(scalar)).count() == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 381}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA0NjIxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxODoxMVrOHyCiSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoxODoxMVrOHyCiSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzMjM5NQ==", "bodyText": "anyMatch", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522232395", "createdAt": "2020-11-12T16:18:11Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/Schema.java", "diffHunk": "@@ -0,0 +1,562 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.GraphQLObjectType;\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.TypeResolver;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import graphql.schema.idl.TypeRuntimeWiring;\n+\n+import static graphql.schema.idl.RuntimeWiring.newRuntimeWiring;\n+import static graphql.schema.idl.TypeRuntimeWiring.newTypeWiring;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSafeClass;\n+\n+/**\n+ * The representation of a GraphQL Schema.\n+ */\n+class Schema implements ElementGenerator {\n+\n+    private static final Logger LOGGER = Logger.getLogger(Schema.class.getName());\n+\n+    /**\n+     * Default query name.\n+     */\n+    public static final String QUERY = \"Query\";\n+\n+    /**\n+     * Default mutation name.\n+     */\n+    public static final String MUTATION = \"Mutation\";\n+\n+    /**\n+     * Default subscription name.\n+     */\n+    public static final String SUBSCRIPTION = \"Subscription\";\n+\n+    /**\n+     * The top level query name.\n+     */\n+    private String queryName;\n+\n+    /**\n+     * The top level mutation name.\n+     */\n+    private String mutationName;\n+\n+    /**\n+     * The top level subscription name.\n+     */\n+    private String subscriptionName;\n+\n+    /**\n+     * List of {@link SchemaType}s for this schema. This includes the standard schema types and other types.\n+     */\n+    private final List<SchemaType> listSchemaTypes;\n+\n+    /**\n+     * List of {@link SchemaScalar}s that should be included in the schema.\n+     */\n+    private final List<SchemaScalar> listSchemaScalars;\n+\n+    /**\n+     * List of {@link SchemaDirective}s that should be included in the schema.\n+     */\n+    private final List<SchemaDirective> listSchemaDirectives;\n+\n+    /**\n+     * List of {@link SchemaInputType}s that should be included in the schema.\n+     */\n+    private final List<SchemaInputType> listInputTypes;\n+\n+    /**\n+     * List of {@link SchemaEnum}s that should be included in the schema.\n+     */\n+    private final List<SchemaEnum> listSchemaEnums;\n+\n+    /**\n+     * Construct a {@link Schema}.\n+     *\n+     * @param builder the {@link Builder} to construct from\n+     */\n+    private Schema(Builder builder) {\n+        this.listSchemaTypes = new ArrayList<>();\n+        this.listSchemaScalars = new ArrayList<>();\n+        this.listSchemaDirectives = new ArrayList<>();\n+        this.listInputTypes = new ArrayList<>();\n+        this.listSchemaEnums = new ArrayList<>();\n+        this.queryName = builder.queryName;\n+        this.subscriptionName = builder.subscriptionName;\n+        this.mutationName = builder.mutationName;\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link Schema}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new Builder();\n+    }\n+\n+    /**\n+     * Build a new {@link Schema}.\n+     *\n+     * @return a new {@link Schema}\n+     */\n+    public static Schema create() {\n+        return builder().build();\n+    }\n+\n+    /**\n+     * Generates a {@link GraphQLSchema} from the current discovered schema.\n+     *\n+     * @return {@link GraphQLSchema}\n+     */\n+    public GraphQLSchema generateGraphQLSchema() {\n+        SchemaParser schemaParser = new SchemaParser();\n+        TypeDefinitionRegistry typeDefinitionRegistry;\n+\n+        try {\n+            typeDefinitionRegistry = schemaParser.parse(getSchemaAsString());\n+            return new graphql.schema.idl.SchemaGenerator().makeExecutableSchema(typeDefinitionRegistry, getRuntimeWiring());\n+        } catch (Exception e) {\n+            String message = \"Unable to parse the generated schema\";\n+            LOGGER.warning(message + \"\\n\" + getSchemaAsString());\n+            throw new GraphQLException(message, e);\n+        }\n+    }\n+\n+    /**\n+     * Return the GraphQL schema representation of the element.\n+     *\n+     * @return the GraphQL schema representation of the element.\n+     */\n+    @Override\n+    public String getSchemaAsString() {\n+        StringBuilder sb = new StringBuilder();\n+\n+        listSchemaDirectives.forEach(d -> sb.append(d.getSchemaAsString()).append('\\n'));\n+        if (listSchemaDirectives.size() > 0) {\n+            sb.append('\\n');\n+        }\n+\n+        sb.append(\"schema \").append(OPEN_CURLY).append(NEWLINE);\n+\n+        // only output \"query\" if we have a query type\n+        if (containsTypeWithName(queryName)) {\n+            sb.append(SPACER).append(\"query: \").append(queryName).append('\\n');\n+        }\n+        if (containsTypeWithName(mutationName)) {\n+            sb.append(SPACER).append(\"mutation: \").append(mutationName).append('\\n');\n+        }\n+        if (containsTypeWithName(subscriptionName)) {\n+            sb.append(SPACER).append(\"subscription: \").append(subscriptionName).append('\\n');\n+        }\n+\n+        sb.append(CLOSE_CURLY).append(NEWLINE).append(NEWLINE);\n+\n+        listSchemaTypes.forEach(t -> sb.append(t.getSchemaAsString()).append(\"\\n\"));\n+\n+        listInputTypes.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaEnums.forEach(e -> sb.append(e.getSchemaAsString()).append('\\n'));\n+\n+        listSchemaScalars.forEach(s -> sb.append(s.getSchemaAsString()).append('\\n'));\n+\n+        return sb.toString();\n+    }\n+\n+    /**\n+     * Return the {@link RuntimeWiring} for the given auto-generated schema.\n+     *\n+     * @return the {@link RuntimeWiring}\n+     */\n+    @SuppressWarnings(\"checkstyle:RegexpSinglelineJava\")\n+    public RuntimeWiring getRuntimeWiring() {\n+        RuntimeWiring.Builder builder = newRuntimeWiring();\n+\n+        //  Create the top level Query Runtime Wiring.\n+        SchemaType querySchemaType = getTypeByName(getQueryName());\n+\n+        if (querySchemaType == null) {\n+            throw new GraphQLException(\"No type exists for query of name \" + getQueryName());\n+        }\n+\n+        final TypeRuntimeWiring.Builder typeRuntimeBuilder = newTypeWiring(getQueryName());\n+\n+        // register a type resolver for any interfaces if we have at least one\n+        Set<SchemaType> setInterfaces = getTypes().stream().filter(SchemaType::isInterface).collect(Collectors.toSet());\n+        if (setInterfaces.size() > 0) {\n+            final Map<String, String> mapTypes = new HashMap<>();\n+\n+            getTypes().stream().filter(t -> !t.isInterface()).forEach(t -> mapTypes.put(t.name(), t.valueClassName()));\n+\n+            // generate a TypeResolver for all types that are not interfaces\n+            TypeResolver typeResolver = env -> {\n+                Object o = env.getObject();\n+                for (Map.Entry<String, String> entry : mapTypes.entrySet()) {\n+                    String valueClass = entry.getValue();\n+                    if (valueClass != null) {\n+                        Class<?> typeClass = getSafeClass(entry.getValue());\n+                        if (typeClass != null && typeClass.isAssignableFrom(o.getClass())) {\n+                            return (GraphQLObjectType) env.getSchema().getType(entry.getKey());\n+                        }\n+                    }\n+                }\n+                return null;\n+            };\n+\n+            // add the type resolver to all interfaces and the Query object\n+            setInterfaces.forEach(t -> builder.type(t.name(), tr -> tr.typeResolver(typeResolver)));\n+            builder.type(getQueryName(), tr -> tr.typeResolver(typeResolver));\n+        }\n+\n+        // register the scalars\n+        getScalars().forEach(s -> {\n+            LOGGER.finest(\"Register Scalar: \" + s);\n+            builder.scalar(s.graphQLScalarType());\n+        });\n+\n+        // we should now have the query runtime binding\n+        builder.type(typeRuntimeBuilder);\n+\n+        // search for any types that have field definitions with DataFetchers\n+        getTypes().forEach(t -> {\n+            boolean hasDataFetchers = t.fieldDefinitions().stream().anyMatch(fd -> fd.dataFetcher() != null);\n+            if (hasDataFetchers) {\n+                final TypeRuntimeWiring.Builder runtimeBuilder = newTypeWiring(t.name());\n+                t.fieldDefinitions().stream()\n+                        .filter(fd -> fd.dataFetcher() != null)\n+                        .forEach(fd -> runtimeBuilder.dataFetcher(fd.name(), fd.dataFetcher()));\n+                builder.type(runtimeBuilder);\n+            }\n+        });\n+\n+        return builder.build();\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the type name.\n+     *\n+     * @param typeName type name to match\n+     * @return a {@link SchemaType} that matches the type name or null if none found\n+     */\n+    public SchemaType getTypeByName(String typeName) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (schemaType.name().equals(typeName)) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaInputType} that matches the type name.\n+     *\n+     * @param inputTypeName type name to match\n+     * @return a {@link SchemaInputType} that matches the type name or null if none found\n+     */\n+    public SchemaInputType getInputTypeByName(String inputTypeName) {\n+        for (SchemaInputType schemaInputType : listInputTypes) {\n+            if (schemaInputType.name().equals(inputTypeName)) {\n+                return schemaInputType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaType} that matches the given class.\n+     *\n+     * @param clazz the class to find\n+     * @return a {@link SchemaType} that matches the given class or null if none found\n+     */\n+    public SchemaType getTypeByClass(String clazz) {\n+        for (SchemaType schemaType : listSchemaTypes) {\n+            if (clazz.equals(schemaType.valueClassName())) {\n+                return schemaType;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaEnum} that matches the enum name.\n+     *\n+     * @param enumName type name to match\n+     * @return a {@link SchemaEnum} that matches the enum name or null if none found\n+     */\n+    public SchemaEnum getEnumByName(String enumName) {\n+        for (SchemaEnum schemaEnum1 : listSchemaEnums) {\n+            if (schemaEnum1.name().equals(enumName)) {\n+                return schemaEnum1;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided class name.\n+     *\n+     * @param actualClazz the class name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByActualClass(String actualClazz) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.actualClass().equals(actualClazz)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return a {@link SchemaScalar} which matches the provided scalar name.\n+     *\n+     * @param scalarName the scalar name to match\n+     * @return {@link SchemaScalar} or null if none found\n+     */\n+    public SchemaScalar getScalarByName(String scalarName) {\n+        for (SchemaScalar schemaScalar : getScalars()) {\n+            if (schemaScalar.name().equals(scalarName)) {\n+                return schemaScalar;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the type list\n+     */\n+    public boolean containsTypeWithName(String type) {\n+        return listSchemaTypes.stream().filter(t -> t.name().equals(type)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaInputType} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param type type name to search for\n+     * @return true if the type name is contained within the input type list\n+     */\n+    public boolean containsInputTypeWithName(String type) {\n+        return listInputTypes.stream().filter(t -> t.name().equals(type)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaScalar} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param scalar the scalar name to search for\n+     * @return true if the scalar name is contained within the scalar list\n+     */\n+    public boolean containsScalarWithName(String scalar) {\n+        return listSchemaScalars.stream().filter(s -> s.name().equals(scalar)).count() == 1;\n+    }\n+\n+    /**\n+     * Return true of the {@link SchemaEnum} with the the given name is present for this {@link Schema}.\n+     *\n+     * @param enumName the enum name to search for\n+     * @return true if the enum name is contained within the enum list\n+     */\n+    public boolean containsEnumWithName(String enumName) {\n+        return listSchemaEnums.stream().filter(e -> e.name().equals(enumName)).count() == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 391}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA2NzkxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyMjoyMlrOHyCvYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyMjoyMlrOHyCvYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzNTc0NQ==", "bodyText": "Maybe I'm confused, but we want to check if the input argument is an instance of one of the coercible classes, IIUC. If so, I'd expect to see something like i.e. clazz.instanceOf(input). I'm not sure what's in the source does what we want (assuming I understand the intent correctly), but even if it does it seems more complicated than needed.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522235745", "createdAt": "2020-11-12T16:22:22Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+\n+import graphql.Scalars;\n+import graphql.language.StringValue;\n+import graphql.scalars.ExtendedScalars;\n+import graphql.schema.Coercing;\n+import graphql.schema.CoercingParseLiteralException;\n+import graphql.schema.CoercingParseValueException;\n+import graphql.schema.CoercingSerializeException;\n+import graphql.schema.GraphQLScalarType;\n+\n+import static graphql.Scalars.GraphQLBigInteger;\n+import static graphql.Scalars.GraphQLFloat;\n+import static graphql.Scalars.GraphQLInt;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+\n+/**\n+ * Custom scalars.\n+ */\n+class CustomScalars {\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private CustomScalars() {\n+    }\n+\n+    /**\n+     * An instance of a custome BigDecimal Scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGDECIMAL_SCALAR = newCustomBigDecimalScalar();\n+\n+    /**\n+     * An instance of a custom Int scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_INT_SCALAR = newCustomGraphQLInt();\n+\n+    /**\n+     * An instance of a custom Float scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_FLOAT_SCALAR = newCustomGraphQLFloat();\n+\n+    /**\n+     * An instance of a custom BigInteger scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGINTEGER_SCALAR = newCustomGraphQLBigInteger();\n+\n+    /**\n+     * An instance of a custom formatted date/time scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(FORMATTED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted time scalar.\n+     */\n+     static final GraphQLScalarType FORMATTED_CUSTOM_TIME_SCALAR = newTimeScalar(FORMATTED_TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted date scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_SCALAR = newDateScalar(FORMATTED_DATE_SCALAR);\n+\n+    /**\n+     * An instance of a custom date/time scalar (with default formatting).\n+     */\n+    static final GraphQLScalarType CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_OFFSET_DATE_TIME_SCALAR =\n+            newOffsetDateTimeScalar(FORMATTED_OFFSET_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_ZONED_DATE_TIME_SCALAR =\n+            newZonedDateTimeScalar(FORMATTED_ZONED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_TIME_SCALAR = newTimeScalar(TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom date scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_DATE_SCALAR = newDateScalar(DATE_SCALAR);\n+\n+    /**\n+     * Return a new custom date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+     static GraphQLScalarType newDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom offset date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newOffsetDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom zoned date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newZonedDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom time scalar\n+     */\n+     static GraphQLScalarType newTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Time;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new TimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom date scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date scalar\n+     */\n+     static GraphQLScalarType newDateScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Date;\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigDecimal scalar.\n+     *\n+     * @return a new custom BigDecimal scalar\n+     */\n+    private static GraphQLScalarType newCustomBigDecimalScalar() {\n+        GraphQLScalarType originalScalar = Scalars.GraphQLBigDecimal;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigDecimal>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Int scalar.\n+     *\n+     * @return a new custom Int scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLInt() {\n+        GraphQLScalarType originalScalar = GraphQLInt;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Integer>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Float scalar.\n+     *\n+     * @return a new custom Float scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLFloat() {\n+        GraphQLScalarType originalScalar = GraphQLFloat;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Double>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigInteger scalar.\n+     *\n+     * @return a new custom BigInteger scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLBigInteger() {\n+        GraphQLScalarType originalScalar = GraphQLBigInteger;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigInteger>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Abstract implementation of {@link Coercing} interface for given classes.\n+     */\n+     abstract static class AbstractDateTimeCoercing implements Coercing {\n+\n+        /**\n+         * {@link Class}es that can be coerced.\n+         */\n+        private final Class<?>[] clazzes;\n+\n+        /**\n+         * Construct a {@link AbstractDateTimeCoercing}.\n+         *\n+         * @param clazzes {@link Class}es to coerce\n+         */\n+         AbstractDateTimeCoercing(Class<?>... clazzes) {\n+            this.clazzes = clazzes;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return convert(dataFetcherResult);\n+        }\n+\n+        @Override\n+        public Object parseValue(Object input) throws CoercingParseValueException {\n+            return convert(input);\n+        }\n+\n+        @Override\n+        public Object parseLiteral(Object input) throws CoercingParseLiteralException {\n+            return parseStringLiteral(input);\n+        }\n+\n+        /**\n+         * Convert the given input to the type of if a String then leave it be.\n+         *\n+         * @param input input to coerce\n+         * @return the coerced value\n+         * @throws CoercingParseLiteralException if any exceptions converting\n+         */\n+        private Object convert(Object input) throws CoercingParseLiteralException {\n+            if (input instanceof String) {\n+                return (String) input;\n+            }\n+\n+            for (Class<?> clazz : clazzes) {\n+                if (input.getClass().isInstance(clazz)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 310}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA3MzQ5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyMzo0MFrOHyCy-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyMzo0MFrOHyCy-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzNjY2NQ==", "bodyText": "Again, the cast seems unnecessary given that the return type is Object.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522236665", "createdAt": "2020-11-12T16:23:40Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+\n+import graphql.Scalars;\n+import graphql.language.StringValue;\n+import graphql.scalars.ExtendedScalars;\n+import graphql.schema.Coercing;\n+import graphql.schema.CoercingParseLiteralException;\n+import graphql.schema.CoercingParseValueException;\n+import graphql.schema.CoercingSerializeException;\n+import graphql.schema.GraphQLScalarType;\n+\n+import static graphql.Scalars.GraphQLBigInteger;\n+import static graphql.Scalars.GraphQLFloat;\n+import static graphql.Scalars.GraphQLInt;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+\n+/**\n+ * Custom scalars.\n+ */\n+class CustomScalars {\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private CustomScalars() {\n+    }\n+\n+    /**\n+     * An instance of a custome BigDecimal Scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGDECIMAL_SCALAR = newCustomBigDecimalScalar();\n+\n+    /**\n+     * An instance of a custom Int scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_INT_SCALAR = newCustomGraphQLInt();\n+\n+    /**\n+     * An instance of a custom Float scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_FLOAT_SCALAR = newCustomGraphQLFloat();\n+\n+    /**\n+     * An instance of a custom BigInteger scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGINTEGER_SCALAR = newCustomGraphQLBigInteger();\n+\n+    /**\n+     * An instance of a custom formatted date/time scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(FORMATTED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted time scalar.\n+     */\n+     static final GraphQLScalarType FORMATTED_CUSTOM_TIME_SCALAR = newTimeScalar(FORMATTED_TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted date scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_SCALAR = newDateScalar(FORMATTED_DATE_SCALAR);\n+\n+    /**\n+     * An instance of a custom date/time scalar (with default formatting).\n+     */\n+    static final GraphQLScalarType CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_OFFSET_DATE_TIME_SCALAR =\n+            newOffsetDateTimeScalar(FORMATTED_OFFSET_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_ZONED_DATE_TIME_SCALAR =\n+            newZonedDateTimeScalar(FORMATTED_ZONED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_TIME_SCALAR = newTimeScalar(TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom date scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_DATE_SCALAR = newDateScalar(DATE_SCALAR);\n+\n+    /**\n+     * Return a new custom date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+     static GraphQLScalarType newDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom offset date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newOffsetDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom zoned date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newZonedDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom time scalar\n+     */\n+     static GraphQLScalarType newTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Time;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new TimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom date scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date scalar\n+     */\n+     static GraphQLScalarType newDateScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Date;\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigDecimal scalar.\n+     *\n+     * @return a new custom BigDecimal scalar\n+     */\n+    private static GraphQLScalarType newCustomBigDecimalScalar() {\n+        GraphQLScalarType originalScalar = Scalars.GraphQLBigDecimal;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigDecimal>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Int scalar.\n+     *\n+     * @return a new custom Int scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLInt() {\n+        GraphQLScalarType originalScalar = GraphQLInt;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Integer>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Float scalar.\n+     *\n+     * @return a new custom Float scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLFloat() {\n+        GraphQLScalarType originalScalar = GraphQLFloat;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Double>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigInteger scalar.\n+     *\n+     * @return a new custom BigInteger scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLBigInteger() {\n+        GraphQLScalarType originalScalar = GraphQLBigInteger;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigInteger>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Abstract implementation of {@link Coercing} interface for given classes.\n+     */\n+     abstract static class AbstractDateTimeCoercing implements Coercing {\n+\n+        /**\n+         * {@link Class}es that can be coerced.\n+         */\n+        private final Class<?>[] clazzes;\n+\n+        /**\n+         * Construct a {@link AbstractDateTimeCoercing}.\n+         *\n+         * @param clazzes {@link Class}es to coerce\n+         */\n+         AbstractDateTimeCoercing(Class<?>... clazzes) {\n+            this.clazzes = clazzes;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return convert(dataFetcherResult);\n+        }\n+\n+        @Override\n+        public Object parseValue(Object input) throws CoercingParseValueException {\n+            return convert(input);\n+        }\n+\n+        @Override\n+        public Object parseLiteral(Object input) throws CoercingParseLiteralException {\n+            return parseStringLiteral(input);\n+        }\n+\n+        /**\n+         * Convert the given input to the type of if a String then leave it be.\n+         *\n+         * @param input input to coerce\n+         * @return the coerced value\n+         * @throws CoercingParseLiteralException if any exceptions converting\n+         */\n+        private Object convert(Object input) throws CoercingParseLiteralException {\n+            if (input instanceof String) {\n+                return (String) input;\n+            }\n+\n+            for (Class<?> clazz : clazzes) {\n+                if (input.getClass().isInstance(clazz)) {\n+                    return clazz.cast(input);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 311}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDA3OTQ5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyNDo1M1rOHyC2tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjoyNDo1M1rOHyC2tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIzNzYyMA==", "bodyText": "Again, why cast here?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522237620", "createdAt": "2020-11-12T16:24:53Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/CustomScalars.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+\n+import graphql.Scalars;\n+import graphql.language.StringValue;\n+import graphql.scalars.ExtendedScalars;\n+import graphql.schema.Coercing;\n+import graphql.schema.CoercingParseLiteralException;\n+import graphql.schema.CoercingParseValueException;\n+import graphql.schema.CoercingSerializeException;\n+import graphql.schema.GraphQLScalarType;\n+\n+import static graphql.Scalars.GraphQLBigInteger;\n+import static graphql.Scalars.GraphQLFloat;\n+import static graphql.Scalars.GraphQLInt;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+\n+/**\n+ * Custom scalars.\n+ */\n+class CustomScalars {\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private CustomScalars() {\n+    }\n+\n+    /**\n+     * An instance of a custome BigDecimal Scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGDECIMAL_SCALAR = newCustomBigDecimalScalar();\n+\n+    /**\n+     * An instance of a custom Int scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_INT_SCALAR = newCustomGraphQLInt();\n+\n+    /**\n+     * An instance of a custom Float scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_FLOAT_SCALAR = newCustomGraphQLFloat();\n+\n+    /**\n+     * An instance of a custom BigInteger scalar.\n+     */\n+    static final GraphQLScalarType CUSTOM_BIGINTEGER_SCALAR = newCustomGraphQLBigInteger();\n+\n+    /**\n+     * An instance of a custom formatted date/time scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(FORMATTED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted time scalar.\n+     */\n+     static final GraphQLScalarType FORMATTED_CUSTOM_TIME_SCALAR = newTimeScalar(FORMATTED_TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom formatted date scalar.\n+     */\n+    static final GraphQLScalarType FORMATTED_CUSTOM_DATE_SCALAR = newDateScalar(FORMATTED_DATE_SCALAR);\n+\n+    /**\n+     * An instance of a custom date/time scalar (with default formatting).\n+     */\n+    static final GraphQLScalarType CUSTOM_DATE_TIME_SCALAR = newDateTimeScalar(DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_OFFSET_DATE_TIME_SCALAR =\n+            newOffsetDateTimeScalar(FORMATTED_OFFSET_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom offset date/time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_ZONED_DATE_TIME_SCALAR =\n+            newZonedDateTimeScalar(FORMATTED_ZONED_DATETIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom time scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_TIME_SCALAR = newTimeScalar(TIME_SCALAR);\n+\n+    /**\n+     * An instance of a custom date scalar (with default formatting).\n+     */\n+     static final GraphQLScalarType CUSTOM_DATE_SCALAR = newDateScalar(DATE_SCALAR);\n+\n+    /**\n+     * Return a new custom date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+     static GraphQLScalarType newDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom offset date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newOffsetDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom zoned date/time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date/time scalar\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static GraphQLScalarType newZonedDateTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.DateTime;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom time scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom time scalar\n+     */\n+     static GraphQLScalarType newTimeScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Time;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new TimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom date scalar.\n+     *\n+     * @param name the name of the scalar\n+     * @return a new custom date scalar\n+     */\n+     static GraphQLScalarType newDateScalar(String name) {\n+        GraphQLScalarType originalScalar = ExtendedScalars.Date;\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new DateTimeCoercing())\n+                .name(name)\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigDecimal scalar.\n+     *\n+     * @return a new custom BigDecimal scalar\n+     */\n+    private static GraphQLScalarType newCustomBigDecimalScalar() {\n+        GraphQLScalarType originalScalar = Scalars.GraphQLBigDecimal;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigDecimal>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Int scalar.\n+     *\n+     * @return a new custom Int scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLInt() {\n+        GraphQLScalarType originalScalar = GraphQLInt;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Integer>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom Float scalar.\n+     *\n+     * @return a new custom Float scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLFloat() {\n+        GraphQLScalarType originalScalar = GraphQLFloat;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<Double>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Return a new custom BigInteger scalar.\n+     *\n+     * @return a new custom BigInteger scalar\n+     */\n+    private static GraphQLScalarType newCustomGraphQLBigInteger() {\n+        GraphQLScalarType originalScalar = GraphQLBigInteger;\n+\n+        return GraphQLScalarType.newScalar()\n+                .coercing(new NumberCoercing<BigInteger>(originalScalar.getCoercing()))\n+                .name(originalScalar.getName())\n+                .description(\"Custom: \" + originalScalar.getDescription())\n+                .build();\n+    }\n+\n+    /**\n+     * Abstract implementation of {@link Coercing} interface for given classes.\n+     */\n+     abstract static class AbstractDateTimeCoercing implements Coercing {\n+\n+        /**\n+         * {@link Class}es that can be coerced.\n+         */\n+        private final Class<?>[] clazzes;\n+\n+        /**\n+         * Construct a {@link AbstractDateTimeCoercing}.\n+         *\n+         * @param clazzes {@link Class}es to coerce\n+         */\n+         AbstractDateTimeCoercing(Class<?>... clazzes) {\n+            this.clazzes = clazzes;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return convert(dataFetcherResult);\n+        }\n+\n+        @Override\n+        public Object parseValue(Object input) throws CoercingParseValueException {\n+            return convert(input);\n+        }\n+\n+        @Override\n+        public Object parseLiteral(Object input) throws CoercingParseLiteralException {\n+            return parseStringLiteral(input);\n+        }\n+\n+        /**\n+         * Convert the given input to the type of if a String then leave it be.\n+         *\n+         * @param input input to coerce\n+         * @return the coerced value\n+         * @throws CoercingParseLiteralException if any exceptions converting\n+         */\n+        private Object convert(Object input) throws CoercingParseLiteralException {\n+            if (input instanceof String) {\n+                return (String) input;\n+            }\n+\n+            for (Class<?> clazz : clazzes) {\n+                if (input.getClass().isInstance(clazz)) {\n+                    return clazz.cast(input);\n+                }\n+            }\n+\n+            throw new CoercingParseLiteralException(\"Unable to convert type of \" + input.getClass());\n+        }\n+\n+        /**\n+         * Parse a String literal and return instance of {@link StringValue} or throw an exception.\n+         *\n+         * @param input input to parse\n+         * @throws CoercingParseLiteralException if it is not a {@link StringValue}\n+         */\n+        private String parseStringLiteral(Object input) throws CoercingParseLiteralException {\n+            if (!(input instanceof StringValue)) {\n+                throw new CoercingParseLiteralException(\"Expected AST type 'StringValue' but was '\"\n+                                                                + (\n+                        input == null\n+                                ? \"null\"\n+                                : input.getClass().getSimpleName()) + \"'.\");\n+            }\n+            return ((StringValue) input).getValue();\n+        }\n+    }\n+\n+    /**\n+     * Coercing Implementation for Date/Time.\n+     */\n+     static class DateTimeCoercing extends AbstractDateTimeCoercing {\n+\n+        /**\n+         * Construct a {@link DateTimeCoercing}.\n+         */\n+         DateTimeCoercing() {\n+            super(LocalDateTime.class, OffsetDateTime.class, ZonedDateTime.class);\n+        }\n+    }\n+\n+    /**\n+     * Coercing implementation for Time.\n+     */\n+     static class TimeCoercing extends AbstractDateTimeCoercing {\n+\n+        /**\n+         * Construct a {@link TimeCoercing}.\n+         */\n+         TimeCoercing() {\n+            super(LocalTime.class, OffsetTime.class);\n+        }\n+    }\n+\n+    /**\n+     * Coercing implementation for Date.\n+     */\n+     static class DateCoercing extends AbstractDateTimeCoercing {\n+\n+        /**\n+         * Construct a {@link DateCoercing}.\n+         */\n+         DateCoercing() {\n+            super(LocalDate.class);\n+        }\n+    }\n+\n+    /**\n+     * Coercing implementation for BigDecimal.\n+     */\n+     static class BigDecimalCoercing extends AbstractDateTimeCoercing {\n+\n+        /**\n+         * Construct a {@link DateCoercing}.\n+         */\n+         BigDecimalCoercing() {\n+            super(BigDecimal.class);\n+        }\n+    }\n+\n+    /**\n+     * Number implementation of {@link Coercing} interface for given classes.\n+     * @param <I> defines input type\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+     static class NumberCoercing<I> implements Coercing<I, Object> {\n+\n+        /**\n+         * Original {@link Coercing} to fall back on if neeed.\n+         */\n+        private final Coercing originalCoercing;\n+\n+        /**\n+         * Construct a {@link NumberCoercing} from an original {@link Coercing}.\n+         *\n+         * @param originalCoercing original {@link Coercing}\n+         */\n+         NumberCoercing(Coercing originalCoercing) {\n+            this.originalCoercing = originalCoercing;\n+        }\n+\n+        @Override\n+        public Object serialize(Object dataFetcherResult) throws CoercingSerializeException {\n+            return dataFetcherResult instanceof String\n+                    ? (String) dataFetcherResult", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 412}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDExMTkxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjozMToxMVrOHyDKHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQyMzo0NjoyNFrOH9y63A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI0MjU5MA==", "bodyText": "I don't know exactly what argument.originalType() can return, but if it could be a subtype of Map then as written this test would let that through -- because Map is not guaranteed to be assignable to a subtype -- but I don't think that's the intent.\nWhat about if (originalType != null && Map.class.isAssignableFrom(originalType))  instead? Then if the originalType is any Map we'd detect it.\nOr maybe I'm missing something.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522242590", "createdAt": "2020-11-12T16:31:11Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "diffHunk": "@@ -0,0 +1,596 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.NumberFormat;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZonedDateTime;\n+import java.time.format.DateTimeFormatter;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.logging.Logger;\n+\n+import javax.enterprise.inject.spi.CDI;\n+\n+import io.helidon.graphql.server.ExecutionContext;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.DataFetcher;\n+import graphql.schema.DataFetchingEnvironment;\n+import graphql.schema.PropertyDataFetcher;\n+import graphql.schema.PropertyDataFetcherHelper;\n+\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatDate;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatNumber;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectDateFormatter;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectNumberFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.isFormatEmpty;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ID;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureRuntimeException;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isDateTimeClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isPrimitiveArray;\n+\n+/**\n+ * Utilities for working with {@link DataFetcher}s.\n+ */\n+class DataFetcherUtils {\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(DataFetcherUtils.class.getName());\n+\n+    /**\n+     * Empty format.\n+     */\n+    private static final String[] EMPTY_FORMAT = new String[] {null, null };\n+\n+    /**\n+     * Map message.\n+     */\n+    private static final String MAP_MESSAGE = \"This implementation does not support using a Map \"\n+            + \"as input to a query or mutation\";\n+\n+    /**\n+     * Private constructor for utilities class.\n+     */\n+    private DataFetcherUtils() {\n+    }\n+\n+    /**\n+     * Create a new {@link DataFetcher} for a {@link Class} and {@link Method} to be executed.\n+     *\n+     * @param clazz  {@link Class} to call\n+     * @param method {@link Method} to call\n+     * @param source defines the source for a @Source annotation - may be null\n+     * @param args   optional {@link SchemaArgument}s\n+     * @param schema {@link Schema} that created this {@link DataFetcher}\n+     * @param <V>    value type\n+     * @return a new {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <V> DataFetcher<V> newMethodDataFetcher(Schema schema, Class<?> clazz, Method method,\n+                                                          String source, SchemaArgument... args) {\n+\n+        // this is an application scoped bean\n+        GraphQlBean bean = CDI.current().select(GraphQlBean.class).get();\n+\n+        return environment -> {\n+            ArrayList<Object> listArgumentValues = new ArrayList<>();\n+            // only one @Source annotation should be present and it should be the first argument\n+            if (source != null) {\n+                Class<?> sourceClazz;\n+                try {\n+                    sourceClazz = Class.forName(source);\n+                    listArgumentValues.add(sourceClazz.cast(environment.getSource()));\n+                } catch (ClassNotFoundException e) {\n+                    LOGGER.warning(\"Unable to find source class \" + source);\n+                }\n+            }\n+\n+            if (args.length > 0) {\n+                for (SchemaArgument argument : args) {\n+                    // ensure a Map is not used as an input type\n+                    Class<?> originalType = argument.originalType();\n+                    if (originalType != null && originalType.isAssignableFrom(Map.class)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1OTQ1Mg==", "bodyText": "my mistake, you are correct.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534559452", "createdAt": "2020-12-02T23:46:24Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "diffHunk": "@@ -0,0 +1,596 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.NumberFormat;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZonedDateTime;\n+import java.time.format.DateTimeFormatter;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.logging.Logger;\n+\n+import javax.enterprise.inject.spi.CDI;\n+\n+import io.helidon.graphql.server.ExecutionContext;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.DataFetcher;\n+import graphql.schema.DataFetchingEnvironment;\n+import graphql.schema.PropertyDataFetcher;\n+import graphql.schema.PropertyDataFetcherHelper;\n+\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatDate;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatNumber;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectDateFormatter;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectNumberFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.isFormatEmpty;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ID;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureRuntimeException;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isDateTimeClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isPrimitiveArray;\n+\n+/**\n+ * Utilities for working with {@link DataFetcher}s.\n+ */\n+class DataFetcherUtils {\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(DataFetcherUtils.class.getName());\n+\n+    /**\n+     * Empty format.\n+     */\n+    private static final String[] EMPTY_FORMAT = new String[] {null, null };\n+\n+    /**\n+     * Map message.\n+     */\n+    private static final String MAP_MESSAGE = \"This implementation does not support using a Map \"\n+            + \"as input to a query or mutation\";\n+\n+    /**\n+     * Private constructor for utilities class.\n+     */\n+    private DataFetcherUtils() {\n+    }\n+\n+    /**\n+     * Create a new {@link DataFetcher} for a {@link Class} and {@link Method} to be executed.\n+     *\n+     * @param clazz  {@link Class} to call\n+     * @param method {@link Method} to call\n+     * @param source defines the source for a @Source annotation - may be null\n+     * @param args   optional {@link SchemaArgument}s\n+     * @param schema {@link Schema} that created this {@link DataFetcher}\n+     * @param <V>    value type\n+     * @return a new {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <V> DataFetcher<V> newMethodDataFetcher(Schema schema, Class<?> clazz, Method method,\n+                                                          String source, SchemaArgument... args) {\n+\n+        // this is an application scoped bean\n+        GraphQlBean bean = CDI.current().select(GraphQlBean.class).get();\n+\n+        return environment -> {\n+            ArrayList<Object> listArgumentValues = new ArrayList<>();\n+            // only one @Source annotation should be present and it should be the first argument\n+            if (source != null) {\n+                Class<?> sourceClazz;\n+                try {\n+                    sourceClazz = Class.forName(source);\n+                    listArgumentValues.add(sourceClazz.cast(environment.getSource()));\n+                } catch (ClassNotFoundException e) {\n+                    LOGGER.warning(\"Unable to find source class \" + source);\n+                }\n+            }\n+\n+            if (args.length > 0) {\n+                for (SchemaArgument argument : args) {\n+                    // ensure a Map is not used as an input type\n+                    Class<?> originalType = argument.originalType();\n+                    if (originalType != null && originalType.isAssignableFrom(Map.class)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI0MjU5MA=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDExNzgwOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGenerator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjozMjoxNlrOHyDNlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjozMjoxNlrOHyDNlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI0MzQ3Ng==", "bodyText": "anyMatch", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522243476", "createdAt": "2020-11-12T16:32:16Z", "author": {"login": "danielkec"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGenerator.java", "diffHunk": "@@ -0,0 +1,1780 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.beans.IntrospectionException;\n+import java.beans.Introspector;\n+import java.beans.MethodDescriptor;\n+import java.beans.PropertyDescriptor;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.Parameter;\n+import java.lang.reflect.ParameterizedType;\n+import java.text.NumberFormat;\n+import java.time.format.DateTimeFormatter;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import javax.json.bind.annotation.JsonbProperty;\n+\n+import io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DiscoveredMethod;\n+\n+import graphql.schema.DataFetcher;\n+import graphql.schema.DataFetcherFactories;\n+import graphql.schema.GraphQLScalarType;\n+import graphql.schema.PropertyDataFetcher;\n+import org.eclipse.microprofile.graphql.Description;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Id;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Mutation;\n+import org.eclipse.microprofile.graphql.Name;\n+import org.eclipse.microprofile.graphql.NonNull;\n+import org.eclipse.microprofile.graphql.Query;\n+import org.eclipse.microprofile.graphql.Source;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_OFFSET_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_ZONED_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.DATE;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.NO_FORMATTING;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.NUMBER;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatDate;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatNumber;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectDateFormatter;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectNumberFormat;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getFormattingAnnotation;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.isJsonbAnnotationPresent;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DiscoveredMethod.MUTATION_TYPE;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.DiscoveredMethod.QUERY_TYPE;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_OFFSET_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.FORMATTED_ZONED_DATETIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ID;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.STRING;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.checkScalars;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureConfigurationException;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureValidName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getAnnotationValue;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getArrayLevels;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getDefaultValueAnnotationValue;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getDescription;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getFieldAnnotations;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getFieldName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getGraphQLType;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getMethodAnnotations;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getMethodName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getParameterAnnotations;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getRootArrayClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSafeClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getScalar;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getSimpleName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.getTypeName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isArrayType;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isDateTimeScalar;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isEnumClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isGraphQLType;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isPrimitive;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.shouldIgnoreField;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.shouldIgnoreMethod;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.stripMethodName;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.validateIDClass;\n+\n+/**\n+ * Various utilities for generating {@link Schema}s from classes.\n+ */\n+class SchemaGenerator {\n+\n+    /**\n+     * \"is\" prefix.\n+     */\n+    protected static final String IS = \"is\";\n+\n+    /**\n+     * \"get\" prefix.\n+     */\n+    protected static final String GET = \"get\";\n+\n+    /**\n+     * \"set\" prefix.\n+     */\n+    protected static final String SET = \"set\";\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(SchemaGenerator.class.getName());\n+\n+    /**\n+     * {@link JandexUtils} instance to hold indexes.\n+     */\n+    private JandexUtils jandexUtils;\n+\n+    /**\n+     * Holds the {@link Set} of unresolved types while processing the annotations.\n+     */\n+    private Set<String> setUnresolvedTypes = new HashSet<>();\n+\n+    /**\n+     * Holds the {@link Set} of additional methods that need to be added to types.\n+     */\n+    private Set<DiscoveredMethod> setAdditionalMethods = new HashSet<>();\n+\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Construct a {@link SchemaGenerator}.\n+     *\n+     * @param builder the {@link io.helidon.microprofile.graphql.server.SchemaGenerator.Builder} to construct from\n+     */\n+    private SchemaGenerator(Builder builder) {\n+        this.collectedApis.addAll(builder.collectedApis);\n+        jandexUtils = JandexUtils.create();\n+        jandexUtils.loadIndexes();\n+        if (!jandexUtils.hasIndex()) {\n+            String message = \"Unable to find or load jandex index files: \"\n+                    + jandexUtils.getIndexFile() + \".\\nEnsure you are using the \"\n+                    + \"jandex-maven-plugin when you are building your application\";\n+            LOGGER.warning(message);\n+        }\n+    }\n+\n+    /**\n+     * Fluent API builder to create {@link SchemaGenerator}.\n+     *\n+     * @return new builder instance\n+     */\n+    public static Builder builder() {\n+        return new SchemaGenerator.Builder();\n+    }\n+\n+    /**\n+     * Generate a {@link Schema} by scanning all discovered classes using the {@link GraphQlCdiExtension}.\n+     *\n+     * @return a {@link Schema}\n+     * @throws java.lang.IllegalStateException in case the schema cannot be generated\n+     */\n+    @SuppressWarnings(\"rawtypes\")\n+    public Schema generateSchema() {\n+        int count = collectedApis.size();\n+\n+        LOGGER.info(\"Discovered \" + count + \" annotated GraphQL API class\" + (count != 1 ? \"es\" : \"\"));\n+\n+        try {\n+            return generateSchemaFromClasses(collectedApis);\n+        } catch (IntrospectionException | ClassNotFoundException e) {\n+            throw new IllegalStateException(\"Cannot generate schema\", e);\n+        }\n+    }\n+\n+    /**\n+     * Generate a {@link Schema} from a given array of classes.  The classes are checked to see if they contain any of the\n+     * annotations from the microprofile spec.\n+     *\n+     * @param clazzes array of classes to check\n+     * @return a {@link Schema}\n+     *\n+     * @throws IntrospectionException if any errors with introspection\n+     * @throws ClassNotFoundException if any classes are not found\n+     */\n+    protected Schema generateSchemaFromClasses(Set<Class<?>> clazzes) throws IntrospectionException, ClassNotFoundException {\n+        Schema schema = Schema.create();\n+        setUnresolvedTypes.clear();\n+        setAdditionalMethods.clear();\n+\n+        SchemaType rootQueryType = SchemaType.builder().name(schema.getQueryName()).build();\n+        SchemaType rootMutationType = SchemaType.builder().name(schema.getMutationName()).build();\n+\n+        // process any specific classes with the Input, Type or Interface annotations\n+        for (Class<?> clazz : clazzes) {\n+            // only include interfaces and concrete classes/enums\n+            if (clazz.isInterface() || (!clazz.isInterface() && !Modifier.isAbstract(clazz.getModifiers()))) {\n+                // Discover Enum via annotation\n+                if (clazz.isAnnotationPresent(org.eclipse.microprofile.graphql.Enum.class)) {\n+                    schema.addEnum(generateEnum(clazz));\n+                    continue;\n+                }\n+\n+                // Type, Interface, Input are all treated similarly\n+                Type typeAnnotation = clazz.getAnnotation(Type.class);\n+                Interface interfaceAnnotation = clazz.getAnnotation(Interface.class);\n+                Input inputAnnotation = clazz.getAnnotation(Input.class);\n+\n+                if (typeAnnotation != null && inputAnnotation != null) {\n+                    ensureConfigurationException(LOGGER, \"Class \" + clazz.getName() + \" has been annotated with\"\n+                            + \" both Type and Input\");\n+                }\n+\n+                if (typeAnnotation != null || interfaceAnnotation != null) {\n+                    if (interfaceAnnotation != null && !clazz.isInterface()) {\n+                        ensureConfigurationException(LOGGER, \"Class \" + clazz.getName() + \" has been annotated with\"\n+                                + \" @Interface but is not one\");\n+                    }\n+\n+                    // assuming value for annotation overrides @Name\n+                    String typeName = getTypeName(clazz, true);\n+                    SchemaType type = SchemaType.builder()\n+                            .name(typeName.isBlank() ? clazz.getSimpleName() : typeName)\n+                            .valueClassName(clazz.getName()).build();\n+                    type.isInterface(clazz.isInterface());\n+                    type.description(getDescription(clazz.getAnnotation(Description.class)));\n+\n+                    // add the discovered type\n+                    addTypeToSchema(schema, type);\n+\n+                    if (type.isInterface()) {\n+                        // is an interface so check for any implementors and add them too\n+                        jandexUtils.getKnownImplementors(clazz.getName()).forEach(c -> setUnresolvedTypes.add(c.getName()));\n+                    }\n+                } else if (inputAnnotation != null) {\n+                    String clazzName = clazz.getName();\n+                    String simpleName = clazz.getSimpleName();\n+\n+                    SchemaInputType inputType = generateType(clazzName, true).createInputType(\"\");\n+                    // if the name of the InputType was not changed then append \"Input\"\n+                    if (inputType.name().equals(simpleName)) {\n+                        inputType.name(inputType.name() + \"Input\");\n+                    }\n+\n+                    if (!schema.containsInputTypeWithName(inputType.name())) {\n+                        schema.addInputType(inputType);\n+                        checkInputType(schema, inputType);\n+                    }\n+                }\n+\n+                // obtain top level query API's\n+                if (clazz.isAnnotationPresent(GraphQLApi.class)) {\n+                    processGraphQLApiAnnotations(rootQueryType, rootMutationType, schema, clazz);\n+                }\n+            }\n+        }\n+\n+        schema.addType(rootQueryType);\n+        schema.addType(rootMutationType);\n+\n+        // process unresolved types\n+        processUnresolvedTypes(schema);\n+\n+        // look though all of interface type and see if any of the known types implement\n+        // the interface and if so, add the interface to the type\n+        schema.getTypes().stream().filter(SchemaType::isInterface).forEach(it -> {\n+            schema.getTypes().stream().filter(t -> !t.isInterface() && t.valueClassName() != null).forEach(type -> {\n+                Class<?> interfaceClass = getSafeClass(it.valueClassName());\n+                Class<?> typeClass = getSafeClass(type.valueClassName());\n+                if (interfaceClass != null\n+                        && typeClass != null\n+                        && interfaceClass.isAssignableFrom(typeClass)) {\n+                    type.implementingInterface(it.name());\n+                }\n+            });\n+        });\n+\n+        // process any additional methods required via the @Source annotation\n+        for (DiscoveredMethod dm : setAdditionalMethods) {\n+            // add the discovered method to the type\n+            SchemaType type = schema.getTypeByClass(dm.source());\n+            if (type != null) {\n+                SchemaFieldDefinition fd = newFieldDefinition(dm, null);\n+                // add all arguments which are not source arguments\n+                if (dm.arguments().size() > 0) {\n+                    dm.arguments().stream().filter(a -> !a.isSourceArgument())\n+                            .forEach(fd::addArgument);\n+                }\n+\n+                // check for existing DataFetcher\n+                fd.dataFetcher(DataFetcherUtils.newMethodDataFetcher(\n+                        schema, dm.method().getDeclaringClass(), dm.method(),\n+                        dm.source(), fd.arguments().toArray(new SchemaArgument[0])));\n+                type.addFieldDefinition(fd);\n+\n+                // we are creating this as a type so ignore any Input annotation\n+                String simpleName = getSimpleName(fd.returnType(), true);\n+                String returnType = fd.returnType();\n+                if (!simpleName.equals(returnType)) {\n+                    updateLongTypes(schema, returnType, simpleName);\n+                }\n+            }\n+        }\n+\n+        // process default values for dates\n+        processDefaultDateTimeValues(schema);\n+\n+        // process the @GraphQLApi annotated classes\n+        if (rootQueryType.fieldDefinitions().size() == 0 && rootMutationType.fieldDefinitions().size() == 0) {\n+            LOGGER.warning(\"Unable to find any classes with @GraphQLApi annotation.\"\n+                                   + \"Unable to build schema\");\n+        }\n+\n+        return schema;\n+    }\n+\n+    /**\n+     * Process all {@link SchemaFieldDefinition}s and {@link SchemaArgument}s and update the default values for any scalars.\n+     *\n+     * @param schema {@link Schema} to update\n+     */\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    private void processDefaultDateTimeValues(Schema schema) {\n+        // concatenate both the SchemaType and SchemaInputType\n+        Stream streamInputTypes = schema.getInputTypes().stream().map(it -> (SchemaType) it);\n+        Stream<SchemaType> streamAll = Stream.concat(streamInputTypes, schema.getTypes().stream());\n+        streamAll.forEach(t -> {\n+            t.fieldDefinitions().forEach(fd -> {\n+                String returnType = fd.returnType();\n+                // only check Date/Time/DateTime scalars that are not Queries or don't have data fetchers\n+                // as default formatting has already been dealt with\n+                if (isDateTimeScalar(returnType) && (t.name().equals(Schema.QUERY) || fd.dataFetcher() == null)) {\n+                    String[] existingFormat = fd.format();\n+                    // check if this type is an array type and if so then get the actual original type\n+                    Class<?> clazzOriginalType = fd.originalArrayType() != null\n+                            ? fd.originalArrayType() : fd.originalType();\n+                    String[] newFormat = ensureFormat(returnType, clazzOriginalType.getName(), existingFormat);\n+                    if (!Arrays.equals(newFormat, existingFormat) && newFormat.length == 2) {\n+                        // formats differ so set the new format and DataFetcher\n+                        fd.format(newFormat);\n+                        if (fd.dataFetcher() == null) {\n+                            // create the raw array to pass to the retrieveFormattingDataFetcher method\n+                            DataFetcher dataFetcher = retrieveFormattingDataFetcher(\n+                                    new String[] {DATE, newFormat[0], newFormat[1]},\n+                                    fd.name(), clazzOriginalType.getName());\n+                            fd.dataFetcher(dataFetcher);\n+                        }\n+                        fd.defaultFormatApplied(true);\n+                        SchemaScalar scalar = schema.getScalarByName(fd.returnType());\n+                        GraphQLScalarType newScalarType = null;\n+                        if (fd.returnType().equals(FORMATTED_DATE_SCALAR)) {\n+                            fd.returnType(DATE_SCALAR);\n+                            newScalarType = CUSTOM_DATE_SCALAR;\n+                        } else if (fd.returnType().equals(FORMATTED_TIME_SCALAR)) {\n+                            fd.returnType(TIME_SCALAR);\n+                            newScalarType = CUSTOM_TIME_SCALAR;\n+                        } else if (fd.returnType().equals(FORMATTED_DATETIME_SCALAR)) {\n+                            fd.returnType(DATETIME_SCALAR);\n+                            newScalarType = CUSTOM_DATE_TIME_SCALAR;\n+                        } else if (fd.returnType().equals(FORMATTED_OFFSET_DATETIME_SCALAR)) {\n+                            fd.returnType(FORMATTED_OFFSET_DATETIME_SCALAR);\n+                            newScalarType = CUSTOM_OFFSET_DATE_TIME_SCALAR;\n+                        } else if (fd.returnType().equals(FORMATTED_ZONED_DATETIME_SCALAR)) {\n+                            fd.returnType(FORMATTED_ZONED_DATETIME_SCALAR);\n+                            newScalarType = CUSTOM_ZONED_DATE_TIME_SCALAR;\n+                        }\n+\n+                        // clone the scalar with the new scalar name\n+                        SchemaScalar newScalar = new SchemaScalar(fd.returnType(), scalar.actualClass(),\n+                                                                  newScalarType, scalar.defaultFormat());\n+                        if (!schema.containsScalarWithName(newScalar.name())) {\n+                            schema.addScalar(newScalar);\n+                        }\n+                    }\n+                }\n+\n+                // check the SchemaArguments\n+                fd.arguments().forEach(a -> {\n+                    String argumentType = a.argumentType();\n+                    if (isDateTimeScalar(argumentType)) {\n+                        String[] existingArgFormat = a.format();\n+                        Class<?> clazzOriginalType = a.originalArrayType() != null\n+                                ? a.originalArrayType() : a.originalType();\n+                        String[] newArgFormat = ensureFormat(argumentType, clazzOriginalType.getName(), existingArgFormat);\n+                        if (!Arrays.equals(newArgFormat, existingArgFormat) && newArgFormat.length == 2) {\n+                            a.format(newArgFormat);\n+                        }\n+                    }\n+                });\n+            });\n+        });\n+    }\n+\n+    /**\n+     * Process any unresolved types.\n+     *\n+     * @param schema {@link Schema} to add types to\n+     */\n+    private void processUnresolvedTypes(Schema schema) {\n+        // create any types that are still unresolved. e.g. an Order that contains OrderLine objects\n+        // also ensure if the unresolved type contains another unresolved type then we process it\n+        while (setUnresolvedTypes.size() > 0) {\n+            String returnType = setUnresolvedTypes.iterator().next();\n+\n+            setUnresolvedTypes.remove(returnType);\n+            try {\n+                String simpleName = getSimpleName(returnType, true);\n+\n+                SchemaScalar scalar = getScalar(returnType);\n+                if (scalar != null) {\n+                    if (!schema.containsScalarWithName(scalar.name())) {\n+                        schema.addScalar(scalar);\n+                    }\n+                    // update the return type with the scalar\n+                    updateLongTypes(schema, returnType, scalar.name());\n+                } else if (isEnumClass(returnType)) {\n+                    SchemaEnum newEnum = generateEnum(Class.forName(returnType));\n+                    if (!schema.containsEnumWithName(simpleName)) {\n+                        schema.addEnum(newEnum);\n+                    }\n+                    updateLongTypes(schema, returnType, newEnum.name());\n+                } else {\n+                    // we will either know this type already or need to add it\n+                    boolean fExists = schema.getTypes().stream()\n+                            .filter(t -> t.name().equals(simpleName)).count() > 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 453}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDE0NzI5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNjozODo0MlrOHyDf4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QwMDoyOTowMVrOH9z4ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI0ODE2MQ==", "bodyText": "Is originalType guaranteed to be the interface type (List here, or Set or Collection a couple lines below) and never a sub-interface or an implementation class? If not, then the direct equals comparison will miss ArrayLists or HashSets, for example.\nAlso confusing me about this: I interpret the JavaDoc for the originalType argument to mean that originalType is the type of the elements in the collection, not the type of the collection itself.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522248161", "createdAt": "2020-11-12T16:38:42Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "diffHunk": "@@ -0,0 +1,596 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.NumberFormat;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZonedDateTime;\n+import java.time.format.DateTimeFormatter;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.logging.Logger;\n+\n+import javax.enterprise.inject.spi.CDI;\n+\n+import io.helidon.graphql.server.ExecutionContext;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.DataFetcher;\n+import graphql.schema.DataFetchingEnvironment;\n+import graphql.schema.PropertyDataFetcher;\n+import graphql.schema.PropertyDataFetcherHelper;\n+\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatDate;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatNumber;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectDateFormatter;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectNumberFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.isFormatEmpty;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ID;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureRuntimeException;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isDateTimeClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isPrimitiveArray;\n+\n+/**\n+ * Utilities for working with {@link DataFetcher}s.\n+ */\n+class DataFetcherUtils {\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(DataFetcherUtils.class.getName());\n+\n+    /**\n+     * Empty format.\n+     */\n+    private static final String[] EMPTY_FORMAT = new String[] {null, null };\n+\n+    /**\n+     * Map message.\n+     */\n+    private static final String MAP_MESSAGE = \"This implementation does not support using a Map \"\n+            + \"as input to a query or mutation\";\n+\n+    /**\n+     * Private constructor for utilities class.\n+     */\n+    private DataFetcherUtils() {\n+    }\n+\n+    /**\n+     * Create a new {@link DataFetcher} for a {@link Class} and {@link Method} to be executed.\n+     *\n+     * @param clazz  {@link Class} to call\n+     * @param method {@link Method} to call\n+     * @param source defines the source for a @Source annotation - may be null\n+     * @param args   optional {@link SchemaArgument}s\n+     * @param schema {@link Schema} that created this {@link DataFetcher}\n+     * @param <V>    value type\n+     * @return a new {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <V> DataFetcher<V> newMethodDataFetcher(Schema schema, Class<?> clazz, Method method,\n+                                                          String source, SchemaArgument... args) {\n+\n+        // this is an application scoped bean\n+        GraphQlBean bean = CDI.current().select(GraphQlBean.class).get();\n+\n+        return environment -> {\n+            ArrayList<Object> listArgumentValues = new ArrayList<>();\n+            // only one @Source annotation should be present and it should be the first argument\n+            if (source != null) {\n+                Class<?> sourceClazz;\n+                try {\n+                    sourceClazz = Class.forName(source);\n+                    listArgumentValues.add(sourceClazz.cast(environment.getSource()));\n+                } catch (ClassNotFoundException e) {\n+                    LOGGER.warning(\"Unable to find source class \" + source);\n+                }\n+            }\n+\n+            if (args.length > 0) {\n+                for (SchemaArgument argument : args) {\n+                    // ensure a Map is not used as an input type\n+                    Class<?> originalType = argument.originalType();\n+                    if (originalType != null && originalType.isAssignableFrom(Map.class)) {\n+                        ensureRuntimeException(LOGGER, MAP_MESSAGE);\n+                    }\n+\n+                    if (argument.isArrayReturnType() && argument.arrayLevels() > 1\n+                            && SchemaGeneratorHelper.isPrimitiveArray(argument.originalType())) {\n+                        throw new GraphQlConfigurationException(\"This implementation does not currently support \"\n+                                                              + \"multi-level primitive arrays as arguments. Please use \"\n+                                                              + \"List or Collection of Object equivalent. E.g. \"\n+                                                              + \"In place of method(int [][] value) use \"\n+                                                              + \" method(List<List<Integer>> value)\");\n+                    }\n+\n+                    listArgumentValues.add(generateArgumentValue(schema, argument.argumentType(),\n+                                                                 argument.originalType(),\n+                                                                 argument.originalArrayType(),\n+                                                                 environment.getArgument(argument.argumentName()),\n+                                                                 argument.format()));\n+                }\n+            }\n+\n+            try {\n+                // this is the right place to validate security\n+                return (V)  bean.runGraphQl(clazz, method, listArgumentValues.toArray());\n+            } catch (InvocationTargetException e) {\n+                Throwable targetException = e.getTargetException();\n+                GraphQLException exception = new GraphQLException(e.getTargetException());\n+                if (targetException instanceof org.eclipse.microprofile.graphql.GraphQLException) {\n+                    // if we have partial results we need to return those results and they will\n+                    // get converted correctly to the format required by GraphQL and the ExecutionContext.execute()\n+                    // we ensure this is throw correctly as an error\n+                    ExecutionContext context = environment.getContext();\n+                    context.partialResultsException(exception);\n+                    return (V) ((org.eclipse.microprofile.graphql.GraphQLException) targetException).getPartialResults();\n+                }\n+                throw exception;\n+            }\n+        };\n+    }\n+\n+    /**\n+     * Return a {@link DataFetcher} which converts a {@link Map} to a {@link Collection} of V.\n+     * This assumes that the key for the {@link Map} is contained within the V\n+     *\n+     * @param propertyName name of the property to apply to\n+     * @param <S>          Source of the property\n+     * @param <V>          type of the value\n+     * @return  a {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <S, V> DataFetcher<Collection<V>> newMapValuesDataFetcher(String propertyName) {\n+        return environment -> {\n+            S source = environment.getSource();\n+            if (source == null) {\n+                return null;\n+            }\n+\n+            // retrieve the map and return the collection of V\n+            Map<?, V> map = (Map<?, V>) PropertyDataFetcherHelper\n+                    .getPropertyValue(propertyName, source, environment.getFieldType(), environment);\n+            return map.values();\n+        };\n+    }\n+\n+    /**\n+     * Generate an argument value with the given information. This may be called recursively.\n+     *\n+     * @param schema    {@link Schema} to introspect if needed\n+     * @param argumentType the type of the argument\n+     * @param originalType if this is non null this means the array was a Collection and this is the type in the collection\n+     * @param originalArrayType the original type of the argument as a class\n+     * @param rawValue  raw value of the argument\n+     * @param format argument format\n+     * @return the argument value\n+     * @throws Exception if any errors\n+     */\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\" })\n+    protected static Object generateArgumentValue(Schema schema, String argumentType, Class<?> originalType,\n+                                                  Class<?> originalArrayType,\n+                                                  Object rawValue, String[] format)\n+        throws Exception{\n+        if (rawValue instanceof Map) {\n+            // this means the type is an input type so convert it to the correct class instance\n+            SchemaInputType inputType = schema.getInputTypeByName(argumentType);\n+\n+            // loop through the map and convert each entry\n+            Map<String, Object> map = (Map) rawValue;\n+            Map<String, Object> mapConverted = new HashMap<>();\n+\n+            for (Map.Entry<String, Object> entry : map.entrySet()) {\n+                // retrieve the Field Definition\n+                String fdName = entry.getKey();\n+                Object value  = entry.getValue();\n+                SchemaFieldDefinition fd = inputType.getFieldDefinitionByName(fdName);\n+\n+                // check to see if the Field Definition return type is an input type\n+                SchemaInputType inputFdInputType = schema.getInputTypeByName(fd.returnType());\n+                if (inputFdInputType != null && value instanceof Map) {\n+                    mapConverted.put(fdName, generateArgumentValue(schema, inputFdInputType.name(),\n+                                                                   Class.forName(inputFdInputType.valueClassName()),\n+                                                                   null,\n+                                                                   value, EMPTY_FORMAT));\n+                } else {\n+                    if (fd.isJsonbFormat() || fd.isJsonbProperty()) {\n+                        // don't deserialize using formatting as Jsonb will do this for us\n+                        mapConverted.put(fdName, value);\n+                    } else {\n+                        // check it is not a Map\n+                        Class<?> originalFdlType = fd.originalType();\n+                        if (originalFdlType != null && originalFdlType.isAssignableFrom(Map.class)) {\n+                            ensureRuntimeException(LOGGER, MAP_MESSAGE);\n+                        }\n+                        // retrieve the data fetcher and check if the property name is different as this should be used\n+                        DataFetcher dataFetcher = fd.dataFetcher();\n+                        if (dataFetcher instanceof PropertyDataFetcher) {\n+                            fdName = ((PropertyDataFetcher) dataFetcher).getPropertyName();\n+                        }\n+                        mapConverted.put(fdName, generateArgumentValue(schema, fd.returnType(), fd.originalType(),\n+                                                                       fd.originalArrayType(), value, fd.format()));\n+                    }\n+                }\n+            }\n+\n+            return JsonUtils.convertFromJson(JsonUtils.convertMapToJson(mapConverted), originalType);\n+\n+        } else if (rawValue instanceof Collection) {\n+            SchemaInputType inputType = schema.getInputTypeByName(argumentType);\n+\n+            Object colResults = null;\n+            boolean isArray = originalType.isArray();\n+            try {\n+                if (originalType.equals(List.class) || isArray) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 256}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU3NTIxMA==", "bodyText": "Yes the original type is specifically checked for List Set and Collection and we create the relevant type.\ne.g. for List -> ArrayList(), and Collection or Set we create a TreeSet.\nAny other type will fall through to else. e.g. LinkedList HasSet, etc and then we get the no-args declared constructor and instantiate this, therefore getting our requires class.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534575210", "createdAt": "2020-12-03T00:29:01Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/DataFetcherUtils.java", "diffHunk": "@@ -0,0 +1,596 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.NumberFormat;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZonedDateTime;\n+import java.time.format.DateTimeFormatter;\n+import java.time.temporal.TemporalAccessor;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.logging.Logger;\n+\n+import javax.enterprise.inject.spi.CDI;\n+\n+import io.helidon.graphql.server.ExecutionContext;\n+\n+import graphql.GraphQLException;\n+import graphql.schema.DataFetcher;\n+import graphql.schema.DataFetchingEnvironment;\n+import graphql.schema.PropertyDataFetcher;\n+import graphql.schema.PropertyDataFetcherHelper;\n+\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatDate;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.formatNumber;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectDateFormatter;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getCorrectNumberFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.isFormatEmpty;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ID;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.ensureRuntimeException;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isDateTimeClass;\n+import static io.helidon.microprofile.graphql.server.SchemaGeneratorHelper.isPrimitiveArray;\n+\n+/**\n+ * Utilities for working with {@link DataFetcher}s.\n+ */\n+class DataFetcherUtils {\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(DataFetcherUtils.class.getName());\n+\n+    /**\n+     * Empty format.\n+     */\n+    private static final String[] EMPTY_FORMAT = new String[] {null, null };\n+\n+    /**\n+     * Map message.\n+     */\n+    private static final String MAP_MESSAGE = \"This implementation does not support using a Map \"\n+            + \"as input to a query or mutation\";\n+\n+    /**\n+     * Private constructor for utilities class.\n+     */\n+    private DataFetcherUtils() {\n+    }\n+\n+    /**\n+     * Create a new {@link DataFetcher} for a {@link Class} and {@link Method} to be executed.\n+     *\n+     * @param clazz  {@link Class} to call\n+     * @param method {@link Method} to call\n+     * @param source defines the source for a @Source annotation - may be null\n+     * @param args   optional {@link SchemaArgument}s\n+     * @param schema {@link Schema} that created this {@link DataFetcher}\n+     * @param <V>    value type\n+     * @return a new {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <V> DataFetcher<V> newMethodDataFetcher(Schema schema, Class<?> clazz, Method method,\n+                                                          String source, SchemaArgument... args) {\n+\n+        // this is an application scoped bean\n+        GraphQlBean bean = CDI.current().select(GraphQlBean.class).get();\n+\n+        return environment -> {\n+            ArrayList<Object> listArgumentValues = new ArrayList<>();\n+            // only one @Source annotation should be present and it should be the first argument\n+            if (source != null) {\n+                Class<?> sourceClazz;\n+                try {\n+                    sourceClazz = Class.forName(source);\n+                    listArgumentValues.add(sourceClazz.cast(environment.getSource()));\n+                } catch (ClassNotFoundException e) {\n+                    LOGGER.warning(\"Unable to find source class \" + source);\n+                }\n+            }\n+\n+            if (args.length > 0) {\n+                for (SchemaArgument argument : args) {\n+                    // ensure a Map is not used as an input type\n+                    Class<?> originalType = argument.originalType();\n+                    if (originalType != null && originalType.isAssignableFrom(Map.class)) {\n+                        ensureRuntimeException(LOGGER, MAP_MESSAGE);\n+                    }\n+\n+                    if (argument.isArrayReturnType() && argument.arrayLevels() > 1\n+                            && SchemaGeneratorHelper.isPrimitiveArray(argument.originalType())) {\n+                        throw new GraphQlConfigurationException(\"This implementation does not currently support \"\n+                                                              + \"multi-level primitive arrays as arguments. Please use \"\n+                                                              + \"List or Collection of Object equivalent. E.g. \"\n+                                                              + \"In place of method(int [][] value) use \"\n+                                                              + \" method(List<List<Integer>> value)\");\n+                    }\n+\n+                    listArgumentValues.add(generateArgumentValue(schema, argument.argumentType(),\n+                                                                 argument.originalType(),\n+                                                                 argument.originalArrayType(),\n+                                                                 environment.getArgument(argument.argumentName()),\n+                                                                 argument.format()));\n+                }\n+            }\n+\n+            try {\n+                // this is the right place to validate security\n+                return (V)  bean.runGraphQl(clazz, method, listArgumentValues.toArray());\n+            } catch (InvocationTargetException e) {\n+                Throwable targetException = e.getTargetException();\n+                GraphQLException exception = new GraphQLException(e.getTargetException());\n+                if (targetException instanceof org.eclipse.microprofile.graphql.GraphQLException) {\n+                    // if we have partial results we need to return those results and they will\n+                    // get converted correctly to the format required by GraphQL and the ExecutionContext.execute()\n+                    // we ensure this is throw correctly as an error\n+                    ExecutionContext context = environment.getContext();\n+                    context.partialResultsException(exception);\n+                    return (V) ((org.eclipse.microprofile.graphql.GraphQLException) targetException).getPartialResults();\n+                }\n+                throw exception;\n+            }\n+        };\n+    }\n+\n+    /**\n+     * Return a {@link DataFetcher} which converts a {@link Map} to a {@link Collection} of V.\n+     * This assumes that the key for the {@link Map} is contained within the V\n+     *\n+     * @param propertyName name of the property to apply to\n+     * @param <S>          Source of the property\n+     * @param <V>          type of the value\n+     * @return  a {@link DataFetcher}\n+     */\n+    @SuppressWarnings(\"unchecked\")\n+    static <S, V> DataFetcher<Collection<V>> newMapValuesDataFetcher(String propertyName) {\n+        return environment -> {\n+            S source = environment.getSource();\n+            if (source == null) {\n+                return null;\n+            }\n+\n+            // retrieve the map and return the collection of V\n+            Map<?, V> map = (Map<?, V>) PropertyDataFetcherHelper\n+                    .getPropertyValue(propertyName, source, environment.getFieldType(), environment);\n+            return map.values();\n+        };\n+    }\n+\n+    /**\n+     * Generate an argument value with the given information. This may be called recursively.\n+     *\n+     * @param schema    {@link Schema} to introspect if needed\n+     * @param argumentType the type of the argument\n+     * @param originalType if this is non null this means the array was a Collection and this is the type in the collection\n+     * @param originalArrayType the original type of the argument as a class\n+     * @param rawValue  raw value of the argument\n+     * @param format argument format\n+     * @return the argument value\n+     * @throws Exception if any errors\n+     */\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\" })\n+    protected static Object generateArgumentValue(Schema schema, String argumentType, Class<?> originalType,\n+                                                  Class<?> originalArrayType,\n+                                                  Object rawValue, String[] format)\n+        throws Exception{\n+        if (rawValue instanceof Map) {\n+            // this means the type is an input type so convert it to the correct class instance\n+            SchemaInputType inputType = schema.getInputTypeByName(argumentType);\n+\n+            // loop through the map and convert each entry\n+            Map<String, Object> map = (Map) rawValue;\n+            Map<String, Object> mapConverted = new HashMap<>();\n+\n+            for (Map.Entry<String, Object> entry : map.entrySet()) {\n+                // retrieve the Field Definition\n+                String fdName = entry.getKey();\n+                Object value  = entry.getValue();\n+                SchemaFieldDefinition fd = inputType.getFieldDefinitionByName(fdName);\n+\n+                // check to see if the Field Definition return type is an input type\n+                SchemaInputType inputFdInputType = schema.getInputTypeByName(fd.returnType());\n+                if (inputFdInputType != null && value instanceof Map) {\n+                    mapConverted.put(fdName, generateArgumentValue(schema, inputFdInputType.name(),\n+                                                                   Class.forName(inputFdInputType.valueClassName()),\n+                                                                   null,\n+                                                                   value, EMPTY_FORMAT));\n+                } else {\n+                    if (fd.isJsonbFormat() || fd.isJsonbProperty()) {\n+                        // don't deserialize using formatting as Jsonb will do this for us\n+                        mapConverted.put(fdName, value);\n+                    } else {\n+                        // check it is not a Map\n+                        Class<?> originalFdlType = fd.originalType();\n+                        if (originalFdlType != null && originalFdlType.isAssignableFrom(Map.class)) {\n+                            ensureRuntimeException(LOGGER, MAP_MESSAGE);\n+                        }\n+                        // retrieve the data fetcher and check if the property name is different as this should be used\n+                        DataFetcher dataFetcher = fd.dataFetcher();\n+                        if (dataFetcher instanceof PropertyDataFetcher) {\n+                            fdName = ((PropertyDataFetcher) dataFetcher).getPropertyName();\n+                        }\n+                        mapConverted.put(fdName, generateArgumentValue(schema, fd.returnType(), fd.originalType(),\n+                                                                       fd.originalArrayType(), value, fd.format()));\n+                    }\n+                }\n+            }\n+\n+            return JsonUtils.convertFromJson(JsonUtils.convertMapToJson(mapConverted), originalType);\n+\n+        } else if (rawValue instanceof Collection) {\n+            SchemaInputType inputType = schema.getInputTypeByName(argumentType);\n+\n+            Object colResults = null;\n+            boolean isArray = originalType.isArray();\n+            try {\n+                if (originalType.equals(List.class) || isArray) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI0ODE2MQ=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 256}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDM4MTM4OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxNzoyODo1N1rOHyFwRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNTowNDozM1rOH-gyPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI4NTEyNw==", "bodyText": "We've just added the class to the set and we add it again if it's an interface?\nIs this really what we want to do here?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522285127", "createdAt": "2020-11-12T17:28:57Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzMTQ2Nw==", "bodyText": "It is a different collection - one is candidateApis the other collectedApis", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r535031467", "createdAt": "2020-12-03T09:55:19Z", "author": {"login": "tomas-langer"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI4NTEyNw=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMxMDkxMA==", "bodyText": "My mistake. Different sets, as Tomas pointed out in separate DM.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r535310910", "createdAt": "2020-12-03T15:04:33Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjI4NTEyNw=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDUyMzI2OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODowMjoxN1rOHyHIbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNTowNjoyNFrOH-g4OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwNzY5Mg==", "bodyText": "I'm not positive, but maybe look into whether observing the Helidon event RuntimeStart instead is what we want to trigger this method.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522307692", "createdAt": "2020-11-12T18:02:17Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {\n+            collectedApis.add(javaClass);\n+        }\n+    }\n+\n+    void collectApis(@Observes @WithAnnotations({Type.class, Input.class,\n+                                                        Interface.class}) ProcessAnnotatedType<?> processAnnotatedType) {\n+        // these are directly added\n+        this.collectedApis.add(processAnnotatedType.getAnnotatedType().getJavaClass());\n+    }\n+\n+    void collectNonVetoed(@Observes ProcessManagedBean<?> event) {\n+        AnnotatedType<?> type = event.getAnnotatedBeanClass();\n+        Class<?> clazz = type.getJavaClass();\n+\n+        if (candidateApis.remove(clazz)) {\n+            collectedApis.add(clazz);\n+        }\n+    }\n+\n+    void addGraphQlBeans(@Observes BeforeBeanDiscovery event) {\n+        event.addAnnotatedType(GraphQlBean.class, GraphQlBean.class.getName())\n+                .add(ApplicationScoped.Literal.INSTANCE);\n+    }\n+\n+    void clearCandidates(@Observes AfterBeanDiscovery event) {\n+        candidateApis.clear();\n+    }\n+\n+    void registerWithWebServer(@Observes @Priority(LIBRARY_BEFORE + 9) @Initialized(ApplicationScoped.class) Object event,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTAzMDc5NA==", "bodyText": "I am not sure why? The runtime start is really for native-image specific handling. In this case, we just want to register with webserver routing.\nSo I think the event is OK.\nDo you think this could be an issue?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r535030794", "createdAt": "2020-12-03T09:54:49Z", "author": {"login": "tomas-langer"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {\n+            collectedApis.add(javaClass);\n+        }\n+    }\n+\n+    void collectApis(@Observes @WithAnnotations({Type.class, Input.class,\n+                                                        Interface.class}) ProcessAnnotatedType<?> processAnnotatedType) {\n+        // these are directly added\n+        this.collectedApis.add(processAnnotatedType.getAnnotatedType().getJavaClass());\n+    }\n+\n+    void collectNonVetoed(@Observes ProcessManagedBean<?> event) {\n+        AnnotatedType<?> type = event.getAnnotatedBeanClass();\n+        Class<?> clazz = type.getJavaClass();\n+\n+        if (candidateApis.remove(clazz)) {\n+            collectedApis.add(clazz);\n+        }\n+    }\n+\n+    void addGraphQlBeans(@Observes BeforeBeanDiscovery event) {\n+        event.addAnnotatedType(GraphQlBean.class, GraphQlBean.class.getName())\n+                .add(ApplicationScoped.Literal.INSTANCE);\n+    }\n+\n+    void clearCandidates(@Observes AfterBeanDiscovery event) {\n+        candidateApis.clear();\n+    }\n+\n+    void registerWithWebServer(@Observes @Priority(LIBRARY_BEFORE + 9) @Initialized(ApplicationScoped.class) Object event,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwNzY5Mg=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTMxMjQ0MQ==", "bodyText": "I just wanted this to be double-checked, which it has been now. Should be OK.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r535312441", "createdAt": "2020-12-03T15:06:24Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/GraphQlCdiExtension.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+\n+import javax.annotation.Priority;\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.context.Initialized;\n+import javax.enterprise.event.Observes;\n+import javax.enterprise.inject.spi.AfterBeanDiscovery;\n+import javax.enterprise.inject.spi.AnnotatedType;\n+import javax.enterprise.inject.spi.BeanManager;\n+import javax.enterprise.inject.spi.BeforeBeanDiscovery;\n+import javax.enterprise.inject.spi.DeploymentException;\n+import javax.enterprise.inject.spi.Extension;\n+import javax.enterprise.inject.spi.ProcessAnnotatedType;\n+import javax.enterprise.inject.spi.ProcessManagedBean;\n+import javax.enterprise.inject.spi.WithAnnotations;\n+\n+import io.helidon.graphql.server.GraphQlSupport;\n+import io.helidon.graphql.server.InvocationHandler;\n+import io.helidon.microprofile.server.ServerCdiExtension;\n+import io.helidon.webserver.Routing;\n+\n+import graphql.schema.GraphQLSchema;\n+import org.eclipse.microprofile.config.Config;\n+import org.eclipse.microprofile.config.ConfigProvider;\n+import org.eclipse.microprofile.graphql.ConfigKey;\n+import org.eclipse.microprofile.graphql.GraphQLApi;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static javax.interceptor.Interceptor.Priority.LIBRARY_BEFORE;\n+\n+/**\n+ * A CDI {@link Extension} to collect the classes that are of interest to Microprofile GraphQL.\n+ */\n+public class GraphQlCdiExtension implements Extension {\n+    private static final Logger LOGGER = Logger.getLogger(GraphQlCdiExtension.class.getName());\n+\n+    /**\n+     * The {@link List} of collected API's.\n+     */\n+    private final Set<Class<?>> candidateApis = new HashSet<>();\n+    private final Set<Class<?>> collectedApis = new HashSet<>();\n+\n+    /**\n+     * Collect the classes that have the following Microprofile GraphQL annotations.\n+     *\n+     * @param processAnnotatedType annotation types to process\n+     */\n+    void collectCandidateApis(@Observes @WithAnnotations(GraphQLApi.class) ProcessAnnotatedType<?> processAnnotatedType) {\n+        Class<?> javaClass = processAnnotatedType.getAnnotatedType().getJavaClass();\n+        this.candidateApis.add(javaClass);\n+        if (javaClass.isInterface()) {\n+            collectedApis.add(javaClass);\n+        }\n+    }\n+\n+    void collectApis(@Observes @WithAnnotations({Type.class, Input.class,\n+                                                        Interface.class}) ProcessAnnotatedType<?> processAnnotatedType) {\n+        // these are directly added\n+        this.collectedApis.add(processAnnotatedType.getAnnotatedType().getJavaClass());\n+    }\n+\n+    void collectNonVetoed(@Observes ProcessManagedBean<?> event) {\n+        AnnotatedType<?> type = event.getAnnotatedBeanClass();\n+        Class<?> clazz = type.getJavaClass();\n+\n+        if (candidateApis.remove(clazz)) {\n+            collectedApis.add(clazz);\n+        }\n+    }\n+\n+    void addGraphQlBeans(@Observes BeforeBeanDiscovery event) {\n+        event.addAnnotatedType(GraphQlBean.class, GraphQlBean.class.getName())\n+                .add(ApplicationScoped.Literal.INSTANCE);\n+    }\n+\n+    void clearCandidates(@Observes AfterBeanDiscovery event) {\n+        candidateApis.clear();\n+    }\n+\n+    void registerWithWebServer(@Observes @Priority(LIBRARY_BEFORE + 9) @Initialized(ApplicationScoped.class) Object event,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwNzY5Mg=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDUzNzA4OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODowNTo0NFrOHyHQ8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxNjo1OToyMFrOH-nBog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwOTg3Mg==", "bodyText": "Do we need to rely directly on the Jandex index(es)? CDI can answer these same questions, and if Jandex indexes are present Weld's CDI implementation will use them. (Maybe use of Jandex is mandated by GraphQL itself; I have no idea.)", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522309872", "createdAt": "2020-11-12T18:05:44Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.reflect.Modifier;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Enumeration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+import org.jboss.jandex.ClassInfo;\n+import org.jboss.jandex.DotName;\n+import org.jboss.jandex.Index;\n+import org.jboss.jandex.IndexReader;\n+\n+/**\n+ * Utilities for working with Jandex indexes.\n+ */\n+class JandexUtils {\n+\n+    private static final Logger LOGGER = Logger.getLogger(JandexUtils.class.getName());\n+\n+    /**\n+     * Default Jandex index file.\n+     */\n+    protected static final String DEFAULT_INDEX_FILE = \"META-INF/jandex.idx\";\n+\n+    /**\n+     * Property to override the default index file. (Normally used for functional tests)\n+     */\n+    public static final String PROP_INDEX_FILE = \"io.helidon.microprofile.graphql.indexfile\";\n+\n+    /**\n+     * The {@link Set} of loaded indexes.\n+     */\n+    private Set<Index> setIndexes = new HashSet<>();\n+\n+    /**\n+     * The file used to load the index.\n+     */\n+    private String indexFile;\n+\n+    /**\n+     * Construct an instance of the utilities class..\n+     */\n+    private JandexUtils() {\n+        indexFile = System.getProperty(PROP_INDEX_FILE, DEFAULT_INDEX_FILE);\n+    }\n+\n+    /**\n+     * Create a new {@link JandexUtils}.\n+     * @return a new {@link JandexUtils}\n+     */\n+    public static JandexUtils create() {\n+         return new JandexUtils();\n+    }\n+\n+    /**\n+     * Load all the index files of the given name.\n+     */\n+    public void loadIndexes() {\n+        try {\n+            List<URL> listUrls = findIndexFiles(indexFile);\n+\n+            // loop through each URL and load the index\n+            for (URL url : listUrls) {\n+                try (InputStream input = url.openStream()) {\n+                    setIndexes.add(new IndexReader(input).read());\n+                } catch (Exception e) {\n+                    LOGGER.warning(\"Unable to load default Jandex index file: \" + url\n+                                           + \" : \" + e.getMessage());\n+                }\n+            }\n+        } catch (IOException ignore) {\n+            // any Exception coming from getResources() or toURL() is ignored and\n+            // the Map of indexes remain empty\n+        }\n+    }\n+\n+    /**\n+     * Return all the Jandex index files with the given name. If the name is absolute then\n+     * return the singl file.\n+     *\n+     * @param indexFileName  index file name\n+     * @return a {@link List} of the index file names\n+     *\n+     * @throws IOException if any error\n+     */\n+    private List<URL> findIndexFiles(String indexFileName) throws IOException {\n+        List<URL> result = new ArrayList<>();\n+        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+        File file = new File(indexFile);\n+        if (file.isAbsolute()) {\n+            result.add(file.toPath().toUri().toURL());\n+            return result;\n+        }\n+\n+        Enumeration<URL> urls = contextClassLoader.getResources(indexFileName);\n+        while (urls.hasMoreElements()) {\n+            result.add(urls.nextElement());\n+        }\n+\n+        return result;\n+    }\n+\n+\n+    /**\n+     * Return a {@link Collection} of {@link Class}es which are implementors of a given class/interface.\n+     *\n+     * @param clazz           {@link Class} to check for implementors\n+     * @param includeAbstract indicates if abstract classes should be included\n+     * @return a {@link Collection} of {@link Class}es\n+     */\n+    public Collection<Class<?>> getKnownImplementors(String clazz, boolean includeAbstract) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1NzI5MA==", "bodyText": "There is one capability that we need Jandex for and that is to find the annotation in the following situation.\npublic method(List<List<@nonnull String>> param).\nI don't believe CDI can answer this, but please provide and example of how it can if i'm no correct. @tjquinno", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534557290", "createdAt": "2020-12-02T23:40:44Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.reflect.Modifier;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Enumeration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+import org.jboss.jandex.ClassInfo;\n+import org.jboss.jandex.DotName;\n+import org.jboss.jandex.Index;\n+import org.jboss.jandex.IndexReader;\n+\n+/**\n+ * Utilities for working with Jandex indexes.\n+ */\n+class JandexUtils {\n+\n+    private static final Logger LOGGER = Logger.getLogger(JandexUtils.class.getName());\n+\n+    /**\n+     * Default Jandex index file.\n+     */\n+    protected static final String DEFAULT_INDEX_FILE = \"META-INF/jandex.idx\";\n+\n+    /**\n+     * Property to override the default index file. (Normally used for functional tests)\n+     */\n+    public static final String PROP_INDEX_FILE = \"io.helidon.microprofile.graphql.indexfile\";\n+\n+    /**\n+     * The {@link Set} of loaded indexes.\n+     */\n+    private Set<Index> setIndexes = new HashSet<>();\n+\n+    /**\n+     * The file used to load the index.\n+     */\n+    private String indexFile;\n+\n+    /**\n+     * Construct an instance of the utilities class..\n+     */\n+    private JandexUtils() {\n+        indexFile = System.getProperty(PROP_INDEX_FILE, DEFAULT_INDEX_FILE);\n+    }\n+\n+    /**\n+     * Create a new {@link JandexUtils}.\n+     * @return a new {@link JandexUtils}\n+     */\n+    public static JandexUtils create() {\n+         return new JandexUtils();\n+    }\n+\n+    /**\n+     * Load all the index files of the given name.\n+     */\n+    public void loadIndexes() {\n+        try {\n+            List<URL> listUrls = findIndexFiles(indexFile);\n+\n+            // loop through each URL and load the index\n+            for (URL url : listUrls) {\n+                try (InputStream input = url.openStream()) {\n+                    setIndexes.add(new IndexReader(input).read());\n+                } catch (Exception e) {\n+                    LOGGER.warning(\"Unable to load default Jandex index file: \" + url\n+                                           + \" : \" + e.getMessage());\n+                }\n+            }\n+        } catch (IOException ignore) {\n+            // any Exception coming from getResources() or toURL() is ignored and\n+            // the Map of indexes remain empty\n+        }\n+    }\n+\n+    /**\n+     * Return all the Jandex index files with the given name. If the name is absolute then\n+     * return the singl file.\n+     *\n+     * @param indexFileName  index file name\n+     * @return a {@link List} of the index file names\n+     *\n+     * @throws IOException if any error\n+     */\n+    private List<URL> findIndexFiles(String indexFileName) throws IOException {\n+        List<URL> result = new ArrayList<>();\n+        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+        File file = new File(indexFile);\n+        if (file.isAbsolute()) {\n+            result.add(file.toPath().toUri().toURL());\n+            return result;\n+        }\n+\n+        Enumeration<URL> urls = contextClassLoader.getResources(indexFileName);\n+        while (urls.hasMoreElements()) {\n+            result.add(urls.nextElement());\n+        }\n+\n+        return result;\n+    }\n+\n+\n+    /**\n+     * Return a {@link Collection} of {@link Class}es which are implementors of a given class/interface.\n+     *\n+     * @param clazz           {@link Class} to check for implementors\n+     * @param includeAbstract indicates if abstract classes should be included\n+     * @return a {@link Collection} of {@link Class}es\n+     */\n+    public Collection<Class<?>> getKnownImplementors(String clazz, boolean includeAbstract) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwOTg3Mg=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDU1ODQ4Nw==", "bodyText": "Actually i mis-read the above comment. Can you provide an example of how CDI can get known implementors?  @tjquinno", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r534558487", "createdAt": "2020-12-02T23:43:52Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.reflect.Modifier;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Enumeration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+import org.jboss.jandex.ClassInfo;\n+import org.jboss.jandex.DotName;\n+import org.jboss.jandex.Index;\n+import org.jboss.jandex.IndexReader;\n+\n+/**\n+ * Utilities for working with Jandex indexes.\n+ */\n+class JandexUtils {\n+\n+    private static final Logger LOGGER = Logger.getLogger(JandexUtils.class.getName());\n+\n+    /**\n+     * Default Jandex index file.\n+     */\n+    protected static final String DEFAULT_INDEX_FILE = \"META-INF/jandex.idx\";\n+\n+    /**\n+     * Property to override the default index file. (Normally used for functional tests)\n+     */\n+    public static final String PROP_INDEX_FILE = \"io.helidon.microprofile.graphql.indexfile\";\n+\n+    /**\n+     * The {@link Set} of loaded indexes.\n+     */\n+    private Set<Index> setIndexes = new HashSet<>();\n+\n+    /**\n+     * The file used to load the index.\n+     */\n+    private String indexFile;\n+\n+    /**\n+     * Construct an instance of the utilities class..\n+     */\n+    private JandexUtils() {\n+        indexFile = System.getProperty(PROP_INDEX_FILE, DEFAULT_INDEX_FILE);\n+    }\n+\n+    /**\n+     * Create a new {@link JandexUtils}.\n+     * @return a new {@link JandexUtils}\n+     */\n+    public static JandexUtils create() {\n+         return new JandexUtils();\n+    }\n+\n+    /**\n+     * Load all the index files of the given name.\n+     */\n+    public void loadIndexes() {\n+        try {\n+            List<URL> listUrls = findIndexFiles(indexFile);\n+\n+            // loop through each URL and load the index\n+            for (URL url : listUrls) {\n+                try (InputStream input = url.openStream()) {\n+                    setIndexes.add(new IndexReader(input).read());\n+                } catch (Exception e) {\n+                    LOGGER.warning(\"Unable to load default Jandex index file: \" + url\n+                                           + \" : \" + e.getMessage());\n+                }\n+            }\n+        } catch (IOException ignore) {\n+            // any Exception coming from getResources() or toURL() is ignored and\n+            // the Map of indexes remain empty\n+        }\n+    }\n+\n+    /**\n+     * Return all the Jandex index files with the given name. If the name is absolute then\n+     * return the singl file.\n+     *\n+     * @param indexFileName  index file name\n+     * @return a {@link List} of the index file names\n+     *\n+     * @throws IOException if any error\n+     */\n+    private List<URL> findIndexFiles(String indexFileName) throws IOException {\n+        List<URL> result = new ArrayList<>();\n+        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+        File file = new File(indexFile);\n+        if (file.isAbsolute()) {\n+            result.add(file.toPath().toUri().toURL());\n+            return result;\n+        }\n+\n+        Enumeration<URL> urls = contextClassLoader.getResources(indexFileName);\n+        while (urls.hasMoreElements()) {\n+            result.add(urls.nextElement());\n+        }\n+\n+        return result;\n+    }\n+\n+\n+    /**\n+     * Return a {@link Collection} of {@link Class}es which are implementors of a given class/interface.\n+     *\n+     * @param clazz           {@link Class} to check for implementors\n+     * @param includeAbstract indicates if abstract classes should be included\n+     * @return a {@link Collection} of {@link Class}es\n+     */\n+    public Collection<Class<?>> getKnownImplementors(String clazz, boolean includeAbstract) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwOTg3Mg=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQxMzE1NA==", "bodyText": "After a DM with Laird, it seems that this is not so easy using CDI-only APIs. So it's probably best to keep the code as-is.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r535413154", "createdAt": "2020-12-03T16:59:20Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/JandexUtils.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.reflect.Modifier;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Enumeration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.logging.Logger;\n+\n+import org.jboss.jandex.ClassInfo;\n+import org.jboss.jandex.DotName;\n+import org.jboss.jandex.Index;\n+import org.jboss.jandex.IndexReader;\n+\n+/**\n+ * Utilities for working with Jandex indexes.\n+ */\n+class JandexUtils {\n+\n+    private static final Logger LOGGER = Logger.getLogger(JandexUtils.class.getName());\n+\n+    /**\n+     * Default Jandex index file.\n+     */\n+    protected static final String DEFAULT_INDEX_FILE = \"META-INF/jandex.idx\";\n+\n+    /**\n+     * Property to override the default index file. (Normally used for functional tests)\n+     */\n+    public static final String PROP_INDEX_FILE = \"io.helidon.microprofile.graphql.indexfile\";\n+\n+    /**\n+     * The {@link Set} of loaded indexes.\n+     */\n+    private Set<Index> setIndexes = new HashSet<>();\n+\n+    /**\n+     * The file used to load the index.\n+     */\n+    private String indexFile;\n+\n+    /**\n+     * Construct an instance of the utilities class..\n+     */\n+    private JandexUtils() {\n+        indexFile = System.getProperty(PROP_INDEX_FILE, DEFAULT_INDEX_FILE);\n+    }\n+\n+    /**\n+     * Create a new {@link JandexUtils}.\n+     * @return a new {@link JandexUtils}\n+     */\n+    public static JandexUtils create() {\n+         return new JandexUtils();\n+    }\n+\n+    /**\n+     * Load all the index files of the given name.\n+     */\n+    public void loadIndexes() {\n+        try {\n+            List<URL> listUrls = findIndexFiles(indexFile);\n+\n+            // loop through each URL and load the index\n+            for (URL url : listUrls) {\n+                try (InputStream input = url.openStream()) {\n+                    setIndexes.add(new IndexReader(input).read());\n+                } catch (Exception e) {\n+                    LOGGER.warning(\"Unable to load default Jandex index file: \" + url\n+                                           + \" : \" + e.getMessage());\n+                }\n+            }\n+        } catch (IOException ignore) {\n+            // any Exception coming from getResources() or toURL() is ignored and\n+            // the Map of indexes remain empty\n+        }\n+    }\n+\n+    /**\n+     * Return all the Jandex index files with the given name. If the name is absolute then\n+     * return the singl file.\n+     *\n+     * @param indexFileName  index file name\n+     * @return a {@link List} of the index file names\n+     *\n+     * @throws IOException if any error\n+     */\n+    private List<URL> findIndexFiles(String indexFileName) throws IOException {\n+        List<URL> result = new ArrayList<>();\n+        ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n+        File file = new File(indexFile);\n+        if (file.isAbsolute()) {\n+            result.add(file.toPath().toUri().toURL());\n+            return result;\n+        }\n+\n+        Enumeration<URL> urls = contextClassLoader.getResources(indexFileName);\n+        while (urls.hasMoreElements()) {\n+            result.add(urls.nextElement());\n+        }\n+\n+        return result;\n+    }\n+\n+\n+    /**\n+     * Return a {@link Collection} of {@link Class}es which are implementors of a given class/interface.\n+     *\n+     * @param clazz           {@link Class} to check for implementors\n+     * @param includeAbstract indicates if abstract classes should be included\n+     * @return a {@link Collection} of {@link Class}es\n+     */\n+    public Collection<Class<?>> getKnownImplementors(String clazz, boolean includeAbstract) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMwOTg3Mg=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDYzOTk1OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaArgument.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMjowNlrOHyIQ3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMjowNlrOHyIQ3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMyNjIzOA==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522326238", "createdAt": "2020-11-12T18:32:06Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaArgument.java", "diffHunk": "@@ -0,0 +1,529 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDY0MjI3OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaDirective.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMjozNFrOHyISOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMjozNFrOHyISOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMyNjU4NA==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522326584", "createdAt": "2020-11-12T18:32:34Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaDirective.java", "diffHunk": "@@ -0,0 +1,219 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDY0NjEyOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaEnum.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMzoyM1rOHyIUeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozMzoyM1rOHyIUeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMyNzE2MQ==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522327161", "createdAt": "2020-11-12T18:33:23Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaEnum.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDY0OTMwOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaFieldDefinition.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozNDoxM1rOHyIWfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozNDoxM1rOHyIWfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMyNzY3Nw==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522327677", "createdAt": "2020-11-12T18:34:13Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaFieldDefinition.java", "diffHunk": "@@ -0,0 +1,635 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDY1OTY4OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGenerator.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozNjo1MlrOHyIckg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODozNjo1MlrOHyIckg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMyOTIzNA==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522329234", "createdAt": "2020-11-12T18:36:52Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGenerator.java", "diffHunk": "@@ -0,0 +1,1780 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDY4Njg5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0Mzo1NFrOHyItUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0Mzo1NFrOHyItUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMzMzUyMw==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522333523", "createdAt": "2020-11-12T18:43:54Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "diffHunk": "@@ -0,0 +1,1966 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDcwMzkxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0ODoyMFrOHyI3zQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0ODoyMFrOHyI3zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMzNjIwNQ==", "bodyText": "How about PRIMITIVE_ARRAY_MAP.containsValue(clazz)?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522336205", "createdAt": "2020-11-12T18:48:20Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "diffHunk": "@@ -0,0 +1,1966 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.PrintWriter;\n+import java.io.StringWriter;\n+import java.lang.annotation.Annotation;\n+import java.lang.reflect.AnnotatedElement;\n+import java.lang.reflect.AnnotatedParameterizedType;\n+import java.lang.reflect.AnnotatedType;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.Parameter;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.logging.Logger;\n+\n+import javax.json.bind.annotation.JsonbProperty;\n+import javax.json.bind.annotation.JsonbTransient;\n+\n+import graphql.scalars.ExtendedScalars;\n+import org.eclipse.microprofile.graphql.DefaultValue;\n+import org.eclipse.microprofile.graphql.Description;\n+import org.eclipse.microprofile.graphql.Enum;\n+import org.eclipse.microprofile.graphql.Id;\n+import org.eclipse.microprofile.graphql.Ignore;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Mutation;\n+import org.eclipse.microprofile.graphql.Name;\n+import org.eclipse.microprofile.graphql.Query;\n+import org.eclipse.microprofile.graphql.Source;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_BIGDECIMAL_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_BIGINTEGER_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_FLOAT_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_INT_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_OFFSET_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_ZONED_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.ElementGenerator.OPEN_SQUARE;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getDefaultDateTimeFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.GET;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.IS;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.SET;\n+\n+/**\n+ * Helper class for {@link SchemaGenerator}.\n+ */\n+final class SchemaGeneratorHelper {\n+\n+    /**\n+     * {@link OffsetTime} class name.\n+     */\n+    protected static final String OFFSET_TIME_CLASS = OffsetTime.class.getName();\n+\n+    /**\n+     * {@link LocalTime} class name.\n+     */\n+    protected static final String LOCAL_TIME_CLASS = LocalTime.class.getName();\n+\n+    /**\n+     * {@link OffsetDateTime} class name.\n+     */\n+    protected static final String OFFSET_DATE_TIME_CLASS = OffsetDateTime.class.getName();\n+\n+    /**\n+     * {@link ZonedDateTime} class name.\n+     */\n+    protected static final String ZONED_DATE_TIME_CLASS = ZonedDateTime.class.getName();\n+\n+    /**\n+     * {@link LocalDateTime} class name.\n+     */\n+    protected static final String LOCAL_DATE_TIME_CLASS = LocalDateTime.class.getName();\n+\n+    /**\n+     * {@link LocalDate} class name.\n+     */\n+    protected static final String LOCAL_DATE_CLASS = LocalDate.class.getName();\n+\n+    /**\n+     * {@link BigDecimal} class name.\n+     */\n+    protected static final String BIG_DECIMAL_CLASS = BigDecimal.class.getName();\n+\n+    /**\n+     * {@link Long} class name.\n+     */\n+    protected static final String LONG_CLASS = Long.class.getName();\n+\n+    /**\n+     * Class name for long primitive.\n+     */\n+    protected static final String LONG_PRIMITIVE_CLASS = long.class.getName();\n+\n+    /**\n+     * {@link Float} class name.\n+     */\n+    protected static final String FLOAT_CLASS = Float.class.getName();\n+\n+    /**\n+     * Class name for float primitive.\n+     */\n+    protected static final String FLOAT_PRIMITIVE_CLASS = float.class.getName();\n+\n+    /**\n+     * {@link Double} class name.\n+     */\n+    protected static final String DOUBLE_CLASS = Double.class.getName();\n+\n+    /**\n+     * Class name for double primitive.\n+     */\n+    protected static final String DOUBLE_PRIMITIVE_CLASS = double.class.getName();\n+\n+    /**\n+     * Class name for {@link BigInteger}.\n+     */\n+    protected static final String BIG_INTEGER_CLASS = BigInteger.class.getName();\n+\n+    /**\n+     * Class name for {@link Integer}.\n+     */\n+    protected static final String INTEGER_CLASS = Integer.class.getName();\n+\n+    /**\n+     * Class name for int.\n+     */\n+    protected static final String INTEGER_PRIMITIVE_CLASS = int.class.getName();\n+\n+    /**\n+     * Class name for {@link Byte}.\n+     */\n+    protected static final String BYTE_CLASS = Byte.class.getName();\n+\n+    /**\n+     * Class name for byte.\n+     */\n+    protected static final String BYTE_PRIMITIVE_CLASS = byte.class.getName();\n+\n+    /**\n+     * Class name for {@link Short}.\n+     */\n+    protected static final String SHORT_CLASS = Short.class.getName();\n+\n+    /**\n+     * Class name for short.\n+     */\n+    protected static final String SHORT_PRIMITIVE_CLASS = short.class.getName();\n+\n+    /**\n+     * Formatted Date scalar.\n+     */\n+    public static final String FORMATTED_DATE_SCALAR = \"FormattedDate\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_DATETIME_SCALAR = \"FormattedDateTime\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_OFFSET_DATETIME_SCALAR = \"FormattedOffsetDateTime\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_ZONED_DATETIME_SCALAR = \"FormattedZonedDateTime\";\n+\n+    /**\n+     * Formatted Time Scalar.\n+     */\n+    public static final String FORMATTED_TIME_SCALAR = \"FormattedTime\";\n+\n+    /**\n+     * Formatted Int.\n+     */\n+\n+    /**\n+     * Date scalar (with default formatting).\n+     */\n+    public static final String DATE_SCALAR = \"Date\";\n+\n+    /**\n+     * DateTime scalar (with default formatting).\n+     */\n+    public static final String DATETIME_SCALAR = \"DateTime\";\n+\n+    /**\n+     * Time Scalar (with default formatting).\n+     */\n+    public static final String TIME_SCALAR = \"Time\";\n+\n+    /**\n+     * Defines a {@link BigDecimal} type.\n+     */\n+    static final String BIG_DECIMAL = \"BigDecimal\";\n+\n+    /**\n+     * Defines a {@link BigInteger} type.\n+     */\n+    static final String BIG_INTEGER = \"BigInteger\";\n+\n+    /**\n+     * Value that indicates that default {@link java.util.Locale}.\n+     */\n+    static final String DEFAULT_LOCALE = \"##default\";\n+\n+    /**\n+     * GraphQL Int.\n+     */\n+    public static final String INT = \"Int\";\n+\n+    /**\n+     * GraphQL Float.\n+     */\n+    public static final String FLOAT = \"Float\";\n+\n+    /**\n+     * GraphQL String.\n+     */\n+    public static final String STRING = \"String\";\n+\n+    /**\n+     * GraphQL ID.\n+     */\n+    public static final String ID = \"ID\";\n+\n+    /**\n+     * GraphQL Boolean.\n+     */\n+    public static final String BOOLEAN = \"Boolean\";\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(SchemaGeneratorHelper.class.getName());\n+\n+    /**\n+     * Indicates empty annotations.\n+     */\n+    private static final Annotation[] EMPTY_ANNOTATIONS = new Annotation[0];\n+\n+    /**\n+     * List of supported scalars keyed by the full class name.\n+     */\n+    static final Map<String, SchemaScalar> SUPPORTED_SCALARS = new HashMap<>() {{\n+        // Object Scalar\n+        put(Object.class.getName(), new SchemaScalar(\"Object\", Object.class.getName(), ExtendedScalars.Object, null));\n+\n+        // Time scalars\n+        put(OffsetTime.class.getName(),\n+            new SchemaScalar(FORMATTED_TIME_SCALAR, OFFSET_TIME_CLASS, FORMATTED_CUSTOM_TIME_SCALAR, \"HH[:mm][:ss]Z\"));\n+        put(LocalTime.class.getName(),\n+            new SchemaScalar(FORMATTED_TIME_SCALAR, LOCAL_TIME_CLASS, FORMATTED_CUSTOM_TIME_SCALAR, \"HH[:mm][:ss]\"));\n+\n+        // DateTime scalars\n+        put(OFFSET_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_OFFSET_DATETIME_SCALAR, OFFSET_DATE_TIME_CLASS, CUSTOM_OFFSET_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]Z\"));\n+        put(ZONED_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_ZONED_DATETIME_SCALAR, ZONED_DATE_TIME_CLASS, CUSTOM_ZONED_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]Z'['VV']'\"));\n+        put(LOCAL_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_DATETIME_SCALAR, LOCAL_DATE_TIME_CLASS, FORMATTED_CUSTOM_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]\"));\n+\n+        // Date scalar\n+        put(LOCAL_DATE_CLASS, new SchemaScalar(FORMATTED_DATE_SCALAR, LOCAL_DATE_CLASS, FORMATTED_CUSTOM_DATE_SCALAR,\n+                                               \"yyyy-MM-dd\"));\n+\n+        // BigDecimal scalars\n+        put(BIG_DECIMAL_CLASS, new SchemaScalar(BIG_DECIMAL, BIG_DECIMAL_CLASS, CUSTOM_BIGDECIMAL_SCALAR, null));\n+\n+        // BigInteger scalars\n+        put(BIG_INTEGER_CLASS, new SchemaScalar(BIG_INTEGER, BIG_INTEGER_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+        put(LONG_PRIMITIVE_CLASS, new SchemaScalar(BIG_INTEGER, LONG_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+        put(LONG_CLASS, new SchemaScalar(BIG_INTEGER, LONG_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+\n+        // Int scalars\n+        put(INTEGER_CLASS, new SchemaScalar(INT, INTEGER_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(INTEGER_PRIMITIVE_CLASS, new SchemaScalar(INT, INTEGER_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(BYTE_CLASS, new SchemaScalar(INT, BYTE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(BYTE_PRIMITIVE_CLASS, new SchemaScalar(INT, BYTE_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(SHORT_CLASS, new SchemaScalar(INT, SHORT_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(SHORT_PRIMITIVE_CLASS, new SchemaScalar(INT, SHORT_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+\n+        // Float scalars\n+        put(FLOAT_CLASS, new SchemaScalar(FLOAT, FLOAT_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(FLOAT_PRIMITIVE_CLASS, new SchemaScalar(FLOAT, FLOAT_PRIMITIVE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(DOUBLE_CLASS, new SchemaScalar(FLOAT, DOUBLE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(DOUBLE_PRIMITIVE_CLASS, new SchemaScalar(FLOAT, DOUBLE_PRIMITIVE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+    }};\n+\n+    /**\n+     * List of types that should map to a GraphQL Boolean.\n+     */\n+    static final List<String> BOOLEAN_LIST = new ArrayList<>() {{\n+        add(\"boolean\");\n+        add(\"java.lang.Boolean\");\n+    }};\n+\n+    /**\n+     * List of types that should map to a GraphQL String.\n+     */\n+    static final List<String> STRING_LIST = new ArrayList<>() {{\n+        add(\"java.lang.String\");\n+        add(\"java.lang.Character\");\n+        add(\"char\");\n+    }};\n+\n+    /**\n+     * List of array primitive types and their array mapping. See https://docs.oracle.com/javase/6/docs/api/java/lang/Class\n+     * .html#getName%28%29\n+     */\n+    static final Map<String, String> PRIMITIVE_ARRAY_MAP = new HashMap<>() {{\n+        put(\"[Z\", \"boolean\");\n+        put(\"[B\", \"byte\");\n+        put(\"[C\", \"char\");\n+        put(\"[D\", \"double\");\n+        put(\"[F\", \"float\");\n+        put(\"[I\", \"int\");\n+        put(\"[J\", \"long\");\n+        put(\"[S\", \"short\");\n+    }};\n+\n+    /**\n+     * List of all Java primitives.\n+     */\n+    static final List<String> JAVA_PRIMITIVE_TYPES = new ArrayList<>() {{\n+        add(\"byte\");\n+        add(\"short\");\n+        add(\"int\");\n+        add(\"long\");\n+        add(\"float\");\n+        add(\"double\");\n+        add(\"boolean\");\n+        add(\"char\");\n+    }};\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private SchemaGeneratorHelper() {\n+    }\n+\n+    /**\n+     * Return the simple name from a given class as a String. This takes into account any annotations that may be present.\n+     *\n+     * @param className class name\n+     * @return the simple class name\n+     * @throws ClassNotFoundException if invalid class name\n+     */\n+    protected static String getSimpleName(String className)\n+            throws ClassNotFoundException {\n+        return getSimpleName(className, false);\n+    }\n+\n+    /**\n+     * Return true of the {@link Class} is a primitive or array of primitives.\n+     *\n+     * @param clazz {@link Class} to check\n+     * @return true of the {@link Class} is a primitive or array of primitives.\n+     */\n+    protected static boolean isPrimitive(Class<?> clazz) {\n+        return isPrimitive(clazz.getName());\n+    }\n+\n+    /**\n+     * Return true of the class name is a primitive or array of primitives.\n+     *\n+     * @param clazz class name to check\n+     * @return true if the class name is a primitive or array of primitives.\n+     */\n+    protected static boolean isPrimitive(String clazz) {\n+        return JAVA_PRIMITIVE_TYPES.contains(clazz)\n+                || PRIMITIVE_ARRAY_MAP.values().stream().anyMatch(v -> v.contains(clazz));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 409}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDcwNjg2OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0OTowNVrOHyI5jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo0OTowNVrOHyI5jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMzNjY1Mg==", "bodyText": "Same comment as above: containsValue(clazz)?", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522336652", "createdAt": "2020-11-12T18:49:05Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaGeneratorHelper.java", "diffHunk": "@@ -0,0 +1,1966 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.microprofile.graphql.server;\n+\n+import java.io.PrintWriter;\n+import java.io.StringWriter;\n+import java.lang.annotation.Annotation;\n+import java.lang.reflect.AnnotatedElement;\n+import java.lang.reflect.AnnotatedParameterizedType;\n+import java.lang.reflect.AnnotatedType;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.Parameter;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.OffsetTime;\n+import java.time.ZonedDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.logging.Logger;\n+\n+import javax.json.bind.annotation.JsonbProperty;\n+import javax.json.bind.annotation.JsonbTransient;\n+\n+import graphql.scalars.ExtendedScalars;\n+import org.eclipse.microprofile.graphql.DefaultValue;\n+import org.eclipse.microprofile.graphql.Description;\n+import org.eclipse.microprofile.graphql.Enum;\n+import org.eclipse.microprofile.graphql.Id;\n+import org.eclipse.microprofile.graphql.Ignore;\n+import org.eclipse.microprofile.graphql.Input;\n+import org.eclipse.microprofile.graphql.Interface;\n+import org.eclipse.microprofile.graphql.Mutation;\n+import org.eclipse.microprofile.graphql.Name;\n+import org.eclipse.microprofile.graphql.Query;\n+import org.eclipse.microprofile.graphql.Source;\n+import org.eclipse.microprofile.graphql.Type;\n+\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_BIGDECIMAL_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_BIGINTEGER_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_FLOAT_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_INT_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_OFFSET_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.CUSTOM_ZONED_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_DATE_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_DATE_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.CustomScalars.FORMATTED_CUSTOM_TIME_SCALAR;\n+import static io.helidon.microprofile.graphql.server.ElementGenerator.OPEN_SQUARE;\n+import static io.helidon.microprofile.graphql.server.FormattingHelper.getDefaultDateTimeFormat;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.GET;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.IS;\n+import static io.helidon.microprofile.graphql.server.SchemaGenerator.SET;\n+\n+/**\n+ * Helper class for {@link SchemaGenerator}.\n+ */\n+final class SchemaGeneratorHelper {\n+\n+    /**\n+     * {@link OffsetTime} class name.\n+     */\n+    protected static final String OFFSET_TIME_CLASS = OffsetTime.class.getName();\n+\n+    /**\n+     * {@link LocalTime} class name.\n+     */\n+    protected static final String LOCAL_TIME_CLASS = LocalTime.class.getName();\n+\n+    /**\n+     * {@link OffsetDateTime} class name.\n+     */\n+    protected static final String OFFSET_DATE_TIME_CLASS = OffsetDateTime.class.getName();\n+\n+    /**\n+     * {@link ZonedDateTime} class name.\n+     */\n+    protected static final String ZONED_DATE_TIME_CLASS = ZonedDateTime.class.getName();\n+\n+    /**\n+     * {@link LocalDateTime} class name.\n+     */\n+    protected static final String LOCAL_DATE_TIME_CLASS = LocalDateTime.class.getName();\n+\n+    /**\n+     * {@link LocalDate} class name.\n+     */\n+    protected static final String LOCAL_DATE_CLASS = LocalDate.class.getName();\n+\n+    /**\n+     * {@link BigDecimal} class name.\n+     */\n+    protected static final String BIG_DECIMAL_CLASS = BigDecimal.class.getName();\n+\n+    /**\n+     * {@link Long} class name.\n+     */\n+    protected static final String LONG_CLASS = Long.class.getName();\n+\n+    /**\n+     * Class name for long primitive.\n+     */\n+    protected static final String LONG_PRIMITIVE_CLASS = long.class.getName();\n+\n+    /**\n+     * {@link Float} class name.\n+     */\n+    protected static final String FLOAT_CLASS = Float.class.getName();\n+\n+    /**\n+     * Class name for float primitive.\n+     */\n+    protected static final String FLOAT_PRIMITIVE_CLASS = float.class.getName();\n+\n+    /**\n+     * {@link Double} class name.\n+     */\n+    protected static final String DOUBLE_CLASS = Double.class.getName();\n+\n+    /**\n+     * Class name for double primitive.\n+     */\n+    protected static final String DOUBLE_PRIMITIVE_CLASS = double.class.getName();\n+\n+    /**\n+     * Class name for {@link BigInteger}.\n+     */\n+    protected static final String BIG_INTEGER_CLASS = BigInteger.class.getName();\n+\n+    /**\n+     * Class name for {@link Integer}.\n+     */\n+    protected static final String INTEGER_CLASS = Integer.class.getName();\n+\n+    /**\n+     * Class name for int.\n+     */\n+    protected static final String INTEGER_PRIMITIVE_CLASS = int.class.getName();\n+\n+    /**\n+     * Class name for {@link Byte}.\n+     */\n+    protected static final String BYTE_CLASS = Byte.class.getName();\n+\n+    /**\n+     * Class name for byte.\n+     */\n+    protected static final String BYTE_PRIMITIVE_CLASS = byte.class.getName();\n+\n+    /**\n+     * Class name for {@link Short}.\n+     */\n+    protected static final String SHORT_CLASS = Short.class.getName();\n+\n+    /**\n+     * Class name for short.\n+     */\n+    protected static final String SHORT_PRIMITIVE_CLASS = short.class.getName();\n+\n+    /**\n+     * Formatted Date scalar.\n+     */\n+    public static final String FORMATTED_DATE_SCALAR = \"FormattedDate\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_DATETIME_SCALAR = \"FormattedDateTime\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_OFFSET_DATETIME_SCALAR = \"FormattedOffsetDateTime\";\n+\n+    /**\n+     * Formatted DateTime scalar.\n+     */\n+    public static final String FORMATTED_ZONED_DATETIME_SCALAR = \"FormattedZonedDateTime\";\n+\n+    /**\n+     * Formatted Time Scalar.\n+     */\n+    public static final String FORMATTED_TIME_SCALAR = \"FormattedTime\";\n+\n+    /**\n+     * Formatted Int.\n+     */\n+\n+    /**\n+     * Date scalar (with default formatting).\n+     */\n+    public static final String DATE_SCALAR = \"Date\";\n+\n+    /**\n+     * DateTime scalar (with default formatting).\n+     */\n+    public static final String DATETIME_SCALAR = \"DateTime\";\n+\n+    /**\n+     * Time Scalar (with default formatting).\n+     */\n+    public static final String TIME_SCALAR = \"Time\";\n+\n+    /**\n+     * Defines a {@link BigDecimal} type.\n+     */\n+    static final String BIG_DECIMAL = \"BigDecimal\";\n+\n+    /**\n+     * Defines a {@link BigInteger} type.\n+     */\n+    static final String BIG_INTEGER = \"BigInteger\";\n+\n+    /**\n+     * Value that indicates that default {@link java.util.Locale}.\n+     */\n+    static final String DEFAULT_LOCALE = \"##default\";\n+\n+    /**\n+     * GraphQL Int.\n+     */\n+    public static final String INT = \"Int\";\n+\n+    /**\n+     * GraphQL Float.\n+     */\n+    public static final String FLOAT = \"Float\";\n+\n+    /**\n+     * GraphQL String.\n+     */\n+    public static final String STRING = \"String\";\n+\n+    /**\n+     * GraphQL ID.\n+     */\n+    public static final String ID = \"ID\";\n+\n+    /**\n+     * GraphQL Boolean.\n+     */\n+    public static final String BOOLEAN = \"Boolean\";\n+\n+    /**\n+     * Logger.\n+     */\n+    private static final Logger LOGGER = Logger.getLogger(SchemaGeneratorHelper.class.getName());\n+\n+    /**\n+     * Indicates empty annotations.\n+     */\n+    private static final Annotation[] EMPTY_ANNOTATIONS = new Annotation[0];\n+\n+    /**\n+     * List of supported scalars keyed by the full class name.\n+     */\n+    static final Map<String, SchemaScalar> SUPPORTED_SCALARS = new HashMap<>() {{\n+        // Object Scalar\n+        put(Object.class.getName(), new SchemaScalar(\"Object\", Object.class.getName(), ExtendedScalars.Object, null));\n+\n+        // Time scalars\n+        put(OffsetTime.class.getName(),\n+            new SchemaScalar(FORMATTED_TIME_SCALAR, OFFSET_TIME_CLASS, FORMATTED_CUSTOM_TIME_SCALAR, \"HH[:mm][:ss]Z\"));\n+        put(LocalTime.class.getName(),\n+            new SchemaScalar(FORMATTED_TIME_SCALAR, LOCAL_TIME_CLASS, FORMATTED_CUSTOM_TIME_SCALAR, \"HH[:mm][:ss]\"));\n+\n+        // DateTime scalars\n+        put(OFFSET_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_OFFSET_DATETIME_SCALAR, OFFSET_DATE_TIME_CLASS, CUSTOM_OFFSET_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]Z\"));\n+        put(ZONED_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_ZONED_DATETIME_SCALAR, ZONED_DATE_TIME_CLASS, CUSTOM_ZONED_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]Z'['VV']'\"));\n+        put(LOCAL_DATE_TIME_CLASS,\n+            new SchemaScalar(FORMATTED_DATETIME_SCALAR, LOCAL_DATE_TIME_CLASS, FORMATTED_CUSTOM_DATE_TIME_SCALAR,\n+                             \"yyyy-MM-dd'T'HH[:mm][:ss]\"));\n+\n+        // Date scalar\n+        put(LOCAL_DATE_CLASS, new SchemaScalar(FORMATTED_DATE_SCALAR, LOCAL_DATE_CLASS, FORMATTED_CUSTOM_DATE_SCALAR,\n+                                               \"yyyy-MM-dd\"));\n+\n+        // BigDecimal scalars\n+        put(BIG_DECIMAL_CLASS, new SchemaScalar(BIG_DECIMAL, BIG_DECIMAL_CLASS, CUSTOM_BIGDECIMAL_SCALAR, null));\n+\n+        // BigInteger scalars\n+        put(BIG_INTEGER_CLASS, new SchemaScalar(BIG_INTEGER, BIG_INTEGER_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+        put(LONG_PRIMITIVE_CLASS, new SchemaScalar(BIG_INTEGER, LONG_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+        put(LONG_CLASS, new SchemaScalar(BIG_INTEGER, LONG_CLASS, CUSTOM_BIGINTEGER_SCALAR, null));\n+\n+        // Int scalars\n+        put(INTEGER_CLASS, new SchemaScalar(INT, INTEGER_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(INTEGER_PRIMITIVE_CLASS, new SchemaScalar(INT, INTEGER_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(BYTE_CLASS, new SchemaScalar(INT, BYTE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(BYTE_PRIMITIVE_CLASS, new SchemaScalar(INT, BYTE_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(SHORT_CLASS, new SchemaScalar(INT, SHORT_CLASS, CUSTOM_INT_SCALAR, null));\n+        put(SHORT_PRIMITIVE_CLASS, new SchemaScalar(INT, SHORT_PRIMITIVE_CLASS, CUSTOM_INT_SCALAR, null));\n+\n+        // Float scalars\n+        put(FLOAT_CLASS, new SchemaScalar(FLOAT, FLOAT_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(FLOAT_PRIMITIVE_CLASS, new SchemaScalar(FLOAT, FLOAT_PRIMITIVE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(DOUBLE_CLASS, new SchemaScalar(FLOAT, DOUBLE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+        put(DOUBLE_PRIMITIVE_CLASS, new SchemaScalar(FLOAT, DOUBLE_PRIMITIVE_CLASS, CUSTOM_FLOAT_SCALAR, null));\n+    }};\n+\n+    /**\n+     * List of types that should map to a GraphQL Boolean.\n+     */\n+    static final List<String> BOOLEAN_LIST = new ArrayList<>() {{\n+        add(\"boolean\");\n+        add(\"java.lang.Boolean\");\n+    }};\n+\n+    /**\n+     * List of types that should map to a GraphQL String.\n+     */\n+    static final List<String> STRING_LIST = new ArrayList<>() {{\n+        add(\"java.lang.String\");\n+        add(\"java.lang.Character\");\n+        add(\"char\");\n+    }};\n+\n+    /**\n+     * List of array primitive types and their array mapping. See https://docs.oracle.com/javase/6/docs/api/java/lang/Class\n+     * .html#getName%28%29\n+     */\n+    static final Map<String, String> PRIMITIVE_ARRAY_MAP = new HashMap<>() {{\n+        put(\"[Z\", \"boolean\");\n+        put(\"[B\", \"byte\");\n+        put(\"[C\", \"char\");\n+        put(\"[D\", \"double\");\n+        put(\"[F\", \"float\");\n+        put(\"[I\", \"int\");\n+        put(\"[J\", \"long\");\n+        put(\"[S\", \"short\");\n+    }};\n+\n+    /**\n+     * List of all Java primitives.\n+     */\n+    static final List<String> JAVA_PRIMITIVE_TYPES = new ArrayList<>() {{\n+        add(\"byte\");\n+        add(\"short\");\n+        add(\"int\");\n+        add(\"long\");\n+        add(\"float\");\n+        add(\"double\");\n+        add(\"boolean\");\n+        add(\"char\");\n+    }};\n+\n+    /**\n+     * Private no-args constructor.\n+     */\n+    private SchemaGeneratorHelper() {\n+    }\n+\n+    /**\n+     * Return the simple name from a given class as a String. This takes into account any annotations that may be present.\n+     *\n+     * @param className class name\n+     * @return the simple class name\n+     * @throws ClassNotFoundException if invalid class name\n+     */\n+    protected static String getSimpleName(String className)\n+            throws ClassNotFoundException {\n+        return getSimpleName(className, false);\n+    }\n+\n+    /**\n+     * Return true of the {@link Class} is a primitive or array of primitives.\n+     *\n+     * @param clazz {@link Class} to check\n+     * @return true of the {@link Class} is a primitive or array of primitives.\n+     */\n+    protected static boolean isPrimitive(Class<?> clazz) {\n+        return isPrimitive(clazz.getName());\n+    }\n+\n+    /**\n+     * Return true of the class name is a primitive or array of primitives.\n+     *\n+     * @param clazz class name to check\n+     * @return true if the class name is a primitive or array of primitives.\n+     */\n+    protected static boolean isPrimitive(String clazz) {\n+        return JAVA_PRIMITIVE_TYPES.contains(clazz)\n+                || PRIMITIVE_ARRAY_MAP.values().stream().anyMatch(v -> v.contains(clazz));\n+    }\n+\n+    /**\n+     * Return true of the class name is an array of primitives.\n+     *\n+     * @param clazz class name to check\n+     * @return true true of the class name is an array of primitives.\n+     */\n+    protected static boolean isPrimitiveArray(String clazz) {\n+        return PRIMITIVE_ARRAY_MAP.values().stream().anyMatch(v -> v.contains(clazz));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 419}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDcyMzYxOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaInputType.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1MzoyNFrOHyJD9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1MzoyNFrOHyJD9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjMzOTMxNg==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522339316", "createdAt": "2020-11-12T18:53:24Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/SchemaInputType.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDczMDU2OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/package-info.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NToxMFrOHyJISA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NToxMFrOHyJISA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MDQyNA==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522340424", "createdAt": "2020-11-12T18:55:10Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/io/helidon/microprofile/graphql/server/package-info.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDczMTcwOnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/java/module-info.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NToyNlrOHyJI-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NToyNlrOHyJI-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MDYwMg==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522340602", "createdAt": "2020-11-12T18:55:26Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/java/module-info.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Copyright (c) 2019, 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDczNDA5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/resources/META-INF/microprofile-config.properties", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NjowOVrOHyJKcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMDo0MTo1N1rOHyUvLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MDk3Ng==", "bodyText": "We no longer need \"All rights reserved.\"", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522340976", "createdAt": "2020-11-12T18:56:09Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/resources/META-INF/microprofile-config.properties", "diffHunk": "@@ -0,0 +1,18 @@\n+#\n+# Copyright (c) 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUzMDYwNA==", "bodyText": "this file should actually be deleted as it's taken care of elsewhere.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522530604", "createdAt": "2020-11-13T00:41:57Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/resources/META-INF/microprofile-config.properties", "diffHunk": "@@ -0,0 +1,18 @@\n+#\n+# Copyright (c) 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MDk3Ng=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDczNTI5OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/resources/META-INF/services/javax.enterprise.inject.spi.Extension", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1NjoyOFrOHyJLJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMDo0MjozNVrOHyUwAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MTE1OA==", "bodyText": "New file, remove 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522341158", "createdAt": "2020-11-12T18:56:28Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/resources/META-INF/services/javax.enterprise.inject.spi.Extension", "diffHunk": "@@ -0,0 +1,17 @@\n+#\n+# Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUzMDgxNw==", "bodyText": "I will check other files as all new classes, etc under graphql should only have 2019.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522530817", "createdAt": "2020-11-13T00:42:35Z", "author": {"login": "tmiddlet2666"}, "path": "microprofile/graphql/server/src/main/resources/META-INF/services/javax.enterprise.inject.spi.Extension", "diffHunk": "@@ -0,0 +1,17 @@\n+#\n+# Copyright (c) 2019, 2020 Oracle and/or its affiliates.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MTE1OA=="}, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NDczNzA3OnYy", "diffSide": "RIGHT", "path": "microprofile/graphql/server/src/main/resources/web/index.html", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1Njo1MFrOHyJMLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxODo1Njo1MFrOHyJMLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjM0MTQyMQ==", "bodyText": "New file, remove 2019. Remove \"All rights reserved.\"", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r522341421", "createdAt": "2020-11-12T18:56:50Z", "author": {"login": "tjquinno"}, "path": "microprofile/graphql/server/src/main/resources/web/index.html", "diffHunk": "@@ -0,0 +1,48 @@\n+<!--\n+\n+    Copyright (c) 2019, 2020 Oracle and/or its affiliates. All rights reserved.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2948b0bf1973d4dc87c6d147f66ec8b382cc4a38"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM3NzAwNDA4OnYy", "diffSide": "RIGHT", "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQwMDoyNDoxOVrOIBBD1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQwMTo0MzowN1rOIT-BsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkzNjg1NA==", "bodyText": "Should this be in a try-finally block so the server is shut down even if an assertion fails?\nI'd say don't make this change now unless you happen to be changing something more important in this file.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r537936854", "createdAt": "2020-12-08T00:24:19Z", "author": {"login": "tjquinno"}, "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.graphql.server;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import io.helidon.media.jsonb.JsonbSupport;\n+import io.helidon.webclient.WebClient;\n+import io.helidon.webserver.Routing;\n+import io.helidon.webserver.WebServer;\n+\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.StaticDataFetcher;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaGenerator;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.notNullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+class GraphQlSupportTest {\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    void testHelloWorld() {\n+        WebServer server = WebServer.builder()\n+                .routing(Routing.builder()\n+                                 .register(GraphQlSupport.create(buildSchema()))\n+                                 .build())\n+                .build()\n+                .start()\n+                .await(10, TimeUnit.SECONDS);\n+\n+        WebClient webClient = WebClient.builder()\n+                .addMediaSupport(JsonbSupport.create())\n+                .build();\n+\n+        LinkedHashMap<String, Object> response = webClient\n+                .post()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .submit(\"{\\\"query\\\": \\\"{hello}\\\"}\", LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        Map<String, Object> data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"POST errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"POST\", data.get(\"hello\"), is(\"world\"));\n+\n+        response = webClient\n+                .get()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .queryParam(\"query\", \"{hello}\")\n+                .request(LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"GET errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"GET\", data.get(\"hello\"), is(\"world\"));\n+\n+        server.shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "32a37fe7a3c33330d5c83c08fbe2c9643cbc75ef"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk0MzAwNA==", "bodyText": "Thanks. I'll add a task to do it when i'm in there at some stage.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r537943004", "createdAt": "2020-12-08T00:39:42Z", "author": {"login": "tmiddlet2666"}, "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.graphql.server;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import io.helidon.media.jsonb.JsonbSupport;\n+import io.helidon.webclient.WebClient;\n+import io.helidon.webserver.Routing;\n+import io.helidon.webserver.WebServer;\n+\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.StaticDataFetcher;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaGenerator;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.notNullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+class GraphQlSupportTest {\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    void testHelloWorld() {\n+        WebServer server = WebServer.builder()\n+                .routing(Routing.builder()\n+                                 .register(GraphQlSupport.create(buildSchema()))\n+                                 .build())\n+                .build()\n+                .start()\n+                .await(10, TimeUnit.SECONDS);\n+\n+        WebClient webClient = WebClient.builder()\n+                .addMediaSupport(JsonbSupport.create())\n+                .build();\n+\n+        LinkedHashMap<String, Object> response = webClient\n+                .post()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .submit(\"{\\\"query\\\": \\\"{hello}\\\"}\", LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        Map<String, Object> data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"POST errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"POST\", data.get(\"hello\"), is(\"world\"));\n+\n+        response = webClient\n+                .get()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .queryParam(\"query\", \"{hello}\")\n+                .request(LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"GET errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"GET\", data.get(\"hello\"), is(\"world\"));\n+\n+        server.shutdown();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkzNjg1NA=="}, "originalCommit": {"oid": "32a37fe7a3c33330d5c83c08fbe2c9643cbc75ef"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzgxMDA5Nw==", "bodyText": "@tjquinno will do this in a change i am doing now.", "url": "https://github.com/oracle/helidon/pull/2504#discussion_r557810097", "createdAt": "2021-01-15T01:43:07Z", "author": {"login": "tmiddlet2666"}, "path": "graphql/server/src/test/java/io/helidon/graphql/server/GraphQlSupportTest.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright (c) 2020 Oracle and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.helidon.graphql.server;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+\n+import io.helidon.media.jsonb.JsonbSupport;\n+import io.helidon.webclient.WebClient;\n+import io.helidon.webserver.Routing;\n+import io.helidon.webserver.WebServer;\n+\n+import graphql.schema.GraphQLSchema;\n+import graphql.schema.StaticDataFetcher;\n+import graphql.schema.idl.RuntimeWiring;\n+import graphql.schema.idl.SchemaGenerator;\n+import graphql.schema.idl.SchemaParser;\n+import graphql.schema.idl.TypeDefinitionRegistry;\n+import org.junit.jupiter.api.Test;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.notNullValue;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+class GraphQlSupportTest {\n+\n+    @SuppressWarnings(\"unchecked\")\n+    @Test\n+    void testHelloWorld() {\n+        WebServer server = WebServer.builder()\n+                .routing(Routing.builder()\n+                                 .register(GraphQlSupport.create(buildSchema()))\n+                                 .build())\n+                .build()\n+                .start()\n+                .await(10, TimeUnit.SECONDS);\n+\n+        WebClient webClient = WebClient.builder()\n+                .addMediaSupport(JsonbSupport.create())\n+                .build();\n+\n+        LinkedHashMap<String, Object> response = webClient\n+                .post()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .submit(\"{\\\"query\\\": \\\"{hello}\\\"}\", LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        Map<String, Object> data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"POST errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"POST\", data.get(\"hello\"), is(\"world\"));\n+\n+        response = webClient\n+                .get()\n+                .uri(\"http://localhost:\" + server.port() + \"/graphql\")\n+                .queryParam(\"query\", \"{hello}\")\n+                .request(LinkedHashMap.class)\n+                .await(10, TimeUnit.SECONDS);\n+\n+        data = (Map<String, Object>) response.get(\"data\");\n+        assertThat(\"GET errors: \" + response.get(\"errors\"), data, notNullValue());\n+        assertThat(\"GET\", data.get(\"hello\"), is(\"world\"));\n+\n+        server.shutdown();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkzNjg1NA=="}, "originalCommit": {"oid": "32a37fe7a3c33330d5c83c08fbe2c9643cbc75ef"}, "originalPosition": 78}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 340, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}