{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzNjAzNTk4", "number": 1877, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDoxNDozN1rOEAHQnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDoxNDozN1rOEAHQnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY4NTU0Mzk3OnYy", "diffSide": "RIGHT", "path": "media/common/src/main/java/io/helidon/media/common/DataChunkInputStream.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNDoxNDozN1rOGbMOnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxMjoxMDoyMFrOGbyM-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE2NTA4NA==", "bodyText": "What would happen with this condition if the last ByteBuffer in the chunk returns 0 and continues in line 144?", "url": "https://github.com/oracle/helidon/pull/1877#discussion_r431165084", "createdAt": "2020-05-27T14:14:37Z", "author": {"login": "spericas"}, "path": "media/common/src/main/java/io/helidon/media/common/DataChunkInputStream.java", "diffHunk": "@@ -132,32 +132,38 @@ public int read(byte[] buf, int off, int len) throws IOException {\n                 return -1;\n             }\n \n-            ByteBuffer currentBuffer = chunk.data();\n-\n-            if (currentBuffer.position() == 0) {\n-                LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n-            }\n-\n-            // If there is anything to read, then read as much as fits into buf\n-            int rem = currentBuffer.remaining();\n-            if (len > rem) {\n-                len = rem;\n+            ByteBuffer[] currentBuffers = chunk.data();\n+            int count = 0;\n+            for (int i = 0; i < currentBuffers.length; i++) {\n+                if (i == 0 && currentBuffers[i].position() == 0) {\n+                    LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n+                }\n+                // If there is anything to read, then read as much as fits into buf\n+                int rem = currentBuffers[i].remaining();\n+                if (rem == 0) {\n+                    continue;\n+                }\n+                int currentLen = len;\n+                if (currentLen > rem) {\n+                    currentLen = rem;\n+                }\n+                currentBuffers[i].get(buf, off, currentLen);\n+                off += currentLen;\n+                count += currentLen;\n+\n+                // Chunk is consumed entirely - release the chunk, and prefetch a new chunk; do not\n+                // wait for it to arrive - the next read may have to wait less.\n+                //\n+                // Assert: it is safe to request new chunks eagerly - there is no mechanism\n+                // to push back unconsumed data, so we can assume we own all the chunks,\n+                // consumed and unconsumed.\n+                if (i == currentBuffers.length - 1 && currentLen == rem) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d29fcdd4e666161b3f417cff69db89f9dd64956b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxNjg1Mg==", "bodyText": "Good point. I will make another pass at this and add a unit test.", "url": "https://github.com/oracle/helidon/pull/1877#discussion_r431316852", "createdAt": "2020-05-27T17:27:42Z", "author": {"login": "romain-grecourt"}, "path": "media/common/src/main/java/io/helidon/media/common/DataChunkInputStream.java", "diffHunk": "@@ -132,32 +132,38 @@ public int read(byte[] buf, int off, int len) throws IOException {\n                 return -1;\n             }\n \n-            ByteBuffer currentBuffer = chunk.data();\n-\n-            if (currentBuffer.position() == 0) {\n-                LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n-            }\n-\n-            // If there is anything to read, then read as much as fits into buf\n-            int rem = currentBuffer.remaining();\n-            if (len > rem) {\n-                len = rem;\n+            ByteBuffer[] currentBuffers = chunk.data();\n+            int count = 0;\n+            for (int i = 0; i < currentBuffers.length; i++) {\n+                if (i == 0 && currentBuffers[i].position() == 0) {\n+                    LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n+                }\n+                // If there is anything to read, then read as much as fits into buf\n+                int rem = currentBuffers[i].remaining();\n+                if (rem == 0) {\n+                    continue;\n+                }\n+                int currentLen = len;\n+                if (currentLen > rem) {\n+                    currentLen = rem;\n+                }\n+                currentBuffers[i].get(buf, off, currentLen);\n+                off += currentLen;\n+                count += currentLen;\n+\n+                // Chunk is consumed entirely - release the chunk, and prefetch a new chunk; do not\n+                // wait for it to arrive - the next read may have to wait less.\n+                //\n+                // Assert: it is safe to request new chunks eagerly - there is no mechanism\n+                // to push back unconsumed data, so we can assume we own all the chunks,\n+                // consumed and unconsumed.\n+                if (i == currentBuffers.length - 1 && currentLen == rem) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE2NTA4NA=="}, "originalCommit": {"oid": "d29fcdd4e666161b3f417cff69db89f9dd64956b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ2ODE1NQ==", "bodyText": "@spericas, I've made changes, please take a look and let me know.", "url": "https://github.com/oracle/helidon/pull/1877#discussion_r431468155", "createdAt": "2020-05-27T22:02:03Z", "author": {"login": "romain-grecourt"}, "path": "media/common/src/main/java/io/helidon/media/common/DataChunkInputStream.java", "diffHunk": "@@ -132,32 +132,38 @@ public int read(byte[] buf, int off, int len) throws IOException {\n                 return -1;\n             }\n \n-            ByteBuffer currentBuffer = chunk.data();\n-\n-            if (currentBuffer.position() == 0) {\n-                LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n-            }\n-\n-            // If there is anything to read, then read as much as fits into buf\n-            int rem = currentBuffer.remaining();\n-            if (len > rem) {\n-                len = rem;\n+            ByteBuffer[] currentBuffers = chunk.data();\n+            int count = 0;\n+            for (int i = 0; i < currentBuffers.length; i++) {\n+                if (i == 0 && currentBuffers[i].position() == 0) {\n+                    LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n+                }\n+                // If there is anything to read, then read as much as fits into buf\n+                int rem = currentBuffers[i].remaining();\n+                if (rem == 0) {\n+                    continue;\n+                }\n+                int currentLen = len;\n+                if (currentLen > rem) {\n+                    currentLen = rem;\n+                }\n+                currentBuffers[i].get(buf, off, currentLen);\n+                off += currentLen;\n+                count += currentLen;\n+\n+                // Chunk is consumed entirely - release the chunk, and prefetch a new chunk; do not\n+                // wait for it to arrive - the next read may have to wait less.\n+                //\n+                // Assert: it is safe to request new chunks eagerly - there is no mechanism\n+                // to push back unconsumed data, so we can assume we own all the chunks,\n+                // consumed and unconsumed.\n+                if (i == currentBuffers.length - 1 && currentLen == rem) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE2NTA4NA=="}, "originalCommit": {"oid": "d29fcdd4e666161b3f417cff69db89f9dd64956b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTc4NzI1OA==", "bodyText": "@romain-grecourt I'll take a closer look. At first glance, the code is still a bit odd; it seems that the DataChunk abstraction needs to be improved so we can call get(byte[], int off, int len) and so that it can iterate over its ByteBuffer's, copy the data and also remember which buffer it is reading from.\nYour code is always starting from the first buffer on each call to read(...), even though buffers may have been consumed in an earlier call. If the DataChunk abstraction is enhanced, thenDataChunkInputStream shouldn't need to change too much.", "url": "https://github.com/oracle/helidon/pull/1877#discussion_r431787258", "createdAt": "2020-05-28T12:10:20Z", "author": {"login": "spericas"}, "path": "media/common/src/main/java/io/helidon/media/common/DataChunkInputStream.java", "diffHunk": "@@ -132,32 +132,38 @@ public int read(byte[] buf, int off, int len) throws IOException {\n                 return -1;\n             }\n \n-            ByteBuffer currentBuffer = chunk.data();\n-\n-            if (currentBuffer.position() == 0) {\n-                LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n-            }\n-\n-            // If there is anything to read, then read as much as fits into buf\n-            int rem = currentBuffer.remaining();\n-            if (len > rem) {\n-                len = rem;\n+            ByteBuffer[] currentBuffers = chunk.data();\n+            int count = 0;\n+            for (int i = 0; i < currentBuffers.length; i++) {\n+                if (i == 0 && currentBuffers[i].position() == 0) {\n+                    LOGGER.finest(() -> \"Reading chunk ID: \" + chunk.id());\n+                }\n+                // If there is anything to read, then read as much as fits into buf\n+                int rem = currentBuffers[i].remaining();\n+                if (rem == 0) {\n+                    continue;\n+                }\n+                int currentLen = len;\n+                if (currentLen > rem) {\n+                    currentLen = rem;\n+                }\n+                currentBuffers[i].get(buf, off, currentLen);\n+                off += currentLen;\n+                count += currentLen;\n+\n+                // Chunk is consumed entirely - release the chunk, and prefetch a new chunk; do not\n+                // wait for it to arrive - the next read may have to wait less.\n+                //\n+                // Assert: it is safe to request new chunks eagerly - there is no mechanism\n+                // to push back unconsumed data, so we can assume we own all the chunks,\n+                // consumed and unconsumed.\n+                if (i == currentBuffers.length - 1 && currentLen == rem) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTE2NTA4NA=="}, "originalCommit": {"oid": "d29fcdd4e666161b3f417cff69db89f9dd64956b"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 579, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}