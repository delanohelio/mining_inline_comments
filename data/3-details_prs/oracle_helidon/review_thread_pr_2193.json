{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUzNzc4Mjg5", "number": 2193, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDowMDozNlrOEQoy8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMDozODoyNVrOESwOfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1ODgxMDczOnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDowMDozNlrOG05adA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDowMDozNlrOG05adA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExOTc5Ng==", "bodyText": "This is a ternary operator inside a lambda, so you may want to indent it a bit more", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r458119796", "createdAt": "2020-07-21T14:00:36Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -102,11 +103,10 @@ public void subscribe(Subscriber<? super ReadableBodyPart> subscriber) {\n \n             @Override\n             public void request(long n) {\n-                long curr = n <= 0 ?\n-                        partsRequested.getAndSet(-1) :\n-                        partsRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n ? v + n\n-                                : v < 0 ? v\n-                                : Long.MAX_VALUE);\n+                long curr = n <= 0\n+                        ? partsRequested.getAndSet(-1)\n+                        : partsRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                        ? v + n : v < 0 ? v : Long.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c778395f88b719ec14ae37e2fd831a92df1564a"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1ODgxNjE2OnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDowMTo1MVrOG05eFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNDowMTo1MVrOG05eFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyMDcyNg==", "bodyText": "Ditto: maybe indent this ternary operator a bit more", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r458120726", "createdAt": "2020-07-21T14:01:51Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -426,11 +425,10 @@ public void subscribe(Subscriber<? super DataChunk> sub) {\n                 public void request(long n) {\n                     // Illegal n makes chunksRequested negative, which interacts with drain() to drain the\n                     // entire bufferEntryIterator, and signal onError\n-                    long curr = n <= 0 ? chunksRequested.getAndSet(-1) :\n-                            chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n ? v + n\n-                                    : v < 0 ? v == Long.MIN_VALUE ? n\n-                                    : v\n-                                    : Long.MAX_VALUE);\n+                    long curr = n <= 0\n+                            ? chunksRequested.getAndSet(-1)\n+                            : chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                            ? v + n : v < 0 ? v == Long.MIN_VALUE ? n : v : Long.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c778395f88b719ec14ae37e2fd831a92df1564a"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjI3OTY4OnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoxOTo1N1rOG25VnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoxOTo1N1rOG25VnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIxNTcwOA==", "bodyText": "...and is used to transition parser state", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460215708", "createdAt": "2020-07-24T18:19:57Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjI4MzA5OnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoyMTowMFrOG25Xnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoyMTowMFrOG25Xnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIxNjIyMw==", "bodyText": "demand for DataChunks by inner Subscriber (exposed by DataChunkPublisher through API)", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460216223", "createdAt": "2020-07-24T18:21:00Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state\n+- partsRequested: for outer `Subscriber` to indicate demand for MIME parts\n+- demand for DataChunks by inner `Subscriber`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjMwOTM2OnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoyOTozNVrOG25n-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODoyOTozNVrOG25n-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyMDQwOQ==", "bodyText": "(concurrent cases are commonly omitted, but here we do take care of them - hence it looks a little more complex than others)", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460220409", "createdAt": "2020-07-24T18:29:35Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state\n+- partsRequested: for outer `Subscriber` to indicate demand for MIME parts\n+- demand for DataChunks by inner `Subscriber`\n+\n+Whenever any of these change, `drain()` is called to enter `drainBoth()` or demand to re-do it again, if\n+a thread already inside `drainBoth()` is detected.\n+\n+Additionally, special care is taken when dealing with:\n+- `upstream`: to interact with upstream\n+- `downstream`: outer `Subscriber`\n+- `bodyPartPublisher`: a special `Publisher` that interacts with inner `Subscriber`\n+\n+At high level, `drainBoth()` operates like a flat map of a stream of `DataChunk` into a stream of\n+`ParserEvents`: `[DataChunk]` -> `[[ParserEvent]]` -> `[ParserEvent]`, which then is fanned out into a stream\n+of streams of DataChunk: `[ParserEvent]` -> `[ReadableBodyPart]`, which is essentially\n+`[ParserEvent]` -> `[[DataChunk]]`. In fact, if not for resource management and the `Processor` interface,\n+it could have been constructed as a composition of existing reactive components.\n+\n+The explanation here may appear in reverse order to what `drainBoth()` is doing, but it may be easier to\n+see it in this order, the goals from high level to low level:\n+\n+- `DataChunk` are requested from upstream one at a time\n+  - this way we do not retain too many `DataChunk`, and flattening `[[ParserEvent]]` is trivial\n+  - this is ensued by inner and outer `Subscriber` detecting when the demand changes from zero\n+  - additionally, the demand of the outer `Subscriber` can become zero only after the next part is done ; this means\n+    that the demand of the outer `Subscriber` is essentially unable to issue upstream request until after the inner\n+    `Subscriber` is done\n+- `DataChunk` are not requested, nor any errors are signalled, while the parser iterator is able to\n+  produce more ParserEvents\n+  - all `onError` events are totally ordered after all possible `onNext` that can be emitted without\n+    requesting more `DataChunk` from upstream\n+- parser iterator does not produce more events, unless there is evidence of demand from inner or\n+  outer `Subscriber`\n+  - outer `Subscriber` demand is ignored while there is a `bodyPartPublisher` responsible for dealing with\n+    the demand of an inner `Subscriber`\n+  - cancellation or error state of inner `Subscriber` appears to `drainBoth()` as a demand for infinite number\n+    of `DataChunk`; this way we can make progress to the end of the MIME part, and serve the demand of the outer\n+    `Subscriber` if any\n+  - inner `Subscriber` demand is witnessed by inner `Subscriber` calling `drain()`, and that observing that\n+    `bodyPartPublisher` is unable to satisfy the demand\n+- parser iterator is not asked for more events, while there is a `bodyPartPublisher` and it satisfies\n+  the demand for `DataChunk` by inner `Subscriber` by the `DataChunk` already given to it\n+\n+## DataChunkPublisher\n+\n+Inner `Subscriber` is dealt with using `DataChunkPublisher`. Essentially, it is a flat map\n+`[[DataChunk]]` -> `[DataChunk]` (given iterators of `BufferEntry`, one at a time, emits `DataChunk` one at a\n+time). In fact, if not for resource management, it could have been constructed using existing reactive\n+components.\n+\n+The design is very simple:\n+- keep track of change of demand and cancellations of inner `Subscriber`\n+- expose methods to allow total order of signals emitted by `drainBoth()`\n+- when cancelled, or a bad request is received, appear as unlimited unsatisfied demand, and merely discard\n+  all `DataChunk` that are received\n+- relies on `drainBoth()` not attempting to deliver `onError` before the previous iterator of `BufferEntry` is\n+  emptied ; this simplifies resource management\n+\n+## Initialization\n+\n+Both `MultiPartDecoder` and `DataChunkPublisher` share a similar approach: they have an atomic counter that:\n+- is initialized to a value indicating the uninitialized state that can never occur naturally throughout the\n+`Publisher` lifetime\n+- can be transitioned into \"subscribed\" state once and only once in its lifetime\n+- is finally transitioned into initialized state only after `onSubscribe` has returned.\n+\n+This allows to ensure that no more than one `Subscriber` is associated with the `Publisher` (concurrent cases are\n+commonly omitted), and enforce the rule that all on* signals get delivered only after `onSubscribe` and none", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjMxMjMyOnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMDozNVrOG25pvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMDozNVrOG25pvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyMDg2Mg==", "bodyText": "Perhaps, highlighting contenders can make it stand out as a reference to the actual variable name.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460220862", "createdAt": "2020-07-24T18:30:35Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state\n+- partsRequested: for outer `Subscriber` to indicate demand for MIME parts\n+- demand for DataChunks by inner `Subscriber`\n+\n+Whenever any of these change, `drain()` is called to enter `drainBoth()` or demand to re-do it again, if\n+a thread already inside `drainBoth()` is detected.\n+\n+Additionally, special care is taken when dealing with:\n+- `upstream`: to interact with upstream\n+- `downstream`: outer `Subscriber`\n+- `bodyPartPublisher`: a special `Publisher` that interacts with inner `Subscriber`\n+\n+At high level, `drainBoth()` operates like a flat map of a stream of `DataChunk` into a stream of\n+`ParserEvents`: `[DataChunk]` -> `[[ParserEvent]]` -> `[ParserEvent]`, which then is fanned out into a stream\n+of streams of DataChunk: `[ParserEvent]` -> `[ReadableBodyPart]`, which is essentially\n+`[ParserEvent]` -> `[[DataChunk]]`. In fact, if not for resource management and the `Processor` interface,\n+it could have been constructed as a composition of existing reactive components.\n+\n+The explanation here may appear in reverse order to what `drainBoth()` is doing, but it may be easier to\n+see it in this order, the goals from high level to low level:\n+\n+- `DataChunk` are requested from upstream one at a time\n+  - this way we do not retain too many `DataChunk`, and flattening `[[ParserEvent]]` is trivial\n+  - this is ensued by inner and outer `Subscriber` detecting when the demand changes from zero\n+  - additionally, the demand of the outer `Subscriber` can become zero only after the next part is done ; this means\n+    that the demand of the outer `Subscriber` is essentially unable to issue upstream request until after the inner\n+    `Subscriber` is done\n+- `DataChunk` are not requested, nor any errors are signalled, while the parser iterator is able to\n+  produce more ParserEvents\n+  - all `onError` events are totally ordered after all possible `onNext` that can be emitted without\n+    requesting more `DataChunk` from upstream\n+- parser iterator does not produce more events, unless there is evidence of demand from inner or\n+  outer `Subscriber`\n+  - outer `Subscriber` demand is ignored while there is a `bodyPartPublisher` responsible for dealing with\n+    the demand of an inner `Subscriber`\n+  - cancellation or error state of inner `Subscriber` appears to `drainBoth()` as a demand for infinite number\n+    of `DataChunk`; this way we can make progress to the end of the MIME part, and serve the demand of the outer\n+    `Subscriber` if any\n+  - inner `Subscriber` demand is witnessed by inner `Subscriber` calling `drain()`, and that observing that\n+    `bodyPartPublisher` is unable to satisfy the demand\n+- parser iterator is not asked for more events, while there is a `bodyPartPublisher` and it satisfies\n+  the demand for `DataChunk` by inner `Subscriber` by the `DataChunk` already given to it\n+\n+## DataChunkPublisher\n+\n+Inner `Subscriber` is dealt with using `DataChunkPublisher`. Essentially, it is a flat map\n+`[[DataChunk]]` -> `[DataChunk]` (given iterators of `BufferEntry`, one at a time, emits `DataChunk` one at a\n+time). In fact, if not for resource management, it could have been constructed using existing reactive\n+components.\n+\n+The design is very simple:\n+- keep track of change of demand and cancellations of inner `Subscriber`\n+- expose methods to allow total order of signals emitted by `drainBoth()`\n+- when cancelled, or a bad request is received, appear as unlimited unsatisfied demand, and merely discard\n+  all `DataChunk` that are received\n+- relies on `drainBoth()` not attempting to deliver `onError` before the previous iterator of `BufferEntry` is\n+  emptied ; this simplifies resource management\n+\n+## Initialization\n+\n+Both `MultiPartDecoder` and `DataChunkPublisher` share a similar approach: they have an atomic counter that:\n+- is initialized to a value indicating the uninitialized state that can never occur naturally throughout the\n+`Publisher` lifetime\n+- can be transitioned into \"subscribed\" state once and only once in its lifetime\n+- is finally transitioned into initialized state only after `onSubscribe` has returned.\n+\n+This allows to ensure that no more than one `Subscriber` is associated with the `Publisher` (concurrent cases are\n+commonly omitted), and enforce the rule that all on* signals get delivered only after `onSubscribe` and none\n+during `onSubscribe`.\n+\n+`DataChunkPublisher` is pretty much done at that stage. `MultiPartDecoder` needs a bit more explanation, as it\n+has two ends that need initializing:\n+- upstream signalling `onSubscribe`, potentially immediately followed by `onError` or `onComplete` for\n+  empty upstream\n+- downstream outer `Subscriber` being attached by `subscribe()`\n+\n+The use of contenders atomic counter allows to synchronize all these.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjMxNjY5OnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMjowNlrOG25seg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMjowNlrOG25seg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyMTU2Mg==", "bodyText": "Vertical arrows are not aligned after adding STREAM to UP_INIT", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460221562", "createdAt": "2020-07-24T18:32:06Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state\n+- partsRequested: for outer `Subscriber` to indicate demand for MIME parts\n+- demand for DataChunks by inner `Subscriber`\n+\n+Whenever any of these change, `drain()` is called to enter `drainBoth()` or demand to re-do it again, if\n+a thread already inside `drainBoth()` is detected.\n+\n+Additionally, special care is taken when dealing with:\n+- `upstream`: to interact with upstream\n+- `downstream`: outer `Subscriber`\n+- `bodyPartPublisher`: a special `Publisher` that interacts with inner `Subscriber`\n+\n+At high level, `drainBoth()` operates like a flat map of a stream of `DataChunk` into a stream of\n+`ParserEvents`: `[DataChunk]` -> `[[ParserEvent]]` -> `[ParserEvent]`, which then is fanned out into a stream\n+of streams of DataChunk: `[ParserEvent]` -> `[ReadableBodyPart]`, which is essentially\n+`[ParserEvent]` -> `[[DataChunk]]`. In fact, if not for resource management and the `Processor` interface,\n+it could have been constructed as a composition of existing reactive components.\n+\n+The explanation here may appear in reverse order to what `drainBoth()` is doing, but it may be easier to\n+see it in this order, the goals from high level to low level:\n+\n+- `DataChunk` are requested from upstream one at a time\n+  - this way we do not retain too many `DataChunk`, and flattening `[[ParserEvent]]` is trivial\n+  - this is ensued by inner and outer `Subscriber` detecting when the demand changes from zero\n+  - additionally, the demand of the outer `Subscriber` can become zero only after the next part is done ; this means\n+    that the demand of the outer `Subscriber` is essentially unable to issue upstream request until after the inner\n+    `Subscriber` is done\n+- `DataChunk` are not requested, nor any errors are signalled, while the parser iterator is able to\n+  produce more ParserEvents\n+  - all `onError` events are totally ordered after all possible `onNext` that can be emitted without\n+    requesting more `DataChunk` from upstream\n+- parser iterator does not produce more events, unless there is evidence of demand from inner or\n+  outer `Subscriber`\n+  - outer `Subscriber` demand is ignored while there is a `bodyPartPublisher` responsible for dealing with\n+    the demand of an inner `Subscriber`\n+  - cancellation or error state of inner `Subscriber` appears to `drainBoth()` as a demand for infinite number\n+    of `DataChunk`; this way we can make progress to the end of the MIME part, and serve the demand of the outer\n+    `Subscriber` if any\n+  - inner `Subscriber` demand is witnessed by inner `Subscriber` calling `drain()`, and that observing that\n+    `bodyPartPublisher` is unable to satisfy the demand\n+- parser iterator is not asked for more events, while there is a `bodyPartPublisher` and it satisfies\n+  the demand for `DataChunk` by inner `Subscriber` by the `DataChunk` already given to it\n+\n+## DataChunkPublisher\n+\n+Inner `Subscriber` is dealt with using `DataChunkPublisher`. Essentially, it is a flat map\n+`[[DataChunk]]` -> `[DataChunk]` (given iterators of `BufferEntry`, one at a time, emits `DataChunk` one at a\n+time). In fact, if not for resource management, it could have been constructed using existing reactive\n+components.\n+\n+The design is very simple:\n+- keep track of change of demand and cancellations of inner `Subscriber`\n+- expose methods to allow total order of signals emitted by `drainBoth()`\n+- when cancelled, or a bad request is received, appear as unlimited unsatisfied demand, and merely discard\n+  all `DataChunk` that are received\n+- relies on `drainBoth()` not attempting to deliver `onError` before the previous iterator of `BufferEntry` is\n+  emptied ; this simplifies resource management\n+\n+## Initialization\n+\n+Both `MultiPartDecoder` and `DataChunkPublisher` share a similar approach: they have an atomic counter that:\n+- is initialized to a value indicating the uninitialized state that can never occur naturally throughout the\n+`Publisher` lifetime\n+- can be transitioned into \"subscribed\" state once and only once in its lifetime\n+- is finally transitioned into initialized state only after `onSubscribe` has returned.\n+\n+This allows to ensure that no more than one `Subscriber` is associated with the `Publisher` (concurrent cases are\n+commonly omitted), and enforce the rule that all on* signals get delivered only after `onSubscribe` and none\n+during `onSubscribe`.\n+\n+`DataChunkPublisher` is pretty much done at that stage. `MultiPartDecoder` needs a bit more explanation, as it\n+has two ends that need initializing:\n+- upstream signalling `onSubscribe`, potentially immediately followed by `onError` or `onComplete` for\n+  empty upstream\n+- downstream outer `Subscriber` being attached by `subscribe()`\n+\n+The use of contenders atomic counter allows to synchronize all these.\n+\n+The partial order of possible events is:\n+\n+```\n+                                                      uninitialized\n+                                                       |         |\n+                       .-------------------------------'         `----------------------.\n+                       |                                                                |\n+                       V                                                                V\n+subscribe(...) --> halfInit(UPSTREAM_INIT) --> deferredInit()          deferredInit() <-- halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                     |                             |            |\n+                       V                     |   onError / onComplete      |            V\n+subscribe(...) --> !halfInit(UPSTREAM_INIT)  |           |                 |       !halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                     |           |  request        |            |\n+                       V                     |           |     |           |            V\n+subscribe(...) --> !halfInit(UPSTREAM_INIT)  `--.        |     |        .--'       !halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                        |        |     |        |               |\n+                       V                        V        V     V        V               V\n+                      ...                      atomic update of contenders             ...", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjMyMTYxOnYy", "diffSide": "RIGHT", "path": "docs-internal/multipartdecoder.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMzo1MVrOG25vhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODozMzo1MVrOG25vhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyMjM0MA==", "bodyText": "highlight request", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460222340", "createdAt": "2020-07-24T18:33:51Z", "author": {"login": "olotenko"}, "path": "docs-internal/multipartdecoder.md", "diffHunk": "@@ -0,0 +1,489 @@\n+# io.helidon.media.multipart.MultiPartDecoder\n+\n+This document provides additional details about the implementation of `MultiPartDecoder`.\n+\n+## Design considerations\n+\n+Reactive `Processor` should assume it is used concurrently, and yet deliver signals to downstream in\n+a total order. There are a few other considerations stemming from the reactive specification.\n+\n+When an error occurs it must be routed downstream, this `Processor` may have more than one downstream over time, thus\n+a given error may be signaled to many subscribers if needed.\n+\n+`Subscriber` may cancel their `Subscription`. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer Subscribers should not cancel upstream subscription while the inner `Subscriber` may\n+need to interact with upstream to make progress.\n+\n+`Subscriber` may issue bad requests. This should translate into a cancellation of upstream\n+subscription at the appropriate time: inner `Subscriber` should allow the outer `Subscriber` to make\n+progress; outer `Subscriber` should not generate errors that can be seen by inner `Subscriber`.\n+\n+Resources pinned by this `Processor` should be released as soon as they are not needed, and it is\n+practical to do so: subsequent requests or cancellations may occur at some arbitrary time in the\n+future.\n+\n+Whenever this `Processor` is known to have entered a terminal state (including cancellation or bad request),\n+ it must release any resources.\n+\n+Since we are essentially dealing with `DataChunk`, need to keep track of who owns the `DataChunk` - that is,\n+ whose responsibility it is to release it (important for cases when `DataChunk` is backed by Netty buffers).\n+\n+In this implementation all interactions with upstream, parser, or any of the `Subscriber` is done\n+in `drainBoth()`, which is guaranteed to be executed single-threadedly, with appropriate memory\n+fences between any two invocations of `drainBoth()`. This allows much of the state to be implemented as\n+non-thread-safe data structures. Additionally, the operation of the `Processor` can be understood\n+by observing `drainBoth()` method alone. The rest then is just a way to cause `drainBoth()` to make further\n+state transitions.\n+\n+The state is described by:\n+- error: for errors that need to be signalled to both inner and outer `Subscriber` (produced by the parser or upstream)\n+- cancelled: for cancellations signalled by outer `Subscriber`\n+- parser: a helper object to capture parser state across multiple `DataChunk`\n+- iterator: parser iterator that holds `ParserEvents` and transition parser state\n+- partsRequested: for outer `Subscriber` to indicate demand for MIME parts\n+- demand for DataChunks by inner `Subscriber`\n+\n+Whenever any of these change, `drain()` is called to enter `drainBoth()` or demand to re-do it again, if\n+a thread already inside `drainBoth()` is detected.\n+\n+Additionally, special care is taken when dealing with:\n+- `upstream`: to interact with upstream\n+- `downstream`: outer `Subscriber`\n+- `bodyPartPublisher`: a special `Publisher` that interacts with inner `Subscriber`\n+\n+At high level, `drainBoth()` operates like a flat map of a stream of `DataChunk` into a stream of\n+`ParserEvents`: `[DataChunk]` -> `[[ParserEvent]]` -> `[ParserEvent]`, which then is fanned out into a stream\n+of streams of DataChunk: `[ParserEvent]` -> `[ReadableBodyPart]`, which is essentially\n+`[ParserEvent]` -> `[[DataChunk]]`. In fact, if not for resource management and the `Processor` interface,\n+it could have been constructed as a composition of existing reactive components.\n+\n+The explanation here may appear in reverse order to what `drainBoth()` is doing, but it may be easier to\n+see it in this order, the goals from high level to low level:\n+\n+- `DataChunk` are requested from upstream one at a time\n+  - this way we do not retain too many `DataChunk`, and flattening `[[ParserEvent]]` is trivial\n+  - this is ensued by inner and outer `Subscriber` detecting when the demand changes from zero\n+  - additionally, the demand of the outer `Subscriber` can become zero only after the next part is done ; this means\n+    that the demand of the outer `Subscriber` is essentially unable to issue upstream request until after the inner\n+    `Subscriber` is done\n+- `DataChunk` are not requested, nor any errors are signalled, while the parser iterator is able to\n+  produce more ParserEvents\n+  - all `onError` events are totally ordered after all possible `onNext` that can be emitted without\n+    requesting more `DataChunk` from upstream\n+- parser iterator does not produce more events, unless there is evidence of demand from inner or\n+  outer `Subscriber`\n+  - outer `Subscriber` demand is ignored while there is a `bodyPartPublisher` responsible for dealing with\n+    the demand of an inner `Subscriber`\n+  - cancellation or error state of inner `Subscriber` appears to `drainBoth()` as a demand for infinite number\n+    of `DataChunk`; this way we can make progress to the end of the MIME part, and serve the demand of the outer\n+    `Subscriber` if any\n+  - inner `Subscriber` demand is witnessed by inner `Subscriber` calling `drain()`, and that observing that\n+    `bodyPartPublisher` is unable to satisfy the demand\n+- parser iterator is not asked for more events, while there is a `bodyPartPublisher` and it satisfies\n+  the demand for `DataChunk` by inner `Subscriber` by the `DataChunk` already given to it\n+\n+## DataChunkPublisher\n+\n+Inner `Subscriber` is dealt with using `DataChunkPublisher`. Essentially, it is a flat map\n+`[[DataChunk]]` -> `[DataChunk]` (given iterators of `BufferEntry`, one at a time, emits `DataChunk` one at a\n+time). In fact, if not for resource management, it could have been constructed using existing reactive\n+components.\n+\n+The design is very simple:\n+- keep track of change of demand and cancellations of inner `Subscriber`\n+- expose methods to allow total order of signals emitted by `drainBoth()`\n+- when cancelled, or a bad request is received, appear as unlimited unsatisfied demand, and merely discard\n+  all `DataChunk` that are received\n+- relies on `drainBoth()` not attempting to deliver `onError` before the previous iterator of `BufferEntry` is\n+  emptied ; this simplifies resource management\n+\n+## Initialization\n+\n+Both `MultiPartDecoder` and `DataChunkPublisher` share a similar approach: they have an atomic counter that:\n+- is initialized to a value indicating the uninitialized state that can never occur naturally throughout the\n+`Publisher` lifetime\n+- can be transitioned into \"subscribed\" state once and only once in its lifetime\n+- is finally transitioned into initialized state only after `onSubscribe` has returned.\n+\n+This allows to ensure that no more than one `Subscriber` is associated with the `Publisher` (concurrent cases are\n+commonly omitted), and enforce the rule that all on* signals get delivered only after `onSubscribe` and none\n+during `onSubscribe`.\n+\n+`DataChunkPublisher` is pretty much done at that stage. `MultiPartDecoder` needs a bit more explanation, as it\n+has two ends that need initializing:\n+- upstream signalling `onSubscribe`, potentially immediately followed by `onError` or `onComplete` for\n+  empty upstream\n+- downstream outer `Subscriber` being attached by `subscribe()`\n+\n+The use of contenders atomic counter allows to synchronize all these.\n+\n+The partial order of possible events is:\n+\n+```\n+                                                      uninitialized\n+                                                       |         |\n+                       .-------------------------------'         `----------------------.\n+                       |                                                                |\n+                       V                                                                V\n+subscribe(...) --> halfInit(UPSTREAM_INIT) --> deferredInit()          deferredInit() <-- halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                     |                             |            |\n+                       V                     |   onError / onComplete      |            V\n+subscribe(...) --> !halfInit(UPSTREAM_INIT)  |           |                 |       !halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                     |           |  request        |            |\n+                       V                     |           |     |           |            V\n+subscribe(...) --> !halfInit(UPSTREAM_INIT)  `--.        |     |        .--'       !halfInit(DOWNSTREAM_INIT) <-- onSubscribe(...)\n+                       |                        |        |     |        |               |\n+                       V                        V        V     V        V               V\n+                      ...                      atomic update of contenders             ...\n+                                                           |\n+                                                           V\n+                                                     contenders >= 0\n+                                                           |\n+                                                           V\n+                                                       initialized\n+```\n+\n+`halfInit()` ensures that one and only one of `UPSTREAM_INIT` / `DOWNSTREAM_INIT` returns true, and any subsequent\n+ future invocations with the same argument get false.\n+\n+Of all atomic updates of contenders counter only the updates by `deferredInit()` are able to turn the value\n+into a non-negative. All other updates observe they are \"locked out\" from entering `drainBoth()`. The second\n+`deferredInit()` can witness if any of `onError`/`onComplete`/request happened, and enter `drainBoth()` on their", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjM1Nzg5OnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODo0NjoxNFrOG26F2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwNzozMzoyMlrOG3DM9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng==", "bodyText": "no need to remove this check, but FYI - the test will always pass for any conforming Publisher: they won't issue more than one of onError/onComplete.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460228056", "createdAt": "2020-07-24T18:46:14Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI3ODI5OA==", "bodyText": "Actually, this is what needs doing: remove the check and the following line setting upstream = CANCELED;. Then the subtle race condition discussed in the comment to drainBoth will disappear: then observing upstream == CANCELED is possible only if onComplete has been observed, which is mutually exclusive with onError.\nAdd upstream = CANCELED; to cleanup.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460278298", "createdAt": "2020-07-24T20:41:56Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng=="}, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM3NzMzMg==", "bodyText": "Well, that won't work. The spec is very particular about not allowing synchronous cancellation, even though concurrent cancellation should be supported by upstream. It is not \"just adding a check\". It is about synchronizing on two variables instead of just one, and the explosion of possible outcomes to bear in mind when proving a correct order of statements.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460377332", "createdAt": "2020-07-25T07:33:22Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyODA1Ng=="}, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjM3MDgzOnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODo1MDo0OVrOG26N7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxODo1MDo0OVrOG26N7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzMDEyNA==", "bodyText": "The bit masks shown here are not 100% accurate. The first time deferredInit is called the fourth bit may be set as 0b1111000..., 0b1011000... or 0b1101000.... That is, the first deferredInit is not necessarily after both onSubscribe and subscribe were called - so some of the bits may be zero.\nIt's a bit of a mouthful to explain fully, so maybe enough to refer to the .md file", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460230124", "createdAt": "2020-07-24T18:50:49Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 215}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjQwMTYzOnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOTowMTozN1rOG26hbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOTowMTozN1rOG26hbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzNTExOA==", "bodyText": "I think these must be moved to line 289: the cleanup must occur asap. Also, add nulling out to cleanup. Although the objects are small, let's be very clean about the promise to not retain objects for longer than necessary.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460235118", "createdAt": "2020-07-24T19:01:37Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;\n+        downstream = null; // after cleanup no uses of downstream are reachable\n+        cancelled = true; // after cleanup the processor appears as cancelled\n+        partsRequested.set(-1);\n         releaseChunks();\n+        parser.cleanup();\n     }\n \n-    private void releaseChunks() {\n-        Iterator<DataChunk> it = chunksByIds.values().iterator();\n-        while (it.hasNext()) {\n-            DataChunk next = it.next();\n-            next.release();\n-            it.remove();\n+    /**\n+     * Drain the upstream data if the contenders value is positive.\n+     */\n+    protected void drain() {\n+        // We do not serve the next part until the last chunk of the previous part has been consumed\n+        // (sent to inner Subscriber).\n+        // Signals to outer Subscriber are serialized with the signals to the inner Subscriber.\n+\n+        // drain() is a loop that retrieves ParserEvents one by one, and transitions to the next state,\n+        // unless waiting on the inner or outer subscriber.\n+\n+        // There are three ways to enter drain():\n+        // 1. We are not processing a part and an outer Subscriber has unsatisfied demand for parts\n+        // 2. We are processing a part and an inner Subscriber has unsatisfied demand for chunks of a part\n+        // 3. Upstream is delivering a DataChunk to satisfy the request from outer or inner Subscriber\n+        if (contenders.getAndIncrement() != 0) {\n+            return;\n         }\n+        drainLoop();\n     }\n \n-    private void drainPart(ReadableBodyPart part) {\n-        part.content().subscribe(new Subscriber<DataChunk>() {\n-            @Override\n-            public void onSubscribe(Subscription subscription) {\n-                subscription.request(Long.MAX_VALUE);\n+    /**\n+     * Drain the upstream data in a loop while the contenders value is positive.\n+     */\n+    protected void drainLoop() {\n+        for (int c = 1; c > 0; c = contenders.addAndGet(-c)) {\n+            drainBoth();\n+        }\n+    }\n+\n+    /**\n+     * Drain the upstream data and signal the given error.\n+     *\n+     * @param th the error to signal\n+     */\n+    protected void drain(Throwable th) {\n+        error = th;\n+        drain();\n+    }\n+\n+    /**\n+     * Drain upstream (raw) data and decoded downstream data.\n+     */\n+    protected void drainBoth() {\n+        if (bodyPartPublisher != null && !bodyPartPublisher.drain()) {\n+            return;\n+        }\n+\n+        try {\n+            // Proceed to drain parserIterator only if parts or body part chunks were requested\n+            // ie. bodyPartPublisher != null && partsRequested > 0\n+            // if bodyPartPublisher != null, then we are here when inner Subscriber has unsatisfied demand\n+            long requested = partsRequested();\n+            while (requested >= 0 && parserIterator.hasNext()) {\n+                // It is safe to consume next ParserEvent only the right Subscriber is ready to receive onNext\n+                // i.e partsRequested > 0\n+                if (requested == 0) {\n+                    // This means there was an attempt to deliver onError or onComplete from upstream\n+                    // which are allowed to be issued without request from outer Subscriber.\n+                    // - partsRequested > 0 for valid requests\n+                    // - partsRequested < 0 cancellation or invalid request\n+                    // we wait until demand has been manifested and parserIterator is drained\n+                    return;\n+                }\n+\n+                MimeParser.ParserEvent event = parserIterator.next();\n+                switch (event.type()) {\n+                    case START_PART:\n+                        bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n+                        bodyPartBuilder = ReadableBodyPart.builder();\n+                        break;\n+                    case HEADER:\n+                        MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n+                        bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n+                        break;\n+                    case END_HEADERS:\n+                        bodyPartPublisher = new DataChunkPublisher();\n+                        downstream.onNext(createPart());\n+                        // exit the parser iterator loop\n+                        // the parser events processing will resume upon inner Subscriber demand\n+                        return;\n+                    case BODY:\n+                        Iterator<BufferEntry> bodyIterator = event.asBodyEvent().body().iterator();\n+                        bodyPartPublisher.nextIterator(bodyIterator);\n+                        if (!bodyPartPublisher.drain()) {\n+                            // the body was not fully drained, exit the parser iterator loop\n+                            // the parser events processing will resume upon inner Subscriber demand\n+                            return;\n+                        }\n+                        break;\n+                    case END_PART:\n+                        bodyPartPublisher.complete(null);\n+                        bodyPartHeaderBuilder = null;\n+                        bodyPartBuilder = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 353}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjQyNjc1OnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOToxMDoyMFrOG26wyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQyMDo0Mjo0OFrOG29LYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTA1MA==", "bodyText": "There is a subtle race condition here. I'll propose a fix later.\n(In essence, Dekker idiom is needed - onError concurrent with drainBoth executed by, say, request - may set CANCELED before error, so drainBoth may see error is null, but after reaching this line also see CANCELED, and deliver onComplete)", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460239050", "createdAt": "2020-07-24T19:10:20Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;\n+        downstream = null; // after cleanup no uses of downstream are reachable\n+        cancelled = true; // after cleanup the processor appears as cancelled\n+        partsRequested.set(-1);\n         releaseChunks();\n+        parser.cleanup();\n     }\n \n-    private void releaseChunks() {\n-        Iterator<DataChunk> it = chunksByIds.values().iterator();\n-        while (it.hasNext()) {\n-            DataChunk next = it.next();\n-            next.release();\n-            it.remove();\n+    /**\n+     * Drain the upstream data if the contenders value is positive.\n+     */\n+    protected void drain() {\n+        // We do not serve the next part until the last chunk of the previous part has been consumed\n+        // (sent to inner Subscriber).\n+        // Signals to outer Subscriber are serialized with the signals to the inner Subscriber.\n+\n+        // drain() is a loop that retrieves ParserEvents one by one, and transitions to the next state,\n+        // unless waiting on the inner or outer subscriber.\n+\n+        // There are three ways to enter drain():\n+        // 1. We are not processing a part and an outer Subscriber has unsatisfied demand for parts\n+        // 2. We are processing a part and an inner Subscriber has unsatisfied demand for chunks of a part\n+        // 3. Upstream is delivering a DataChunk to satisfy the request from outer or inner Subscriber\n+        if (contenders.getAndIncrement() != 0) {\n+            return;\n         }\n+        drainLoop();\n     }\n \n-    private void drainPart(ReadableBodyPart part) {\n-        part.content().subscribe(new Subscriber<DataChunk>() {\n-            @Override\n-            public void onSubscribe(Subscription subscription) {\n-                subscription.request(Long.MAX_VALUE);\n+    /**\n+     * Drain the upstream data in a loop while the contenders value is positive.\n+     */\n+    protected void drainLoop() {\n+        for (int c = 1; c > 0; c = contenders.addAndGet(-c)) {\n+            drainBoth();\n+        }\n+    }\n+\n+    /**\n+     * Drain the upstream data and signal the given error.\n+     *\n+     * @param th the error to signal\n+     */\n+    protected void drain(Throwable th) {\n+        error = th;\n+        drain();\n+    }\n+\n+    /**\n+     * Drain upstream (raw) data and decoded downstream data.\n+     */\n+    protected void drainBoth() {\n+        if (bodyPartPublisher != null && !bodyPartPublisher.drain()) {\n+            return;\n+        }\n+\n+        try {\n+            // Proceed to drain parserIterator only if parts or body part chunks were requested\n+            // ie. bodyPartPublisher != null && partsRequested > 0\n+            // if bodyPartPublisher != null, then we are here when inner Subscriber has unsatisfied demand\n+            long requested = partsRequested();\n+            while (requested >= 0 && parserIterator.hasNext()) {\n+                // It is safe to consume next ParserEvent only the right Subscriber is ready to receive onNext\n+                // i.e partsRequested > 0\n+                if (requested == 0) {\n+                    // This means there was an attempt to deliver onError or onComplete from upstream\n+                    // which are allowed to be issued without request from outer Subscriber.\n+                    // - partsRequested > 0 for valid requests\n+                    // - partsRequested < 0 cancellation or invalid request\n+                    // we wait until demand has been manifested and parserIterator is drained\n+                    return;\n+                }\n+\n+                MimeParser.ParserEvent event = parserIterator.next();\n+                switch (event.type()) {\n+                    case START_PART:\n+                        bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n+                        bodyPartBuilder = ReadableBodyPart.builder();\n+                        break;\n+                    case HEADER:\n+                        MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n+                        bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n+                        break;\n+                    case END_HEADERS:\n+                        bodyPartPublisher = new DataChunkPublisher();\n+                        downstream.onNext(createPart());\n+                        // exit the parser iterator loop\n+                        // the parser events processing will resume upon inner Subscriber demand\n+                        return;\n+                    case BODY:\n+                        Iterator<BufferEntry> bodyIterator = event.asBodyEvent().body().iterator();\n+                        bodyPartPublisher.nextIterator(bodyIterator);\n+                        if (!bodyPartPublisher.drain()) {\n+                            // the body was not fully drained, exit the parser iterator loop\n+                            // the parser events processing will resume upon inner Subscriber demand\n+                            return;\n+                        }\n+                        break;\n+                    case END_PART:\n+                        bodyPartPublisher.complete(null);\n+                        bodyPartHeaderBuilder = null;\n+                        bodyPartBuilder = null;\n+                        bodyPartPublisher = null;\n+                        requested = partsRequested.updateAndGet(v -> v == Long.MAX_VALUE || v < 0 ? v : v - 1);\n+                        break;\n+                    default:\n+                }\n             }\n \n-            @Override\n-            public void onNext(DataChunk item) {\n-                item.release();\n+            // we allow requested <= 0 to reach here, because we want to allow delivery of termination signals\n+            // without requests or cancellations, but ultimately need to make sure we do not request from\n+            // upstream, unless actual demand is observed (requested > 0)\n+            if (requested < 0) {\n+                if (cancelled) {\n+                    upstream.cancel();\n+                    cleanup();\n+                    return;\n+                }\n+                // now is the right time to convert a bad request into an error\n+                // bodyPartPublisher is null, so this error gets delivered only to outer Subscriber\n+                error = new IllegalArgumentException(\"Expecting only positive requests for parts\");\n             }\n \n-            @Override\n-            public void onError(Throwable throwable) {\n+            // ordering the delivery of errors after the delivery of all signals that precede it\n+            // in the order of events emitted by the parser\n+            if (error != null) {\n+                if (bodyPartPublisher != null) {\n+                    bodyPartPublisher.complete(error);\n+                    bodyPartPublisher = null;\n+                }\n+                upstream.cancel();\n+                downstream.onError(error);\n+                cleanup();\n+                return;\n             }\n \n-            @Override\n-            public void onComplete() {\n+            // parserIterator is drained, drop the reference to it, but keep it safe for any later invocations\n+            parserIterator = EMPTY_PARSER_ITERATOR;\n+            if (upstream == SubscriptionHelper.CANCELED) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 397}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI3ODYyNQ==", "bodyText": "(With the change so that onError does not set upstream = CANCELED; the race condition disappears)", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460278625", "createdAt": "2020-07-24T20:42:48Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,229 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain(throwable);\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set (0b11100000)\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit (0b11110000)\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits (0b00000000)\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;\n+        downstream = null; // after cleanup no uses of downstream are reachable\n+        cancelled = true; // after cleanup the processor appears as cancelled\n+        partsRequested.set(-1);\n         releaseChunks();\n+        parser.cleanup();\n     }\n \n-    private void releaseChunks() {\n-        Iterator<DataChunk> it = chunksByIds.values().iterator();\n-        while (it.hasNext()) {\n-            DataChunk next = it.next();\n-            next.release();\n-            it.remove();\n+    /**\n+     * Drain the upstream data if the contenders value is positive.\n+     */\n+    protected void drain() {\n+        // We do not serve the next part until the last chunk of the previous part has been consumed\n+        // (sent to inner Subscriber).\n+        // Signals to outer Subscriber are serialized with the signals to the inner Subscriber.\n+\n+        // drain() is a loop that retrieves ParserEvents one by one, and transitions to the next state,\n+        // unless waiting on the inner or outer subscriber.\n+\n+        // There are three ways to enter drain():\n+        // 1. We are not processing a part and an outer Subscriber has unsatisfied demand for parts\n+        // 2. We are processing a part and an inner Subscriber has unsatisfied demand for chunks of a part\n+        // 3. Upstream is delivering a DataChunk to satisfy the request from outer or inner Subscriber\n+        if (contenders.getAndIncrement() != 0) {\n+            return;\n         }\n+        drainLoop();\n     }\n \n-    private void drainPart(ReadableBodyPart part) {\n-        part.content().subscribe(new Subscriber<DataChunk>() {\n-            @Override\n-            public void onSubscribe(Subscription subscription) {\n-                subscription.request(Long.MAX_VALUE);\n+    /**\n+     * Drain the upstream data in a loop while the contenders value is positive.\n+     */\n+    protected void drainLoop() {\n+        for (int c = 1; c > 0; c = contenders.addAndGet(-c)) {\n+            drainBoth();\n+        }\n+    }\n+\n+    /**\n+     * Drain the upstream data and signal the given error.\n+     *\n+     * @param th the error to signal\n+     */\n+    protected void drain(Throwable th) {\n+        error = th;\n+        drain();\n+    }\n+\n+    /**\n+     * Drain upstream (raw) data and decoded downstream data.\n+     */\n+    protected void drainBoth() {\n+        if (bodyPartPublisher != null && !bodyPartPublisher.drain()) {\n+            return;\n+        }\n+\n+        try {\n+            // Proceed to drain parserIterator only if parts or body part chunks were requested\n+            // ie. bodyPartPublisher != null && partsRequested > 0\n+            // if bodyPartPublisher != null, then we are here when inner Subscriber has unsatisfied demand\n+            long requested = partsRequested();\n+            while (requested >= 0 && parserIterator.hasNext()) {\n+                // It is safe to consume next ParserEvent only the right Subscriber is ready to receive onNext\n+                // i.e partsRequested > 0\n+                if (requested == 0) {\n+                    // This means there was an attempt to deliver onError or onComplete from upstream\n+                    // which are allowed to be issued without request from outer Subscriber.\n+                    // - partsRequested > 0 for valid requests\n+                    // - partsRequested < 0 cancellation or invalid request\n+                    // we wait until demand has been manifested and parserIterator is drained\n+                    return;\n+                }\n+\n+                MimeParser.ParserEvent event = parserIterator.next();\n+                switch (event.type()) {\n+                    case START_PART:\n+                        bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n+                        bodyPartBuilder = ReadableBodyPart.builder();\n+                        break;\n+                    case HEADER:\n+                        MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n+                        bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n+                        break;\n+                    case END_HEADERS:\n+                        bodyPartPublisher = new DataChunkPublisher();\n+                        downstream.onNext(createPart());\n+                        // exit the parser iterator loop\n+                        // the parser events processing will resume upon inner Subscriber demand\n+                        return;\n+                    case BODY:\n+                        Iterator<BufferEntry> bodyIterator = event.asBodyEvent().body().iterator();\n+                        bodyPartPublisher.nextIterator(bodyIterator);\n+                        if (!bodyPartPublisher.drain()) {\n+                            // the body was not fully drained, exit the parser iterator loop\n+                            // the parser events processing will resume upon inner Subscriber demand\n+                            return;\n+                        }\n+                        break;\n+                    case END_PART:\n+                        bodyPartPublisher.complete(null);\n+                        bodyPartHeaderBuilder = null;\n+                        bodyPartBuilder = null;\n+                        bodyPartPublisher = null;\n+                        requested = partsRequested.updateAndGet(v -> v == Long.MAX_VALUE || v < 0 ? v : v - 1);\n+                        break;\n+                    default:\n+                }\n             }\n \n-            @Override\n-            public void onNext(DataChunk item) {\n-                item.release();\n+            // we allow requested <= 0 to reach here, because we want to allow delivery of termination signals\n+            // without requests or cancellations, but ultimately need to make sure we do not request from\n+            // upstream, unless actual demand is observed (requested > 0)\n+            if (requested < 0) {\n+                if (cancelled) {\n+                    upstream.cancel();\n+                    cleanup();\n+                    return;\n+                }\n+                // now is the right time to convert a bad request into an error\n+                // bodyPartPublisher is null, so this error gets delivered only to outer Subscriber\n+                error = new IllegalArgumentException(\"Expecting only positive requests for parts\");\n             }\n \n-            @Override\n-            public void onError(Throwable throwable) {\n+            // ordering the delivery of errors after the delivery of all signals that precede it\n+            // in the order of events emitted by the parser\n+            if (error != null) {\n+                if (bodyPartPublisher != null) {\n+                    bodyPartPublisher.complete(error);\n+                    bodyPartPublisher = null;\n+                }\n+                upstream.cancel();\n+                downstream.onError(error);\n+                cleanup();\n+                return;\n             }\n \n-            @Override\n-            public void onComplete() {\n+            // parserIterator is drained, drop the reference to it, but keep it safe for any later invocations\n+            parserIterator = EMPTY_PARSER_ITERATOR;\n+            if (upstream == SubscriptionHelper.CANCELED) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIzOTA1MA=="}, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 397}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg3MjQ1MTY2OnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOToxOTozNFrOG27AhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxOToxOTozNFrOG27AhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI0MzA3Nw==", "bodyText": "Move to line 471 and change the condition to:\nif (chunksRequested.get() < 0 && !cancelled && th == null) {\n   th = new IllegalArgumentException(\"Expecting only positive requests for content\");\n}\n\n(Because currently a cancel concurrent with complete will not be distinguishable from bad request)", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r460243077", "createdAt": "2020-07-24T19:19:34Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -247,85 +392,148 @@ private BodyPartChunk createPartChunk(BufferEntry entry) {\n             throw new IllegalStateException(\"Parent chunk not found, id=\" + id);\n         }\n         ByteBuffer[] originalBuffers = chunk.data();\n+        // FIXME: the current resource management is not implemented properly and needs to be fixed\n         boolean release = data.limit() == originalBuffers[originalBuffers.length - 1].limit();\n         if (release) {\n             chunksByIds.remove(id);\n         }\n         return new BodyPartChunk(data, release ? chunk : null);\n     }\n \n-    private final class ParserEventProcessor implements MimeParser.EventProcessor {\n+    /**\n+     * Inner publisher that publishes the body part as {@link DataChunk}.\n+     */\n+    protected final class DataChunkPublisher implements Publisher<DataChunk> {\n \n-        private MimeParser.ParserEvent lastEvent = null;\n+        private final AtomicLong chunksRequested = new AtomicLong(Long.MIN_VALUE + 1);\n+        private Iterator<BufferEntry> bufferEntryIterator = EMPTY_BUFFER_ENTRY_ITERATOR;\n+        private boolean cancelled;\n+        private Subscriber<? super DataChunk> subscriber;\n \n         @Override\n-        public void process(MimeParser.ParserEvent event) {\n-            MimeParser.EventType eventType = event.type();\n-            switch (eventType) {\n-                case START_PART:\n-                    bodyPartPublisher = BufferedEmittingPublisher.create();\n-                    bodyPartHeaderBuilder = ReadableBodyPartHeaders.builder();\n-                    bodyPartBuilder = ReadableBodyPart.builder();\n-                    break;\n-                case HEADER:\n-                    MimeParser.HeaderEvent headerEvent = event.asHeaderEvent();\n-                    bodyPartHeaderBuilder.header(headerEvent.name(), headerEvent.value());\n-                    break;\n-                case END_HEADERS:\n-                    bodyParts.add(createPart());\n-                    break;\n-                case CONTENT:\n-                    bodyPartPublisher.emit(createPartChunk(event.asContentEvent().content()));\n-                    break;\n-                case END_PART:\n-                    bodyPartPublisher.complete();\n-                    bodyPartPublisher = null;\n-                    bodyPartHeaderBuilder = null;\n-                    bodyPartBuilder = null;\n-                    break;\n-                default:\n-                // nothing to do\n+        public void subscribe(Subscriber<? super DataChunk> sub) {\n+            if (!chunksRequested.compareAndSet(Long.MIN_VALUE + 1, Long.MIN_VALUE)) {\n+                Multi.<DataChunk>error(new IllegalStateException(\"Only one Subscriber allowed\"))\n+                     .subscribe(subscriber);\n+                return;\n+            }\n+\n+            subscriber = sub;\n+            sub.onSubscribe(new Subscription() {\n+\n+                @Override\n+                public void request(long n) {\n+                    // Illegal n makes chunksRequested negative, which interacts with drain() to drain the\n+                    // entire bufferEntryIterator, and signal onError\n+                    long curr = n <= 0\n+                                ? chunksRequested.getAndSet(-1)\n+                                : chunksRequested.getAndUpdate(v -> Long.MAX_VALUE - v > n\n+                                ? v + n : v < 0 ? v == Long.MIN_VALUE ? n : v : Long.MAX_VALUE);\n+                    if (curr == 0) {\n+                        MultiPartDecoder.this.drain();\n+                    }\n+                }\n+\n+                @Override\n+                public void cancel() {\n+                    cancelled = true;\n+                    // Ensure the part chunks are drained to make the next part available\n+                    if (chunksRequested.getAndSet(-1) == 0) {\n+                        MultiPartDecoder.this.drain();\n+                    }\n+                }\n+            });\n+\n+            if (chunksRequested.compareAndSet(Long.MIN_VALUE, 0)) {\n+                return;\n             }\n-            lastEvent = event;\n+            MultiPartDecoder.this.drain();\n         }\n \n         /**\n-         * Indicate if the parser has received any data.\n-         *\n-         * @return {@code true} if the parser has been offered data,\n-         * {@code false} otherwise\n+         * Set the next buffer entry iterator.\n+         * @param iterator the iterator to set\n          */\n-        boolean isStarted() {\n-            return lastEvent != null;\n+        void nextIterator(Iterator<BufferEntry> iterator) {\n+            // This is invoked only when the previous bufferEntryIterator has been consumed fully,\n+            // and chunksRequested > 0, so no one is calling drain() concurrently\n+            // chunksRequested is modified atomically, so any future invocation of drain() will observe\n+            // bufferEntryIterator normal store (bufferEntryIterator and all of its content is published safely)\n+            bufferEntryIterator = iterator;\n         }\n \n         /**\n-         * Indicate if the parser has reached the end of the message.\n+         * Complete the publisher.\n          *\n-         * @return {@code true} if completed, {@code false} otherwise\n+         * @param th throwable, if not {@code null} signals {@code onError}, otherwise signals {@code onComplete}\n          */\n-        boolean isCompleted() {\n-            return lastEvent.type() == MimeParser.EventType.END_MESSAGE;\n+        void complete(Throwable th) {\n+            if (cancelled) {\n+                subscriber = null;\n+                return;\n+            }\n+            cancelled = true;\n+\n+            // bufferEntryIterator is drained because complete() is invoked only by drain() which proceeds past\n+            // state == BODY only when drain() returned true\n+            if (th != null) {\n+                subscriber.onError(th);\n+            } else if (chunksRequested.get() < 0) {\n+                subscriber.onError(new IllegalArgumentException(\"Expecting only positive requests\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "642c2f25d7927a8e6977491cb54ec6fb1a3c39a9"}, "originalPosition": 559}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MDk5OTY1OnYy", "diffSide": "RIGHT", "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMDozODoyNVrOG4GzaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxMDozODoyNVrOG4GzaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTQ4NDkwNQ==", "bodyText": "I apologise I didn't make the comment\n\nAdd upstream = CANCELED; to cleanup\n\nclearer and forgot to add it in the onError synchronization fixup.\nPlease, add upstream = CANCELED somewhere here to drop references to upstream.", "url": "https://github.com/oracle/helidon/pull/2193#discussion_r461484905", "createdAt": "2020-07-28T10:38:25Z", "author": {"login": "olotenko"}, "path": "media/multipart/src/main/java/io/helidon/media/multipart/MultiPartDecoder.java", "diffHunk": "@@ -106,120 +142,231 @@ public void onNext(DataChunk chunk) {\n                 int id = parser.offer(byteBuffers[i]);\n                 // record the chunk using the id of the last buffer\n                 if (i == byteBuffers.length - 1) {\n+                    // drain() cannot be invoked concurrently, it is safe to use HashMap\n                     chunksByIds.put(id, chunk);\n                 }\n             }\n-            parser.parse();\n+            parserIterator = parser.parseIterator();\n+            drain();\n         } catch (MimeParser.ParsingException ex) {\n-            emitter.fail(ex);\n-            chunk.release();\n-            releaseChunks();\n-        }\n-\n-        // submit parsed parts\n-        while (!bodyParts.isEmpty()) {\n-            if (emitter.isCancelled()) {\n-                return;\n-            }\n-            emitter.emit(bodyParts.poll());\n-        }\n-\n-        // complete the parts publisher\n-        if (parserEventProcessor.isCompleted()) {\n-            emitter.complete();\n-            // parts are delivered sequentially\n-            // we potentially drop the last part if not requested\n-            emitter.clearBuffer(this::drainPart);\n-            releaseChunks();\n-        }\n-\n-        // request more data to detect the next part\n-        // if not in the middle of a part content\n-        // or if the part content subscriber needs more\n-        if (upstream != SubscriptionHelper.CANCELED\n-                && emitter.hasRequests()\n-                && parserEventProcessor.isDataRequired()\n-                && (!parserEventProcessor.isContentDataRequired() || bodyPartPublisher.hasRequests())) {\n-\n-            upstream.request(1);\n+            drain(ex);\n         }\n     }\n \n     @Override\n     public void onError(Throwable throwable) {\n         Objects.requireNonNull(throwable);\n-        initFuture.whenComplete((e, t) -> e.fail(throwable));\n+        error = throwable;\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n     }\n \n     @Override\n     public void onComplete() {\n-        initFuture.whenComplete((e, t) -> {\n-            if (upstream != SubscriptionHelper.CANCELED) {\n-                upstream = SubscriptionHelper.CANCELED;\n-                try {\n-                    parser.close();\n-                } catch (MimeParser.ParsingException ex) {\n-                    emitter.fail(ex);\n-                    releaseChunks();\n-                }\n-            }\n-        });\n+        if (upstream != SubscriptionHelper.CANCELED) {\n+            upstream = SubscriptionHelper.CANCELED;\n+            drain();\n+        }\n+    }\n+\n+    private boolean halfInit(int mask) {\n+        // Attempts to set the given init mask, if contenders is in the right state for that, and\n+        // reports whether the contenders was in a state where that part of init needed completing.\n+        int c = contenders.getAndUpdate(v -> v < 0 ? v | mask : v);\n+        return c < 0 && (c & mask) == 0;\n     }\n \n     private void deferredInit() {\n-        if (upstream != null && downstream != null) {\n-            emitter = BufferedEmittingPublisher.create();\n-            emitter.onRequest(this::onPartRequest);\n-            emitter.onEmit(this::drainPart);\n-            //emitter.onCancel(this::onPartCancel);\n-            emitter.subscribe(downstream);\n-            initFuture.complete(emitter);\n-            downstream = null;\n+        // deferredInit is invoked twice: onSubscribe and subscribe\n+        // after onSubscribe and subscribe three top bits are set\n+        // adding SUBSCRIPTION_LOCK for the first time sets the fourth bit\n+        // adding SUBSCRIPTION_LOCK for the second time clears all top bits\n+        // making the contenders counter 0,\n+        // unless there were onError, onComplete, request for parts or downstream cancellation\n+        if (contenders.addAndGet(SUBSCRIPTION_LOCK) > 0) {\n+            drainLoop();\n         }\n     }\n \n-    private void onPartRequest(long requested, long total) {\n-        // require more raw chunks to decode if the decoding has not\n-        // yet started or if more data is required to make progress\n-        if (!parserEventProcessor.isStarted() || parserEventProcessor.isDataRequired()) {\n-            upstream.request(1);\n-        }\n+    private long partsRequested() {\n+        // Returns a negative number, if we are serving outer Subscriber, and we can tell it may\n+        // not issue more requests for parts: either cancelled, or a bad request was observed.\n+        // Otherwise returns a positive number, if serving inner Subscriber, or actual partsRequested.\n+        return bodyPartPublisher != null ? 1 : partsRequested.get();\n     }\n \n-    private void onPartCancel() {\n-        emitter.clearBuffer(this::drainPart);\n+    private void cleanup() {\n+        // drop the reference to parserIterator, but keep it safe for any later invocation of parserIterator\n+        parserIterator = EMPTY_PARSER_ITERATOR;\n+        error = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b1248af3d1283bcc327e823861e1e4ed6bb886d6"}, "originalPosition": 243}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 465, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}