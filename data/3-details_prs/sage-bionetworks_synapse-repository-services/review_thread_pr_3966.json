{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0MDMwMzI2", "number": 3966, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoxNTo0NlrODl7fQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDozMzoyM1rODl7w5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxMDk4NTYzOnYy", "diffSide": "RIGHT", "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoxNTo0NlrOFzGJ8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMzo0NDo1OVrOFzKoUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMjU0Ng==", "bodyText": "Try prefix includes the trailing delimiter, so we don't need that weird if statement.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389122546", "createdAt": "2020-03-06T20:15:46Z", "author": {"login": "DwayneJengSage"}, "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "diffHunk": "@@ -0,0 +1,175 @@\n+package org.sagebionetworks.sample.sts;\n+\n+import com.amazonaws.services.s3.AmazonS3;\n+import com.amazonaws.services.s3.model.ListObjectsRequest;\n+import com.amazonaws.services.s3.model.ObjectListing;\n+import com.amazonaws.services.s3.model.S3Object;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.codec.digest.DigestUtils;\n+import org.sagebionetworks.client.SynapseClient;\n+import org.sagebionetworks.client.exceptions.SynapseException;\n+import org.sagebionetworks.repo.model.FileEntity;\n+import org.sagebionetworks.repo.model.Folder;\n+import org.sagebionetworks.repo.model.file.S3FileHandle;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class MigrateS3Bucket {\n+\tprivate static final String DELIMITER = \"/\";\n+\n+\tprivate final DigestUtils md5DigestUtils;\n+\tprivate final AmazonS3 s3Client;\n+\tprivate final String s3Bucket;\n+\tprivate final String s3Folder;\n+\tprivate final long storageLocationId;\n+\tprivate final SynapseClient synapseClient;\n+\tprivate final String synapseFolderId;\n+\n+\tpublic MigrateS3Bucket(AmazonS3 s3Client, SynapseClient synapseClient, String s3Bucket, String s3Folder,\n+\t\t\tString synapseFolderId, long storageLocationId) {\n+\t\t// Init MD5 digest utils.\n+\t\tthis.md5DigestUtils = new DigestUtils(DigestUtils.getMd5Digest());\n+\n+\t\tthis.s3Client = s3Client;\n+\t\tthis.synapseClient = synapseClient;\n+\n+\t\t// This is the S3 bucket and folder that we migrate from. If folder is null, we import all files in the S3\n+\t\t// bucket.\n+\t\tthis.s3Bucket = s3Bucket;\n+\t\tthis.s3Folder = s3Folder;\n+\n+\t\t// This is the entity ID of the folder in Synapse to which we migrate the S3 files. This folder must have an\n+\t\t// external S3 storage location with STS-enabled, as described in\n+\t\t// https://docs.synapse.org/articles/sts_storage_locations.html\n+\t\tthis.synapseFolderId = synapseFolderId;\n+\n+\t\t// This is the storage location ID that is set on the Synapse folder.\n+\t\tthis.storageLocationId = storageLocationId;\n+\t}\n+\n+\t/** Executes the migration. */\n+\tpublic void execute() throws IOException, SynapseException {\n+\t\texecuteForSubfolder(s3Folder, synapseFolderId);\n+\t}\n+\n+\t/**\n+\t * Helper method to recursively walk the S3 folder hierarchy and migrate files to the given Synapse folder.\n+\t * When this method makes a recursive call, it will update s3SubFolder to the next folder and it will create\n+\t * a Synapse folder in which to migrate S3 files.\n+\t *\n+\t * @param s3SubFolder\n+\t *         the S3 subfolder from which we migrate files; if this is null then we export from the S3 bucket root\n+\t * @param synapseSubFolderId\n+\t *         the Synapse folder to which we migrate the S3 files\n+\t */\n+\tprivate void executeForSubfolder(String s3SubFolder, String synapseSubFolderId) throws IOException,\n+\t\t\tSynapseException {\n+\t\tListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(s3Bucket)\n+\t\t\t\t.withPrefix(s3SubFolder).withDelimiter(DELIMITER);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE3MTY1Mg==", "bodyText": "I don't know what I did wrong when I first tested this, but apparently I don't need to filter out the subfolder at all.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389171652", "createdAt": "2020-03-06T22:18:57Z", "author": {"login": "DwayneJengSage"}, "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "diffHunk": "@@ -0,0 +1,175 @@\n+package org.sagebionetworks.sample.sts;\n+\n+import com.amazonaws.services.s3.AmazonS3;\n+import com.amazonaws.services.s3.model.ListObjectsRequest;\n+import com.amazonaws.services.s3.model.ObjectListing;\n+import com.amazonaws.services.s3.model.S3Object;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.codec.digest.DigestUtils;\n+import org.sagebionetworks.client.SynapseClient;\n+import org.sagebionetworks.client.exceptions.SynapseException;\n+import org.sagebionetworks.repo.model.FileEntity;\n+import org.sagebionetworks.repo.model.Folder;\n+import org.sagebionetworks.repo.model.file.S3FileHandle;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class MigrateS3Bucket {\n+\tprivate static final String DELIMITER = \"/\";\n+\n+\tprivate final DigestUtils md5DigestUtils;\n+\tprivate final AmazonS3 s3Client;\n+\tprivate final String s3Bucket;\n+\tprivate final String s3Folder;\n+\tprivate final long storageLocationId;\n+\tprivate final SynapseClient synapseClient;\n+\tprivate final String synapseFolderId;\n+\n+\tpublic MigrateS3Bucket(AmazonS3 s3Client, SynapseClient synapseClient, String s3Bucket, String s3Folder,\n+\t\t\tString synapseFolderId, long storageLocationId) {\n+\t\t// Init MD5 digest utils.\n+\t\tthis.md5DigestUtils = new DigestUtils(DigestUtils.getMd5Digest());\n+\n+\t\tthis.s3Client = s3Client;\n+\t\tthis.synapseClient = synapseClient;\n+\n+\t\t// This is the S3 bucket and folder that we migrate from. If folder is null, we import all files in the S3\n+\t\t// bucket.\n+\t\tthis.s3Bucket = s3Bucket;\n+\t\tthis.s3Folder = s3Folder;\n+\n+\t\t// This is the entity ID of the folder in Synapse to which we migrate the S3 files. This folder must have an\n+\t\t// external S3 storage location with STS-enabled, as described in\n+\t\t// https://docs.synapse.org/articles/sts_storage_locations.html\n+\t\tthis.synapseFolderId = synapseFolderId;\n+\n+\t\t// This is the storage location ID that is set on the Synapse folder.\n+\t\tthis.storageLocationId = storageLocationId;\n+\t}\n+\n+\t/** Executes the migration. */\n+\tpublic void execute() throws IOException, SynapseException {\n+\t\texecuteForSubfolder(s3Folder, synapseFolderId);\n+\t}\n+\n+\t/**\n+\t * Helper method to recursively walk the S3 folder hierarchy and migrate files to the given Synapse folder.\n+\t * When this method makes a recursive call, it will update s3SubFolder to the next folder and it will create\n+\t * a Synapse folder in which to migrate S3 files.\n+\t *\n+\t * @param s3SubFolder\n+\t *         the S3 subfolder from which we migrate files; if this is null then we export from the S3 bucket root\n+\t * @param synapseSubFolderId\n+\t *         the Synapse folder to which we migrate the S3 files\n+\t */\n+\tprivate void executeForSubfolder(String s3SubFolder, String synapseSubFolderId) throws IOException,\n+\t\t\tSynapseException {\n+\t\tListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(s3Bucket)\n+\t\t\t\t.withPrefix(s3SubFolder).withDelimiter(DELIMITER);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMjU0Ng=="}, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE5NTg1Ng==", "bodyText": "The documentation I found is inconclusive on this. On one side the official docs (https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/model/ListObjectsRequest.html) seems to suggest that the delimiter is needed in the prefix to get our expected results but others suggest the behavior you reported initially. If I'm not wrong when you create a \"folder\" through the AWS console, AWS automatically adds a key named as the folder. The build is green so I'm guessing it's not an issue.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389195856", "createdAt": "2020-03-06T23:44:59Z", "author": {"login": "marcomarasca"}, "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "diffHunk": "@@ -0,0 +1,175 @@\n+package org.sagebionetworks.sample.sts;\n+\n+import com.amazonaws.services.s3.AmazonS3;\n+import com.amazonaws.services.s3.model.ListObjectsRequest;\n+import com.amazonaws.services.s3.model.ObjectListing;\n+import com.amazonaws.services.s3.model.S3Object;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.codec.digest.DigestUtils;\n+import org.sagebionetworks.client.SynapseClient;\n+import org.sagebionetworks.client.exceptions.SynapseException;\n+import org.sagebionetworks.repo.model.FileEntity;\n+import org.sagebionetworks.repo.model.Folder;\n+import org.sagebionetworks.repo.model.file.S3FileHandle;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class MigrateS3Bucket {\n+\tprivate static final String DELIMITER = \"/\";\n+\n+\tprivate final DigestUtils md5DigestUtils;\n+\tprivate final AmazonS3 s3Client;\n+\tprivate final String s3Bucket;\n+\tprivate final String s3Folder;\n+\tprivate final long storageLocationId;\n+\tprivate final SynapseClient synapseClient;\n+\tprivate final String synapseFolderId;\n+\n+\tpublic MigrateS3Bucket(AmazonS3 s3Client, SynapseClient synapseClient, String s3Bucket, String s3Folder,\n+\t\t\tString synapseFolderId, long storageLocationId) {\n+\t\t// Init MD5 digest utils.\n+\t\tthis.md5DigestUtils = new DigestUtils(DigestUtils.getMd5Digest());\n+\n+\t\tthis.s3Client = s3Client;\n+\t\tthis.synapseClient = synapseClient;\n+\n+\t\t// This is the S3 bucket and folder that we migrate from. If folder is null, we import all files in the S3\n+\t\t// bucket.\n+\t\tthis.s3Bucket = s3Bucket;\n+\t\tthis.s3Folder = s3Folder;\n+\n+\t\t// This is the entity ID of the folder in Synapse to which we migrate the S3 files. This folder must have an\n+\t\t// external S3 storage location with STS-enabled, as described in\n+\t\t// https://docs.synapse.org/articles/sts_storage_locations.html\n+\t\tthis.synapseFolderId = synapseFolderId;\n+\n+\t\t// This is the storage location ID that is set on the Synapse folder.\n+\t\tthis.storageLocationId = storageLocationId;\n+\t}\n+\n+\t/** Executes the migration. */\n+\tpublic void execute() throws IOException, SynapseException {\n+\t\texecuteForSubfolder(s3Folder, synapseFolderId);\n+\t}\n+\n+\t/**\n+\t * Helper method to recursively walk the S3 folder hierarchy and migrate files to the given Synapse folder.\n+\t * When this method makes a recursive call, it will update s3SubFolder to the next folder and it will create\n+\t * a Synapse folder in which to migrate S3 files.\n+\t *\n+\t * @param s3SubFolder\n+\t *         the S3 subfolder from which we migrate files; if this is null then we export from the S3 bucket root\n+\t * @param synapseSubFolderId\n+\t *         the Synapse folder to which we migrate the S3 files\n+\t */\n+\tprivate void executeForSubfolder(String s3SubFolder, String synapseSubFolderId) throws IOException,\n+\t\t\tSynapseException {\n+\t\tListObjectsRequest listObjectsRequest = new ListObjectsRequest().withBucketName(s3Bucket)\n+\t\t\t\t.withPrefix(s3SubFolder).withDelimiter(DELIMITER);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyMjU0Ng=="}, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxMTAwMTY4OnYy", "diffSide": "RIGHT", "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyMTo1M1rOFzGUAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyMTo1M1rOFzGUAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyNTEyMg==", "bodyText": "Only the storage location owner can import files from S3.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389125122", "createdAt": "2020-03-06T20:21:53Z", "author": {"login": "DwayneJengSage"}, "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateS3Bucket.java", "diffHunk": "@@ -0,0 +1,175 @@\n+package org.sagebionetworks.sample.sts;\n+\n+import com.amazonaws.services.s3.AmazonS3;\n+import com.amazonaws.services.s3.model.ListObjectsRequest;\n+import com.amazonaws.services.s3.model.ObjectListing;\n+import com.amazonaws.services.s3.model.S3Object;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.codec.digest.DigestUtils;\n+import org.sagebionetworks.client.SynapseClient;\n+import org.sagebionetworks.client.exceptions.SynapseException;\n+import org.sagebionetworks.repo.model.FileEntity;\n+import org.sagebionetworks.repo.model.Folder;\n+import org.sagebionetworks.repo.model.file.S3FileHandle;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class MigrateS3Bucket {\n+\tprivate static final String DELIMITER = \"/\";\n+\n+\tprivate final DigestUtils md5DigestUtils;\n+\tprivate final AmazonS3 s3Client;\n+\tprivate final String s3Bucket;\n+\tprivate final String s3Folder;\n+\tprivate final long storageLocationId;\n+\tprivate final SynapseClient synapseClient;\n+\tprivate final String synapseFolderId;\n+\n+\tpublic MigrateS3Bucket(AmazonS3 s3Client, SynapseClient synapseClient, String s3Bucket, String s3Folder,\n+\t\t\tString synapseFolderId, long storageLocationId) {\n+\t\t// Init MD5 digest utils.\n+\t\tthis.md5DigestUtils = new DigestUtils(DigestUtils.getMd5Digest());\n+\n+\t\tthis.s3Client = s3Client;\n+\t\tthis.synapseClient = synapseClient;\n+\n+\t\t// This is the S3 bucket and folder that we migrate from. If folder is null, we import all files in the S3\n+\t\t// bucket.\n+\t\tthis.s3Bucket = s3Bucket;\n+\t\tthis.s3Folder = s3Folder;\n+\n+\t\t// This is the entity ID of the folder in Synapse to which we migrate the S3 files. This folder must have an\n+\t\t// external S3 storage location with STS-enabled, as described in\n+\t\t// https://docs.synapse.org/articles/sts_storage_locations.html\n+\t\tthis.synapseFolderId = synapseFolderId;\n+\n+\t\t// This is the storage location ID that is set on the Synapse folder.\n+\t\tthis.storageLocationId = storageLocationId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxMTAxNTQyOnYy", "diffSide": "RIGHT", "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateSynapseProject.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyNzowNFrOFzGcqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyNzowNFrOFzGcqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyNzMzOA==", "bodyText": "Inline the constant for readability for sample code.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389127338", "createdAt": "2020-03-06T20:27:04Z", "author": {"login": "DwayneJengSage"}, "path": "client/sample-code/src/main/java/org/sagebionetworks/sample/sts/MigrateSynapseProject.java", "diffHunk": "@@ -0,0 +1,131 @@\n+package org.sagebionetworks.sample.sts;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.io.Files;\n+import org.sagebionetworks.client.SynapseClient;\n+import org.sagebionetworks.client.exceptions.SynapseException;\n+import org.sagebionetworks.repo.model.Entity;\n+import org.sagebionetworks.repo.model.EntityChildrenRequest;\n+import org.sagebionetworks.repo.model.EntityChildrenResponse;\n+import org.sagebionetworks.repo.model.EntityHeader;\n+import org.sagebionetworks.repo.model.EntityType;\n+import org.sagebionetworks.repo.model.FileEntity;\n+import org.sagebionetworks.repo.model.Folder;\n+import org.sagebionetworks.repo.model.file.FileHandle;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+\n+public class MigrateSynapseProject {\n+\tprivate static final List<EntityType> CHILD_ENTITY_TYPE_LIST = ImmutableList.of(EntityType.file,\n+\t\t\tEntityType.folder);\n+\n+\tprivate final String destinationFolderId;\n+\tprivate final long destinationStorageLocationId;\n+\tprivate final String sourceEntityId;\n+\tprivate final SynapseClient synapseClient;\n+\tprivate final File tmpDir;\n+\n+\tpublic MigrateSynapseProject(SynapseClient synapseClient, String sourceEntityId, String destinationFolderId,\n+\t\t\tlong destinationStorageLocationId) {\n+\t\tthis.synapseClient = synapseClient;\n+\n+\t\t// This is the Synapse entity from which you want to migrate data. This can be a project or a folder.\n+\t\tthis.sourceEntityId = sourceEntityId;\n+\n+\t\t// This is the entity ID of the folder in Synapse to which we migrate the S3 files. This folder must have an\n+\t\t// external S3 storage location with STS-enabled, as described in\n+\t\t// https://docs.synapse.org/articles/sts_storage_locations.html\n+\t\tthis.destinationFolderId = destinationFolderId;\n+\n+\t\t// This is the storage location ID that is set on the Synapse folder.\n+\t\tthis.destinationStorageLocationId = destinationStorageLocationId;\n+\n+\t\t// Temporary directory to store downloaded files.\n+\t\ttmpDir = Files.createTempDir();\n+\t}\n+\n+\t/** Executes the migration. */\n+\tpublic void execute() throws IOException, SynapseException {\n+\t\texecuteForSubfolder(sourceEntityId, destinationFolderId);\n+\n+\t\ttmpDir.delete();\n+\t}\n+\n+\t/**\n+\t * Helper method to recursively walk the source folder hierarchy and migrate files to the given destination folder.\n+\t * When this method makes a recursive call, it will update sourceSubFolderId to the next folder and it will create\n+\t * a destination folder in which to migrate files.\n+\t *\n+\t * @param sourceSubFolderId\n+\t *         the subfolder from which we migrate files\n+\t * @param destinationSubFolderId\n+\t *         the folder to which we migrate the files\n+\t */\n+\tprivate void executeForSubfolder(String sourceSubFolderId, String destinationSubFolderId) throws IOException,\n+\t\t\tSynapseException {\n+\t\tEntityChildrenRequest entityChildrenRequest = new EntityChildrenRequest();\n+\t\tentityChildrenRequest.setParentId(sourceSubFolderId);\n+\t\tentityChildrenRequest.setIncludeTypes(CHILD_ENTITY_TYPE_LIST);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxMTAyMTc2OnYy", "diffSide": "RIGHT", "path": "integration-test/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyOToyM1rOFzGgwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDoyOToyM1rOFzGgwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyODM4NQ==", "bodyText": "The version should be in the root pom.xml under dependencyManagement.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389128385", "createdAt": "2020-03-06T20:29:23Z", "author": {"login": "DwayneJengSage"}, "path": "integration-test/pom.xml", "diffHunk": "@@ -269,6 +269,12 @@\n \t\t\t<scope>test</scope>\n \t\t</dependency>\n \n+\t\t<dependency>\n+\t\t\t<groupId>org.sagebionetworks</groupId>\n+\t\t\t<artifactId>sample-code</artifactId>\n+\t\t\t<version>develop-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxMTAzMDc3OnYy", "diffSide": "RIGHT", "path": "integration-test/src/test/java/org/sagebionetworks/ITStorageLocation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDozMzoyM1rOFzGmpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQyMDozMzoyM1rOFzGmpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTEyOTg5Mg==", "bodyText": "Make a comment in the sample code that we migrate owner.txt. You can add a check to prevent this.", "url": "https://github.com/Sage-Bionetworks/Synapse-Repository-Services/pull/3966#discussion_r389129892", "createdAt": "2020-03-06T20:33:23Z", "author": {"login": "DwayneJengSage"}, "path": "integration-test/src/test/java/org/sagebionetworks/ITStorageLocation.java", "diffHunk": "@@ -196,7 +221,150 @@ public void synapseS3StorageLocationWithSts() throws SynapseException {\n \n \t\ttestStsStorageLocation(synapseS3StorageLocationSetting);\n \t}\n-\t\n+\n+\t@Test\n+\tpublic void sampleCode_MigrateS3Bucket() throws Exception {\n+\t\t// Create external S3 storage location with STS.\n+\t\tExternalS3StorageLocationSetting externalS3StorageLocationSetting = createExternalS3StorageLocation();\n+\t\texternalS3StorageLocationSetting.setStsEnabled(true);\n+\t\texternalS3StorageLocationSetting = synapse.createStorageLocationSetting(externalS3StorageLocationSetting);\n+\t\tapplyStorageLocationToFolder(externalS3StorageLocationSetting);\n+\n+\t\t// Create some test data to migrate\n+\t\t// baseKey/f1\n+\t\t// baseKey/f2\n+\t\t// baseKey/a/f3\n+\t\t// baseKey/a/f4\n+\t\t// baseKey/a/b/c/f5\n+\t\t// baseKey/a/b/c/f6\n+\t\tString baseKey = externalS3StorageLocationSetting.getBaseKey();\n+\t\tuploadToExternalS3Bucket(baseKey, \"f1\", \"sample content 1\");\n+\t\tuploadToExternalS3Bucket(baseKey, \"f2\", \"sample content 2\");\n+\t\tuploadToExternalS3Bucket(baseKey + \"/a\", \"f3\", \"sample content 3\");\n+\t\tuploadToExternalS3Bucket(baseKey + \"/a\", \"f4\", \"sample content 4\");\n+\t\tuploadToExternalS3Bucket(baseKey + \"/a/b/c\", \"f5\", \"sample content 5\");\n+\t\tuploadToExternalS3Bucket(baseKey + \"/a/b/c\", \"f6\", \"sample content 6\");\n+\n+\t\t// Run sample code.\n+\t\tMigrateS3Bucket migration = new MigrateS3Bucket(synapseS3Client.getUSStandardAmazonClient(), synapse,\n+\t\t\t\texternalS3Bucket, baseKey, folder.getId(), externalS3StorageLocationSetting.getStorageLocationId());\n+\t\tmigration.execute();\n+\n+\t\t// Verify results.\n+\t\t// Get files in baseKey (f1, f2, and owner.txt).\n+\t\tMap<String, EntityHeader> childrenByName = getChildren(folder.getId(), EntityType.file);\n+\t\tassertEquals(3, childrenByName.size());\n+\t\tassertTrue(childrenByName.containsKey(\"f1\"));\n+\t\tassertTrue(childrenByName.containsKey(\"f2\"));\n+\t\tassertTrue(childrenByName.containsKey(\"owner.txt\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71b908bcf7f9c154994a46e4b9879edbdf25c28d"}, "originalPosition": 152}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3141, "cost": 1, "resetAt": "2021-11-12T12:57:47Z"}}}