{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEzMDM0MzQz", "number": 4769, "title": "Issue 4676: (PDP-34 ) - Part 3 of 4 - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.", "bodyText": "Issue 4676: (PDP-34) Initial Implementation (Part 1 of 4) - Core functionality.\nSigned-off-by: Sachin Joshi sachin.joshi@emc.com\nChange log description\n\nInitial implementation of PDP 34.\nTableBasedMetatadataStore that stores storage metadata in table segments.\nModifying storage factory interface.\nUpdated initialization sequence in StreamSegmentContainer\nNew config values\nEnd to end integration tests.\n\nPurpose of the change\nFixes #4676 - Initial implementation of PDP -34\nWhat the code does\nDesign :\n\nThis PR implements core parts of following design.  https://github.com/pravega/pravega/wiki/PDP-34:-Simplified-Tier-2\n\nGeneral Comments:\n\nThe code is added in a manner so that older AsyncStorage+Sync based code continues to work. Reusing and refactoring code wherever possible.\n\nPart 3 of 4 PRs :\n\nCore implementation.\nChunkStorageProvider implementation for HDFS, ECS and FileSystem\nThis PR Table segment based metadata store,  container bootstrap logic.  end to end integration tests.\nChanges for configuration, tests and other incidental changes\n\nout of scope :\n\nThis initial implementation does not implement actual provider that supports only immutable writes. (Although it should include design elements to support that.)\nThe initial implementation does not support upgrade path.\nNon-critical performance improvements. (Especially on read path. Coming very very soon)\n\nHow to verify it\n\n New or old unit tests should pass.\n System tests should pass.", "createdAt": "2020-05-04T15:49:58Z", "url": "https://github.com/pravega/pravega/pull/4769", "merged": true, "mergeCommit": {"oid": "a4e3163c4fa12bb24347b472b66ef2bbb05454b1"}, "closed": true, "closedAt": "2020-07-29T13:48:04Z", "author": {"login": "sachin-j-joshi"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcfTLGHgFqTQwODI5NjY5OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc5muOhgFqTQ1NzMwMjcwNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4Mjk2Njk4", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-408296698", "createdAt": "2020-05-08T14:53:34Z", "commit": null, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo1MzozNFrOGSoahg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo1NTo0OVrOGSogEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4OTcwMg==", "bodyText": "nit: initializeStorage", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r422189702", "createdAt": "2020-05-08T14:53:34Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +181,76 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     * @throws Exception\n+     */\n+    private void InitializeStorage() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE5MDMyOQ==", "bodyText": "4000 * 30 seconds ?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r422190329", "createdAt": "2020-05-08T14:54:31Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/tables/TableServiceTests.java", "diffHunk": "@@ -58,22 +61,22 @@\n public class TableServiceTests extends ThreadPooledTestSuite {\n     //region Config and Setup\n \n-    private static final int THREADPOOL_SIZE_SEGMENT_STORE = 20;\n-    private static final int THREADPOOL_SIZE_SEGMENT_STORE_STORAGE = 10;\n-    private static final int THREADPOOL_SIZE_TEST = 3;\n+    private static final int THREADPOOL_SIZE_SEGMENT_STORE = 200;\n+    private static final int THREADPOOL_SIZE_SEGMENT_STORE_STORAGE = 100;\n+    private static final int THREADPOOL_SIZE_TEST = 1000;\n     private static final int SEGMENT_COUNT = 10;\n     private static final int KEY_COUNT = 1000;\n     private static final int MAX_KEY_LENGTH = 128;\n     private static final int MAX_VALUE_LENGTH = 32;\n     private static final Duration TIMEOUT = Duration.ofSeconds(30); // Individual call timeout\n     @Rule\n-    public Timeout globalTimeout = new Timeout((int) TIMEOUT.toMillis() * 4, TimeUnit.MILLISECONDS);\n+    public Timeout globalTimeout = new Timeout((int) TIMEOUT.toMillis() * 4000, TimeUnit.MILLISECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE5MTEyMw==", "bodyText": "Why don't we have a better serialization mechanism ?\nJava serialization is heavy and it could lead to security issues.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r422191123", "createdAt": "2020-05-08T14:55:49Z", "author": {"login": "eolivelli"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    TableStore tableStore;\n+    String tableName;\n+    Duration timeout = Duration.ofSeconds(1L);\n+    AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    @Override\n+    protected TransactionData read( String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<ArrayView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    ObjectInputStream input = new ObjectInputStream(new ByteArrayInputStream(arr.array(), arr.arrayOffset(), arr.getLength()));\n+                    TransactionData txnData = (TransactionData) input.readObject();\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    //version = TableKey.NO_VERSION;\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                ByteArrayOutputStream bos = new ByteArrayOutputStream();\n+                ObjectOutputStream out = new ObjectOutputStream(bos);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 99}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "7689cd8e1555921237aee4aa95bd4143c2be84a2", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/7689cd8e1555921237aee4aa95bd4143c2be84a2", "committedDate": "2020-06-05T00:04:42Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7689cd8e1555921237aee4aa95bd4143c2be84a2", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/7689cd8e1555921237aee4aa95bd4143c2be84a2", "committedDate": "2020-06-05T00:04:42Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "committedDate": "2020-06-12T15:34:24Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/8017d7fe4b0e1e499cc3ac21d9e4d06f94babd2b", "committedDate": "2020-06-12T15:34:24Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "d0b5de8556822817bce33ca050dae296c4d5f1ff", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/d0b5de8556822817bce33ca050dae296c4d5f1ff", "committedDate": "2020-06-25T17:48:23Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d0b5de8556822817bce33ca050dae296c4d5f1ff", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/d0b5de8556822817bce33ca050dae296c4d5f1ff", "committedDate": "2020-06-25T17:48:23Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}, "afterCommit": null}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "75f5600813260a073b4b20796c958b3076630bd0", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/75f5600813260a073b4b20796c958b3076630bd0", "committedDate": "2020-07-08T20:13:41Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Ignore StorageLoaderTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "75f5600813260a073b4b20796c958b3076630bd0", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/75f5600813260a073b4b20796c958b3076630bd0", "committedDate": "2020-07-08T20:13:41Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Ignore StorageLoaderTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}, "afterCommit": {"oid": "2e589c6b564714c3b1d06e6812f0d8020f6579cb", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/2e589c6b564714c3b1d06e6812f0d8020f6579cb", "committedDate": "2020-07-14T23:41:49Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Boot fix.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e589c6b564714c3b1d06e6812f0d8020f6579cb", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/2e589c6b564714c3b1d06e6812f0d8020f6579cb", "committedDate": "2020-07-14T23:41:49Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Boot fix.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}, "afterCommit": null}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxODIzNzE3", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-451823717", "createdAt": "2020-07-20T17:42:58Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxNzo0Mjo1OVrOG0YqbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxNzo0ODowNFrOG0Y15g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4MzIxMw==", "bodyText": "Nit: perhaps not intentional space added", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457583213", "createdAt": "2020-07-20T17:42:59Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/ExtendedS3IntegrationTest.java", "diffHunk": "@@ -5,7 +5,7 @@\n  * you may not use this file except in compliance with the License.\n  * You may obtain a copy of the License at\n  *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n+ *     http://www.apache.org/licenses/LICENSE-2.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4NDk5NQ==", "bodyText": "I am not sure this is a good way of doing this:\n\nwhy aren't we fast failing and return a failed future?\nwhy are we catching a generic Exception?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457584995", "createdAt": "2020-07-20T17:46:01Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -253,7 +279,11 @@ protected void doStart() {\n     }\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n-        this.storage.initialize(this.metadata.getContainerEpoch());\n+        try {\n+            initializeStorage();\n+        } catch (Exception ex) {\n+            doStop(ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4NjE1MA==", "bodyText": "This instanceof someone smells.\nBtw you have to cast it to ChunkedSegmentStorage so I don't know if we can do it better", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457586150", "createdAt": "2020-07-20T17:48:04Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +180,29 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     *\n+     * @throws Exception\n+     */\n+    private void initializeStorage() throws Exception {\n+        this.storage.initialize(this.metadata.getContainerEpoch());\n+\n+        if (this.storage instanceof ChunkedSegmentStorage) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1c4bea922d076022d8fa338681f039ee4b290aa", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/e1c4bea922d076022d8fa338681f039ee4b290aa", "committedDate": "2020-07-20T18:13:57Z", "message": "Issue 4676: (PDP-34) Initial Implementation (3 of 4) - Bug Fix -truncate should not lazyCommit.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f4542abb18631733ddb0fab30e43f71ed9f121a", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/2f4542abb18631733ddb0fab30e43f71ed9f121a", "committedDate": "2020-07-20T18:13:57Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - TableBasedMetadataStore and hooking it up in StreamSegmentContainer.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d768fff1f065330a439bbcb7ea49472e7318cf16", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/d768fff1f065330a439bbcb7ea49472e7318cf16", "committedDate": "2020-07-20T18:13:57Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxODQxODU3", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-451841857", "createdAt": "2020-07-20T18:08:29Z", "commit": null, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxODowODoyOVrOG0ZjNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQxODoxMzoyNlrOG0ZuNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5Nzc1MA==", "bodyText": "Nit: remove", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457597750", "createdAt": "2020-07-20T18:08:29Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -305,20 +327,35 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n      */\n     @Test\n     public void testEndToEndWithFencing() throws Exception {\n-        endToEndProcessWithFencing(true);\n+        endToEndProcessWithFencing(true, false);\n+    }\n+\n+    /**\n+     * Tests an end-to-end scenario for the SegmentStore where operations are continuously executed while the SegmentStore\n+     * itself is being fenced out by new instances. The difference between this and testEndToEnd() is that this does not\n+     * do a graceful shutdown of the Segment Store, instead it creates a new instance while the previous one is still running.\n+     *\n+     * @throws Exception If an exception occurred.\n+     */\n+    @Test\n+    //@Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5OTc2MA==", "bodyText": "I am not sure this is a good name for the public audience.\nWhat about:\n\nV07\nRAW\nSIMPLE\n\nSomething that makes it clear that is not TABLE_BASED but as it is the default it cannot smell like 'this is old stuff, probably no more very much supported'", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457599760", "createdAt": "2020-07-20T18:11:58Z", "author": {"login": "eolivelli"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageManagerLayoutType.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage;\n+\n+/**\n+ * Type of Storage metadata layout to use.\n+ */\n+public enum StorageManagerLayoutType {\n+    /**\n+     * Uses RollingStorage based layout.\n+     */\n+    LEGACY,", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwMDU2Nw==", "bodyText": "Please also write log about what are you doing. Otherwise we will see errors without context", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457600567", "createdAt": "2020-07-20T18:13:26Z", "author": {"login": "eolivelli"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -1321,4 +1346,20 @@ private void checkInitialized() {\n         Preconditions.checkState(0 != this.epoch);\n         Preconditions.checkState(!closed.get());\n     }\n+\n+    private void checkChunksExist(MetadataTransaction txn, SegmentMetadata segmentMetadata) throws StorageMetadataException, ChunkStorageException {\n+        if (config.isDebugEnabled()) {\n+            String current = segmentMetadata.getFirstChunk();", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 167}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/e0281e13fb1602d279ac2064282546f02a07482b", "committedDate": "2020-07-20T19:02:38Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/e0281e13fb1602d279ac2064282546f02a07482b", "committedDate": "2020-07-20T19:02:38Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix tests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9de3f2e55a2bbcda51055f0e3be1e77ffc741106", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/9de3f2e55a2bbcda51055f0e3be1e77ffc741106", "committedDate": "2020-07-20T22:43:47Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Rename and clean up.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxOTk5OTE4", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-451999918", "createdAt": "2020-07-20T22:22:10Z", "commit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 39, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMjoyMjoxMVrOG0hT_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMjo1NjoyN1rOG0iFVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNDkyNQ==", "bodyText": "Tip: this constructor can be auto-generated if you annotate the class with @RequiredArgsConstructor and each field with @NonNull.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457724925", "createdAt": "2020-07-20T22:22:11Z", "author": {"login": "andreipaduroiu"}, "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3SimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.storage.extendeds3;\n+\n+import com.emc.object.s3.S3Client;\n+import com.emc.object.s3.S3Config;\n+import com.emc.object.s3.jersey.S3JerseyClient;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * Factory for ExtendedS3 {@link Storage} implemented using {@link ChunkedSegmentStorage} and {@link ExtendedS3ChunkStorage}.\n+ */\n+public class ExtendedS3SimpleStorageFactory implements StorageFactory {\n+    private final ExtendedS3StorageConfig config;\n+    private final ExecutorService executor;\n+\n+    /**\n+     * Creates a new instance of the {@link ExtendedS3SimpleStorageFactory} class.\n+     *\n+     * @param config   The Configuration to use.\n+     * @param executor An executor to use for background operations.\n+     */\n+    public ExtendedS3SimpleStorageFactory(ExtendedS3StorageConfig config, ExecutorService executor) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg==", "bodyText": "TIP: You can annotate each field with @NonNull; Lombok will auto-generate the precondition checks.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457725372", "createdAt": "2020-07-20T22:23:26Z", "author": {"login": "andreipaduroiu"}, "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3StorageFactoryCreator.java", "diffHunk": "@@ -9,19 +9,43 @@\n  */\n package io.pravega.storage.extendeds3;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageManagerLayoutType;\n+import io.pravega.segmentstore.storage.StorageManagerType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class ExtendedS3StorageFactoryCreator implements StorageFactoryCreator {\n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new ExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {\n+        Preconditions.checkNotNull(storageFactoryInfo, \"storageFactoryInfo\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTY4Nw==", "bodyText": "Same in the other classes.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457725687", "createdAt": "2020-07-20T22:24:19Z", "author": {"login": "andreipaduroiu"}, "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3StorageFactoryCreator.java", "diffHunk": "@@ -9,19 +9,43 @@\n  */\n package io.pravega.storage.extendeds3;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageManagerLayoutType;\n+import io.pravega.segmentstore.storage.StorageManagerType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class ExtendedS3StorageFactoryCreator implements StorageFactoryCreator {\n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new ExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {\n+        Preconditions.checkNotNull(storageFactoryInfo, \"storageFactoryInfo\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNjUzNQ==", "bodyText": "I am wondering too whether \"LEGACY\" is meaningful here. Maybe \"ROLLING_STORAGE\" (and somewhere put a link to the RollingStorage.java class on GitHub (branch 0.7 -since it will be gone from master at one point).\nWhat do you think?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457726535", "createdAt": "2020-07-20T22:26:31Z", "author": {"login": "andreipaduroiu"}, "path": "config/config.properties", "diffHunk": "@@ -97,6 +97,21 @@ pravegaservice.dataLog.impl.name=BOOKKEEPER\n # Default value: HDFS\n # pravegaservice.storage.impl.name=HDFS\n \n+\n+# Storage layout for Tier 2 storage.\n+# Valid values:\n+#   TABLE_BASED - Using TableStore.\n+#   LEGACY      - Using header files.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNzEzNw==", "bodyText": "Please put this ( on the previous line.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457727137", "createdAt": "2020-07-20T22:28:15Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/host/src/main/java/io/pravega/segmentstore/server/host/StorageLoader.java", "diffHunk": "@@ -28,18 +31,28 @@\n  */\n @Slf4j\n public class StorageLoader {\n-    public StorageFactory load(ConfigSetup setup, String storageImplementation, ScheduledExecutorService executor) {\n+    public StorageFactory load(ConfigSetup setup,\n+                               String storageImplementation,\n+                               StorageManagerType storageManagerType,\n+                               StorageManagerLayoutType storageManagerLayoutType,\n+                               ScheduledExecutorService executor) {\n         ServiceLoader<StorageFactoryCreator> loader = ServiceLoader.load(StorageFactoryCreator.class);\n         StorageExtraConfig noOpConfig = setup.getConfig(StorageExtraConfig::builder);\n         for (StorageFactoryCreator factoryCreator : loader) {\n-            log.info(\"Loading {}, trying {}\", storageImplementation, factoryCreator.getName());\n-            if (factoryCreator.getName().equals(storageImplementation)) {\n-                StorageFactory factory = factoryCreator.createFactory(setup, executor);\n-                if (!noOpConfig.isStorageNoOpMode()) {\n-                    return factory;\n-                } else { //The specified storage implementation is in No-Op mode.\n-                    log.warn(\"{} IS IN NO-OP MODE: DATA LOSS WILL HAPPEN! MAKE SURE IT IS BY FULL INTENTION FOR TESTING PURPOSE!\", storageImplementation);\n-                    return new NoOpStorageFactory(noOpConfig, executor, factory, null);\n+            val factories = factoryCreator.getStorageFactories();\n+            for (val factoryInfo : factories) {\n+                log.info(\"Loading {}, trying {}\", storageImplementation, factoryInfo);\n+                if (factoryInfo.getName().equals(storageImplementation)\n+                        && factoryInfo.getStorageManagerLayoutType() == storageManagerLayoutType\n+                        && factoryInfo.getStorageManagerType() == storageManagerType\n+                ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNzcyOQ==", "bodyText": "I think this will go away once we remove the legacy code (RollingStorage and AsyncStorageWrapper). Until this code comes out of beta, we'll have to live with both.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457727729", "createdAt": "2020-07-20T22:29:53Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +180,29 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     *\n+     * @throws Exception\n+     */\n+    private void initializeStorage() throws Exception {\n+        this.storage.initialize(this.metadata.getContainerEpoch());\n+\n+        if (this.storage instanceof ChunkedSegmentStorage) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4NjE1MA=="}, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODQzNw==", "bodyText": "And what it if it is null? Won't this be checked in the constructor of TableBasedMetadataStore below?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457728437", "createdAt": "2020-07-20T22:31:43Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +180,29 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     *\n+     * @throws Exception\n+     */\n+    private void initializeStorage() throws Exception {\n+        this.storage.initialize(this.metadata.getContainerEpoch());\n+\n+        if (this.storage instanceof ChunkedSegmentStorage) {\n+            ChunkedSegmentStorage storageManager = (ChunkedSegmentStorage) this.storage;\n+\n+            // Initialize storage metadata table segment\n+            ContainerTableExtension tableExtension = getExtension(ContainerTableExtension.class);\n+            Preconditions.checkNotNull(tableExtension);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTQzNA==", "bodyText": "You do not need to do this. Let the exception bubble up, whatever that exception is, and observe how this method is used. In startWhenDurableLogOnline, a listener is attached to its returned Future which will invoke the (correct) shutdown procedure. No need for extra stuff here.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457729434", "createdAt": "2020-07-20T22:34:26Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -253,7 +279,11 @@ protected void doStart() {\n     }\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n-        this.storage.initialize(this.metadata.getContainerEpoch());\n+        try {\n+            initializeStorage();\n+        } catch (Exception ex) {\n+            doStop(ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4NDk5NQ=="}, "originalCommit": null, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTg4Ng==", "bodyText": "Why don't we add these things to SegmentProperties interface so we don't have to remember to set them everywhere? You can just go back to StreamSegmentInformation and update the from method which should automatically take effect wherever it's used.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457729886", "createdAt": "2020-07-20T22:35:34Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentMetadata.java", "diffHunk": "@@ -353,7 +353,11 @@ public synchronized boolean isActive() {\n \n     @Override\n     public synchronized SegmentProperties getSnapshot() {\n-        return StreamSegmentInformation.from(this).attributes(new HashMap<>(getAttributes())).build();\n+        return StreamSegmentInformation.from(this)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDQ3Mg==", "bodyText": "Does this include the one you just removed from here? That's the container metadata segment which has nothing to do with chunks.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457730472", "createdAt": "2020-07-20T22:37:16Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/StreamSegmentContainerTests.java", "diffHunk": "@@ -1881,11 +1881,17 @@ private void checkActiveSegments(SegmentContainer container, int expectedCount)\n         val initialActiveSegments = container.getActiveSegments();\n         int ignoredSegments = 0;\n         for (SegmentProperties sp : initialActiveSegments) {\n-            if (sp.getName().equals(EXPECTED_METADATA_SEGMENT_NAME)) {\n+            boolean match = false;\n+            for (String systemSegment : SystemJournal.getChunkStorageSystemSegments(container.getId())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMDYwMA==", "bodyText": "Why?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457730600", "createdAt": "2020-07-20T22:37:39Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -24,6 +25,7 @@\n  * because user segment write operation is no-oped.\n  */\n @Slf4j\n+@Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTE1MA==", "bodyText": "private final; I don't think you have any reason to mutate this object.\neverywhere below too.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457731150", "createdAt": "2020-07-20T22:39:13Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageFactoryInfo.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage;\n+\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import lombok.Builder;\n+import lombok.Data;\n+\n+/**\n+ * Information about the capabilities supported by a {@link StorageFactory}.\n+ */\n+@Data\n+@Builder\n+public class StorageFactoryInfo {\n+    /**\n+     * Name of storage binding.\n+     */\n+    String name;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTQwMQ==", "bodyText": "I added a similar comment in the config file. Let's be consistent. A bit of documentation pointing to the (soon-to-be-defunct) RollingStorage.java would help too.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457731401", "createdAt": "2020-07-20T22:39:52Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageManagerLayoutType.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage;\n+\n+/**\n+ * Type of Storage metadata layout to use.\n+ */\n+public enum StorageManagerLayoutType {\n+    /**\n+     * Uses RollingStorage based layout.\n+     */\n+    LEGACY,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5OTc2MA=="}, "originalCommit": null, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMTg4OA==", "bodyText": "Do all of these calls result in LTS or Table Segment calls? You've added quite a bit of now.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457731888", "createdAt": "2020-07-20T22:41:06Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -597,6 +614,7 @@ private void collectGarbage(Collection<String> chunksTodelete) {\n                 // Validate preconditions.\n                 checkSegmentExists(streamSegmentName, segmentMetadata);\n                 checkOwnership(streamSegmentName, segmentMetadata);\n+                checkChunksExist(txn, segmentMetadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjA0NQ==", "bodyText": "This sounds pretty aggressive. 30s?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732045", "createdAt": "2020-07-20T22:41:34Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjYwMQ==", "bodyText": "getBytes will encode the string in whatever default charset happens to be on the machine. While nowadays it's UTF8, this doesn't mean it won't change at one point in the future.\nTo make sure our data is compatible between different hosts, let's keep a reference to Charsets.UTF8 and pass that to everywhere we are encoding or decoding String keys in this file.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732601", "createdAt": "2020-07-20T22:43:09Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw==", "bodyText": "So what if it's not 1?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457732833", "createdAt": "2020-07-20T22:43:49Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzM5Nw==", "bodyText": "encoding here\nUse TableKey.Unversioned if you want to specify NO_VERSION", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733397", "createdAt": "2020-07-20T22:45:14Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzY2Ng==", "bodyText": "Or did you mean to specify a version (you have a version variable)?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733666", "createdAt": "2020-07-20T22:46:00Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzM5Nw=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzczMQ==", "bodyText": "encoding", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457733731", "createdAt": "2020-07-20T22:46:09Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA==", "bodyText": "Do you really need to do this? This will block this thread and use another thread to execute that call. It is a recipe for running out of threads very very quickly.\nPlease rewrite this method to be a CompletableFuture (async) so it doesn't have this problem.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734114", "createdAt": "2020-07-20T22:47:16Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDIyNw==", "bodyText": "same here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734227", "createdAt": "2020-07-20T22:47:34Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDM2Mg==", "bodyText": "Aren't these two catch blocks the same?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734362", "createdAt": "2020-07-20T22:47:58Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDQ3NQ==", "bodyText": "You can use Exceptions.unwrap to help here.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734475", "createdAt": "2020-07-20T22:48:14Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDM2Mg=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDYyNQ==", "bodyText": "I think this should be a WARN.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734625", "createdAt": "2020-07-20T22:48:36Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDgyMA==", "bodyText": "set e=Exceptions.unwrap(e) and simplify this code.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457734820", "createdAt": "2020-07-20T22:49:04Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTA2MA==", "bodyText": "Same comment here about making this be async.\nFurthermore, you use join here and above you use get.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735060", "createdAt": "2020-07-20T22:49:42Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);\n+        }\n+        throw new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTE1Ng==", "bodyText": "Exceptions.unwrap", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735156", "createdAt": "2020-07-20T22:49:55Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw e; // To make spotbugs happy.\n+        } catch (java.util.concurrent.ExecutionException e) {\n+            handleException(e.getCause());\n+            return;\n+        } catch (Exception e) {\n+            handleException(e);\n+            return;\n+        }\n+\n+    }\n+\n+    private void handleException(Throwable e) throws StorageMetadataException {\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            throw new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            throw new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        if (e.getCause() != null) {\n+            if (e.getCause().getCause() instanceof BadKeyVersionException) {\n+                throw new StorageMetadataWritesFencedOutException(\"Transaction writer is fenced off.\", e);\n+            }\n+            if (e.getCause().getCause() instanceof DataLogWriterNotPrimaryException) {\n+                throw new StorageMetadataVersionMismatchException(\"Transaction failed. Writer fenced off\", e);\n+            }\n+        } else {\n+            log.debug(\"e.getCause()=null\", e);\n+        }\n+        throw new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();\n+                log.info(\"Created table segment {}\", tableName);\n+            } catch (CompletionException e) {\n+                if (e.getCause() instanceof StreamSegmentExistsException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTMzOA==", "bodyText": "?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735338", "createdAt": "2020-07-20T22:50:17Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemorySimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * In-Memory mock for StorageFactory. Contents is destroyed when object is garbage collected.\n+ */\n+public class InMemorySimpleStorageFactory implements StorageFactory, AutoCloseable {\n+    @VisibleForTesting\n+    protected ScheduledExecutorService executor;\n+\n+    private Storage singletonStorage;\n+    private ChunkStorage singletonChunkStorage;\n+    private boolean reuseStorage;\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    public InMemorySimpleStorageFactory() {\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, boolean reuseStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.reuseStorage = reuseStorage;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, Storage storage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonStorage = Preconditions.checkNotNull(storage, \"Storage\");\n+        this.reuseStorage = true;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, ChunkStorage chunkStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonChunkStorage = Preconditions.checkNotNull(chunkStorage, \"chunkStorage\");\n+        this.reuseStorage = false;\n+    }\n+\n+    @Override\n+    public Storage createStorageAdapter() {\n+        synchronized (this) {\n+            if (reuseStorage) {\n+                if (null != singletonStorage) {\n+                    return singletonStorage;\n+                }\n+                singletonStorage = getStorage();\n+                return singletonStorage;\n+            }\n+            return getStorage();\n+        }\n+    }\n+\n+    private Storage getStorage() {\n+        if (null == singletonChunkStorage) {\n+            return newStorage(executor);\n+        } else {\n+            return newStorage(executor, singletonChunkStorage);\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        // ?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNTUwNw==", "bodyText": "Delete this commented out code", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457735507", "createdAt": "2020-07-20T22:50:42Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemorySimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ScheduledExecutorService;\n+\n+/**\n+ * In-Memory mock for StorageFactory. Contents is destroyed when object is garbage collected.\n+ */\n+public class InMemorySimpleStorageFactory implements StorageFactory, AutoCloseable {\n+    @VisibleForTesting\n+    protected ScheduledExecutorService executor;\n+\n+    private Storage singletonStorage;\n+    private ChunkStorage singletonChunkStorage;\n+    private boolean reuseStorage;\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+    }\n+\n+    public InMemorySimpleStorageFactory() {\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, boolean reuseStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.reuseStorage = reuseStorage;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, Storage storage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonStorage = Preconditions.checkNotNull(storage, \"Storage\");\n+        this.reuseStorage = true;\n+    }\n+\n+    public InMemorySimpleStorageFactory(ScheduledExecutorService executor, ChunkStorage chunkStorage) {\n+        this.executor = Preconditions.checkNotNull(executor, \"executor\");\n+        this.singletonChunkStorage = Preconditions.checkNotNull(chunkStorage, \"chunkStorage\");\n+        this.reuseStorage = false;\n+    }\n+\n+    @Override\n+    public Storage createStorageAdapter() {\n+        synchronized (this) {\n+            if (reuseStorage) {\n+                if (null != singletonStorage) {\n+                    return singletonStorage;\n+                }\n+                singletonStorage = getStorage();\n+                return singletonStorage;\n+            }\n+            return getStorage();\n+        }\n+    }\n+\n+    private Storage getStorage() {\n+        if (null == singletonChunkStorage) {\n+            return newStorage(executor);\n+        } else {\n+            return newStorage(executor, singletonChunkStorage);\n+        }\n+    }\n+\n+    @Override\n+    public void close() {\n+        // ?\n+    }\n+\n+    /**\n+     * Creates a new InMemory Storage, without a rolling wrapper.\n+     *\n+     * @param executor An Executor to use for async operations.\n+     * @return A new InMemoryStorage.\n+     */\n+    @VisibleForTesting\n+    public static Storage newStorage(Executor executor) {\n+        return newStorage(executor, new InMemoryChunkStorage());\n+    }\n+\n+    /**\n+     * Creates a new InMemory Storage, without a rolling wrapper.\n+     *\n+     * @param executor     An Executor to use for async operations.\n+     * @param chunkStorage ChunkStorage to use.\n+     * @return A new InMemoryStorage.\n+     */\n+    @VisibleForTesting\n+    public static Storage newStorage(Executor executor, ChunkStorage chunkStorage) {\n+        //TableStore tableStore = new InMemoryTableStore(executor);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjMzMg==", "bodyText": "What is wrong with TableStoreMock that already exists?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736332", "createdAt": "2020-07-20T22:52:48Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemoryTableStore.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.KeyNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.SneakyThrows;\n+import lombok.val;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+@RequiredArgsConstructor\n+@ThreadSafe\n+public class InMemoryTableStore implements TableStore {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjUwOA==", "bodyText": "This class looks suspiciously similar to that one ...", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736508", "createdAt": "2020-07-20T22:53:19Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/mocks/InMemoryTableStore.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.IteratorArgs;\n+import io.pravega.segmentstore.contracts.tables.IteratorItem;\n+import io.pravega.segmentstore.contracts.tables.KeyNotExistsException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.SneakyThrows;\n+import lombok.val;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+import javax.annotation.concurrent.ThreadSafe;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+@RequiredArgsConstructor\n+@ThreadSafe\n+public class InMemoryTableStore implements TableStore {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjMzMg=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc3MA==", "bodyText": "When are you going to do it?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736770", "createdAt": "2020-07-20T22:54:02Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/test/java/io/pravega/segmentstore/storage/mocks/TableBasedMetadataSimpleStorageTests.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedRollingStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+import io.pravega.segmentstore.storage.chunklayer.SimpleStorageTests;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadataStore;\n+import io.pravega.segmentstore.storage.metadata.TableBasedMetadataStore;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * Unit tests for {@link TableBasedMetadataStore} with {@link InMemoryChunkStorage} using {@link SimpleStorageTests}.\n+ */\n+public class TableBasedMetadataSimpleStorageTests extends SimpleStorageTests {\n+\n+    protected ChunkStorage getChunkStorage() throws Exception {\n+        return new InMemoryChunkStorage();\n+    }\n+\n+    protected ChunkMetadataStore getMetadataStore() throws Exception {\n+        TableStore tableStore = new InMemoryTableStore(executorService());\n+        String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+        return new TableBasedMetadataStore(tableName, tableStore);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testZombieFencing() throws Exception {\n+        //TableBasedMetadataStore does not support clone.\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedRollingStorageTests}.\n+     */\n+    public static class InMemorySimpleStorageRollingTests extends ChunkedRollingStorageTests {\n+        protected ChunkStorage getChunkStorage() throws Exception {\n+            return new InMemoryChunkStorage();\n+        }\n+\n+        protected ChunkMetadataStore getMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(executorService());\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedSegmentStorageTests}.\n+     */\n+    public static class InMemorySimpleStorage extends ChunkedSegmentStorageTests {\n+        @Override\n+        public ChunkMetadataStore createMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(Executors.newScheduledThreadPool(1));\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+\n+        public TestContext getTestContext() throws Exception {\n+            return new InMemorySimpleStorageTestContext(executorService());\n+        }\n+\n+        @Test\n+        @Ignore(\"This is not implemented yet.\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc5OQ==", "bodyText": "And below too.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736799", "createdAt": "2020-07-20T22:54:10Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/test/java/io/pravega/segmentstore/storage/mocks/TableBasedMetadataSimpleStorageTests.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.mocks;\n+\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedRollingStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageTests;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkStorage;\n+import io.pravega.segmentstore.storage.chunklayer.SimpleStorageTests;\n+import io.pravega.segmentstore.storage.metadata.ChunkMetadataStore;\n+import io.pravega.segmentstore.storage.metadata.TableBasedMetadataStore;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * Unit tests for {@link TableBasedMetadataStore} with {@link InMemoryChunkStorage} using {@link SimpleStorageTests}.\n+ */\n+public class TableBasedMetadataSimpleStorageTests extends SimpleStorageTests {\n+\n+    protected ChunkStorage getChunkStorage() throws Exception {\n+        return new InMemoryChunkStorage();\n+    }\n+\n+    protected ChunkMetadataStore getMetadataStore() throws Exception {\n+        TableStore tableStore = new InMemoryTableStore(executorService());\n+        String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+        return new TableBasedMetadataStore(tableName, tableStore);\n+    }\n+\n+    @Test\n+    @Override\n+    public void testZombieFencing() throws Exception {\n+        //TableBasedMetadataStore does not support clone.\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedRollingStorageTests}.\n+     */\n+    public static class InMemorySimpleStorageRollingTests extends ChunkedRollingStorageTests {\n+        protected ChunkStorage getChunkStorage() throws Exception {\n+            return new InMemoryChunkStorage();\n+        }\n+\n+        protected ChunkMetadataStore getMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(executorService());\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+    }\n+\n+    /**\n+     * Unit tests for {@link TableBasedMetadataStore} using {@link ChunkedSegmentStorageTests}.\n+     */\n+    public static class InMemorySimpleStorage extends ChunkedSegmentStorageTests {\n+        @Override\n+        public ChunkMetadataStore createMetadataStore() throws Exception {\n+            TableStore tableStore = new InMemoryTableStore(Executors.newScheduledThreadPool(1));\n+            String tableName = \"TableBasedMetadataSimpleStorageTests\";\n+            return new TableBasedMetadataStore(tableName, tableStore);\n+        }\n+\n+        public TestContext getTestContext() throws Exception {\n+            return new InMemorySimpleStorageTestContext(executorService());\n+        }\n+\n+        @Test\n+        @Ignore(\"This is not implemented yet.\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjc3MA=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNjk5MQ==", "bodyText": "most of the changes in this file look unrelated. Any chance you could revert them?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457736991", "createdAt": "2020-07-20T22:54:46Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -421,14 +425,14 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for ( ServiceStarter starter : this.nodeServiceStarter ) {\n+            for (ServiceStarter starter : this.nodeServiceStarter) {\n                 starter.shutdown();\n             }\n         }\n         if (isInProcController) {\n-            for ( ControllerServiceMain controller : this.controllerServers ) {\n-                    controller.stopAsync();\n-                }\n+            for (ControllerServiceMain controller : this.controllerServers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzE2Ng==", "bodyText": "Delete commented out code", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737166", "createdAt": "2020-07-20T22:55:15Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzIwOQ==", "bodyText": "and here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737209", "createdAt": "2020-07-20T22:55:24Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}\n \n+                //try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                //    val segmentStore = builder.createStreamSegmentService();\n                 checkReadsWhileTruncating(segmentContents, startOffsets, segmentStore);\n                 log.info(\"Finished checking reads while truncating.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Phase 3.\");\n             }\n         }\n \n         // Phase 4: Force a recovery, seal segments and then delete them.\n         log.info(\"Starting Phase 4.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage)) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             // Seals.\n             sealSegments(segmentNames, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n             log.info(\"Finished sealing.\");\n \n             checkSegmentStatus(lengths, startOffsets, true, false, expectedAttributeValue, segmentStore);\n-\n+            //}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzIzNQ==", "bodyText": "and here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737235", "createdAt": "2020-07-20T22:55:31Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -241,50 +258,55 @@ void endToEndProcess(boolean verifySegmentContent) throws Exception {\n \n         // Phase 3: Force a recovery, immediately check reads, then truncate and read at the same time.\n         log.info(\"Starting Phase 3.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             checkReads(segmentContents, segmentStore);\n             log.info(\"Finished checking reads.\");\n+        }\n \n-            if (verifySegmentContent) {\n+        if (verifySegmentContent) {\n+            try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                val segmentStore = builder.createStreamSegmentService();\n                 // Wait for all the data to move to Storage.\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                waitForSegmentsInStorage(segmentNames, segmentStore)\n                         .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n                 log.info(\"Finished waiting for segments in Storage.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n+                //}\n \n+                //try (val builder = createBuilder(++instanceId, useChunkStorage);) {\n+                //    val segmentStore = builder.createStreamSegmentService();\n                 checkReadsWhileTruncating(segmentContents, startOffsets, segmentStore);\n                 log.info(\"Finished checking reads while truncating.\");\n \n-                checkStorage(segmentContents, segmentStore, readOnlySegmentStore);\n+                checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Phase 3.\");\n             }\n         }\n \n         // Phase 4: Force a recovery, seal segments and then delete them.\n         log.info(\"Starting Phase 4.\");\n-        try (val builder = createBuilder(++instanceId);\n-             val readOnlyBuilder = createReadOnlyBuilder(instanceId)) {\n+        try (val builder = createBuilder(++instanceId, useChunkStorage)) {\n             val segmentStore = builder.createStreamSegmentService();\n-            val readOnlySegmentStore = readOnlyBuilder.createStreamSegmentService();\n-\n             // Seals.\n             sealSegments(segmentNames, segmentStore).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n             log.info(\"Finished sealing.\");\n \n             checkSegmentStatus(lengths, startOffsets, true, false, expectedAttributeValue, segmentStore);\n-\n+            //}\n             if (verifySegmentContent) {\n-                waitForSegmentsInStorage(segmentNames, segmentStore, readOnlySegmentStore)\n+                //try (val builder = createBuilder(++instanceId, useChunkStorage)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNzU1OQ==", "bodyText": "remove", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r457737559", "createdAt": "2020-07-20T22:56:27Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -869,11 +898,33 @@ private void checkAppendLeaks(ArrayList<ByteBuf> buffers) {\n                 buffers.stream().allMatch(r -> r.refCnt() == 0));\n     }\n \n-    private CompletableFuture<Void> waitForSegmentsInStorage(Collection<String> segmentNames, StreamSegmentStore baseStore,\n+    private ArrayList<SegmentProperties> getStreamSegmentInfoList(Collection<String> segmentNames, StreamSegmentStore baseStore) {\n+        ArrayList<SegmentProperties> retValue = new ArrayList<>();\n+        for (String segmentName : segmentNames) {\n+            SegmentProperties sp = baseStore.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+            retValue.add(sp);\n+        }\n+\n+        return retValue;\n+    }\n+\n+    /*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 419}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06e978a33ea9cc04de7b22ef7e86440866d00114", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/06e978a33ea9cc04de7b22ef7e86440866d00114", "committedDate": "2020-07-21T01:19:10Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d729474da6cd83e992ca173ced69e6d55bacbd5", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/7d729474da6cd83e992ca173ced69e6d55bacbd5", "committedDate": "2020-07-21T19:58:37Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Add covergage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41449187e49b40df5392d774654dd29c4e4baf62", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/41449187e49b40df5392d774654dd29c4e4baf62", "committedDate": "2020-07-21T21:50:05Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cbb406d928ffeb9a0f44380a186e80ae27504ba0", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/cbb406d928ffeb9a0f44380a186e80ae27504ba0", "committedDate": "2020-07-21T21:53:03Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/41c8da911d4823374ed171deba9bab7d6ee3a926", "committedDate": "2020-07-21T21:56:45Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove debug check that all chunks exist.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMTM5NTgw", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-453139580", "createdAt": "2020-07-22T09:15:58Z", "commit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOToxNTo1OFrOG1Z99w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDowOTo1MFrOG1b4Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY1MzE3NQ==", "bodyText": "By design, I understand that it should be either 0 or 1, but what if there is a bug in the logic and we get a value greater than 1? Is returning TableKey.NOT_EXISTS? Even if such a case is not expected, I'd say we should validate it.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458653175", "createdAt": "2020-07-22T09:15:58Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2NDEyNA==", "bodyText": "There is no easy way to do this method.\n\nI'm not sure I get what is hard about it. If you are referring to visibility, then having the test class is in the same package should enable this method to be package protected.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458664124", "createdAt": "2020-07-22T09:34:20Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,195 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Charsets;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    /**\n+     * Instance of the {@link TableStore}.\n+     */\n+    @Getter\n+    private final TableStore tableStore;\n+\n+    /**\n+     * Name of the table segment.\n+     */\n+    @Getter\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(30);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes(Charsets.UTF_8)));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.unversioned(new ByteArraySegment(txnData.getKey().getBytes(Charsets.UTF_8)));\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes(Charsets.UTF_8)),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();\n+\n+            // Update versions.\n+            int i = 0;\n+            for (TableEntry tableEntry : toUpdate) {\n+                entryToTxnDataMap.get(tableEntry).setDbObject(ret.get(i));\n+                i++;\n+            }\n+\n+            // Delete deleted keys.\n+            this.tableStore.remove(tableName, keysToDelete, timeout).get();\n+            for (val deletedKey : keysToDelete) {\n+                deletedKeyToTxnDataMap.get(deletedKey).setDbObject(TableKey.NOT_EXISTS);\n+            }\n+        } catch (RuntimeException e) {\n+            throw handleException(e); // Make spotbugs happy.\n+        } catch (Exception e) {\n+            throw handleException(e);\n+        }\n+    }\n+\n+    private StorageMetadataException handleException(Throwable e) throws StorageMetadataException {\n+        e  = Exceptions.unwrap(e);\n+        if (e instanceof DataLogWriterNotPrimaryException) {\n+            return new StorageMetadataWritesFencedOutException(\"Transaction failed. Writer fenced off\", e);\n+        }\n+        if (e instanceof BadKeyVersionException) {\n+            return new StorageMetadataVersionMismatchException(\"Transaction failed. Version Mismatch.\", e);\n+        }\n+        return new StorageMetadataException(\"Transaction failed\", e);\n+    }\n+\n+    private void ensureInitialized() {\n+        if (!isTableInitialized.get()) {\n+            try {\n+                this.tableStore.createSegment(tableName, timeout).join();\n+                log.info(\"Created table segment {}\", tableName);\n+            } catch (CompletionException e) {\n+                if (e.getCause() instanceof StreamSegmentExistsException) {\n+                    log.info(\"Table segment {} already exists.\", tableName);\n+                }\n+            }\n+            isTableInitialized.set(true);\n+        }\n+    }\n+\n+    /**\n+     * Copy the version of one instance to other.\n+     * This only for test purposes. There is no easy way to do this method.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2NzQ3Ng==", "bodyText": "It also seems to be serializing the execution unnecessarily:\n\nput\nupdate versions after put\ndelete\nupdate version after delete\n\nwe can have a higher degree of parallelism here, which should be relevant for larger numbers of items in dataList. any idea of what we expect the size of dataList to be?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458667476", "createdAt": "2020-07-22T09:40:03Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {\n+                TableEntry entry = retValue.get(0);\n+                if (null != entry) {\n+                    val arr = entry.getValue();\n+                    TransactionData txnData = serializer.deserialize(arr);\n+                    txnData.setDbObject(entry.getKey().getVersion());\n+                    txnData.setPersisted(true);\n+                    return txnData;\n+                }\n+            }\n+        } catch (IllegalStateException e) {\n+            throw e;\n+        } catch (Exception e) {\n+            throw new StorageMetadataException(\"Error while reading\", e);\n+        }\n+\n+        return TransactionData.builder()\n+                .key(key)\n+                .persisted(true)\n+                .dbObject(TableKey.NOT_EXISTS)\n+                .build();\n+    }\n+\n+    /**\n+     * Writes transaction data from a given list to the metadata store.\n+     *\n+     * @param dataList List of transaction data to write.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected void writeAll(Collection<TransactionData> dataList) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<TableEntry> toUpdate = new ArrayList<>();\n+        HashMap<TableEntry, TransactionData> entryToTxnDataMap = new HashMap<TableEntry, TransactionData>();\n+        HashMap<TableKey, TransactionData> deletedKeyToTxnDataMap = new HashMap<TableKey, TransactionData>();\n+        List<TableKey> keysToDelete = new ArrayList<>();\n+        try {\n+            for (TransactionData txnData : dataList) {\n+                Preconditions.checkState(null != txnData.getDbObject());\n+\n+                long version = ((Long) txnData.getDbObject()).longValue();\n+                if (null == txnData.getValue()) {\n+                    val toDelete = TableKey.versioned(new ByteArraySegment(txnData.getKey().getBytes()),\n+                            TableKey.NO_VERSION);\n+                    keysToDelete.add(toDelete);\n+                    deletedKeyToTxnDataMap.put(toDelete, txnData);\n+                }\n+\n+                val arraySegment = serializer.serialize(txnData);\n+\n+                TableEntry tableEntry = TableEntry.versioned(\n+                        new ByteArraySegment(txnData.getKey().getBytes()),\n+                        arraySegment,\n+                        version);\n+                entryToTxnDataMap.put(tableEntry, txnData);\n+                toUpdate.add(tableEntry);\n+            }\n+\n+            // Now put uploaded keys.\n+            List<Long> ret = this.tableStore.put(tableName, toUpdate, timeout).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczNDExNA=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3NTg1NQ==", "bodyText": "I see that you have created a Simple class for each storage option. I understand that you have done to be able to create chunk-based storage adaptors. Why have you chosen this path rather than say having a single factory per option and configure using the configuration that we pass to the factory?\nWhat's the plan going forward? Once we deprecate and remove rolling storage, we keep the Simple term in the name, rename it, or what else?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458675855", "createdAt": "2020-07-22T09:54:42Z", "author": {"login": "fpj"}, "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3SimpleStorageFactory.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.storage.extendeds3;\n+\n+import com.emc.object.s3.S3Client;\n+import com.emc.object.s3.S3Config;\n+import com.emc.object.s3.jersey.S3JerseyClient;\n+import io.pravega.segmentstore.storage.Storage;\n+import io.pravega.segmentstore.storage.StorageFactory;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorage;\n+import io.pravega.segmentstore.storage.chunklayer.ChunkedSegmentStorageConfig;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * Factory for ExtendedS3 {@link Storage} implemented using {@link ChunkedSegmentStorage} and {@link ExtendedS3ChunkStorage}.\n+ */\n+@RequiredArgsConstructor\n+public class ExtendedS3SimpleStorageFactory implements StorageFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3ODI0OQ==", "bodyText": "Is the pair ROLLING_STORAGE and TABLE_BASED a viable option?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458678249", "createdAt": "2020-07-22T09:58:43Z", "author": {"login": "fpj"}, "path": "config/config.properties", "diffHunk": "@@ -97,6 +97,21 @@ pravegaservice.dataLog.impl.name=BOOKKEEPER\n # Default value: HDFS\n # pravegaservice.storage.impl.name=HDFS\n \n+\n+# Storage layout for Tier 2 storage.\n+# Valid values:\n+#   CHUNKED_STORAGE - Using ChunkedSegmentStorage.\n+#   ROLLING_STORAGE - Using RollingStorage.\n+# Default value: ROLLING_STORAGE\n+# pravegaservice.storage.layout=ROLLING_STORAGE\n+\n+# Storage metadata format for Tier 2 storage.\n+# Valid values:\n+#   TABLE_BASED   - Using ChunkedSegmentStorage.\n+#   HEADER_BASED  - Using AsyncStorageWrapper.\n+# Default value: HEADER_BASED\n+# pravegaservice.storage.metadata.format=HEADER_BASED", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDA0Mw==", "bodyText": "The indentation looks incorrect.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458680043", "createdAt": "2020-07-22T10:01:46Z", "author": {"login": "fpj"}, "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/StorageLoaderTest.java", "diffHunk": "@@ -49,16 +61,88 @@ public void testNoOpWithWithInMemoryStorage() throws Exception {\n \n         configBuilder\n                 .include(StorageExtraConfig.builder()\n-                .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n+                        .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MDYwOQ==", "bodyText": "Why is this being ignored? I actually see a few test cases ignored in this class.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458680609", "createdAt": "2020-07-22T10:02:47Z", "author": {"login": "fpj"}, "path": "segmentstore/server/host/src/test/java/io/pravega/segmentstore/server/host/StorageLoaderTest.java", "diffHunk": "@@ -49,16 +61,88 @@ public void testNoOpWithWithInMemoryStorage() throws Exception {\n \n         configBuilder\n                 .include(StorageExtraConfig.builder()\n-                .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n+                        .with(StorageExtraConfig.STORAGE_NO_OP_MODE, false));\n \n         builder = ServiceBuilder.newInMemoryBuilder(configBuilder.build())\n                 .withStorageFactory(setup -> {\n                     StorageLoader loader = new StorageLoader();\n-                    expectedFactory = loader.load(setup, \"INMEMORY\", executor);\n+                    expectedFactory = loader.load(setup, \"INMEMORY\", StorageLayoutType.ROLLING_STORAGE, StorageMetadataFormat.HEADER_BASED, executor);\n                     return expectedFactory;\n                 });\n         builder.initialize();\n         assertTrue(expectedFactory instanceof InMemoryStorageFactory);\n         builder.close();\n     }\n+\n+    @Test\n+    public void testFileSystemStorage() throws Exception {\n+        val storageType = ServiceConfig.StorageType.FILESYSTEM;\n+        ServiceBuilder builder = getStorageFactory(storageType, \"FILESYSTEM\", StorageLayoutType.ROLLING_STORAGE, StorageMetadataFormat.HEADER_BASED);\n+        assertTrue(expectedFactory instanceof FileSystemStorageFactory);\n+        builder.close();\n+    }\n+\n+    @Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4MTY0OA==", "bodyText": "Is it intentional to remove this getName() method? I guess it is fine as otherwise the build would fail...", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458681648", "createdAt": "2020-07-22T10:04:34Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/StorageFactoryCreator.java", "diffHunk": "@@ -18,14 +18,17 @@\n public interface StorageFactoryCreator {\n     /**\n      * API to create a storage factory with given configuration.\n-     * @param setup     Configuration for the factory.\n-     * @param executor  The storage factory is expected to use this ExecutorService for execution of its tasks.\n+     *\n+     * @param storageFactoryInfo Properties of storage factory to create.\n+     * @param setup              Configuration for the factory.\n+     * @param executor           The storage factory is expected to use this ExecutorService for execution of its tasks.\n      */\n-    StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor);\n+    StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor);\n \n     /**\n-     * The unique name for the storage factory.\n-     * @return  Unique name for the storage factory.\n+     * The properties of the available storage factories.\n+     *\n+     * @return The array of StorageFactoryInfo.\n      */\n-    String getName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDI3Ng==", "bodyText": "I don't understand what this exception path is doing, why is it correct to update the metadata and commit given that we suspect that there is a new owner?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458684276", "createdAt": "2020-07-22T10:09:30Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -244,23 +239,42 @@ private void claimOwnership(MetadataTransaction txn, SegmentMetadata segmentMeta\n                     segmentMetadata.getName(),\n                     lastChunk.getName(),\n                     lastChunk.getLength());\n-            ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);\n-            Preconditions.checkState(chunkInfo != null);\n-            Preconditions.checkState(lastChunk != null);\n-            // Adjust its length;\n-            if (chunkInfo.getLength() != lastChunk.getLength()) {\n-                Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n-                // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n-                lastChunk.setLength(chunkInfo.getLength());\n-                segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n-                txn.update(lastChunk);\n-                log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n+            try {\n+                ChunkInfo chunkInfo = chunkStorage.getInfo(lastChunkName);\n+                Preconditions.checkState(chunkInfo != null);\n+                Preconditions.checkState(lastChunk != null);\n+                // Adjust its length;\n+                if (chunkInfo.getLength() != lastChunk.getLength()) {\n+                    Preconditions.checkState(chunkInfo.getLength() > lastChunk.getLength());\n+                    // Whatever length you see right now is the final \"sealed\" length of the last chunk.\n+                    lastChunk.setLength(chunkInfo.getLength());\n+                    segmentMetadata.setLength(segmentMetadata.getLastChunkStartOffset() + lastChunk.getLength());\n+                    txn.update(lastChunk);\n+                    log.debug(\"{} claimOwnership - Length of last chunk adjusted - segment={}, last chunk={}, Length={}.\",\n+                            logPrefix,\n+                            segmentMetadata.getName(),\n+                            lastChunk.getName(),\n+                            chunkInfo.getLength());\n+                }\n+            } catch (ChunkNotFoundException e) {\n+                // This probably means that this instance is fenced out and newer instance truncated this segment.\n+                // Try a commit of unmodified data to fail fast.\n+                log.debug(\"{} claimOwnership - Last chunk was missing, failing fast - segment={}, last chunk={}.\",\n                         logPrefix,\n                         segmentMetadata.getName(),\n-                        lastChunk.getName(),\n-                        chunkInfo.getLength());\n+                        lastChunk.getName());\n+                txn.update(segmentMetadata);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY4NDQ0Mw==", "bodyText": "I don't understand this change, can you elaborate, please?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r458684443", "createdAt": "2020-07-22T10:09:50Z", "author": {"login": "fpj"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorage.java", "diffHunk": "@@ -1045,7 +1059,7 @@ private void concatUsingAppend(ConcatArgument[] concatArgs) throws ChunkStorageE\n                 }\n \n                 // Finally commit.\n-                txn.commit(chunksToDelete.size() == 0); // if layout did not change then commit with lazyWrite.\n+                txn.commit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 73}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54d71e184a464532a9547d3c3871164f3c8f7216", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/54d71e184a464532a9547d3c3871164f3c8f7216", "committedDate": "2020-07-22T17:33:12Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix StorageLoaderTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a739c45202b885b80082d2c9b2e386b17a75bdae", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/a739c45202b885b80082d2c9b2e386b17a75bdae", "committedDate": "2020-07-22T18:57:49Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Move all TableBasedMetadataStore related tests to TableBasedMetadataStoreTests.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88434db59cc483cf51008b10edc7a6eb48cc2848", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/88434db59cc483cf51008b10edc7a6eb48cc2848", "committedDate": "2020-07-22T21:38:50Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove unused code.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b2c256d17a74ac3d16a6b6831c90b9b4ec120eb", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/4b2c256d17a74ac3d16a6b6831c90b9b4ec120eb", "committedDate": "2020-07-22T22:01:03Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Fix white space.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/5c0d20dc7d564d13604bc69e454841f05dafc9bf", "committedDate": "2020-07-23T00:21:31Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Even more coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0MzAwNjE5", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-454300619", "createdAt": "2020-07-23T16:25:31Z", "commit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNjoyNTozMVrOG2SNCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxNjo0Mjo0NVrOG2S1wA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3NDUzOQ==", "bodyText": "Can we make sure that we throw an error (in the ServiceConfig constructor) if this happens. We want to prevent startup for illegal combinations.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459574539", "createdAt": "2020-07-23T16:25:31Z", "author": {"login": "andreipaduroiu"}, "path": "config/config.properties", "diffHunk": "@@ -97,6 +97,21 @@ pravegaservice.dataLog.impl.name=BOOKKEEPER\n # Default value: HDFS\n # pravegaservice.storage.impl.name=HDFS\n \n+\n+# Storage layout for Tier 2 storage.\n+# Valid values:\n+#   CHUNKED_STORAGE - Using ChunkedSegmentStorage.\n+#   ROLLING_STORAGE - Using RollingStorage.\n+# Default value: ROLLING_STORAGE\n+# pravegaservice.storage.layout=ROLLING_STORAGE\n+\n+# Storage metadata format for Tier 2 storage.\n+# Valid values:\n+#   TABLE_BASED   - Using ChunkedSegmentStorage.\n+#   HEADER_BASED  - Using AsyncStorageWrapper.\n+# Default value: HEADER_BASED\n+# pravegaservice.storage.metadata.format=HEADER_BASED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3ODI0OQ=="}, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODgwOQ==", "bodyText": "Remove this please", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578809", "createdAt": "2020-07-23T16:32:25Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -274,10 +274,7 @@ void endToEndProcess(boolean verifySegmentContent, boolean useChunkStorage) thro\n \n                 checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n-                //}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODg2NQ==", "bodyText": "and below", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578865", "createdAt": "2020-07-23T16:32:33Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -274,10 +274,7 @@ void endToEndProcess(boolean verifySegmentContent, boolean useChunkStorage) thro\n \n                 checkStorage(segmentContents, segmentStore);\n                 log.info(\"Finished Storage check.\");\n-                //}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODgwOQ=="}, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODk1MA==", "bodyText": "Remove this", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459578950", "createdAt": "2020-07-23T16:32:41Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -338,24 +332,23 @@ public void testEndToEndWithFencing() throws Exception {\n      * @throws Exception If an exception occurred.\n      */\n     @Test\n-    //@Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3OTA3Nw==", "bodyText": "and this", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459579077", "createdAt": "2020-07-23T16:32:52Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -908,18 +901,6 @@ private void checkAppendLeaks(ArrayList<ByteBuf> buffers) {\n         return retValue;\n     }\n \n-    /*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 212}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4MTIzOQ==", "bodyText": "The contract clearly says that you will get a List of size equal to the size of the key List you requested, regardless of whether those keys exist or not. You will not get 0 and you will not get 2.\nIf you want, a simple assert retValue.size() == 1 will do (and will execute only in tests), and we can remove all these unnecessary checks.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459581239", "createdAt": "2020-07-23T16:36:31Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/main/java/io/pravega/segmentstore/storage/metadata/TableBasedMetadataStore.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.storage.metadata;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.BufferView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.StreamSegmentExistsException;\n+import io.pravega.segmentstore.contracts.tables.BadKeyVersionException;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.contracts.tables.TableStore;\n+import io.pravega.segmentstore.storage.DataLogWriterNotPrimaryException;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.concurrent.CompletionException;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * {@link TableStore} based storage metadata store.\n+ */\n+@Slf4j\n+public class TableBasedMetadataStore extends BaseMetadataStore {\n+    private final TableStore tableStore;\n+    private final String tableName;\n+    private final Duration timeout = Duration.ofSeconds(1L);\n+    private final AtomicBoolean isTableInitialized = new AtomicBoolean(false);\n+    private final BaseMetadataStore.TransactionData.TransactionDataSerializer serializer = new BaseMetadataStore.TransactionData.TransactionDataSerializer();\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param tableName Name of the table segment.\n+     * @param tableStore Instance of the {@link TableStore}.\n+     */\n+    public TableBasedMetadataStore(String tableName, TableStore tableStore) {\n+        this.tableStore = Preconditions.checkNotNull(tableStore, \"tableStore\");\n+        this.tableName = Preconditions.checkNotNull(tableName, \"tableName\");\n+    }\n+\n+    /**\n+     * Reads a metadata record for the given key.\n+     *\n+     * @param key Key for the metadata record.\n+     * @return Associated {@link io.pravega.segmentstore.storage.metadata.BaseMetadataStore.TransactionData}.\n+     * @throws StorageMetadataException Exception related to storage metadata operations.\n+     */\n+    @Override\n+    protected TransactionData read(String key) throws StorageMetadataException {\n+        ensureInitialized();\n+        List<BufferView> keys = new ArrayList<>();\n+        keys.add(new ByteArraySegment(key.getBytes()));\n+        try {\n+            List<TableEntry> retValue = this.tableStore.get(tableName, keys, timeout).get();\n+            if (retValue.size() == 1) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjgzMw=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4Mzk1NA==", "bodyText": "Why did we add all these extra lines?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459583954", "createdAt": "2020-07-23T16:41:01Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -88,6 +86,7 @@\n     private int segmentStoreCount;\n     private int[] segmentStorePorts;\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDA3Nw==", "bodyText": "Extra space.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584077", "createdAt": "2020-07-23T16:41:14Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -161,7 +161,7 @@ public InProcPravegaCluster build() {\n \n     @Synchronized\n     public void setControllerPorts(int[] controllerPorts) {\n-        this.controllerPorts = Arrays.copyOf(controllerPorts, controllerPorts.length);\n+        this.controllerPorts = Arrays.copyOf( controllerPorts, controllerPorts.length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDIxOA==", "bodyText": "space", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584218", "createdAt": "2020-07-23T16:41:28Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -228,7 +228,7 @@ private void cleanUpZK() {\n         @Cleanup\n         CuratorFramework zclient = builder.build();\n         zclient.start();\n-        for (String path : pathsTobeCleaned) {\n+        for ( String path : pathsTobeCleaned ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDI3Nw==", "bodyText": "and here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584277", "createdAt": "2020-07-23T16:41:36Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -425,12 +425,12 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for (ServiceStarter starter : this.nodeServiceStarter) {\n+            for ( ServiceStarter starter : this.nodeServiceStarter ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDM0NA==", "bodyText": "and here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584344", "createdAt": "2020-07-23T16:41:41Z", "author": {"login": "andreipaduroiu"}, "path": "standalone/src/main/java/io/pravega/local/InProcPravegaCluster.java", "diffHunk": "@@ -425,12 +425,12 @@ public String getZkUrl() {\n     @Synchronized\n     public void close() throws Exception {\n         if (isInProcSegmentStore) {\n-            for (ServiceStarter starter : this.nodeServiceStarter) {\n+            for ( ServiceStarter starter : this.nodeServiceStarter ) {\n                 starter.shutdown();\n             }\n         }\n         if (isInProcController) {\n-            for (ControllerServiceMain controller : this.controllerServers) {\n+            for ( ControllerServiceMain controller : this.controllerServers ) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5c0d20dc7d564d13604bc69e454841f05dafc9bf"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU4NDk2MA==", "bodyText": "One possible solution that comes to my mind is having a unified enum that lists all legal combinations. Since we have 2 x 2 and one of those is not allowed, we are left with 3 legal combinations. Would this make things less prone to problems?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r459584960", "createdAt": "2020-07-23T16:42:45Z", "author": {"login": "andreipaduroiu"}, "path": "config/config.properties", "diffHunk": "@@ -97,6 +97,21 @@ pravegaservice.dataLog.impl.name=BOOKKEEPER\n # Default value: HDFS\n # pravegaservice.storage.impl.name=HDFS\n \n+\n+# Storage layout for Tier 2 storage.\n+# Valid values:\n+#   CHUNKED_STORAGE - Using ChunkedSegmentStorage.\n+#   ROLLING_STORAGE - Using RollingStorage.\n+# Default value: ROLLING_STORAGE\n+# pravegaservice.storage.layout=ROLLING_STORAGE\n+\n+# Storage metadata format for Tier 2 storage.\n+# Valid values:\n+#   TABLE_BASED   - Using ChunkedSegmentStorage.\n+#   HEADER_BASED  - Using AsyncStorageWrapper.\n+# Default value: HEADER_BASED\n+# pravegaservice.storage.metadata.format=HEADER_BASED", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY3ODI0OQ=="}, "originalCommit": {"oid": "41c8da911d4823374ed171deba9bab7d6ee3a926"}, "originalPosition": 17}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3935b46788108c5bcf1a5e9800845e785deae5d", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/f3935b46788108c5bcf1a5e9800845e785deae5d", "committedDate": "2020-07-23T17:28:30Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - More coverage.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/b93967814181a08081b8c3025588ecba5c6331e9", "committedDate": "2020-07-23T18:06:59Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Revert unitented whitespace in InProcPravegaCluster.java.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0OTU3NTcy", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-454957572", "createdAt": "2020-07-24T14:58:15Z", "commit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNDo1ODoxNlrOG2yr_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNTowODoxMVrOG2zE6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwNjc0OQ==", "bodyText": "maybe I'm confused, @sachin-j-joshi have you actually done the change suggested?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460106749", "createdAt": "2020-07-24T14:58:16Z", "author": {"login": "RaulGracia"}, "path": "bindings/src/main/java/io/pravega/storage/extendeds3/ExtendedS3StorageFactoryCreator.java", "diffHunk": "@@ -9,19 +9,43 @@\n  */\n package io.pravega.storage.extendeds3;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageManagerLayoutType;\n+import io.pravega.segmentstore.storage.StorageManagerType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class ExtendedS3StorageFactoryCreator implements StorageFactoryCreator {\n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new ExtendedS3StorageFactory(setup.getConfig(ExtendedS3StorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {\n+        Preconditions.checkNotNull(storageFactoryInfo, \"storageFactoryInfo\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNTM3Mg=="}, "originalCommit": {"oid": "e0281e13fb1602d279ac2064282546f02a07482b"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwODQ0Ng==", "bodyText": "This piece of code seems the same as ExtendedS3StorageFactoryCreator and perhaps other places. Wondering if we can do this in a common method, and then pass the specific instance on each implementation instead of repeating the same logic everywhere.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460108446", "createdAt": "2020-07-24T15:00:52Z", "author": {"login": "RaulGracia"}, "path": "bindings/src/main/java/io/pravega/storage/filesystem/FileSystemStorageFactoryCreator.java", "diffHunk": "@@ -9,20 +9,44 @@\n  */\n package io.pravega.storage.filesystem;\n \n+import com.google.common.base.Preconditions;\n import io.pravega.segmentstore.storage.ConfigSetup;\n import io.pravega.segmentstore.storage.StorageFactory;\n import io.pravega.segmentstore.storage.StorageFactoryCreator;\n+import io.pravega.segmentstore.storage.StorageFactoryInfo;\n+import io.pravega.segmentstore.storage.StorageMetadataFormat;\n+import io.pravega.segmentstore.storage.StorageLayoutType;\n+\n import java.util.concurrent.ScheduledExecutorService;\n \n public class FileSystemStorageFactoryCreator implements StorageFactoryCreator {\n \n     @Override\n-    public String getName() {\n-        return \"FILESYSTEM\";\n+    public StorageFactoryInfo[] getStorageFactories() {\n+        return new StorageFactoryInfo[]{\n+                StorageFactoryInfo.builder()\n+                        .name(\"FILESYSTEM\")\n+                        .storageMetadataFormat(StorageMetadataFormat.TABLE_BASED)\n+                        .storageLayoutType(StorageLayoutType.CHUNKED_STORAGE)\n+                        .build(),\n+                StorageFactoryInfo.builder()\n+                        .name(\"FILESYSTEM\")\n+                        .storageMetadataFormat(StorageMetadataFormat.HEADER_BASED)\n+                        .storageLayoutType(StorageLayoutType.ROLLING_STORAGE)\n+                        .build()\n+        };\n     }\n \n     @Override\n-    public StorageFactory createFactory(ConfigSetup setup, ScheduledExecutorService executor) {\n-        return new FileSystemStorageFactory(setup.getConfig(FileSystemStorageConfig::builder), executor);\n+    public StorageFactory createFactory(StorageFactoryInfo storageFactoryInfo, ConfigSetup setup, ScheduledExecutorService executor) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEwOTI3NA==", "bodyText": "Is this change necessary? The previous indentation seemed ok.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460109274", "createdAt": "2020-07-24T15:02:07Z", "author": {"login": "RaulGracia"}, "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -76,21 +91,21 @@ private StreamSegmentInformation(String name, long startOffset, long length, boo\n      */\n     public static StreamSegmentInformationBuilder from(SegmentProperties base) {\n         return StreamSegmentInformation.builder()\n-                                       .name(base.getName())\n-                                       .startOffset(base.getStartOffset())\n-                                       .length(base.getLength())\n-                                       .sealed(base.isSealed())\n-                                       .deleted(base.isDeleted())\n-                                       .lastModified(base.getLastModified())\n-                                       .attributes(base.getAttributes());\n+                .name(base.getName())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDExMzEzMA==", "bodyText": "Isn't this equivalent to what it was before? A boolean set to true and then if (checkClosed).", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460113130", "createdAt": "2020-07-24T15:08:11Z", "author": {"login": "RaulGracia"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentStoreTestBase.java", "diffHunk": "@@ -671,19 +686,25 @@ private void checkReads(HashMap<String, ByteArrayOutputStream> segmentContents,\n             // This is gracefully handled by retries in AppendProcessor and/or Client, but in this case, we simply have to\n             // do the retries ourselves, hoping that the callback eventually executes.\n             Retry.withExpBackoff(100, 2, 10, TIMEOUT.toMillis() / 5)\n-                 .retryWhen(ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException)\n-                 .run(() -> {\n-                     checkSegmentReads(segmentName, expectedCurrentOffset, segmentLength, store, expectedData);\n-                     return null;\n-                 });\n+                    .retryWhen(ex -> Exceptions.unwrap(ex) instanceof StreamSegmentNotExistsException || info.get().getLength() != info.get().getStorageLength())\n+                    .run(() -> {\n+                        val latestInfo =  (StreamSegmentInformation) store.getStreamSegmentInfo(segmentName, TIMEOUT).join();\n+                        try {\n+                            checkSegmentReads(segmentName, expectedCurrentOffset, info.get().getLength(), store, expectedData);\n+                        } catch (Exception ex2) {\n+                            log.debug(\"Exception during checkReads\", ex2);\n+                        }\n+                        info.set(latestInfo);\n+                        return null;\n+                    });\n         }\n     }\n \n     private void checkSegmentReads(String segmentName, AtomicLong expectedCurrentOffset, long segmentLength, StreamSegmentStore store, byte[] expectedData) throws Exception {\n         @Cleanup\n         ReadResult readResult = store.read(segmentName, expectedCurrentOffset.get(), (int) (segmentLength - expectedCurrentOffset.get()), TIMEOUT).join();\n         Assert.assertTrue(\"Empty read result for segment \" + segmentName, readResult.hasNext());\n-\n+        boolean checkClosed = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "originalPosition": 342}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0OTkxMzY1", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-454991365", "createdAt": "2020-07-24T15:41:33Z", "commit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNTo0MTozNFrOG20Tnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQxNTo0MjoyMVrOG20Vfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzI3OQ==", "bodyText": "okay", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460133279", "createdAt": "2020-07-24T15:41:34Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -177,6 +180,29 @@ private MetadataStore createMetadataStore() {\n         return builder.build();\n     }\n \n+    /**\n+     * Initializes storage.\n+     *\n+     * @throws Exception\n+     */\n+    private void initializeStorage() throws Exception {\n+        this.storage.initialize(this.metadata.getContainerEpoch());\n+\n+        if (this.storage instanceof ChunkedSegmentStorage) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU4NjE1MA=="}, "originalCommit": null, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA==", "bodyText": "we are not dealing with InterruptedException here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460133758", "createdAt": "2020-07-24T15:42:21Z", "author": {"login": "eolivelli"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -253,7 +278,11 @@ protected void doStart() {\n     }\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n-        this.storage.initialize(this.metadata.getContainerEpoch());\n+        try {\n+            initializeStorage();\n+        } catch (Exception ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5edcd82ff198b871e342562c43769b919b340f0e", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/5edcd82ff198b871e342562c43769b919b340f0e", "committedDate": "2020-07-24T16:41:30Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1OTA2NzQ2", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-455906746", "createdAt": "2020-07-27T15:44:49Z", "commit": {"oid": "5edcd82ff198b871e342562c43769b919b340f0e"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNTo0NDo0OVrOG3oZ8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QxNTo0NDo1NlrOG3oaVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njg2NQ==", "bodyText": "Why is this ignored?", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460986865", "createdAt": "2020-07-27T15:44:49Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -69,7 +70,14 @@ protected ServiceBuilder createBuilder(ServiceBuilderConfig.Builder builderConfi\n     @Override\n     @Test\n     public void testEndToEnd() throws Exception {\n-        endToEndProcess(false);\n+        endToEndProcess(false, false);\n+    }\n+\n+    @Override\n+    @Test\n+    @Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5edcd82ff198b871e342562c43769b919b340f0e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDk4Njk2NA==", "bodyText": "And here", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r460986964", "createdAt": "2020-07-27T15:44:56Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/store/StreamSegmentServiceNoOpWriteOnlyTests.java", "diffHunk": "@@ -79,6 +87,13 @@ public void testEndToEnd() throws Exception {\n     @Override\n     @Test\n     public void testEndToEndWithFencing() throws Exception {\n-        endToEndProcessWithFencing(false);\n+        endToEndProcessWithFencing(false, false);\n+    }\n+\n+    @Override\n+    @Test\n+    @Ignore", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5edcd82ff198b871e342562c43769b919b340f0e"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf", "committedDate": "2020-07-27T17:26:18Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Remove storage fromat as config option.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NTU3NDQy", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-456557442", "createdAt": "2020-07-28T11:54:58Z", "commit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2NzQxMTk4", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-456741198", "createdAt": "2020-07-28T15:16:51Z", "commit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNToxNjo1MlrOG4Ru3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQxNToyNTozNFrOG4SHmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2Mzk2Ng==", "bodyText": "Clearly indicate this is EXPERIMENTAL and not to be used in production.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461663966", "createdAt": "2020-07-28T15:16:52Z", "author": {"login": "andreipaduroiu"}, "path": "config/config.properties", "diffHunk": "@@ -97,6 +97,14 @@ pravegaservice.dataLog.impl.name=BOOKKEEPER\n # Default value: HDFS\n # pravegaservice.storage.impl.name=HDFS\n \n+\n+# Storage layout for Tier 2 storage.\n+# Valid values:\n+#   CHUNKED_STORAGE - Using ChunkedSegmentStorage.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NDkwNQ==", "bodyText": "Since you've added this, I want to add a precondition check to validate that 0<=storageLength<=length (see above how we do it for startOffset.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461664905", "createdAt": "2020-07-28T15:18:14Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -46,24 +53,30 @@\n     /**\n      * Creates a new instance of the StreamSegmentInformation class.\n      *\n-     * @param name         The name of the StreamSegment.\n-     * @param startOffset  The first available offset in this StreamSegment.\n-     * @param length       The length of the StreamSegment.\n-     * @param sealed       Whether the StreamSegment is sealed (for modifications).\n-     * @param deleted      Whether the StreamSegment is deleted (does not exist).\n-     * @param attributes   The attributes of this StreamSegment.\n-     * @param lastModified The last time the StreamSegment was modified.\n+     * @param name             The name of the StreamSegment.\n+     * @param startOffset      The first available offset in this StreamSegment.\n+     * @param length           The length of the StreamSegment.\n+     * @param sealed           Whether the StreamSegment is sealed (for modifications).\n+     * @param deleted          Whether the StreamSegment is deleted (does not exist).\n+     * @param storageLength    Storage length.\n+     * @param sealedInStorage  Whether the StreamSegment is sealed (for modifications) in storage.\n+     * @param deletedInStorage Whether the StreamSegment is deleted (does not exist) in storage.\n+     * @param attributes       The attributes of this StreamSegment.\n+     * @param lastModified     The last time the StreamSegment was modified.\n      */\n     @Builder\n-    private StreamSegmentInformation(String name, long startOffset, long length, boolean sealed, boolean deleted,\n-                                    Map<UUID, Long> attributes, ImmutableDate lastModified) {\n+    private StreamSegmentInformation(String name, long startOffset, long length, long storageLength, boolean sealed, boolean deleted,\n+                                     boolean sealedInStorage, boolean deletedInStorage, Map<UUID, Long> attributes, ImmutableDate lastModified) {\n         Preconditions.checkArgument(startOffset >= 0, \"startOffset must be a non-negative number.\");\n         Preconditions.checkArgument(length >= startOffset, \"length must be a non-negative number and greater than startOffset.\");\n         this.name = Exceptions.checkNotNullOrEmpty(name, \"name\");\n         this.startOffset = startOffset;\n         this.length = length;\n+        this.storageLength = storageLength;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NTMxNQ==", "bodyText": "Precondition check. If deletedInStorage == true, then deleted must be true as well.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461665315", "createdAt": "2020-07-28T15:18:48Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/StreamSegmentInformation.java", "diffHunk": "@@ -46,24 +53,30 @@\n     /**\n      * Creates a new instance of the StreamSegmentInformation class.\n      *\n-     * @param name         The name of the StreamSegment.\n-     * @param startOffset  The first available offset in this StreamSegment.\n-     * @param length       The length of the StreamSegment.\n-     * @param sealed       Whether the StreamSegment is sealed (for modifications).\n-     * @param deleted      Whether the StreamSegment is deleted (does not exist).\n-     * @param attributes   The attributes of this StreamSegment.\n-     * @param lastModified The last time the StreamSegment was modified.\n+     * @param name             The name of the StreamSegment.\n+     * @param startOffset      The first available offset in this StreamSegment.\n+     * @param length           The length of the StreamSegment.\n+     * @param sealed           Whether the StreamSegment is sealed (for modifications).\n+     * @param deleted          Whether the StreamSegment is deleted (does not exist).\n+     * @param storageLength    Storage length.\n+     * @param sealedInStorage  Whether the StreamSegment is sealed (for modifications) in storage.\n+     * @param deletedInStorage Whether the StreamSegment is deleted (does not exist) in storage.\n+     * @param attributes       The attributes of this StreamSegment.\n+     * @param lastModified     The last time the StreamSegment was modified.\n      */\n     @Builder\n-    private StreamSegmentInformation(String name, long startOffset, long length, boolean sealed, boolean deleted,\n-                                    Map<UUID, Long> attributes, ImmutableDate lastModified) {\n+    private StreamSegmentInformation(String name, long startOffset, long length, long storageLength, boolean sealed, boolean deleted,\n+                                     boolean sealedInStorage, boolean deletedInStorage, Map<UUID, Long> attributes, ImmutableDate lastModified) {\n         Preconditions.checkArgument(startOffset >= 0, \"startOffset must be a non-negative number.\");\n         Preconditions.checkArgument(length >= startOffset, \"length must be a non-negative number and greater than startOffset.\");\n         this.name = Exceptions.checkNotNullOrEmpty(name, \"name\");\n         this.startOffset = startOffset;\n         this.length = length;\n+        this.storageLength = storageLength;\n         this.sealed = sealed;\n+        this.sealedInStorage = sealedInStorage;\n         this.deleted = deleted;\n+        this.deletedInStorage = deletedInStorage;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY2NzgzMA==", "bodyText": "We do not do this anywhere else in the code. If this must be changed, then we should do it throughout the codebase, not just here.\n@sachin-j-joshi I would suggest to clean this up and add a follow-up issue that will add a helper in Futures to do this.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461667830", "createdAt": "2020-07-28T15:22:13Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/StreamSegmentContainer.java", "diffHunk": "@@ -253,7 +278,11 @@ protected void doStart() {\n     }\n \n     private CompletableFuture<Void> initializeSecondaryServices() {\n-        this.storage.initialize(this.metadata.getContainerEpoch());\n+        try {\n+            initializeStorage();\n+        } catch (Exception ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDEzMzc1OA=="}, "originalCommit": {"oid": "b93967814181a08081b8c3025588ecba5c6331e9"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY3MDI5OA==", "bodyText": "Can you make 42 and 10 class-level constants? They are used everywhere in these tests.", "url": "https://github.com/pravega/pravega/pull/4769#discussion_r461670298", "createdAt": "2020-07-28T15:25:34Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/storage/src/test/java/io/pravega/segmentstore/storage/chunklayer/ChunkedSegmentStorageTests.java", "diffHunk": "@@ -1505,6 +1502,191 @@ private void testTruncate(long maxChunkLength, long truncateAt, int chunksCountB\n         TestUtils.checkChunksExistInStorage(testContext.storageProvider, testContext.metadataStore, testSegmentName);\n     }\n \n+    /**\n+     * Test read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testReadWriteWithMultipleFailovers() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long epoch = 42;\n+        ArrayList<Long> lengths = new ArrayList<>();\n+        for (int i = 1; i < 5; i++) {\n+            // Create a new test context and initialize with new epoch.\n+            val hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+            testContext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[i]), i, null).join();\n+            writeAt += i;\n+            lengths.add((long) i);\n+\n+            // Read in same epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fork the context.\n+            val oldTestCotext = testContext;\n+            testContext = oldTestCotext.fork(epoch++);\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fence out old store.\n+            oldTestCotext.metadataStore.markFenced();\n+\n+            // Read in new epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+        }\n+\n+        int total = 10;\n+\n+        // Create a new test context and initialize with new epoch.\n+        testContext = testContext.fork(epoch++);\n+\n+        checkDataRead(testSegmentName, testContext, 0, total);\n+    }\n+\n+    /**\n+     * Test read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testReadWriteWithMultipleFailoversWithGarbage() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long epoch = 42;\n+        SegmentHandle hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+        ArrayList<Long> lengths = new ArrayList<>();\n+        for (int i = 1; i < 5; i++) {\n+            // Create a new test context and initialize with new epoch.\n+            testContext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[i]), i, null).join();\n+            writeAt += i;\n+            lengths.add((long) i);\n+\n+            // Read in same epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Fork the context.\n+            val oldTestCotext = testContext;\n+            testContext = oldTestCotext.fork(epoch++);\n+            TestUtils.checkSegmentLayout(testContext.metadataStore, testSegmentName, Longs.toArray(lengths));\n+\n+            // Make sure to open segment with new instance before writing garbage to old instance.\n+            hWrite =  testContext.storageManager.openWrite(testSegmentName).get();\n+\n+            // Write some garbage\n+            oldTestCotext.storageManager.write(hWrite, writeAt, new ByteArrayInputStream(new byte[10]), 10, null).join();\n+\n+            // Fence out old store.\n+            boolean exceptionThrown = false;\n+            oldTestCotext.metadataStore.markFenced();\n+\n+            AssertExtensions.assertFutureThrows(\"conact() allowed for invalid parameters\",\n+                    oldTestCotext.storageManager.write(hWrite, writeAt + 10, new ByteArrayInputStream(new byte[10]), 10, null),\n+                    ex -> ex instanceof StorageNotPrimaryException);\n+            // Read in new epoch.\n+            checkDataRead(testSegmentName, testContext, 0, writeAt);\n+        }\n+\n+        int total = 10;\n+\n+        // Create a new test context and initialize with new epoch.\n+        testContext = testContext.fork(epoch++);\n+\n+        checkDataRead(testSegmentName, testContext, 0, total);\n+    }\n+\n+    /**\n+     * Test truncate, read and write with multiple failovers.\n+     *\n+     * @throws Exception Exception if any.\n+     */\n+    @Test\n+    public void testTruncateWithMultipleFailoversWithGarbage() throws Exception {\n+        String testSegmentName = \"foo\";\n+        TestContext testContext = getTestContext();\n+\n+        // Create\n+        testContext.storageManager.create(testSegmentName, null).get();\n+\n+        // Write some data.\n+        long writeAt = 0;\n+        long truncateAt = 0;\n+        long epoch = 42;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee9ee28b3c0bd7db7347ee5601ab13032c1a8ddf"}, "originalPosition": 175}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abc00aed5ee5b78eb0335f7e0c82506383412faf", "author": {"user": {"login": "sachin-j-joshi", "name": "Sachin Jayant Joshi"}}, "url": "https://github.com/pravega/pravega/commit/abc00aed5ee5b78eb0335f7e0c82506383412faf", "committedDate": "2020-07-28T17:59:41Z", "message": "Issue 4676: (PDP-34) Initial Implementation (Part 3 of 4) - Address review comments.\n\nSigned-off-by: Sachin Joshi <sachin.joshi@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2OTkzMzM1", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-456993335", "createdAt": "2020-07-28T20:38:44Z", "commit": {"oid": "abc00aed5ee5b78eb0335f7e0c82506383412faf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MjI3MTEw", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-457227110", "createdAt": "2020-07-29T06:26:21Z", "commit": {"oid": "abc00aed5ee5b78eb0335f7e0c82506383412faf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MzAyNzA3", "url": "https://github.com/pravega/pravega/pull/4769#pullrequestreview-457302707", "createdAt": "2020-07-29T08:26:39Z", "commit": {"oid": "abc00aed5ee5b78eb0335f7e0c82506383412faf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3461, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}