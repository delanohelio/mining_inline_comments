{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk5NTE5NzMz", "number": 5239, "title": "Issue 5233: (SegmentStore) Flush-to-Storage API", "bodyText": "Change log description\n\nAdded an API on the SegmentContainer to fully flush all Tier 1 and in-memory data to LTS/Storage.\nThis API is experimental and should only be used to aid testing. It is not yet supported for production use.\n\nPurpose of the change\nFixes #5233.\nWhat the code does\n\nSegmentContainer.flushToStorage\n\nThis method invokes LogFlusher to expedite the movement of all outstanding Tier 1 data into LTS.\n\n\nLogFlusher\n\nWorks in 3 steps, with each step making sure that all data from previous steps are persisted to LTS.\nStep 1: Creates a Metadata Checkpoint, extracts the Sequence Number for it, and instructs StorageWriter to flush all data up to, and including that Sequence Number.\n\nThis is executed in a loop as long as the StorageWriter reports that it had data to flush. The loop is required because each iteration of the StorageWriter may have, as effect, the generation of additional Tier 1 operations (ex: Attribute Aggregator, Table Segment Indexing, etc.)\nThe repeated invocations of the checkpoint-writer flush should converge into a stable state where a writer iteration has no further effects; as such, the subsequent iteration will report it had nothing to do.\n\n\nStep 2: Persist all in-memory Segment Metadata to the Container Metadata Table Segment.\n\nThis will include the effects of any modifications done at Step 1.\n\n\nStep 3: repeat Step 1 to ensure that all modifications done at Step 2 are also persisted to LTS.\n\n\nStorageWriter\n\nAdded a new API forceFlush which sets a flag on the WriterState pointing to the desired \"flush-to-sequence-number\".\nThe StorageWriter will work (as usual) but pass the flag down to its segment processors instructing them to fully flush whatever outstanding data they have (i.e., ignore the time or size-based flush thresholds).\nWhen the Storage Writer has flushed everything past the Operation with given sequence number, it notifies the requestor that the flush has completed.\n\n\n\nHow to verify it\nAll unit tests must pass.", "createdAt": "2020-10-07T21:12:22Z", "url": "https://github.com/pravega/pravega/pull/5239", "merged": true, "mergeCommit": {"oid": "bf1f5928652094952d6bf4ffa8794717b58eb523"}, "closed": true, "closedAt": "2020-10-13T21:04:06Z", "author": {"login": "andreipaduroiu"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdQBuPRAH2gAyNDk5NTE5NzMzOmFiODk5YjdjNzZhMGU1ZmFkNWJhNmIyYjJlODExMTkyNTI1MDJjM2U=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdSNY5fAFqTUwNzc0NDQwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ab899b7c76a0e5fad5ba6b2b2e81119252502c3e", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/ab899b7c76a0e5fad5ba6b2b2e81119252502c3e", "committedDate": "2020-10-07T00:20:26Z", "message": "Force Flush API.\nStorageWriter + SegmentAggregator + AttributeAggregator + Tests.\nMetadataCleaner + Tests\nStreamSegmentContainer + impl (needs tests).\nLogFlusher (needs tests)\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb1555730f6247f4f038979fcce04559dbf31a8c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/eb1555730f6247f4f038979fcce04559dbf31a8c", "committedDate": "2020-10-07T21:10:54Z", "message": "unit tests for LogFlusher and StreamSegmentContainer. Bug fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d71382cb726150f905f8348bfe59a92c4514611", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/3d71382cb726150f905f8348bfe59a92c4514611", "committedDate": "2020-10-07T21:12:40Z", "message": "unit tests for LogFlusher and StreamSegmentContainer. Bug fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff6dcb714e0ec65d3d14983e1def16c4da907c2f", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/ff6dcb714e0ec65d3d14983e1def16c4da907c2f", "committedDate": "2020-10-07T21:12:57Z", "message": "Merge branch 'master' into issue-5233-flush"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cc9c3800e93ec43dbf6959ce417cd7f085dee2a", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/4cc9c3800e93ec43dbf6959ce417cd7f085dee2a", "committedDate": "2020-10-07T22:12:34Z", "message": "Fixed a possible concurrency bug.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/d1820301b71b8963f78b51b1f39524199654c4fc", "committedDate": "2020-10-08T19:13:15Z", "message": "Merge branch 'master' into issue-5233-flush"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2ODY5NjM4", "url": "https://github.com/pravega/pravega/pull/5239#pullrequestreview-506869638", "createdAt": "2020-10-12T19:39:07Z", "commit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxOTozOTowOFrOHgK5hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxOTo0ODozMVrOHgLHtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQ5NTA0Ng==", "bodyText": "Not sure why we don't want to flush deleted and merged segment.", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503495046", "createdAt": "2020-10-12T19:39:08Z", "author": {"login": "sachin-j-joshi"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/MetadataCleaner.java", "diffHunk": "@@ -100,6 +101,24 @@ protected void doStop() {\n \n     //endregion\n \n+    /**\n+     * Persists the metadata of all active Segments from the Container's metadata into the {@link MetadataStore}.\n+     * This method does not evict or otherwise perform any cleanup tasks on the Container or its Metadata, nor does it\n+     * interfere with the regular operation of {@link #runOnce()}.\n+     *\n+     * @param timeout Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, indicates that the operation completed.\n+     */\n+    CompletableFuture<Void> persistAll(Duration timeout) {\n+        val tasks = this.metadata.getAllStreamSegmentIds().stream()\n+                .map(this.metadata::getStreamSegmentMetadata)\n+                .filter(Objects::nonNull)\n+                .filter(sm -> !sm.isDeleted() && !sm.isMerged())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQ5ODY3Nw==", "bodyText": "What happens when there is nothing to flush?", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503498677", "createdAt": "2020-10-12T19:48:31Z", "author": {"login": "sachin-j-joshi"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/WriterState.java", "diffHunk": "@@ -122,6 +129,57 @@ long getLastReadSequenceNumber() {\n     void setLastReadSequenceNumber(long value) {\n         Preconditions.checkArgument(value >= this.lastReadSequenceNumber.get(), \"New LastReadSequenceNumber cannot be smaller than the previous one.\");\n         this.lastReadSequenceNumber.set(value);\n+        recordReadComplete();\n+    }\n+\n+    /**\n+     * Indicates the fact that the {@link StorageWriter} has completed reading.\n+     */\n+    void recordReadComplete() {\n+        val ffc = this.forceFlushContext.get();\n+        if (ffc != null) {\n+            ffc.setLastReadSequenceNumber(this.lastReadSequenceNumber.get());\n+        }\n+    }\n+\n+    /**\n+     * Indicates the fact that the {@link StorageWriter} has completed a flush stage.\n+     *\n+     * @param result The {@link WriterFlushResult} summarizing the flush stage.\n+     */\n+    void recordFlushComplete(WriterFlushResult result) {\n+        val ffc = this.forceFlushContext.get();\n+        if (ffc != null && ffc.flushComplete(result)) {\n+            this.forceFlushContext.set(null);\n+            ffc.getCompletion().complete(ffc.isAnythingFlushed());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3MDczNTg0", "url": "https://github.com/pravega/pravega/pull/5239#pullrequestreview-507073584", "createdAt": "2020-10-13T05:12:52Z", "commit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwNToyMTozM1rOHgVx_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwODozODowNFrOHgbsBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY3MzM0Mg==", "bodyText": "Should it be mustFlush instead of mustFlush()?", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503673342", "createdAt": "2020-10-13T05:21:33Z", "author": {"login": "ManishKumarKeshri"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/WriterSegmentProcessor.java", "diffHunk": "@@ -54,9 +54,22 @@\n     /**\n      * Flushes the contents of the Processor.\n      *\n+     * @param force   If true, force-flushes everything accumulated in the {@link WriterSegmentProcessor}, regardless of\n+     *                the value returned by {@link #mustFlush()}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzY5Mzc0MA==", "bodyText": "Will MAX_FLUSH_ATTEMPTS be reached before flushing all operations? I mean, what if there is still something to flush after attemptNo has reached to MAX_FLUSH_ATTEMPTS.", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503693740", "createdAt": "2020-10-13T06:23:37Z", "author": {"login": "ManishKumarKeshri"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/containers/LogFlusher.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.containers;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.RetriesExhaustedException;\n+import io.pravega.segmentstore.server.OperationLog;\n+import io.pravega.segmentstore.server.Writer;\n+import java.time.Duration;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * Utility class that helps the {@link StreamSegmentContainer} to force-flush all the data to the underlying Storage.\n+ */\n+@RequiredArgsConstructor\n+@Slf4j\n+class LogFlusher {\n+    /**\n+     * Maximum number of {@link Writer} flushes to attempt until no more flush progress is expected to be made.\n+     */\n+    @VisibleForTesting\n+    static final int MAX_FLUSH_ATTEMPTS = 10;\n+    private final int containerId;\n+    @NonNull\n+    private final OperationLog durableLog;\n+    @NonNull\n+    private final Writer writer;\n+    @NonNull\n+    private final MetadataCleaner metadataCleaner;\n+    @NonNull\n+    private final ScheduledExecutorService executor;\n+\n+    /**\n+     * Flushes every outstanding Operation in the Container's {@link OperationLog} to Storage. When this method completes:\n+     * - Every Operation that has been initiated in the {@link OperationLog} prior to the invocation of this method\n+     * will be flushed to the Storage via the {@link Writer}.\n+     * - The effects of such Operations on the Container's Metadata will be persisted to the Container's Metadata Store.\n+     * - The Container's Metadata Store will be persisted (and fully indexed) in Storage (it will contain all changes\n+     * from the previous step).\n+     *\n+     * @param timeout Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation completed successfully. If the\n+     * operation failed, it will be failed with the appropriate exception.\n+     */\n+    public CompletableFuture<Void> flushToStorage(Duration timeout) {\n+        // 1. Flush everything we have so far.\n+        // 2. Flush all in-memory Segment metadata to the Metadata Store.\n+        // 3. Flush everything we have so far (again) - to make sure step 2 is persisted in Storage.\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        log.info(\"LogFlusher[{}]: Flushing outstanding data.\", this.containerId);\n+        return flushAll(timer)\n+                .thenComposeAsync(v -> {\n+                    log.info(\"LogFlusher[{}]: Persisting active segment metadata.\", this.containerId);\n+                    return this.metadataCleaner.persistAll(timer.getRemaining());\n+                }, this.executor)\n+                .thenComposeAsync(v -> {\n+                    log.info(\"LogFlusher[{}]: Flushing metadata store.\", this.containerId);\n+                    return flushAll(timer);\n+                }, this.executor);\n+    }\n+\n+    private CompletableFuture<Void> flushAll(TimeoutTimer timer) {\n+        // 1. Queue a checkpoint and get its SeqNo. This is poor man's way of ensuring all initiated ops are in.\n+        // 2. Tell StorageWriter to flush all (new API, with seqNo). Includes: segment data and table segment indexing.\n+        // 3. Repeat 1+2 until StorageWriter claims there is nothing more to flush.\n+        val flushAgain = new AtomicBoolean(true);\n+        val attemptNo = new AtomicInteger(0);\n+        return Futures.loop(\n+                () -> flushAgain.get() && attemptNo.getAndIncrement() < MAX_FLUSH_ATTEMPTS,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcwMzUwOQ==", "bodyText": "#mustFlush, as I see in other places.", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503703509", "createdAt": "2020-10-13T06:46:58Z", "author": {"login": "ManishKumarKeshri"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "diffHunk": "@@ -190,14 +190,16 @@ public boolean mustFlush() {\n     /**\n      * Flushes the contents of the Aggregator to the Storage.\n      *\n+     * @param force   If true, force-flushes everything accumulated in the {@link AttributeAggregator}, regardless of\n+     *                the value returned by {@link #mustFlush()}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzc3MDExNg==", "bodyText": "One question: why didn't you use INFREQUENT_FLUSH_WRITER_CONFIG?", "url": "https://github.com/pravega/pravega/pull/5239#discussion_r503770116", "createdAt": "2020-10-13T08:38:04Z", "author": {"login": "ManishKumarKeshri"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/writer/SegmentAggregatorTests.java", "diffHunk": "@@ -683,6 +683,55 @@ public void testFlushEmptyAppend() throws Exception {\n         verifySegmentData(expectedData, context);\n     }\n \n+    /**\n+     * Tests the flush() method with the force flag set.\n+     * Verifies both length-based and time-based flush triggers, as well as flushing rather large operations.\n+     */\n+    @Test\n+    public void testFlushForced() throws Exception {\n+        final WriterConfig config = DEFAULT_CONFIG;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3Njg0MjM4", "url": "https://github.com/pravega/pravega/pull/5239#pullrequestreview-507684238", "createdAt": "2020-10-13T17:43:33Z", "commit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3NzQ0NDAx", "url": "https://github.com/pravega/pravega/pull/5239#pullrequestreview-507744401", "createdAt": "2020-10-13T19:03:50Z", "commit": {"oid": "d1820301b71b8963f78b51b1f39524199654c4fc"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3895, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}