{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYxNjgxNTYy", "number": 4485, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwNzoyMzozOVrODXUa5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo1NDoxM1rODYXc3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1Nzc4NDA3OnYy", "diffSide": "RIGHT", "path": "common/src/main/java/io/pravega/common/util/btree/BTreeIndex.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQwNzoyMzozOVrOFcktPA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMVQxNTo0Njo1MFrOFcmDqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUwNTg1Mg==", "bodyText": "Will some sort of compare-and-set help here in preventing races?\nYou know the expected previous state", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r365505852", "createdAt": "2020-01-11T07:23:39Z", "author": {"login": "eolivelli"}, "path": "common/src/main/java/io/pravega/common/util/btree/BTreeIndex.java", "diffHunk": "@@ -790,14 +792,17 @@ private ByteArraySegment generateMinKey() {\n         long rootMinOffset = lastPage.getMinOffset();\n         assert rootMinOffset >= 0 : \"root.MinOffset not set\";\n         return this.write.apply(pages, oldOffsets, rootMinOffset, timeout)\n-                         .thenApply(indexLength -> setState(indexLength, rootOffset, rootLength).length);\n+                .thenApply(indexLength -> {\n+                    setState(indexLength, rootOffset, rootLength);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b3db6abe4464e1bf77803acade2fcff4035e6eb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUyNzk3OQ==", "bodyText": "It's not just in memory state that I care about. What I noticed is that, at least for NFS Tier 2 mounts, even if I send a 1MB data block, if we crash while writing it, part of it may have been durably stored onto whatever is behind the NFS mount. While not a problem for regular stream segments (since they're append-only and we can always resume from where we left off), for BTreeIndex it's different. It needs the file (at least the last 12 bytes of it) to be structured, otherwise it won't be able to read the BTree Pages properly. If we wanted to write 10 pages, for example, but crashed after writing 6.5 of them, then the data structure won't be able to recover afterwards.\nGoing back to your question. I need to persist somewhere the pointer to the root page of the BTree index. Previously it was the last 12 bytes of the Attribute File, but since that's not reliable, one of the changes in this PR is to also store it in the main Segment's Core Attributes (these attributes have a different lifecycle so they're not susceptible to this problem). If we crash in the middle of a write (or just after a good write but before persisting the new pointer), we'll always be able to recover from the previous BTree Index pointer, and try again.\nPlease wait until I finish this PR. I only submitted it so I can get some Travis builds done and get some system tests executed, but I am not ready for review. I'll add the appropriate description and explanations when I'm done, most likely in a few days.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r365527979", "createdAt": "2020-01-11T15:46:50Z", "author": {"login": "andreipaduroiu"}, "path": "common/src/main/java/io/pravega/common/util/btree/BTreeIndex.java", "diffHunk": "@@ -790,14 +792,17 @@ private ByteArraySegment generateMinKey() {\n         long rootMinOffset = lastPage.getMinOffset();\n         assert rootMinOffset >= 0 : \"root.MinOffset not set\";\n         return this.write.apply(pages, oldOffsets, rootMinOffset, timeout)\n-                         .thenApply(indexLength -> setState(indexLength, rootOffset, rootLength).length);\n+                .thenApply(indexLength -> {\n+                    setState(indexLength, rootOffset, rootLength);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTUwNTg1Mg=="}, "originalCommit": {"oid": "0b3db6abe4464e1bf77803acade2fcff4035e6eb"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODczODQ3OnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/WriterConfig.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTozNDozM1rOFeLqHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNTo0NzowOVrOFeeCyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5MjYwNQ==", "bodyText": "It seems odd to configure a minimum in terms of a count without also providing some sort of bound. Like maybe based on time. Otherwise it could sit unflushed indefinitely.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367192605", "createdAt": "2020-01-16T01:34:33Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/WriterConfig.java", "diffHunk": "@@ -52,6 +53,12 @@\n     @Getter\n     private final Duration flushThresholdTime;\n \n+    /**\n+     * The minimum number of attributes that should accumulate before flushing them into the Attribute Index.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ5MzgzMw==", "bodyText": "There already is a time bound (see line 54 above). It's the same setting used for the regular segment transfer; I decided I didn't want another setting that would have essentially the same value.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367493833", "createdAt": "2020-01-16T15:47:09Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/WriterConfig.java", "diffHunk": "@@ -52,6 +53,12 @@\n     @Getter\n     private final Duration flushThresholdTime;\n \n+    /**\n+     * The minimum number of attributes that should accumulate before flushing them into the Attribute Index.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5MjYwNQ=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODc0NjUxOnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/writer/AttributeAggregatorTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo0MDowNVrOFeLvBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjoyNjo0N1rOFefjOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5Mzg2MA==", "bodyText": "This should be an immutable list.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367193860", "createdAt": "2020-01-16T01:40:05Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/writer/AttributeAggregatorTests.java", "diffHunk": "@@ -0,0 +1,784 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.AttributeUpdateType;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.ManualTimer;\n+import io.pravega.segmentstore.server.MetadataBuilder;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableContainerMetadata;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.CachedStreamSegmentAppendOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StorageOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentAppendOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentTruncateOperation;\n+import io.pravega.segmentstore.server.logs.operations.UpdateAttributesOperation;\n+import io.pravega.test.common.AssertExtensions;\n+import io.pravega.test.common.ErrorInjector;\n+import io.pravega.test.common.IntentionalException;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import lombok.Cleanup;\n+import lombok.RequiredArgsConstructor;\n+import lombok.SneakyThrows;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+/**\n+ * Unit test for the {@link AttributeAggregator} class.\n+ */\n+public class AttributeAggregatorTests extends ThreadPooledTestSuite {\n+    private static final int CONTAINER_ID = 0;\n+    private static final long SEGMENT_ID = 123;\n+    private static final String SEGMENT_NAME = \"Segment\";\n+    private static final byte[] APPEND_DATA = SEGMENT_NAME.getBytes();\n+    private static final UUID CORE_ATTRIBUTE_ID = Attributes.EVENT_COUNT;\n+    private static final List<UUID> EXTENDED_ATTRIBUTE_IDS = IntStream.range(0, 20).mapToObj(i -> UUID.randomUUID()).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUxODUyMg==", "bodyText": "Fixed.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367518522", "createdAt": "2020-01-16T16:26:47Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/writer/AttributeAggregatorTests.java", "diffHunk": "@@ -0,0 +1,784 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.AttributeUpdateType;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.ManualTimer;\n+import io.pravega.segmentstore.server.MetadataBuilder;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableContainerMetadata;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.CachedStreamSegmentAppendOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StorageOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentAppendOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentTruncateOperation;\n+import io.pravega.segmentstore.server.logs.operations.UpdateAttributesOperation;\n+import io.pravega.test.common.AssertExtensions;\n+import io.pravega.test.common.ErrorInjector;\n+import io.pravega.test.common.IntentionalException;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+import lombok.Cleanup;\n+import lombok.RequiredArgsConstructor;\n+import lombok.SneakyThrows;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+\n+/**\n+ * Unit test for the {@link AttributeAggregator} class.\n+ */\n+public class AttributeAggregatorTests extends ThreadPooledTestSuite {\n+    private static final int CONTAINER_ID = 0;\n+    private static final long SEGMENT_ID = 123;\n+    private static final String SEGMENT_NAME = \"Segment\";\n+    private static final byte[] APPEND_DATA = SEGMENT_NAME.getBytes();\n+    private static final UUID CORE_ATTRIBUTE_ID = Attributes.EVENT_COUNT;\n+    private static final List<UUID> EXTENDED_ATTRIBUTE_IDS = IntStream.range(0, 20).mapToObj(i -> UUID.randomUUID()).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5Mzg2MA=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODc0ODE3OnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/StreamSegmentContainerTests.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo0MToxNVrOFeLv-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjoyNjo0MlrOFefjAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDEwNw==", "bodyText": "This should be an immutable set.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367194107", "createdAt": "2020-01-16T01:41:15Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/StreamSegmentContainerTests.java", "diffHunk": "@@ -143,6 +145,11 @@\n  * DurableDataLog.\n  */\n public class StreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    /**\n+     * Auto-generated attributes which are not set externally but maintained internally. To ease our testing, we will\n+     * exclude these from all our checks.\n+     */\n+    private static final Collection<UUID> AUTO_ATTRIBUTES = Sets.newHashSet(Attributes.ATTRIBUTE_SEGMENT_ROOT_POINTER, Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUxODQ2NA==", "bodyText": "Fixed.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367518464", "createdAt": "2020-01-16T16:26:42Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/containers/StreamSegmentContainerTests.java", "diffHunk": "@@ -143,6 +145,11 @@\n  * DurableDataLog.\n  */\n public class StreamSegmentContainerTests extends ThreadPooledTestSuite {\n+    /**\n+     * Auto-generated attributes which are not set externally but maintained internally. To ease our testing, we will\n+     * exclude these from all our checks.\n+     */\n+    private static final Collection<UUID> AUTO_ATTRIBUTES = Sets.newHashSet(Attributes.ATTRIBUTE_SEGMENT_ROOT_POINTER, Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDEwNw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODc1MTM4OnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo0MzoyN1rOFeLx5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMTo1MDowNlrOFfGJGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw==", "bodyText": "Between this and the Javadoc at the top of the file it seems like maybe a refactoring is due.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367194597", "createdAt": "2020-01-16T01:43:27Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUyMjY1OQ==", "bodyText": "Well this was a refactoring. The SegmentAggregator deals exclusively with transferring data within the segment and the AttributeAggregator handles attribute transfer.\nI decided to keep segment deletion logic in here because we want to remember to delete attributes when we delete the segment, when we merge it, and one more complex situation. Instead of doing it twice, I preferred to keep that part in one place.\nI don't understand what is wrong with this line though. The SegmentAggregator only handles StorageOperations; all other types of operations are MetadataOperations are not its responsibility. There are other processors for each segment within the StorageWriter, and each deals with its own types of operations. WriterTableProcessor only handles append operations, AttributeAggregator handles AttributeUpdaterOperations (appends & attribute updates) and this handles appends, seals, mergers, deletes, truncates, etc. In other words, anything which applies directly to Tier 2 is a StorageOperation and is handled by this class, while others are a bit more specialized and do not touch Tier 2 (directly).", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367522659", "createdAt": "2020-01-16T16:33:22Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzczNjUyNA==", "bodyText": "I don't have enough context here to suggest a specific alternative, but I am always wary when I see reflection being used in code. It decouples the caller in an impl that makes it possible for one to change without the other knowing that ends up breaking things. There are a lot of ways around this:\n\nJust have multiple functions\nPer type listeners\nVisitor pattern like we do in WireCommands\nHaving a getting on the operation to return a type.\netc.\n\nAs I say, I don't really know the context here. I am not aware of any particularly extreme circumstances that prevents any of these. If there is, then let's document it. If not then let's try to find a more standard pattern.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367736524", "createdAt": "2020-01-17T01:52:46Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA1MzUxMQ==", "bodyText": "Let's see if I can explain. The StorageWriter picks Operations (all of them) from Tier1/DurableLog. The StorageWriter also has WriterProcessors for each active segment in the container. A WriterProcessor has a SegmentAggregator, an AttributeAggregator (new in this PR) and a WriterTableProcessor (for Table Segments).\nThe StorageWriter picks operation from Tier 1 (in order) and sends them to all its WriterProcessors, which in turn sends them to all of the aggregators sub-processors. So from this POV, it is using the visitor pattern (in a way). The operations themselves are immutable, but each Processor/Aggregator knows which operations it needs to process and will just ignore the rest. IMO, this can be done in two ways: the current way, in which all processors see all operations and decide which ones they use, and another in which they register with the StorageWriter to send them only those operations they care about. I just happen to do the former, because even if it accepts an operation of a given type, it may end up ignoring it due to other factors.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r368053511", "createdAt": "2020-01-17T17:34:11Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE0NTUyMw==", "bodyText": "That sounds reasonable.\nAlternatively: You could also make WriterProcessor the one to send some types to the SegmentAddregator and others to the WriterTableProcessor. (Obviously this makes it more aware of what those classes are doing, so its up to you as to whether that falls too far outside of its current responsibilities.)", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r368145523", "createdAt": "2020-01-17T21:33:56Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE1MDgxMA==", "bodyText": "Good suggestion. Since this is outside of the scope of this change, I captured this in #4493, which also includes an additional refactoring of the StorageWriter to make it more efficient.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r368150810", "createdAt": "2020-01-17T21:50:06Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/SegmentAggregator.java", "diffHunk": "@@ -331,26 +322,23 @@ public String toString() {\n     @Override\n     public void add(SegmentOperation operation) throws DataCorruptionException {\n         ensureInitializedAndNotClosed();\n+        if (!(operation instanceof StorageOperation)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NDU5Nw=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODc1NDQ0OnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo0NTo0N1rOFeLzzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjoyODo0N1rOFefoEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NTA4NA==", "bodyText": "Would an enum be better here?", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367195084", "createdAt": "2020-01-16T01:45:47Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.AbstractTimer;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentMergedException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.WriterSegmentProcessor;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import java.time.Duration;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+import lombok.Data;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Aggregates Attribute Updates for a specific Segment.\n+ *\n+ * This class handles the following operations on a Segment: Attribute Updates (extended attributes only) and Sealing\n+ * the Attribute Index. Any Attribute Index deletions are handled by {@link SegmentAggregator}.\n+ */\n+@Slf4j\n+class AttributeAggregator implements WriterSegmentProcessor, AutoCloseable {\n+    //region Members\n+\n+    private final UpdateableSegmentMetadata metadata;\n+    private final WriterConfig config;\n+    private final AbstractTimer timer;\n+    private final Executor executor;\n+    private final String traceObjectId;\n+    private final WriterDataSource dataSource;\n+    private final AtomicReference<Duration> lastFlush;\n+    private final State state;\n+    private final AtomicBoolean closed;\n+    private final AtomicReference<RootPointerInfo> lastRootPointer;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link AttributeAggregator} class.\n+     *\n+     * @param segmentMetadata The Metadata for the Segment to construct this Aggregator for.\n+     * @param dataSource      The {@link WriterDataSource} to use.\n+     * @param config          The {@link WriterConfig} to use.\n+     * @param timer           An {@link AbstractTimer} to use to determine elapsed time.\n+     * @param executor        An Executor to use for async operations.\n+     */\n+    AttributeAggregator(@NonNull UpdateableSegmentMetadata segmentMetadata, @NonNull WriterDataSource dataSource,\n+                        @NonNull WriterConfig config, @NonNull AbstractTimer timer, @NonNull Executor executor) {\n+        this.metadata = segmentMetadata;\n+        this.config = config;\n+        this.dataSource = dataSource;\n+        this.timer = timer;\n+        this.executor = executor;\n+        this.lastFlush = new AtomicReference<>(timer.getElapsed());\n+\n+        Preconditions.checkArgument(this.metadata.getContainerId() == dataSource.getId(), \"SegmentMetadata.ContainerId is different from WriterDataSource.Id\");\n+        this.traceObjectId = String.format(\"AttributeAggregator[%d-%d]\", this.metadata.getContainerId(), this.metadata.getId());\n+        this.state = new State(segmentMetadata.getAttributes().getOrDefault(Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO, Operation.NO_SEQUENCE_NUMBER));\n+        this.closed = new AtomicBoolean();\n+        this.lastRootPointer = new AtomicReference<>();\n+    }\n+\n+    //endregion\n+\n+    //region AutoCloseable Implementation\n+\n+    @Override\n+    public void close() {\n+        this.closed.set(true);\n+    }\n+\n+    //endregion\n+\n+    //region WriterSegmentProcessor Implementation\n+\n+    @Override\n+    public long getLowestUncommittedSequenceNumber() {\n+        if (this.lastRootPointer.get() == null) {\n+            // There is no async pending update for the root pointer attribute. The LUSN is whatever we accumulated in\n+            // our buffers (if nothing, then this will return Operation.NO_SEQUENCE_NUMBER).\n+            return this.state.getFirstSequenceNumber();\n+        } else {\n+            // There is an async pending update for the root pointer attribute. The LUSN can be calculated based off\n+            // whatever we were last able to acknowledge.\n+            long lpsn = this.state.getLastPersistedSequenceNumber();\n+            return lpsn == Operation.NO_SEQUENCE_NUMBER ? this.state.getFirstSequenceNumber() : lpsn + 1;\n+        }\n+    }\n+\n+    @Override\n+    public boolean isClosed() {\n+        return this.closed.get();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"[%d: %s] Count = %d, LUSN = %d, LastSeqNo = %d, LastFlush = %ds\", this.metadata.getId(), this.metadata.getName(),\n+                this.state.size(), getLowestUncommittedSequenceNumber(), this.state.getLastSequenceNumber(), getElapsedSinceLastFlush().toMillis() / 1000);\n+    }\n+\n+    /**\n+     * Adds the given SegmentOperation to the Aggregator.\n+     *\n+     * @param operation the Operation to add.\n+     * @throws DataCorruptionException  If the validation of the given Operation indicates a possible data corruption in\n+     *                                  the code (offset gaps, out-of-order operations, etc.)\n+     * @throws IllegalArgumentException If the validation of the given Operation indicates a possible non-corrupting bug\n+     *                                  in the code.\n+     */\n+    @Override\n+    public void add(SegmentOperation operation) throws DataCorruptionException {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        Preconditions.checkArgument(\n+                operation.getStreamSegmentId() == this.metadata.getId(),\n+                \"Operation '%s' refers to a different Segment than this one (%s).\", operation, this.metadata.getId());\n+        if (isSegmentDeleted()) {\n+            return;\n+        }\n+\n+        boolean processed = false;\n+        if (operation instanceof StreamSegmentSealOperation) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUxOTc2MA==", "bodyText": "That means I'd need to maintain an enum for the types of Operations, where each operation would have a getter that returns its enum value. That would resolve the instanceof but I would still need to cast them eventually to the correct type, so I am not sure we're going to get much benefit out of it. The downside of that would be the need to ensure that the enum matches the operation type; at least with instanceof and cast we don't need to worry about that problem.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367519760", "createdAt": "2020-01-16T16:28:47Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.AbstractTimer;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentMergedException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.WriterSegmentProcessor;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import java.time.Duration;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+import lombok.Data;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Aggregates Attribute Updates for a specific Segment.\n+ *\n+ * This class handles the following operations on a Segment: Attribute Updates (extended attributes only) and Sealing\n+ * the Attribute Index. Any Attribute Index deletions are handled by {@link SegmentAggregator}.\n+ */\n+@Slf4j\n+class AttributeAggregator implements WriterSegmentProcessor, AutoCloseable {\n+    //region Members\n+\n+    private final UpdateableSegmentMetadata metadata;\n+    private final WriterConfig config;\n+    private final AbstractTimer timer;\n+    private final Executor executor;\n+    private final String traceObjectId;\n+    private final WriterDataSource dataSource;\n+    private final AtomicReference<Duration> lastFlush;\n+    private final State state;\n+    private final AtomicBoolean closed;\n+    private final AtomicReference<RootPointerInfo> lastRootPointer;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link AttributeAggregator} class.\n+     *\n+     * @param segmentMetadata The Metadata for the Segment to construct this Aggregator for.\n+     * @param dataSource      The {@link WriterDataSource} to use.\n+     * @param config          The {@link WriterConfig} to use.\n+     * @param timer           An {@link AbstractTimer} to use to determine elapsed time.\n+     * @param executor        An Executor to use for async operations.\n+     */\n+    AttributeAggregator(@NonNull UpdateableSegmentMetadata segmentMetadata, @NonNull WriterDataSource dataSource,\n+                        @NonNull WriterConfig config, @NonNull AbstractTimer timer, @NonNull Executor executor) {\n+        this.metadata = segmentMetadata;\n+        this.config = config;\n+        this.dataSource = dataSource;\n+        this.timer = timer;\n+        this.executor = executor;\n+        this.lastFlush = new AtomicReference<>(timer.getElapsed());\n+\n+        Preconditions.checkArgument(this.metadata.getContainerId() == dataSource.getId(), \"SegmentMetadata.ContainerId is different from WriterDataSource.Id\");\n+        this.traceObjectId = String.format(\"AttributeAggregator[%d-%d]\", this.metadata.getContainerId(), this.metadata.getId());\n+        this.state = new State(segmentMetadata.getAttributes().getOrDefault(Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO, Operation.NO_SEQUENCE_NUMBER));\n+        this.closed = new AtomicBoolean();\n+        this.lastRootPointer = new AtomicReference<>();\n+    }\n+\n+    //endregion\n+\n+    //region AutoCloseable Implementation\n+\n+    @Override\n+    public void close() {\n+        this.closed.set(true);\n+    }\n+\n+    //endregion\n+\n+    //region WriterSegmentProcessor Implementation\n+\n+    @Override\n+    public long getLowestUncommittedSequenceNumber() {\n+        if (this.lastRootPointer.get() == null) {\n+            // There is no async pending update for the root pointer attribute. The LUSN is whatever we accumulated in\n+            // our buffers (if nothing, then this will return Operation.NO_SEQUENCE_NUMBER).\n+            return this.state.getFirstSequenceNumber();\n+        } else {\n+            // There is an async pending update for the root pointer attribute. The LUSN can be calculated based off\n+            // whatever we were last able to acknowledge.\n+            long lpsn = this.state.getLastPersistedSequenceNumber();\n+            return lpsn == Operation.NO_SEQUENCE_NUMBER ? this.state.getFirstSequenceNumber() : lpsn + 1;\n+        }\n+    }\n+\n+    @Override\n+    public boolean isClosed() {\n+        return this.closed.get();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"[%d: %s] Count = %d, LUSN = %d, LastSeqNo = %d, LastFlush = %ds\", this.metadata.getId(), this.metadata.getName(),\n+                this.state.size(), getLowestUncommittedSequenceNumber(), this.state.getLastSequenceNumber(), getElapsedSinceLastFlush().toMillis() / 1000);\n+    }\n+\n+    /**\n+     * Adds the given SegmentOperation to the Aggregator.\n+     *\n+     * @param operation the Operation to add.\n+     * @throws DataCorruptionException  If the validation of the given Operation indicates a possible data corruption in\n+     *                                  the code (offset gaps, out-of-order operations, etc.)\n+     * @throws IllegalArgumentException If the validation of the given Operation indicates a possible non-corrupting bug\n+     *                                  in the code.\n+     */\n+    @Override\n+    public void add(SegmentOperation operation) throws DataCorruptionException {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        Preconditions.checkArgument(\n+                operation.getStreamSegmentId() == this.metadata.getId(),\n+                \"Operation '%s' refers to a different Segment than this one (%s).\", operation, this.metadata.getId());\n+        if (isSegmentDeleted()) {\n+            return;\n+        }\n+\n+        boolean processed = false;\n+        if (operation instanceof StreamSegmentSealOperation) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NTA4NA=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODc2NjM5OnYy", "diffSide": "RIGHT", "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwMTo1NDoxM1rOFeL69A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjoyNjozNlrOFefixQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NjkxNg==", "bodyText": "The other members of this class are atomics and this is a normal hashmap which is accessed by include without any synchronization. This looks like a bug.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367196916", "createdAt": "2020-01-16T01:54:13Z", "author": {"login": "tkaitchuck"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.AbstractTimer;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentMergedException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.WriterSegmentProcessor;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import java.time.Duration;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+import lombok.Data;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Aggregates Attribute Updates for a specific Segment.\n+ *\n+ * This class handles the following operations on a Segment: Attribute Updates (extended attributes only) and Sealing\n+ * the Attribute Index. Any Attribute Index deletions are handled by {@link SegmentAggregator}.\n+ */\n+@Slf4j\n+class AttributeAggregator implements WriterSegmentProcessor, AutoCloseable {\n+    //region Members\n+\n+    private final UpdateableSegmentMetadata metadata;\n+    private final WriterConfig config;\n+    private final AbstractTimer timer;\n+    private final Executor executor;\n+    private final String traceObjectId;\n+    private final WriterDataSource dataSource;\n+    private final AtomicReference<Duration> lastFlush;\n+    private final State state;\n+    private final AtomicBoolean closed;\n+    private final AtomicReference<RootPointerInfo> lastRootPointer;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link AttributeAggregator} class.\n+     *\n+     * @param segmentMetadata The Metadata for the Segment to construct this Aggregator for.\n+     * @param dataSource      The {@link WriterDataSource} to use.\n+     * @param config          The {@link WriterConfig} to use.\n+     * @param timer           An {@link AbstractTimer} to use to determine elapsed time.\n+     * @param executor        An Executor to use for async operations.\n+     */\n+    AttributeAggregator(@NonNull UpdateableSegmentMetadata segmentMetadata, @NonNull WriterDataSource dataSource,\n+                        @NonNull WriterConfig config, @NonNull AbstractTimer timer, @NonNull Executor executor) {\n+        this.metadata = segmentMetadata;\n+        this.config = config;\n+        this.dataSource = dataSource;\n+        this.timer = timer;\n+        this.executor = executor;\n+        this.lastFlush = new AtomicReference<>(timer.getElapsed());\n+\n+        Preconditions.checkArgument(this.metadata.getContainerId() == dataSource.getId(), \"SegmentMetadata.ContainerId is different from WriterDataSource.Id\");\n+        this.traceObjectId = String.format(\"AttributeAggregator[%d-%d]\", this.metadata.getContainerId(), this.metadata.getId());\n+        this.state = new State(segmentMetadata.getAttributes().getOrDefault(Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO, Operation.NO_SEQUENCE_NUMBER));\n+        this.closed = new AtomicBoolean();\n+        this.lastRootPointer = new AtomicReference<>();\n+    }\n+\n+    //endregion\n+\n+    //region AutoCloseable Implementation\n+\n+    @Override\n+    public void close() {\n+        this.closed.set(true);\n+    }\n+\n+    //endregion\n+\n+    //region WriterSegmentProcessor Implementation\n+\n+    @Override\n+    public long getLowestUncommittedSequenceNumber() {\n+        if (this.lastRootPointer.get() == null) {\n+            // There is no async pending update for the root pointer attribute. The LUSN is whatever we accumulated in\n+            // our buffers (if nothing, then this will return Operation.NO_SEQUENCE_NUMBER).\n+            return this.state.getFirstSequenceNumber();\n+        } else {\n+            // There is an async pending update for the root pointer attribute. The LUSN can be calculated based off\n+            // whatever we were last able to acknowledge.\n+            long lpsn = this.state.getLastPersistedSequenceNumber();\n+            return lpsn == Operation.NO_SEQUENCE_NUMBER ? this.state.getFirstSequenceNumber() : lpsn + 1;\n+        }\n+    }\n+\n+    @Override\n+    public boolean isClosed() {\n+        return this.closed.get();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"[%d: %s] Count = %d, LUSN = %d, LastSeqNo = %d, LastFlush = %ds\", this.metadata.getId(), this.metadata.getName(),\n+                this.state.size(), getLowestUncommittedSequenceNumber(), this.state.getLastSequenceNumber(), getElapsedSinceLastFlush().toMillis() / 1000);\n+    }\n+\n+    /**\n+     * Adds the given SegmentOperation to the Aggregator.\n+     *\n+     * @param operation the Operation to add.\n+     * @throws DataCorruptionException  If the validation of the given Operation indicates a possible data corruption in\n+     *                                  the code (offset gaps, out-of-order operations, etc.)\n+     * @throws IllegalArgumentException If the validation of the given Operation indicates a possible non-corrupting bug\n+     *                                  in the code.\n+     */\n+    @Override\n+    public void add(SegmentOperation operation) throws DataCorruptionException {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        Preconditions.checkArgument(\n+                operation.getStreamSegmentId() == this.metadata.getId(),\n+                \"Operation '%s' refers to a different Segment than this one (%s).\", operation, this.metadata.getId());\n+        if (isSegmentDeleted()) {\n+            return;\n+        }\n+\n+        boolean processed = false;\n+        if (operation instanceof StreamSegmentSealOperation) {\n+            this.state.seal();\n+            processed = true;\n+        } else if (operation instanceof AttributeUpdaterOperation) {\n+            AttributeUpdaterOperation op = (AttributeUpdaterOperation) operation;\n+            if (this.state.hasSeal()) {\n+                if (op.isInternal() && op.hasOnlyCoreAttributes()) {\n+                    log.debug(\"{}: Ignored internal operation on sealed segment {}.\", this.traceObjectId, operation);\n+                    return;\n+                } else {\n+                    throw new DataCorruptionException(String.format(\"Illegal operation for a sealed Segment; received '%s'.\", operation));\n+                }\n+            }\n+\n+            processed = this.state.include(op);\n+        }\n+\n+        if (processed) {\n+            log.debug(\"{}: Add {}; OpCount={}.\", this.traceObjectId, operation, this.state.size());\n+        }\n+    }\n+\n+    /**\n+     * Gets a value indicating whether a call to {@link #flush} is required given the current state of this aggregator.\n+     */\n+    @Override\n+    public boolean mustFlush() {\n+        if (isSegmentDeleted()) {\n+            // There isn't more that we can do.\n+            return false;\n+        }\n+\n+        return this.state.hasSeal()\n+                || this.state.size() >= this.config.getFlushAttributesThreshold()\n+                || (this.state.size() > 0 && getElapsedSinceLastFlush().compareTo(this.config.getFlushThresholdTime()) >= 0);\n+    }\n+\n+    /**\n+     * Flushes the contents of the Aggregator to the Storage.\n+     *\n+     * @param timeout Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, will contain a summary of the flush operation. If any errors\n+     * occurred during the flush, the Future will be completed with the appropriate exception.\n+     */\n+    @Override\n+    public CompletableFuture<WriterFlushResult> flush(Duration timeout) {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        if (!mustFlush()) {\n+            return CompletableFuture.completedFuture(new WriterFlushResult());\n+        }\n+\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        CompletableFuture<Void> result = handleAttributeException(persistPendingAttributes(\n+                this.state.getAttributes(), this.state.getLastSequenceNumber(), timer));\n+        if (this.state.hasSeal()) {\n+            result = result.thenComposeAsync(v -> handleAttributeException(sealAttributes(timer)));\n+        }\n+\n+        return result.thenApply(v -> {\n+            if (this.state.size() > 0) {\n+                log.debug(\"{}: Flushed. Count={}, SeqNo={}-{}.\", this.traceObjectId, this.state.size(),\n+                        this.state.getFirstSequenceNumber(), this.state.getLastSequenceNumber());\n+            }\n+\n+            WriterFlushResult r = new WriterFlushResult();\n+            r.withFlushedAttributes(this.state.size());\n+            this.state.acceptChanges();\n+            this.lastFlush.set(this.timer.getElapsed());\n+            return r;\n+        });\n+    }\n+\n+    //endregion\n+\n+    //region Helpers\n+\n+    private CompletableFuture<Void> persistPendingAttributes(Map<UUID, Long> attributes, long lastSeqNo, TimeoutTimer timer) {\n+        if (attributes.isEmpty()) {\n+            return CompletableFuture.completedFuture(null);\n+        }\n+\n+        return this.dataSource.persistAttributes(this.metadata.getId(), attributes, timer.getRemaining())\n+                .thenAcceptAsync(rootPointer -> queueRootPointerUpdate(rootPointer, lastSeqNo), this.executor);\n+    }\n+\n+    private CompletableFuture<Void> sealAttributes(TimeoutTimer timer) {\n+        log.debug(\"{}: Sealing Attribute Index.\", this.traceObjectId);\n+        return this.dataSource.sealAttributes(this.metadata.getId(), timer.getRemaining());\n+    }\n+\n+    public void queueRootPointerUpdate(long newRootPointer, long lastSeqNo) {\n+        if (this.lastRootPointer.getAndSet(new RootPointerInfo(newRootPointer, lastSeqNo)) == null) {\n+            // There was nothing else executing now.\n+            // Initiate an async loop that will execute as long as we have a new value.\n+            AtomicBoolean canContinue = new AtomicBoolean(this.lastRootPointer.get() != null);\n+            Futures.loop(\n+                    canContinue::get,\n+                    () -> {\n+                        RootPointerInfo rpi = this.lastRootPointer.get();\n+                        log.debug(\"{}: Updating Root Pointer info to {}.\", this.traceObjectId, rpi);\n+                        return this.dataSource.notifyAttributesPersisted(this.metadata.getId(), rpi.getRootPointer(), rpi.getLastSequenceNumber(), this.config.getFlushTimeout())\n+                                .whenCompleteAsync((r, ex) -> {\n+                                    if (ex != null) {\n+                                        log.error(\"{}: Unable to persist root pointer {}.\", this.traceObjectId, rpi, ex);\n+                                    } else {\n+                                        this.state.setLastPersistedSequenceNumber(rpi.getLastSequenceNumber());\n+                                    }\n+\n+                                    // Set the latest value to null ONLY if it hasn't changed in the meantime.\n+                                    if (this.lastRootPointer.compareAndSet(rpi, null)) {\n+                                        // No new value. Instruct the loop to stop processing.\n+                                        canContinue.set(false);\n+                                    }\n+                                }, this.executor);\n+\n+                    },\n+                    this.executor);\n+        }\n+    }\n+\n+    /**\n+     * Handles expected Attribute-related exceptions. Since the attribute index is a separate segment from the main one,\n+     * it is highly likely that it may get temporarily out of sync with the main one, thus causing spurious StreamSegmentSealedExceptions\n+     * or StreamSegmentNotExistsExceptions. If we get either of those, and they are consistent with our current state, the\n+     * we can safely ignore them; otherwise we should be rethrowing them.\n+     */\n+    private <T> CompletableFuture<T> handleAttributeException(CompletableFuture<T> future) {\n+        return Futures.exceptionallyExpecting(\n+                future,\n+                ex -> (ex instanceof StreamSegmentSealedException && this.metadata.isSealed())\n+                        || ((ex instanceof StreamSegmentNotExistsException || ex instanceof StreamSegmentMergedException)\n+                        && (this.metadata.isMerged() || this.metadata.isDeleted())),\n+                null);\n+    }\n+\n+    private boolean isSegmentDeleted() {\n+        return this.metadata.isDeleted() || this.metadata.isMerged();\n+    }\n+\n+    private Duration getElapsedSinceLastFlush() {\n+        return this.timer.getElapsed().minus(this.lastFlush.get());\n+    }\n+\n+    //endregion\n+\n+    //region RootPointer\n+\n+    @Data\n+    private static class RootPointerInfo {\n+        private final long rootPointer;\n+        private final long lastSequenceNumber;\n+\n+        @Override\n+        public String toString() {\n+            return String.format(\"RootPointer=%s, LastSeqNo=%s\", this.rootPointer, this.lastSequenceNumber);\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region AggregatedAttributes\n+\n+    /**\n+     * Aggregates pending Attribute Updates.\n+     */\n+    private static class State {\n+        private final HashMap<UUID, Long> attributes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 317}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUxODQwNQ==", "bodyText": "Good catch. Fixed.", "url": "https://github.com/pravega/pravega/pull/4485#discussion_r367518405", "createdAt": "2020-01-16T16:26:36Z", "author": {"login": "andreipaduroiu"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/writer/AttributeAggregator.java", "diffHunk": "@@ -0,0 +1,477 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.writer;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.AbstractTimer;\n+import io.pravega.common.Exceptions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.segmentstore.contracts.AttributeUpdate;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.StreamSegmentMergedException;\n+import io.pravega.segmentstore.contracts.StreamSegmentNotExistsException;\n+import io.pravega.segmentstore.contracts.StreamSegmentSealedException;\n+import io.pravega.segmentstore.server.DataCorruptionException;\n+import io.pravega.segmentstore.server.SegmentOperation;\n+import io.pravega.segmentstore.server.UpdateableSegmentMetadata;\n+import io.pravega.segmentstore.server.WriterFlushResult;\n+import io.pravega.segmentstore.server.WriterSegmentProcessor;\n+import io.pravega.segmentstore.server.logs.operations.AttributeUpdaterOperation;\n+import io.pravega.segmentstore.server.logs.operations.Operation;\n+import io.pravega.segmentstore.server.logs.operations.StreamSegmentSealOperation;\n+import java.time.Duration;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicReference;\n+import lombok.Data;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Aggregates Attribute Updates for a specific Segment.\n+ *\n+ * This class handles the following operations on a Segment: Attribute Updates (extended attributes only) and Sealing\n+ * the Attribute Index. Any Attribute Index deletions are handled by {@link SegmentAggregator}.\n+ */\n+@Slf4j\n+class AttributeAggregator implements WriterSegmentProcessor, AutoCloseable {\n+    //region Members\n+\n+    private final UpdateableSegmentMetadata metadata;\n+    private final WriterConfig config;\n+    private final AbstractTimer timer;\n+    private final Executor executor;\n+    private final String traceObjectId;\n+    private final WriterDataSource dataSource;\n+    private final AtomicReference<Duration> lastFlush;\n+    private final State state;\n+    private final AtomicBoolean closed;\n+    private final AtomicReference<RootPointerInfo> lastRootPointer;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link AttributeAggregator} class.\n+     *\n+     * @param segmentMetadata The Metadata for the Segment to construct this Aggregator for.\n+     * @param dataSource      The {@link WriterDataSource} to use.\n+     * @param config          The {@link WriterConfig} to use.\n+     * @param timer           An {@link AbstractTimer} to use to determine elapsed time.\n+     * @param executor        An Executor to use for async operations.\n+     */\n+    AttributeAggregator(@NonNull UpdateableSegmentMetadata segmentMetadata, @NonNull WriterDataSource dataSource,\n+                        @NonNull WriterConfig config, @NonNull AbstractTimer timer, @NonNull Executor executor) {\n+        this.metadata = segmentMetadata;\n+        this.config = config;\n+        this.dataSource = dataSource;\n+        this.timer = timer;\n+        this.executor = executor;\n+        this.lastFlush = new AtomicReference<>(timer.getElapsed());\n+\n+        Preconditions.checkArgument(this.metadata.getContainerId() == dataSource.getId(), \"SegmentMetadata.ContainerId is different from WriterDataSource.Id\");\n+        this.traceObjectId = String.format(\"AttributeAggregator[%d-%d]\", this.metadata.getContainerId(), this.metadata.getId());\n+        this.state = new State(segmentMetadata.getAttributes().getOrDefault(Attributes.ATTRIBUTE_SEGMENT_PERSIST_SEQ_NO, Operation.NO_SEQUENCE_NUMBER));\n+        this.closed = new AtomicBoolean();\n+        this.lastRootPointer = new AtomicReference<>();\n+    }\n+\n+    //endregion\n+\n+    //region AutoCloseable Implementation\n+\n+    @Override\n+    public void close() {\n+        this.closed.set(true);\n+    }\n+\n+    //endregion\n+\n+    //region WriterSegmentProcessor Implementation\n+\n+    @Override\n+    public long getLowestUncommittedSequenceNumber() {\n+        if (this.lastRootPointer.get() == null) {\n+            // There is no async pending update for the root pointer attribute. The LUSN is whatever we accumulated in\n+            // our buffers (if nothing, then this will return Operation.NO_SEQUENCE_NUMBER).\n+            return this.state.getFirstSequenceNumber();\n+        } else {\n+            // There is an async pending update for the root pointer attribute. The LUSN can be calculated based off\n+            // whatever we were last able to acknowledge.\n+            long lpsn = this.state.getLastPersistedSequenceNumber();\n+            return lpsn == Operation.NO_SEQUENCE_NUMBER ? this.state.getFirstSequenceNumber() : lpsn + 1;\n+        }\n+    }\n+\n+    @Override\n+    public boolean isClosed() {\n+        return this.closed.get();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return String.format(\"[%d: %s] Count = %d, LUSN = %d, LastSeqNo = %d, LastFlush = %ds\", this.metadata.getId(), this.metadata.getName(),\n+                this.state.size(), getLowestUncommittedSequenceNumber(), this.state.getLastSequenceNumber(), getElapsedSinceLastFlush().toMillis() / 1000);\n+    }\n+\n+    /**\n+     * Adds the given SegmentOperation to the Aggregator.\n+     *\n+     * @param operation the Operation to add.\n+     * @throws DataCorruptionException  If the validation of the given Operation indicates a possible data corruption in\n+     *                                  the code (offset gaps, out-of-order operations, etc.)\n+     * @throws IllegalArgumentException If the validation of the given Operation indicates a possible non-corrupting bug\n+     *                                  in the code.\n+     */\n+    @Override\n+    public void add(SegmentOperation operation) throws DataCorruptionException {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        Preconditions.checkArgument(\n+                operation.getStreamSegmentId() == this.metadata.getId(),\n+                \"Operation '%s' refers to a different Segment than this one (%s).\", operation, this.metadata.getId());\n+        if (isSegmentDeleted()) {\n+            return;\n+        }\n+\n+        boolean processed = false;\n+        if (operation instanceof StreamSegmentSealOperation) {\n+            this.state.seal();\n+            processed = true;\n+        } else if (operation instanceof AttributeUpdaterOperation) {\n+            AttributeUpdaterOperation op = (AttributeUpdaterOperation) operation;\n+            if (this.state.hasSeal()) {\n+                if (op.isInternal() && op.hasOnlyCoreAttributes()) {\n+                    log.debug(\"{}: Ignored internal operation on sealed segment {}.\", this.traceObjectId, operation);\n+                    return;\n+                } else {\n+                    throw new DataCorruptionException(String.format(\"Illegal operation for a sealed Segment; received '%s'.\", operation));\n+                }\n+            }\n+\n+            processed = this.state.include(op);\n+        }\n+\n+        if (processed) {\n+            log.debug(\"{}: Add {}; OpCount={}.\", this.traceObjectId, operation, this.state.size());\n+        }\n+    }\n+\n+    /**\n+     * Gets a value indicating whether a call to {@link #flush} is required given the current state of this aggregator.\n+     */\n+    @Override\n+    public boolean mustFlush() {\n+        if (isSegmentDeleted()) {\n+            // There isn't more that we can do.\n+            return false;\n+        }\n+\n+        return this.state.hasSeal()\n+                || this.state.size() >= this.config.getFlushAttributesThreshold()\n+                || (this.state.size() > 0 && getElapsedSinceLastFlush().compareTo(this.config.getFlushThresholdTime()) >= 0);\n+    }\n+\n+    /**\n+     * Flushes the contents of the Aggregator to the Storage.\n+     *\n+     * @param timeout Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, will contain a summary of the flush operation. If any errors\n+     * occurred during the flush, the Future will be completed with the appropriate exception.\n+     */\n+    @Override\n+    public CompletableFuture<WriterFlushResult> flush(Duration timeout) {\n+        Exceptions.checkNotClosed(isClosed(), this);\n+        if (!mustFlush()) {\n+            return CompletableFuture.completedFuture(new WriterFlushResult());\n+        }\n+\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        CompletableFuture<Void> result = handleAttributeException(persistPendingAttributes(\n+                this.state.getAttributes(), this.state.getLastSequenceNumber(), timer));\n+        if (this.state.hasSeal()) {\n+            result = result.thenComposeAsync(v -> handleAttributeException(sealAttributes(timer)));\n+        }\n+\n+        return result.thenApply(v -> {\n+            if (this.state.size() > 0) {\n+                log.debug(\"{}: Flushed. Count={}, SeqNo={}-{}.\", this.traceObjectId, this.state.size(),\n+                        this.state.getFirstSequenceNumber(), this.state.getLastSequenceNumber());\n+            }\n+\n+            WriterFlushResult r = new WriterFlushResult();\n+            r.withFlushedAttributes(this.state.size());\n+            this.state.acceptChanges();\n+            this.lastFlush.set(this.timer.getElapsed());\n+            return r;\n+        });\n+    }\n+\n+    //endregion\n+\n+    //region Helpers\n+\n+    private CompletableFuture<Void> persistPendingAttributes(Map<UUID, Long> attributes, long lastSeqNo, TimeoutTimer timer) {\n+        if (attributes.isEmpty()) {\n+            return CompletableFuture.completedFuture(null);\n+        }\n+\n+        return this.dataSource.persistAttributes(this.metadata.getId(), attributes, timer.getRemaining())\n+                .thenAcceptAsync(rootPointer -> queueRootPointerUpdate(rootPointer, lastSeqNo), this.executor);\n+    }\n+\n+    private CompletableFuture<Void> sealAttributes(TimeoutTimer timer) {\n+        log.debug(\"{}: Sealing Attribute Index.\", this.traceObjectId);\n+        return this.dataSource.sealAttributes(this.metadata.getId(), timer.getRemaining());\n+    }\n+\n+    public void queueRootPointerUpdate(long newRootPointer, long lastSeqNo) {\n+        if (this.lastRootPointer.getAndSet(new RootPointerInfo(newRootPointer, lastSeqNo)) == null) {\n+            // There was nothing else executing now.\n+            // Initiate an async loop that will execute as long as we have a new value.\n+            AtomicBoolean canContinue = new AtomicBoolean(this.lastRootPointer.get() != null);\n+            Futures.loop(\n+                    canContinue::get,\n+                    () -> {\n+                        RootPointerInfo rpi = this.lastRootPointer.get();\n+                        log.debug(\"{}: Updating Root Pointer info to {}.\", this.traceObjectId, rpi);\n+                        return this.dataSource.notifyAttributesPersisted(this.metadata.getId(), rpi.getRootPointer(), rpi.getLastSequenceNumber(), this.config.getFlushTimeout())\n+                                .whenCompleteAsync((r, ex) -> {\n+                                    if (ex != null) {\n+                                        log.error(\"{}: Unable to persist root pointer {}.\", this.traceObjectId, rpi, ex);\n+                                    } else {\n+                                        this.state.setLastPersistedSequenceNumber(rpi.getLastSequenceNumber());\n+                                    }\n+\n+                                    // Set the latest value to null ONLY if it hasn't changed in the meantime.\n+                                    if (this.lastRootPointer.compareAndSet(rpi, null)) {\n+                                        // No new value. Instruct the loop to stop processing.\n+                                        canContinue.set(false);\n+                                    }\n+                                }, this.executor);\n+\n+                    },\n+                    this.executor);\n+        }\n+    }\n+\n+    /**\n+     * Handles expected Attribute-related exceptions. Since the attribute index is a separate segment from the main one,\n+     * it is highly likely that it may get temporarily out of sync with the main one, thus causing spurious StreamSegmentSealedExceptions\n+     * or StreamSegmentNotExistsExceptions. If we get either of those, and they are consistent with our current state, the\n+     * we can safely ignore them; otherwise we should be rethrowing them.\n+     */\n+    private <T> CompletableFuture<T> handleAttributeException(CompletableFuture<T> future) {\n+        return Futures.exceptionallyExpecting(\n+                future,\n+                ex -> (ex instanceof StreamSegmentSealedException && this.metadata.isSealed())\n+                        || ((ex instanceof StreamSegmentNotExistsException || ex instanceof StreamSegmentMergedException)\n+                        && (this.metadata.isMerged() || this.metadata.isDeleted())),\n+                null);\n+    }\n+\n+    private boolean isSegmentDeleted() {\n+        return this.metadata.isDeleted() || this.metadata.isMerged();\n+    }\n+\n+    private Duration getElapsedSinceLastFlush() {\n+        return this.timer.getElapsed().minus(this.lastFlush.get());\n+    }\n+\n+    //endregion\n+\n+    //region RootPointer\n+\n+    @Data\n+    private static class RootPointerInfo {\n+        private final long rootPointer;\n+        private final long lastSequenceNumber;\n+\n+        @Override\n+        public String toString() {\n+            return String.format(\"RootPointer=%s, LastSeqNo=%s\", this.rootPointer, this.lastSequenceNumber);\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region AggregatedAttributes\n+\n+    /**\n+     * Aggregates pending Attribute Updates.\n+     */\n+    private static class State {\n+        private final HashMap<UUID, Long> attributes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE5NjkxNg=="}, "originalCommit": {"oid": "6b3310d901a8a209c496900f4418f56b17138d90"}, "originalPosition": 317}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4387, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}