{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyOTk5MTM4", "number": 5099, "title": "Issue 5095: DR Integration tests included for multiple containers and Transactional writers", "bodyText": "Change log description\nThe PR which explains about DR Integration test in detail is: #4716\nA short summary: It tests the scenario when durable data log fails after all the segments have been flushed to the long term storage. In such a situation, debug segment container(s) are started to restore the data in a new durable data log.\nIn this PR, tests have been included to start multiple debug segment containers and use transactions for writing events.\nPurpose of the change\nPartially fixes #5095\nWhat the code does\nThere are two tests which have been included here:\n\nTests the DR scenario when 4 containers are used in running normal segment store and then 4 debug segment containers are created for data restoration.\nTests the scenario when events are written in the form of transactions.\n\nHow to verify it\nBuild shall pass.", "createdAt": "2020-08-25T07:22:50Z", "url": "https://github.com/pravega/pravega/pull/5099", "merged": true, "mergeCommit": {"oid": "3133e69378534d02dbf4564d5fb200a3c54f5aa3"}, "closed": true, "closedAt": "2020-09-03T21:16:56Z", "author": {"login": "ManishKumarKeshri"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdCOaIlAH2gAyNDcyOTk5MTM4OmMwMWFjYzRjNzMyYzE4ODE4OTU4ODdkZTZhZDc2YWNhMTFmYmMwMmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdFVS7KAFqTQ4MjExODIyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c01acc4c732c1881895887de6ad76aca11fbc02d", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/c01acc4c732c1881895887de6ad76aca11fbc02d", "committedDate": "2020-08-25T03:12:18Z", "message": "Integration test with multiple containers.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5b59e2b4f5b32690fef7e68c1995a4efe5fbdd9", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/a5b59e2b4f5b32690fef7e68c1995a4efe5fbdd9", "committedDate": "2020-08-25T07:04:29Z", "message": "Adding DR integration test with Transactional Writer.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1be7b9cc66f2bccfc5fadd7a9df1a5dbf5e52aa8", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/1be7b9cc66f2bccfc5fadd7a9df1a5dbf5e52aa8", "committedDate": "2020-08-25T07:42:19Z", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5f7806d2a402e23485a23a3d136c91bca5f8ac3", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/e5f7806d2a402e23485a23a3d136c91bca5f8ac3", "committedDate": "2020-08-25T08:54:52Z", "message": "Changing serializer.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf6b7df145818463df4355a6543c465772df2df0", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/bf6b7df145818463df4355a6543c465772df2df0", "committedDate": "2020-08-25T17:11:40Z", "message": "Catch StreamSegmentNotExists exception on transational writer segments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a62b16f0c20d2c1b212f0fa7ea08da377982fea", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/8a62b16f0c20d2c1b212f0fa7ea08da377982fea", "committedDate": "2020-08-25T18:59:16Z", "message": "Updating Javadoc.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad", "committedDate": "2020-08-25T19:18:07Z", "message": "Updating.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc3OTY2MTM1", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-477966135", "createdAt": "2020-08-28T19:10:49Z", "commit": {"oid": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxOToxMDo1MFrOHJRngQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxOToxMTo0N1rOHJRpDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4Nzg3Mw==", "bodyText": "Instead of duplicating code , please extract out method that takes two parameters - number of containers and boolean for whether or not to use transactions.\nGenerally try to follow the DRY (Don't Repeat Yourself)  principle by extracting common functionality in smaller methods,", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r479487873", "createdAt": "2020-08-28T19:10:50Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -423,8 +435,312 @@ public void testDurableDataLogFail() throws Exception {\n         log.info(\"Segments have been recovered.\");\n \n         // Start a new segment store and controller\n-        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n-        controllerStarter = startController(this.bookKeeperStarter.bkPort, this.segmentStoreStarter.servicePort);\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with multiple segment containers. Segments recovery is attained using multiple\n+     * debug segment containers as well.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryMultipleContainers() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ4ODI3MA==", "bodyText": "take a boolean parameter for whether to use transactions or not.", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r479488270", "createdAt": "2020-08-28T19:11:47Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -423,8 +435,312 @@ public void testDurableDataLogFail() throws Exception {\n         log.info(\"Segments have been recovered.\");\n \n         // Start a new segment store and controller\n-        this.segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory);\n-        controllerStarter = startController(this.bookKeeperStarter.bkPort, this.segmentStoreStarter.servicePort);\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with multiple segment containers. Segments recovery is attained using multiple\n+     * debug segment containers as well.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryMultipleContainers() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n+        log.info(\"Writing events on to stream: {}\", STREAM2);\n+        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+\n+        // Verify events write by reading them.\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Verified that events were written, by reading them.\");\n+\n+        readerGroupManager.close();\n+        clientFactory.close();\n+\n+        controllerStarter.close(); // Shut down the controller\n+\n+        // Get names of all the segments created.\n+        ConcurrentHashMap<String, Boolean> allSegments = segmentStoreStarter.segmentsTracker.getSegments();\n+        log.info(\"No. of segments created = {}\", allSegments.size());\n+\n+        // Get the long term storage from the running pravega instance\n+        @Cleanup\n+        Storage storage = new AsyncStorageWrapper(new RollingStorage(this.storageFactory.createSyncStorage(),\n+                new SegmentRollingPolicy(DEFAULT_ROLLING_SIZE)), executorService());\n+\n+        // wait for all segments to be flushed to the long term storage.\n+        waitForSegmentsInStorage(allSegments.keySet(), segmentStoreStarter.segmentsTracker, storage)\n+                .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+\n+        segmentStoreStarter.close(); // Shutdown SegmentStore\n+        log.info(\"Segment Store Shutdown\");\n+\n+        this.bookKeeperStarter.close(); // Shutdown BookKeeper & ZooKeeper\n+        this.bookKeeperStarter = null;\n+        log.info(\"BookKeeper & ZooKeeper shutdown\");\n+\n+        // start a new BookKeeper and ZooKeeper.\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        this.dataLogFactory = new BookKeeperLogFactory(this.bookKeeperStarter.bkConfig.get(), this.bookKeeperStarter.zkClient.get(),\n+                executorService());\n+        this.dataLogFactory.initialize();\n+        log.info(\"Started a new BookKeeper and ZooKeeper.\");\n+\n+        // Create the environment for DebugSegmentContainer.\n+        @Cleanup\n+        DebugStreamSegmentContainerTests.TestContext context = DebugStreamSegmentContainerTests.createContext(executorService());\n+        // Use dataLogFactory from new BK instance.\n+        OperationLogFactory localDurableLogFactory = new DurableLogFactory(DURABLE_LOG_CONFIG, this.dataLogFactory,\n+                executorService());\n+\n+        // Start a debug segment container corresponding to the given container Id and put it in the Hashmap with the Id.\n+        Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerMap = new HashMap<>();\n+\n+        // Create a debug segment container instances using a new dataLog and old storage.\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n+                    DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n+                    context.getDefaultExtensions(), executorService());\n+\n+            Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.put(containerId, debugStreamSegmentContainer);\n+\n+            // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+            ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, containerId).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+        }\n+\n+        // List segments from storage and recover them using debug segment container instance.\n+        ContainerRecoveryUtils.recoverAllSegments(storage, debugStreamSegmentContainerMap, executorService());\n+\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            // Wait for metadata segment to be flushed to LTS\n+            String metadataSegmentName = NameUtils.getMetadataSegmentName(containerId);\n+            waitForSegmentsInStorage(Collections.singleton(metadataSegmentName), debugStreamSegmentContainerMap.get(containerId),\n+                    storage)\n+                    .get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            log.info(\"Long term storage has been update with a new container metadata segment.\");\n+\n+            // Stop the debug segment container\n+            Services.stopAsync(debugStreamSegmentContainerMap.get(containerId), executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.get(containerId).close();\n+        }\n+        log.info(\"Segments have been recovered.\");\n+\n+        this.dataLogFactory.close();\n+        // Start a new segment store and controller\n+        segmentStoreStarter = startSegmentStore(this.storageFactory, this.dataLogFactory, containerCount);\n+        controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort, containerCount);\n+        log.info(\"Started segment store and controller again.\");\n+\n+        connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        // Try creating the same segments again with the new controller\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+\n+        // Try reading all events again\n+        readAllEvents(STREAM1, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        readAllEvents(STREAM2, clientFactory, readerGroupManager, \"RG\" + RANDOM.nextInt(Integer.MAX_VALUE),\n+                \"R\" + RANDOM.nextInt(Integer.MAX_VALUE));\n+        log.info(\"Read all events again to verify that segments were recovered.\");\n+    }\n+\n+    /**\n+     * Tests the data recovery scenario with transactional writer. Events are written using a transactional writer.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just 4 segment containers.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts 4 debug segment containers using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoveryTransactionalWriter() throws Exception {\n+        int instanceId = 0;\n+        int containerCount = 4;\n+\n+        // Creating a long term storage only once here.\n+        this.storageFactory = new InMemoryStorageFactory(executorService());\n+        log.info(\"Created a long term storage.\");\n+\n+        // Start a new BK & ZK, segment store and controller\n+        this.bookKeeperStarter = setUpNewBK(instanceId++);\n+        @Cleanup\n+        SegmentStoreStarter segmentStoreStarter = startSegmentStore(this.storageFactory, null, containerCount);\n+        @Cleanup\n+        ControllerStarter controllerStarter = startController(this.bookKeeperStarter.bkPort, segmentStoreStarter.servicePort,\n+                containerCount);\n+\n+        // Create two streams for writing data onto two different segments\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM1);\n+        createScopeStream(controllerStarter.controller, SCOPE, STREAM2);\n+        log.info(\"Created two streams.\");\n+\n+        @Cleanup\n+        ConnectionFactory connectionFactory = new SocketConnectionFactoryImpl(ClientConfig.builder()\n+                .controllerURI(controllerStarter.controllerURI).build());\n+        @Cleanup\n+        ClientFactoryImpl clientFactory = new ClientFactoryImpl(SCOPE, controllerStarter.controller, connectionFactory);\n+        @Cleanup\n+        ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n+\n+        log.info(\"Writing events on to stream: {}\", STREAM1);\n+        writeTransactionalEvents(STREAM1, clientFactory); // write 300 events on one segment", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a49c1f2f0f68baed9e56779b7d3b24074a3a0ad"}, "originalPosition": 410}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/e93b0b35a278eb98aeb5efcd633fabb3c31227bb", "committedDate": "2020-09-01T16:02:30Z", "message": "Avoiding repetition of code.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwMTAyNDc4", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-480102478", "createdAt": "2020-09-01T20:46:10Z", "commit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMDo0NjoxMVrOHLHmKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMDo1MTowM1rOHLHwMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMDg0MQ==", "bodyText": "replace magic number with const.", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481420841", "createdAt": "2020-09-01T20:46:11Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -469,6 +543,21 @@ private void writeEvents(String streamName, ClientFactoryImpl clientFactory) {\n         writer.close();\n     }\n \n+    private void writeTransactionalEvents(String streamName, ClientFactoryImpl clientFactory) throws TxnFailedException {\n+        EventWriterConfig writerConfig = EventWriterConfig.builder().transactionTimeoutTime(10000).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 326}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjYzMA==", "bodyText": "Do we need this method ?\nwhy not just call new SegmentStoreStarter(storageFactory, dataLogFactory, containerCount);  directly where it is needed?", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481422630", "createdAt": "2020-09-01T20:49:34Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -247,8 +236,9 @@ public void close() throws Exception {\n         }\n     }\n \n-    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory) throws DurableDataLogException {\n-        return new SegmentStoreStarter(storageFactory, dataLogFactory);\n+    SegmentStoreStarter startSegmentStore(StorageFactory storageFactory, BookKeeperLogFactory dataLogFactory, int containerCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMjk3OA==", "bodyText": "Do we need this method ?\nwhy not just call new ControllerStarter(bkPort, servicePort, containerCount)directly where it is needed?", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481422978", "createdAt": "2020-09-01T20:50:16Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -287,8 +282,8 @@ public void close() {\n         }\n     }\n \n-    ControllerStarter startController(int bkPort, int servicePort) throws InterruptedException {\n-        return new ControllerStarter(bkPort, servicePort);\n+    ControllerStarter startController(int bkPort, int servicePort, int containerCount) throws InterruptedException {\n+        return new ControllerStarter(bkPort, servicePort, containerCount);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMzIwNg==", "bodyText": "nice!", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481423206", "createdAt": "2020-09-01T20:50:40Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -314,18 +309,86 @@ public void close() throws Exception {\n         }\n     }\n \n+    /**\n+     * Tests the data recovery scenario with just one segment container. Segments recovery is attained using just one\n+     * debug segment container.\n+     *  What test does, step by step:\n+     *  1. Starts Pravega locally with just one segment container.\n+     *  2. Writes 300 events to two different segments.\n+     *  3. Waits for all segments created to be flushed to the long term storage.\n+     *  4. Shuts down the controller, segment store and bookeeper/zookeeper.\n+     *  5. Deletes container metadata segment and its attribute segment from the old LTS.\n+     *  5. Starts just one debug segment container using a new bookeeper/zookeeper and the old LTS.\n+     *  6. Re-creates the container metadata segment in Tier1 and let's it flushed to the LTS.\n+     *  7. Starts segment store and controller.\n+     *  8. Reads all 600 events again.\n+     * @throws Exception    In case of an exception occurred while execution.\n+     */\n+    @Test(timeout = 180000)\n+    public void testDurableDataLogFailRecoverySingleContainer() throws Exception {\n+        testRecovery(1, false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQyMzQxMA==", "bodyText": "nice!", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481423410", "createdAt": "2020-09-01T20:51:03Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -340,10 +403,17 @@ public void testDurableDataLogFail() throws Exception {\n         @Cleanup\n         ReaderGroupManager readerGroupManager = new ReaderGroupManagerImpl(SCOPE, controllerStarter.controller, clientFactory);\n \n-        log.info(\"Writing events on to stream: {}\", STREAM1);\n-        writeEvents(STREAM1, clientFactory); // write 300 events on one segment\n-        log.info(\"Writing events on to stream: {}\", STREAM2);\n-        writeEvents(STREAM2, clientFactory); // write 300 events on other segment\n+        if (withTransaction) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 221}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwMTE2NDkx", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-480116491", "createdAt": "2020-09-01T21:08:00Z", "commit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMTowODowMFrOHLISjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMTowOTozNFrOHLIVjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjIwNg==", "bodyText": "make final wherever possible.", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481432206", "createdAt": "2020-09-01T21:08:00Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -149,7 +144,6 @@\n \n     private StorageFactory storageFactory;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQzMjk3NA==", "bodyText": "try to see if we can break it into small methods", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r481432974", "createdAt": "2020-09-01T21:09:34Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -395,36 +464,41 @@ public void testDurableDataLogFail() throws Exception {\n         // Start a debug segment container corresponding to the given container Id and put it in the Hashmap with the Id.\n         Map<Integer, DebugStreamSegmentContainer> debugStreamSegmentContainerMap = new HashMap<>();\n \n-        // Create a debug segment container instance using a new dataLog and old storage.\n-        DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n-                DebugStreamSegmentContainerTests.MetadataCleanupContainer(CONTAINER_ID, CONTAINER_CONFIG, localDurableLogFactory,\n-                context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n-                context.getDefaultExtensions(), executorService());\n+        // Create a debug segment container instances using a new dataLog and old storage.\n+        for (int containerId = 0; containerId < containerCount; containerId++) {\n+            DebugStreamSegmentContainerTests.MetadataCleanupContainer debugStreamSegmentContainer = new\n+                    DebugStreamSegmentContainerTests.MetadataCleanupContainer(containerId, CONTAINER_CONFIG, localDurableLogFactory,\n+                    context.readIndexFactory, context.attributeIndexFactory, context.writerFactory, this.storageFactory,\n+                    context.getDefaultExtensions(), executorService());\n \n-        Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n-        debugStreamSegmentContainerMap.put(CONTAINER_ID, debugStreamSegmentContainer);\n+            Services.startAsync(debugStreamSegmentContainer, executorService()).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            debugStreamSegmentContainerMap.put(containerId, debugStreamSegmentContainer);\n \n-        // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n-        ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, CONTAINER_ID).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+            // Delete container metadata segment and attributes index segment corresponding to the container Id from the long term storage\n+            ContainerRecoveryUtils.deleteMetadataAndAttributeSegments(storage, containerId).get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93b0b35a278eb98aeb5efcd633fabb3c31227bb"}, "originalPosition": 283}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ca7a160970b4abaae24c51483955bffcfa80aff", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/1ca7a160970b4abaae24c51483955bffcfa80aff", "committedDate": "2020-09-02T06:36:00Z", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f96814758a5c208acca40b401f50be25b7d68db3", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/f96814758a5c208acca40b401f50be25b7d68db3", "committedDate": "2020-09-02T06:38:59Z", "message": "Updating transaction timeout.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1bbd94f83515c323eb7e1eed766ec81bb325dad9", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/1bbd94f83515c323eb7e1eed766ec81bb325dad9", "committedDate": "2020-09-02T22:38:58Z", "message": "Fixing comments.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d23f85385cfad61df9777daf399ffa6ad3cc2605", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/d23f85385cfad61df9777daf399ffa6ad3cc2605", "committedDate": "2020-09-02T22:44:34Z", "message": "Updating comment.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxMzY2MzMx", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-481366331", "createdAt": "2020-09-02T22:50:17Z", "commit": {"oid": "d23f85385cfad61df9777daf399ffa6ad3cc2605"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxMzg5NzYz", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-481389763", "createdAt": "2020-09-02T23:56:22Z", "commit": {"oid": "d23f85385cfad61df9777daf399ffa6ad3cc2605"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzo1NjoyM1rOHMP9WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzo1NjoyM1rOHMP9WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwNjQyNA==", "bodyText": "what happens when there are exceptions here ?\nLet's make sure test exits cleanly.\nI suggest we use\ntry {\n} catch (Exception e) {\n   this.close()\n}", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r482606424", "createdAt": "2020-09-02T23:56:23Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -175,30 +159,27 @@ protected int getThreadPoolSize() {\n         return 100;\n     }\n \n-    BookKeeperStarter setUpNewBK(int instanceId) throws Exception {\n-        return new BookKeeperStarter(instanceId);\n-    }\n-\n     /**\n      * Sets up a new BookKeeper & ZooKeeper.\n      */\n-    private static class BookKeeperStarter implements AutoCloseable {\n-        private final int bookieCount = 1;\n-        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n-        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n-        private BookKeeperServiceRunner bookKeeperServiceRunner;\n-        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n-        private int bkPort;\n-\n-        BookKeeperStarter(int instanceId) throws Exception {\n+    private static class BookKeeperRunner implements AutoCloseable {\n+        private final int bkPort;\n+        private final BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private final AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private final AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private final AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+\n+        BookKeeperRunner(int instanceId, int bookieCount) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d23f85385cfad61df9777daf399ffa6ad3cc2605"}, "originalPosition": 119}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "646fd48d74d3d6df39f88a4365c1911621e8883e", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/646fd48d74d3d6df39f88a4365c1911621e8883e", "committedDate": "2020-09-03T16:32:53Z", "message": "Handling bookKeeper start exception.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMDk1NDMx", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-482095431", "createdAt": "2020-09-03T18:25:27Z", "commit": {"oid": "646fd48d74d3d6df39f88a4365c1911621e8883e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxODoyNToyOFrOHMyh5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxODoyNjozNlrOHMykNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ==", "bodyText": "please rethrow exception otherwise it will just continue as if nothing happened.", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483172839", "createdAt": "2020-09-03T18:25:28Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -175,32 +159,33 @@ protected int getThreadPoolSize() {\n         return 100;\n     }\n \n-    BookKeeperStarter setUpNewBK(int instanceId) throws Exception {\n-        return new BookKeeperStarter(instanceId);\n-    }\n-\n     /**\n      * Sets up a new BookKeeper & ZooKeeper.\n      */\n-    private static class BookKeeperStarter implements AutoCloseable {\n-        private final int bookieCount = 1;\n-        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n-        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n-        private BookKeeperServiceRunner bookKeeperServiceRunner;\n-        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n-        private int bkPort;\n-\n-        BookKeeperStarter(int instanceId) throws Exception {\n+    private static class BookKeeperRunner implements AutoCloseable {\n+        private final int bkPort;\n+        private final BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private final AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private final AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private final AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+\n+        BookKeeperRunner(int instanceId, int bookieCount) throws Exception {\n             bkPort = TestUtils.getAvailableListenPort();\n-            val bookiePort = new ArrayList<>(Arrays.asList(TestUtils.getAvailableListenPort()));\n-\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n             this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n                     .startZk(true)\n                     .zkPort(bkPort)\n                     .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n-                    .bookiePorts(bookiePort)\n+                    .bookiePorts(bookiePorts)\n                     .build();\n-            this.bookKeeperServiceRunner.startAll();\n+            try {\n+                this.bookKeeperServiceRunner.startAll();\n+            } catch (Exception e) {\n+                this.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "646fd48d74d3d6df39f88a4365c1911621e8883e"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MzQzMQ==", "bodyText": "we need similar try cache block around this.zkClient.get().start(); as well", "url": "https://github.com/pravega/pravega/pull/5099#discussion_r483173431", "createdAt": "2020-09-03T18:26:36Z", "author": {"login": "sachin-j-joshi"}, "path": "test/integration/src/test/java/io/pravega/test/integration/RestoreBackUpDataRecoveryTest.java", "diffHunk": "@@ -175,32 +159,33 @@ protected int getThreadPoolSize() {\n         return 100;\n     }\n \n-    BookKeeperStarter setUpNewBK(int instanceId) throws Exception {\n-        return new BookKeeperStarter(instanceId);\n-    }\n-\n     /**\n      * Sets up a new BookKeeper & ZooKeeper.\n      */\n-    private static class BookKeeperStarter implements AutoCloseable {\n-        private final int bookieCount = 1;\n-        private AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n-        private AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n-        private BookKeeperServiceRunner bookKeeperServiceRunner;\n-        private AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n-        private int bkPort;\n-\n-        BookKeeperStarter(int instanceId) throws Exception {\n+    private static class BookKeeperRunner implements AutoCloseable {\n+        private final int bkPort;\n+        private final BookKeeperServiceRunner bookKeeperServiceRunner;\n+        private final AtomicReference<BookKeeperConfig> bkConfig = new AtomicReference<>();\n+        private final AtomicReference<CuratorFramework> zkClient = new AtomicReference<>();\n+        private final AtomicReference<BookKeeperServiceRunner> bkService = new AtomicReference<>();\n+\n+        BookKeeperRunner(int instanceId, int bookieCount) throws Exception {\n             bkPort = TestUtils.getAvailableListenPort();\n-            val bookiePort = new ArrayList<>(Arrays.asList(TestUtils.getAvailableListenPort()));\n-\n+            val bookiePorts = new ArrayList<Integer>();\n+            for (int i = 0; i < bookieCount; i++) {\n+                bookiePorts.add(TestUtils.getAvailableListenPort());\n+            }\n             this.bookKeeperServiceRunner = BookKeeperServiceRunner.builder()\n                     .startZk(true)\n                     .zkPort(bkPort)\n                     .ledgersPath(\"/pravega/bookkeeper/ledgers\")\n-                    .bookiePorts(bookiePort)\n+                    .bookiePorts(bookiePorts)\n                     .build();\n-            this.bookKeeperServiceRunner.startAll();\n+            try {\n+                this.bookKeeperServiceRunner.startAll();\n+            } catch (Exception e) {\n+                this.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE3MjgzOQ=="}, "originalCommit": {"oid": "646fd48d74d3d6df39f88a4365c1911621e8883e"}, "originalPosition": 138}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e062dcfe9966e8296e6341719d7d089452805906", "author": {"user": null}, "url": "https://github.com/pravega/pravega/commit/e062dcfe9966e8296e6341719d7d089452805906", "committedDate": "2020-09-03T18:45:58Z", "message": "Throwing exception caught.\n\nSigned-off-by: ManishKumarKeshri <manish.keshri562@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMTE4MjIy", "url": "https://github.com/pravega/pravega/pull/5099#pullrequestreview-482118222", "createdAt": "2020-09-03T18:55:32Z", "commit": {"oid": "e062dcfe9966e8296e6341719d7d089452805906"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3827, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}