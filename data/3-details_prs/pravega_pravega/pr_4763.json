{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDExNzQxMDI0", "number": 4763, "title": "Issue 4656: (KeyValue Tables) Sorted Table Segments", "bodyText": "Change log description\n\nAdded a new type of Table Segment that can iterate through Keys/Entries in a bitwise lexicographical order.\n\nExisting Table Segment is untouched and provides the same functionality.\n\n\n\nPurpose of the change\nFixes #4656.\nWhat the code does\nTableSegments (TS) are a hash-table based structure that keep their indices in Segment Attributes. However they provide no order between keys, making range queries impossible.\nSorted Table Segments (STS) are an extension to Table Segments in the following way:\n\nSTS can TS can coexist side-by-side. TSs have not been touched or affected in any way by the existences of STSs.\nSTS is built on top of TS using the following scheme:\n\nAll Keys are additionally stored in a B+Tree Set (BTS - see below) that provides order between keys.\nThe BTS stores its data (nodes) alongside the original TS data, but with its keys being differentiated from external keys. BTS keys are prefixed with a byte (I) denoting they're Internal, while external keys are prefixed with a byte (E) denoting they're External. No external query can access internal keys, so they cannot leak out.\nSTS delegates all operations to the underlying TS implementation exception Key/Entry iterators. Iterators are delegated to the BTS iterator, which provides ordering and range queries.\n\nThis is the only difference between TSs and STSs. They both function as a Hash Table, but STSs allow for iterating keys in order.\n\n\nFor TS, the WriterTableProcessor is the one that updates the index, so it knows which keys are inserted or removed. For STSs, this component is the one that updates the BTS, and it only does so when it detects a new key or that a key has been removed.\nThe ContainerKeyIndex component keeps a small tail cache of keys in sorted order (see below) that aids iterators for the tail (unidexed) section of the segment.\n\n\n\nB+Tree Set (BTS)\n\nThis is a an ordinary B+Tree but with no values. Only Keys are stored.\nWholly contained in io.pravega.common.util.btree.sets\n\nNot to be confused with io.pravega.common.util.btree.BTreeIndex which is a fixed-length KV-pair on append-only storage index.\n\n\nThe only operations implemented are: Update (Insert or Remove) and iterate.\nThis follows the typical B+Tree implementation with node splits, but it does not do mergers (yet). It only removes a node when it becomes empty (which is how the tree shrinks).\nIt supports variable-length keys with a maximum node size of 1MB.\nSince it does not have to store data directly in Durable Log (formerly known as Tier 1) or Long-Term Storage (formerly known as Tier 2), it does not have to worry about how to store or compact data; the underlying TS takes care of that.\n\nIntegrating B+TreeSet with Table Segments to form Sorted Table Segments:\n\nThe SortedKeyIndex component has been created, and it only is present for STSs.\n\nThis keeps an instance of the BTS, and updates it from the WriterTableProcessor (when it performs final indexing) and queries it during iteration.\nIt also keeps an in-memory TreeSet for the tail cache, which it cleans very aggressively as the WriterTableProcessor makes indexing progress; it uses this to complete iterator queries.\n\n\nThe SortedKeyIndex instance is shared between the WriterTableProcessor and the \"front-end\" ContainerKeyIndex; it provides a unified view of the STS keys.\n\nResource and performance considerations:\n\nThe presence of STSs in the Segment store will require more resources and more CPU utilization in order to maintain the B+TreeSet and sorted tail index.\n\nNo impact is anticipated for cases where STSs aren't used - regular Table Segments are not affected by the new code.\n\n\nThe BTS is only updated for new and removed keys. Updates to existing keys do not touch the BTS index, so this should only take up processing resources for STSs where we have a high degree of key churn.\nThe sorted tail cache now stores the tail keys in Java heap arrays. This may increase the heap requirements, however the throttling mechanisms inside the segment store will slow down the intake rate of new update requests if LTS and WriterTableProcessor falls too much behind, so this should be mostly contained.\n\nHow to verify it\nExtensive new unit tests added that verify new functionality.\nExisting unit tests validate that no existing functionality was affected.", "createdAt": "2020-04-30T17:45:54Z", "url": "https://github.com/pravega/pravega/pull/4763", "merged": true, "mergeCommit": {"oid": "063462df33ce86a983cb32e0c1f40f512c4eb64f"}, "closed": true, "closedAt": "2020-06-05T17:31:49Z", "author": {"login": "andreipaduroiu"}, "timelineItems": {"totalCount": 57, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcHmcifgH2gAyNDExNzQxMDI0OmVmOTExMzQzMTk3NDQwZDE4YzMxODQ3MzFlNTZmNzhiM2I3NzUxOTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcoWH2GAFqTQyNTQ4OTY3Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ef911343197440d18c3184731e56f78b3b775192", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/ef911343197440d18c3184731e56f78b3b775192", "committedDate": "2020-02-24T23:51:07Z", "message": "Refactored TableSegment, TableEntry, TableKey in preparation for creating KeyValueTable. Moved a few classes around.\n\nRefactored SegmentHelper to make use of TableSegmentKey, TableSegmentEntry and TableSegmentKeyVersion which better map to what a Table Segment can do. Refactored upstream code and adjusted unit tests.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05ff3487b0c7e26b69c22e3ef1969823915141a2", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/05ff3487b0c7e26b69c22e3ef1969823915141a2", "committedDate": "2020-02-25T00:21:59Z", "message": "Javadoc.\nMoved IteratorItem into its own file.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65f52b7d5bc0cc86d9490957498480d151703be2", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/65f52b7d5bc0cc86d9490957498480d151703be2", "committedDate": "2020-02-25T18:03:54Z", "message": "Javadoc.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "201e5f049c5ba118018d0633463cf739ea11e7e4", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/201e5f049c5ba118018d0633463cf739ea11e7e4", "committedDate": "2020-02-25T18:21:59Z", "message": "Made IteratorState a class.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bc363a9e6025c935db640f44603b7e67359f57a", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/0bc363a9e6025c935db640f44603b7e67359f57a", "committedDate": "2020-02-25T22:30:08Z", "message": "TableSegmentImpl.\nTableSegmentIterator.\nFixed a bug in MockConnectionFactoryImpl that was closing an externally-provided Executor when it shouldn't be.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e11121b0ee12384c7bae18228bf06d87bacc3b4", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/2e11121b0ee12384c7bae18228bf06d87bacc3b4", "committedDate": "2020-02-25T22:48:52Z", "message": "Updated TableSegment.keyIterator and TableSegment.entryIterator.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50bf936a5332db202e2153701412b7bc2dc64718", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/50bf936a5332db202e2153701412b7bc2dc64718", "committedDate": "2020-02-25T22:49:16Z", "message": "Merge remote-tracking branch 'remotes/ap/issue-4568-key-value-table-contracts' into issue-4333-tables-segment-client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc34a4e4d15ad134512155432fc88e525e2985c2", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/fc34a4e4d15ad134512155432fc88e525e2985c2", "committedDate": "2020-02-25T22:50:20Z", "message": "Updated TableSegment.keyIterator and TableSegment.entryIterator.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "206d4847cf8fd13c7ed69deabe9abf7f047a9589", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/206d4847cf8fd13c7ed69deabe9abf7f047a9589", "committedDate": "2020-02-26T18:14:46Z", "message": "Javadoc fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e848733fbbb3a14ce48713e73a5cfa520dbaca03", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/e848733fbbb3a14ce48713e73a5cfa520dbaca03", "committedDate": "2020-03-02T18:24:40Z", "message": "Merge remote-tracking branch 'remotes/origin/master' into issue-4568-key-value-table-contracts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bec961271dd6680d2f065f11505cd618bc50e14b", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/bec961271dd6680d2f065f11505cd618bc50e14b", "committedDate": "2020-03-03T16:10:18Z", "message": "Refactored TableSegment, TableEntry, TableKey in preparation for creating KeyValueTable. Moved a few classes around.\n\nRefactored SegmentHelper to make use of TableSegmentKey, TableSegmentEntry and TableSegmentKeyVersion which better map to what a Table Segment can do. Refactored upstream code and adjusted unit tests.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fdc48e967cae0a052e064c0178aacde4a34f7124", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/fdc48e967cae0a052e064c0178aacde4a34f7124", "committedDate": "2020-03-03T16:10:18Z", "message": "Javadoc.\nMoved IteratorItem into its own file.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57a4ae4f6a76424ffd789947232bb426e7266cec", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/57a4ae4f6a76424ffd789947232bb426e7266cec", "committedDate": "2020-03-03T16:10:18Z", "message": "Javadoc.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a9cc3e0dbf4d34ac8d51a2e842b999dc2fc471d", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/9a9cc3e0dbf4d34ac8d51a2e842b999dc2fc471d", "committedDate": "2020-03-03T16:10:18Z", "message": "Made IteratorState a class.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c138dd219c3bed59ad5998638c3cdf28e27471f", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/2c138dd219c3bed59ad5998638c3cdf28e27471f", "committedDate": "2020-03-03T16:10:18Z", "message": "Updated TableSegment.keyIterator and TableSegment.entryIterator.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "096cdd4843a0cb3dd11893b7c66592c858b1471e", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/096cdd4843a0cb3dd11893b7c66592c858b1471e", "committedDate": "2020-03-03T16:10:18Z", "message": "Javadoc fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f81fbb3aa9d099e39986a9c258da838a4e7f630", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/5f81fbb3aa9d099e39986a9c258da838a4e7f630", "committedDate": "2020-03-04T16:17:34Z", "message": "Merge branch 'issue-4568-key-value-table-contracts' of https://github.com/andreipaduroiu/pravega into issue-4568-key-value-table-contracts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8a3e9cb0186f3c390a8b500d71be299cceb8c8c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/e8a3e9cb0186f3c390a8b500d71be299cceb8c8c", "committedDate": "2020-03-04T16:56:28Z", "message": "Unit tests ... for coverage.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cadfa9c07c323757ad24197deccd3e6fb27f577", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/1cadfa9c07c323757ad24197deccd3e6fb27f577", "committedDate": "2020-03-04T21:05:59Z", "message": "Increasing coverage.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0fac12be237bb6f5053dad56b446a8e3011cb619", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/0fac12be237bb6f5053dad56b446a8e3011cb619", "committedDate": "2020-03-04T22:48:59Z", "message": "Merge remote-tracking branch 'remotes/ap/issue-4568-key-value-table-contracts' into issue-4333-tables-segment-client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d0d197c9913c94f37ec6f9d15361359a70dc33f", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/6d0d197c9913c94f37ec6f9d15361359a70dc33f", "committedDate": "2020-03-04T22:58:46Z", "message": "Default methods.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3adfa77124cf1c79eac5528e8090a8f0ee3e403e", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/3adfa77124cf1c79eac5528e8090a8f0ee3e403e", "committedDate": "2020-03-04T23:59:10Z", "message": "Added Wire Protocol support for prefix-filtered iterators.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@dell.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df7480352538f93c7ccb10db86216513e019faa5", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/df7480352538f93c7ccb10db86216513e019faa5", "committedDate": "2020-03-09T22:03:06Z", "message": "Fixed some Javadoc verbiage.\nSeparated IteratorState (interface) and IteratorStateImpl (class) to hide some implementation details.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afb51fed4467aa7df842b38eba434b58ade7326f", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/afb51fed4467aa7df842b38eba434b58ade7326f", "committedDate": "2020-03-09T23:28:42Z", "message": "Merge remote-tracking branch 'remotes/ap/issue-4568-key-value-table-contracts' into issue-4333-tables-segment-client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4958aba6aea2fbf39df8a4e247bbe9d92ea3414c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/4958aba6aea2fbf39df8a4e247bbe9d92ea3414c", "committedDate": "2020-03-09T23:36:56Z", "message": "Merged with parent branch. Fixed some tests.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3f2e4d22f861bc513255b0a1d26e916c66e905b", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/d3f2e4d22f861bc513255b0a1d26e916c66e905b", "committedDate": "2020-03-17T16:00:03Z", "message": "Javadoc fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fa9ebfaafd25626e344949f70230ca690a41ff4", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/5fa9ebfaafd25626e344949f70230ca690a41ff4", "committedDate": "2020-03-17T18:06:19Z", "message": "KeyValueTable API variant #2\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f6c79281346819c2d1247c9ed1b265d8a761be1", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/1f6c79281346819c2d1247c9ed1b265d8a761be1", "committedDate": "2020-03-20T16:57:22Z", "message": "Merge remote-tracking branch 'remotes/ap/issue-4568-key-value-table-contracts' into issue-4333-tables-segment-client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53fd8fd07db76368d20a0e2c9b4657eb98044bba", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/53fd8fd07db76368d20a0e2c9b4657eb98044bba", "committedDate": "2020-03-30T22:39:15Z", "message": "Plumbed through key prefix filter. Not yet implemented.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "828167b4079c763a165fdb8825e091985970c94a", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/828167b4079c763a165fdb8825e091985970c94a", "committedDate": "2020-03-31T17:51:28Z", "message": "TableStore.createSegment now supports 'sorted' flag.\nDefined SegmentSortedKeyIndex.\nWiring up SegmentSortedKeyIndex throughout the codebase.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e4684fd95bbf7ab2916e258aad0d1f9a43890ba", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/2e4684fd95bbf7ab2916e258aad0d1f9a43890ba", "committedDate": "2020-04-03T02:04:50Z", "message": "SegmentSortedKeyIndexImpl: In-Memory Key List.\nAdded BTreeList and BTreeListPage.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "258833c7092e362ce9842b09307bc549e817b3ab", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/258833c7092e362ce9842b09307bc549e817b3ab", "committedDate": "2020-04-03T02:09:11Z", "message": "Merge remote-tracking branch 'remotes/origin/feature-key-value-tables' into issue-4656-iterator-filters\n\n# Conflicts:\n#\tclient/src/main/java/io/pravega/client/tables/IteratorState.java\n#\tclient/src/main/java/io/pravega/client/tables/KeyValueTable.java\n#\tclient/src/main/java/io/pravega/client/tables/TableKey.java\n#\tclient/src/main/java/io/pravega/client/tables/impl/TableSegment.java\n#\tclient/src/main/java/io/pravega/client/tables/impl/TableSegmentImpl.java\n#\tclient/src/main/java/io/pravega/client/tables/impl/TableSegmentIterator.java\n#\tclient/src/test/java/io/pravega/client/tables/IteratorStateTests.java\n#\tclient/src/test/java/io/pravega/client/tables/TableEntryTests.java\n#\tclient/src/test/java/io/pravega/client/tables/TableKeyTests.java\n#\tclient/src/test/java/io/pravega/client/tables/impl/TableSegmentImplTest.java\n#\tcontroller/src/main/java/io/pravega/controller/server/SegmentHelper.java\n#\tsegmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/ContainerTableExtensionImpl.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "345d0d2922979b69a7517cb7c14f560ad7bce1ef", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/345d0d2922979b69a7517cb7c14f560ad7bce1ef", "committedDate": "2020-04-03T02:10:04Z", "message": "Merge fallout.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c1a805d41438dce4fa7a5880aa37a9c6d2e8e71", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/4c1a805d41438dce4fa7a5880aa37a9c6d2e8e71", "committedDate": "2020-04-03T21:56:55Z", "message": "BTreeSetPage: unit tests and fixes.\nByteArrayComparator: unit tests.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76cea1f51b2f60336120b40f29aa8ca603d94629", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/76cea1f51b2f60336120b40f29aa8ca603d94629", "committedDate": "2020-04-06T20:46:33Z", "message": "BTreeSet: update path.\nBTreeSetPage: updated tests.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8aacbad6094866f1115c516e85f0a0dd2813bf9b", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/8aacbad6094866f1115c516e85f0a0dd2813bf9b", "committedDate": "2020-04-07T16:10:32Z", "message": "Refactored update path.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45850d0d727bf4221eeef4beaa2124f1f5360ce6", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/45850d0d727bf4221eeef4beaa2124f1f5360ce6", "committedDate": "2020-04-07T17:42:51Z", "message": "Moved BTreeSet into its own package. Factored out some classes.\nItemIterator.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cf52e0b174eb52e629e28cbe45c98fab60c02e4", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/0cf52e0b174eb52e629e28cbe45c98fab60c02e4", "committedDate": "2020-04-08T22:03:31Z", "message": "BTreeSet: unit tests and lots of bug fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35d81f9060c743cbf1de7f57efce0f51048acd86", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/35d81f9060c743cbf1de7f57efce0f51048acd86", "committedDate": "2020-04-09T22:22:05Z", "message": "KeyTranslator, SegmentSortedKeyIndexImpl, Sorted Iterators.\n(Next is unit tests for all of these)\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2260e33ea82ba88fe40e7c96f6f9949e360fd199", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/2260e33ea82ba88fe40e7c96f6f9949e360fd199", "committedDate": "2020-04-10T22:47:45Z", "message": "KeyTranslator: unit tests.\nSegmentSortedKeyIndexImpl: unit tests and bug fixes.\nBTreeSet: root page Id is now -1L.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c71cf022dbac5dd6ff579b0cf92b5c0b0b9340c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/3c71cf022dbac5dd6ff579b0cf92b5c0b0b9340c", "committedDate": "2020-04-13T18:13:18Z", "message": "ContainerKeyIndex unit tests updates.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ea83606c8960b9a52e955e43cd53a3fe92bdd98", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/5ea83606c8960b9a52e955e43cd53a3fe92bdd98", "committedDate": "2020-04-13T23:54:36Z", "message": "Remaining unit tests.\nRemoved @Beta on TableStore. Added elsewhere as appropriate.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f4abf549b8a6f903c4f3c028a4950ad6f4f5a58", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/8f4abf549b8a6f903c4f3c028a4950ad6f4f5a58", "committedDate": "2020-04-14T18:23:58Z", "message": "Bug fixes.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "894bfd70d259a5789a01d052a67fb8d67a3c26a9", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/894bfd70d259a5789a01d052a67fb8d67a3c26a9", "committedDate": "2020-04-14T23:58:32Z", "message": "Fixed a bug where the sorted iterator may return fewer keys than available if between the iteration initiation and the execution of `getNext`, a call to `persist()` and `updateSegmentIndexedOffset` occurred.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "750a7bf6ba52447365870ad82383e6d4c3d38a1c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/750a7bf6ba52447365870ad82383e6d4c3d38a1c", "committedDate": "2020-04-15T15:51:46Z", "message": "Checkstyle.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24355582c3515958bc8b93fe47ffddb31f0bc834", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/24355582c3515958bc8b93fe47ffddb31f0bc834", "committedDate": "2020-04-30T17:22:35Z", "message": "Merge remote-tracking branch 'remotes/origin/feature-key-value-tables' into issue-4656-iterator-filters\n\n# Conflicts:\n#\tcommon/src/main/java/io/pravega/common/util/ArrayView.java\n#\tsegmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/ContainerKeyIndex.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f49d624bdf368c4fece8d07b5f9f77234b686818", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/f49d624bdf368c4fece8d07b5f9f77234b686818", "committedDate": "2020-04-30T17:24:34Z", "message": "Build fix.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a3375d985df74e01255ae52043877f4a613c8da", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/7a3375d985df74e01255ae52043877f4a613c8da", "committedDate": "2020-04-30T19:38:35Z", "message": "checkstyle\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23a8802f315d3b96f85dcc59a368a4410b1a342c", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/23a8802f315d3b96f85dcc59a368a4410b1a342c", "committedDate": "2020-05-04T15:12:40Z", "message": "Merge remote-tracking branch 'remotes/origin/feature-key-value-tables' into issue-4656-iterator-filters\n\n# Conflicts:\n#\tcommon/src/main/java/io/pravega/common/util/ArrayView.java\n#\tcommon/src/main/java/io/pravega/common/util/AsyncIterator.java\n#\tcommon/src/test/java/io/pravega/common/concurrent/AsyncIteratorTests.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/e23c68e3087386a7ba7090d86218ad916e2dabac", "committedDate": "2020-05-04T15:18:17Z", "message": "Integrated with upstream branch.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNDY5MDMx", "url": "https://github.com/pravega/pravega/pull/4763#pullrequestreview-420469031", "createdAt": "2020-05-28T20:31:17Z", "commit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMDozMjozMFrOGcFsfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMToxMTo0N1rOGcG4xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwNjYyMw==", "bodyText": "It is not entirely clear to me why we are making this optional. Could we make all table segments sorted rather than deciding whether it needs to be sorted upon creation?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432106623", "createdAt": "2020-05-28T20:32:30Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/TableService.java", "diffHunk": "@@ -48,9 +48,9 @@ public TableService(SegmentContainerRegistry segmentContainerRegistry, SegmentTo\n     //region TableStore Implementation\n \n     @Override\n-    public CompletableFuture<Void> createSegment(String segmentName, Duration timeout) {\n+    public CompletableFuture<Void> createSegment(String segmentName, boolean sorted, Duration timeout) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwODIxOQ==", "bodyText": "If the sorted key index is updated separately from the table segment index, then is there a chance that the user of this table sees an update in one but not in the other? For example, a regular lookup can return a key that is not present in a range query.\nPerhaps I'm missing an overall view of the flow for the calls in this interface.", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432108219", "createdAt": "2020-05-28T20:35:49Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/SegmentSortedKeyIndex.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.tables;\n+\n+import com.google.common.annotations.Beta;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import javax.annotation.Nullable;\n+import lombok.Data;\n+\n+/**\n+ * Defines an index that maintains a Table Segment's Keys in lexicographic bitwise order.\n+ */\n+@Beta\n+interface SegmentSortedKeyIndex {\n+    /**\n+     * Include and persist updates that have been included in a Table Segment Index.\n+     *\n+     * @param bucketUpdates A Collection of {@link BucketUpdate} instances that reflect what keys have been added and/or\n+     *                      removed.\n+     * @param timeout       Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation has completed.\n+     */\n+    CompletableFuture<Void> persistUpdate(Collection<BucketUpdate> bucketUpdates, Duration timeout);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyNjE0OA==", "bodyText": "The next three calls are to maintain a tail cache, if I understand it right. By reading these, it is not clear to me the expected flow of these calls for a user of this interface, and it is also not not clear what the consistency guarantee is.", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432126148", "createdAt": "2020-05-28T21:11:47Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/SegmentSortedKeyIndex.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.tables;\n+\n+import com.google.common.annotations.Beta;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import java.time.Duration;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import javax.annotation.Nullable;\n+import lombok.Data;\n+\n+/**\n+ * Defines an index that maintains a Table Segment's Keys in lexicographic bitwise order.\n+ */\n+@Beta\n+interface SegmentSortedKeyIndex {\n+    /**\n+     * Include and persist updates that have been included in a Table Segment Index.\n+     *\n+     * @param bucketUpdates A Collection of {@link BucketUpdate} instances that reflect what keys have been added and/or\n+     *                      removed.\n+     * @param timeout       Timeout for the operation.\n+     * @return A CompletableFuture that, when completed, will indicate that the operation has completed.\n+     */\n+    CompletableFuture<Void> persistUpdate(Collection<BucketUpdate> bucketUpdates, Duration timeout);\n+\n+    /**\n+     * Includes the given {@link TableKeyBatch} which contains Keys that have recently been updated or removed, but not\n+     * yet indexed. These will be stored in a memory data structure until {@link #updateSegmentIndexOffset} will be invoked\n+     * with an offset that exceeds their offset.\n+     *\n+     * @param batch              The {@link TableKeyBatch} to include.\n+     * @param batchSegmentOffset The offset of the {@link TableKeyBatch}.\n+     */\n+    void includeTailUpdate(TableKeyBatch batch, long batchSegmentOffset);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 46}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwODg2MTg1", "url": "https://github.com/pravega/pravega/pull/4763#pullrequestreview-420886185", "createdAt": "2020-05-29T11:58:36Z", "commit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMTo1ODozNlrOGcZwwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQxMzozODo0MlrOGcc_iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQzNTM5Mw==", "bodyText": "I understand that there are different properties and API we want for this set implementation vs. the index implementation backed by a B+ tree. I'm wondering if there is any opportunity for consolidation as they are both backed by a B+ tree. I haven't done a close comparison, but at a high-level sounds possible. Any insight you can share?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432435393", "createdAt": "2020-05-29T11:58:36Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSet.java", "diffHunk": "@@ -0,0 +1,414 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArrayComparator;\n+import java.time.Duration;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * A B+Tree-backed Set. Stores all items in a B+Tree Structure using a {@link ByteArrayComparator} for ordering them.\n+ *\n+ * NOTE: This component is in {@link Beta}. There are no guarantees about data or API compatibility with future versions.\n+ * Any component that is directly dependent on this one should either be in {@link Beta} as well.\n+ */\n+@NotThreadSafe\n+@Beta\n+@Slf4j\n+public class BTreeSet {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ4MjQyOA==", "bodyText": "If ai understand the flow right, ContainerTableExtensionImpl implements ContainerTableExtension, which implements TableStore. keyIterator and entryIterator are calls in the TableStore interface, so that's how code using table segments use the sorted table segments.\nSegmentSortedKeyIndex is made available via ContainerKeyIndex, which is used in this class. This is how the TableStore interface connects with the SegmentSortedKeyIndex, is it right?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432482428", "createdAt": "2020-05-29T13:28:49Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/ContainerTableExtensionImpl.java", "diffHunk": "@@ -269,16 +311,49 @@ public void close() {\n         return builder.getResultFutures();\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n+    private <T, V extends Collection<T>> V translateItems(V items, SegmentProperties segmentInfo, boolean isExternal,\n+                                                          BiFunction<KeyTranslator, T, T> translateFunction) {\n+        if (!ContainerSortedKeyIndex.isSortedTableSegment(segmentInfo)) {\n+            // Nothing to translate for non-sorted segments.\n+            return items;\n+        }\n+\n+        val t = isExternal ? SortedKeyIndexDataSource.EXTERNAL_TRANSLATOR : SortedKeyIndexDataSource.INTERNAL_TRANSLATOR;\n+        return (V) items.stream().map(i -> translateItem(i, t, translateFunction)).collect(Collectors.toList());\n+    }\n+\n+    private <T> T translateItem(T item, KeyTranslator translator, BiFunction<KeyTranslator, T, T> translateItem) {\n+        return item == null ? null : translateItem.apply(translator, item);\n+    }\n+\n     @Override\n     public CompletableFuture<AsyncIterator<IteratorItem<TableKey>>> keyIterator(String segmentName, IteratorArgs args) {\n-        logRequest(\"keyIterator\", segmentName);\n-        return newIterator(segmentName, args, TableBucketReader::key);\n+        return this.segmentContainer.forSegment(segmentName, args.getFetchTimeout())\n+                .thenComposeAsync(segment -> {\n+                    if (ContainerSortedKeyIndex.isSortedTableSegment(segment.getInfo())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ4NDI0MQ==", "bodyText": "I'm curious, why you think it is a good idea to have booleans for inclusion rather than pick one option and go with it?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432484241", "createdAt": "2020-05-29T13:31:51Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSet.java", "diffHunk": "@@ -0,0 +1,414 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArrayComparator;\n+import java.time.Duration;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * A B+Tree-backed Set. Stores all items in a B+Tree Structure using a {@link ByteArrayComparator} for ordering them.\n+ *\n+ * NOTE: This component is in {@link Beta}. There are no guarantees about data or API compatibility with future versions.\n+ * Any component that is directly dependent on this one should either be in {@link Beta} as well.\n+ */\n+@NotThreadSafe\n+@Beta\n+@Slf4j\n+public class BTreeSet {\n+    //region Members\n+\n+    public static final Comparator<ArrayView> COMPARATOR = new ByteArrayComparator()::compare;\n+    private static final Comparator<PagePointer> POINTER_COMPARATOR = PagePointer.getComparator(COMPARATOR);\n+\n+    private final int maxPageSize;\n+    private final int maxItemSize;\n+    @NonNull\n+    private final ReadPage read;\n+    @NonNull\n+    private final PersistPages update;\n+    @NonNull\n+    private final Executor executor;\n+    @NonNull\n+    private final String traceLogId;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link BTreeSet} class.\n+     *\n+     * @param maxPageSize The maximum size, in bytes, of any page.\n+     * @param maxItemSize The maximum size, in bytes, of any single item in the {@link BTreeSet}.\n+     * @param read        A {@link ReadPage} function that can be used to fetch a single {@link BTreeSet} page from an\n+     *                    external data source.\n+     * @param update      A {@link PersistPages} function that can be used to store and delete multiple {@link BTreeSet}\n+     *                    pages to/from an external data source.\n+     * @param executor    Executor for async operations.\n+     * @param traceLogId  Trace id for logging.\n+     */\n+    public BTreeSet(int maxPageSize, int maxItemSize, @NonNull ReadPage read, @NonNull PersistPages update,\n+                    @NonNull Executor executor, String traceLogId) {\n+        Preconditions.checkArgument(maxItemSize < maxPageSize / 2, \"maxItemSize must be at most half of maxPageSize.\");\n+        this.maxItemSize = maxItemSize;\n+        this.maxPageSize = maxPageSize;\n+        this.read = read;\n+        this.update = update;\n+        this.executor = executor;\n+        this.traceLogId = traceLogId == null ? \"\" : traceLogId;\n+    }\n+\n+    //endregion\n+\n+    //region Updates\n+\n+    /**\n+     * Atomically inserts the items in 'toInsert' into the {@link BTreeSet} and removes the items in 'toRemove'\n+     * from the {@link BTreeSet}. No duplicates are allowed; the same item cannot exist multiple times in either 'toInsert'\n+     * or 'toRemove' or in both of them.\n+     *\n+     * @param toInsert      (Optional). A Collection of {@link ArrayView} instances representing the items to insert.\n+     *                      If an item is already present, it will not be reinserted (updates are idempotent).\n+     * @param toRemove      (Optional). A Collection of {@link ArrayView} instances representing the items to remove.\n+     * @param getNextPageId A Supplier that, when invoked, will return a unique number representing the Id of the next\n+     *                      {@link BTreeSet} page that has to be generated.\n+     * @param timeout       Timeout for the operation.\n+     * @return A CompletableFuture that, when completed normally, will indicate that the updates have been applied\n+     * successfully. If the operation failed, the Future will be completed with the appropriate exception.\n+     */\n+    public CompletableFuture<Void> update(@Nullable Collection<? extends ArrayView> toInsert, @Nullable Collection<? extends ArrayView> toRemove,\n+                                          @NonNull Supplier<Long> getNextPageId, @NonNull Duration timeout) {\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        val updates = new ArrayList<UpdateItem>();\n+        int insertCount = collectUpdates(toInsert, false, updates);\n+        int removeCount = collectUpdates(toRemove, true, updates);\n+        updates.sort(UpdateItem::compareTo);\n+        log.debug(\"{}: Update (Insert={}, Remove={}).\", this.traceLogId, insertCount, removeCount);\n+        if (updates.isEmpty()) {\n+            // Nothing to do.\n+            return CompletableFuture.completedFuture(null);\n+        }\n+\n+        // The updates are sorted, so any empty items will be placed first.\n+        Preconditions.checkArgument(updates.get(0).getItem().getLength() > 0, \"No empty items allowed.\");\n+        return applyUpdates(updates.iterator(), timer)\n+                .thenApply(pageCollection -> processModifiedPages(pageCollection, getNextPageId))\n+                .thenComposeAsync(pageCollection -> writePages(pageCollection, timer), this.executor);\n+    }\n+\n+    private int collectUpdates(Collection<? extends ArrayView> items, boolean isRemoval, List<UpdateItem> updates) {\n+        if (items == null) {\n+            return 0;\n+        }\n+\n+        for (val i : items) {\n+            Preconditions.checkArgument(i.getLength() <= this.maxItemSize,\n+                    \"Item exceeds maximum allowed length (%s).\", this.maxItemSize);\n+            updates.add(new UpdateItem(i, isRemoval));\n+        }\n+        return items.size();\n+    }\n+\n+    private CompletableFuture<PageCollection> applyUpdates(Iterator<UpdateItem> items, TimeoutTimer timer) {\n+        val pageCollection = new PageCollection();\n+        val lastPage = new AtomicReference<BTreeSetPage.LeafPage>(null);\n+        val lastPageUpdates = new ArrayList<UpdateItem>();\n+        return Futures.loop(\n+                items::hasNext,\n+                () -> {\n+                    // Locate the page where the update is to be executed. Do not apply it yet as it is more efficient\n+                    // to bulk-apply multiple at once. Collect all updates for each Page, and only apply them once we have\n+                    // \"moved on\" to another page.\n+                    val next = items.next();\n+                    return locatePage(next.getItem(), pageCollection, timer)\n+                            .thenAccept(page -> {\n+                                val last = lastPage.get();\n+                                if (page != last) {\n+                                    // This key goes to a different page than the one we were looking at.\n+                                    if (last != null) {\n+                                        // Commit the outstanding updates.\n+                                        last.update(lastPageUpdates);\n+                                    }\n+\n+                                    // Update the pointers.\n+                                    lastPage.set(page);\n+                                    lastPageUpdates.clear();\n+                                }\n+\n+                                // Record the current update.\n+                                lastPageUpdates.add(next);\n+                            });\n+                },\n+                this.executor)\n+                .thenApplyAsync(v -> {\n+                    // We need not forget to apply the last batch of updates from the last page.\n+                    if (lastPage.get() != null) {\n+                        lastPage.get().update(lastPageUpdates);\n+                    }\n+                    return pageCollection;\n+                }, this.executor);\n+    }\n+\n+    private PageCollection processModifiedPages(PageCollection pageCollection, Supplier<Long> getNewPageId) {\n+        Collection<BTreeSetPage> candidates = pageCollection.getLeafPages();\n+        while (!candidates.isEmpty()) {\n+            // Process each candidate and determine if it should be deleted or split into multiple pages.\n+            val tmc = new TreeModificationContext(pageCollection);\n+            for (BTreeSetPage p : candidates) {\n+                if (p.getItemCount() == 0) {\n+                    deletePage(p, tmc);\n+                } else {\n+                    splitPageIfNecessary(p, getNewPageId, tmc);\n+                }\n+            }\n+\n+            // Update those pages' parents.\n+            tmc.accept(BTreeSetPage.IndexPage::addChildren, BTreeSetPage.IndexPage::removeChildren, POINTER_COMPARATOR);\n+            candidates = tmc.getModifiedParents();\n+        }\n+\n+        pageCollection.getIndexPages().forEach(p -> {\n+            if (p.isModified()) {\n+                p.seal();\n+            }\n+        });\n+        return pageCollection;\n+    }\n+\n+    private void deletePage(BTreeSetPage p, TreeModificationContext context) {\n+        // Delete the page if it's empty, but only if it's not the root page.\n+        if (p.getPagePointer().hasParent()) {\n+            context.getPageCollection().pageDeleted(p);\n+            context.deleted(p.getPagePointer());\n+            log.debug(\"{}: Deleted empty page {}.\", this.traceLogId, p.getPagePointer());\n+        } else if (p.isIndexPage()) {\n+            p = BTreeSetPage.emptyLeafRoot();\n+            p.markModified();\n+            context.getPageCollection().pageUpdated(p);\n+            log.debug(\"{}: Replaced empty Index Root with empty Leaf Root.\", this.traceLogId);\n+        }\n+    }\n+\n+    private void splitPageIfNecessary(BTreeSetPage p, Supplier<Long> getNewPageId, TreeModificationContext context) {\n+        val splits = p.split(this.maxPageSize, getNewPageId);\n+        if (splits == null) {\n+            // No split necessary\n+            return;\n+        }\n+\n+        if (p.getPagePointer().hasParent()) {\n+            Preconditions.checkArgument(splits.get(0).getPagePointer().getPageId() == p.getPagePointer().getPageId(),\n+                    \"First split result (%s) not current page (%s).\", splits.get(0).getPagePointer(), p.getPagePointer());\n+        } else {\n+            // If we split the root, the new pages will already point to the root; we must create a blank\n+            // index root page, which will be updated in the next step.\n+            context.getPageCollection().pageUpdated(BTreeSetPage.emptyIndexRoot());\n+        }\n+\n+        splits.forEach(splitPage -> {\n+            context.getPageCollection().pageUpdated(splitPage);\n+            context.created(splitPage.getPagePointer());\n+        });\n+        log.debug(\"{}: Page '{}' split into {}: {}.\", this.traceLogId, p, splits.size(), splits);\n+    }\n+\n+    private CompletableFuture<Void> writePages(@NonNull PageCollection pageCollection, TimeoutTimer timer) {\n+        // Order the pages from bottom up. The upstream code may have limitations in how much it can update atomically,\n+        // so it may commit this in multiple non-atomic operations. If the process is interrupted mid-way then we want\n+        // to ensure that parent pages aren't updated before leaf pages (which would cause index corruptions - i.e., by\n+        // pointing to inexistent pages).\n+        val processedPageIds = new HashSet<Long>();\n+\n+        // First collect updates. Begin from the bottom (Leaf Pages).\n+        val toWrite = new ArrayList<Map.Entry<Long, ArrayView>>();\n+        collectWriteCandidates(pageCollection.getLeafPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Newly split pages may not be reachable from any modified Leaf Pages. Collect them too.\n+        collectWriteCandidates(pageCollection.getIndexPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Then collect deletions, making sure we also consider all their parents (which should be modified/deleted as well).\n+        collectWriteCandidates(pageCollection.getDeletedPagesParents(), toWrite, processedPageIds, pageCollection);\n+        log.debug(\"{}: Persist (Updates={}, Deletions={}).\", this.traceLogId, toWrite.size(), pageCollection.getDeletedPageIds().size());\n+        return this.update.apply(toWrite, pageCollection.getDeletedPageIds(), timer.getRemaining());\n+    }\n+\n+    private void collectWriteCandidates(Collection<BTreeSetPage> candidates, List<Map.Entry<Long, ArrayView>> toWrite,\n+                                        Set<Long> processedIds, PageCollection pageCollection) {\n+        while (!candidates.isEmpty()) {\n+            val next = new ArrayList<BTreeSetPage>();\n+            candidates.stream()\n+                    .filter(p -> p.isModified() && !processedIds.contains(p.getPagePointer().getPageId()))\n+                    .forEach(p -> {\n+                        toWrite.add(new AbstractMap.SimpleImmutableEntry<>(p.getPagePointer().getPageId(), p.getData()));\n+                        val parent = pageCollection.get(p.getPagePointer().getParentPageId());\n+                        assert p.getPagePointer().hasParent() == (parent != null);\n+                        processedIds.add(p.getPagePointer().getPageId());\n+                        if (parent != null) {\n+                            next.add(parent);\n+                        }\n+                    });\n+            candidates = next;\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region Queries\n+\n+    /**\n+     * Returns an {@link AsyncIterator} that will iterate through all the items in this {@link BTreeSet} within the\n+     * specified bounds. All iterated items will be returned in lexicographic order (smallest to largest).\n+     * See {@link ByteArrayComparator} for ordering details.\n+     *\n+     * @param firstItem          An {@link ArrayView} indicating the first Item to iterate from. If null, the iteration\n+     *                           will begin with the first item in the index.\n+     * @param firstItemInclusive If true, firstIem will be included in the iteration (provided it exists), otherwise it", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ4ODMyOA==", "bodyText": "It is not great that we have to create an exception for the serialization versioning. I understand that the concern is the overhead of serializing, but could you elaborate on why you believe this is concern that justifies creating an exception for not using VersionedSerializer? Is there a way of using VersionedSerializer that could solve the issue, e.g., changing a version such that it is not backwards compatible when the overhead is high?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r432488328", "createdAt": "2020-05-29T13:38:42Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSetPage.java", "diffHunk": "@@ -0,0 +1,879 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.BitConverter;\n+import io.pravega.common.util.ByteArrayComparator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.common.util.IllegalDataFormatException;\n+import io.pravega.common.util.btree.SearchResult;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.function.Supplier;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.Getter;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+/**\n+ * Represents a Page (Node) within a {@link BTreeSet}. Pages can be of type {@link IndexPage} or {@link LeafPage}.\n+ */\n+@NotThreadSafe\n+abstract class BTreeSetPage {\n+    //region Serialization format\n+\n+    /**\n+     * Format Version related fields. The version itself is the first byte of the serialization. When we will have to\n+     * support multiple versions, we will need to read this byte and choose the appropriate deserialization approach.\n+     * We cannot use VersionedSerializer in here - doing so would prevent us from efficiently querying and modifying the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyNDE3NjM4", "url": "https://github.com/pravega/pravega/pull/4763#pullrequestreview-422417638", "createdAt": "2020-06-02T07:39:28Z", "commit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQwNzozOToyOFrOGdls3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQxMzozNDoyOFrOGdx2Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY3OTU4MQ==", "bodyText": "There is a typo in firstIem.", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433679581", "createdAt": "2020-06-02T07:39:28Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSet.java", "diffHunk": "@@ -0,0 +1,414 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArrayComparator;\n+import java.time.Duration;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * A B+Tree-backed Set. Stores all items in a B+Tree Structure using a {@link ByteArrayComparator} for ordering them.\n+ *\n+ * NOTE: This component is in {@link Beta}. There are no guarantees about data or API compatibility with future versions.\n+ * Any component that is directly dependent on this one should either be in {@link Beta} as well.\n+ */\n+@NotThreadSafe\n+@Beta\n+@Slf4j\n+public class BTreeSet {\n+    //region Members\n+\n+    public static final Comparator<ArrayView> COMPARATOR = new ByteArrayComparator()::compare;\n+    private static final Comparator<PagePointer> POINTER_COMPARATOR = PagePointer.getComparator(COMPARATOR);\n+\n+    private final int maxPageSize;\n+    private final int maxItemSize;\n+    @NonNull\n+    private final ReadPage read;\n+    @NonNull\n+    private final PersistPages update;\n+    @NonNull\n+    private final Executor executor;\n+    @NonNull\n+    private final String traceLogId;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link BTreeSet} class.\n+     *\n+     * @param maxPageSize The maximum size, in bytes, of any page.\n+     * @param maxItemSize The maximum size, in bytes, of any single item in the {@link BTreeSet}.\n+     * @param read        A {@link ReadPage} function that can be used to fetch a single {@link BTreeSet} page from an\n+     *                    external data source.\n+     * @param update      A {@link PersistPages} function that can be used to store and delete multiple {@link BTreeSet}\n+     *                    pages to/from an external data source.\n+     * @param executor    Executor for async operations.\n+     * @param traceLogId  Trace id for logging.\n+     */\n+    public BTreeSet(int maxPageSize, int maxItemSize, @NonNull ReadPage read, @NonNull PersistPages update,\n+                    @NonNull Executor executor, String traceLogId) {\n+        Preconditions.checkArgument(maxItemSize < maxPageSize / 2, \"maxItemSize must be at most half of maxPageSize.\");\n+        this.maxItemSize = maxItemSize;\n+        this.maxPageSize = maxPageSize;\n+        this.read = read;\n+        this.update = update;\n+        this.executor = executor;\n+        this.traceLogId = traceLogId == null ? \"\" : traceLogId;\n+    }\n+\n+    //endregion\n+\n+    //region Updates\n+\n+    /**\n+     * Atomically inserts the items in 'toInsert' into the {@link BTreeSet} and removes the items in 'toRemove'\n+     * from the {@link BTreeSet}. No duplicates are allowed; the same item cannot exist multiple times in either 'toInsert'\n+     * or 'toRemove' or in both of them.\n+     *\n+     * @param toInsert      (Optional). A Collection of {@link ArrayView} instances representing the items to insert.\n+     *                      If an item is already present, it will not be reinserted (updates are idempotent).\n+     * @param toRemove      (Optional). A Collection of {@link ArrayView} instances representing the items to remove.\n+     * @param getNextPageId A Supplier that, when invoked, will return a unique number representing the Id of the next\n+     *                      {@link BTreeSet} page that has to be generated.\n+     * @param timeout       Timeout for the operation.\n+     * @return A CompletableFuture that, when completed normally, will indicate that the updates have been applied\n+     * successfully. If the operation failed, the Future will be completed with the appropriate exception.\n+     */\n+    public CompletableFuture<Void> update(@Nullable Collection<? extends ArrayView> toInsert, @Nullable Collection<? extends ArrayView> toRemove,\n+                                          @NonNull Supplier<Long> getNextPageId, @NonNull Duration timeout) {\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        val updates = new ArrayList<UpdateItem>();\n+        int insertCount = collectUpdates(toInsert, false, updates);\n+        int removeCount = collectUpdates(toRemove, true, updates);\n+        updates.sort(UpdateItem::compareTo);\n+        log.debug(\"{}: Update (Insert={}, Remove={}).\", this.traceLogId, insertCount, removeCount);\n+        if (updates.isEmpty()) {\n+            // Nothing to do.\n+            return CompletableFuture.completedFuture(null);\n+        }\n+\n+        // The updates are sorted, so any empty items will be placed first.\n+        Preconditions.checkArgument(updates.get(0).getItem().getLength() > 0, \"No empty items allowed.\");\n+        return applyUpdates(updates.iterator(), timer)\n+                .thenApply(pageCollection -> processModifiedPages(pageCollection, getNextPageId))\n+                .thenComposeAsync(pageCollection -> writePages(pageCollection, timer), this.executor);\n+    }\n+\n+    private int collectUpdates(Collection<? extends ArrayView> items, boolean isRemoval, List<UpdateItem> updates) {\n+        if (items == null) {\n+            return 0;\n+        }\n+\n+        for (val i : items) {\n+            Preconditions.checkArgument(i.getLength() <= this.maxItemSize,\n+                    \"Item exceeds maximum allowed length (%s).\", this.maxItemSize);\n+            updates.add(new UpdateItem(i, isRemoval));\n+        }\n+        return items.size();\n+    }\n+\n+    private CompletableFuture<PageCollection> applyUpdates(Iterator<UpdateItem> items, TimeoutTimer timer) {\n+        val pageCollection = new PageCollection();\n+        val lastPage = new AtomicReference<BTreeSetPage.LeafPage>(null);\n+        val lastPageUpdates = new ArrayList<UpdateItem>();\n+        return Futures.loop(\n+                items::hasNext,\n+                () -> {\n+                    // Locate the page where the update is to be executed. Do not apply it yet as it is more efficient\n+                    // to bulk-apply multiple at once. Collect all updates for each Page, and only apply them once we have\n+                    // \"moved on\" to another page.\n+                    val next = items.next();\n+                    return locatePage(next.getItem(), pageCollection, timer)\n+                            .thenAccept(page -> {\n+                                val last = lastPage.get();\n+                                if (page != last) {\n+                                    // This key goes to a different page than the one we were looking at.\n+                                    if (last != null) {\n+                                        // Commit the outstanding updates.\n+                                        last.update(lastPageUpdates);\n+                                    }\n+\n+                                    // Update the pointers.\n+                                    lastPage.set(page);\n+                                    lastPageUpdates.clear();\n+                                }\n+\n+                                // Record the current update.\n+                                lastPageUpdates.add(next);\n+                            });\n+                },\n+                this.executor)\n+                .thenApplyAsync(v -> {\n+                    // We need not forget to apply the last batch of updates from the last page.\n+                    if (lastPage.get() != null) {\n+                        lastPage.get().update(lastPageUpdates);\n+                    }\n+                    return pageCollection;\n+                }, this.executor);\n+    }\n+\n+    private PageCollection processModifiedPages(PageCollection pageCollection, Supplier<Long> getNewPageId) {\n+        Collection<BTreeSetPage> candidates = pageCollection.getLeafPages();\n+        while (!candidates.isEmpty()) {\n+            // Process each candidate and determine if it should be deleted or split into multiple pages.\n+            val tmc = new TreeModificationContext(pageCollection);\n+            for (BTreeSetPage p : candidates) {\n+                if (p.getItemCount() == 0) {\n+                    deletePage(p, tmc);\n+                } else {\n+                    splitPageIfNecessary(p, getNewPageId, tmc);\n+                }\n+            }\n+\n+            // Update those pages' parents.\n+            tmc.accept(BTreeSetPage.IndexPage::addChildren, BTreeSetPage.IndexPage::removeChildren, POINTER_COMPARATOR);\n+            candidates = tmc.getModifiedParents();\n+        }\n+\n+        pageCollection.getIndexPages().forEach(p -> {\n+            if (p.isModified()) {\n+                p.seal();\n+            }\n+        });\n+        return pageCollection;\n+    }\n+\n+    private void deletePage(BTreeSetPage p, TreeModificationContext context) {\n+        // Delete the page if it's empty, but only if it's not the root page.\n+        if (p.getPagePointer().hasParent()) {\n+            context.getPageCollection().pageDeleted(p);\n+            context.deleted(p.getPagePointer());\n+            log.debug(\"{}: Deleted empty page {}.\", this.traceLogId, p.getPagePointer());\n+        } else if (p.isIndexPage()) {\n+            p = BTreeSetPage.emptyLeafRoot();\n+            p.markModified();\n+            context.getPageCollection().pageUpdated(p);\n+            log.debug(\"{}: Replaced empty Index Root with empty Leaf Root.\", this.traceLogId);\n+        }\n+    }\n+\n+    private void splitPageIfNecessary(BTreeSetPage p, Supplier<Long> getNewPageId, TreeModificationContext context) {\n+        val splits = p.split(this.maxPageSize, getNewPageId);\n+        if (splits == null) {\n+            // No split necessary\n+            return;\n+        }\n+\n+        if (p.getPagePointer().hasParent()) {\n+            Preconditions.checkArgument(splits.get(0).getPagePointer().getPageId() == p.getPagePointer().getPageId(),\n+                    \"First split result (%s) not current page (%s).\", splits.get(0).getPagePointer(), p.getPagePointer());\n+        } else {\n+            // If we split the root, the new pages will already point to the root; we must create a blank\n+            // index root page, which will be updated in the next step.\n+            context.getPageCollection().pageUpdated(BTreeSetPage.emptyIndexRoot());\n+        }\n+\n+        splits.forEach(splitPage -> {\n+            context.getPageCollection().pageUpdated(splitPage);\n+            context.created(splitPage.getPagePointer());\n+        });\n+        log.debug(\"{}: Page '{}' split into {}: {}.\", this.traceLogId, p, splits.size(), splits);\n+    }\n+\n+    private CompletableFuture<Void> writePages(@NonNull PageCollection pageCollection, TimeoutTimer timer) {\n+        // Order the pages from bottom up. The upstream code may have limitations in how much it can update atomically,\n+        // so it may commit this in multiple non-atomic operations. If the process is interrupted mid-way then we want\n+        // to ensure that parent pages aren't updated before leaf pages (which would cause index corruptions - i.e., by\n+        // pointing to inexistent pages).\n+        val processedPageIds = new HashSet<Long>();\n+\n+        // First collect updates. Begin from the bottom (Leaf Pages).\n+        val toWrite = new ArrayList<Map.Entry<Long, ArrayView>>();\n+        collectWriteCandidates(pageCollection.getLeafPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Newly split pages may not be reachable from any modified Leaf Pages. Collect them too.\n+        collectWriteCandidates(pageCollection.getIndexPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Then collect deletions, making sure we also consider all their parents (which should be modified/deleted as well).\n+        collectWriteCandidates(pageCollection.getDeletedPagesParents(), toWrite, processedPageIds, pageCollection);\n+        log.debug(\"{}: Persist (Updates={}, Deletions={}).\", this.traceLogId, toWrite.size(), pageCollection.getDeletedPageIds().size());\n+        return this.update.apply(toWrite, pageCollection.getDeletedPageIds(), timer.getRemaining());\n+    }\n+\n+    private void collectWriteCandidates(Collection<BTreeSetPage> candidates, List<Map.Entry<Long, ArrayView>> toWrite,\n+                                        Set<Long> processedIds, PageCollection pageCollection) {\n+        while (!candidates.isEmpty()) {\n+            val next = new ArrayList<BTreeSetPage>();\n+            candidates.stream()\n+                    .filter(p -> p.isModified() && !processedIds.contains(p.getPagePointer().getPageId()))\n+                    .forEach(p -> {\n+                        toWrite.add(new AbstractMap.SimpleImmutableEntry<>(p.getPagePointer().getPageId(), p.getData()));\n+                        val parent = pageCollection.get(p.getPagePointer().getParentPageId());\n+                        assert p.getPagePointer().hasParent() == (parent != null);\n+                        processedIds.add(p.getPagePointer().getPageId());\n+                        if (parent != null) {\n+                            next.add(parent);\n+                        }\n+                    });\n+            candidates = next;\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region Queries\n+\n+    /**\n+     * Returns an {@link AsyncIterator} that will iterate through all the items in this {@link BTreeSet} within the\n+     * specified bounds. All iterated items will be returned in lexicographic order (smallest to largest).\n+     * See {@link ByteArrayComparator} for ordering details.\n+     *\n+     * @param firstItem          An {@link ArrayView} indicating the first Item to iterate from. If null, the iteration\n+     *                           will begin with the first item in the index.\n+     * @param firstItemInclusive If true, firstIem will be included in the iteration (provided it exists), otherwise it", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgyOTg5Nw==", "bodyText": "There is probably something silly I'm missing, but they seem unnecessary, here is my reasoning:\n\nit should be always exclusive\nif the caller has the first item and wants it inclusive, then it can use the first item it already has.\nif the caller has the last item and wants it inclusive, then it can return the last item once there are no more items to read within the range of the iterator, then return the last one.\n\nWhat am I missing?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433829897", "createdAt": "2020-06-02T12:15:32Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSet.java", "diffHunk": "@@ -0,0 +1,414 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArrayComparator;\n+import java.time.Duration;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * A B+Tree-backed Set. Stores all items in a B+Tree Structure using a {@link ByteArrayComparator} for ordering them.\n+ *\n+ * NOTE: This component is in {@link Beta}. There are no guarantees about data or API compatibility with future versions.\n+ * Any component that is directly dependent on this one should either be in {@link Beta} as well.\n+ */\n+@NotThreadSafe\n+@Beta\n+@Slf4j\n+public class BTreeSet {\n+    //region Members\n+\n+    public static final Comparator<ArrayView> COMPARATOR = new ByteArrayComparator()::compare;\n+    private static final Comparator<PagePointer> POINTER_COMPARATOR = PagePointer.getComparator(COMPARATOR);\n+\n+    private final int maxPageSize;\n+    private final int maxItemSize;\n+    @NonNull\n+    private final ReadPage read;\n+    @NonNull\n+    private final PersistPages update;\n+    @NonNull\n+    private final Executor executor;\n+    @NonNull\n+    private final String traceLogId;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link BTreeSet} class.\n+     *\n+     * @param maxPageSize The maximum size, in bytes, of any page.\n+     * @param maxItemSize The maximum size, in bytes, of any single item in the {@link BTreeSet}.\n+     * @param read        A {@link ReadPage} function that can be used to fetch a single {@link BTreeSet} page from an\n+     *                    external data source.\n+     * @param update      A {@link PersistPages} function that can be used to store and delete multiple {@link BTreeSet}\n+     *                    pages to/from an external data source.\n+     * @param executor    Executor for async operations.\n+     * @param traceLogId  Trace id for logging.\n+     */\n+    public BTreeSet(int maxPageSize, int maxItemSize, @NonNull ReadPage read, @NonNull PersistPages update,\n+                    @NonNull Executor executor, String traceLogId) {\n+        Preconditions.checkArgument(maxItemSize < maxPageSize / 2, \"maxItemSize must be at most half of maxPageSize.\");\n+        this.maxItemSize = maxItemSize;\n+        this.maxPageSize = maxPageSize;\n+        this.read = read;\n+        this.update = update;\n+        this.executor = executor;\n+        this.traceLogId = traceLogId == null ? \"\" : traceLogId;\n+    }\n+\n+    //endregion\n+\n+    //region Updates\n+\n+    /**\n+     * Atomically inserts the items in 'toInsert' into the {@link BTreeSet} and removes the items in 'toRemove'\n+     * from the {@link BTreeSet}. No duplicates are allowed; the same item cannot exist multiple times in either 'toInsert'\n+     * or 'toRemove' or in both of them.\n+     *\n+     * @param toInsert      (Optional). A Collection of {@link ArrayView} instances representing the items to insert.\n+     *                      If an item is already present, it will not be reinserted (updates are idempotent).\n+     * @param toRemove      (Optional). A Collection of {@link ArrayView} instances representing the items to remove.\n+     * @param getNextPageId A Supplier that, when invoked, will return a unique number representing the Id of the next\n+     *                      {@link BTreeSet} page that has to be generated.\n+     * @param timeout       Timeout for the operation.\n+     * @return A CompletableFuture that, when completed normally, will indicate that the updates have been applied\n+     * successfully. If the operation failed, the Future will be completed with the appropriate exception.\n+     */\n+    public CompletableFuture<Void> update(@Nullable Collection<? extends ArrayView> toInsert, @Nullable Collection<? extends ArrayView> toRemove,\n+                                          @NonNull Supplier<Long> getNextPageId, @NonNull Duration timeout) {\n+        TimeoutTimer timer = new TimeoutTimer(timeout);\n+        val updates = new ArrayList<UpdateItem>();\n+        int insertCount = collectUpdates(toInsert, false, updates);\n+        int removeCount = collectUpdates(toRemove, true, updates);\n+        updates.sort(UpdateItem::compareTo);\n+        log.debug(\"{}: Update (Insert={}, Remove={}).\", this.traceLogId, insertCount, removeCount);\n+        if (updates.isEmpty()) {\n+            // Nothing to do.\n+            return CompletableFuture.completedFuture(null);\n+        }\n+\n+        // The updates are sorted, so any empty items will be placed first.\n+        Preconditions.checkArgument(updates.get(0).getItem().getLength() > 0, \"No empty items allowed.\");\n+        return applyUpdates(updates.iterator(), timer)\n+                .thenApply(pageCollection -> processModifiedPages(pageCollection, getNextPageId))\n+                .thenComposeAsync(pageCollection -> writePages(pageCollection, timer), this.executor);\n+    }\n+\n+    private int collectUpdates(Collection<? extends ArrayView> items, boolean isRemoval, List<UpdateItem> updates) {\n+        if (items == null) {\n+            return 0;\n+        }\n+\n+        for (val i : items) {\n+            Preconditions.checkArgument(i.getLength() <= this.maxItemSize,\n+                    \"Item exceeds maximum allowed length (%s).\", this.maxItemSize);\n+            updates.add(new UpdateItem(i, isRemoval));\n+        }\n+        return items.size();\n+    }\n+\n+    private CompletableFuture<PageCollection> applyUpdates(Iterator<UpdateItem> items, TimeoutTimer timer) {\n+        val pageCollection = new PageCollection();\n+        val lastPage = new AtomicReference<BTreeSetPage.LeafPage>(null);\n+        val lastPageUpdates = new ArrayList<UpdateItem>();\n+        return Futures.loop(\n+                items::hasNext,\n+                () -> {\n+                    // Locate the page where the update is to be executed. Do not apply it yet as it is more efficient\n+                    // to bulk-apply multiple at once. Collect all updates for each Page, and only apply them once we have\n+                    // \"moved on\" to another page.\n+                    val next = items.next();\n+                    return locatePage(next.getItem(), pageCollection, timer)\n+                            .thenAccept(page -> {\n+                                val last = lastPage.get();\n+                                if (page != last) {\n+                                    // This key goes to a different page than the one we were looking at.\n+                                    if (last != null) {\n+                                        // Commit the outstanding updates.\n+                                        last.update(lastPageUpdates);\n+                                    }\n+\n+                                    // Update the pointers.\n+                                    lastPage.set(page);\n+                                    lastPageUpdates.clear();\n+                                }\n+\n+                                // Record the current update.\n+                                lastPageUpdates.add(next);\n+                            });\n+                },\n+                this.executor)\n+                .thenApplyAsync(v -> {\n+                    // We need not forget to apply the last batch of updates from the last page.\n+                    if (lastPage.get() != null) {\n+                        lastPage.get().update(lastPageUpdates);\n+                    }\n+                    return pageCollection;\n+                }, this.executor);\n+    }\n+\n+    private PageCollection processModifiedPages(PageCollection pageCollection, Supplier<Long> getNewPageId) {\n+        Collection<BTreeSetPage> candidates = pageCollection.getLeafPages();\n+        while (!candidates.isEmpty()) {\n+            // Process each candidate and determine if it should be deleted or split into multiple pages.\n+            val tmc = new TreeModificationContext(pageCollection);\n+            for (BTreeSetPage p : candidates) {\n+                if (p.getItemCount() == 0) {\n+                    deletePage(p, tmc);\n+                } else {\n+                    splitPageIfNecessary(p, getNewPageId, tmc);\n+                }\n+            }\n+\n+            // Update those pages' parents.\n+            tmc.accept(BTreeSetPage.IndexPage::addChildren, BTreeSetPage.IndexPage::removeChildren, POINTER_COMPARATOR);\n+            candidates = tmc.getModifiedParents();\n+        }\n+\n+        pageCollection.getIndexPages().forEach(p -> {\n+            if (p.isModified()) {\n+                p.seal();\n+            }\n+        });\n+        return pageCollection;\n+    }\n+\n+    private void deletePage(BTreeSetPage p, TreeModificationContext context) {\n+        // Delete the page if it's empty, but only if it's not the root page.\n+        if (p.getPagePointer().hasParent()) {\n+            context.getPageCollection().pageDeleted(p);\n+            context.deleted(p.getPagePointer());\n+            log.debug(\"{}: Deleted empty page {}.\", this.traceLogId, p.getPagePointer());\n+        } else if (p.isIndexPage()) {\n+            p = BTreeSetPage.emptyLeafRoot();\n+            p.markModified();\n+            context.getPageCollection().pageUpdated(p);\n+            log.debug(\"{}: Replaced empty Index Root with empty Leaf Root.\", this.traceLogId);\n+        }\n+    }\n+\n+    private void splitPageIfNecessary(BTreeSetPage p, Supplier<Long> getNewPageId, TreeModificationContext context) {\n+        val splits = p.split(this.maxPageSize, getNewPageId);\n+        if (splits == null) {\n+            // No split necessary\n+            return;\n+        }\n+\n+        if (p.getPagePointer().hasParent()) {\n+            Preconditions.checkArgument(splits.get(0).getPagePointer().getPageId() == p.getPagePointer().getPageId(),\n+                    \"First split result (%s) not current page (%s).\", splits.get(0).getPagePointer(), p.getPagePointer());\n+        } else {\n+            // If we split the root, the new pages will already point to the root; we must create a blank\n+            // index root page, which will be updated in the next step.\n+            context.getPageCollection().pageUpdated(BTreeSetPage.emptyIndexRoot());\n+        }\n+\n+        splits.forEach(splitPage -> {\n+            context.getPageCollection().pageUpdated(splitPage);\n+            context.created(splitPage.getPagePointer());\n+        });\n+        log.debug(\"{}: Page '{}' split into {}: {}.\", this.traceLogId, p, splits.size(), splits);\n+    }\n+\n+    private CompletableFuture<Void> writePages(@NonNull PageCollection pageCollection, TimeoutTimer timer) {\n+        // Order the pages from bottom up. The upstream code may have limitations in how much it can update atomically,\n+        // so it may commit this in multiple non-atomic operations. If the process is interrupted mid-way then we want\n+        // to ensure that parent pages aren't updated before leaf pages (which would cause index corruptions - i.e., by\n+        // pointing to inexistent pages).\n+        val processedPageIds = new HashSet<Long>();\n+\n+        // First collect updates. Begin from the bottom (Leaf Pages).\n+        val toWrite = new ArrayList<Map.Entry<Long, ArrayView>>();\n+        collectWriteCandidates(pageCollection.getLeafPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Newly split pages may not be reachable from any modified Leaf Pages. Collect them too.\n+        collectWriteCandidates(pageCollection.getIndexPages(), toWrite, processedPageIds, pageCollection);\n+\n+        // Then collect deletions, making sure we also consider all their parents (which should be modified/deleted as well).\n+        collectWriteCandidates(pageCollection.getDeletedPagesParents(), toWrite, processedPageIds, pageCollection);\n+        log.debug(\"{}: Persist (Updates={}, Deletions={}).\", this.traceLogId, toWrite.size(), pageCollection.getDeletedPageIds().size());\n+        return this.update.apply(toWrite, pageCollection.getDeletedPageIds(), timer.getRemaining());\n+    }\n+\n+    private void collectWriteCandidates(Collection<BTreeSetPage> candidates, List<Map.Entry<Long, ArrayView>> toWrite,\n+                                        Set<Long> processedIds, PageCollection pageCollection) {\n+        while (!candidates.isEmpty()) {\n+            val next = new ArrayList<BTreeSetPage>();\n+            candidates.stream()\n+                    .filter(p -> p.isModified() && !processedIds.contains(p.getPagePointer().getPageId()))\n+                    .forEach(p -> {\n+                        toWrite.add(new AbstractMap.SimpleImmutableEntry<>(p.getPagePointer().getPageId(), p.getData()));\n+                        val parent = pageCollection.get(p.getPagePointer().getParentPageId());\n+                        assert p.getPagePointer().hasParent() == (parent != null);\n+                        processedIds.add(p.getPagePointer().getPageId());\n+                        if (parent != null) {\n+                            next.add(parent);\n+                        }\n+                    });\n+            candidates = next;\n+        }\n+    }\n+\n+    //endregion\n+\n+    //region Queries\n+\n+    /**\n+     * Returns an {@link AsyncIterator} that will iterate through all the items in this {@link BTreeSet} within the\n+     * specified bounds. All iterated items will be returned in lexicographic order (smallest to largest).\n+     * See {@link ByteArrayComparator} for ordering details.\n+     *\n+     * @param firstItem          An {@link ArrayView} indicating the first Item to iterate from. If null, the iteration\n+     *                           will begin with the first item in the index.\n+     * @param firstItemInclusive If true, firstIem will be included in the iteration (provided it exists), otherwise it", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjQ4NDI0MQ=="}, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgzMjUwMA==", "bodyText": "When it says \"No duplicates are allowed\", does it mean that a duplicate would cause the execution of the method to return an error? What happens if there is a duplicate in the collection?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433832500", "createdAt": "2020-06-02T12:20:31Z", "author": {"login": "fpj"}, "path": "common/src/main/java/io/pravega/common/util/btree/sets/BTreeSet.java", "diffHunk": "@@ -0,0 +1,414 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.common.util.btree.sets;\n+\n+import com.google.common.annotations.Beta;\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.TimeoutTimer;\n+import io.pravega.common.concurrent.Futures;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArrayComparator;\n+import java.time.Duration;\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+\n+/**\n+ * A B+Tree-backed Set. Stores all items in a B+Tree Structure using a {@link ByteArrayComparator} for ordering them.\n+ *\n+ * NOTE: This component is in {@link Beta}. There are no guarantees about data or API compatibility with future versions.\n+ * Any component that is directly dependent on this one should either be in {@link Beta} as well.\n+ */\n+@NotThreadSafe\n+@Beta\n+@Slf4j\n+public class BTreeSet {\n+    //region Members\n+\n+    public static final Comparator<ArrayView> COMPARATOR = new ByteArrayComparator()::compare;\n+    private static final Comparator<PagePointer> POINTER_COMPARATOR = PagePointer.getComparator(COMPARATOR);\n+\n+    private final int maxPageSize;\n+    private final int maxItemSize;\n+    @NonNull\n+    private final ReadPage read;\n+    @NonNull\n+    private final PersistPages update;\n+    @NonNull\n+    private final Executor executor;\n+    @NonNull\n+    private final String traceLogId;\n+\n+    //endregion\n+\n+    //region Constructor\n+\n+    /**\n+     * Creates a new instance of the {@link BTreeSet} class.\n+     *\n+     * @param maxPageSize The maximum size, in bytes, of any page.\n+     * @param maxItemSize The maximum size, in bytes, of any single item in the {@link BTreeSet}.\n+     * @param read        A {@link ReadPage} function that can be used to fetch a single {@link BTreeSet} page from an\n+     *                    external data source.\n+     * @param update      A {@link PersistPages} function that can be used to store and delete multiple {@link BTreeSet}\n+     *                    pages to/from an external data source.\n+     * @param executor    Executor for async operations.\n+     * @param traceLogId  Trace id for logging.\n+     */\n+    public BTreeSet(int maxPageSize, int maxItemSize, @NonNull ReadPage read, @NonNull PersistPages update,\n+                    @NonNull Executor executor, String traceLogId) {\n+        Preconditions.checkArgument(maxItemSize < maxPageSize / 2, \"maxItemSize must be at most half of maxPageSize.\");\n+        this.maxItemSize = maxItemSize;\n+        this.maxPageSize = maxPageSize;\n+        this.read = read;\n+        this.update = update;\n+        this.executor = executor;\n+        this.traceLogId = traceLogId == null ? \"\" : traceLogId;\n+    }\n+\n+    //endregion\n+\n+    //region Updates\n+\n+    /**\n+     * Atomically inserts the items in 'toInsert' into the {@link BTreeSet} and removes the items in 'toRemove'\n+     * from the {@link BTreeSet}. No duplicates are allowed; the same item cannot exist multiple times in either 'toInsert'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg2NDAwNg==", "bodyText": "To clarify, is it only the prefixFilter that is experimental? Basically, getpPrefixFilter returns an ArrayView that is not guaranteed to be correct? Do you know whether this is displayed correctly with javadocs (because of the @DaTa lombok annotation)?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433864006", "createdAt": "2020-06-02T13:13:40Z", "author": {"login": "fpj"}, "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/IteratorArgs.java", "diffHunk": "@@ -24,9 +24,11 @@\n @Builder\n public class IteratorArgs {\n     /**\n+     * EXPERIMENTAL!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg2NzcxMg==", "bodyText": "Do you want to add that this additional space is proportional to the number and length of keys, but not the size of the value?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433867712", "createdAt": "2020-06-02T13:19:16Z", "author": {"login": "fpj"}, "path": "segmentstore/contracts/src/main/java/io/pravega/segmentstore/contracts/tables/TableStore.java", "diffHunk": "@@ -41,8 +39,19 @@\n  * will be atomically checked-and-applied.\n  * * Unconditional Updates (insert, update, remove) will take effect regardless of what the current Key version exists in\n  * the Table Segment.\n+ *\n+ * Sorted vs Non-Sorted Table Segments:\n+ * * All Table Segments are a Hash-Table-like data structure, where Keys are mapped to Values.\n+ * * Non-Sorted Table Segments provide no ordering guarantees for {@link #keyIterator} or {@link #entryIterator}.\n+ * * Sorted Table Segments store additional information about the Keys and will return results for {@link #keyIterator}\n+ * or {@link #entryIterator} in lexicographic bitwise order. All other contracts are identical to the Non-Sorted variant.\n+ * * Sorted Table Segments will require additional storage space to store the ordered Keys and may require additional", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3MDc5OQ==", "bodyText": "This Future will wait on any Segment-specific recovery to complete before executing.\n\nThis is a good information to have, but it made me wonder if that's not true of any segment-related operation. Is there anything special about this call to get the sorted key index with respect to recovery?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433870799", "createdAt": "2020-06-02T13:23:42Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/ContainerKeyIndex.java", "diffHunk": "@@ -538,6 +546,25 @@ void notifyIndexOffsetChanged(long segmentId, long indexOffset) {\n                 ignored -> CompletableFuture.completedFuture(this.cache.getTailHashes(segment.getSegmentId())));\n     }\n \n+    /**\n+     * Gets the {@link SegmentSortedKeyIndex} associated with the given Segment, as provided by\n+     * {@link ContainerSortedKeyIndex#getSortedKeyIndex}. This can be used to safely iterate through Keys of a Sorted\n+     * Table Segment while including both fully indexed and tail updates.\n+     *\n+     * Note: this will return the same result as {@link ContainerSortedKeyIndex#getSortedKeyIndex}, however this method\n+     * will wait on any Segment-specific recovery (and trigger it) to complete before executing, which should enable a\n+     * safe iteration for recently recovered Table Segments.\n+     *\n+     * @param segment A {@link DirectSegmentAccess} representing the Segment for which to get the {@link SegmentSortedKeyIndex}.\n+     * @return A CompletableFuture that, when completed, will contain the desired result. This Future will wait on any", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3Mzg4NQ==", "bodyText": "I'm not sure what this notification is about, could you elaborate?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433873885", "createdAt": "2020-06-02T13:28:02Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/ContainerSortedKeyIndex.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.tables;\n+\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.tables.TableAttributes;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executor;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+\n+/**\n+ * Manages {@link SegmentSortedKeyIndex} instances.\n+ */\n+@RequiredArgsConstructor\n+class ContainerSortedKeyIndex {\n+    //region Members\n+\n+    private final ConcurrentHashMap<Long, SegmentSortedKeyIndex> sortedKeyIndices = new ConcurrentHashMap<>();\n+    @NonNull\n+    private final SortedKeyIndexDataSource dataSource;\n+    @NonNull\n+    private final Executor executor;\n+\n+    //endregion\n+\n+    //region Operations\n+\n+    /**\n+     * Determines whether the given {@link SegmentProperties} instance indicates the associated Table Segment is a sorted one.\n+     *\n+     * @param info The {@link SegmentProperties} to query.\n+     * @return True if Sorted Table Segment, false otherwise.\n+     */\n+    static boolean isSortedTableSegment(SegmentProperties info) {\n+        return info.getAttributes().getOrDefault(TableAttributes.SORTED, Attributes.BOOLEAN_FALSE) == Attributes.BOOLEAN_TRUE;\n+    }\n+\n+    /**\n+     * Gets a {@link SegmentSortedKeyIndex} instance for the given Segment. If there is no {@link SegmentSortedKeyIndex}\n+     * currently associated with the given segment, it will be associated (and the same instance will be returned later).\n+     *\n+     * @param segmentId   The Id of the Segment.\n+     * @param segmentInfo A {@link SegmentProperties} associated with the segment.\n+     * @return A {@link SegmentSortedKeyIndex} if segmentInfo indicates a Sorted Table Segment, or\n+     * {@link SegmentSortedKeyIndex#noop()} otherwise.\n+     */\n+    SegmentSortedKeyIndex getSortedKeyIndex(long segmentId, SegmentProperties segmentInfo) {\n+        if (isSortedTableSegment(segmentInfo)) {\n+            return this.sortedKeyIndices.computeIfAbsent(segmentId, id -> createSortedKeyIndex(segmentInfo.getName()));\n+        } else {\n+            // Not a Sorted Table Segment.\n+            return SegmentSortedKeyIndex.noop();\n+        }\n+    }\n+\n+    /**\n+     * Notifies that the indexed offset for a particular Segment Id has been changed.\n+     *\n+     * @param segmentId   The Segment Id whose indexed offset has changed.\n+     * @param indexOffset The new indexed offset. If -1, and if the given Segment is currently registered, it will be\n+     *                    de-registered (since -1 indicates it has been evicted).\n+     */\n+    void notifyIndexOffsetChanged(long segmentId, long indexOffset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3NjQyNA==", "bodyText": "What's this KeyTranslator about?", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433876424", "createdAt": "2020-06-02T13:31:32Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/main/java/io/pravega/segmentstore/server/tables/KeyTranslator.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.tables;\n+\n+import com.google.common.base.Preconditions;\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.segmentstore.contracts.tables.TableEntry;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import lombok.RequiredArgsConstructor;\n+\n+/**\n+ * Translates Table Segment Keys from an external form into an internal one and back.\n+ */\n+abstract class KeyTranslator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzg3ODU0Mw==", "bodyText": "Typo.", "url": "https://github.com/pravega/pravega/pull/4763#discussion_r433878543", "createdAt": "2020-06-02T13:34:28Z", "author": {"login": "fpj"}, "path": "segmentstore/server/src/test/java/io/pravega/segmentstore/server/tables/ContainerSortedKeyIndexTests.java", "diffHunk": "@@ -0,0 +1,392 @@\n+/**\n+ * Copyright (c) Dell Inc., or its subsidiaries. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ */\n+package io.pravega.segmentstore.server.tables;\n+\n+import io.pravega.common.util.ArrayView;\n+import io.pravega.common.util.AsyncIterator;\n+import io.pravega.common.util.ByteArraySegment;\n+import io.pravega.common.util.HashedArray;\n+import io.pravega.segmentstore.contracts.Attributes;\n+import io.pravega.segmentstore.contracts.SegmentProperties;\n+import io.pravega.segmentstore.contracts.StreamSegmentInformation;\n+import io.pravega.segmentstore.contracts.tables.TableAttributes;\n+import io.pravega.segmentstore.contracts.tables.TableKey;\n+import io.pravega.segmentstore.server.TableStoreMock;\n+import io.pravega.test.common.AssertExtensions;\n+import io.pravega.test.common.ThreadPooledTestSuite;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import lombok.RequiredArgsConstructor;\n+import lombok.val;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * Unit tess for {@link ContainerSortedKeyIndex} and {@link SegmentSortedKeyIndexImpl}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e23c68e3087386a7ba7090d86218ad916e2dabac"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a49f683a8fdfbca002bf902dc4aeaa304868035", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/7a49f683a8fdfbca002bf902dc4aeaa304868035", "committedDate": "2020-06-02T15:32:01Z", "message": "Javadoc.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc0512d0cc1e492407840516d5e80687c266868b", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/bc0512d0cc1e492407840516d5e80687c266868b", "committedDate": "2020-06-03T17:29:11Z", "message": "Javadoc.\n\nSigned-off-by: Andrei Paduroiu <andrei.paduroiu@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "98344ae86c94318e874fc6695d96892394e31ade", "author": {"user": {"login": "andreipaduroiu", "name": "Andrei Paduroiu"}}, "url": "https://github.com/pravega/pravega/commit/98344ae86c94318e874fc6695d96892394e31ade", "committedDate": "2020-06-03T19:51:03Z", "message": "Merge remote-tracking branch 'remotes/origin/feature-key-value-tables' into issue-4656-iterator-filters\n\n# Conflicts:\n#\tcommon/src/main/java/io/pravega/common/util/AsyncIterator.java"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDg5Njc3", "url": "https://github.com/pravega/pravega/pull/4763#pullrequestreview-425489677", "createdAt": "2020-06-05T17:29:32Z", "commit": {"oid": "98344ae86c94318e874fc6695d96892394e31ade"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3449, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}