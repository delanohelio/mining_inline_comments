{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyODMwNDA2", "number": 5289, "title": "Issue 5111: Consumption based retention policy implementation", "bodyText": "Change log description\nImplements consumption based retention policy.\nPurpose of the change\nFixes #5111\nWhat the code does\nThis does two things primarily -\n\nIn Stream Metadata Tasks it consolidates and computes lower bound on subscriber streamcuts and truncates at the said stream cut. This also applies time/size bounds\nIn stream cut validation in stream metadata store, we assumed stream cuts to be made of non overlapping segments, but a stream cut could have future segments which may not have been read from. These are represented using \"-1\" as the offset. So we update the logic in stream metadata store for validation as well as size computations for streamcuts.\n\nHow to verify it\nUnit tests added.", "createdAt": "2020-10-30T08:10:47Z", "url": "https://github.com/pravega/pravega/pull/5289", "merged": true, "mergeCommit": {"oid": "d4bdbd06812ffca15fc8e21327d258ee6b3e2d2c"}, "closed": true, "closedAt": "2020-11-18T06:13:03Z", "author": {"login": "shiveshr"}, "timelineItems": {"totalCount": 116, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdbH9FngFqTUyNzEyMzU4OQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABddzX1jAFqTUzMzgwNTcyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MTIzNTg5", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-527123589", "createdAt": "2020-11-10T11:48:59Z", "commit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMTo0OTowMFrOHwY-Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMTo0OTowMFrOHwY-Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUwMjgzNQ==", "bodyText": "Using updateStream() API when a user tries to switch the Retention Policy for an existing Stream( Stream created prior to 0.9) from non-CBR to CBR, we need to invoke createSubscribersRecordIfAbsent to make sure the SubscribersSet Record is created in the Stream metadata table. Without this add/createSubscriber would fail for existing Streams.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r520502835", "createdAt": "2020-11-10T11:49:00Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -78,18 +79,23 @@\n import io.pravega.shared.protocol.netty.WireCommands;\n import java.io.Serializable;\n import java.time.Duration;\n+import java.util.AbstractMap;\n import java.util.ArrayList;\n import java.util.Comparator;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Optional;\n import java.util.Set;\n+import java.util.TreeMap;\n import java.util.UUID;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionException;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicBoolean;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MTQwMjMz", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-527140233", "createdAt": "2020-11-10T12:12:41Z", "commit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjoxMjo0MlrOHwZwcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMjoxMjo0MlrOHwZwcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDUxNTY5Ng==", "bodyText": "incomplete comment.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r520515696", "createdAt": "2020-11-10T12:12:42Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -507,32 +514,283 @@ public void initializeStreamWriters(final EventStreamClientFactory clientFactory\n \n     private CompletableFuture<Void> truncate(String scope, String stream, RetentionPolicy policy, OperationContext context,\n                                              RetentionSet retentionSet, StreamCutRecord newRecord, long recordingTime, long requestId) {\n-        Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n-        if (!truncationRecord.isPresent()) {\n-            log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n-            return CompletableFuture.completedFuture(null);\n+        if (policy.getRetentionType().equals(RetentionPolicy.RetentionType.CONSUMPTION)) {\n+            return subscriberBasedTruncation(scope, stream, context, policy, retentionSet, newRecord, requestId);\n+        } else {\n+            Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n+            if (!truncationRecord.isPresent()) {\n+                log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n+                    truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n+\n+            return truncate(scope, stream, context, requestId, truncationRecord.get());\n         }\n+    }\n+\n+    private CompletableFuture<Void> truncate(String scope, String stream, OperationContext context, long requestId,\n+                                                   StreamCutReferenceRecord truncationRecord) {\n         log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n-                truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n-        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord.get(), context, executor)\n-                   .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n-                   .thenCompose(started -> {\n-                       if (started) {\n-                                return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord.get(), context, executor);\n+                truncationRecord.getRecordingTime(), truncationRecord.getRecordingSize());\n+        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord, context, executor)\n+                                  .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n+                                  .thenCompose(started -> {\n+                                      if (started) {\n+                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord, context, executor);\n+                                      } else {\n+                                          throw new RuntimeException(\"Could not start truncation\");\n+                                      }\n+                                  })\n+                                  .exceptionally(e -> {\n+                                      if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n+                                          // This is ignorable exception. Throwing this will cause unnecessary retries and exceptions logged.\n+                                          log.debug(requestId, \"Cannot truncate at given \" +\n+                                                  \"streamCut because it intersects with existing truncation point\");\n+                                          return null;\n+                                      } else {\n+                                          throw new CompletionException(e);\n+                                      }\n+                                  });\n+    }\n+\n+    private CompletableFuture<Void> subscriberBasedTruncation(String scope, String stream, OperationContext context,\n+                                                              RetentionPolicy policy, RetentionSet retentionSet, \n+                                                              StreamCutRecord newRecord, long requestId) {\n+        return streamMetadataStore.listSubscribers(scope, stream, context, executor)\n+                           .thenCompose(list -> Futures.allOfWithResults(list.stream().map(x -> \n+                                   streamMetadataStore.getSubscriber(scope, stream, x, context, executor)).collect(Collectors.toList())))\n+                           .thenCompose(subscribers -> {\n+                               // if the range for which we are looking at is ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "originalPosition": 110}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI4MDEzODAy", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-528013802", "createdAt": "2020-11-11T09:43:39Z", "commit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwOTo0MzozOVrOHxFsNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDo0NToxOFrOHxH2Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTIzNTUxMQ==", "bodyText": "uncomment the timeout.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r521235511", "createdAt": "2020-11-11T09:43:39Z", "author": {"login": "shrids"}, "path": "controller/src/test/java/io/pravega/controller/store/stream/StreamTestBase.java", "diffHunk": "@@ -688,7 +688,7 @@ public void segmentQueriesDuringRollingTxn() {\n         stream.completeCommittingTransactions(ctr).join();\n     }\n \n-    @Test(timeout = 30000L)\n+    @Test//(timeout = 30000L)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI3MDc5OA==", "bodyText": "Q: We can use the getCreationEpoch() here right?", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r521270798", "createdAt": "2020-11-11T10:45:18Z", "author": {"login": "shrids"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -507,32 +514,283 @@ public void initializeStreamWriters(final EventStreamClientFactory clientFactory\n \n     private CompletableFuture<Void> truncate(String scope, String stream, RetentionPolicy policy, OperationContext context,\n                                              RetentionSet retentionSet, StreamCutRecord newRecord, long recordingTime, long requestId) {\n-        Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n-        if (!truncationRecord.isPresent()) {\n-            log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n-            return CompletableFuture.completedFuture(null);\n+        if (policy.getRetentionType().equals(RetentionPolicy.RetentionType.CONSUMPTION)) {\n+            return subscriberBasedTruncation(scope, stream, context, policy, retentionSet, newRecord, requestId);\n+        } else {\n+            Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n+            if (!truncationRecord.isPresent()) {\n+                log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n+                    truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n+\n+            return truncate(scope, stream, context, requestId, truncationRecord.get());\n         }\n+    }\n+\n+    private CompletableFuture<Void> truncate(String scope, String stream, OperationContext context, long requestId,\n+                                                   StreamCutReferenceRecord truncationRecord) {\n         log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n-                truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n-        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord.get(), context, executor)\n-                   .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n-                   .thenCompose(started -> {\n-                       if (started) {\n-                                return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord.get(), context, executor);\n+                truncationRecord.getRecordingTime(), truncationRecord.getRecordingSize());\n+        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord, context, executor)\n+                                  .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n+                                  .thenCompose(started -> {\n+                                      if (started) {\n+                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord, context, executor);\n+                                      } else {\n+                                          throw new RuntimeException(\"Could not start truncation\");\n+                                      }\n+                                  })\n+                                  .exceptionally(e -> {\n+                                      if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n+                                          // This is ignorable exception. Throwing this will cause unnecessary retries and exceptions logged.\n+                                          log.debug(requestId, \"Cannot truncate at given \" +\n+                                                  \"streamCut because it intersects with existing truncation point\");\n+                                          return null;\n+                                      } else {\n+                                          throw new CompletionException(e);\n+                                      }\n+                                  });\n+    }\n+\n+    private CompletableFuture<Void> subscriberBasedTruncation(String scope, String stream, OperationContext context,\n+                                                              RetentionPolicy policy, RetentionSet retentionSet, \n+                                                              StreamCutRecord newRecord, long requestId) {\n+        return streamMetadataStore.listSubscribers(scope, stream, context, executor)\n+                           .thenCompose(list -> Futures.allOfWithResults(list.stream().map(x -> \n+                                   streamMetadataStore.getSubscriber(scope, stream, x, context, executor)).collect(Collectors.toList())))\n+                           .thenCompose(subscribers -> {\n+                               // if the range for which we are looking at is \n+                               return Futures.allOfWithResults(subscribers.stream().map(x -> {\n+                                   ImmutableSet<Map.Entry<Long, Long>> entries = x.getObject().getTruncationStreamCut().entrySet();\n+\n+                                   return Futures.keysAllOfWithResults(entries.stream().collect(Collectors.toMap(\n+                                           y -> streamMetadataStore.getSegment(scope, stream, y.getKey(), context, executor), Map.Entry::getValue)));\n+                               }).collect(Collectors.toList()));\n+                           })\n+                           .thenApply(this::computeSubscribersLowerBound)\n+                .thenCompose(lowerBound -> {\n+                    CompletableFuture<Map<Long, Long>> toTruncateAt; \n+                    if (policy.getConsumptionLimits().getType().equals(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES)) {\n+                        toTruncateAt = getTruncationStreamCutBySizeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    } else {\n+                        toTruncateAt = getTruncationStreamCutByTimeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    }\n+                    return toTruncateAt.thenCompose(truncationStreamCut -> {\n+                        if (truncationStreamCut == null || truncationStreamCut.isEmpty()) {\n+                            log.debug(\"no truncation record could be compute that satisfied retention policy\");\n+                            return CompletableFuture.completedFuture(null);\n+                        } \n+                        return startTruncation(scope, stream, truncationStreamCut, context, requestId)\n+                                .thenCompose(started -> {\n+                                    if (started) {\n+                                        return streamMetadataStore.findStreamCutReferenceRecordBefore(scope, stream, truncationStreamCut, retentionSet, context, executor)\n+                                                                  .thenCompose(ref -> {\n+                                                                      if (ref != null) {\n+                                                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, ref, context, executor);\n+                                                                      } else {\n+                                                                          return CompletableFuture.completedFuture(null);\n+                                                                      }\n+                                                                  });\n+                                    } else {\n+                                        throw new RuntimeException(\"Could not start truncation\");\n+                                    }\n+                                });\n+                    });\n+                });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutBySizeLimit(String scope, String stream, OperationContext context, RetentionPolicy policy,\n+                                                                                 RetentionSet retentionSet, Map<Long, Long> lowerBound, StreamCutRecord newRecord) {\n+        // if the lowerbound on subscribers streamcuts satisfies the policy size bound, then return it. \n+        // else return the stream cut that satisfies maximum bound on size. \n+        long currentSize = newRecord != null ? newRecord.getRecordingSize() : retentionSet.getLatest().getRecordingSize();\n+        return streamMetadataStore.getSizeTillStreamCut(scope, stream, lowerBound, Optional.empty(), context, executor)\n+                          .thenCompose(sizeTill -> {\n+                               long retainedSize = currentSize - sizeTill;\n+                               Supplier<Optional<StreamCutReferenceRecord>> maxBound = () -> retentionSet\n+                                      .getRetentionRecords().stream()\n+                                      .filter(x -> currentSize - x.getRecordingSize() > policy.getConsumptionLimits().getMaxValue())\n+                                      .max(Comparator.comparingLong(StreamCutReferenceRecord::getRecordingTime));\n+\n+                               // if retainedSize is less than min size then do not truncate the stream. \n+                               if (retainedSize < policy.getConsumptionLimits().getMinValue()) {\n+                                   return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                                               .thenApply(StreamCutRecord::getStreamCut))\n+                                                  .orElse(CompletableFuture.completedFuture(null));\n+                               } else {\n+                                   // if retained size is less than max allowed, then truncate the stream at subscriber lower bound. \n+                                   if (retainedSize < policy.getConsumptionLimits().getMaxValue()) {\n+                                       return CompletableFuture.completedFuture(lowerBound);\n+                                   } else {\n+                                       // if retained size is greater than max allowed, then truncate the stream at streamcut\n+                                       // from retention set that matches the retention policy size bound. \n+                                       return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                   .thenApply(StreamCutRecord::getStreamCut)\n+                                                   .thenCompose(maxRecord -> {\n+                                                       // if max record is strictly greater than lowerbound then we can truncate at max record\n+                                                       return streamMetadataStore.streamCutStrictlyGreaterThan(\n+                                                               scope, stream, maxRecord, lowerBound, context, executor)\n+                                                                                 .thenApply(gt -> {\n+                                                                                     if (gt) {\n+                                                                                         return maxRecord;\n+                                                                                     } else {\n+                                                                                         return lowerBound;\n+                                                                                     }\n+                                                                                 });\n+                                                   })).orElse(CompletableFuture.completedFuture(null));   \n+                                   }\n+                               }\n+                           });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutByTimeLimit(String scope, String stream, OperationContext context,\n+                                                                                 RetentionPolicy policy, RetentionSet retentionSet,\n+                                                                                 Map<Long, Long> lowerBound, StreamCutRecord latest) {\n+        Map.Entry<StreamCutReferenceRecord, StreamCutReferenceRecord> limits =\n+                getBoundStreamCuts(policy.getConsumptionLimits(), retentionSet, latest);\n+        // if subscriber lowerbound is ahead of streamcut corresponding to the max time and is behind stream cut for min time \n+        // from the retention set then we can safely truncate at lowerbound. Else we will truncate at the max time bound if it\n+        // exists\n+        CompletableFuture<StreamCutRecord> limitMaxFuture = limits.getKey() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getKey(), context, executor);\n+        CompletableFuture<StreamCutRecord> limitMinFuture = limits.getValue() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getValue(), context, executor);\n+        return CompletableFuture.allOf(limitMaxFuture, limitMinFuture)\n+                         .thenCompose(v -> {\n+                             StreamCutRecord limitMax = limitMaxFuture.join();\n+                             StreamCutRecord limitMin = limitMinFuture.join();\n+                             if (limitMin != null) {\n+                                 return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMin.getStreamCut(), lowerBound, context, executor)\n+                                                    .thenCompose(gtMin -> {\n+                                                        if (gtMin) {\n+                                                            if (limitMax == null) {\n+                                                                return CompletableFuture.completedFuture(lowerBound);\n+                                                            } else {\n+                                                                return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMax.getStreamCut(), lowerBound, context, executor)\n+                                                                                          .thenApply(gtMax -> gtMax ? limitMax.getStreamCut() : lowerBound);\n+                                                            }\n+                                                        } else {\n+                                                            return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, lowerBound, limitMin.getStreamCut(), context, executor)\n+                                                                               .thenApply(gt -> gt ? limitMin.getStreamCut() : null);\n+                                                        }\n+                                                    });\n+                             } else {\n+                                return CompletableFuture.completedFuture(null);  \n+                             }\n+                         });\n+    }\n+\n+    private Map<Long, Long> computeSubscribersLowerBound(List<Map<StreamSegmentRecord, Long>> subscribers) {\n+        // loop over all streamcuts and for each segment in new streamcut: \n+        // if new segment is predecessor of any segment in the bound then replace the successor segment with\n+        // this segment. \n+        Map<StreamSegmentRecord, Long> lowerBound = new HashMap<>();\n+        subscribers.forEach(streamCut -> streamCut.forEach((segment, offset) -> {\n+            if (lowerBound.containsKey(segment)) {\n+                if (lowerBound.get(segment) > offset) {\n+                    lowerBound.put(segment, offset);\n+                }\n+            } else {\n+                Map<StreamSegmentRecord, Long> predecessors = new HashMap<>();\n+                Map<StreamSegmentRecord, Long> successors = new HashMap<>();\n+                lowerBound.forEach((s, o) -> {\n+                    if (s.overlaps(segment)) {\n+                        if (s.segmentId() < segment.segmentId()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "originalPosition": 246}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/bd7badf9bd8d1dd457baf8014f4716b0b468f61c", "committedDate": "2020-11-11T13:48:51Z", "message": "serialize retention policy cbr consumption limits\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5MDM0MTg0", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-529034184", "createdAt": "2020-11-12T12:23:28Z", "commit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjoyMzoyOVrOHx4aAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjozODowMFrOHx45sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA2NjQzMg==", "bodyText": "With this the SubscribersSet record gets added only when updateStream() is invoked.\nHowever,  if the client tries to addSubscriber() to a Stream, without changing the retention policy using updateStream, it will lead to an exception.\nPerhaps it may be good to add createSubscribersRecordIfAbsent() here:\nhttps://github.com/pravega/pravega/blob/master/controller/src/main/java/io/pravega/controller/store/stream/AbstractStreamMetadataStore.java#L528", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r522066432", "createdAt": "2020-11-12T12:23:29Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/PersistentStreamBase.java", "diffHunk": "@@ -250,7 +351,8 @@ private boolean greaterThan(Map<Long, Long> cut1, Map<StreamSegmentRecord, Integ\n      */\n     @Override\n     public CompletableFuture<Void> startUpdateConfiguration(final StreamConfiguration newConfiguration) {\n-        return getVersionedConfigurationRecord()\n+        return createSubscribersRecordIfAbsent()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3NDU0NQ==", "bodyText": "Instead of re-implementing binarySearch could we use Collections.binarySearch() ?", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r522074545", "createdAt": "2020-11-12T12:38:00Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/PersistentStreamBase.java", "diffHunk": "@@ -242,6 +248,101 @@ private boolean greaterThan(Map<Long, Long> cut1, Map<StreamSegmentRecord, Integ\n                 });\n     }\n \n+    @Override\n+    public CompletableFuture<Boolean> isStreamCutStrictlyGreaterThan(Map<Long, Long> streamcut1, Map<Long, Long> streamcut2) {\n+        CompletableFuture<ImmutableMap<StreamSegmentRecord, Integer>> span1Future = computeStreamCutSpan(streamcut1);\n+        CompletableFuture<ImmutableMap<StreamSegmentRecord, Integer>> span2Future = computeStreamCutSpan(streamcut2);\n+        return CompletableFuture.allOf(span1Future, span2Future)\n+                    .thenApply(v -> {\n+                        ImmutableMap<StreamSegmentRecord, Integer> span1 = span1Future.join();\n+                        ImmutableMap<StreamSegmentRecord, Integer> span2 = span2Future.join();\n+                        return greaterThan(streamcut1, span1, streamcut2, span2);\n+                    });\n+    }\n+\n+    @Override\n+    public CompletableFuture<StreamCutReferenceRecord> findStreamCutReferenceRecordBefore(Map<Long, Long> streamCut, RetentionSet retentionSet) {\n+        Map<Set<Long>, ImmutableMap<StreamSegmentRecord, Integer>> fetched = new HashMap<>();\n+        int size = retentionSet.getRetentionRecords().size();\n+\n+        if (retentionSet.getRetentionRecords().isEmpty()) {\n+            return CompletableFuture.completedFuture(null);\n+        }\n+        return computeStreamCutSpan(streamCut)\n+                .thenCompose(span1 -> {\n+                    fetched.put(streamCut.keySet(), span1);\n+                    BiFunction<StreamCutReferenceRecord, Boolean, CompletableFuture<Integer>> fn = (refRecord, comparison) -> {\n+                        return getStreamCutRecord(refRecord)\n+                                .thenCompose(record -> {\n+                                    if (record.getStreamCut().equals(streamCut)) {\n+                                        return CompletableFuture.completedFuture(0);\n+                                    }\n+                                    ImmutableMap<StreamSegmentRecord, Integer> sc = fetched.get(record.getStreamCut().keySet());\n+                                    CompletableFuture<ImmutableMap<StreamSegmentRecord, Integer>> future;\n+                                    if (sc != null) {\n+                                        future = CompletableFuture.completedFuture(sc);\n+                                    } else {\n+                                        future = computeStreamCutSpan(record.getStreamCut())\n+                                                .thenApply(span2 -> {\n+                                                    fetched.put(record.getStreamCut().keySet(), span2);\n+                                                    return span2;\n+                                                });\n+                                    }\n+                                    return future.thenApply(span2 -> {\n+                                        boolean compare = comparison ? greaterThan(streamCut, span1, record.getStreamCut(), span2) :\n+                                                greaterThan(record.getStreamCut(), span2, streamCut, span1);\n+                                        if (compare) {\n+                                            return 1;\n+                                        } else {\n+                                            return -1;\n+                                        }\n+                                    });\n+                                });\n+                    };\n+\n+                    // binary search retention set. \n+                    return binarySearch(0, size, index -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI5MDUwMTMy", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-529050132", "createdAt": "2020-11-12T12:44:37Z", "commit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo0NDozN1rOHx5Iwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQxMjo0NjoxNFrOHx5MjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3ODQwMg==", "bodyText": "Do these tests cover all cases listed here:\n\n  \n    \n      pravega/controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java\n    \n    \n         Line 608\n      in\n      bd7badf\n    \n    \n    \n    \n\n        \n          \n           // 1. if lowerbound.size < max and lowerbound.size > min truncate at lowerbound", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r522078402", "createdAt": "2020-11-12T12:44:37Z", "author": {"login": "pbelgundi"}, "path": "controller/src/test/java/io/pravega/controller/task/Stream/StreamMetadataTasksTest.java", "diffHunk": "@@ -1020,6 +1021,446 @@ public void sizeBasedRetentionStreamTest() throws Exception {\n         // endregion\n         // endregion\n     }\n+    \n+    @Test(timeout = 30000)\n+    public void consumptionBasedRetentionSizeLimitTest() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3ODgzNg==", "bodyText": "Do these tests cover all cases listed here:\n\n  \n    \n      pravega/controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java\n    \n    \n         Line 659\n      in\n      bd7badf\n    \n    \n    \n    \n\n        \n          \n           // 1. if LB > min => truncate at min", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r522078836", "createdAt": "2020-11-12T12:45:19Z", "author": {"login": "pbelgundi"}, "path": "controller/src/test/java/io/pravega/controller/task/Stream/StreamMetadataTasksTest.java", "diffHunk": "@@ -1020,6 +1021,446 @@ public void sizeBasedRetentionStreamTest() throws Exception {\n         // endregion\n         // endregion\n     }\n+    \n+    @Test(timeout = 30000)\n+    public void consumptionBasedRetentionSizeLimitTest() throws Exception {\n+        final ScalingPolicy policy = ScalingPolicy.fixed(2);\n+        final RetentionPolicy retentionPolicy = RetentionPolicy.byConsumption(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES, 2L, 10L);\n+\n+        String stream1 = \"consumptionSize\";\n+        final StreamConfiguration configuration = StreamConfiguration.builder().scalingPolicy(policy)\n+                .retentionPolicy(retentionPolicy).build();\n+\n+        streamStorePartialMock.createStream(SCOPE, stream1, configuration, System.currentTimeMillis(), null, executor).get();\n+        streamStorePartialMock.setState(SCOPE, stream1, State.ACTIVE, null, executor).get();\n+\n+        assertNotEquals(0, consumer.getCurrentSegments(SCOPE, stream1).get().size());\n+        WriterMock requestEventWriter = new WriterMock(streamMetadataTasks, executor);\n+        streamMetadataTasks.setRequestEventWriter(requestEventWriter);\n+        streamMetadataTasks.setRetentionFrequencyMillis(1L);\n+        // region case 1: basic retention\n+        // add subscriber 1\n+        // add subscriber 2\n+        String subscriber1 = \"subscriber1\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber1, null).join();\n+\n+        String subscriber2 = \"subscriber2\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber2, null).join();\n+        \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 2L, 1L, 1L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 1L, 1L, 2L), null).join();\n+\n+        Map<Long, Long> map1 = new HashMap<>();\n+        map1.put(0L, 2L);\n+        map1.put(1L, 2L);\n+        long size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(1L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // call retention and verify that retention policy applies\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 1L, null, \"\").join();\n+        // now retention set has one stream cut 0/2, 1/2\n+        // subscriber lowerbound is 0/1, 1/1.. trucation should happen at lowerbound\n+\n+        VersionedMetadata<StreamTruncationRecord> truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 1L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 1L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 2 min policy check\n+        // we will update the new streamcut to 0/10, 1/10\n+        map1.put(0L, 2L);\n+        map1.put(1L, 2L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(20L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 2L, 1L, 2L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 2L, 1L, 2L), null).join();\n+\n+        // no new truncation should happen. \n+        // verify that truncation record has not changed. \n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 20L, null, \"\").join();\n+        // now retention set has two stream cut 0/2, 1/2...0/2, 1/2\n+        // subscriber lowerbound is 0/2, 1/2.. does not meet min bound criteria. we also do not have a max that satisfies the limit. no truncation should happen. \n+        // no change:\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 1L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 1L);\n+        assertFalse(truncationRecord.getObject().isUpdating());\n+        // endregion\n+        \n+        // region case 3: min criteria not met on lower bound. truncate at max. \n+        map1.put(0L, 10L);\n+        map1.put(1L, 10L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(30L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 10L, 1L, 9L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 10L, 1L, 9L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 30L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10\n+        // subscriber lowerbound is 0/10, 1/9.. does not meet min bound criteria. but we have max bound on truncation record\n+        // truncation should happen at 0/2, 1/2\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 2L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 2L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 4: lowerbound behind max\n+        // now move the stream further ahead so that max truncation limit is crossed but lowerbound is behind max. \n+        map1.put(0L, 20L);\n+        map1.put(1L, 20L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(40L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+        \n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 40L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10.. 0/20, 1/20\n+        // subscriber lowerbound is 0/10, 1/9.. meets min bound criteria. but we have max bound on truncation record\n+        // truncation should happen at 0/10, 1/10\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 10L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 10L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+\n+        // region case 5: lowerbound overlaps with max\n+        map1.put(0L, 30L);\n+        map1.put(1L, 30L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(50L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 21L, 1L, 19L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 21L, 1L, 19L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 50L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10.. 0/20, 1/20.. 0/30, 1/30\n+        // subscriber lowerbound is 0/21, 1/19.. meets min bound criteria. and its also greater than max bound. but it overlaps with max bound. \n+        // truncation should happen at 0/21, 1/19\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 21L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 19L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+    }\n+    \n+    @Test(timeout = 30000)\n+    public void consumptionBasedRetentionTimeLimitTest() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA3OTM3Mg==", "bodyText": "We need to add tests to cover the following corner cases:\n\nCBR Retention Policy does not specify any max/min limit (so they are at their default values)\nStream does not have any subscribers (# of subscribers = 0 and/or no subscriber has a valid StreamCut... there have been addSubscriber() calls but no updateSubscriberStreamCut() calls so far)\nStream has few subscribers with empty StreamCuts (StreamCuts have not been updated from client so far)", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r522079372", "createdAt": "2020-11-12T12:46:14Z", "author": {"login": "pbelgundi"}, "path": "controller/src/test/java/io/pravega/controller/task/Stream/StreamMetadataTasksTest.java", "diffHunk": "@@ -1020,6 +1021,446 @@ public void sizeBasedRetentionStreamTest() throws Exception {\n         // endregion\n         // endregion\n     }\n+    \n+    @Test(timeout = 30000)\n+    public void consumptionBasedRetentionSizeLimitTest() throws Exception {\n+        final ScalingPolicy policy = ScalingPolicy.fixed(2);\n+        final RetentionPolicy retentionPolicy = RetentionPolicy.byConsumption(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES, 2L, 10L);\n+\n+        String stream1 = \"consumptionSize\";\n+        final StreamConfiguration configuration = StreamConfiguration.builder().scalingPolicy(policy)\n+                .retentionPolicy(retentionPolicy).build();\n+\n+        streamStorePartialMock.createStream(SCOPE, stream1, configuration, System.currentTimeMillis(), null, executor).get();\n+        streamStorePartialMock.setState(SCOPE, stream1, State.ACTIVE, null, executor).get();\n+\n+        assertNotEquals(0, consumer.getCurrentSegments(SCOPE, stream1).get().size());\n+        WriterMock requestEventWriter = new WriterMock(streamMetadataTasks, executor);\n+        streamMetadataTasks.setRequestEventWriter(requestEventWriter);\n+        streamMetadataTasks.setRetentionFrequencyMillis(1L);\n+        // region case 1: basic retention\n+        // add subscriber 1\n+        // add subscriber 2\n+        String subscriber1 = \"subscriber1\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber1, null).join();\n+\n+        String subscriber2 = \"subscriber2\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber2, null).join();\n+        \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 2L, 1L, 1L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 1L, 1L, 2L), null).join();\n+\n+        Map<Long, Long> map1 = new HashMap<>();\n+        map1.put(0L, 2L);\n+        map1.put(1L, 2L);\n+        long size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(1L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // call retention and verify that retention policy applies\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 1L, null, \"\").join();\n+        // now retention set has one stream cut 0/2, 1/2\n+        // subscriber lowerbound is 0/1, 1/1.. trucation should happen at lowerbound\n+\n+        VersionedMetadata<StreamTruncationRecord> truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 1L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 1L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 2 min policy check\n+        // we will update the new streamcut to 0/10, 1/10\n+        map1.put(0L, 2L);\n+        map1.put(1L, 2L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(20L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 2L, 1L, 2L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 2L, 1L, 2L), null).join();\n+\n+        // no new truncation should happen. \n+        // verify that truncation record has not changed. \n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 20L, null, \"\").join();\n+        // now retention set has two stream cut 0/2, 1/2...0/2, 1/2\n+        // subscriber lowerbound is 0/2, 1/2.. does not meet min bound criteria. we also do not have a max that satisfies the limit. no truncation should happen. \n+        // no change:\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 1L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 1L);\n+        assertFalse(truncationRecord.getObject().isUpdating());\n+        // endregion\n+        \n+        // region case 3: min criteria not met on lower bound. truncate at max. \n+        map1.put(0L, 10L);\n+        map1.put(1L, 10L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(30L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 10L, 1L, 9L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 10L, 1L, 9L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 30L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10\n+        // subscriber lowerbound is 0/10, 1/9.. does not meet min bound criteria. but we have max bound on truncation record\n+        // truncation should happen at 0/2, 1/2\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 2L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 2L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 4: lowerbound behind max\n+        // now move the stream further ahead so that max truncation limit is crossed but lowerbound is behind max. \n+        map1.put(0L, 20L);\n+        map1.put(1L, 20L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(40L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+        \n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 40L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10.. 0/20, 1/20\n+        // subscriber lowerbound is 0/10, 1/9.. meets min bound criteria. but we have max bound on truncation record\n+        // truncation should happen at 0/10, 1/10\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 10L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 10L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+\n+        // region case 5: lowerbound overlaps with max\n+        map1.put(0L, 30L);\n+        map1.put(1L, 30L);\n+        size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(50L, size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 21L, 1L, 19L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 21L, 1L, 19L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, 50L, null, \"\").join();\n+        // now retention set has three stream cut 0/2, 1/2...0/2, 1/2... 0/10, 1/10.. 0/20, 1/20.. 0/30, 1/30\n+        // subscriber lowerbound is 0/21, 1/19.. meets min bound criteria. and its also greater than max bound. but it overlaps with max bound. \n+        // truncation should happen at 0/21, 1/19\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 21L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 19L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+    }\n+    \n+    @Test(timeout = 30000)\n+    public void consumptionBasedRetentionTimeLimitTest() throws Exception {\n+        final ScalingPolicy policy = ScalingPolicy.fixed(2);\n+        final RetentionPolicy retentionPolicy = RetentionPolicy.byConsumption(RetentionPolicy.ConsumptionLimits.Type.TIME_MILLIS, 1L, 10L);\n+\n+        String stream1 = \"consumptionTime\";\n+        final StreamConfiguration configuration = StreamConfiguration.builder().scalingPolicy(policy)\n+                .retentionPolicy(retentionPolicy).build();\n+\n+        streamStorePartialMock.createStream(SCOPE, stream1, configuration, System.currentTimeMillis(), null, executor).get();\n+        streamStorePartialMock.setState(SCOPE, stream1, State.ACTIVE, null, executor).get();\n+\n+        assertNotEquals(0, consumer.getCurrentSegments(SCOPE, stream1).get().size());\n+        WriterMock requestEventWriter = new WriterMock(streamMetadataTasks, executor);\n+        streamMetadataTasks.setRequestEventWriter(requestEventWriter);\n+        streamMetadataTasks.setRetentionFrequencyMillis(1L);\n+        AtomicLong time = new AtomicLong(0L);\n+        streamMetadataTasks.setRetentionClock(time::get);\n+        // region case 1: basic retention\n+        // add subscriber 1\n+        // add subscriber 2\n+        String subscriber1 = \"subscriber1\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber1, null).join();\n+\n+        String subscriber2 = \"subscriber2\";\n+        streamMetadataTasks.addSubscriber(SCOPE, stream1, subscriber2, null).join();\n+        \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 2L, 1L, 1L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 1L, 1L, 2L), null).join();\n+\n+        Map<Long, Long> map1 = new HashMap<>();\n+        map1.put(0L, 2L);\n+        map1.put(1L, 2L);\n+        long size = streamStorePartialMock.getSizeTillStreamCut(SCOPE, stream1, map1, Optional.empty(), null, executor).join();\n+        doReturn(CompletableFuture.completedFuture(new StreamCutRecord(time.get(), size, ImmutableMap.copyOf(map1))))\n+                .when(streamMetadataTasks).generateStreamCut(anyString(), anyString(), any(), any(), any());\n+\n+        // call retention and verify that retention policy applies\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, time.get(), null, \"\").join();\n+        // now retention set has one stream cut 0/2, 1/2, recording time 1L\n+        // subscriber lowerbound is 0/1, 1/1.. trucation should not happen as this lowerbound is ahead of min retention streamcut.\n+        VersionedMetadata<StreamTruncationRecord> truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertFalse(truncationRecord.getObject().isUpdating());\n+        // endregion\n+        \n+        // region case 2 min policy check\n+        // subscriber streamcut > min time streamcut while\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(2L, 4L, ImmutableMap.of(0L, 2L, 1L, 2L)), null, executor).join();\n+\n+        time.set(10L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 20L, ImmutableMap.of(0L, 10L, 1L, 10L)), null, executor).join();\n+\n+        time.set(11L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 20L, ImmutableMap.of(0L, 10L, 1L, 10L)), null, executor).join();\n+\n+        // retentionset: 0L: 0L/2L, 1L/2L... 2L: 0L/2L, 1L/2L... 10L: 0/10, 1/10....11L: 0/10, 1/10. \n+        // update both readers to 0/3, 1/3.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 3L, 1L, 3L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 3L, 1L, 3L), null).join();\n+\n+        // new truncation should happen at subscriber lowerbound.\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, time.get(), null, \"\").join();\n+\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 3L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 3L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 3: min criteria not met on lower bound. truncate at max.\n+        time.set(20L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 22L, ImmutableMap.of(0L, 11L, 1L, 11L)), null, executor).join();\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 11L, 1L, 11L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 11L, 1L, 11L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, time.get(), null, \"\").join();\n+        // retentionset: 0L: 0L/2L, 1L/2L... 2L: 0L/2L, 1L/2L... 10L: 0/10, 1/10....11L: 0/10, 1/10... 20: 0/11, 1/11\n+        // subscriber lowerbound is 0/11, 1/11 \n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        // truncate at limit min\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 10L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 10L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+        \n+        // region case 4: lowerbound behind max\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(30L, 40L, ImmutableMap.of(0L, 20L, 1L, 20L)), null, executor).join();\n+        time.set(40L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 42L, ImmutableMap.of(0L, 21L, 1L, 21L)), null, executor).join();\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 11L, 1L, 11L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 11L, 1L, 11L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, time.get(), null, \"\").join();\n+        // now retention set has five stream cuts 1: 0/2, 1/2...10: 0/10, 1/10... 20: 0/11, 1/11.. 30: 0/20, 1/20.. 40L: 0/21, 1/21\n+        // subscriber lowerbound is 0/11, 1/11 \n+        // max = 30. truncate at max\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 20L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 20L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+\n+        // region case 5: lowerbound overlaps with max\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(50L, 43L, ImmutableMap.of(0L, 21L, 1L, 22L)), null, executor).join();\n+        time.set(59L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 60L, ImmutableMap.of(0L, 30L, 1L, 30L)), null, executor).join();\n+        time.set(60L);\n+        streamStorePartialMock.addStreamCutToRetentionSet(SCOPE, stream1,\n+                new StreamCutRecord(time.get(), 60L, ImmutableMap.of(0L, 30L, 1L, 30L)), null, executor).join();\n+\n+        // update both readers to make sure they have read till the latest position - 1. we have set the min limit to 2.  \n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber1, ImmutableMap.of(0L, 22L, 1L, 21L), null).join();\n+        streamMetadataTasks.updateSubscriberStreamCut(SCOPE, stream1, subscriber2, ImmutableMap.of(0L, 22L, 1L, 21L), null).join();\n+\n+        streamMetadataTasks.retention(SCOPE, stream1, retentionPolicy, time.get(), null, \"\").join();\n+        // now retention set has five stream cuts 1: 0/2, 1/2...10: 0/10, 1/10... 20: 0/11, 1/11.. 30: 0/20, 1/20.. 40L: 0/21, 1/21\n+        // 50: 0/21, 1/22 ... 59: 0/30, 1/30.. 60: 0/30, 1/30\n+        // subscriber lowerbound is 0/22, 1/21 \n+        // this overlaps with max. so truncate at streamcut\n+        truncationRecord = streamStorePartialMock.getTruncationRecord(SCOPE, stream1, null, executor).join();\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(0L).longValue(), 22L);\n+        assertEquals(truncationRecord.getObject().getStreamCut().get(1L).longValue(), 21L);\n+        assertTrue(truncationRecord.getObject().isUpdating());\n+        streamStorePartialMock.completeTruncation(SCOPE, stream1, truncationRecord, null, executor).join();\n+        // endregion\n+    }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bd7badf9bd8d1dd457baf8014f4716b0b468f61c"}, "originalPosition": 289}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df6c62a4a7ce3b6bdb866d872764eeeb98706a70", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/df6c62a4a7ce3b6bdb866d872764eeeb98706a70", "committedDate": "2020-11-13T11:27:20Z", "message": "Merge branch 'master' into CBR-controller"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c39597475e4377d84c252ddab601050aab478452", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/c39597475e4377d84c252ddab601050aab478452", "committedDate": "2020-11-13T11:52:05Z", "message": "PR comments\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08287d42322c148d1bd8b3f3a920ad9e03c58056", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/08287d42322c148d1bd8b3f3a920ad9e03c58056", "committedDate": "2020-11-13T12:19:56Z", "message": "Use latest as min bound if retention set is empty\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37bcb576bb790874c9274e23abe09aa22d578a11", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/37bcb576bb790874c9274e23abe09aa22d578a11", "committedDate": "2020-11-13T13:45:18Z", "message": "Checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07c2838e170b5ac7b040ca02680ca3ab32983ab5", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/07c2838e170b5ac7b040ca02680ca3ab32983ab5", "committedDate": "2020-11-16T17:21:19Z", "message": "Merge branch 'master' into CBR-controller"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyMDUzNjY5", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-532053669", "createdAt": "2020-11-17T06:29:54Z", "commit": {"oid": "07c2838e170b5ac7b040ca02680ca3ab32983ab5"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwNjoyOTo1NFrOH0mDig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwNjozMjoxMFrOH0mGog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkxMTQ5OA==", "bodyText": "In the case where a Stream has only a single Subscriber, there is no need to compute a \"lower bound\" and we could short circuit this computation and directly return the Stream-Cut  corresponding to that Subscriber.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r524911498", "createdAt": "2020-11-17T06:29:54Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -507,32 +514,296 @@ public void initializeStreamWriters(final EventStreamClientFactory clientFactory\n \n     private CompletableFuture<Void> truncate(String scope, String stream, RetentionPolicy policy, OperationContext context,\n                                              RetentionSet retentionSet, StreamCutRecord newRecord, long recordingTime, long requestId) {\n-        Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n-        if (!truncationRecord.isPresent()) {\n-            log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n-            return CompletableFuture.completedFuture(null);\n+        if (policy.getRetentionType().equals(RetentionPolicy.RetentionType.CONSUMPTION)) {\n+            return subscriberBasedTruncation(scope, stream, context, policy, retentionSet, newRecord, requestId);\n+        } else {\n+            Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n+            if (!truncationRecord.isPresent()) {\n+                log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n+                    truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n+\n+            return truncate(scope, stream, context, requestId, truncationRecord.get());\n         }\n+    }\n+\n+    private CompletableFuture<Void> truncate(String scope, String stream, OperationContext context, long requestId,\n+                                                   StreamCutReferenceRecord truncationRecord) {\n         log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n-                truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n-        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord.get(), context, executor)\n-                   .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n-                   .thenCompose(started -> {\n-                       if (started) {\n-                                return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord.get(), context, executor);\n+                truncationRecord.getRecordingTime(), truncationRecord.getRecordingSize());\n+        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord, context, executor)\n+                                  .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n+                                  .thenCompose(started -> {\n+                                      if (started) {\n+                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord, context, executor);\n+                                      } else {\n+                                          throw new RuntimeException(\"Could not start truncation\");\n+                                      }\n+                                  })\n+                                  .exceptionally(e -> {\n+                                      if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n+                                          // This is ignorable exception. Throwing this will cause unnecessary retries and exceptions logged.\n+                                          log.debug(requestId, \"Cannot truncate at given \" +\n+                                                  \"streamCut because it intersects with existing truncation point\");\n+                                          return null;\n+                                      } else {\n+                                          throw new CompletionException(e);\n+                                      }\n+                                  });\n+    }\n+\n+    private CompletableFuture<Void> subscriberBasedTruncation(String scope, String stream, OperationContext context,\n+                                                              RetentionPolicy policy, RetentionSet retentionSet, \n+                                                              StreamCutRecord newRecord, long requestId) {\n+        return streamMetadataStore.listSubscribers(scope, stream, context, executor)\n+                           .thenCompose(list -> Futures.allOfWithResults(list.stream().map(x -> \n+                                   streamMetadataStore.getSubscriber(scope, stream, x, context, executor)).collect(Collectors.toList())))\n+                           .thenCompose(subscribers -> {\n+                               // convert all streamcuts to include the segment range\n+                               return Futures.allOfWithResults(subscribers.stream().map(x -> {\n+                                   ImmutableSet<Map.Entry<Long, Long>> entries = x.getObject().getTruncationStreamCut().entrySet();\n+\n+                                   return Futures.keysAllOfWithResults(entries.stream().collect(Collectors.toMap(\n+                                           y -> streamMetadataStore.getSegment(scope, stream, y.getKey(), context, executor), Map.Entry::getValue)));\n+                               }).collect(Collectors.toList()));\n+                           })\n+                           .thenApply(this::computeSubscribersLowerBound)\n+                .thenCompose(lowerBound -> {\n+                    CompletableFuture<Map<Long, Long>> toTruncateAt; \n+                    if (policy.getConsumptionLimits().getType().equals(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES)) {\n+                        toTruncateAt = getTruncationStreamCutBySizeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    } else {\n+                        toTruncateAt = getTruncationStreamCutByTimeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    }\n+                    return toTruncateAt.thenCompose(truncationStreamCut -> {\n+                        if (truncationStreamCut == null || truncationStreamCut.isEmpty()) {\n+                            log.debug(\"no truncation record could be compute that satisfied retention policy\");\n+                            return CompletableFuture.completedFuture(null);\n+                        } \n+                        return startTruncation(scope, stream, truncationStreamCut, context, requestId)\n+                                .thenCompose(started -> {\n+                                    if (started) {\n+                                        return streamMetadataStore.findStreamCutReferenceRecordBefore(scope, stream, truncationStreamCut, retentionSet, context, executor)\n+                                                                  .thenCompose(ref -> {\n+                                                                      if (ref != null) {\n+                                                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, ref, context, executor);\n+                                                                      } else {\n+                                                                          return CompletableFuture.completedFuture(null);\n+                                                                      }\n+                                                                  });\n+                                    } else {\n+                                        throw new RuntimeException(\"Could not start truncation\");\n+                                    }\n+                                });\n+                    });\n+                });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutBySizeLimit(String scope, String stream, OperationContext context, RetentionPolicy policy,\n+                                                                                 RetentionSet retentionSet, Map<Long, Long> lowerBound, StreamCutRecord newRecord) {\n+        // if the lowerbound on subscribers streamcuts satisfies the policy size bound, then return it. \n+        // else return the stream cut that satisfies maximum bound on size. \n+        // 1. if lowerbound.size < max and lowerbound.size > min truncate at lowerbound\n+        // 2. if lowerbound.size < min, truncate at max irrespective of if lowerbound overlaps with max or not. \n+        // 3. if lowerbound.size > max, truncate at max\n+        long currentSize = newRecord != null ? newRecord.getRecordingSize() : retentionSet.getLatest().getRecordingSize();\n+        return streamMetadataStore.getSizeTillStreamCut(scope, stream, lowerBound, Optional.empty(), context, executor)\n+                          .thenCompose(sizeTill -> {\n+                               long retainedSize = currentSize - sizeTill;\n+                               Supplier<Optional<StreamCutReferenceRecord>> maxBound = () -> retentionSet\n+                                      .getRetentionRecords().stream()\n+                                      .filter(x -> currentSize - x.getRecordingSize() > policy.getConsumptionLimits().getMaxValue())\n+                                      .max(Comparator.comparingLong(StreamCutReferenceRecord::getRecordingTime));\n+\n+                               // if retainedSize is less than min size then do not truncate the stream. \n+                               if (retainedSize < policy.getConsumptionLimits().getMinValue()) {\n+                                   return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                                               .thenApply(StreamCutRecord::getStreamCut))\n+                                                  .orElse(CompletableFuture.completedFuture(null));\n+                               } else {\n+                                   // if retained size is less than max allowed, then truncate the stream at subscriber lower bound. \n+                                   if (retainedSize < policy.getConsumptionLimits().getMaxValue()) {\n+                                       return CompletableFuture.completedFuture(lowerBound);\n+                                   } else {\n+                                       // if retained size is greater than max allowed, then truncate the stream at streamcut\n+                                       // from retention set that matches the retention policy size bound. \n+                                       return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                   .thenApply(StreamCutRecord::getStreamCut)\n+                                                   .thenCompose(maxRecord -> {\n+                                                       // if max record is strictly greater than lowerbound then we can truncate at max record\n+                                                       return streamMetadataStore.streamCutStrictlyGreaterThan(\n+                                                               scope, stream, maxRecord, lowerBound, context, executor)\n+                                                                                 .thenApply(gt -> {\n+                                                                                     if (gt) {\n+                                                                                         return maxRecord;\n+                                                                                     } else {\n+                                                                                         return lowerBound;\n+                                                                                     }\n+                                                                                 });\n+                                                   })).orElse(CompletableFuture.completedFuture(null));   \n+                                   }\n+                               }\n+                           });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutByTimeLimit(String scope, String stream, OperationContext context,\n+                                                                                 RetentionPolicy policy, RetentionSet retentionSet,\n+                                                                                 Map<Long, Long> lowerBound, StreamCutRecord latest) {\n+        Map.Entry<StreamCutReferenceRecord, StreamCutReferenceRecord> limits =\n+                getBoundStreamCuts(policy.getConsumptionLimits(), retentionSet);\n+        // if subscriber lowerbound is ahead of streamcut corresponding to the max time and is behind stream cut for min time \n+        // from the retention set then we can safely truncate at lowerbound. Else we will truncate at the max time bound if it\n+        // exists\n+        // 1. if LB > min => truncate at min\n+        // 2. if LB < max => truncate at max\n+        // 3. if LB < min && LB > max => truncate at LB\n+        // 4. if LB < min && overlaps max => truncate at LB\n+        CompletableFuture<StreamCutRecord> limitMaxFuture = limits.getKey() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getKey(), context, executor);\n+        CompletableFuture<StreamCutRecord> limitMinFuture = limits.getValue() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getValue(), context, executor);\n+        return CompletableFuture.allOf(limitMaxFuture, limitMinFuture)\n+                         .thenCompose(v -> {\n+                             StreamCutRecord limitMax = limitMaxFuture.join();\n+                             StreamCutRecord limitMin = limitMinFuture.join();\n+                             if (limitMin != null) {\n+                                 return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMin.getStreamCut(), lowerBound, context, executor)\n+                                                    .thenCompose(gtMin -> {\n+                                                        if (gtMin) {\n+                                                            if (limitMax == null) {\n+                                                                return CompletableFuture.completedFuture(lowerBound);\n+                                                            } else {\n+                                                                return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMax.getStreamCut(), lowerBound, context, executor)\n+                                                                                          .thenApply(gtMax -> gtMax ? limitMax.getStreamCut() : lowerBound);\n+                                                            }\n+                                                        } else {\n+                                                            return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, lowerBound, limitMin.getStreamCut(), context, executor)\n+                                                                               .thenApply(gt -> gt ? limitMin.getStreamCut() : null);\n+                                                        }\n+                                                    });\n+                             } else {\n+                                 // if min limit is 0 then latest effectively becomes the min. and we truncate at the lowerbound.\n+                                 if (latest != null && policy.getConsumptionLimits().getMinValue() == 0L) {\n+                                     // truncate at the lower bound \n+                                     return CompletableFuture.completedFuture(lowerBound);\n+                                 } else {\n+                                     return CompletableFuture.completedFuture(null);\n+                                 }\n+                             }\n+                         });\n+    }\n+\n+    private Map<Long, Long> computeSubscribersLowerBound(List<Map<StreamSegmentRecord, Long>> subscribers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "07c2838e170b5ac7b040ca02680ca3ab32983ab5"}, "originalPosition": 244}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkxMjI5MA==", "bodyText": "It may be good to add a test case covering this scenario.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r524912290", "createdAt": "2020-11-17T06:32:10Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -507,32 +514,296 @@ public void initializeStreamWriters(final EventStreamClientFactory clientFactory\n \n     private CompletableFuture<Void> truncate(String scope, String stream, RetentionPolicy policy, OperationContext context,\n                                              RetentionSet retentionSet, StreamCutRecord newRecord, long recordingTime, long requestId) {\n-        Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n-        if (!truncationRecord.isPresent()) {\n-            log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n-            return CompletableFuture.completedFuture(null);\n+        if (policy.getRetentionType().equals(RetentionPolicy.RetentionType.CONSUMPTION)) {\n+            return subscriberBasedTruncation(scope, stream, context, policy, retentionSet, newRecord, requestId);\n+        } else {\n+            Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n+            if (!truncationRecord.isPresent()) {\n+                log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n+                    truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n+\n+            return truncate(scope, stream, context, requestId, truncationRecord.get());\n         }\n+    }\n+\n+    private CompletableFuture<Void> truncate(String scope, String stream, OperationContext context, long requestId,\n+                                                   StreamCutReferenceRecord truncationRecord) {\n         log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n-                truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n-        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord.get(), context, executor)\n-                   .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n-                   .thenCompose(started -> {\n-                       if (started) {\n-                                return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord.get(), context, executor);\n+                truncationRecord.getRecordingTime(), truncationRecord.getRecordingSize());\n+        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord, context, executor)\n+                                  .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n+                                  .thenCompose(started -> {\n+                                      if (started) {\n+                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord, context, executor);\n+                                      } else {\n+                                          throw new RuntimeException(\"Could not start truncation\");\n+                                      }\n+                                  })\n+                                  .exceptionally(e -> {\n+                                      if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n+                                          // This is ignorable exception. Throwing this will cause unnecessary retries and exceptions logged.\n+                                          log.debug(requestId, \"Cannot truncate at given \" +\n+                                                  \"streamCut because it intersects with existing truncation point\");\n+                                          return null;\n+                                      } else {\n+                                          throw new CompletionException(e);\n+                                      }\n+                                  });\n+    }\n+\n+    private CompletableFuture<Void> subscriberBasedTruncation(String scope, String stream, OperationContext context,\n+                                                              RetentionPolicy policy, RetentionSet retentionSet, \n+                                                              StreamCutRecord newRecord, long requestId) {\n+        return streamMetadataStore.listSubscribers(scope, stream, context, executor)\n+                           .thenCompose(list -> Futures.allOfWithResults(list.stream().map(x -> \n+                                   streamMetadataStore.getSubscriber(scope, stream, x, context, executor)).collect(Collectors.toList())))\n+                           .thenCompose(subscribers -> {\n+                               // convert all streamcuts to include the segment range\n+                               return Futures.allOfWithResults(subscribers.stream().map(x -> {\n+                                   ImmutableSet<Map.Entry<Long, Long>> entries = x.getObject().getTruncationStreamCut().entrySet();\n+\n+                                   return Futures.keysAllOfWithResults(entries.stream().collect(Collectors.toMap(\n+                                           y -> streamMetadataStore.getSegment(scope, stream, y.getKey(), context, executor), Map.Entry::getValue)));\n+                               }).collect(Collectors.toList()));\n+                           })\n+                           .thenApply(this::computeSubscribersLowerBound)\n+                .thenCompose(lowerBound -> {\n+                    CompletableFuture<Map<Long, Long>> toTruncateAt; \n+                    if (policy.getConsumptionLimits().getType().equals(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES)) {\n+                        toTruncateAt = getTruncationStreamCutBySizeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    } else {\n+                        toTruncateAt = getTruncationStreamCutByTimeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    }\n+                    return toTruncateAt.thenCompose(truncationStreamCut -> {\n+                        if (truncationStreamCut == null || truncationStreamCut.isEmpty()) {\n+                            log.debug(\"no truncation record could be compute that satisfied retention policy\");\n+                            return CompletableFuture.completedFuture(null);\n+                        } \n+                        return startTruncation(scope, stream, truncationStreamCut, context, requestId)\n+                                .thenCompose(started -> {\n+                                    if (started) {\n+                                        return streamMetadataStore.findStreamCutReferenceRecordBefore(scope, stream, truncationStreamCut, retentionSet, context, executor)\n+                                                                  .thenCompose(ref -> {\n+                                                                      if (ref != null) {\n+                                                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, ref, context, executor);\n+                                                                      } else {\n+                                                                          return CompletableFuture.completedFuture(null);\n+                                                                      }\n+                                                                  });\n+                                    } else {\n+                                        throw new RuntimeException(\"Could not start truncation\");\n+                                    }\n+                                });\n+                    });\n+                });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutBySizeLimit(String scope, String stream, OperationContext context, RetentionPolicy policy,\n+                                                                                 RetentionSet retentionSet, Map<Long, Long> lowerBound, StreamCutRecord newRecord) {\n+        // if the lowerbound on subscribers streamcuts satisfies the policy size bound, then return it. \n+        // else return the stream cut that satisfies maximum bound on size. \n+        // 1. if lowerbound.size < max and lowerbound.size > min truncate at lowerbound\n+        // 2. if lowerbound.size < min, truncate at max irrespective of if lowerbound overlaps with max or not. \n+        // 3. if lowerbound.size > max, truncate at max\n+        long currentSize = newRecord != null ? newRecord.getRecordingSize() : retentionSet.getLatest().getRecordingSize();\n+        return streamMetadataStore.getSizeTillStreamCut(scope, stream, lowerBound, Optional.empty(), context, executor)\n+                          .thenCompose(sizeTill -> {\n+                               long retainedSize = currentSize - sizeTill;\n+                               Supplier<Optional<StreamCutReferenceRecord>> maxBound = () -> retentionSet\n+                                      .getRetentionRecords().stream()\n+                                      .filter(x -> currentSize - x.getRecordingSize() > policy.getConsumptionLimits().getMaxValue())\n+                                      .max(Comparator.comparingLong(StreamCutReferenceRecord::getRecordingTime));\n+\n+                               // if retainedSize is less than min size then do not truncate the stream. \n+                               if (retainedSize < policy.getConsumptionLimits().getMinValue()) {\n+                                   return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                                               .thenApply(StreamCutRecord::getStreamCut))\n+                                                  .orElse(CompletableFuture.completedFuture(null));\n+                               } else {\n+                                   // if retained size is less than max allowed, then truncate the stream at subscriber lower bound. \n+                                   if (retainedSize < policy.getConsumptionLimits().getMaxValue()) {\n+                                       return CompletableFuture.completedFuture(lowerBound);\n+                                   } else {\n+                                       // if retained size is greater than max allowed, then truncate the stream at streamcut\n+                                       // from retention set that matches the retention policy size bound. \n+                                       return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                   .thenApply(StreamCutRecord::getStreamCut)\n+                                                   .thenCompose(maxRecord -> {\n+                                                       // if max record is strictly greater than lowerbound then we can truncate at max record\n+                                                       return streamMetadataStore.streamCutStrictlyGreaterThan(\n+                                                               scope, stream, maxRecord, lowerBound, context, executor)\n+                                                                                 .thenApply(gt -> {\n+                                                                                     if (gt) {\n+                                                                                         return maxRecord;\n+                                                                                     } else {\n+                                                                                         return lowerBound;\n+                                                                                     }\n+                                                                                 });\n+                                                   })).orElse(CompletableFuture.completedFuture(null));   \n+                                   }\n+                               }\n+                           });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutByTimeLimit(String scope, String stream, OperationContext context,\n+                                                                                 RetentionPolicy policy, RetentionSet retentionSet,\n+                                                                                 Map<Long, Long> lowerBound, StreamCutRecord latest) {\n+        Map.Entry<StreamCutReferenceRecord, StreamCutReferenceRecord> limits =\n+                getBoundStreamCuts(policy.getConsumptionLimits(), retentionSet);\n+        // if subscriber lowerbound is ahead of streamcut corresponding to the max time and is behind stream cut for min time \n+        // from the retention set then we can safely truncate at lowerbound. Else we will truncate at the max time bound if it\n+        // exists\n+        // 1. if LB > min => truncate at min\n+        // 2. if LB < max => truncate at max\n+        // 3. if LB < min && LB > max => truncate at LB\n+        // 4. if LB < min && overlaps max => truncate at LB\n+        CompletableFuture<StreamCutRecord> limitMaxFuture = limits.getKey() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getKey(), context, executor);\n+        CompletableFuture<StreamCutRecord> limitMinFuture = limits.getValue() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getValue(), context, executor);\n+        return CompletableFuture.allOf(limitMaxFuture, limitMinFuture)\n+                         .thenCompose(v -> {\n+                             StreamCutRecord limitMax = limitMaxFuture.join();\n+                             StreamCutRecord limitMin = limitMinFuture.join();\n+                             if (limitMin != null) {\n+                                 return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMin.getStreamCut(), lowerBound, context, executor)\n+                                                    .thenCompose(gtMin -> {\n+                                                        if (gtMin) {\n+                                                            if (limitMax == null) {\n+                                                                return CompletableFuture.completedFuture(lowerBound);\n+                                                            } else {\n+                                                                return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMax.getStreamCut(), lowerBound, context, executor)\n+                                                                                          .thenApply(gtMax -> gtMax ? limitMax.getStreamCut() : lowerBound);\n+                                                            }\n+                                                        } else {\n+                                                            return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, lowerBound, limitMin.getStreamCut(), context, executor)\n+                                                                               .thenApply(gt -> gt ? limitMin.getStreamCut() : null);\n+                                                        }\n+                                                    });\n+                             } else {\n+                                 // if min limit is 0 then latest effectively becomes the min. and we truncate at the lowerbound.\n+                                 if (latest != null && policy.getConsumptionLimits().getMinValue() == 0L) {\n+                                     // truncate at the lower bound \n+                                     return CompletableFuture.completedFuture(lowerBound);\n+                                 } else {\n+                                     return CompletableFuture.completedFuture(null);\n+                                 }\n+                             }\n+                         });\n+    }\n+\n+    private Map<Long, Long> computeSubscribersLowerBound(List<Map<StreamSegmentRecord, Long>> subscribers) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkxMTQ5OA=="}, "originalCommit": {"oid": "07c2838e170b5ac7b040ca02680ca3ab32983ab5"}, "originalPosition": 244}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43ed4c9779a615ec60ff036dbabfd6cb411c6394", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/43ed4c9779a615ec60ff036dbabfd6cb411c6394", "committedDate": "2020-11-17T07:05:26Z", "message": "Merge branch 'master' into CBR-controller"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMTAwMzU3", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-533100357", "createdAt": "2020-11-18T04:43:36Z", "commit": {"oid": "43ed4c9779a615ec60ff036dbabfd6cb411c6394"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwNDo0MzozNlrOH1cevQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwNDo0MzozNlrOH1cevQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgwMzE5Nw==", "bodyText": "It should be a small change. I think we should do it as part of this PR itself.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r525803197", "createdAt": "2020-11-18T04:43:36Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/task/Stream/StreamMetadataTasks.java", "diffHunk": "@@ -507,32 +514,296 @@ public void initializeStreamWriters(final EventStreamClientFactory clientFactory\n \n     private CompletableFuture<Void> truncate(String scope, String stream, RetentionPolicy policy, OperationContext context,\n                                              RetentionSet retentionSet, StreamCutRecord newRecord, long recordingTime, long requestId) {\n-        Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n-        if (!truncationRecord.isPresent()) {\n-            log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n-            return CompletableFuture.completedFuture(null);\n+        if (policy.getRetentionType().equals(RetentionPolicy.RetentionType.CONSUMPTION)) {\n+            return subscriberBasedTruncation(scope, stream, context, policy, retentionSet, newRecord, requestId);\n+        } else {\n+            Optional<StreamCutReferenceRecord> truncationRecord = findTruncationRecord(policy, retentionSet, newRecord, recordingTime);\n+            if (!truncationRecord.isPresent()) {\n+                log.info(\"No suitable truncation record found, per retention policy for stream {}/{}\", scope, stream);\n+                return CompletableFuture.completedFuture(null);\n+            }\n+            log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n+                    truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n+\n+            return truncate(scope, stream, context, requestId, truncationRecord.get());\n         }\n+    }\n+\n+    private CompletableFuture<Void> truncate(String scope, String stream, OperationContext context, long requestId,\n+                                                   StreamCutReferenceRecord truncationRecord) {\n         log.info(\"Found truncation record for stream {}/{} truncationRecord time/size: {}/{}\", scope, stream,\n-                truncationRecord.get().getRecordingTime(), truncationRecord.get().getRecordingSize());\n-        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord.get(), context, executor)\n-                   .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n-                   .thenCompose(started -> {\n-                       if (started) {\n-                                return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord.get(), context, executor);\n+                truncationRecord.getRecordingTime(), truncationRecord.getRecordingSize());\n+        return streamMetadataStore.getStreamCutRecord(scope, stream, truncationRecord, context, executor)\n+                                  .thenCompose(streamCutRecord -> startTruncation(scope, stream, streamCutRecord.getStreamCut(), context, requestId))\n+                                  .thenCompose(started -> {\n+                                      if (started) {\n+                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, truncationRecord, context, executor);\n+                                      } else {\n+                                          throw new RuntimeException(\"Could not start truncation\");\n+                                      }\n+                                  })\n+                                  .exceptionally(e -> {\n+                                      if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n+                                          // This is ignorable exception. Throwing this will cause unnecessary retries and exceptions logged.\n+                                          log.debug(requestId, \"Cannot truncate at given \" +\n+                                                  \"streamCut because it intersects with existing truncation point\");\n+                                          return null;\n+                                      } else {\n+                                          throw new CompletionException(e);\n+                                      }\n+                                  });\n+    }\n+\n+    private CompletableFuture<Void> subscriberBasedTruncation(String scope, String stream, OperationContext context,\n+                                                              RetentionPolicy policy, RetentionSet retentionSet, \n+                                                              StreamCutRecord newRecord, long requestId) {\n+        return streamMetadataStore.listSubscribers(scope, stream, context, executor)\n+                           .thenCompose(list -> Futures.allOfWithResults(list.stream().map(x -> \n+                                   streamMetadataStore.getSubscriber(scope, stream, x, context, executor)).collect(Collectors.toList())))\n+                           .thenCompose(subscribers -> {\n+                               // convert all streamcuts to include the segment range\n+                               return Futures.allOfWithResults(subscribers.stream().map(x -> {\n+                                   ImmutableSet<Map.Entry<Long, Long>> entries = x.getObject().getTruncationStreamCut().entrySet();\n+\n+                                   return Futures.keysAllOfWithResults(entries.stream().collect(Collectors.toMap(\n+                                           y -> streamMetadataStore.getSegment(scope, stream, y.getKey(), context, executor), Map.Entry::getValue)));\n+                               }).collect(Collectors.toList()));\n+                           })\n+                           .thenApply(this::computeSubscribersLowerBound)\n+                .thenCompose(lowerBound -> {\n+                    CompletableFuture<Map<Long, Long>> toTruncateAt; \n+                    if (policy.getConsumptionLimits().getType().equals(RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES)) {\n+                        toTruncateAt = getTruncationStreamCutBySizeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    } else {\n+                        toTruncateAt = getTruncationStreamCutByTimeLimit(scope, stream, context, policy, retentionSet, lowerBound, newRecord);\n+                    }\n+                    return toTruncateAt.thenCompose(truncationStreamCut -> {\n+                        if (truncationStreamCut == null || truncationStreamCut.isEmpty()) {\n+                            log.debug(\"no truncation record could be compute that satisfied retention policy\");\n+                            return CompletableFuture.completedFuture(null);\n+                        } \n+                        return startTruncation(scope, stream, truncationStreamCut, context, requestId)\n+                                .thenCompose(started -> {\n+                                    if (started) {\n+                                        return streamMetadataStore.findStreamCutReferenceRecordBefore(scope, stream, truncationStreamCut, retentionSet, context, executor)\n+                                                                  .thenCompose(ref -> {\n+                                                                      if (ref != null) {\n+                                                                          return streamMetadataStore.deleteStreamCutBefore(scope, stream, ref, context, executor);\n+                                                                      } else {\n+                                                                          return CompletableFuture.completedFuture(null);\n+                                                                      }\n+                                                                  });\n+                                    } else {\n+                                        throw new RuntimeException(\"Could not start truncation\");\n+                                    }\n+                                });\n+                    });\n+                });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutBySizeLimit(String scope, String stream, OperationContext context, RetentionPolicy policy,\n+                                                                                 RetentionSet retentionSet, Map<Long, Long> lowerBound, StreamCutRecord newRecord) {\n+        // if the lowerbound on subscribers streamcuts satisfies the policy size bound, then return it. \n+        // else return the stream cut that satisfies maximum bound on size. \n+        // 1. if lowerbound.size < max and lowerbound.size > min truncate at lowerbound\n+        // 2. if lowerbound.size < min, truncate at max irrespective of if lowerbound overlaps with max or not. \n+        // 3. if lowerbound.size > max, truncate at max\n+        long currentSize = newRecord != null ? newRecord.getRecordingSize() : retentionSet.getLatest().getRecordingSize();\n+        return streamMetadataStore.getSizeTillStreamCut(scope, stream, lowerBound, Optional.empty(), context, executor)\n+                          .thenCompose(sizeTill -> {\n+                               long retainedSize = currentSize - sizeTill;\n+                               Supplier<Optional<StreamCutReferenceRecord>> maxBound = () -> retentionSet\n+                                      .getRetentionRecords().stream()\n+                                      .filter(x -> currentSize - x.getRecordingSize() > policy.getConsumptionLimits().getMaxValue())\n+                                      .max(Comparator.comparingLong(StreamCutReferenceRecord::getRecordingTime));\n+\n+                               // if retainedSize is less than min size then do not truncate the stream. \n+                               if (retainedSize < policy.getConsumptionLimits().getMinValue()) {\n+                                   return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                                               .thenApply(StreamCutRecord::getStreamCut))\n+                                                  .orElse(CompletableFuture.completedFuture(null));\n+                               } else {\n+                                   // if retained size is less than max allowed, then truncate the stream at subscriber lower bound. \n+                                   if (retainedSize < policy.getConsumptionLimits().getMaxValue()) {\n+                                       return CompletableFuture.completedFuture(lowerBound);\n+                                   } else {\n+                                       // if retained size is greater than max allowed, then truncate the stream at streamcut\n+                                       // from retention set that matches the retention policy size bound. \n+                                       return maxBound.get().map(x -> streamMetadataStore.getStreamCutRecord(scope, stream, x, context, executor)\n+                                                   .thenApply(StreamCutRecord::getStreamCut)\n+                                                   .thenCompose(maxRecord -> {\n+                                                       // if max record is strictly greater than lowerbound then we can truncate at max record\n+                                                       return streamMetadataStore.streamCutStrictlyGreaterThan(\n+                                                               scope, stream, maxRecord, lowerBound, context, executor)\n+                                                                                 .thenApply(gt -> {\n+                                                                                     if (gt) {\n+                                                                                         return maxRecord;\n+                                                                                     } else {\n+                                                                                         return lowerBound;\n+                                                                                     }\n+                                                                                 });\n+                                                   })).orElse(CompletableFuture.completedFuture(null));   \n+                                   }\n+                               }\n+                           });\n+    }\n+\n+    private CompletableFuture<Map<Long, Long>> getTruncationStreamCutByTimeLimit(String scope, String stream, OperationContext context,\n+                                                                                 RetentionPolicy policy, RetentionSet retentionSet,\n+                                                                                 Map<Long, Long> lowerBound, StreamCutRecord latest) {\n+        Map.Entry<StreamCutReferenceRecord, StreamCutReferenceRecord> limits =\n+                getBoundStreamCuts(policy.getConsumptionLimits(), retentionSet);\n+        // if subscriber lowerbound is ahead of streamcut corresponding to the max time and is behind stream cut for min time \n+        // from the retention set then we can safely truncate at lowerbound. Else we will truncate at the max time bound if it\n+        // exists\n+        // 1. if LB > min => truncate at min\n+        // 2. if LB < max => truncate at max\n+        // 3. if LB < min && LB > max => truncate at LB\n+        // 4. if LB < min && overlaps max => truncate at LB\n+        CompletableFuture<StreamCutRecord> limitMaxFuture = limits.getKey() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getKey(), context, executor);\n+        CompletableFuture<StreamCutRecord> limitMinFuture = limits.getValue() == null ? CompletableFuture.completedFuture(null) :\n+                streamMetadataStore.getStreamCutRecord(scope, stream, limits.getValue(), context, executor);\n+        return CompletableFuture.allOf(limitMaxFuture, limitMinFuture)\n+                         .thenCompose(v -> {\n+                             StreamCutRecord limitMax = limitMaxFuture.join();\n+                             StreamCutRecord limitMin = limitMinFuture.join();\n+                             if (limitMin != null) {\n+                                 return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMin.getStreamCut(), lowerBound, context, executor)\n+                                                    .thenCompose(gtMin -> {\n+                                                        if (gtMin) {\n+                                                            if (limitMax == null) {\n+                                                                return CompletableFuture.completedFuture(lowerBound);\n+                                                            } else {\n+                                                                return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, limitMax.getStreamCut(), lowerBound, context, executor)\n+                                                                                          .thenApply(gtMax -> gtMax ? limitMax.getStreamCut() : lowerBound);\n+                                                            }\n+                                                        } else {\n+                                                            return streamMetadataStore.streamCutStrictlyGreaterThan(scope, stream, lowerBound, limitMin.getStreamCut(), context, executor)\n+                                                                               .thenApply(gt -> gt ? limitMin.getStreamCut() : null);\n+                                                        }\n+                                                    });\n+                             } else {\n+                                 // if min limit is 0 then latest effectively becomes the min. and we truncate at the lowerbound.\n+                                 if (latest != null && policy.getConsumptionLimits().getMinValue() == 0L) {\n+                                     // truncate at the lower bound \n+                                     return CompletableFuture.completedFuture(lowerBound);\n+                                 } else {\n+                                     return CompletableFuture.completedFuture(null);\n+                                 }\n+                             }\n+                         });\n+    }\n+\n+    private Map<Long, Long> computeSubscribersLowerBound(List<Map<StreamSegmentRecord, Long>> subscribers) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkxMTQ5OA=="}, "originalCommit": {"oid": "07c2838e170b5ac7b040ca02680ca3ab32983ab5"}, "originalPosition": 244}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzMTIzOTc5", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-533123979", "createdAt": "2020-11-18T05:56:45Z", "commit": {"oid": "43ed4c9779a615ec60ff036dbabfd6cb411c6394"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzODA1NzIy", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-533805722", "createdAt": "2020-11-18T19:32:14Z", "commit": {"oid": "43ed4c9779a615ec60ff036dbabfd6cb411c6394"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTozMjoxNFrOH1-wcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOTozMjoxNFrOH1-wcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM2NDc4NQ==", "bodyText": "subscribed reader groups. is not a concept that has be introduced.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r526364785", "createdAt": "2020-11-18T19:32:14Z", "author": {"login": "tkaitchuck"}, "path": "client/src/main/java/io/pravega/client/stream/RetentionPolicy.java", "diffHunk": "@@ -57,6 +63,45 @@ public static RetentionPolicy byTime(Duration duration) {\n      * @return Retention policy object.\n      */\n     public static RetentionPolicy bySizeBytes(long size) {\n-        return new RetentionPolicy(RetentionType.SIZE, size);\n+        return RetentionPolicy.builder().retentionType(RetentionType.SIZE).retentionParam(size).build();\n+    }\n+    \n+    /**\n+     * Create a retention policy to configure a stream to truncate a stream\n+     * according to positions of subscribed reader groups.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ed4c9779a615ec60ff036dbabfd6cb411c6394"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed85e6e87e6352f930e8511b9aa0ea67a5fdb2ca", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/ed85e6e87e6352f930e8511b9aa0ea67a5fdb2ca", "committedDate": "2020-09-25T12:46:24Z", "message": "addSubscriber API\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87e256205ee452c8476e2c6e9628bb16f4e3cd60", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/87e256205ee452c8476e2c6e9628bb16f4e3cd60", "committedDate": "2020-09-25T12:51:10Z", "message": "addSubscriber improvements\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c1b623b84e422f7e5a205deeba8e8458e66f5b5", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/8c1b623b84e422f7e5a205deeba8e8458e66f5b5", "committedDate": "2020-09-25T12:51:10Z", "message": "fix tests\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a142f1c701bab038c7a5b307100d9595ff0ed03", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/6a142f1c701bab038c7a5b307100d9595ff0ed03", "committedDate": "2020-09-25T12:51:10Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f60191187da0b5497a930c80a036ed5360621402", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/f60191187da0b5497a930c80a036ed5360621402", "committedDate": "2020-09-25T12:51:10Z", "message": "added code for ControllerImpl\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a548b10373d40fc93641e0d80dded7558320653", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/6a548b10373d40fc93641e0d80dded7558320653", "committedDate": "2020-09-28T06:46:58Z", "message": "RemoveSubscriber API\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "44e62c169ee5af1f133667b558a2e65d933acc72", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/44e62c169ee5af1f133667b558a2e65d933acc72", "committedDate": "2020-09-28T08:26:26Z", "message": "MockController fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a930f49f78b4deea60eb11b46906a57dd1c3fd94", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/a930f49f78b4deea60eb11b46906a57dd1c3fd94", "committedDate": "2020-09-28T09:23:28Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bee195165af3e23c22071a74ddec761f705cb5c4", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/bee195165af3e23c22071a74ddec761f705cb5c4", "committedDate": "2020-09-28T11:31:13Z", "message": "addSubscriber API - changed return status to AddSubscriberStatus\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "177ee53c7e23b410796ca5968721738fad0ee7b3", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/177ee53c7e23b410796ca5968721738fad0ee7b3", "committedDate": "2020-09-29T07:37:12Z", "message": "code review comments\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a2b76724863bd2fa3fbde3e6f3d229c2ea710a1", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/2a2b76724863bd2fa3fbde3e6f3d229c2ea710a1", "committedDate": "2020-09-29T10:58:06Z", "message": "code changes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ed03cf9b0e2c8de69dd3a6464434997894d5ad4", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/8ed03cf9b0e2c8de69dd3a6464434997894d5ad4", "committedDate": "2020-09-29T10:59:45Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7d1238fc2fd4654a7116fbc0b8232ae0bd253fe", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/d7d1238fc2fd4654a7116fbc0b8232ae0bd253fe", "committedDate": "2020-10-01T07:31:41Z", "message": "changes for adding Unit and Integration tests\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e19722ed73646a75a1425e3db5d159a90009a89", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/6e19722ed73646a75a1425e3db5d159a90009a89", "committedDate": "2020-10-01T11:24:04Z", "message": "fix tests and code\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e70bbd60cf389ad9873214cc0a40ee0a41ef23f1", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/e70bbd60cf389ad9873214cc0a40ee0a41ef23f1", "committedDate": "2020-10-01T11:25:54Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcd1a0e135e809b6b8d3e568bfefcf23715c8b0b", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/fcd1a0e135e809b6b8d3e568bfefcf23715c8b0b", "committedDate": "2020-10-01T13:31:08Z", "message": "more tests\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5509932287a56919c52c51a17b893a2ec10ed01c", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/5509932287a56919c52c51a17b893a2ec10ed01c", "committedDate": "2020-10-01T15:09:22Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9619f5b7909ef3b6a382b44f7acc52069406f06", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/f9619f5b7909ef3b6a382b44f7acc52069406f06", "committedDate": "2020-10-05T13:42:57Z", "message": "unit tests fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c7d6afb928dcc9d10575d2a34c8651cbf8eee01", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/3c7d6afb928dcc9d10575d2a34c8651cbf8eee01", "committedDate": "2020-10-05T13:43:01Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ae405ff8556068a73938ee2fe6e67842b02fd02", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/0ae405ff8556068a73938ee2fe6e67842b02fd02", "committedDate": "2020-10-06T12:13:27Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b937fbd11d9ec8c936fcc1c4d23630c4d29ff03e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/b937fbd11d9ec8c936fcc1c4d23630c4d29ff03e", "committedDate": "2020-10-06T12:13:53Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c88c8e06f0ff116ceb457b3cf48eddecabe666c1", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/c88c8e06f0ff116ceb457b3cf48eddecabe666c1", "committedDate": "2020-10-08T12:15:59Z", "message": "code review changes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0776a7e8bab826220d560119bf372beaf0866389", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/0776a7e8bab826220d560119bf372beaf0866389", "committedDate": "2020-10-08T12:16:22Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61e5cbe3f88b32fb0d46eb9ed6be354044d133eb", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/61e5cbe3f88b32fb0d46eb9ed6be354044d133eb", "committedDate": "2020-10-08T16:26:41Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8211fa464a753eee4496d31b38e2cfc25fc1d01", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/e8211fa464a753eee4496d31b38e2cfc25fc1d01", "committedDate": "2020-10-09T06:13:42Z", "message": "unit tests fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c85c47bfd42db4a892e41e5bceb7892afd88c7a7", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/c85c47bfd42db4a892e41e5bceb7892afd88c7a7", "committedDate": "2020-10-09T06:13:57Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc80b9197fc1b3c89fda495bf975276ba4d472f5", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/bc80b9197fc1b3c89fda495bf975276ba4d472f5", "committedDate": "2020-10-09T08:54:46Z", "message": "removeSubscriber fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a69c29e0fbac4eb352c16d30022b4617d3bfbb8d", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/a69c29e0fbac4eb352c16d30022b4617d3bfbb8d", "committedDate": "2020-10-09T09:10:57Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "937971e03571e0d267ed78d5b59155187a65533e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/937971e03571e0d267ed78d5b59155187a65533e", "committedDate": "2020-10-09T14:07:17Z", "message": "updateTruncationStreamCut API\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "272b559ec710b5b6f3d9e354c8a356ae702c919e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/272b559ec710b5b6f3d9e354c8a356ae702c919e", "committedDate": "2020-10-13T09:45:33Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa0492d5a6c966573f0b71c432bffdbfb7720ada", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/fa0492d5a6c966573f0b71c432bffdbfb7720ada", "committedDate": "2020-10-13T10:34:35Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cb28fbe9589c9d4722020f14277e447478de995", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/1cb28fbe9589c9d4722020f14277e447478de995", "committedDate": "2020-10-13T14:29:49Z", "message": "UT for updateTruncationStreamCut\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea8a64a0d485e5cad38a9b1720f9e5a7861345f6", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/ea8a64a0d485e5cad38a9b1720f9e5a7861345f6", "committedDate": "2020-10-13T15:31:38Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68f768bad814f7abf7c31569618937d956d7855d", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/68f768bad814f7abf7c31569618937d956d7855d", "committedDate": "2020-10-14T04:27:28Z", "message": "checkstyle fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b5dd0a852d0906bc453f3c872aff44719fadbec", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/3b5dd0a852d0906bc453f3c872aff44719fadbec", "committedDate": "2020-10-14T04:27:49Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1c891c9de0b6aa9e339046af5ac6caaa541955e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/e1c891c9de0b6aa9e339046af5ac6caaa541955e", "committedDate": "2020-10-14T13:29:38Z", "message": "integration test\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c11ec9961f20efddc94c17f598fdb4c3c692e30", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/5c11ec9961f20efddc94c17f598fdb4c3c692e30", "committedDate": "2020-10-14T17:20:25Z", "message": "unit tests\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c09719267b76164583ecce5043e0a5455ca54b0", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/7c09719267b76164583ecce5043e0a5455ca54b0", "committedDate": "2020-10-15T05:55:07Z", "message": "spotbugsfix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "effae36bd9829f1a753651835dc5bb4dec156d42", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/effae36bd9829f1a753651835dc5bb4dec156d42", "committedDate": "2020-10-15T06:45:28Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "823704278d6c6b4e940451b8664a2b3c0bd826af", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/823704278d6c6b4e940451b8664a2b3c0bd826af", "committedDate": "2020-10-15T11:27:02Z", "message": "test fixes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8836451842d78227808ca3e394657605adb99a7c", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/8836451842d78227808ca3e394657605adb99a7c", "committedDate": "2020-10-16T06:15:36Z", "message": "review comments fixes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5684aa9bdb9791d1a1cb01e270f622d73f3f092", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/b5684aa9bdb9791d1a1cb01e270f622d73f3f092", "committedDate": "2020-10-16T06:15:57Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46a84150a9fe9a23ced359e1a5de643045237f56", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/46a84150a9fe9a23ced359e1a5de643045237f56", "committedDate": "2020-10-16T07:57:11Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45c3fdc9218fb10f21926a2976928d75906e382e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/45c3fdc9218fb10f21926a2976928d75906e382e", "committedDate": "2020-10-16T15:51:19Z", "message": "review comments\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aeeb77797b09bfa4bc927e94831a22519fe39304", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/aeeb77797b09bfa4bc927e94831a22519fe39304", "committedDate": "2020-10-18T17:43:30Z", "message": "change in metadata store for subscribers\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "029baace0a6d6736e5fc5b8935ccde17a0ec20cd", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/029baace0a6d6736e5fc5b8935ccde17a0ec20cd", "committedDate": "2020-10-18T17:43:51Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d017febc8eb30b8519f898b8666cbd487a77ed9", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/4d017febc8eb30b8519f898b8666cbd487a77ed9", "committedDate": "2020-10-19T13:09:47Z", "message": "code review changes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d516a49a1ab31559fcf91016f698a248cab0a9c", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/6d516a49a1ab31559fcf91016f698a248cab0a9c", "committedDate": "2020-10-19T13:20:06Z", "message": "fixed ZKStream\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "569638a58f636921f4df3472fa192184d5119840", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/569638a58f636921f4df3472fa192184d5119840", "committedDate": "2020-10-19T13:33:23Z", "message": "code review comments\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad1dca5cf0c3d81b6a9802158be56ccb0e1ec0bf", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/ad1dca5cf0c3d81b6a9802158be56ccb0e1ec0bf", "committedDate": "2020-10-19T13:35:13Z", "message": "checkstyle\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ffa5f7c3fc8bb3a95807f5a5a6de02d95ef86de6", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/ffa5f7c3fc8bb3a95807f5a5a6de02d95ef86de6", "committedDate": "2020-10-21T11:26:18Z", "message": "tmp\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5884f972dfde247955a1c725b6f0d5d66fda3b8", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/c5884f972dfde247955a1c725b6f0d5d66fda3b8", "committedDate": "2020-10-27T03:56:30Z", "message": "impl\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "599552583b49fee6363b872f3932683a847e6eea", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/599552583b49fee6363b872f3932683a847e6eea", "committedDate": "2020-10-27T04:18:52Z", "message": "impl\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24dbe85714d4ca3ae894c171ef480877649e03d1", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/24dbe85714d4ca3ae894c171ef480877649e03d1", "committedDate": "2020-10-27T04:48:17Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8eae5539388050d4428e9e37c39412767b20bcd0", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/8eae5539388050d4428e9e37c39412767b20bcd0", "committedDate": "2020-10-27T13:28:17Z", "message": "binary sarch\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "077b6ca52732d08994e2c4f4c2731de3c841706e", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/077b6ca52732d08994e2c4f4c2731de3c841706e", "committedDate": "2020-10-27T13:28:34Z", "message": "code review changes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a2f6ed872d0b53b4cab3db98f95504543bf1490", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/0a2f6ed872d0b53b4cab3db98f95504543bf1490", "committedDate": "2020-10-27T16:54:54Z", "message": "tmp\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec9c7ca93fb75e6e93ad79f12cbdde3170d3c441", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/ec9c7ca93fb75e6e93ad79f12cbdde3170d3c441", "committedDate": "2020-10-27T19:12:13Z", "message": "impl complete\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "992fddf19a005454bc392a3f0d9b20b32f4f33c4", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/992fddf19a005454bc392a3f0d9b20b32f4f33c4", "committedDate": "2020-10-27T19:25:35Z", "message": "checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e74dd30bf8761af259eef2c4eaaa25a780ef51f", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/7e74dd30bf8761af259eef2c4eaaa25a780ef51f", "committedDate": "2020-10-28T03:07:40Z", "message": "rest\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e691c5135b5d42685265095ea00b726a87bb67f", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/6e691c5135b5d42685265095ea00b726a87bb67f", "committedDate": "2020-10-28T03:18:53Z", "message": "Merge branch 'master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90aa383f4aafc3391b97d1278dd023db9b12aa0a", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/90aa383f4aafc3391b97d1278dd023db9b12aa0a", "committedDate": "2020-10-28T03:24:38Z", "message": "rest model\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e156e1ebb4290471f062c2f992cfa7602816d3d3", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/e156e1ebb4290471f062c2f992cfa7602816d3d3", "committedDate": "2020-10-28T03:26:09Z", "message": "Merge branch 'CBR' into CBR-controller"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e50608046fc3b464d92166abaefa5efb96a79ba", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/3e50608046fc3b464d92166abaefa5efb96a79ba", "committedDate": "2020-10-28T06:08:06Z", "message": "simplest test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6e066829a2af649d5e7697df43d9b21e9a28471", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/a6e066829a2af649d5e7697df43d9b21e9a28471", "committedDate": "2020-10-28T08:46:49Z", "message": "test fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8ea150b0f5d3aaa29db18dc2cde7d0b6c9e23e6", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/e8ea150b0f5d3aaa29db18dc2cde7d0b6c9e23e6", "committedDate": "2020-10-28T08:47:46Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f68ad98a230256cc90007f929ebd0d59bdbd9144", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/f68ad98a230256cc90007f929ebd0d59bdbd9144", "committedDate": "2020-10-28T08:58:18Z", "message": "basic unit test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "126b59c542667ced7cb858624c77e4fbf9b2202f", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/126b59c542667ced7cb858624c77e4fbf9b2202f", "committedDate": "2020-10-28T09:20:22Z", "message": "tests fixed\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fad11d00e71200a9586c4d5462d5aae76ec73c5", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/5fad11d00e71200a9586c4d5462d5aae76ec73c5", "committedDate": "2020-10-28T09:56:33Z", "message": "test case fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "620bbd7fe32186a1b8d920d0ee3ef5e6ac227bc8", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/620bbd7fe32186a1b8d920d0ee3ef5e6ac227bc8", "committedDate": "2020-10-29T05:59:56Z", "message": "tests fix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f656e88700c79f1fac2fa8efd1f980fa779728b", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/4f656e88700c79f1fac2fa8efd1f980fa779728b", "committedDate": "2020-10-29T06:00:22Z", "message": "Merge remote-tracking branch 'upstream/master' into issue-5109-subscriber-rg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e48f7bd405ba9463f85d08e8e496b2dbae2d8063", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/e48f7bd405ba9463f85d08e8e496b2dbae2d8063", "committedDate": "2020-10-29T06:54:44Z", "message": "code coverage\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66279487aa0d449c4ca21a14cc1237a971e01df7", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/66279487aa0d449c4ca21a14cc1237a971e01df7", "committedDate": "2020-10-29T07:31:20Z", "message": "isvalid check\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff9c62646b17c210ee0cfe6705b502a8fddf5eea", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/ff9c62646b17c210ee0cfe6705b502a8fddf5eea", "committedDate": "2020-10-29T07:50:54Z", "message": "temp\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ccbd1a3e7d17c7e70691717238f577999908f65", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/2ccbd1a3e7d17c7e70691717238f577999908f65", "committedDate": "2020-10-29T07:51:38Z", "message": "Merge branch 'issue-5109-subscriber-rg' of https://github.com/pbelgundi/pravega into CBR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7f4ede362ff2e1f448e76cea1de0a02fa1bc209", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/a7f4ede362ff2e1f448e76cea1de0a02fa1bc209", "committedDate": "2020-10-29T07:51:49Z", "message": "Merge branch 'CBR' into CBR-controller"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf4a64eaa88d46a03710b72991f3a63bf66a5993", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/bf4a64eaa88d46a03710b72991f3a63bf66a5993", "committedDate": "2020-10-29T09:44:11Z", "message": "test fixes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16e95c00f9de8287956c63decd66d21b59cc83e2", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/16e95c00f9de8287956c63decd66d21b59cc83e2", "committedDate": "2020-10-29T09:58:40Z", "message": "minor change\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "60b87d267bd4e386204b4cc0f4c394d81b1d8109", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/60b87d267bd4e386204b4cc0f4c394d81b1d8109", "committedDate": "2020-10-29T12:22:12Z", "message": "checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87507fe816c44f9ea2241a9a8ccc544f45473c95", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/87507fe816c44f9ea2241a9a8ccc544f45473c95", "committedDate": "2020-10-29T16:14:48Z", "message": "failing test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f677facaca33ded934c7abd24707104584de0637", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/f677facaca33ded934c7abd24707104584de0637", "committedDate": "2020-10-29T16:38:56Z", "message": "unit tes\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "917431851590738fe79a65bf26c28645f703decc", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/917431851590738fe79a65bf26c28645f703decc", "committedDate": "2020-10-30T02:18:25Z", "message": "lower bound computation\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bfc8c858ef6c5b8ca2a623b0c3862ad9340c6efe", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/bfc8c858ef6c5b8ca2a623b0c3862ad9340c6efe", "committedDate": "2020-10-30T04:26:24Z", "message": "review fixes\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a031a9e49d51ba0a6dcc57be635c5e1fc295aab", "author": {"user": {"login": "pbelgundi", "name": "Prajakta Belgundi"}}, "url": "https://github.com/pravega/pravega/commit/9a031a9e49d51ba0a6dcc57be635c5e1fc295aab", "committedDate": "2020-10-30T04:52:04Z", "message": "testfix\n\nSigned-off-by: pbelgundi <prajakta.belgundi@emc.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84ff32ab51e1012faf945b6d6bf6db2f7e63574f", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/84ff32ab51e1012faf945b6d6bf6db2f7e63574f", "committedDate": "2020-10-30T06:31:18Z", "message": "more complex unit test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9deaab4abb33e731d859910ebaae8df1c4c65ddc", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/9deaab4abb33e731d859910ebaae8df1c4c65ddc", "committedDate": "2020-10-30T06:40:40Z", "message": "unit test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e7cfe3cca62d1b1e12906ffc971c8e1a3d30deb", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/2e7cfe3cca62d1b1e12906ffc971c8e1a3d30deb", "committedDate": "2020-10-30T06:41:00Z", "message": "Merge branch 'issue-5109-subscriber-rg' of https://github.com/pbelgundi/pravega into CBR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fd5bf786453a693b9f5e0c3eef0ce7c1bf03606", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/6fd5bf786453a693b9f5e0c3eef0ce7c1bf03606", "committedDate": "2020-10-30T07:35:04Z", "message": "merge\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e60fa106056075433f40a6a50b483eddb61ca04a", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/e60fa106056075433f40a6a50b483eddb61ca04a", "committedDate": "2020-10-30T07:38:56Z", "message": "checkstyle\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80f5ded254595f3571821d3af8d39e8da6064864", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/80f5ded254595f3571821d3af8d39e8da6064864", "committedDate": "2020-10-30T08:03:57Z", "message": "test\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ab89ac6c92cb8ef1c9618414904c5270f08eab4", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/9ab89ac6c92cb8ef1c9618414904c5270f08eab4", "committedDate": "2020-10-30T08:17:29Z", "message": "Merge with master\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f512c735a13a0e90a46a047b6b0e694f48f9139", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/7f512c735a13a0e90a46a047b6b0e694f48f9139", "committedDate": "2020-11-02T02:51:23Z", "message": "remove merge flags\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "346a0753b7a505453cdb79f2ff82bf53b530137e", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/346a0753b7a505453cdb79f2ff82bf53b530137e", "committedDate": "2020-11-02T03:37:46Z", "message": "NPE\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/97717a9384ff8c460ad2c3b83774587ebbdc27b9", "committedDate": "2020-11-02T04:00:36Z", "message": "rename proto enum\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMzYwMzA1", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-521360305", "createdAt": "2020-11-02T06:36:35Z", "commit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNjozNjozNVrOHr3wBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNzoxMToyOFrOHr4XPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc2NDIyOQ==", "bodyText": "TIME_MINUTES enum mapping to TIME_MILLS String value... looks like a typo to me.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515764229", "createdAt": "2020-11-02T06:36:35Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/server/rest/generated/model/ConsumptionLimits.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Pravega Controller APIs\n+ * List of admin REST APIs for the pravega controller service.\n+ *\n+ * OpenAPI spec version: 0.0.1\n+ *\n+ *\n+ * NOTE: This class is auto generated by the swagger code generator program.\n+ * https://github.com/swagger-api/swagger-codegen.git\n+ * Do not edit the class manually.\n+ */\n+\n+\n+\n+package io.pravega.controller.server.rest.generated.model;\n+\n+import java.util.Objects;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.swagger.annotations.ApiModel;\n+import io.swagger.annotations.ApiModelProperty;\n+\n+\n+\n+\n+/**\n+ * ConsumptionLimits\n+ */\n+\n+public class ConsumptionLimits   {\n+  /**\n+   * Indicates if consumption limits is by space or time.\n+   */\n+  public enum TypeEnum {\n+    SIZE_MB(\"SIZE_MB\"),\n+    \n+    TIME_MINUTES(\"TIME_MILLIS\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc2NjMyNA==", "bodyText": "These 4 lines are repeated in 3 different methods in this class, perhaps we could encapsulate them in a private method?", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515766324", "createdAt": "2020-11-02T06:44:04Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/PersistentStreamBase.java", "diffHunk": "@@ -164,20 +166,24 @@ public String getScopeName() {\n                 .thenCompose(existing -> {\n                     Preconditions.checkNotNull(existing);\n                     Preconditions.checkArgument(!existing.getObject().isUpdating());\n-                    return isStreamCutValid(streamCut)\n-                        .thenCompose(isValid -> {\n+                    long mostRecent = streamCut.keySet().stream().max(Comparator.naturalOrder()).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3MTgxOQ==", "bodyText": "span2 will never be equal to CompletableFuture.completedFuture(ImmutableMap.of()) becuase if previousStreamCut.isEmpty=true, that case is already handled in the if block.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515771819", "createdAt": "2020-11-02T07:03:24Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/PersistentStreamBase.java", "diffHunk": "@@ -634,75 +734,183 @@ private long findSegmentSplitsMerges(List<StreamSegmentRecord> referenceSegments\n         int epochHigh = NameUtils.getEpoch(mostRecent);\n \n         return fetchEpochs(epochLow, epochHigh, true).thenApply(epochs ->  {\n-            List<Long> toFind = new ArrayList<>(streamCut.keySet());\n-            ImmutableMap.Builder<StreamSegmentRecord, Integer> resultSet = ImmutableMap.builder();\n-            for (int i = epochHigh - epochLow; i >= 0; i--) {\n-                if (toFind.isEmpty()) {\n-                    break;\n-                }\n-                EpochRecord epochRecord = epochs.get(i);\n-                Set<Long> epochSegments = epochRecord.getSegmentIds();\n-                List<Long> found = toFind.stream().filter(epochSegments::contains).collect(Collectors.toList());\n-                resultSet.putAll(found.stream().collect(\n-                        Collectors.toMap(x -> epochRecord.getSegments().stream().filter(z -> z.segmentId() == x).findFirst().get(),\n-                                x -> epochRecord.getEpoch())));\n-\n-                toFind.removeAll(epochSegments);\n-            }\n-            return resultSet.build();\n+            return computeStreamCutSpanInternal(streamCut, epochLow, epochHigh, epochs);\n         });\n     }\n \n+    private ImmutableMap<StreamSegmentRecord, Integer> computeStreamCutSpanInternal(Map<Long, Long> streamCut, int epochLow, \n+                                                                                    int epochHigh, List<EpochRecord> epochs) {\n+        List<Long> toFind = new ArrayList<>(streamCut.keySet());\n+        ImmutableMap.Builder<StreamSegmentRecord, Integer> resultSet = ImmutableMap.builder();\n+        for (int i = epochHigh - epochLow; i >= 0; i--) {\n+            if (toFind.isEmpty()) {\n+                break;\n+            }\n+            EpochRecord epochRecord = epochs.get(i);\n+            Set<Long> epochSegments = epochRecord.getSegmentIds();\n+            List<Long> found = toFind.stream().filter(epochSegments::contains).collect(Collectors.toList());\n+            resultSet.putAll(found.stream().collect(\n+                    Collectors.toMap(x -> epochRecord.getSegments().stream().filter(z -> z.segmentId() == x).findFirst().get(),\n+                            x -> epochRecord.getEpoch())));\n+\n+            toFind.removeAll(epochSegments);\n+        }\n+        return resultSet.build();\n+    }\n+\n     @Override\n     public CompletableFuture<Boolean> isStreamCutValid(Map<Long, Long> streamCut) {\n-        Map<Integer, List<Long>> groupByEpoch = streamCut.keySet().stream().collect(groupingBy(NameUtils::getEpoch));\n-\n-        CompletableFuture<List<List<Map.Entry<Double, Double>>>> segmentRangesByEpoch = Futures.allOfWithResults(groupByEpoch.entrySet().stream().map(epochGroup -> {\n-            return getEpochRecord(epochGroup.getKey())\n-                    .thenApply(epochRecord -> {\n-                        return epochGroup.getValue().stream().map(segmentId -> {\n-                            StreamSegmentRecord segment = epochRecord.getSegment(segmentId);\n-                            return (Map.Entry<Double, Double>) new SimpleEntry<>(segment.getKeyStart(), segment.getKeyEnd());\n-                        }).collect(Collectors.toList());\n-                    });\n-        }).collect(Collectors.toList()));\n+        long mostRecent = streamCut.keySet().stream().max(Comparator.naturalOrder()).get();\n+        long oldest = streamCut.keySet().stream().min(Comparator.naturalOrder()).get();\n+        int epochLow = NameUtils.getEpoch(oldest);\n+        int epochHigh = NameUtils.getEpoch(mostRecent);\n \n-        CompletableFuture<List<Map.Entry<Double, Double>>> segmentRangesFlattened = segmentRangesByEpoch\n-                .thenApply(listOfList -> listOfList.stream().flatMap(Collection::stream).collect(Collectors.toList()));\n-        \n-        return segmentRangesFlattened\n-                      .thenAccept(x -> RecordHelper.validateStreamCut(new ArrayList<>(x)))\n-                      .handle((r, e) -> {\n-                          if (e != null) {\n-                              if (Exceptions.unwrap(e) instanceof IllegalArgumentException) {\n-                                  return false;\n-                              } else {\n-                                  log.warn(\"Exception while trying to validate a stream cut for stream {}/{}\", scope, name);\n-                                  throw Exceptions.sneakyThrow(e);\n-                              }\n-                          } else {\n-                              return true;\n-                          }\n-                      });\n+        return fetchEpochs(epochLow, epochHigh, true).thenApply(epochs -> isStreamCutValidInternal(streamCut, epochLow, epochs));\n+    }\n+\n+    private boolean isStreamCutValidInternal(Map<Long, Long> streamCut, int epochLow, List<EpochRecord> epochs) {\n+        Set<StreamSegmentRecord> segmentsInStreamCut = new HashSet<>();\n+        Set<StreamSegmentRecord> futureSegment = new HashSet<>();\n+\n+        boolean isValid = true;\n+        // for each segment get its epoch and the segment record\n+        streamCut.forEach((key, value) -> {\n+            int epoch = NameUtils.getEpoch(key);\n+            int index = epoch - epochLow;\n+            EpochRecord epochRecord = epochs.get(index);\n+            StreamSegmentRecord segmentRecord = epochRecord.getSegment(key);\n+            if (value < 0) {\n+                futureSegment.add(segmentRecord);\n+            } else {\n+                segmentsInStreamCut.add(segmentRecord);\n+            }\n+        });\n+\n+        isValid = futureSegment.stream().allMatch(x -> \n+                segmentsInStreamCut.stream().filter(y -> y.overlaps(x)).allMatch(y -> y.segmentId() < x.segmentId()));\n+\n+        if (isValid) {\n+            List<StreamSegmentRecord> sorted = segmentsInStreamCut\n+                    .stream().sorted(Comparator.comparingDouble(StreamSegmentRecord::getKeyStart)).collect(Collectors.toList());\n+\n+            // all future segments should have a predecessor and all missing ranges should be covered by a future segment. \n+            Map<Double, Double> missingRanges = new HashMap<>();\n+\n+            StreamSegmentRecord previous = sorted.get(0);\n+            BiFunction<Double, Double, Boolean> validate = (start, end) -> futureSegment.stream().anyMatch(x -> x.overlaps(start, end));\n+\n+            if (previous.getKeyStart() > 0.0) {\n+                double start = 0.0;\n+                double end = previous.getKeyStart();\n+                missingRanges.put(start, end);\n+                // missing range should be covered by a future segment\n+                isValid = validate.apply(start, end);\n+            }\n+\n+            for (int i = 1; i < sorted.size(); i++) {\n+                StreamSegmentRecord next = sorted.get(i);\n+                if (previous.getKeyEnd() < next.getKeyStart()) {\n+                    double start = previous.getKeyEnd();\n+                    double end = next.getKeyStart();\n+                    missingRanges.put(start, end);\n+                    //  missing range should be covered by a future segment\n+                    isValid = validate.apply(start, end);\n+                    if (!isValid) {\n+                        break;\n+                    }\n+                } else if (previous.getKeyEnd() > next.getKeyStart()) {\n+                    isValid = false;\n+                    break;\n+                }\n+                previous = next;\n+            }\n+\n+            if (previous.getKeyEnd() < 1.0) {\n+                double start = previous.getKeyEnd();\n+                double end = 1.0;\n+                missingRanges.put(start, end);\n+                isValid = validate.apply(start, end);\n+            }\n+\n+            if (isValid) {\n+                List<StreamSegmentRecord> toCheck = new ArrayList<>();\n+                Set<StreamSegmentRecord> fullyReadFrom = new HashSet<>();\n+\n+                // now traverse the stream for missing ranges and verify that we can reach those future segments \n+                // in logically consistent fashion for the missing ranges. \n+                missingRanges.entrySet().forEach(x -> toCheck.addAll(findSegmentsForMissingRange(epochs.get(0), x)));\n+                while (!toCheck.isEmpty()) {\n+                    StreamSegmentRecord segmentRecord = toCheck.get(0);\n+                    if (!(fullyReadFrom.contains(segmentRecord) || segmentsInStreamCut.contains(segmentRecord) ||\n+                            futureSegment.contains(segmentRecord))) {\n+                        for (StreamSegmentRecord s : segmentsInStreamCut) {\n+                            if (s.overlaps(segmentRecord)) {\n+                                if (s.segmentId() < segmentRecord.segmentId()) {\n+                                    // if segment record has a predecessor, then it should have been in future segment.  \n+                                    if (!futureSegment.contains(segmentRecord)) {\n+                                        return false;\n+                                    } else {\n+                                        // segment record is a predecessor of a previous segment. \n+                                        fullyReadFrom.add(segmentRecord);\n+                                    }\n+                                } else {\n+                                    // if segment is predecessor of another segment in the stream cut then it has to be \n+                                    // fully read \n+                                    fullyReadFrom.add(segmentRecord);\n+                                    // find successors of segmentRecord and add it to tocheck list\n+                                    int segmentEpoch = NameUtils.getEpoch(segmentRecord.segmentId());\n+                                    int index = segmentEpoch - epochLow;\n+                                    for (int i = index; i < epochs.size(); i++) {\n+                                        if (!epochs.get(i).containsSegment(segmentRecord.segmentId())) {\n+                                            epochs.get(i).getSegments().forEach(x -> {\n+                                                if (x.overlaps(segmentRecord)) {\n+                                                    toCheck.add(x);\n+                                                }\n+                                            });\n+                                            break;\n+                                        }\n+                                    }\n+                                }\n+                            }\n+                        }\n+                    }\n+\n+                    toCheck.remove(segmentRecord);\n+                }\n+            }\n+        }\n+        return isValid;\n+    }\n+    \n+    private List<StreamSegmentRecord> findSegmentsForMissingRange(EpochRecord epochRecord, Map.Entry<Double, Double> missingRange) {\n+        return epochRecord.getSegments().stream().filter(x -> x.overlaps(missingRange.getKey(), missingRange.getValue()))\n+                          .collect(Collectors.toList());\n     }\n \n     private CompletableFuture<Boolean> isStreamCutValidForTruncation(Map<Long, Long> previousStreamCut, final Map<Long, Long> streamCut) {\n         if (previousStreamCut.isEmpty()) {\n             return isStreamCutValid(streamCut);\n         } else {\n             return isStreamCutValid(streamCut)\n-                    .thenCompose( isValidStreamCut -> {\n+                    .thenCompose(isValidStreamCut -> {\n                         if (isValidStreamCut) {\n-                            return computeStreamCutSpan(streamCut)\n-                                    .thenCompose(span -> computeStreamCutSpan(previousStreamCut)\n-                                            .thenApply(previousSpan -> greaterThan(streamCut, span, previousStreamCut, previousSpan)));\n+                            CompletableFuture<ImmutableMap<StreamSegmentRecord, Integer>> span1 = computeStreamCutSpan(streamCut);\n+                            CompletableFuture<ImmutableMap<StreamSegmentRecord, Integer>> span2 = previousStreamCut.isEmpty() ?\n+                                    CompletableFuture.completedFuture(ImmutableMap.of()) : computeStreamCutSpan(previousStreamCut);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 402}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3MjEyMg==", "bodyText": "method name should be isStreamCutStrictlyGreaterThan since it returns a boolean.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515772122", "createdAt": "2020-11-02T07:04:23Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/Stream.java", "diffHunk": "@@ -680,4 +680,22 @@\n      * @return Completable future that, upon completion, holds the epoch in which the segment was sealed.\n      */\n     CompletableFuture<Integer> getSegmentSealedEpoch(long segmentId);\n+\n+    /**\n+     * Method to compare streamcuts to check if streamcut1 is strictly ahead of streamcut2. \n+     * @param cut1 streamcut to check\n+     * @param cut2 streamcut to check against. \n+     *\n+     * @return CompletableFuture which, upon completion, will indicate if the streamcut1 is strictly ahead of streamcut2.\n+     */\n+    CompletableFuture<Boolean> streamCutStrictlyGreaterThan(Map<Long, Long> cut1, Map<Long, Long> cut2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3MzE0NQ==", "bodyText": "What is meant by \"strictly\" here? Would be good to explain that in the javadoc", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515773145", "createdAt": "2020-11-02T07:07:49Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/store/stream/StreamMetadataStore.java", "diffHunk": "@@ -1276,4 +1276,40 @@\n     CompletableFuture<Integer> getSegmentSealedEpoch(final String scope, final String streamName, final long segmentId,\n                                                      final OperationContext context, final Executor executor);\n \n+    /**\n+     * Compares two Stream cuts and returns true if streamcut1 is strictly ahead of streamcut2 else returns false. \n+     * This method will return false for both strictly less than and overlapping streamcuts.\n+     * A streamcut is considered greater than if for all key ranges the segment/offset in one streamcut is ahead of \n+     * second streamcut. \n+     *\n+     * @param scope      stream scope.\n+     * @param streamName stream name.\n+     * @param streamCut1 Stream cut to check\n+     * @param streamCut2 Streamcut to check against\n+     * @param context    operation context.\n+     * @param executor   callers executor.\n+     *                   \n+     * @return A completable future which when completed will hold a boolean which will indicate if streamcut1 is strictly\n+     * ahead of streamcut2. \n+     */\n+    CompletableFuture<Boolean> streamCutStrictlyGreaterThan(final String scope, final String streamName,\n+                                                            Map<Long, Long> streamCut1, Map<Long, Long> streamCut2,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3NDI2OA==", "bodyText": "Here, UNKNOWN perhaps means we don;t set a limit for CBR. Could we call it NONE instead of UNKNOWN?", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515774268", "createdAt": "2020-11-02T07:11:28Z", "author": {"login": "pbelgundi"}, "path": "shared/controller-api/src/main/proto/Controller.proto", "diffHunk": "@@ -298,9 +298,22 @@ message RetentionPolicy {\n         UNKNOWN = 0;\n         TIME = 1;\n         SIZE = 2;\n+        CONSUMPTION = 3;\n     }\n     RetentionPolicyType retentionType = 1;\n     int64 retentionParam = 2;\n+    ConsumptionLimits consumptionLimits = 3;\n+}\n+\n+message ConsumptionLimits {\n+    enum ConsumptionLimitType {\n+        UNKNOWN = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxMzc1MzI2", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-521375326", "createdAt": "2020-11-02T07:16:19Z", "commit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNzoxNjozM1rOHr4eGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwNzoxNjozM1rOHr4eGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3NjAyNw==", "bodyText": "ConsumptionLimit.UNKNOWN is not covered here. That is a valid usecase and should not throw \"NotImplementedException\"", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r515776027", "createdAt": "2020-11-02T07:16:33Z", "author": {"login": "pbelgundi"}, "path": "controller/src/main/java/io/pravega/controller/server/rest/ModelHelper.java", "diffHunk": "@@ -70,6 +80,24 @@ public static final StreamConfiguration getCreateStreamConfig(final CreateStream\n                 .build();\n     }\n \n+    private static RetentionPolicy getConsumptionRetentionPolicy(ConsumptionLimits consumptionLimits) {\n+        RetentionPolicy.ConsumptionLimits.Type type;\n+        int multiplier;\n+        switch (consumptionLimits.getType()) {\n+            case SIZE_MB:\n+                type = RetentionPolicy.ConsumptionLimits.Type.SIZE_BYTES;\n+                multiplier = BYTES_TO_MB;\n+                break;\n+            case TIME_MINUTES:\n+                type = RetentionPolicy.ConsumptionLimits.Type.TIME_MILLIS;\n+                multiplier = MILLIS_TO_MINUTES;\n+                break;\n+            default:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f920561301bf485d0a44204902cac7ba563de661", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/f920561301bf485d0a44204902cac7ba563de661", "committedDate": "2020-11-02T15:58:53Z", "message": "unit test for time based limits\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ec0c1b35335563953bc378d81ea28b18a01d7db", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/9ec0c1b35335563953bc378d81ea28b18a01d7db", "committedDate": "2020-11-03T06:34:26Z", "message": "PR comments\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2", "author": {"user": {"login": "shiveshr", "name": "shivesh ranjan"}}, "url": "https://github.com/pravega/pravega/commit/7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2", "committedDate": "2020-11-03T07:04:04Z", "message": "build\n\nSigned-off-by: Shivesh Ranjan <shivesh.ranjan@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3MTAxMTcz", "url": "https://github.com/pravega/pravega/pull/5289#pullrequestreview-527101173", "createdAt": "2020-11-10T11:18:22Z", "commit": {"oid": "7ee349a4a1b3d67ab0224c4f33e3a8c958adf7c2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMToxOToxNlrOHwX8nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxMToxOToxNlrOHwX8nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ4NjA0NA==", "bodyText": "UNKNOWN = 0 in protobuf allows future safety of enums evolution .. when reading a protobuf message using an older enum schema, any enum that is not understood is set to unknown.\nif we want to support NONE, that should be a separate enum value. if you think we want to support \"none\" i could add that. but logically none is equivalent to providing limits as null.\n\nOkay.", "url": "https://github.com/pravega/pravega/pull/5289#discussion_r520486044", "createdAt": "2020-11-10T11:19:16Z", "author": {"login": "pbelgundi"}, "path": "shared/controller-api/src/main/proto/Controller.proto", "diffHunk": "@@ -298,9 +298,22 @@ message RetentionPolicy {\n         UNKNOWN = 0;\n         TIME = 1;\n         SIZE = 2;\n+        CONSUMPTION = 3;\n     }\n     RetentionPolicyType retentionType = 1;\n     int64 retentionParam = 2;\n+    ConsumptionLimits consumptionLimits = 3;\n+}\n+\n+message ConsumptionLimits {\n+    enum ConsumptionLimitType {\n+        UNKNOWN = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc3NDI2OA=="}, "originalCommit": {"oid": "97717a9384ff8c460ad2c3b83774587ebbdc27b9"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3691, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}