{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4ODY3MzQ5", "number": 622, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwODo1NDowN1rOEb-Ilw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNzo0MTowNlrOEpIymg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NzY1MDE1OnYy", "diffSide": "RIGHT", "path": "test/print_env_info.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwODo1NDowN1rOHGOS8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODo0OTo1N1rOHhI04A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI4NzczMA==", "bodyText": "Name it torchserve_env . In namedtuple as well.", "url": "https://github.com/pytorch/serve/pull/622#discussion_r476287730", "createdAt": "2020-08-25T08:54:07Z", "author": {"login": "dhaniram-kshirsagar"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,373 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+# System Environment Information\n+SystemEnv = namedtuple('SystemEnv', [", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97864f1a3c25092d5ac05d6e2d5b9433acf87e44"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwOTY2NA==", "bodyText": "Done.", "url": "https://github.com/pytorch/serve/pull/622#discussion_r504509664", "createdAt": "2020-10-14T08:49:57Z", "author": {"login": "harshbafna"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,373 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+# System Environment Information\n+SystemEnv = namedtuple('SystemEnv', [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI4NzczMA=="}, "originalCommit": {"oid": "97864f1a3c25092d5ac05d6e2d5b9433acf87e44"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNTY3MDc4OnYy", "diffSide": "RIGHT", "path": "test/regression_tests.sh", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNzoyOTo0N1rOHaoKtg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODo0ODo0MlrOHhIxNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4MzEyNg==", "bodyText": "Why are we removing the option to provide a custom branch? It will be helpful to have this option if I want to run regression suite on a standalone basis", "url": "https://github.com/pytorch/serve/pull/622#discussion_r497683126", "createdAt": "2020-09-30T17:29:47Z", "author": {"login": "maaquib"}, "path": "test/regression_tests.sh", "diffHunk": "@@ -4,7 +4,7 @@ set -x\n #set -e\n \n TS_REPO=\"https://github.com/pytorch/serve\"\n-BRANCH=${1:-master}\n+BRANCH=\"master\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUwODcyNw==", "bodyText": "This was buggy, we have already enhanced the script to take branch name as argument, else the default value will be \"master\"", "url": "https://github.com/pytorch/serve/pull/622#discussion_r504508727", "createdAt": "2020-10-14T08:48:42Z", "author": {"login": "harshbafna"}, "path": "test/regression_tests.sh", "diffHunk": "@@ -4,7 +4,7 @@ set -x\n #set -e\n \n TS_REPO=\"https://github.com/pytorch/serve\"\n-BRANCH=${1:-master}\n+BRANCH=\"master\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4MzEyNg=="}, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNTY5NDEzOnYy", "diffSide": "RIGHT", "path": "test/print_env_info.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNzozNjozM1rOHaoZjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODo1MToyNlrOHhI5Aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4NjkyNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            def get_gpu_info(run):\n          \n          \n            \n            def get_nvidia_gpu_info(run):", "url": "https://github.com/pytorch/serve/pull/622#discussion_r497686924", "createdAt": "2020-09-30T17:36:33Z", "author": {"login": "maaquib"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUxMDcyMw==", "bodyText": "Done.", "url": "https://github.com/pytorch/serve/pull/622#discussion_r504510723", "createdAt": "2020-10-14T08:51:26Z", "author": {"login": "harshbafna"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4NjkyNA=="}, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNTY5OTUyOnYy", "diffSide": "RIGHT", "path": "test/print_env_info.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNzozODowMFrOHaoc8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODo1MTo0N1rOHhI6BA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4Nzc5NA==", "bodyText": "Why is this a function?", "url": "https://github.com/pytorch/serve/pull/622#discussion_r497687794", "createdAt": "2020-09-30T17:38:00Z", "author": {"login": "maaquib"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):\n+    if get_platform() == 'darwin':\n+        if TORCH_AVAILABLE and torch.cuda.is_available():\n+            return torch.cuda.get_device_name(None)\n+        return None\n+    smi = get_nvidia_smi()\n+    uuid_regex = re.compile(r' \\(UUID: .+?\\)')\n+    rc, out, _ = run(smi + ' -L')\n+    if rc != 0:\n+        return None\n+    # Anonymize GPUs by removing their UUID\n+    return \"\\n\" + re.sub(uuid_regex, '', out)\n+\n+def get_running_cuda_version(run):\n+    return run_and_parse_first_match(run, 'nvcc --version', r'V(.*)$')\n+\n+def get_cudnn_version(run):\n+    \"\"\"This will return a list of libcudnn.so; it's hard to tell which one is being used\"\"\"\n+    if get_platform() == 'darwin':\n+        # CUDA libraries and drivers can be found in /usr/local/cuda/. See\n+        cudnn_cmd = 'ls /usr/local/cuda/lib/libcudnn*'\n+    else:\n+        cudnn_cmd = 'ldconfig -p | grep libcudnn | rev | cut -d\" \" -f1 | rev'\n+    rc, out, _ = run(cudnn_cmd)\n+    # find will return 1 if there are permission errors or if not found\n+    if len(out) == 0 or (rc != 1 and rc != 0):\n+        l = os.environ.get('CUDNN_LIBRARY')\n+        if l is not None and os.path.isfile(l):\n+            return os.path.realpath(l)\n+        return None\n+    files = set()\n+    for fn in out.split('\\n'):\n+        fn = os.path.realpath(fn)  # eliminate symbolic links\n+        if os.path.isfile(fn):\n+            files.add(fn)\n+    if not files:\n+        return None\n+    # Alphabetize the result because the order is non-deterministic otherwise\n+    files = list(sorted(files))\n+    if len(files) == 1:\n+        return files[0]\n+    result = '\\n'.join(files)\n+    return 'Probably one of the following:\\n{}'.format(result)\n+\n+def get_nvidia_smi():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUxMDk4MA==", "bodyText": "Moved to module-level variable,", "url": "https://github.com/pytorch/serve/pull/622#discussion_r504510980", "createdAt": "2020-10-14T08:51:47Z", "author": {"login": "harshbafna"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):\n+    if get_platform() == 'darwin':\n+        if TORCH_AVAILABLE and torch.cuda.is_available():\n+            return torch.cuda.get_device_name(None)\n+        return None\n+    smi = get_nvidia_smi()\n+    uuid_regex = re.compile(r' \\(UUID: .+?\\)')\n+    rc, out, _ = run(smi + ' -L')\n+    if rc != 0:\n+        return None\n+    # Anonymize GPUs by removing their UUID\n+    return \"\\n\" + re.sub(uuid_regex, '', out)\n+\n+def get_running_cuda_version(run):\n+    return run_and_parse_first_match(run, 'nvcc --version', r'V(.*)$')\n+\n+def get_cudnn_version(run):\n+    \"\"\"This will return a list of libcudnn.so; it's hard to tell which one is being used\"\"\"\n+    if get_platform() == 'darwin':\n+        # CUDA libraries and drivers can be found in /usr/local/cuda/. See\n+        cudnn_cmd = 'ls /usr/local/cuda/lib/libcudnn*'\n+    else:\n+        cudnn_cmd = 'ldconfig -p | grep libcudnn | rev | cut -d\" \" -f1 | rev'\n+    rc, out, _ = run(cudnn_cmd)\n+    # find will return 1 if there are permission errors or if not found\n+    if len(out) == 0 or (rc != 1 and rc != 0):\n+        l = os.environ.get('CUDNN_LIBRARY')\n+        if l is not None and os.path.isfile(l):\n+            return os.path.realpath(l)\n+        return None\n+    files = set()\n+    for fn in out.split('\\n'):\n+        fn = os.path.realpath(fn)  # eliminate symbolic links\n+        if os.path.isfile(fn):\n+            files.add(fn)\n+    if not files:\n+        return None\n+    # Alphabetize the result because the order is non-deterministic otherwise\n+    files = list(sorted(files))\n+    if len(files) == 1:\n+        return files[0]\n+    result = '\\n'.join(files)\n+    return 'Probably one of the following:\\n{}'.format(result)\n+\n+def get_nvidia_smi():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4Nzc5NA=="}, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNTcxMDk4OnYy", "diffSide": "RIGHT", "path": "test/print_env_info.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQxNzo0MTowNlrOHaoj9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQwODo1MjowMVrOHhI6hQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4OTU4OQ==", "bodyText": "It seems to be making an assumption that the script will be invoked from the top level directory. We should make the path relative to this script. Same for get_torch_model_archiver", "url": "https://github.com/pytorch/serve/pull/622#discussion_r497689589", "createdAt": "2020-09-30T17:41:06Z", "author": {"login": "maaquib"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):\n+    if get_platform() == 'darwin':\n+        if TORCH_AVAILABLE and torch.cuda.is_available():\n+            return torch.cuda.get_device_name(None)\n+        return None\n+    smi = get_nvidia_smi()\n+    uuid_regex = re.compile(r' \\(UUID: .+?\\)')\n+    rc, out, _ = run(smi + ' -L')\n+    if rc != 0:\n+        return None\n+    # Anonymize GPUs by removing their UUID\n+    return \"\\n\" + re.sub(uuid_regex, '', out)\n+\n+def get_running_cuda_version(run):\n+    return run_and_parse_first_match(run, 'nvcc --version', r'V(.*)$')\n+\n+def get_cudnn_version(run):\n+    \"\"\"This will return a list of libcudnn.so; it's hard to tell which one is being used\"\"\"\n+    if get_platform() == 'darwin':\n+        # CUDA libraries and drivers can be found in /usr/local/cuda/. See\n+        cudnn_cmd = 'ls /usr/local/cuda/lib/libcudnn*'\n+    else:\n+        cudnn_cmd = 'ldconfig -p | grep libcudnn | rev | cut -d\" \" -f1 | rev'\n+    rc, out, _ = run(cudnn_cmd)\n+    # find will return 1 if there are permission errors or if not found\n+    if len(out) == 0 or (rc != 1 and rc != 0):\n+        l = os.environ.get('CUDNN_LIBRARY')\n+        if l is not None and os.path.isfile(l):\n+            return os.path.realpath(l)\n+        return None\n+    files = set()\n+    for fn in out.split('\\n'):\n+        fn = os.path.realpath(fn)  # eliminate symbolic links\n+        if os.path.isfile(fn):\n+            files.add(fn)\n+    if not files:\n+        return None\n+    # Alphabetize the result because the order is non-deterministic otherwise\n+    files = list(sorted(files))\n+    if len(files) == 1:\n+        return files[0]\n+    result = '\\n'.join(files)\n+    return 'Probably one of the following:\\n{}'.format(result)\n+\n+def get_nvidia_smi():\n+    smi = 'nvidia-smi'\n+    return smi\n+\n+def get_torchserve_version():\n+    #fetch the torchserve version from version.txt file\n+    with open(\"ts/version.txt\", 'r') as file:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 205}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDUxMTEwOQ==", "bodyText": "Fixed.", "url": "https://github.com/pytorch/serve/pull/622#discussion_r504511109", "createdAt": "2020-10-14T08:52:01Z", "author": {"login": "harshbafna"}, "path": "test/print_env_info.py", "diffHunk": "@@ -0,0 +1,327 @@\n+# This script outputs relevant system environment info\n+# Run it with `python print_env_info.py`.\n+from __future__ import absolute_import, division, print_function, unicode_literals\n+import locale\n+import re\n+import subprocess\n+import sys\n+import os\n+from collections import namedtuple\n+\n+try:\n+    import torch\n+    TORCH_AVAILABLE = True\n+except (ImportError, NameError, AttributeError):\n+    TORCH_AVAILABLE = False\n+\n+torchserve_env = {\n+    \"torch\" : \"**Warning: torch not present ..\",\n+    \"torch_model_archiver\" : \"**Warning: torch-model-archiver not installed ..\",\n+    \"torchserve\" : \"**Warning: torchserve not installed ..\",\n+    \"torchtext\" : \"**Warning: torchtext not present ..\",\n+    \"torchvision\" : \"**Warning: torchvision not present ..\",\n+    \"torchaudio\" : \"**Warning: torchaudio not present ..\"\n+}\n+\n+python_env = {\n+    \"python_version\" : \"N/A\",\n+    \"pip_version\" : \"\",\n+    \"pip_packages\" : []\n+}\n+\n+java_env = {\n+    \"java_version\" : []\n+}\n+\n+os_info = {\n+    \"os\" : \"\",\n+    \"gcc_version\" : \"\",\n+    \"clang_version\" : \"N/A\",\n+    \"cmake_version\" : \"N/A\"\n+}\n+\n+cuda_env = {\n+    \"is_cuda_available\" : \"No\",\n+    \"cuda_runtime_version\" : \"N/A\",\n+    \"nvidia_gpu_models\" : [],\n+    \"nvidia_driver_version\" : \"N/A\",\n+    \"cudnn_version\" : []\n+}\n+\n+def run(command):\n+    \"\"\"Returns (return-code, stdout, stderr)\"\"\"\n+    p = subprocess.Popen(command, stdout=subprocess.PIPE,\n+                         stderr=subprocess.PIPE, shell=True)\n+    output, err = p.communicate()\n+    rc = p.returncode\n+    enc = locale.getpreferredencoding()\n+    output = output.decode(enc)\n+    err = err.decode(enc)\n+    return rc, output.strip(), err.strip()\n+\n+def run_and_read_all(run, command):\n+    \"\"\"Reads and returns entire output if rc is 0\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    return out\n+\n+def run_and_parse_first_match(run, command, regex):\n+    \"\"\"Returns the first regex match if it exists\"\"\"\n+    rc, out, _ = run(command)\n+    if rc != 0:\n+        return \"N/A\"\n+    match = re.search(regex, out)\n+    if match is None:\n+        return \"N/A\"\n+    return match.group(1)\n+\n+def get_pip_packages(run, package_name=None):\n+    \"\"\"Returns `pip list` output. \"\"\"\n+    # systems generally have `pip` as `pip` or `pip3`\n+    def run_with_pip(pip):\n+        if package_name == \"torch\":\n+            grep_cmd = 'grep \"' + package_name + '\"'\n+        else:\n+            grep_cmd = r'grep \"numpy\\|pytest\\|pylint\"'\n+        return run_and_read_all(run, pip + ' list --format=freeze | ' + grep_cmd)\n+    out = run_with_pip('pip3')\n+    if out == \"N/A\":\n+        out = None\n+    return 'pip3', out\n+\n+def get_java_version(run):\n+    rc, out, _ = run(\"java --version\")\n+    if rc != 0:\n+        return \"**Warning: java not installed...\"\n+    return out\n+\n+def get_platform():\n+    if sys.platform.startswith('linux'):\n+        return 'linux'\n+    elif sys.platform.startswith('cygwin'):\n+        return 'cygwin'\n+    elif sys.platform.startswith('darwin'):\n+        return 'darwin'\n+    else:\n+        return sys.platform\n+\n+def get_mac_version(run):\n+    return run_and_parse_first_match(run, 'sw_vers -productVersion', r'(.*)')\n+\n+def get_lsb_version(run):\n+    return run_and_parse_first_match(run, 'lsb_release -a', r'Description:\\t(.*)')\n+\n+def check_release_file(run):\n+    return run_and_parse_first_match(run, 'cat /etc/*-release', r'PRETTY_NAME=\"(.*)\"')\n+\n+def get_os(run):\n+    from platform import machine\n+    platform = get_platform()\n+    if platform == 'darwin':\n+        version = get_mac_version(run)\n+        if version is None:\n+            return None\n+        return 'Mac OSX {} ({})'.format(version, machine())\n+    if platform == 'linux':\n+        # Ubuntu/Debian based\n+        desc = get_lsb_version(run)\n+        if desc is not None:\n+            return desc\n+        # Try reading /etc/*-release\n+        desc = check_release_file(run)\n+        if desc is not None:\n+            return desc\n+        return '{} ({})'.format(platform, machine())\n+    # Unknown platform\n+    return platform\n+\n+def get_gcc_version(run):\n+    return run_and_parse_first_match(run, 'gcc --version', r'gcc (.*)')\n+\n+def get_clang_version(run):\n+    return run_and_parse_first_match(run, 'clang --version', r'clang version (.*)')\n+\n+def get_cmake_version(run):\n+    return run_and_parse_first_match(run, 'cmake --version', r'cmake (.*)')\n+\n+def get_nvidia_driver_version(run):\n+    if get_platform() == 'darwin':\n+        cmd = 'kextstat | grep -i cuda'\n+        return run_and_parse_first_match(run, cmd, r'com[.]nvidia[.]CUDA [(](.*?)[)]')\n+    smi = get_nvidia_smi()\n+    return run_and_parse_first_match(run, smi, r'Driver Version: (.*?) ')\n+\n+def get_gpu_info(run):\n+    if get_platform() == 'darwin':\n+        if TORCH_AVAILABLE and torch.cuda.is_available():\n+            return torch.cuda.get_device_name(None)\n+        return None\n+    smi = get_nvidia_smi()\n+    uuid_regex = re.compile(r' \\(UUID: .+?\\)')\n+    rc, out, _ = run(smi + ' -L')\n+    if rc != 0:\n+        return None\n+    # Anonymize GPUs by removing their UUID\n+    return \"\\n\" + re.sub(uuid_regex, '', out)\n+\n+def get_running_cuda_version(run):\n+    return run_and_parse_first_match(run, 'nvcc --version', r'V(.*)$')\n+\n+def get_cudnn_version(run):\n+    \"\"\"This will return a list of libcudnn.so; it's hard to tell which one is being used\"\"\"\n+    if get_platform() == 'darwin':\n+        # CUDA libraries and drivers can be found in /usr/local/cuda/. See\n+        cudnn_cmd = 'ls /usr/local/cuda/lib/libcudnn*'\n+    else:\n+        cudnn_cmd = 'ldconfig -p | grep libcudnn | rev | cut -d\" \" -f1 | rev'\n+    rc, out, _ = run(cudnn_cmd)\n+    # find will return 1 if there are permission errors or if not found\n+    if len(out) == 0 or (rc != 1 and rc != 0):\n+        l = os.environ.get('CUDNN_LIBRARY')\n+        if l is not None and os.path.isfile(l):\n+            return os.path.realpath(l)\n+        return None\n+    files = set()\n+    for fn in out.split('\\n'):\n+        fn = os.path.realpath(fn)  # eliminate symbolic links\n+        if os.path.isfile(fn):\n+            files.add(fn)\n+    if not files:\n+        return None\n+    # Alphabetize the result because the order is non-deterministic otherwise\n+    files = list(sorted(files))\n+    if len(files) == 1:\n+        return files[0]\n+    result = '\\n'.join(files)\n+    return 'Probably one of the following:\\n{}'.format(result)\n+\n+def get_nvidia_smi():\n+    smi = 'nvidia-smi'\n+    return smi\n+\n+def get_torchserve_version():\n+    #fetch the torchserve version from version.txt file\n+    with open(\"ts/version.txt\", 'r') as file:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY4OTU4OQ=="}, "originalCommit": {"oid": "d4c4250bce89c4806687f5426fb906a93c4f8c30"}, "originalPosition": 205}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1390, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}