{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEzMDQ4ODYy", "number": 302, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQyMDowMToxM1rOD5JL8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTozOToxNVrOD6DrLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMjQ1OTM4OnYy", "diffSide": "RIGHT", "path": "examples/Huggingface_Transformers/Download_Transformer_models.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQyMDowMToxM1rOGQQBwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQyMTo0ODo0N1rOGQTezQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5Mjk5Mg==", "bodyText": "Should we add a else warning here if the mode is not supported?", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419692992", "createdAt": "2020-05-04T20:01:13Z", "author": {"login": "zhangguanheng66"}, "path": "examples/Huggingface_Transformers/Download_Transformer_models.py", "diffHunk": "@@ -0,0 +1,103 @@\n+import transformers\n+from pathlib import Path\n+import os\n+import json\n+import torch\n+from transformers import (AutoModelForSequenceClassification, AutoTokenizer, AutoModelForQuestionAnswering,\n+ AutoModelForTokenClassification, AutoConfig)\n+\"\"\" This function, save the checkpoint, config file along with tokenizer config and vocab files\n+    of a transformer model of your choice.\n+\"\"\"\n+print('Transformers version',transformers.__version__)\n+\n+def transformers_model_dowloader(mode,pretrained_model_name,num_labels,do_lower_case):\n+    print(\"Download model and tokenizer\", pretrained_model_name)\n+    #loading pre-trained model and tokenizer\n+    if mode== \"sequence_classification\":\n+        config = AutoConfig.from_pretrained(pretrained_model_name,num_labels=num_labels)\n+        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, config=config)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+    elif mode== \"question_answering\":\n+        model = AutoModelForQuestionAnswering.from_pretrained(pretrained_model_name)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+    elif mode== \"token_classification\":\n+        config = AutoConfig.from_pretrained(pretrained_model_name,num_labels=num_labels)\n+        model = AutoModelForTokenClassification.from_pretrained(pretrained_model_name)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc0OTU4MQ==", "bodyText": "Thanks for your suggestion, the warning is added now.", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419749581", "createdAt": "2020-05-04T21:48:47Z", "author": {"login": "HamidShojanazeri"}, "path": "examples/Huggingface_Transformers/Download_Transformer_models.py", "diffHunk": "@@ -0,0 +1,103 @@\n+import transformers\n+from pathlib import Path\n+import os\n+import json\n+import torch\n+from transformers import (AutoModelForSequenceClassification, AutoTokenizer, AutoModelForQuestionAnswering,\n+ AutoModelForTokenClassification, AutoConfig)\n+\"\"\" This function, save the checkpoint, config file along with tokenizer config and vocab files\n+    of a transformer model of your choice.\n+\"\"\"\n+print('Transformers version',transformers.__version__)\n+\n+def transformers_model_dowloader(mode,pretrained_model_name,num_labels,do_lower_case):\n+    print(\"Download model and tokenizer\", pretrained_model_name)\n+    #loading pre-trained model and tokenizer\n+    if mode== \"sequence_classification\":\n+        config = AutoConfig.from_pretrained(pretrained_model_name,num_labels=num_labels)\n+        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, config=config)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+    elif mode== \"question_answering\":\n+        model = AutoModelForQuestionAnswering.from_pretrained(pretrained_model_name)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+    elif mode== \"token_classification\":\n+        config = AutoConfig.from_pretrained(pretrained_model_name,num_labels=num_labels)\n+        model = AutoModelForTokenClassification.from_pretrained(pretrained_model_name)\n+        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name,do_lower_case=do_lower_case)\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5Mjk5Mg=="}, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYxMjUwMjczOnYy", "diffSide": "RIGHT", "path": "examples/Huggingface_Transformers/Transformers_handler.py", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNFQyMDoxNDoxNVrOGQQc4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwMzo1NDoyMVrOGQZoCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5OTkzOQ==", "bodyText": "why not combine self.initialize func and constructor together? Do you expect user to initialize the class multiple times?", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419699939", "createdAt": "2020-05-04T20:14:15Z", "author": {"login": "zhangguanheng66"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,112 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.initialized = False\n+\n+    def initialize(self, ctx):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc1MDI0MQ==", "bodyText": "Constructor and self.initialize func are combined.", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419750241", "createdAt": "2020-05-04T21:50:12Z", "author": {"login": "HamidShojanazeri"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,112 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.initialized = False\n+\n+    def initialize(self, ctx):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5OTkzOQ=="}, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc1NzcxNQ==", "bodyText": "How about this one?", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419757715", "createdAt": "2020-05-04T22:07:05Z", "author": {"login": "zhangguanheng66"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,112 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.initialized = False\n+\n+    def initialize(self, ctx):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5OTkzOQ=="}, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTc3OTgyMQ==", "bodyText": "Sure, modified as well. Thanks.", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419779821", "createdAt": "2020-05-04T23:06:19Z", "author": {"login": "HamidShojanazeri"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,112 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.initialized = False\n+\n+    def initialize(self, ctx):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5OTkzOQ=="}, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTg1MDI0OA==", "bodyText": "@zhangguanheng66 The initialize method has a special purpose in TorchServe base model handlers. @mycpuorg Can you please describe the details for why it needs to be separate?", "url": "https://github.com/pytorch/serve/pull/302#discussion_r419850248", "createdAt": "2020-05-05T03:54:21Z", "author": {"login": "chauhang"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,112 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.initialized = False\n+\n+    def initialize(self, ctx):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTY5OTkzOQ=="}, "originalCommit": {"oid": "44217c1775ca52cbd1bf41a686d642b679a54333"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyMjAzOTg1OnYy", "diffSide": "RIGHT", "path": "examples/Huggingface_Transformers/Transformer_handler_generalized.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTozODowMVrOGRrVYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTozODowMVrOGRrVYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE4ODk2Mw==", "bodyText": "We could be doing all these inside the initialize method instead of the constructor. initialize is called with service context which can be very helpful.", "url": "https://github.com/pytorch/serve/pull/302#discussion_r421188963", "createdAt": "2020-05-07T01:38:01Z", "author": {"login": "mycpuorg"}, "path": "examples/Huggingface_Transformers/Transformer_handler_generalized.py", "diffHunk": "@@ -0,0 +1,148 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+import ast\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForQuestionAnswering,AutoModelForTokenClassification\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers handler class for sequence, token classification and question answering.\n+    \"\"\"\n+    def __init__(self,ctx):\n+        super(TransformersSeqClassifierHandler, self).__init__()\n+        self.manifest = ctx.manifest\n+        properties = ctx.system_properties", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e609eb2e1daf68c29e5f6432b7a05d84c049daae"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyMjA0MjA1OnYy", "diffSide": "RIGHT", "path": "examples/Huggingface_Transformers/Transformers_handler.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTozOToxNVrOGRrWsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTozOToxNVrOGRrWsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE4OTI5Ng==", "bodyText": "Same comment as before.\nIn general, both initialize and instantiation happen around the same time during model load stage. But the initialize function is called with service context  which gives the handler information provided about the model during registration such as:\n\nmodel_name\nmodel_dir\nmanifest\nbatch_size\ngpu\nts.version\n\nSo the handlers can make better decisions during initialize than in constructor.", "url": "https://github.com/pytorch/serve/pull/302#discussion_r421189296", "createdAt": "2020-05-07T01:39:15Z", "author": {"login": "mycpuorg"}, "path": "examples/Huggingface_Transformers/Transformers_handler.py", "diffHunk": "@@ -0,0 +1,106 @@\n+from abc import ABC\n+import json\n+import logging\n+import os\n+\n+import torch\n+from transformers import AutoModelForSequenceClassification, AutoTokenizer\n+\n+from ts.torch_handler.base_handler import BaseHandler\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class TransformersSeqClassifierHandler(BaseHandler, ABC):\n+    \"\"\"\n+    Transformers text classifier handler class. This handler takes a text (string) and\n+    as input and returns the classification text based on the serialized transformers checkpoint.\n+    \"\"\"\n+    def __init__(self, ctx):\n+        super(TransformersSeqClassifierHandler, self).__init__()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e609eb2e1daf68c29e5f6432b7a05d84c049daae"}, "originalPosition": 20}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1634, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}