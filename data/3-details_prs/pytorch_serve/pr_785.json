{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyMzY1OTc0", "number": 785, "title": "Workflow support", "bodyText": "Description\nPlease refer issue comment for details\nFixes #682\nType of change\nPlease delete options that are not relevant.\n\n Bug fix (non-breaking change which fixes an issue)\n New feature (non-breaking change which adds functionality)\n Breaking change (fix or feature that would cause existing functionality to not work as expected)\n This change requires a documentation update\n\nFeature/Issue validation/testing\nPlease describe the tests [UT/IT] that you ran to verify your changes and relevent result summary. Provide instructions so it can be reproduced.\nPlease also list any relevant details for your test configuration.\n\n\n Test A\n\n\n Test B\n\n\nUT/IT execution results\n\n\nLogs\n\n\nChecklist:\n\n Have you added tests that prove your fix is effective or that this feature works?\n New and existing unit tests pass locally with these changes?\n Has code been commented, particularly in hard-to-understand areas?\n Have you made corresponding changes to the documentation?", "createdAt": "2020-11-17T12:18:05Z", "url": "https://github.com/pytorch/serve/pull/785", "merged": true, "mergeCommit": {"oid": "8920a5ce2252046ad86462972bb43dd43dcdcf30"}, "closed": true, "closedAt": "2021-05-19T21:54:09Z", "author": {"login": "dhaniram-kshirsagar"}, "timelineItems": {"totalCount": 225, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdpPWaNgH2gAyNTIyMzY1OTc0Ojg4YjEzMzYxNjMzNjRkMDI0ZDRhZDUyMWQ0ZjIxM2ZlMjkwOTkwZjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABeIXYVrgFqTYyMzUxNzg4Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "88b1336163364d024d4ad521d4f213fe290990f6", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/88b1336163364d024d4ad521d4f213fe290990f6", "committedDate": "2020-12-24T08:21:11Z", "message": "removed intial model loading"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c233403b5748a3020439c9f7b82ee0e9bc5b8a68", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c233403b5748a3020439c9f7b82ee0e9bc5b8a68", "committedDate": "2020-12-24T11:02:46Z", "message": "workflow function handler file path fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e8133c173c610443ff87f9584f005750f95c8b3", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8e8133c173c610443ff87f9584f005750f95c8b3", "committedDate": "2020-12-24T11:33:52Z", "message": "fixed function signature"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "471a70e95e84c16b25cc9254ede832472016e6f4", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/471a70e95e84c16b25cc9254ede832472016e6f4", "committedDate": "2020-12-24T11:47:22Z", "message": "renamed example directory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e695bde7051a4f4ab47c31eb6a6777e47c6b356", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8e695bde7051a4f4ab47c31eb6a6777e47c6b356", "committedDate": "2020-12-24T12:27:07Z", "message": "fixed workflow handler file path issue on windows"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb50e5e01b5f8ae8bd2cbe0f48d7124ab5116d05", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/bb50e5e01b5f8ae8bd2cbe0f48d7124ab5116d05", "committedDate": "2020-12-24T12:40:22Z", "message": "enhanced torchserve_sanity script to validate pileline workflow examples"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bed28a3768f4eddd5a5b4fdda81510a1b6b02610", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/bed28a3768f4eddd5a5b4fdda81510a1b6b02610", "committedDate": "2020-12-24T13:07:48Z", "message": "PMD fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cf7fbb1057be67a2380cec9949e96bd2b14b653", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2cf7fbb1057be67a2380cec9949e96bd2b14b653", "committedDate": "2020-12-24T13:58:33Z", "message": "added no config snapshot in workflow sanity"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8af6c400d8438a915cdb6740e5bbf4ab56701e34", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8af6c400d8438a915cdb6740e5bbf4ab56701e34", "committedDate": "2020-12-24T14:59:40Z", "message": "fixed handler path in function model archive"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "acd7e47401e44264880ef149b40991c71fb817fa", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/acd7e47401e44264880ef149b40991c71fb817fa", "committedDate": "2020-12-24T15:25:26Z", "message": "added os specific command for workflow sanity"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee5917488e736b80d03c7f1a92bbf9fe668fe083", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ee5917488e736b80d03c7f1a92bbf9fe668fe083", "committedDate": "2020-12-24T16:12:28Z", "message": "replaced commands with python utilitiy calls"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ab5c96847d8ecd39ed4983e3eadda9efdce1c86", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8ab5c96847d8ecd39ed4983e3eadda9efdce1c86", "committedDate": "2020-12-24T17:14:20Z", "message": "Merge branch 'master' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e3a1c5d62ac1f4fe5d673f40319074e410ac0fe", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/4e3a1c5d62ac1f4fe5d673f40319074e410ac0fe", "committedDate": "2020-12-28T06:36:18Z", "message": "added negative test cases and fixed corresponding responses"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "455911fe38ba7eb78ed6ca5fd6373ee29fed47ab", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/455911fe38ba7eb78ed6ca5fd6373ee29fed47ab", "committedDate": "2020-12-28T07:31:12Z", "message": "more negative test cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22faedd45d0d2660b731ed55fb9b777afe69d303", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/22faedd45d0d2660b731ed55fb9b777afe69d303", "committedDate": "2020-12-28T15:17:43Z", "message": "improved error handling and added more test cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df35dd3e6630acfef85d36d32e683d2906aa7115", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/df35dd3e6630acfef85d36d32e683d2906aa7115", "committedDate": "2020-12-29T04:57:17Z", "message": "Multi input support (#931)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "456fe55ac1e348f5568bfb4d9c41a819fda88765", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/456fe55ac1e348f5568bfb4d9c41a819fda88765", "committedDate": "2020-12-29T05:41:01Z", "message": "updated expected output"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77ed6af4d31332de781d5c266850d1496c79a3bd", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/77ed6af4d31332de781d5c266850d1496c79a3bd", "committedDate": "2020-12-29T11:45:30Z", "message": "more test cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "author": {"user": {"login": "dhanainme", "name": null}}, "url": "https://github.com/pytorch/serve/commit/14627541568be02cf2ba7256c53b350d7b3ee3ad", "committedDate": "2021-01-19T22:28:09Z", "message": "Merge branch 'master' into issue_682"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg3MDM4Mzcw", "url": "https://github.com/pytorch/serve/pull/785#pullrequestreview-587038370", "createdAt": "2021-02-09T21:43:04Z", "commit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMTo0MzowNVrOIitMjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMjo0NjozM1rOIivnJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2Mjk4OQ==", "bodyText": "Large method. Can be split in to small pieces.\n\nParsing manifest file.\nCreating / validating DAG", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573262989", "createdAt": "2021-02-09T21:43:05Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;\n+            WorkflowModel wfm;\n+            if (!models.containsKey(modelName)) {\n+                wfm =\n+                        new WorkflowModel(\n+                                modelName,\n+                                null,\n+                                1,\n+                                1,\n+                                1,\n+                                0,\n+                                handlerFile.getPath() + \":\" + nodeName);\n+            } else {\n+                wfm = models.get(modelName);\n+            }\n+            Node fromNode = new Node(nodeName, wfm);\n+            dag.addNode(fromNode);\n+\n+            @SuppressWarnings(\"unchecked\")\n+            ArrayList<String> values = (ArrayList<String>) entry.getValue();\n+            for (String toNodeName : values) {\n+\n+                if (toNodeName == null || (\"\").equals(toNodeName.strip())) {\n+                    continue;\n+                }\n+                String toModelName = workFlowName + \"__\" + toNodeName;\n+                WorkflowModel toWfm;\n+                if (!models.containsKey(toModelName)) {\n+                    toWfm =\n+                            new WorkflowModel(\n+                                    toModelName,\n+                                    null,\n+                                    1,\n+                                    1,\n+                                    1,\n+                                    0,\n+                                    handlerFile.getPath() + \":\" + toNodeName);\n+                } else {\n+                    toWfm = models.get(toModelName);\n+                }\n+                Node toNode = new Node(toNodeName, toWfm);\n+                dag.addNode(toNode);\n+                dag.addEdge(fromNode, toNode);\n+            }\n+        }\n+        dag.validate();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzUwMg==", "bodyText": "min-workers / max-workers / others are Java constants", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573263502", "createdAt": "2021-02-09T21:44:01Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzY5Mg==", "bodyText": "final", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573263692", "createdAt": "2021-02-09T21:44:19Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NDI2NQ==", "bodyText": "Lombok ?\nThis is refactoring opportunity for larger code base.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573264265", "createdAt": "2021-02-09T21:45:21Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;\n+            WorkflowModel wfm;\n+            if (!models.containsKey(modelName)) {\n+                wfm =\n+                        new WorkflowModel(\n+                                modelName,\n+                                null,\n+                                1,\n+                                1,\n+                                1,\n+                                0,\n+                                handlerFile.getPath() + \":\" + nodeName);\n+            } else {\n+                wfm = models.get(modelName);\n+            }\n+            Node fromNode = new Node(nodeName, wfm);\n+            dag.addNode(fromNode);\n+\n+            @SuppressWarnings(\"unchecked\")\n+            ArrayList<String> values = (ArrayList<String>) entry.getValue();\n+            for (String toNodeName : values) {\n+\n+                if (toNodeName == null || (\"\").equals(toNodeName.strip())) {\n+                    continue;\n+                }\n+                String toModelName = workFlowName + \"__\" + toNodeName;\n+                WorkflowModel toWfm;\n+                if (!models.containsKey(toModelName)) {\n+                    toWfm =\n+                            new WorkflowModel(\n+                                    toModelName,\n+                                    null,\n+                                    1,\n+                                    1,\n+                                    1,\n+                                    0,\n+                                    handlerFile.getPath() + \":\" + toNodeName);\n+                } else {\n+                    toWfm = models.get(toModelName);\n+                }\n+                Node toNode = new Node(toNodeName, toWfm);\n+                dag.addNode(toNode);\n+                dag.addEdge(fromNode, toNode);\n+            }\n+        }\n+        dag.validate();\n+    }\n+\n+    private static Map<String, Object> readSpecFile(File file)\n+            throws IOException, InvalidWorkflowException {\n+        Yaml yaml = new Yaml();\n+        try (Reader r =\n+                new InputStreamReader(\n+                        Files.newInputStream(file.toPath()), StandardCharsets.UTF_8)) {\n+            @SuppressWarnings(\"unchecked\")\n+            Map<String, Object> loadedYaml = (Map<String, Object>) yaml.load(r);\n+            return loadedYaml;\n+        } catch (YAMLException e) {\n+            throw new InvalidWorkflowException(\"Failed to parse yaml.\", e);\n+        }\n+    }\n+\n+    public Object getWorkflowSpec() {\n+        return workflowSpec;\n+    }\n+\n+    public Dag getDag() {\n+        return this.dag;\n+    }\n+\n+    public WorkflowArchive getWorkflowArchive() {\n+        return workflowArchive;\n+    }\n+\n+    public int getMinWorkers() {\n+        return minWorkers;\n+    }\n+\n+    public void setMinWorkers(int minWorkers) {\n+        this.minWorkers = minWorkers;\n+    }\n+\n+    public int getMaxWorkers() {\n+        return maxWorkers;\n+    }\n+\n+    public void setMaxWorkers(int maxWorkers) {\n+        this.maxWorkers = maxWorkers;\n+    }\n+\n+    public int getBatchSize() {\n+        return batchSize;\n+    }\n+\n+    public void setBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+    }\n+\n+    public int getMaxBatchDelay() {\n+        return maxBatchDelay;\n+    }\n+\n+    public void setMaxBatchDelay(int maxBatchDelay) {\n+        this.maxBatchDelay = maxBatchDelay;\n+    }\n+\n+    public String getWorkflowDag() {\n+        return this.workflowSpec.get(\"dag\").toString();\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NTYwOA==", "bodyText": "Also SnakeYML will convert a Java YML file to a object. Much better to use than parsing manually. https://bitbucket.org/asomov/snakeyaml/wiki/Documentation", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573265608", "createdAt": "2021-02-09T21:47:25Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzUwMg=="}, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NjA2OA==", "bodyText": "String builder", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573266068", "createdAt": "2021-02-09T21:48:07Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI5OTU4MA==", "bodyText": "final / Lombok", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573299580", "createdAt": "2021-02-09T22:40:32Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/Node.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class Node {\n+\n+    private String name;\n+    private String parentName;\n+    private WorkflowModel workflowModel;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI5OTk1Ng==", "bodyText": "Refactor to use Guava Graph lib - https://guava.dev/releases/23.0/api/docs/com/google/common/graph/Graph.html", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573299956", "createdAt": "2021-02-09T22:41:20Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/Dag.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/** Direct acyclic graph for ensemble */\n+public class Dag {\n+\n+    private Map<String, Node> nodes = new HashMap<>();\n+\n+    private Map<String, Map<String, Set<String>>> dagMap = new HashMap<>();\n+\n+    public void addNode(Node node) {\n+        if (!checkNodeExist(node)) {\n+            nodes.put(node.getName(), node);\n+            Map<String, Set<String>> degreeMap = new HashMap<>();\n+            degreeMap.put(\"inDegree\", new HashSet<String>());\n+            degreeMap.put(\"outDegree\", new HashSet<String>());\n+            dagMap.put(node.getName(), degreeMap);\n+        }\n+    }\n+\n+    public boolean checkNodeExist(Node node) {\n+        return nodes.containsKey(node.getName());\n+    }\n+\n+    public boolean hasEdgeTo(Node from, Node to) {\n+        return dagMap.get(from.getName()).get(\"inDegree\").contains(to.getName());\n+    }\n+\n+    public void addEdge(Node from, Node to) throws InvalidDAGException {\n+        if (!checkNodeExist(from)) {\n+            addNode(from);\n+        }\n+        if (!checkNodeExist(to)) {\n+            addNode(to);\n+        }\n+\n+        if (from.getName().equals(to.getName())) {\n+            throw new InvalidDAGException(\"Self loop exception\");\n+        }\n+\n+        if (hasEdgeTo(to, from)) {\n+            throw new InvalidDAGException(\"loop exception\");\n+        }\n+\n+        dagMap.get(from.getName()).get(\"outDegree\").add(to.getName());\n+        dagMap.get(to.getName()).get(\"inDegree\").add(from.getName());\n+    }\n+\n+    public Set<String> getEndNodeNames(String degree) {\n+        Set<String> startNodes = new HashSet<>();\n+        for (Map.Entry<String, Map<String, Set<String>>> entry : dagMap.entrySet()) {\n+            Set<String> value = entry.getValue().get(degree);\n+            if (value.isEmpty()) {\n+                startNodes.add(entry.getKey());\n+            }\n+        }\n+        return startNodes;\n+    }\n+\n+    public Set<String> getStartNodeNames() {\n+        return getEndNodeNames(\"inDegree\");\n+    }\n+\n+    public Set<String> getLeafNodeNames() {\n+        return getEndNodeNames(\"outDegree\");\n+    }\n+\n+    public Map<String, Integer> getDegreeMap(String degree) {\n+        Map<String, Integer> inDegreeMap = new HashMap<>();\n+        for (Map.Entry<String, Map<String, Set<String>>> entry : dagMap.entrySet()) {\n+            inDegreeMap.put(entry.getKey(), entry.getValue().get(degree).size());\n+        }\n+        return inDegreeMap;\n+    }\n+\n+    public Map<String, Integer> getInDegreeMap() {\n+        return getDegreeMap(\"inDegree\");\n+    }\n+\n+    public Map<String, Integer> getOutDegreeMap() {\n+        return getDegreeMap(\"outDegree\");\n+    }\n+\n+    public Map<String, Node> getNodes() {\n+        return nodes;\n+    }\n+\n+    public Map<String, Map<String, Set<String>>> getDagMap() {\n+        return dagMap;\n+    }\n+\n+    public ArrayList<String> validate() throws InvalidDAGException {\n+        Set<String> startNodes = getStartNodeNames();\n+\n+        if (startNodes.size() != 1) {\n+            throw new InvalidDAGException(\"DAG should have only one start node\");\n+        }\n+\n+        ArrayList<String> topoSortedList = new ArrayList<>();\n+        DagExecutor de = new DagExecutor(this);\n+        de.execute(null, topoSortedList);\n+        if (topoSortedList.size() != nodes.size()) {\n+            throw new InvalidDAGException(\"Not a valid DAG\");\n+        }\n+        return topoSortedList;\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMTcwNQ==", "bodyText": "ListenableFuture may be a more appropriate\nhttps://guava.dev/releases/21.0/api/docs/com/google/common/util/concurrent/ListenableFuture.html\nhttps://stackoverflow.com/questions/19138212/how-to-implement-a-dag-like-scheduler-in-java has a good example.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573301705", "createdAt": "2021-02-09T22:44:53Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/DagExecutor.java", "diffHunk": "@@ -0,0 +1,161 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionService;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorCompletionService;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import org.pytorch.serve.archive.model.ModelNotFoundException;\n+import org.pytorch.serve.archive.model.ModelVersionNotFoundException;\n+import org.pytorch.serve.http.InternalServerException;\n+import org.pytorch.serve.job.RestJob;\n+import org.pytorch.serve.util.ApiUtils;\n+import org.pytorch.serve.util.messages.InputParameter;\n+import org.pytorch.serve.util.messages.RequestInput;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class DagExecutor {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(DagExecutor.class);\n+\n+    private Dag dag;\n+    private Map<String, RequestInput> inputRequestMap;\n+\n+    public DagExecutor(Dag dag) {\n+        this.dag = dag;\n+        inputRequestMap = new ConcurrentHashMap<>();\n+    }\n+\n+    public ArrayList<NodeOutput> execute(RequestInput input, ArrayList<String> topoSortedList) {\n+\n+        CompletionService<NodeOutput> executorCompletionService = null;\n+        if (topoSortedList == null) {\n+            ExecutorService executorService = Executors.newFixedThreadPool(4);\n+            executorCompletionService = new ExecutorCompletionService<>(executorService);\n+        }\n+\n+        Map<String, Integer> inDegreeMap = this.dag.getInDegreeMap();\n+        Set<String> zeroInDegree = dag.getStartNodeNames();\n+        Set<String> executing = new HashSet<>();\n+\n+        if (topoSortedList == null) {\n+            for (String s : zeroInDegree) {\n+                RequestInput newInput = new RequestInput(UUID.randomUUID().toString());\n+                newInput.setHeaders(input.getHeaders());\n+                newInput.setParameters(input.getParameters());\n+                inputRequestMap.put(s, newInput);\n+            }\n+        }\n+\n+        ArrayList<NodeOutput> leafOutputs = new ArrayList<>();\n+\n+        while (!zeroInDegree.isEmpty()) {\n+            Set<String> readyToExecute = new HashSet<>(zeroInDegree);\n+            readyToExecute.removeAll(executing);\n+            executing.addAll(readyToExecute);\n+\n+            ArrayList<NodeOutput> outputs = new ArrayList<>();\n+            if (topoSortedList == null) {\n+                for (String name : readyToExecute) {\n+                    executorCompletionService.submit(\n+                            () ->\n+                                    invokeModel(\n+                                            name,\n+                                            this.dag.getNodes().get(name).getWorkflowModel(),\n+                                            inputRequestMap.get(name)));\n+                }\n+\n+                try {\n+                    outputs.add(executorCompletionService.take().get());\n+                } catch (InterruptedException | ExecutionException e) {\n+                    String[] error = e.getMessage().split(\":\");\n+                    throw new InternalServerException(error[error.length - 1]); // NOPMD\n+                }\n+            } else {\n+                for (String name : readyToExecute) {\n+                    outputs.add(new NodeOutput(name, null));\n+                }\n+            }\n+\n+            for (NodeOutput output : outputs) {\n+                String nodeName = output.getNodeName();\n+                executing.remove(nodeName);\n+                zeroInDegree.remove(nodeName);\n+\n+                if (topoSortedList != null) {\n+                    topoSortedList.add(nodeName);\n+                }\n+\n+                Set<String> childNodes = this.dag.getDagMap().get(nodeName).get(\"outDegree\");\n+                if (childNodes.isEmpty()) {\n+                    leafOutputs.add(output);\n+                } else {\n+                    for (String newNodeName : childNodes) {\n+\n+                        if (topoSortedList == null) {\n+                            byte[] response = (byte[]) output.getData();\n+\n+                            RequestInput newInput = this.inputRequestMap.get(newNodeName);\n+                            if (newInput == null) {\n+                                List<InputParameter> params = new ArrayList<>();\n+                                newInput = new RequestInput(UUID.randomUUID().toString());\n+                                if (inDegreeMap.get(newNodeName) == 1) {\n+                                    params.add(new InputParameter(\"body\", response));\n+                                } else {\n+                                    params.add(new InputParameter(nodeName, response));\n+                                }\n+                                newInput.setParameters(params);\n+                                newInput.setHeaders(input.getHeaders());\n+                            } else {\n+                                newInput.addParameter(new InputParameter(nodeName, response));\n+                            }\n+                            this.inputRequestMap.put(newNodeName, newInput);\n+                        }\n+\n+                        inDegreeMap.replace(newNodeName, inDegreeMap.get(newNodeName) - 1);\n+                        if (inDegreeMap.get(newNodeName) == 0) {\n+                            zeroInDegree.add(newNodeName);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        return leafOutputs;\n+    }\n+\n+    private NodeOutput invokeModel(String nodeName, WorkflowModel workflowModel, RequestInput input)\n+            throws ModelNotFoundException, ModelVersionNotFoundException, ExecutionException,\n+                    InterruptedException {\n+        try {\n+            CompletableFuture<byte[]> respFuture = new CompletableFuture<>();\n+\n+            RestJob job = ApiUtils.addRESTInferenceJob(null, workflowModel.getName(), null, input);\n+            job.setResponsePromise(respFuture);\n+            byte[] resp = respFuture.get();\n+            return new NodeOutput(nodeName, resp);\n+        } catch (InterruptedException | ExecutionException e) {\n+            logger.error(\"Failed to execute workflow Node.\");\n+            logger.error(nodeName + \" : \" + e.getMessage());\n+            String[] error = e.getMessage().split(\":\");\n+            throw new InternalServerException(nodeName + \" - \" + error[error.length - 1]); // NOPMD\n+        } catch (ModelNotFoundException e) {\n+            logger.error(\"Model not found.\");\n+            logger.error(e.getMessage());\n+            throw e;\n+        } catch (ModelVersionNotFoundException e) {\n+            logger.error(\"Model version not found.\");\n+            logger.error(e.getMessage());\n+            throw e;\n+        }\n+    }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjAzMg==", "bodyText": "Lombok", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302032", "createdAt": "2021-02-09T22:45:30Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/NodeOutput.java", "diffHunk": "@@ -0,0 +1,27 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class NodeOutput {\n+    private String nodeName;\n+    private Object data;\n+\n+    public NodeOutput(String nodeName, Object data) {\n+        this.nodeName = nodeName;\n+        this.data = data;\n+    }\n+\n+    public String getNodeName() {\n+        return nodeName;\n+    }\n+\n+    public void setNodeName(String nodeName) {\n+        this.nodeName = nodeName;\n+    }\n+\n+    public Object getData() {\n+        return data;\n+    }\n+\n+    public void setData(Object data) {\n+        this.data = data;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjQwMg==", "bodyText": "final / lombok", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302402", "createdAt": "2021-02-09T22:46:12Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkflowManifest.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.pytorch.serve.ensemble;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class WorkflowManifest {\n+\n+    private String createdOn;\n+    private String description;\n+    private String archiverVersion;\n+    private RuntimeType runtime;\n+    private Workflow workflow;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjU2NQ==", "bodyText": "final / lombok", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302565", "createdAt": "2021-02-09T22:46:33Z", "author": {"login": "dhanainme"}, "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkflowModel.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class WorkflowModel {\n+\n+    private String name;\n+    private String url;\n+    private int minWorkers;\n+    private int maxWorkers;\n+    private int batchSize;\n+    private int maxBatchDelay;\n+    private String handler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 11}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg3MDk0NTQ1", "url": "https://github.com/pytorch/serve/pull/785#pullrequestreview-587094545", "createdAt": "2021-02-09T22:56:50Z", "commit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMjo1Njo1MFrOIiv7Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMzowNjozN1rOIiwNTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwNzcxMQ==", "bodyText": "Nit : Fix narrative style.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573307711", "createdAt": "2021-02-09T22:56:50Z", "author": {"login": "dhanainme"}, "path": "workflow-archiver/README.md", "diffHunk": "@@ -0,0 +1,97 @@\n+# Torch Workflow archiver for TorchServe\n+\n+## Contents of this Document\n+* [Overview](#overview)\n+* [Installation](#installation)\n+* [Torch Workflow Archiver CLI](#torch-workflow-archiver-command-line-interface)\n+* [Artifact Details](#artifact-details)\n+    * [WAR-INFO](#war-inf)\n+    * [Workflow name](#workflow-name)\n+    * [Spec File](#spec-file)\n+    * [handler](#handler)\n+\n+## Overview\n+\n+A key feature of TorchServe is the ability to package workflow specification (.yaml) and other workflow dependency files into a single workflow archive file (.war). This file can then be redistributed and served by anyone using TorchServe.\n+ \n+The CLI creates a `.war` file that TorchServe CLI uses to serve the workflows.\n+\n+The following information is required to create a standalone workflow archive:\n+1. [Workflow name](#workflow-name)\n+2. [Spec file](#spec-file)\n+\n+## Installation\n+\n+Install torch-workflow-archiver as follows:\n+\n+```bash\n+pip install torch-workflow-archiver\n+```\n+\n+## Installation from source\n+\n+Install torch-workflow-archiver from source as follows:\n+\n+```bash\n+git clone https://github.com/pytorch/serve.git\n+cd serve/workflow-archiver\n+pip install .\n+```\n+\n+## Torch Workflow Archiver Command Line Interface\n+\n+Now let's cover the details on using the CLI tool: `torch-workflow-archiver`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwODcyMw==", "bodyText": "required : False ?\nWhat happens if no handler is provided ?", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573308723", "createdAt": "2021-02-09T22:58:47Z", "author": {"login": "dhanainme"}, "path": "workflow-archiver/workflow_archiver/arg_parser.py", "diffHunk": "@@ -0,0 +1,72 @@\n+\n+\n+\"\"\"\n+This module parses the arguments given through the torch-workflow-archiver command-line.\n+\"\"\"\n+\n+import argparse\n+import os\n+\n+\n+# noinspection PyTypeChecker\n+class ArgParser(object):\n+\n+    \"\"\"\n+    Argument parser for torch-workflow-archiver commands\n+    \"\"\"\n+\n+    @staticmethod\n+    def workflow_archiver_args_parser():\n+\n+        \"\"\" Argument parser for torch-workflow-archiver\n+        \"\"\"\n+\n+        parser_workflow_archiver = argparse.ArgumentParser(prog='torch-workflow-archiver',\n+                                                           description='Torch Workflow Archiver Tool',\n+                                                           formatter_class=argparse.RawTextHelpFormatter)\n+\n+        parser_workflow_archiver.add_argument('--workflow-name',\n+                                              required=True,\n+                                              type=str,\n+                                              default=None,\n+                                              help='Exported workflow name. Exported file will be named as'\n+                                                   ' workflow-name.war and saved in current working directory '\n+                                                   'if no --export-path is specified, '\n+                                                   'else it will be saved under the export path')\n+\n+        parser_workflow_archiver.add_argument('--spec-file',\n+                                              required=True,\n+                                              type=str,\n+                                              default=None,\n+                                              help='Path to .yaml file containing workflow DAG specification.')\n+\n+        parser_workflow_archiver.add_argument('--handler',\n+                                              required=False,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMxMTY4MA==", "bodyText": "May have to explicitly document this behavior on what files get archived.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573311680", "createdAt": "2021-02-09T23:05:15Z", "author": {"login": "dhanainme"}, "path": "workflow-archiver/workflow_archiver/workflow_packaging_utils.py", "diffHunk": "@@ -0,0 +1,198 @@\n+\n+\n+\"\"\"\n+Helper utils for Workflow Archiver tool\n+\"\"\"\n+\n+import logging\n+import os\n+import re\n+import zipfile\n+import shutil\n+import tempfile\n+from .workflow_archiver_error import WorkflowArchiverError\n+\n+from .manifest_components.manifest import Manifest\n+from .manifest_components.workflow import Workflow\n+\n+MANIFEST_FILE_NAME = 'MANIFEST.json'\n+WAR_INF = 'WAR-INF'\n+\n+\n+class WorkflowExportUtils(object):\n+    \"\"\"\n+    Helper utils for Workflow Archiver tool.\n+    This class lists out all the methods such as validations for workflow archiving.\n+    \"\"\"\n+\n+    @staticmethod\n+    def get_archive_export_path(export_file_path, workflow_name):\n+        return os.path.join(export_file_path, f'{workflow_name}.war')\n+\n+    @staticmethod\n+    def check_war_already_exists(workflow_name, export_file_path, overwrite):\n+        \"\"\"\n+        Function to check if .war already exists\n+        :param workflow_name:\n+        :param export_file_path:\n+        :param overwrite:\n+        :return:\n+        \"\"\"\n+        if export_file_path is None:\n+            export_file_path = os.getcwd()\n+\n+        export_file = WorkflowExportUtils.get_archive_export_path(export_file_path, workflow_name)\n+\n+        if os.path.exists(export_file):\n+            if overwrite:\n+                logging.warning(\"Overwriting %s ...\", export_file)\n+            else:\n+                raise WorkflowArchiverError(\"{0} already exists.\\n\"\n+                                            \"Please specify --force/-f option to overwrite the workflow archive \"\n+                                            \"output file.\\n\"\n+                                            \"See -h/--help for more details.\".format(export_file))\n+\n+        return export_file_path\n+\n+    @staticmethod\n+    def generate_workflow(workflow_args):\n+        workflow = Workflow(workflow_name=workflow_args.workflow_name, spec_file=workflow_args.spec_file,\n+                            handler=workflow_args.handler)\n+        return workflow\n+\n+    @staticmethod\n+    def generate_manifest_json(args):\n+        \"\"\"\n+        Function to generate manifest as a json string from the inputs provided by the user in the command line\n+        :param args:\n+        :return:s\n+        \"\"\"\n+\n+        workflow = WorkflowExportUtils.generate_workflow(args)\n+\n+        manifest = Manifest(workflow=workflow)\n+\n+        return str(manifest)\n+\n+    @staticmethod\n+    def clean_temp_files(temp_files):\n+        for f in temp_files:\n+            os.remove(f)\n+\n+    @staticmethod\n+    def make_dir(d):\n+        if not os.path.isdir(d):\n+            os.makedirs(d)\n+\n+    @staticmethod\n+    def copy_artifacts(workflow_name, artifact_files):\n+        \"\"\"\n+        copy workflow artifacts in a common workflow directory for archiving\n+        :param workflow_name: name of workflow being archived\n+        :param artifact_files: list of files to be copied in archive\n+        :return:\n+        \"\"\"\n+        workflow_path = os.path.join(tempfile.gettempdir(), workflow_name)\n+        if os.path.exists(workflow_path):\n+            shutil.rmtree(workflow_path)\n+        WorkflowExportUtils.make_dir(workflow_path)\n+        for path in artifact_files:\n+            if path:\n+                for file in path.split(\",\"):\n+                    shutil.copy(file, workflow_path)\n+\n+        return workflow_path\n+\n+    @staticmethod\n+    def archive(export_file, workflow_name, workflow_path, manifest):\n+        \"\"\"\n+        Create a workflow-archive\n+        :param export_file:\n+        :param workflow_name:\n+        :param workflow_path\n+        :param manifest:\n+        :return:\n+        \"\"\"\n+        war_path = WorkflowExportUtils.get_archive_export_path(export_file, workflow_name)\n+        try:\n+            with zipfile.ZipFile(war_path, 'w', zipfile.ZIP_DEFLATED) as z:\n+                WorkflowExportUtils.archive_dir(workflow_path, z)\n+                # Write the manifest here now as a json\n+                z.writestr(os.path.join(WAR_INF, MANIFEST_FILE_NAME), manifest)\n+        except IOError:\n+            logging.error(\"Failed to save the workflow-archive to workflow-path \\\"%s\\\". \"\n+                          \"Check the file permissions and retry.\", export_file)\n+            raise\n+        except Exception as e:\n+            logging.error(\"Failed to convert %s to the workflow-archive.\", workflow_name)\n+            raise e\n+\n+    @staticmethod\n+    def archive_dir(path, dst):\n+\n+        \"\"\"\n+        This method zips the dir and filters out some files based on a expression\n+        :param path:\n+        :param dst:\n+        :return:\n+        \"\"\"\n+        unwanted_dirs = {'__MACOSX', '__pycache__'}\n+\n+        for root, directories, files in os.walk(path):\n+            # Filter directories\n+            directories[:] = [d for d in directories if WorkflowExportUtils.directory_filter(d, unwanted_dirs)]\n+            for f in files:\n+                file_path = os.path.join(root, f)\n+                dst.write(file_path, os.path.relpath(file_path, path))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMxMjMzMg==", "bodyText": "Nit : Separate methods for single method calls which can be grouped.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573312332", "createdAt": "2021-02-09T23:06:37Z", "author": {"login": "dhanainme"}, "path": "workflow-archiver/workflow_archiver/workflow_packaging_utils.py", "diffHunk": "@@ -0,0 +1,198 @@\n+\n+\n+\"\"\"\n+Helper utils for Workflow Archiver tool\n+\"\"\"\n+\n+import logging\n+import os\n+import re\n+import zipfile\n+import shutil\n+import tempfile\n+from .workflow_archiver_error import WorkflowArchiverError\n+\n+from .manifest_components.manifest import Manifest\n+from .manifest_components.workflow import Workflow\n+\n+MANIFEST_FILE_NAME = 'MANIFEST.json'\n+WAR_INF = 'WAR-INF'\n+\n+\n+class WorkflowExportUtils(object):\n+    \"\"\"\n+    Helper utils for Workflow Archiver tool.\n+    This class lists out all the methods such as validations for workflow archiving.\n+    \"\"\"\n+\n+    @staticmethod\n+    def get_archive_export_path(export_file_path, workflow_name):\n+        return os.path.join(export_file_path, f'{workflow_name}.war')\n+\n+    @staticmethod\n+    def check_war_already_exists(workflow_name, export_file_path, overwrite):\n+        \"\"\"\n+        Function to check if .war already exists\n+        :param workflow_name:\n+        :param export_file_path:\n+        :param overwrite:\n+        :return:\n+        \"\"\"\n+        if export_file_path is None:\n+            export_file_path = os.getcwd()\n+\n+        export_file = WorkflowExportUtils.get_archive_export_path(export_file_path, workflow_name)\n+\n+        if os.path.exists(export_file):\n+            if overwrite:\n+                logging.warning(\"Overwriting %s ...\", export_file)\n+            else:\n+                raise WorkflowArchiverError(\"{0} already exists.\\n\"\n+                                            \"Please specify --force/-f option to overwrite the workflow archive \"\n+                                            \"output file.\\n\"\n+                                            \"See -h/--help for more details.\".format(export_file))\n+\n+        return export_file_path\n+\n+    @staticmethod\n+    def generate_workflow(workflow_args):\n+        workflow = Workflow(workflow_name=workflow_args.workflow_name, spec_file=workflow_args.spec_file,\n+                            handler=workflow_args.handler)\n+        return workflow\n+\n+    @staticmethod\n+    def generate_manifest_json(args):\n+        \"\"\"\n+        Function to generate manifest as a json string from the inputs provided by the user in the command line\n+        :param args:\n+        :return:s\n+        \"\"\"\n+\n+        workflow = WorkflowExportUtils.generate_workflow(args)\n+\n+        manifest = Manifest(workflow=workflow)\n+\n+        return str(manifest)\n+\n+    @staticmethod\n+    def clean_temp_files(temp_files):\n+        for f in temp_files:\n+            os.remove(f)\n+\n+    @staticmethod\n+    def make_dir(d):\n+        if not os.path.isdir(d):\n+            os.makedirs(d)\n+\n+    @staticmethod\n+    def copy_artifacts(workflow_name, artifact_files):\n+        \"\"\"\n+        copy workflow artifacts in a common workflow directory for archiving\n+        :param workflow_name: name of workflow being archived\n+        :param artifact_files: list of files to be copied in archive\n+        :return:\n+        \"\"\"\n+        workflow_path = os.path.join(tempfile.gettempdir(), workflow_name)\n+        if os.path.exists(workflow_path):\n+            shutil.rmtree(workflow_path)\n+        WorkflowExportUtils.make_dir(workflow_path)\n+        for path in artifact_files:\n+            if path:\n+                for file in path.split(\",\"):\n+                    shutil.copy(file, workflow_path)\n+\n+        return workflow_path\n+\n+    @staticmethod\n+    def archive(export_file, workflow_name, workflow_path, manifest):\n+        \"\"\"\n+        Create a workflow-archive\n+        :param export_file:\n+        :param workflow_name:\n+        :param workflow_path\n+        :param manifest:\n+        :return:\n+        \"\"\"\n+        war_path = WorkflowExportUtils.get_archive_export_path(export_file, workflow_name)\n+        try:\n+            with zipfile.ZipFile(war_path, 'w', zipfile.ZIP_DEFLATED) as z:\n+                WorkflowExportUtils.archive_dir(workflow_path, z)\n+                # Write the manifest here now as a json\n+                z.writestr(os.path.join(WAR_INF, MANIFEST_FILE_NAME), manifest)\n+        except IOError:\n+            logging.error(\"Failed to save the workflow-archive to workflow-path \\\"%s\\\". \"\n+                          \"Check the file permissions and retry.\", export_file)\n+            raise\n+        except Exception as e:\n+            logging.error(\"Failed to convert %s to the workflow-archive.\", workflow_name)\n+            raise e\n+\n+    @staticmethod\n+    def archive_dir(path, dst):\n+\n+        \"\"\"\n+        This method zips the dir and filters out some files based on a expression\n+        :param path:\n+        :param dst:\n+        :return:\n+        \"\"\"\n+        unwanted_dirs = {'__MACOSX', '__pycache__'}\n+\n+        for root, directories, files in os.walk(path):\n+            # Filter directories\n+            directories[:] = [d for d in directories if WorkflowExportUtils.directory_filter(d, unwanted_dirs)]\n+            for f in files:\n+                file_path = os.path.join(root, f)\n+                dst.write(file_path, os.path.relpath(file_path, path))\n+\n+    @staticmethod\n+    def directory_filter(directory, unwanted_dirs):\n+        \"\"\"\n+        This method weeds out unwanted hidden directories from the workflow archive .war file\n+        :param directory:\n+        :param unwanted_dirs:\n+        :return:\n+        \"\"\"\n+        if directory in unwanted_dirs:\n+            return False\n+        if directory.startswith('.'):\n+            return False\n+\n+        return True\n+\n+    @staticmethod\n+    def file_filter(current_file, files_to_exclude):\n+        \"\"\"\n+        This method weeds out unwanted files\n+        :param current_file:\n+        :param files_to_exclude:\n+        :return:\n+        \"\"\"\n+        files_to_exclude.add('MANIFEST.json')\n+        if current_file in files_to_exclude:\n+            return False\n+\n+        elif current_file.endswith(('.pyc', '.DS_Store', '.war')):\n+            return False\n+\n+        return True\n+\n+    @staticmethod\n+    def check_workflow_name_regex_or_exit(workflow_name):\n+        \"\"\"\n+        Method checks whether workflow name passes regex filter.\n+        If the regex Filter fails, the method exits.\n+        :param workflow_name:\n+        :return:\n+        \"\"\"\n+        if not re.match(r'^[A-Za-z0-9][A-Za-z0-9_\\-.]*$', workflow_name):\n+            raise WorkflowArchiverError(\"Workflow name contains special characters.\\n\"\n+                                        \"The allowed regular expression filter for workflow \"\n+                                        \"name is: ^[A-Za-z0-9][A-Za-z0-9_\\\\-.]*$\")\n+\n+    @staticmethod\n+    def validate_inputs(workflow_name, export_path):\n+        WorkflowExportUtils.check_workflow_name_regex_or_exit(workflow_name)\n+        if not os.path.isdir(os.path.abspath(export_path)):\n+            raise WorkflowArchiverError(\"Given export-path {} is not a directory. \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 197}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg3MTA1MzE1", "url": "https://github.com/pytorch/serve/pull/785#pullrequestreview-587105315", "createdAt": "2021-02-09T23:13:32Z", "commit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMzoxMzozMlrOIiwi0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMzoxMzozMlrOIiwi0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMxNzg0Mw==", "bodyText": "Q : Why 2 stores ? Why not just 1 dir for both models & workflow.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573317843", "createdAt": "2021-02-09T23:13:32Z", "author": {"login": "dhanainme"}, "path": "ts/arg_parser.py", "diffHunk": "@@ -33,6 +33,10 @@ def ts_parser():\n                             required=False,\n                             dest='model_store',\n                             help='Model store location from where local or default models can be loaded')\n+        parser.add_argument('--workflow-store',\n+                            required=False,\n+                            dest='workflow_store',\n+                            help='Workflow store location from where local or default workflows can be loaded')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307", "author": {"user": {"login": "dhanainme", "name": null}}, "url": "https://github.com/pytorch/serve/commit/ad264e6919f6d84536b25ae0c0bf2f92a618a307", "committedDate": "2021-03-04T00:08:58Z", "message": "Merge branch 'master' into issue_682"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTUyNjYz", "url": "https://github.com/pytorch/serve/pull/785#pullrequestreview-621552663", "createdAt": "2021-03-25T20:31:25Z", "commit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yNVQyMDozMToyNlrOI98HLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yNVQyMDo0OTowNFrOI98w6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMTgxODkyNw==", "bodyText": "@dhanainme We need to document/add user guide for the differences of the handler for models(nodes) in the workflow with regular handlers we have in the non-workflow use-cases.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r601818927", "createdAt": "2021-03-25T20:31:26Z", "author": {"login": "HamidShojanazeri"}, "path": "examples/Workflows/densenet_image_classifier_pipeline/densenet_model/densenet_handler.py", "diffHunk": "@@ -0,0 +1,147 @@\n+\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMTgyMjQ0Mg==", "bodyText": "@dhanainme Please add some clarification on how the gpu assignment would be handled here.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r601822442", "createdAt": "2021-03-25T20:37:28Z", "author": {"login": "HamidShojanazeri"}, "path": "docs/workflows.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# TorchServe Workflows\n+\n+TorchServe can be used for serving ensemble of models & functions (python) through Workflow APIs. \n+\n+It utilizes [REST based APIs](rest_api.md) for workflow management and predictions.\n+\n+A Workflow is served on TorchServe using a workflow-archive(.war) which comprises of following: \n+\n+## Workflow Specification file\n+\n+A workflow specification is a YAML file which provides the details of the models to be executed and a DAG for defining data flow.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMTgyOTYxMA==", "bodyText": "@dhanainme is this planned to be aded as default handler? or having it in the example would suffice.", "url": "https://github.com/pytorch/serve/pull/785#discussion_r601829610", "createdAt": "2021-03-25T20:49:04Z", "author": {"login": "HamidShojanazeri"}, "path": "ts/torch_handler/densenet_handler.py", "diffHunk": "@@ -0,0 +1,147 @@\n+\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIzNTE3ODgy", "url": "https://github.com/pytorch/serve/pull/785#pullrequestreview-623517882", "createdAt": "2021-03-29T18:18:20Z", "commit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yOVQxODoxODoyMFrOI_jdYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0yOVQxODoxODozMFrOI_jd2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzUxMjE2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            def preprocss(data, context):\n          \n          \n            \n            def preprocess(data, context):", "url": "https://github.com/pytorch/serve/pull/785#discussion_r603512162", "createdAt": "2021-03-29T18:18:20Z", "author": {"login": "maaquib"}, "path": "docs/workflows.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# TorchServe Workflows\n+\n+TorchServe can be used for serving ensemble of models & functions (python) through Workflow APIs. \n+\n+It utilizes [REST based APIs](rest_api.md) for workflow management and predictions.\n+\n+A Workflow is served on TorchServe using a workflow-archive(.war) which comprises of following: \n+\n+## Workflow Specification file\n+\n+A workflow specification is a YAML file which provides the details of the models to be executed and a DAG for defining data flow.\n+\n+E.g.\n+\n+```\n+models:\n+    #global model params\n+    min-workers: 1\n+    max-workers: 4\n+    batch-size: 3\n+    max-batch-delay : 5000\n+    m1:\n+       url : model1.mar #local or public URI\n+       min-workers: 1   #override the global params\n+       max-workers: 2\n+       batch-size: 4\n+     \n+    m2:\n+       url : model2.mar\n+\n+    m3:\n+       url : model3.mar\n+       batch-size: 3\n+\n+    m4:\n+      url : model4.mar\n+ \n+dag:\n+  pre_processing : [m1]\n+  m1 : [m2]\n+  m2 : [m3]\n+  m3 : [m4]\n+  m4 : [postprocessing]\n+```\n+\n+### Workflow Models\n+\n+The `models` section of the workflow specification defines the models used in the workflow. It uses the following syntax:\n+\n+```\n+models:\n+    <model_name>:\n+        url: <local or public url for mar file>\n+```\n+\n+### Workflow model properties\n+\n+User can define following workflow model properties:\n+\n+| Properties | Description | Default value |\n+| --- | --- | --- |\n+| min-workers | Number of minimum workers launched for every workflow model | 1 |\n+| max-workers | Number of maximum workers launched for every workflow model | 1 |\n+| batch-size | Batch size used for every workflow model | 1 |\n+| max-batch-delay | Maximum batch delay time TorchServe waits for every workflow model to receive `batch_size` number of requests.| 50 ms |\n+\n+These properties can be defined as a global value for every model and can be over-ridden at every model level in workflow specification. Refer the above example for more details.\n+\n+## Workflow DAG\n+\n+User can define the dataflow of a workflow using the `dag` section of the workflow specification. The `dag` consists of the model names defined in the `model` section and python function names which are implemented in the workflow-archive's handler file.\n+\n+Eg.\n+```\n+dag:\n+  function1 : [model1]\n+  model1 : [model2]\n+  model2 : [function2]\n+```\n+\n+In the above example the data will flow as follows:\n+\n+```\n+input -> function1 -> model1 -> model2 -> function2 -> output\n+```\n+\n+## Handler file\n+\n+A handler file (python) is supplied in the workflow archive (.war) and consists of all the functions used in the workflow dag.\n+\n+Eg.\n+```\n+\n+def preprocss(data, context):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYwMzUxMjI4Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            def postprocess(data, xontext):\n          \n          \n            \n            def postprocess(data, context):", "url": "https://github.com/pytorch/serve/pull/785#discussion_r603512282", "createdAt": "2021-03-29T18:18:30Z", "author": {"login": "maaquib"}, "path": "docs/workflows.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# TorchServe Workflows\n+\n+TorchServe can be used for serving ensemble of models & functions (python) through Workflow APIs. \n+\n+It utilizes [REST based APIs](rest_api.md) for workflow management and predictions.\n+\n+A Workflow is served on TorchServe using a workflow-archive(.war) which comprises of following: \n+\n+## Workflow Specification file\n+\n+A workflow specification is a YAML file which provides the details of the models to be executed and a DAG for defining data flow.\n+\n+E.g.\n+\n+```\n+models:\n+    #global model params\n+    min-workers: 1\n+    max-workers: 4\n+    batch-size: 3\n+    max-batch-delay : 5000\n+    m1:\n+       url : model1.mar #local or public URI\n+       min-workers: 1   #override the global params\n+       max-workers: 2\n+       batch-size: 4\n+     \n+    m2:\n+       url : model2.mar\n+\n+    m3:\n+       url : model3.mar\n+       batch-size: 3\n+\n+    m4:\n+      url : model4.mar\n+ \n+dag:\n+  pre_processing : [m1]\n+  m1 : [m2]\n+  m2 : [m3]\n+  m3 : [m4]\n+  m4 : [postprocessing]\n+```\n+\n+### Workflow Models\n+\n+The `models` section of the workflow specification defines the models used in the workflow. It uses the following syntax:\n+\n+```\n+models:\n+    <model_name>:\n+        url: <local or public url for mar file>\n+```\n+\n+### Workflow model properties\n+\n+User can define following workflow model properties:\n+\n+| Properties | Description | Default value |\n+| --- | --- | --- |\n+| min-workers | Number of minimum workers launched for every workflow model | 1 |\n+| max-workers | Number of maximum workers launched for every workflow model | 1 |\n+| batch-size | Batch size used for every workflow model | 1 |\n+| max-batch-delay | Maximum batch delay time TorchServe waits for every workflow model to receive `batch_size` number of requests.| 50 ms |\n+\n+These properties can be defined as a global value for every model and can be over-ridden at every model level in workflow specification. Refer the above example for more details.\n+\n+## Workflow DAG\n+\n+User can define the dataflow of a workflow using the `dag` section of the workflow specification. The `dag` consists of the model names defined in the `model` section and python function names which are implemented in the workflow-archive's handler file.\n+\n+Eg.\n+```\n+dag:\n+  function1 : [model1]\n+  model1 : [model2]\n+  model2 : [function2]\n+```\n+\n+In the above example the data will flow as follows:\n+\n+```\n+input -> function1 -> model1 -> model2 -> function2 -> output\n+```\n+\n+## Handler file\n+\n+A handler file (python) is supplied in the workflow archive (.war) and consists of all the functions used in the workflow dag.\n+\n+Eg.\n+```\n+\n+def preprocss(data, context):\n+    pass\n+\n+def postprocess(data, xontext):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307"}, "originalPosition": 97}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3774d22f316dc7429368787ec3efee6ae3d4b03", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c3774d22f316dc7429368787ec3efee6ae3d4b03", "committedDate": "2020-11-26T14:23:44Z", "message": "fixed path in grpc client stub generation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7df082a4036b85095fd9a60d94067b305980242", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/b7df082a4036b85095fd9a60d94067b305980242", "committedDate": "2020-11-26T14:27:32Z", "message": "Corrected exception handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d62f22db63e9349a93a40c658bdde37b103fc9d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/5d62f22db63e9349a93a40c658bdde37b103fc9d", "committedDate": "2020-11-26T14:56:51Z", "message": "fixed path for grpc client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94055831c28081e8aa9e769c0968e174ff1dd3ff", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/94055831c28081e8aa9e769c0968e174ff1dd3ff", "committedDate": "2020-11-27T04:22:34Z", "message": "added list workflow API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43a569fd6e42815d7e0addf54a292b0536ec5d31", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/43a569fd6e42815d7e0addf54a292b0536ec5d31", "committedDate": "2020-11-27T05:18:38Z", "message": "resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a3925b8f84a53082948946bb895b4f2a864db41", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/9a3925b8f84a53082948946bb895b4f2a864db41", "committedDate": "2020-11-27T05:20:56Z", "message": "added unregister API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a350141e1a181e248804cda5c9d12f3036c3f79b", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/a350141e1a181e248804cda5c9d12f3036c3f79b", "committedDate": "2020-11-27T05:30:00Z", "message": "conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cda415c3cf8fcd2ea97686d423a5c96e4004f4b2", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/cda415c3cf8fcd2ea97686d423a5c96e4004f4b2", "committedDate": "2020-11-27T05:30:06Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a158d14fd0e2b2d70f3b2ee353feefe080598eb6", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/a158d14fd0e2b2d70f3b2ee353feefe080598eb6", "committedDate": "2020-11-27T05:50:55Z", "message": "fixed archive UTs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1f7938b64c366b403a640479816e9879130ba91", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/e1f7938b64c366b403a640479816e9879130ba91", "committedDate": "2020-11-27T05:53:40Z", "message": "added missed checkin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "febbd9cf81c78c3bc90e08928d048f993292f740", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/febbd9cf81c78c3bc90e08928d048f993292f740", "committedDate": "2020-11-27T06:02:14Z", "message": "temporarily lowered jacoco coverage criteria"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "861ea2bc3d15eba1212eae6f3e625e03c49e7542", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/861ea2bc3d15eba1212eae6f3e625e03c49e7542", "committedDate": "2020-11-27T06:33:18Z", "message": "PMD and checkstyle fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9a264d6b0dab03d52635b3650a06ab5a2831485", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/a9a264d6b0dab03d52635b3650a06ab5a2831485", "committedDate": "2020-11-27T06:48:35Z", "message": "refactored modelarchive to archive in paths"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "326fdd27640a585bc3def80c4880f0f4d1020865", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/326fdd27640a585bc3def80c4880f0f4d1020865", "committedDate": "2020-11-27T06:55:37Z", "message": "small fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9436387db4dd76a9a70dfd2fc0b5d34a686f837", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/f9436387db4dd76a9a70dfd2fc0b5d34a686f837", "committedDate": "2020-11-27T06:56:33Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf2a0b7f50da7ac6cc9e0750a78ff1ec6cd96be0", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/bf2a0b7f50da7ac6cc9e0750a78ff1ec6cd96be0", "committedDate": "2020-11-27T06:56:51Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b890657012231a555997ad703a14e9961ed13253", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/b890657012231a555997ad703a14e9961ed13253", "committedDate": "2020-11-27T07:01:16Z", "message": "Suppressed unchecked cast warnings (#807)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8cc7b32829f0c15b946d533e813a1b7d6843f0a", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/d8cc7b32829f0c15b946d533e813a1b7d6843f0a", "committedDate": "2020-11-27T07:01:21Z", "message": "workflow inference-1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c7cc73f06b77d6648822e145eb25f8b910b76d04", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/c7cc73f06b77d6648822e145eb25f8b910b76d04", "committedDate": "2020-11-27T07:01:57Z", "message": "Fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a831890e8d5610af65d46bb65529c673a3e0305", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8a831890e8d5610af65d46bb65529c673a3e0305", "committedDate": "2020-11-27T07:15:58Z", "message": "fixed unregister and import issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb4259913e3a5959b2812e6ec59f8845ff15f441", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/eb4259913e3a5959b2812e6ec59f8845ff15f441", "committedDate": "2020-11-27T07:18:47Z", "message": "Merge branch 'issue_682' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c746b1d6f599ac8888ff591f74b87575fea2af5", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/2c746b1d6f599ac8888ff591f74b87575fea2af5", "committedDate": "2020-11-27T07:19:34Z", "message": "minor refactoring (#808)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b70d7cb14ada2afb2eef52467f15d8ee0b67d6e7", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/b70d7cb14ada2afb2eef52467f15d8ee0b67d6e7", "committedDate": "2020-11-27T07:21:51Z", "message": "java formatting fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52dd85edf3e3dfe3d69daf645623163a12fda767", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/52dd85edf3e3dfe3d69daf645623163a12fda767", "committedDate": "2020-11-27T07:27:56Z", "message": "conflict resolution"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "39d22e5395ecc0de2de82f65e87f2ddcd1999a39", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/39d22e5395ecc0de2de82f65e87f2ddcd1999a39", "committedDate": "2020-11-27T08:57:17Z", "message": "Inference handler related enhancements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be72815cde5a4e2a40a3279d70bd4d3643099edf", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/be72815cde5a4e2a40a3279d70bd4d3643099edf", "committedDate": "2020-11-27T09:32:21Z", "message": "ModelServerTest fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "773b20a939d1dbf10534cfa5c740d566e30544bf", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/773b20a939d1dbf10534cfa5c740d566e30544bf", "committedDate": "2020-11-27T10:18:20Z", "message": "PMD fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd67fb8b19b0a254de3e9a91286e77cb88766483", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/fd67fb8b19b0a254de3e9a91286e77cb88766483", "committedDate": "2020-11-27T12:27:30Z", "message": "merged gRPC branch and resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "895189f4969bbdab2ea390599ad4912bb0432560", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/895189f4969bbdab2ea390599ad4912bb0432560", "committedDate": "2020-11-27T16:07:38Z", "message": "Parallel register and error handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdab465fe7e41f6f6ad8bff711b4d5a9f3cd072f", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/bdab465fe7e41f6f6ad8bff711b4d5a9f3cd072f", "committedDate": "2020-11-27T16:09:08Z", "message": "Parallel register and error handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "732ae6e413dccdd248b4045c696ad29979a721f2", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/732ae6e413dccdd248b4045c696ad29979a721f2", "committedDate": "2020-11-27T16:25:39Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ModelServer.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/util/ApiUtils.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/workflow/WorkflowManager.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c283d38578aca5eb433b2fbd3e31544df95dd35", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/7c283d38578aca5eb433b2fbd3e31544df95dd35", "committedDate": "2020-11-27T16:29:28Z", "message": "Merge upstream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08f28402177a69a40fe9fbc8a3c216541b7d085c", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/08f28402177a69a40fe9fbc8a3c216541b7d085c", "committedDate": "2020-11-27T16:32:09Z", "message": "Merge upstream"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe102717cad2f71883435d07e66914727b5e75b3", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/fe102717cad2f71883435d07e66914727b5e75b3", "committedDate": "2020-11-27T16:38:25Z", "message": "Add exception to status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cabca403629cc88cfc20da8a510c88df10f065db", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/cabca403629cc88cfc20da8a510c88df10f065db", "committedDate": "2020-11-27T16:41:04Z", "message": "Small fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ee63d14ce2bf537a08c00114d57a0440ab0638b", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/0ee63d14ce2bf537a08c00114d57a0440ab0638b", "committedDate": "2020-11-27T16:42:22Z", "message": "Small fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d3b6195b5eea4bf01fd8c4a316c8729f7603d02", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/5d3b6195b5eea4bf01fd8c4a316c8729f7603d02", "committedDate": "2020-11-27T16:44:36Z", "message": "Merge pull request #810 from maheshambule/issue_682\n\nIssue 682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91615195a727ff6e8837d3db21a410ac1b1acca8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/91615195a727ff6e8837d3db21a410ac1b1acca8", "committedDate": "2020-11-28T04:33:36Z", "message": "refactored ModelRegistrationResult to a new message class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e6d1fa55b5a3a6513438e421301fb7622d47a62", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/1e6d1fa55b5a3a6513438e421301fb7622d47a62", "committedDate": "2020-11-28T08:19:28Z", "message": "Changes for inference request"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a7a9fc016442615afa6eb1c369a21255a696b67", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/8a7a9fc016442615afa6eb1c369a21255a696b67", "committedDate": "2020-11-28T08:19:34Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b136edd919f68d1e7b947599483c96e7b5c0d329", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/b136edd919f68d1e7b947599483c96e7b5c0d329", "committedDate": "2020-11-30T03:52:49Z", "message": "End to end flow for workflow inference request"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "49aea427ac55c4f13885a4a1e06b1286be06d426", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/49aea427ac55c4f13885a4a1e06b1286be06d426", "committedDate": "2020-11-30T04:12:05Z", "message": "Fixed input for inference"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0a332914d0ad2c95b5e76bfce171a0b105afd70", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/c0a332914d0ad2c95b5e76bfce171a0b105afd70", "committedDate": "2020-11-30T05:51:15Z", "message": "Fixed few issues and added pipeline workflow example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0af3a0713dc9ab5fe0d64135e1468bf25f030f7c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0af3a0713dc9ab5fe0d64135e1468bf25f030f7c", "committedDate": "2020-11-30T06:02:47Z", "message": "fixed checkstyle and pmd issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e95aaf65d62bc781628912ef3db62cdc59a94a08", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/e95aaf65d62bc781628912ef3db62cdc59a94a08", "committedDate": "2020-11-30T07:57:12Z", "message": "added workflow store config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c258f8d43a8234e1d999c7c413238ebeebb6fe7", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/7c258f8d43a8234e1d999c7c413238ebeebb6fe7", "committedDate": "2020-11-30T07:57:36Z", "message": "fixed data passing through DAG nodes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "246e2a5f1b0399224bde7cb2ce1ed4e1a1ba9ab6", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/246e2a5f1b0399224bde7cb2ce1ed4e1a1ba9ab6", "committedDate": "2020-11-30T09:59:01Z", "message": "fixed inference flow and updated test war file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1abac691d8a929884711e99abbf6232244335d8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c1abac691d8a929884711e99abbf6232244335d8", "committedDate": "2020-11-30T11:39:27Z", "message": "Added workflow archive test cases"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ddf2c57cb7d981b93fa5f1719db56691f394152e", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ddf2c57cb7d981b93fa5f1719db56691f394152e", "committedDate": "2020-11-30T13:51:30Z", "message": "Added workflow test cases in frontend build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b6f704be417bc42f5cacd79ecbdf2a3373443a5", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/6b6f704be417bc42f5cacd79ecbdf2a3373443a5", "committedDate": "2020-11-30T14:28:14Z", "message": "removed functions from list model api response"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdd28133452a24c881f3d57cd73807605483ed87", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/bdd28133452a24c881f3d57cd73807605483ed87", "committedDate": "2020-11-30T15:02:22Z", "message": "skipped snapshot generation for workflow models"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d934c393eea59527ab9994a67e295ca6eb131c8d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d934c393eea59527ab9994a67e295ca6eb131c8d", "committedDate": "2020-12-01T05:07:17Z", "message": "fixed multiple inference issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "075999c8271d187b78333197794e495ef5df626f", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/075999c8271d187b78333197794e495ef5df626f", "committedDate": "2020-12-01T05:08:02Z", "message": "refactored max batch delay param"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dc6feb98f6e51344e29cc13537b41f4fc5f57e9", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/9dc6feb98f6e51344e29cc13537b41f4fc5f57e9", "committedDate": "2020-12-01T09:17:41Z", "message": "Async predict request handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27c8840e6941c59da43f7f66d5c851d84b29cb50", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/27c8840e6941c59da43f7f66d5c851d84b29cb50", "committedDate": "2020-12-01T09:27:04Z", "message": "disabled html escaping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c008365ce831016db499152b01999c2cdce2e0ff", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c008365ce831016db499152b01999c2cdce2e0ff", "committedDate": "2020-12-01T10:18:22Z", "message": "frontend build fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "497a6c8253973fa1c95167847f8fe75b69b9a6a8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/497a6c8253973fa1c95167847f8fe75b69b9a6a8", "committedDate": "2020-12-01T10:18:41Z", "message": "added support for single node dag"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "881cb384a8aa4a819a4551015e9af263ab9bcf07", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/881cb384a8aa4a819a4551015e9af263ab9bcf07", "committedDate": "2020-12-01T17:04:47Z", "message": "removed generated gRPC files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b7c1a3776d896a2c7541b7622dcdde1ccb60292", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0b7c1a3776d896a2c7541b7622dcdde1ccb60292", "committedDate": "2020-12-01T17:32:42Z", "message": "refactored workflow inference execuor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac33310b1bf6fb9e04a5124bd284135e9d7e7382", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/ac33310b1bf6fb9e04a5124bd284135e9d7e7382", "committedDate": "2020-12-01T21:05:11Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0422f0933489ed42b4c896be042d79b6005dcade", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0422f0933489ed42b4c896be042d79b6005dcade", "committedDate": "2020-12-02T04:08:26Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b68184561378807bb8b4b66fed9991915478b6c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8b68184561378807bb8b4b66fed9991915478b6c", "committedDate": "2020-12-02T06:53:43Z", "message": "incorporated code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1e7d23f6fd8471399d4fa7871a77b1f1fc24425", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/a1e7d23f6fd8471399d4fa7871a77b1f1fc24425", "committedDate": "2020-12-02T09:48:07Z", "message": "added support for multi output"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2388a21a044ecea5ace440eb76a95635d71f4786", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2388a21a044ecea5ace440eb76a95635d71f4786", "committedDate": "2020-12-02T10:36:33Z", "message": "resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "385f92a84502652a3c66118d34129f354a967682", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/385f92a84502652a3c66118d34129f354a967682", "committedDate": "2020-12-02T10:37:08Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8239d5fb2817080a46e6d43d7e8fc5d2c039c2a9", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8239d5fb2817080a46e6d43d7e8fc5d2c039c2a9", "committedDate": "2020-12-02T10:42:53Z", "message": "reverted unwanted changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "273863d2fad6453420699ff7eca36a2d7fd3922b", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/273863d2fad6453420699ff7eca36a2d7fd3922b", "committedDate": "2020-12-02T16:13:01Z", "message": "added workflow documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d61852dd3a995332c244ed86c91826bc6d2d264", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0d61852dd3a995332c244ed86c91826bc6d2d264", "committedDate": "2020-12-02T16:31:20Z", "message": "added workflow-store flag in torchserve"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30e15d263479d9624f40bb365f338ad4f294cdb1", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/30e15d263479d9624f40bb365f338ad4f294cdb1", "committedDate": "2020-12-02T16:57:44Z", "message": "Removed old scripts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43f5d4f08471b34cd15190237a544def85e91d07", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/43f5d4f08471b34cd15190237a544def85e91d07", "committedDate": "2020-12-02T16:58:09Z", "message": "updated known issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35af895b693a31d8bb11b7c29333e22f337a3935", "author": {"user": {"login": "chauhang", "name": "Geeta Chauhan"}}, "url": "https://github.com/pytorch/serve/commit/35af895b693a31d8bb11b7c29333e22f337a3935", "committedDate": "2020-12-03T02:54:38Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8779c5d752196099bebdae036426cededda31359", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/8779c5d752196099bebdae036426cededda31359", "committedDate": "2020-12-04T16:46:51Z", "message": "Multi output support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "591f3ecbc0980b2b5f2da1ce0757c4a658e30b2a", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/591f3ecbc0980b2b5f2da1ce0757c4a658e30b2a", "committedDate": "2020-12-09T03:46:10Z", "message": "merged master and resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c17eee86df7f9dccfeabbf97d7d963aab367d5ea", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c17eee86df7f9dccfeabbf97d7d963aab367d5ea", "committedDate": "2020-12-09T03:46:27Z", "message": "Merge branch 'issue_656' of https://github.com/pytorch/serve into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26cfa0a859bdce1cead7c39cc2d281e15261c2e5", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/26cfa0a859bdce1cead7c39cc2d281e15261c2e5", "committedDate": "2020-12-09T03:56:50Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccdd310e704afb8eb0c506f4ac3c554241acf1bf", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ccdd310e704afb8eb0c506f4ac3c554241acf1bf", "committedDate": "2020-12-09T06:53:58Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "557f51e00d1c4fb5f319d6fddeff3abdfa6f875a", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/557f51e00d1c4fb5f319d6fddeff3abdfa6f875a", "committedDate": "2020-12-10T04:51:42Z", "message": "fixed management api newman command"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9bf3a7988df337b9aab074a09079ea792c88aa3", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d9bf3a7988df337b9aab074a09079ea792c88aa3", "committedDate": "2020-12-10T05:00:10Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dfdecc607da0df3e48fa7ed36cd5a2329e5f1da", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/4dfdecc607da0df3e48fa7ed36cd5a2329e5f1da", "committedDate": "2020-12-10T05:24:40Z", "message": "fixed import issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b21a174de3fa8971137a763cdc6be02267a851ae", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/b21a174de3fa8971137a763cdc6be02267a851ae", "committedDate": "2020-12-10T05:24:56Z", "message": "fixed regression pytest issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e015f40dd628eacf5a94e2fbbccd8aa96b434d6", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/5e015f40dd628eacf5a94e2fbbccd8aa96b434d6", "committedDate": "2020-12-10T16:56:53Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72afd136062d744e6feddb74c973cd7c1ad0da71", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/72afd136062d744e6feddb74c973cd7c1ad0da71", "committedDate": "2020-12-16T11:59:42Z", "message": "resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5ff103b62b77e266f025a1d3bff9520f0804bb6", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/b5ff103b62b77e266f025a1d3bff9520f0804bb6", "committedDate": "2020-12-16T12:28:18Z", "message": "Merge branch 'master' into workflow_archiver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c370a99a254192587d9b7f9bd47fa18d3c24c72", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2c370a99a254192587d9b7f9bd47fa18d3c24c72", "committedDate": "2020-12-16T12:31:07Z", "message": "minor doc fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd8125da1868d14cdb0b4a0104b2b2de2b61b108", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/bd8125da1868d14cdb0b4a0104b2b2de2b61b108", "committedDate": "2020-12-16T12:33:33Z", "message": "Merge branch 'issue_656' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c76136aa4245d042e6ebfd547e7c0a7a22569a9d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c76136aa4245d042e6ebfd547e7c0a7a22569a9d", "committedDate": "2020-12-16T12:54:14Z", "message": "fixed test cases for windows"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "73d6400b4f8c9ffc842480c013a645bf5528564a", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/73d6400b4f8c9ffc842480c013a645bf5528564a", "committedDate": "2020-12-16T12:58:53Z", "message": "refactored file location"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d4e82970f0e2ad8e4b5577d5fea1a2b7c29f3c1", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8d4e82970f0e2ad8e4b5577d5fea1a2b7c29f3c1", "committedDate": "2020-12-16T13:13:55Z", "message": "fixed typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "077fe91412a58ef7a49f4bed63bf2675a972be25", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/077fe91412a58ef7a49f4bed63bf2675a972be25", "committedDate": "2020-12-16T13:57:14Z", "message": "merged master and resloved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d130f38aeb016d9184d9623b540293c5c25cc6bd", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d130f38aeb016d9184d9623b540293c5c25cc6bd", "committedDate": "2020-12-16T14:13:03Z", "message": "doc updates and test case fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04b40ed750fac689f909c4c0cb6d6bdd1d4ad568", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/04b40ed750fac689f909c4c0cb6d6bdd1d4ad568", "committedDate": "2020-12-16T15:03:03Z", "message": "test case fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "367af7b148e40e2fbf570ba89bbc30e19edad125", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/367af7b148e40e2fbf570ba89bbc30e19edad125", "committedDate": "2020-12-16T15:07:47Z", "message": "ModelArchiveTest fix for windows"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "957a51673aa5cac688a6f00e4e6ceb1177355cbc", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/957a51673aa5cac688a6f00e4e6ceb1177355cbc", "committedDate": "2020-12-22T05:23:28Z", "message": "Merge branch 'master' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11440ddca81232289e028141994edd40e1738cf5", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/11440ddca81232289e028141994edd40e1738cf5", "committedDate": "2020-12-22T06:06:05Z", "message": "merged workflow archiver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4350b8bb9384b3aa90436f2030d518dc9bb2ca2", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/e4350b8bb9384b3aa90436f2030d518dc9bb2ca2", "committedDate": "2020-12-22T06:33:04Z", "message": "fixed workflow archiver test case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc4634e15ddf35c27b9a2a3de6331e42a8dfe5b1", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/cc4634e15ddf35c27b9a2a3de6331e42a8dfe5b1", "committedDate": "2020-12-24T05:23:25Z", "message": "refactored workflow test cases to a new file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31fefab8bbe9aacde34e93e5183ebaf6fb4a1b0d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/31fefab8bbe9aacde34e93e5183ebaf6fb4a1b0d", "committedDate": "2020-12-24T06:20:55Z", "message": "added workflow example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b7e71a2db54437a5ef1497ea4d5f947bf5e2525", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0b7e71a2db54437a5ef1497ea4d5f947bf5e2525", "committedDate": "2020-12-24T06:57:07Z", "message": "fixed test case ordering"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d66a40c9f5c531d1a7ac649c7396b29233e8282", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/5d66a40c9f5c531d1a7ac649c7396b29233e8282", "committedDate": "2020-12-24T07:31:36Z", "message": "fixed load model from URI for windows"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fe0a60932945daeeee05f8348ee63365ac6f99d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/3fe0a60932945daeeee05f8348ee63365ac6f99d", "committedDate": "2020-12-24T07:42:07Z", "message": "minor refactoring and cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21427156af58767dea527e1e15b557c9fc4c6816", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/21427156af58767dea527e1e15b557c9fc4c6816", "committedDate": "2020-09-17T17:19:21Z", "message": "refactored torchserve job"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77b135601e8052efeaf3895766a274129dca874d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/77b135601e8052efeaf3895766a274129dca874d", "committedDate": "2020-09-17T17:21:11Z", "message": "added grpc server side implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b75b81a07d4879f4e84f7a7ef3e21027f3e69125", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/b75b81a07d4879f4e84f7a7ef3e21027f3e69125", "committedDate": "2020-09-17T17:22:27Z", "message": "added protobuff files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d46d56a9537c13bf23771292650c550b135ed482", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d46d56a9537c13bf23771292650c550b135ed482", "committedDate": "2020-09-17T17:24:39Z", "message": "added grpc server startup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fec11bfef5e9877639a5eb2cf02d17f3a1251072", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/fec11bfef5e9877639a5eb2cf02d17f3a1251072", "committedDate": "2020-09-17T17:25:02Z", "message": "fixed valid port test case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22734badb2627f8be501225fb6ab748221a9f31e", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/22734badb2627f8be501225fb6ab748221a9f31e", "committedDate": "2020-09-17T17:27:13Z", "message": "automated server stub generation through gradle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14cb1eb338b14079df737e35dc1e88b057e49de9", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/14cb1eb338b14079df737e35dc1e88b057e49de9", "committedDate": "2020-09-17T17:30:30Z", "message": "enhanced sanity script to validate grpc inference api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "199811c627df6a19584bb324b8c533065c2ab51d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/199811c627df6a19584bb324b8c533065c2ab51d", "committedDate": "2020-09-17T17:32:21Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "151cdcc39f422f64d600b2eaf8b4a2cc9aaa51bd", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/151cdcc39f422f64d600b2eaf8b4a2cc9aaa51bd", "committedDate": "2020-09-17T18:00:24Z", "message": "Added grpcio-tools package"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1abb5cb2b8575448a4e99c36eb849bf3fb14157", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d1abb5cb2b8575448a4e99c36eb849bf3fb14157", "committedDate": "2020-09-17T18:14:45Z", "message": "fixed path issue in grpc client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48b049c3befb3c3c357a1fce92636c1bbb046211", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/48b049c3befb3c3c357a1fce92636c1bbb046211", "committedDate": "2020-09-17T18:27:16Z", "message": "fixed incorrect exit logic in client script"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "897d5d7a226f12f9dbda509db620e9d03b0f2f55", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/897d5d7a226f12f9dbda509db620e9d03b0f2f55", "committedDate": "2020-09-18T01:48:44Z", "message": "removed json parse in python gRPC client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ffc689c85b2d9af523c4309f0dbb516ed3f437c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0ffc689c85b2d9af523c4309f0dbb516ed3f437c", "committedDate": "2020-09-18T05:02:03Z", "message": "removed unnecessary file checkin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3770272cbc46f99f48d7970e4869cd87a26fde5e", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/3770272cbc46f99f48d7970e4869cd87a26fde5e", "committedDate": "2020-09-18T07:16:51Z", "message": "added regression test cases for gRPC regression APIs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "585c03f75f571f9c40766f249e20ce40082865e0", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/585c03f75f571f9c40766f249e20ce40082865e0", "committedDate": "2020-09-18T07:55:32Z", "message": "added tolerance check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79dd23b6ce8d1c17e42e7d59b2de3175030c3931", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/79dd23b6ce8d1c17e42e7d59b2de3175030c3931", "committedDate": "2020-09-18T09:41:50Z", "message": "added python client stub cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7037e6cc2c8a5e0af020983f2f318de57fc4a6b5", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/7037e6cc2c8a5e0af020983f2f318de57fc4a6b5", "committedDate": "2020-09-22T03:34:17Z", "message": "enhanced error handling for inference APIs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a4a69a5bbcd5001b65831ad0ded1910cfceec20", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/5a4a69a5bbcd5001b65831ad0ded1910cfceec20", "committedDate": "2020-09-22T03:42:54Z", "message": "removed unused utility file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "438683e9df08f9c800929deef8d03fd37e24b703", "author": {"user": {"login": "shivamshriwas", "name": "shivamshriwas"}}, "url": "https://github.com/pytorch/serve/commit/438683e9df08f9c800929deef8d03fd37e24b703", "committedDate": "2020-09-24T08:58:22Z", "message": "added support for datafile driven management api test collection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90bfde4c5ea0d60600105933f7d852827182b0f8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/90bfde4c5ea0d60600105933f7d852827182b0f8", "committedDate": "2020-09-28T05:44:58Z", "message": "added gRPC support for management APIs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e3ccaaf17a5d8c9e97870c8d3c3b919f8ade848", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/7e3ccaaf17a5d8c9e97870c8d3c3b919f8ade848", "committedDate": "2020-09-28T07:22:12Z", "message": "added minor fixes found during testing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee0f0579f1ddbe1559fd8f0ce59135b137b69a83", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ee0f0579f1ddbe1559fd8f0ce59135b137b69a83", "committedDate": "2020-09-28T11:44:27Z", "message": "enhanced grpc pytest suite to use grpc client for registering and unregistering model"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78533c249cc89785f00b511ac1a5294ddb5132e4", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/78533c249cc89785f00b511ac1a5294ddb5132e4", "committedDate": "2020-09-28T11:45:32Z", "message": "updated command to generate python client stubs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dfbffa36c7fddfe400a768b6531b4099639feb74", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/dfbffa36c7fddfe400a768b6531b4099639feb74", "committedDate": "2020-09-28T11:46:07Z", "message": "removed netty http staus dependency from wlm framework"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a529cdf55ee47a5593b8ab6ce8036ce8843c766", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2a529cdf55ee47a5593b8ab6ce8036ce8843c766", "committedDate": "2020-09-28T12:13:17Z", "message": "refacroted common code to utility module"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b70abaf794eba2bc6326d921dedcb4e12a10c67", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/6b70abaf794eba2bc6326d921dedcb4e12a10c67", "committedDate": "2020-09-28T18:23:08Z", "message": "added gRPC management api test cases in regression suite and minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "747e5068ee7009c1c733673de4c73ce1e3859a7c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/747e5068ee7009c1c733673de4c73ce1e3859a7c", "committedDate": "2020-09-29T11:30:26Z", "message": "added ping api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8413651bfa100ccea09528535a4a32ec24764ba0", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8413651bfa100ccea09528535a4a32ec24764ba0", "committedDate": "2020-09-29T11:31:36Z", "message": "removed grpc metric api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "328bb4e7e022bb22eace1a71218743746a94749c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/328bb4e7e022bb22eace1a71218743746a94749c", "committedDate": "2020-09-29T14:50:46Z", "message": "added ssl support for gRPC server"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0c1795dc84065cbc908119e09e8b5a87d9bc3edb", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0c1795dc84065cbc908119e09e8b5a87d9bc3edb", "committedDate": "2020-09-29T15:58:20Z", "message": "added documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff2517544e8346ca602367c4820b27f6c675b3b9", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ff2517544e8346ca602367c4820b27f6c675b3b9", "committedDate": "2020-09-30T05:39:42Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1822ae336ecc25c70ef6b25a5155cfa09844438b", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/1822ae336ecc25c70ef6b25a5155cfa09844438b", "committedDate": "2020-09-30T06:36:40Z", "message": "fixed issue after conflict resolution"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "039f48c411b0758cd2035ba8c7831a9d43441554", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/039f48c411b0758cd2035ba8c7831a9d43441554", "committedDate": "2020-09-30T08:57:45Z", "message": "added reference to python gRPC client, used in regression suite, in grpc doc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "126532e559d26dc4a976748e76290079ed207112", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/126532e559d26dc4a976748e76290079ed207112", "committedDate": "2020-09-30T13:36:22Z", "message": "added validation for register and unregister model in sanity script"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca76ede3b93380502f765da61aa19769164fd25b", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ca76ede3b93380502f765da61aa19769164fd25b", "committedDate": "2020-09-30T13:36:37Z", "message": "updated docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6eb737f35c9d7281aa9404743210b489a0747700", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/6eb737f35c9d7281aa9404743210b489a0747700", "committedDate": "2020-09-30T14:41:49Z", "message": "minor fixes in grpc doc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d27495cda48b568da8ecc10c7f907d6b0894791a", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d27495cda48b568da8ecc10c7f907d6b0894791a", "committedDate": "2020-09-30T17:09:42Z", "message": "updated gRPC server await termination code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b7eabfe6274730682707f98c564c6f87687360c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0b7eabfe6274730682707f98c564c6f87687360c", "committedDate": "2020-09-30T17:24:31Z", "message": "refactored gRPC server startup code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "15322c6659a98b3f545f0d3339e400e4b163b63c", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/15322c6659a98b3f545f0d3339e400e4b163b63c", "committedDate": "2020-09-30T18:08:39Z", "message": "added null check before terminating gRPC servers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "590fca846bc97fd1d16663ec4584bf57bb49d175", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/590fca846bc97fd1d16663ec4584bf57bb49d175", "committedDate": "2020-10-01T12:44:49Z", "message": "minor refactoring of method name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b3a6b5847d6272520af7eae3b49bfba211b41ce", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/5b3a6b5847d6272520af7eae3b49bfba211b41ce", "committedDate": "2020-10-01T12:45:24Z", "message": "skipped grpc package from jacoco verification"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "63aa51ab276c76c55fb0ffc91b1aec1542412ee3", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/63aa51ab276c76c55fb0ffc91b1aec1542412ee3", "committedDate": "2020-10-12T13:07:05Z", "message": "Fixed typo in doc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "461395bc1f624ef8f240c14d3e5931608deb83f7", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/461395bc1f624ef8f240c14d3e5931608deb83f7", "committedDate": "2020-10-12T13:07:37Z", "message": "added error logs in gRPC client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "653276e09b8097f58c15c88203362292b61d8030", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/653276e09b8097f58c15c88203362292b61d8030", "committedDate": "2020-10-12T13:09:47Z", "message": "added gRPC server interceptor to log api access data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1a62279c9c9d94041aac0150dbe60adfc690df2", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/f1a62279c9c9d94041aac0150dbe60adfc690df2", "committedDate": "2020-10-12T13:44:56Z", "message": "added checkstyle fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e78dbff1edff59a1222fb79e8e6856603ca4ff1d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/e78dbff1edff59a1222fb79e8e6856603ca4ff1d", "committedDate": "2020-10-13T09:22:54Z", "message": "fixed grpc command in readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3bb125a4374fd47552d74e306876ee34fc5956f2", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/3bb125a4374fd47552d74e306876ee34fc5956f2", "committedDate": "2020-10-14T03:31:33Z", "message": "refactored test cases to removed code duplication"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fa484a21838e7157fe3705b0215d3aa5d2bcdfe", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/4fa484a21838e7157fe3705b0215d3aa5d2bcdfe", "committedDate": "2020-10-14T03:32:42Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b867a0da6d1896166692e15b12991546cbd6968", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2b867a0da6d1896166692e15b12991546cbd6968", "committedDate": "2020-10-14T09:51:18Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3d7b0b9add224eee1017ca4ba0b13ba583ed5a65", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/3d7b0b9add224eee1017ca4ba0b13ba583ed5a65", "committedDate": "2020-10-17T02:03:47Z", "message": "Fixed typo in link.\n\nCo-authored-by: Amit Agarwal <amtagrwl@gmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8dac80c5b3279d323535da0d8694f6ac30e1b9a8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/8dac80c5b3279d323535da0d8694f6ac30e1b9a8", "committedDate": "2020-10-27T06:06:40Z", "message": "merge master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "700defce59120529158478d0841fbc54dab4c6d8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/700defce59120529158478d0841fbc54dab4c6d8", "committedDate": "2020-10-27T06:27:24Z", "message": "fixed compilation issues after conflict resolution"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc8e410e4b1ff891f361a970ea609947324ecc0d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/dc8e410e4b1ff891f361a970ea609947324ecc0d", "committedDate": "2020-10-30T10:49:28Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fb3d8ffc1bdba064a261a58994f06d013827954", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/7fb3d8ffc1bdba064a261a58994f06d013827954", "committedDate": "2020-10-30T13:25:16Z", "message": "Ensemble DAG and Scheduling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01bedc868f5f742416fe241553a140ed254973cf", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/01bedc868f5f742416fe241553a140ed254973cf", "committedDate": "2020-11-05T04:45:28Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22d1b06b1b81f2f66efdf4191f4a26fea215c862", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/22d1b06b1b81f2f66efdf4191f4a26fea215c862", "committedDate": "2020-11-06T03:05:32Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f5818ca248cf25b45134415c59536f6ab4326aef", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/f5818ca248cf25b45134415c59536f6ab4326aef", "committedDate": "2020-11-06T04:27:18Z", "message": "fixed regression suite pytest issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "410ce11a62f8fbe331298bd4bc62299fb8caab45", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/410ce11a62f8fbe331298bd4bc62299fb8caab45", "committedDate": "2020-11-06T05:06:40Z", "message": "fixed pytest case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1bd835d7c5e1c3ecc384e7a44e7ef0a71dabf570", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/1bd835d7c5e1c3ecc384e7a44e7ef0a71dabf570", "committedDate": "2020-11-09T18:18:07Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d28264655f4e3f779a1f3e7370a8344b508c2e1b", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/d28264655f4e3f779a1f3e7370a8344b508c2e1b", "committedDate": "2020-11-11T08:52:22Z", "message": "add tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87575f6b4cfc6155549ec10cb8158a0e84b43413", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/87575f6b4cfc6155549ec10cb8158a0e84b43413", "committedDate": "2020-11-11T17:38:13Z", "message": "workflow archiver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbaeafaff1be364bd4d1509b96356c8473af80b6", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/bbaeafaff1be364bd4d1509b96356c8473af80b6", "committedDate": "2020-11-11T17:39:32Z", "message": "removed pytest report dir"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99df5166d8f165981d642792c5ba2d954b6cda76", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/99df5166d8f165981d642792c5ba2d954b6cda76", "committedDate": "2020-11-12T03:59:37Z", "message": "added workflow test cases to sanity suite"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58172914f0fcb632f472529f73f4cb73dafb751d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/58172914f0fcb632f472529f73f4cb73dafb751d", "committedDate": "2020-11-12T04:37:09Z", "message": "Added coveragerc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fff09b3315ee299e83db8802129738ef281efbae", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/fff09b3315ee299e83db8802129738ef281efbae", "committedDate": "2020-11-12T05:09:40Z", "message": "removed unwanted init files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9fc96730f6a2d54d2c73f74551861d45ff44cae", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/b9fc96730f6a2d54d2c73f74551861d45ff44cae", "committedDate": "2020-11-17T12:10:10Z", "message": "workflow rest apis"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52288b4a3d227beba9117395bb96fc781cfe5569", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/52288b4a3d227beba9117395bb96fc781cfe5569", "committedDate": "2020-11-17T12:16:13Z", "message": "Merged issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c70138d0b9b237055f98e9ed717daf6269e1ed4e", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/c70138d0b9b237055f98e9ed717daf6269e1ed4e", "committedDate": "2020-11-17T12:27:18Z", "message": "Merge branch 'workflow_archiver' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e44a793397572f264cc4c5963b941e4722031b3", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/3e44a793397572f264cc4c5963b941e4722031b3", "committedDate": "2020-11-18T09:24:09Z", "message": "added dummy workflow manager"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d7991e0ba963a8e45810eb023dbcc9d187dfb1d", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/0d7991e0ba963a8e45810eb023dbcc9d187dfb1d", "committedDate": "2020-11-18T09:24:23Z", "message": "yaml read"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a32da3131cfae956204f3c85013b930992cfab85", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/a32da3131cfae956204f3c85013b930992cfab85", "committedDate": "2020-11-18T09:34:49Z", "message": "change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4a4147904d5d95360d507575380628f9531b855", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/f4a4147904d5d95360d507575380628f9531b855", "committedDate": "2020-11-18T09:41:31Z", "message": "Merge branch 'issue_682' into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46a0d8488b696568e0cae27796adab88f6be683c", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/46a0d8488b696568e0cae27796adab88f6be683c", "committedDate": "2020-11-18T09:42:19Z", "message": "Merge pull request #786 from maheshambule/issue_682\n\nEnsemble support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7aa38ddf7363aac9f71138c83fdfb48b05255c07", "author": {"user": {"login": "dhanainme", "name": null}}, "url": "https://github.com/pytorch/serve/commit/7aa38ddf7363aac9f71138c83fdfb48b05255c07", "committedDate": "2020-11-19T00:36:48Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b3ba4c9e16b13bea9969fabed9120648de1c350", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/0b3ba4c9e16b13bea9969fabed9120648de1c350", "committedDate": "2020-11-19T01:42:37Z", "message": "model registration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23f92b60154c0e6955af5a0fc526bbd43609cd77", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/23f92b60154c0e6955af5a0fc526bbd43609cd77", "committedDate": "2020-11-19T01:52:33Z", "message": "add response"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab379aa191bffb7f17602af5c4d05270d53b6c7a", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/ab379aa191bffb7f17602af5c4d05270d53b6c7a", "committedDate": "2020-11-23T05:00:28Z", "message": "Merge pull request #788 from maheshambule/issue_682\n\nmodel registration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c6171666dbea4599055760b83ef156cad2ed075a", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c6171666dbea4599055760b83ef156cad2ed075a", "committedDate": "2020-11-23T06:33:29Z", "message": "merged master and resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8f3f7f9cdc53b640ae584a3b589806f6d2a26e8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/a8f3f7f9cdc53b640ae584a3b589806f6d2a26e8", "committedDate": "2020-11-23T06:55:08Z", "message": "fixed import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2c48a0a9239b27c47ea262c0d52038ef35e8c13", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c2c48a0a9239b27c47ea262c0d52038ef35e8c13", "committedDate": "2020-11-23T07:58:08Z", "message": "fixed sanity suite"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54c63a5264f2d73325eae78f59e745c40a99a7a7", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/54c63a5264f2d73325eae78f59e745c40a99a7a7", "committedDate": "2020-11-23T10:46:42Z", "message": "Updates for register API"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e83517af4856b468256f30f14be03541d68bcd9", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/1e83517af4856b468256f30f14be03541d68bcd9", "committedDate": "2020-11-23T11:41:48Z", "message": "register api changes and formating"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2603a7db9cef908f4d942a87f597badf686861a7", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/2603a7db9cef908f4d942a87f597badf686861a7", "committedDate": "2020-11-23T15:33:25Z", "message": "added workflow archiver in frontend"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a90674f5d222e5a2cfc9a0b4e6329b5380aa528", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/5a90674f5d222e5a2cfc9a0b4e6329b5380aa528", "committedDate": "2020-11-23T15:53:31Z", "message": "add"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0444dbbc38107e29055970b52fd763a6371ef3f0", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/0444dbbc38107e29055970b52fd763a6371ef3f0", "committedDate": "2020-11-23T16:49:24Z", "message": "register refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0c82f7588da6662650575488939927977975aaf", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/e0c82f7588da6662650575488939927977975aaf", "committedDate": "2020-11-24T15:39:57Z", "message": "refactored workflow registration api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04662907a5e972eb7123436f243169d00a8aca05", "author": {"user": {"login": "dhanainme", "name": null}}, "url": "https://github.com/pytorch/serve/commit/04662907a5e972eb7123436f243169d00a8aca05", "committedDate": "2020-11-24T20:53:57Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab7be17b43621435568f1ed349c194ea91d73116", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/ab7be17b43621435568f1ed349c194ea91d73116", "committedDate": "2020-11-24T21:37:57Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5cf2af045df267234fadd893acad31cf134c56b5", "author": {"user": {"login": "chauhang", "name": "Geeta Chauhan"}}, "url": "https://github.com/pytorch/serve/commit/5cf2af045df267234fadd893acad31cf134c56b5", "committedDate": "2020-11-25T07:35:52Z", "message": "Merge branch 'master' into issue_656"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f9f978d65a2036f2c3b18bd547a3cae0b283139", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/8f9f978d65a2036f2c3b18bd547a3cae0b283139", "committedDate": "2020-11-26T07:30:16Z", "message": "Resolve conflicts and Function mar changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc149cf3b05c1f9a297b391a6dd82d2b5ab83578", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/bc149cf3b05c1f9a297b391a6dd82d2b5ab83578", "committedDate": "2020-11-26T08:33:32Z", "message": "added support for pre and post process functions in workflow (#795)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4722928effef4c8ec5c4a01e8db7c04c771b5cc3", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/4722928effef4c8ec5c4a01e8db7c04c771b5cc3", "committedDate": "2020-11-26T08:48:15Z", "message": " refactored workflow message classes to new package"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9c682775281aa4657125641a79f28e2b5008e93", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/c9c682775281aa4657125641a79f28e2b5008e93", "committedDate": "2020-11-26T09:03:28Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fb2209f717136edd51749d17550cce4d84b8cd8", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/8fb2209f717136edd51749d17550cce4d84b8cd8", "committedDate": "2020-11-26T11:30:56Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "733b9797e5605457ac3d82091c84a09beadf0007", "author": {"user": {"login": "maheshambule", "name": "Mahesh Ambule"}}, "url": "https://github.com/pytorch/serve/commit/733b9797e5605457ac3d82091c84a09beadf0007", "committedDate": "2020-11-26T11:31:13Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "decc037bc07974c0a925670e80b49c5ef45fc561", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/decc037bc07974c0a925670e80b49c5ef45fc561", "committedDate": "2020-11-26T13:35:22Z", "message": "added describe workflow api"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f3a0ef8af8ec9c23602ee39ad7d638007e0d2268", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/f3a0ef8af8ec9c23602ee39ad7d638007e0d2268", "committedDate": "2020-11-26T13:36:44Z", "message": "fixed java formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe784637dd34c4db7eb9aab1c70d6cb1ac658f67", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/fe784637dd34c4db7eb9aab1c70d6cb1ac658f67", "committedDate": "2020-11-26T13:56:10Z", "message": "Error handling and request formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbf1b2e2bf94dd2e5296e17417a60d5b8fee6aee", "author": {"user": {"login": "dhaniram-kshirsagar", "name": null}}, "url": "https://github.com/pytorch/serve/commit/fbf1b2e2bf94dd2e5296e17417a60d5b8fee6aee", "committedDate": "2020-11-26T13:56:15Z", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d113274769ed7ea0f3a73eebe21f05e6c4ced7a4", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d113274769ed7ea0f3a73eebe21f05e6c4ced7a4", "committedDate": "2020-11-26T14:10:00Z", "message": "merged master and resolved conflicts"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2134, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}