{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYyMzcyMzE5", "number": 585, "title": "Batch inference hf handler", "bodyText": "Description\nAdding batch inference to HF handler.\nType of change\nPlease delete options that are not relevant.\n\n New feature (non-breaking change which adds functionality)\n This change requires a documentation update\n\nFeature/Issue validation/testing\nThe feature has been tested for sequence, token classification and question answering with batch sizes of 1,4,8.\nHere are the steps to reproduce the results.\nSequence classification:\n\u2022 use this setup_confing.json\nsetup_config_seq_classification.txt\n\u2022 Run the Download_Transformer_models.py\n\u2022torch-model-archiver --model-name BERT_seq_Classification --version 1.0 --serialized-file Transformer_model/pytorch_model.bin --handler ./Transformer_handler_generalized.py --extra-files \"Transformer_model/config.json,./setup_config.json,./Seq_classification_artifacts/index_to_name.json\"\n\u2022torchserve --start --model-store model-store\n\u2022curl -X POST \"localhost:8081/models?model_name=BERT_seq_Classification&url=BERT_seq_Classification.mar&batch_size=3&max_batch_delay=5000&initial_workers=3&synchronous=true\"\n\u2022curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification  -T ./Seq_classification_artifacts/sample_text1.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification  -T ./Seq_classification_artifacts/sample_text2.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text3.txt&\nFor batch size of 8\n\u2022curl -X POST \"localhost:8081/models?model_name=BERT_seq_Classification&url=BERT_seq_Classification.mar&batch_size=8&max_batch_delay=5000&initial_workers=3&synchronous=true\"\n\u2022 curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification  -T ./Seq_classification_artifacts/sample_text1.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification  -T ./Seq_classification_artifacts/sample_text2.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text3.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text4.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text5.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text6.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text7.txt& curl -X POST http://127.0.0.1:8080/predictions/BERT_seq_Classification -T ./Seq_classification_artifacts/sample_text8.txt&\nQuestion answering:\n\u2022use this setup_confing.json\nsetup_config_question_answeing.txt\n\u2022Run the Download_Transformer_models.py\n\u2022torch-model-archiver --model-name DistillBert_qa  --version 1.0 --serialized-file Transformer_model/pytorch_model.bin --handler ./Transformer_handler_generalized.py --extra-files \"Transformer_model/config.json,./setup_config.json\"\n\u2022\u2022torchserve --start --model-store model-store\n\u2022curl -X POST \"localhost:8081/models?model_name=DistillBert_qa&url=DistillBert_qa.mar&batch_size=4&max_batch_delay=5000&initial_workers=3&synchronous=true\"\n\u2022curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa  -T ./QA_artifacts/sample_text.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa  -T ./QA_artifacts/sample_text1.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa-T ./QA_artifacts/sample_text2.txt&\nFor bath size of 8\n\u2022 curl -X POST \"localhost:8081/models?model_name=DistillBert_qa&url=DistillBert_qa.mar&batch_size=8&max_batch_delay=5000&initial_workers=3&synchronous=true\"\n\u2022 curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa  -T ./QA_artifacts/sample_text.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa  -T ./QA_artifacts/sample_text1.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa -T ./QA_artifacts/sample_text2.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa -T ./QA_artifacts/sample_text3.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa -T ./QA_artifacts/sample_text4.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa -T ./QA_artifacts/sample_text5.txt& curl -X POST http://127.0.0.1:8080/predictions/DistillBert_qa -T ./QA_artifacts/sample_text6.txt&\nSame steps for mentioned in sequence classification can be followed for token classification using this setup_config setting\nsetup_config_token_classification.txt\n\n\nUT/IT execution results\n\n\nLogs\nQuestion_answering_batch_inference.log\nBert_seq_classifcation_batch_inference.log\nBert_token_classifcation_batch_inference.log\n\n\nChecklist:\n\n Have you added tests that prove your fix is effective or that this feature works?\n[X ] Have you made corresponding changes to the documentation?", "createdAt": "2020-08-03T20:07:40Z", "url": "https://github.com/pytorch/serve/pull/585", "merged": true, "mergeCommit": {"oid": "c0f2292830c8ed7774f632b2a49eb8b934b9ce90"}, "closed": true, "closedAt": "2020-08-04T18:02:26Z", "author": {"login": "HamidShojanazeri"}, "timelineItems": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7JqcPgH2gAyNDYyMzcyMzE5OjYzNjRhNDQxMDQ4ZDE4NGE4NmE3ZTU2ZjIzZWExOGZmNjkxYTY2M2I=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7qjEiAFqTQ2MTA0NjEyNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6364a441048d184a86a7e56f23ea18ff691a663b", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/6364a441048d184a86a7e56f23ea18ff691a663b", "committedDate": "2020-08-03T03:43:07Z", "message": "Added batch inference"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "174af0e4295cad71394ad0df06558b2c22ed7e96", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/174af0e4295cad71394ad0df06558b2c22ed7e96", "committedDate": "2020-08-03T18:45:05Z", "message": "added the batch inference support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d7195a4148b8994cb4ccf71089fb0b2339897ca", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/6d7195a4148b8994cb4ccf71089fb0b2339897ca", "committedDate": "2020-08-03T18:49:54Z", "message": "duplicated file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b3aed714c441bed17baa69231e6156f0b37efdb", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/3b3aed714c441bed17baa69231e6156f0b37efdb", "committedDate": "2020-08-03T18:50:50Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5c1b8d9a5c0fc0dc893f1b187cd5c68169a6bf3", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/a5c1b8d9a5c0fc0dc893f1b187cd5c68169a6bf3", "committedDate": "2020-08-03T18:51:02Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "717fdef4f092682de790c019d657fc03fb11d2b5", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/717fdef4f092682de790c019d657fc03fb11d2b5", "committedDate": "2020-08-03T18:51:10Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "877a982eef5a9c9b84d3bc28d71bfad072b8a7b7", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/877a982eef5a9c9b84d3bc28d71bfad072b8a7b7", "committedDate": "2020-08-03T18:51:18Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "963c3187312cb3f4071b763875a986602b914f72", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/963c3187312cb3f4071b763875a986602b914f72", "committedDate": "2020-08-03T18:51:28Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb06d7ca1621341c8f891091280d865cd755cc39", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/cb06d7ca1621341c8f891091280d865cd755cc39", "committedDate": "2020-08-03T18:51:38Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f8fe4f9864158998300ae0c300b5f5bae078100", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/5f8fe4f9864158998300ae0c300b5f5bae078100", "committedDate": "2020-08-03T18:52:16Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2cc6029cf54dc71f6f162163277a36151cad3c10", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/2cc6029cf54dc71f6f162163277a36151cad3c10", "committedDate": "2020-08-03T18:52:40Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97671b25e986fe8f3f696cb59283674ce6db3167", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/97671b25e986fe8f3f696cb59283674ce6db3167", "committedDate": "2020-08-03T18:53:29Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d374153d88621ec7cdf7b2bf9dd6bc637267f04a", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/d374153d88621ec7cdf7b2bf9dd6bc637267f04a", "committedDate": "2020-08-03T18:53:37Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a955f55338748a4c81b0f5ad35976102cfc29015", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/a955f55338748a4c81b0f5ad35976102cfc29015", "committedDate": "2020-08-03T18:53:50Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fb77e4182334d1204be2cd67ce4ff774fdf80e6", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/3fb77e4182334d1204be2cd67ce4ff774fdf80e6", "committedDate": "2020-08-03T18:53:59Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1c902ab553fbbfb66f5252f4889aba49367fe41", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/a1c902ab553fbbfb66f5252f4889aba49367fe41", "committedDate": "2020-08-03T18:54:14Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b1bbcf16badc5f50d2e4bf2a5f78d3364c05b61", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/0b1bbcf16badc5f50d2e4bf2a5f78d3364c05b61", "committedDate": "2020-08-03T18:54:21Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0c23833ed265c21ee4aeabe7a2b02fd68388876", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/c0c23833ed265c21ee4aeabe7a2b02fd68388876", "committedDate": "2020-08-03T18:54:29Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04e29312f9f4e93c108eb8adb3e21237ed15ed69", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/04e29312f9f4e93c108eb8adb3e21237ed15ed69", "committedDate": "2020-08-03T18:54:40Z", "message": "batch inference text example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e246af488cff0e77a70e614f9459b21005540ee", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/5e246af488cff0e77a70e614f9459b21005540ee", "committedDate": "2020-08-03T18:56:29Z", "message": "clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50c30c79e04e082db908ebf9fbeaf9e60e50a6ac", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/50c30c79e04e082db908ebf9fbeaf9e60e50a6ac", "committedDate": "2020-08-03T19:05:52Z", "message": "adding support for batch inference"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a18c470ed4592dbcb340ca70f50a09e8d762fae8", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/a18c470ed4592dbcb340ca70f50a09e8d762fae8", "committedDate": "2020-08-04T04:47:02Z", "message": "add example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30217e2a97793d445a62b0a71fb397e0c5267f93", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/30217e2a97793d445a62b0a71fb397e0c5267f93", "committedDate": "2020-08-04T04:47:41Z", "message": "add logs to server side for output tensors from model"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwOTUyNTk2", "url": "https://github.com/pytorch/serve/pull/585#pullrequestreview-460952596", "createdAt": "2020-08-04T15:58:30Z", "commit": {"oid": "30217e2a97793d445a62b0a71fb397e0c5267f93"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "898086a436f5a802b4733e4a764cfc18902c2c7e", "author": {"user": {"login": "chauhang", "name": "Geeta Chauhan"}}, "url": "https://github.com/pytorch/serve/commit/898086a436f5a802b4733e4a764cfc18902c2c7e", "committedDate": "2020-08-04T15:58:38Z", "message": "Merge branch 'master' into batch_inference_HF_Handler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "480586f01377bf2f1b4da99118e024920e20d5b3", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/480586f01377bf2f1b4da99118e024920e20d5b3", "committedDate": "2020-08-04T17:07:34Z", "message": "Merge branch 'master' into batch_inference_HF_Handler"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDIwNDg2", "url": "https://github.com/pytorch/serve/pull/585#pullrequestreview-461020486", "createdAt": "2020-08-04T17:26:10Z", "commit": {"oid": "480586f01377bf2f1b4da99118e024920e20d5b3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzoyNjoxMFrOG7qQeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzoyNjoxMFrOG7qQeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMTUxNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            curl -X POST \"localhost:8081/models?model_name=BERT_seq_Classification&url=BERT_seq_Classification.mar&batch_size=4&max_batch_delay=5000&initial_workers=3&synchronous=true\"\n          \n          \n            \n            curl -X POST \"localhost:8081/models?model_name=BERT_seq_Classification&url=BERTSeqClassification.mar&batch_size=4&max_batch_delay=5000&initial_workers=3&synchronous=true\"", "url": "https://github.com/pytorch/serve/pull/585#discussion_r465211514", "createdAt": "2020-08-04T17:26:10Z", "author": {"login": "maaquib"}, "path": "examples/Huggingface_Transformers/README.md", "diffHunk": "@@ -133,3 +133,19 @@ torchserve --start --model-store model_store --models my_tc=BERTSeqClassificatio\n ```\n \n - To run the inference using our registered model, open a new terminal and run: `curl -X POST http://127.0.0.1:8080/predictions/my_tc -T ./Seq_classification_artifacts/sample_text.txt`\n+\n+### Registering the Model on TorchServe and Running batch Inference\n+\n+The following uses .mar file created from  model packaging using pretrained for save_mode to register the model for batch inference on sequence classification, by setting the batch_size when registering the model.\n+\n+```\n+mkdir model_store\n+mv BERTSeqClassification.mar model_store/\n+torchserve --start --model-store model_store \n+\n+curl -X POST \"localhost:8081/models?model_name=BERT_seq_Classification&url=BERT_seq_Classification.mar&batch_size=4&max_batch_delay=5000&initial_workers=3&synchronous=true\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "480586f01377bf2f1b4da99118e024920e20d5b3"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb0134cd0fed3da1924246977ff142d64c9a14f3", "author": {"user": {"login": "HamidShojanazeri", "name": "Hamid Shojanazeri"}}, "url": "https://github.com/pytorch/serve/commit/bb0134cd0fed3da1924246977ff142d64c9a14f3", "committedDate": "2020-08-04T17:39:52Z", "message": "Update examples/Huggingface_Transformers/README.md\n\nCo-authored-by: Aaqib <maaquib@gmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDQ2MTI0", "url": "https://github.com/pytorch/serve/pull/585#pullrequestreview-461046124", "createdAt": "2020-08-04T18:01:56Z", "commit": {"oid": "bb0134cd0fed3da1924246977ff142d64c9a14f3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1993, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}