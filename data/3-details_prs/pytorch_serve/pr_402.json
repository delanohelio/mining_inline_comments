{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIzMDk0NDE2", "number": 402, "title": "added backend profiling and fixed benchmark's install dependency scripts", "bodyText": "Description\nThis PR addresses following :\n\nadded code changes to enable backend profiling\nmakes benchmark install dependency scripts independent of jmeter version.\n\nFixes #400\nType of change\nPlease delete options that are not relevant.\n\n Bug fix (non-breaking change which fixes an issue)\n New feature (non-breaking change which adds functionality)\n Breaking change (fix or feature that would cause existing functionality to not work as expected)\n This change requires a documentation update\n\nFeature/Issue validation/testing\n\ncreate a docker image with BENCHMARK parameter set to true in model_service_worker.py\n\ngit clone https://github.com/pytorch/serve.git\ncd serve\ngit checkout issue_400\ncd docker\ngit clone https://github.com/pytorch/serve.git\ncd serve\ngit checkout issue_400\n## set BENCHMARK flag to true\nvim ts/model_service_worker.py\ncd ..\nDOCKER_BUILDKIT=1 docker build --file Dockerfile_dev.cpu -t torchserve:dev .\n\n\nrun benchmark's install_dependencies.sh\n\ncd benchmark\n./install_dependencies.sh\n\n\nstart docker with /tmp directory mapped to local /tmp\n\ndocker run --rm -it -p 8080:8080 -p 8081:8081 -v /tmp:/tmp torchserve:dev\n\n\nstart default throughput benchmark\n\ncd benchmark\npython benchmark.py throughput --ts http://127.0.0.1:8080\n\n**Profiling **\nAttached generated report for 10 loops in zip format :\nprofile.zip\nTo access report on browser run following\nunzip profile.zip\npip install snakeviz\nsnakeviz tsPythonProfile.prof\n\nProfiling report generated on Mac :\nprofile_mac.zip\nChecklist:\n\n Have you made corresponding changes to the documentation?", "createdAt": "2020-05-26T09:36:50Z", "url": "https://github.com/pytorch/serve/pull/402", "merged": true, "mergeCommit": {"oid": "7dc846775996a26b0e8d3bc971ccad35421b9129"}, "closed": true, "closedAt": "2020-05-29T05:59:09Z", "author": {"login": "harshbafna"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABck-r-RAH2gAyNDIzMDk0NDE2Ojg4OWIwOGI1ZTEyY2JmYmM5OWFhNWU2ZTU3M2QwNzdhNjRlZmE0YjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcl8CDzAFqTQyMDY3MTAyMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "889b08b5e12cbfbc99aa5e6e573d077a64efa4b2", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/889b08b5e12cbfbc99aa5e6e573d077a64efa4b2", "committedDate": "2020-05-26T06:29:30Z", "message": "added backend profiling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c65921dae7f8b1dbe7a4b82c80e9577059b0c97e", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c65921dae7f8b1dbe7a4b82c80e9577059b0c97e", "committedDate": "2020-05-26T09:18:00Z", "message": "updated install dependency scripts to make them jmeter version independent"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "674ed488e01fbb087215d41428ca2c1c6dc37981", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/674ed488e01fbb087215d41428ca2c1c6dc37981", "committedDate": "2020-05-26T11:58:29Z", "message": "updated readme"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NTQ1NDM5", "url": "https://github.com/pytorch/serve/pull/402#pullrequestreview-418545439", "createdAt": "2020-05-26T17:59:20Z", "commit": {"oid": "674ed488e01fbb087215d41428ca2c1c6dc37981"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo1OToyMVrOGap7Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxODowMToyMVrOGaqCgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwMzAzMQ==", "bodyText": "It will be good to give the example launch command here. Also shouldn't the docker container be created after updating the BENCHMARK flag in the code and use that updated code to build the container. To reduce confusion for users, can the BENCHMARK flag be handled as an Environment variable that one sets before starting torchserve to run in benchmark mode?", "url": "https://github.com/pytorch/serve/pull/402#discussion_r430603031", "createdAt": "2020-05-26T17:59:21Z", "author": {"login": "chauhang"}, "path": "benchmarks/README.md", "diffHunk": "@@ -150,7 +150,7 @@ Once you have stopped recording, you should be able to analyze the data.  One us\n The benchmarks can also be used to analyze the backend performance using cProfile.  It does not require any additional packages to run the benchmark, but viewing the logs does require an additional package.  Run `pip install snakeviz` to install this.  To run the python profiling, follow these steps:\n \n 1. In the file `ts/model_service_worker.py`, set the constant BENCHMARK to true at the top to enable benchmarking.\n-2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag.\n+2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag. If you are running `TorchServe` inside docker container make sure you map the `/tmp` directory to some local directory on your machine while starting docker.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "674ed488e01fbb087215d41428ca2c1c6dc37981"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwMzQ3Nw==", "bodyText": "Same here, will be useful to give example of actual launch command", "url": "https://github.com/pytorch/serve/pull/402#discussion_r430603477", "createdAt": "2020-05-26T17:59:49Z", "author": {"login": "chauhang"}, "path": "benchmarks/README.md", "diffHunk": "@@ -150,7 +150,7 @@ Once you have stopped recording, you should be able to analyze the data.  One us\n The benchmarks can also be used to analyze the backend performance using cProfile.  It does not require any additional packages to run the benchmark, but viewing the logs does require an additional package.  Run `pip install snakeviz` to install this.  To run the python profiling, follow these steps:\n \n 1. In the file `ts/model_service_worker.py`, set the constant BENCHMARK to true at the top to enable benchmarking.\n-2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag.\n+2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag. If you are running `TorchServe` inside docker container make sure you map the `/tmp` directory to some local directory on your machine while starting docker.\n 3. Run TorchServe directly through gradle (do not use docker).  This can be done either on your machine or on a remote machine accessible through SSH.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "674ed488e01fbb087215d41428ca2c1c6dc37981"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwNDkzMQ==", "bodyText": "Also add steps in readme for installing snakeviz using pip install snakeviz", "url": "https://github.com/pytorch/serve/pull/402#discussion_r430604931", "createdAt": "2020-05-26T18:01:21Z", "author": {"login": "chauhang"}, "path": "benchmarks/README.md", "diffHunk": "@@ -150,7 +150,7 @@ Once you have stopped recording, you should be able to analyze the data.  One us\n The benchmarks can also be used to analyze the backend performance using cProfile.  It does not require any additional packages to run the benchmark, but viewing the logs does require an additional package.  Run `pip install snakeviz` to install this.  To run the python profiling, follow these steps:\n \n 1. In the file `ts/model_service_worker.py`, set the constant BENCHMARK to true at the top to enable benchmarking.\n-2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag.\n+2. Run the benchmark and TorchServe.  They can either be done automatically inside the docker container or separately with the \"--ts\" flag. If you are running `TorchServe` inside docker container make sure you map the `/tmp` directory to some local directory on your machine while starting docker.\n 3. Run TorchServe directly through gradle (do not use docker).  This can be done either on your machine or on a remote machine accessible through SSH.\n 4. Run the Benchmark script targeting your running TorchServe instance.  It might run something like `./benchmark.py throughput --ts https://127.0.0.1:8443`.  It can be run on either your local machine or a remote machine (if you are running remote), but we recommend running the benchmark on the same machine as the model server to avoid confounding network latencies.\n 5. Run `snakeviz /tmp/tsPythonProfile.prof` to view the profiling data.  It should start up a web server on your machine and automatically open the page.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "674ed488e01fbb087215d41428ca2c1c6dc37981"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80edb4b5cc617f2f31ca560da5c9b87bd00218b4", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/80edb4b5cc617f2f31ca560da5c9b87bd00218b4", "committedDate": "2020-05-28T02:01:51Z", "message": "Fix benchmarks/README typo and JMeter versioning issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9af97df73824b84a8c454095d46378b397eceb65", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/9af97df73824b84a8c454095d46378b397eceb65", "committedDate": "2020-05-29T04:20:01Z", "message": "Merge branch 'staging_0_1_1' into issue_400"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "819e0398ac2abb3a02a9df8cf95e85bcc60f79d7", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/819e0398ac2abb3a02a9df8cf95e85bcc60f79d7", "committedDate": "2020-05-29T04:32:45Z", "message": "merged #412 and resolved conflicts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d166682a5740aa8f614b3f833f6ebe5e2ceae66f", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/d166682a5740aa8f614b3f833f6ebe5e2ceae66f", "committedDate": "2020-05-29T04:44:57Z", "message": "updated documentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNjcxMDIy", "url": "https://github.com/pytorch/serve/pull/402#pullrequestreview-420671022", "createdAt": "2020-05-29T05:57:50Z", "commit": {"oid": "d166682a5740aa8f614b3f833f6ebe5e2ceae66f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2168, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}