{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxMjc0OTAy", "number": 910, "title": "Modified the readmes for kfserving, wrapper and image transformer", "bodyText": "Description\nModified the readmes for kfserving, End to end document of kfserving, kfserving wrapper and image transformer.\n\n This change requires a documentation update\n\nChecklist:\n\n Have you made corresponding changes to the documentation?", "createdAt": "2020-12-16T16:09:14Z", "url": "https://github.com/pytorch/serve/pull/910", "merged": true, "mergeCommit": {"oid": "6293b649f2bea059d6e1cc0bfe746289fc8dfa0f"}, "closed": true, "closedAt": "2020-12-18T00:10:11Z", "author": {"login": "abishekchiffon"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdmxE1PgH2gAyNTQxMjc0OTAyOjE4ZTllMDcyYWRlMWEwYzE3ZjJhMjhiZjMxZGZiMTFhYjM4MGU3ODg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdnMdvxAFqTU1NTA3ODY4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "author": {"user": {"login": "abishekchiffon", "name": "Abishek Chiffon"}}, "url": "https://github.com/pytorch/serve/commit/18e9e072ade1a0c17f2a28bf31dfb11ab380e788", "committedDate": "2020-12-16T15:56:59Z", "message": "Modified the readmes for kfserving, wrapper and image transformer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTIyMzY0", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553922364", "createdAt": "2020-12-16T17:31:05Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzozMTowNVrOIHQ6KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzozMTowNVrOIHQ6KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ4Nzk3Nw==", "bodyText": "@abishekchiffon Please change to \"TorchServe supports Captum explanations for eager mode only\"  this is for all models and nothing specific to mnist model", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544487977", "createdAt": "2020-12-16T17:31:05Z", "author": {"login": "chauhang"}, "path": "examples/image_classifier/mnist/README.md", "diffHunk": "@@ -51,6 +51,8 @@ When a json file is passed as a request format to the curl, Torchserve unwraps t\n \n The explain is called with the following request api http://127.0.0.1:8080/explanations/mnist_explain\n \n+Torchserve supports Captum Explanations for Eager models of mnist only.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTI1Nzgz", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553925783", "createdAt": "2020-12-16T17:35:10Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzozNToxMFrOIHRFKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxNzozNToxMFrOIHRFKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDQ5MDc5NA==", "bodyText": "Please change to \"The service_envelope=kfserving setting is needed when deploying models on KFServing\"", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544490794", "createdAt": "2020-12-16T17:35:10Z", "author": {"login": "chauhang"}, "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -14,17 +14,23 @@ This produces all the required files for packaging using a huggingface transform\n The .mar file creation command is as below:\n \n ```\n-torch-model-archiver --model-name BERTSeqClassification --version 1.0 --serialized-file serve/examples/Huggingface_Transformers/Transformer_model/pytorch_model.bin --handler serve/examples/Huggingface_Transformers/Transformer_model/Transformer_handler_generalized.py --source-vocab serve/examples/Huggingface_Transformers/Transformer_model/vocab.txt --extra-files \"Transformer_model/config.json,serve/examples/Huggingface_Transformers/Transformer_model/setup_config.json,serve/examples/Huggingface_Transformers/Transformer_model/index_to_name.json\"\n+torch-model-archiver --model-name BERTSeqClassification --version 1.0 --serialized-file serve/examples/Huggingface_Transformers/Transformer_model/pytorch_model.bin --handler serve/examples/Huggingface_Transformers/Transformer_model/Transformer_handler_generalized.py --extra-files \"serve/examples/Huggingface_Transformers/Transformer_model/vocab.txt,serve/examples/Huggingface_Transformers/Transformer_model/config.json,serve/examples/Huggingface_Transformers/Transformer_model/setup_config.json,serve/examples/Huggingface_Transformers/Transformer_model/index_to_name.json\"\n ```\n \n-## Starting Torchserve\n+## Starting Torchserve for KFServing Predictor\n To serve an Inference Request for Torchserve using the KFServing Spec, follow the below:\n \n * create a config.properties file and specify the details as shown:\n ```\n+inference_address=http://127.0.0.0:8085\n+management_address=http://127.0.0.0:8081\n+number_of_netty_threads=4\n service_envelope=kfserving\n+job_queue_size=10\n+model_store=model-store\n+\n ```\n-The Service Envelope field is mandatory for Torchserve to process the KFServing Input Request Format.\n+The Service Envelope field should be set as kfserving and it is mandatory.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTgzODQ0", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553983844", "createdAt": "2020-12-16T18:47:48Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo0Nzo0OVrOIHUCUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo0Nzo0OVrOIHUCUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDUzOTIxNw==", "bodyText": "Nitpick: Shouldn't this be json?", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544539217", "createdAt": "2020-12-16T18:47:49Z", "author": {"login": "fbbradheintz"}, "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -102,6 +112,20 @@ The Explanation response is as below :\n   ]\n }\n ```\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:\n+```bash", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTg2ODU4", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553986858", "createdAt": "2020-12-16T18:51:55Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MTo1NVrOIHUMMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MTo1NVrOIHUMMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MTc0NQ==", "bodyText": "Should this be json?", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544541745", "createdAt": "2020-12-16T18:51:55Z", "author": {"login": "fbbradheintz"}, "path": "kubernetes/kfserving/README.md", "diffHunk": "@@ -231,7 +237,25 @@ The response is as below :\n   ]\n }\n ```\n-For the request and response of BERT and Text Classifier models, refer the \"Request and Response\" section of section of [BERT Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/Huggingface_readme.md) and [Text Classifier Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/text_classifier_readme.md). .\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:\n+\n+```bash", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTg3NzQ2", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553987746", "createdAt": "2020-12-16T18:52:59Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MzowMFrOIHUPAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MzowMFrOIHUPAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjQ2NQ==", "bodyText": "Somewhere, we should add that when performing static batching this way, the user needs to make sure they're using batch size of 1 (even though more than one input instance is specified in the input). Doing otherwise will cause a failure.", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544542465", "createdAt": "2020-12-16T18:53:00Z", "author": {"login": "fbbradheintz"}, "path": "kubernetes/kfserving/README.md", "diffHunk": "@@ -231,7 +237,25 @@ The response is as below :\n   ]\n }\n ```\n-For the request and response of BERT and Text Classifier models, refer the \"Request and Response\" section of section of [BERT Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/Huggingface_readme.md) and [Text Classifier Readme file](https://github.com/pytorch/serve/blob/master/kubernetes/kfserving/text_classifier_readme.md). .\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUzOTg3OTUz", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-553987953", "createdAt": "2020-12-16T18:53:16Z", "commit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MzoxNlrOIHUPqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxODo1MzoxNlrOIHUPqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MjYzMw==", "bodyText": "Somewhere, we should add that when performing static batching this way, the user needs to make sure they're using batch size of 1 (even though more than one input instance is specified in the input). Doing otherwise will cause a failure.", "url": "https://github.com/pytorch/serve/pull/910#discussion_r544542633", "createdAt": "2020-12-16T18:53:16Z", "author": {"login": "fbbradheintz"}, "path": "kubernetes/kfserving/Huggingface_readme.md", "diffHunk": "@@ -102,6 +112,20 @@ The Explanation response is as below :\n   ]\n }\n ```\n+\n+KFServing supports Static batching by adding new examples in the instances key of the request:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18e9e072ade1a0c17f2a28bf31dfb11ab380e788"}, "originalPosition": 58}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2c8a987c45f44479457fc74e5afbe0fded146d8f", "author": {"user": {"login": "abishekchiffon", "name": "Abishek Chiffon"}}, "url": "https://github.com/pytorch/serve/commit/2c8a987c45f44479457fc74e5afbe0fded146d8f", "committedDate": "2020-12-17T09:21:22Z", "message": "KFserving readme changes for static batching, image transformer and kfserving wrapper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "205b03ffb3b6aba92852d22c124c2746c2cfaa10", "author": {"user": {"login": "abishekchiffon", "name": "Abishek Chiffon"}}, "url": "https://github.com/pytorch/serve/commit/205b03ffb3b6aba92852d22c124c2746c2cfaa10", "committedDate": "2020-12-17T12:58:29Z", "message": "Readme changes for kf cluster in end to end document"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDY2NjY1", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-555066665", "createdAt": "2020-12-17T23:22:18Z", "commit": {"oid": "205b03ffb3b6aba92852d22c124c2746c2cfaa10"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03667af29f6b02e75c23f8ab335ae67b348c8612", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/03667af29f6b02e75c23f8ab335ae67b348c8612", "committedDate": "2020-12-17T23:41:04Z", "message": "Merge branch 'master' into kf_readme2"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDc4Njg0", "url": "https://github.com/pytorch/serve/pull/910#pullrequestreview-555078684", "createdAt": "2020-12-17T23:51:38Z", "commit": {"oid": "03667af29f6b02e75c23f8ab335ae67b348c8612"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1972, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}