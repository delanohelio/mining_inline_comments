{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2ODE1NDg3", "number": 337, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMzozNzoyMFrOD-Ahfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTo0MTozM1rOD-pYYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzQ2ODc4OnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMzozNzoyMFrOGX2QuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxODozMzozM1rOGYYv8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY1OTQ0OQ==", "bodyText": "This works, but their is no server-side exception, fails silently. I have to run curl with verbose output to see the following response code. Maybe we should document this\n< HTTP/1.1 413 Request Entity Too Large\n< content-length: 0\n* HTTP error before end of send, stop sending\n\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `max_request_size` : The maximum allowable request size that the Torchserve accepts.\n          \n          \n            \n            * `max_request_size` : The maximum allowable request size that the Torchserve accepts, in bytes.", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427659449", "createdAt": "2020-05-19T23:37:20Z", "author": {"login": "maaquib"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.\n+* `model_server_home` : Torchserve home directory.\n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIyNDQ5OA==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428224498", "createdAt": "2020-05-20T18:33:33Z", "author": {"login": "shivamshriwas"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.\n+* `model_server_home` : Torchserve home directory.\n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY1OTQ0OQ=="}, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzQ3NDgxOnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMzo0MDozNVrOGX2Ugg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxODo0MDoyNlrOGYZHeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQxOA==", "bodyText": "Doesn't seem to be working\n> cat /tmp/serve/config.properties\ndebug=true\nmodel_store=/tmp/model-store\nmodel_server_home=/tmp/model-server-home\nmax_request_size=1000000\nmax_response_size=1\n\n> torchserve --start --ts-config config.properties\n...\nDefault workers per model: 1\nBlacklist Regex: N/A\nMaximum Response Size: 1\nMaximum Request Size: 1000000\n...\n\n> curl -X POST \"http://127.0.0.1:8081/models?url=https://torchserve.s3.amazonaws.com/mar_files/squeezenet1_1.mar\"\n\n> curl -X POST http://0.0.0.0:8080/predictions/squeezenet1_1 -T /tmp/kitten.jpg\n{\n  \"code\": 503,\n  \"type\": \"ServiceUnavailableException\",\n  \"message\": \"No worker is available to serve request: squeezenet1_1\"\n}\n\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n          \n          \n            \n            * `debug`: Runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427660418", "createdAt": "2020-05-19T23:40:35Z", "author": {"login": "maaquib"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIzMDUyMA==", "bodyText": "@maaquib Updated debug in config properties as suggested.\nFor detailed description on running to torchserve in debug mode we will be adding\na separate doc file.", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428230520", "createdAt": "2020-05-20T18:40:26Z", "author": {"login": "shivamshriwas"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQxOA=="}, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzQ3NTMyOnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMzo0MDo0NVrOGX2Uww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxODo0MDo0M1rOGYZIfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQ4Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `model_store` : path of model store directory.\n          \n          \n            \n            * `model_store` : Path of model store directory.", "url": "https://github.com/pytorch/serve/pull/337#discussion_r427660483", "createdAt": "2020-05-19T23:40:45Z", "author": {"login": "maaquib"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODIzMDc4Mg==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428230782", "createdAt": "2020-05-20T18:40:43Z", "author": {"login": "shivamshriwas"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,18 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `debug`: runs Torchserve in debug mode where `default_workers_per_model` is set to 1 when this flag is true.\n+* `model_store` : path of model store directory.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY2MDQ4Mw=="}, "originalCommit": {"oid": "d8ca5e1add1334d0c8c51e614c36089ee4436f29"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MDE2MjkwOnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNTo0MTozM1rOGY3-zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxNjo1Mzo0MlrOGY6yXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczNjIwNw==", "bodyText": "List down steps", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428736207", "createdAt": "2020-05-21T15:41:33Z", "author": {"login": "dhaniram-kshirsagar"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,17 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `model_store` : Path of model store directory.\n+* `model_server_home` : Torchserve home directory. \n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts, in bytes. Default: 6553500\n+* `max_response_size` : The maximum buffer size the frontend allocates for a worker response, in bytes. Default: 6553500\n+\n+---\n+**NOTE**\n+\n+Config properties can be set using environment variable only when `enable_envvars_config` is true and ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b8fe71dc187f6f04d3bfa2c50ea79299bf8f31e"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODc4MjE3NA==", "bodyText": "done", "url": "https://github.com/pytorch/serve/pull/337#discussion_r428782174", "createdAt": "2020-05-21T16:53:42Z", "author": {"login": "shivamshriwas"}, "path": "docs/configuration.md", "diffHunk": "@@ -191,3 +191,17 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `decode_input_request`: Configuration to let backend workers to decode requests, when the content type is known.\n If this is set to \"true\", backend workers do \"Bytearray to JSON object\" conversion when the content type is \"application/json\" and\n the backend workers convert \"Bytearray to utf-8 string\" when the Content-Type of the request is set to \"text*\". Default: true  \n+* `model_store` : Path of model store directory.\n+* `model_server_home` : Torchserve home directory. \n+* `max_request_size` : The maximum allowable request size that the Torchserve accepts, in bytes. Default: 6553500\n+* `max_response_size` : The maximum buffer size the frontend allocates for a worker response, in bytes. Default: 6553500\n+\n+---\n+**NOTE**\n+\n+Config properties can be set using environment variable only when `enable_envvars_config` is true and ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODczNjIwNw=="}, "originalCommit": {"oid": "5b8fe71dc187f6f04d3bfa2c50ea79299bf8f31e"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1654, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}