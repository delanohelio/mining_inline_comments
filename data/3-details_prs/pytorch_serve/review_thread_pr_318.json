{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1MzIxNTc3", "number": 318, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNzo1ODozNlrOD6ughQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxODowMjoxMVrOD6uk1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyOTA1OTg5OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConfigManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNzo1ODozNlrOGSuRkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNzo1ODozNlrOGSuRkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NTcxMw==", "bodyText": "Why is this change required? This seems to be a breaking change and without any functionality change.", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422285713", "createdAt": "2020-05-08T17:58:36Z", "author": {"login": "vdantu"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConfigManager.java", "diffHunk": "@@ -53,7 +53,8 @@\n     private static final String TS_MANAGEMENT_ADDRESS = \"management_address\";\n     private static final String TS_LOAD_MODELS = \"load_models\";\n     private static final String TS_BLACKLIST_ENV_VARS = \"blacklist_env_vars\";\n-    private static final String TS_DEFAULT_WORKERS_PER_MODEL = \"default_workers_per_model\";\n+    private static final String TS_DEFAULT_WORKERS_PER_INIT_MODEL =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyOTA2NTMxOnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxODowMDoxMlrOGSuU-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxOTo0ODozNlrOGSxioA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NjU4NQ==", "bodyText": "Why are we modifying the original configuration? Can't we simply change the snapshot to follow what exists in main configuration?", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422286585", "createdAt": "2020-05-08T18:00:12Z", "author": {"login": "vdantu"}, "path": "docs/configuration.md", "diffHunk": "@@ -183,7 +183,7 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `enable_envvars_config`: Enable configuring TorchServe through environment variables. When this option is set to \"true\", all the static configurations of TorchServe can come through environment variables as well. Default: false\n * `number_of_netty_threads`: number frontend netty thread. Default: number of logical processors available to the JVM.\n * `netty_client_threads`: number of backend netty thread. Default: number of logical processors available to the JVM.\n-* `default_workers_per_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.\n+* `default_workers_per_init_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI5MjAzOA==", "bodyText": "@vdantu : The actual configuration parameter documented is default_workers_per_model. However, the config manager internally uses both default_workers_per_model and NUM_WORKERS. Further, the snapshots generated is a combination of config properties and state of all registered models. The config manager dumps NUM_WORKERS param in the snapshot instead of default_workers_per_model.\nThus it makes sense to use only the documented parameter.\nWe are also renaming the config parameter as it is only applicable for the models which are loaded/initialized at the time of starting torchserve. For all other models registered through API, the user needs to provide the number of workers.", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422292038", "createdAt": "2020-05-08T18:11:43Z", "author": {"login": "harshbafna"}, "path": "docs/configuration.md", "diffHunk": "@@ -183,7 +183,7 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `enable_envvars_config`: Enable configuring TorchServe through environment variables. When this option is set to \"true\", all the static configurations of TorchServe can come through environment variables as well. Default: false\n * `number_of_netty_threads`: number frontend netty thread. Default: number of logical processors available to the JVM.\n * `netty_client_threads`: number of backend netty thread. Default: number of logical processors available to the JVM.\n-* `default_workers_per_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.\n+* `default_workers_per_init_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NjU4NQ=="}, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMyODkzOA==", "bodyText": "I was thinking from customers view point. If a customer was using previously released version of TorchServe and they are moving to newer version of TorchServe, would changing this option break their experience or not? Variables used internally can be modified while maintaining backwards compatibility would be my thought here. Changing the customer experience here seems odd. Can't we keep this variable as it is and change the NUM_WORKERS to current_num_workers or to some other better name? Also, init in default_workers_per_init_model seems redundant. I am open for other views here, but it seems like we are changing UX for something that can be fully kept internal to codebase. Correct me if I am wrong.", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422328938", "createdAt": "2020-05-08T19:26:13Z", "author": {"login": "vdantu"}, "path": "docs/configuration.md", "diffHunk": "@@ -183,7 +183,7 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `enable_envvars_config`: Enable configuring TorchServe through environment variables. When this option is set to \"true\", all the static configurations of TorchServe can come through environment variables as well. Default: false\n * `number_of_netty_threads`: number frontend netty thread. Default: number of logical processors available to the JVM.\n * `netty_client_threads`: number of backend netty thread. Default: number of logical processors available to the JVM.\n-* `default_workers_per_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.\n+* `default_workers_per_init_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NjU4NQ=="}, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjMzOTIzMg==", "bodyText": "The only idea to introduce the init keyword here is to indicate that it applies to the startup/initialization models and not to every model.\nJust default_workers_per_model sounds like it will apply to every model if no worker is provided.\nI agree this will impact the UX where the parameter is already being used in config.properties.", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422339232", "createdAt": "2020-05-08T19:48:36Z", "author": {"login": "harshbafna"}, "path": "docs/configuration.md", "diffHunk": "@@ -183,7 +183,7 @@ Most of the following properties are designed for performance tuning. Adjusting\n * `enable_envvars_config`: Enable configuring TorchServe through environment variables. When this option is set to \"true\", all the static configurations of TorchServe can come through environment variables as well. Default: false\n * `number_of_netty_threads`: number frontend netty thread. Default: number of logical processors available to the JVM.\n * `netty_client_threads`: number of backend netty thread. Default: number of logical processors available to the JVM.\n-* `default_workers_per_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.\n+* `default_workers_per_init_model`: number of workers to create for each model that loaded at startup time. Default: available GPUs in system or number of logical processors available to the JVM.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NjU4NQ=="}, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyOTA3MDk0OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/test/resources/snapshots/snapshot4.cfg", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxODowMjoxMVrOGSuYjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQwNTowMDozMFrOGcO1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NzUwMg==", "bodyText": "Can we just call this default_workers_per_model?", "url": "https://github.com/pytorch/serve/pull/318#discussion_r422287502", "createdAt": "2020-05-08T18:02:11Z", "author": {"login": "vdantu"}, "path": "frontend/server/src/test/resources/snapshots/snapshot4.cfg", "diffHunk": "@@ -6,7 +6,7 @@ enable_envvars_config=true\n load_models=noop.mar\n private_key_file=src/test/resources/key.pem\n snapshot_store=FS\n-NUM_WORKERS=4\n+default_workers_per_init_model=4", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1NjMwNg==", "bodyText": "done", "url": "https://github.com/pytorch/serve/pull/318#discussion_r432256306", "createdAt": "2020-05-29T05:00:30Z", "author": {"login": "shivamshriwas"}, "path": "frontend/server/src/test/resources/snapshots/snapshot4.cfg", "diffHunk": "@@ -6,7 +6,7 @@ enable_envvars_config=true\n load_models=noop.mar\n private_key_file=src/test/resources/key.pem\n snapshot_store=FS\n-NUM_WORKERS=4\n+default_workers_per_init_model=4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4NzUwMg=="}, "originalCommit": {"oid": "4cea48401dd42420048cbd46e7a6fb7f8a39d241"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1646, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}