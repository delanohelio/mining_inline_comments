{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0NzQ4OTE4", "number": 460, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwMzo0NjoyNlrOENITMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyMzo0OVrOEO5DNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjAyOTI4OnYy", "diffSide": "RIGHT", "path": "frontend/server/build.gradle", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwMzo0NjoyNlrOGvo8Bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwMzo0NjoyNlrOGvo8Bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwNjk4Mg==", "bodyText": "Use implementation syntax instead of compile which has been deprecated.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452606982", "createdAt": "2020-07-10T03:46:26Z", "author": {"login": "harshbafna"}, "path": "frontend/server/build.gradle", "diffHunk": "@@ -1,4 +1,6 @@\n dependencies {\n+    compile \"io.prometheus:simpleclient:${prometheus_version}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA0ODU2OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/main/java/org/pytorch/serve/servingsdk/impl/PluginsManager.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwMzo1OToxN1rOGvpHGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxOTowMDoyNlrOGw1wjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwOTgxNg==", "bodyText": "should be EndpointTypes.METRICS", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452609816", "createdAt": "2020-07-10T03:59:17Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/main/java/org/pytorch/serve/servingsdk/impl/PluginsManager.java", "diffHunk": "@@ -68,11 +70,20 @@ private boolean validateEndpointPlugin(Annotation a, EndpointTypes type) {\n         return getEndpoints(EndpointTypes.MANAGEMENT);\n     }\n \n+    private HashMap<String, ModelServerEndpoint> initMetricsEndpoints() {\n+        // TODO: Change to METRICS after fixing serving-sdk dependency\n+        return getEndpoints(EndpointTypes.MANAGEMENT);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2OTk4Mw==", "bodyText": "Yes. I have tested that with localMaven repo and EndpointTypes.METRICS. But the serving-sdk dependency in torchserve is pulled from JCenter. We need to publish a new version with the sdk changes. I'll separate this PR out into two separate ones", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453069983", "createdAt": "2020-07-10T20:47:51Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/servingsdk/impl/PluginsManager.java", "diffHunk": "@@ -68,11 +70,20 @@ private boolean validateEndpointPlugin(Annotation a, EndpointTypes type) {\n         return getEndpoints(EndpointTypes.MANAGEMENT);\n     }\n \n+    private HashMap<String, ModelServerEndpoint> initMetricsEndpoints() {\n+        // TODO: Change to METRICS after fixing serving-sdk dependency\n+        return getEndpoints(EndpointTypes.MANAGEMENT);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwOTgxNg=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQxOTQyNg==", "bodyText": "Please add a ticket to update and re-publish the sdk.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453419426", "createdAt": "2020-07-13T03:45:15Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/main/java/org/pytorch/serve/servingsdk/impl/PluginsManager.java", "diffHunk": "@@ -68,11 +70,20 @@ private boolean validateEndpointPlugin(Annotation a, EndpointTypes type) {\n         return getEndpoints(EndpointTypes.MANAGEMENT);\n     }\n \n+    private HashMap<String, ModelServerEndpoint> initMetricsEndpoints() {\n+        // TODO: Change to METRICS after fixing serving-sdk dependency\n+        return getEndpoints(EndpointTypes.MANAGEMENT);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwOTgxNg=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTYxMw==", "bodyText": "Create PR #530", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453865613", "createdAt": "2020-07-13T19:00:26Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/servingsdk/impl/PluginsManager.java", "diffHunk": "@@ -68,11 +70,20 @@ private boolean validateEndpointPlugin(Annotation a, EndpointTypes type) {\n         return getEndpoints(EndpointTypes.MANAGEMENT);\n     }\n \n+    private HashMap<String, ModelServerEndpoint> initMetricsEndpoints() {\n+        // TODO: Change to METRICS after fixing serving-sdk dependency\n+        return getEndpoints(EndpointTypes.MANAGEMENT);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYwOTgxNg=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA1Mzk0OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/main/java/org/pytorch/serve/util/Connector.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDowMzoxNlrOGvpKQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMDowMTozN1rOGwEHcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMDYyNw==", "bodyText": "ssl port for metric endpoint?", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452610627", "createdAt": "2020-07-10T04:03:16Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/Connector.java", "diffHunk": "@@ -97,18 +97,23 @@ public static Connector parse(String binding, boolean management) {\n         boolean ssl = \"https\".equalsIgnoreCase(protocol);\n         int port;\n         if (listeningPort == null) {\n-            if (management) {\n-                port = ssl ? 8444 : 8081;\n-            } else {\n-                port = ssl ? 443 : 80;\n+            switch (connectorType) {\n+                case MANAGEMENT_CONNECTOR:\n+                    port = ssl ? 8444 : 8081;\n+                    break;\n+                case METRICS_CONNECTOR:\n+                    port = 8082;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjI3NA==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453052274", "createdAt": "2020-07-10T20:01:37Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/Connector.java", "diffHunk": "@@ -97,18 +97,23 @@ public static Connector parse(String binding, boolean management) {\n         boolean ssl = \"https\".equalsIgnoreCase(protocol);\n         int port;\n         if (listeningPort == null) {\n-            if (management) {\n-                port = ssl ? 8444 : 8081;\n-            } else {\n-                port = ssl ? 443 : 80;\n+            switch (connectorType) {\n+                case MANAGEMENT_CONNECTOR:\n+                    port = ssl ? 8444 : 8081;\n+                    break;\n+                case METRICS_CONNECTOR:\n+                    port = 8082;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMDYyNw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA1NzE4OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDowNTo1NFrOGvpMKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxOTowMDo0MFrOGw1xCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMTExMw==", "bodyText": "can we change this to ALL and use the same during server initialization?", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452611113", "createdAt": "2020-07-10T04:05:54Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "diffHunk": "@@ -3,5 +3,6 @@\n public enum ConnectorType {\n     INFERENCE_CONNECTOR,\n     MANAGEMENT_CONNECTOR,\n+    METRICS_CONNECTOR,\n     BOTH", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAxOTI4NA==", "bodyText": "This is used in UTs and a few other classes for getting the different channels for the connectors", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453019284", "createdAt": "2020-07-10T18:51:11Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "diffHunk": "@@ -3,5 +3,6 @@\n public enum ConnectorType {\n     INFERENCE_CONNECTOR,\n     MANAGEMENT_CONNECTOR,\n+    METRICS_CONNECTOR,\n     BOTH", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMTExMw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyMDAxOA==", "bodyText": "Can't we use ALL instead of BOTH and initialize all three channels using this keyword? BOTH now looks a bit odd here.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453420018", "createdAt": "2020-07-13T03:47:59Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "diffHunk": "@@ -3,5 +3,6 @@\n public enum ConnectorType {\n     INFERENCE_CONNECTOR,\n     MANAGEMENT_CONNECTOR,\n+    METRICS_CONNECTOR,\n     BOTH", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMTExMw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc3ODYxOA==", "bodyText": "Ah, I see what you meant. Will do", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453778618", "createdAt": "2020-07-13T16:33:11Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "diffHunk": "@@ -3,5 +3,6 @@\n public enum ConnectorType {\n     INFERENCE_CONNECTOR,\n     MANAGEMENT_CONNECTOR,\n+    METRICS_CONNECTOR,\n     BOTH", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMTExMw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTczOA==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453865738", "createdAt": "2020-07-13T19:00:40Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/main/java/org/pytorch/serve/util/ConnectorType.java", "diffHunk": "@@ -3,5 +3,6 @@\n public enum ConnectorType {\n     INFERENCE_CONNECTOR,\n     MANAGEMENT_CONNECTOR,\n+    METRICS_CONNECTOR,\n     BOTH", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMTExMw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA2OTA2OnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDoxNDozMlrOGvpTRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMDowMTo1NFrOGwEH8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMjkzNQ==", "bodyText": "Move this section to metric_api.md under docs and add a reference in docs/rest_api.md", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452612935", "createdAt": "2020-07-10T04:14:32Z", "author": {"login": "harshbafna"}, "path": "README.md", "diffHunk": "@@ -226,6 +226,58 @@ You will see this result in the response to your `curl` call to the predict endp\n \n Now you've seen how easy it can be to serve a deep learning model with TorchServe! [Would you like to know more?](docs/server.md)\n \n+### Get metrics", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjQwMQ==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453052401", "createdAt": "2020-07-10T20:01:54Z", "author": {"login": "maaquib"}, "path": "README.md", "diffHunk": "@@ -226,6 +226,58 @@ You will see this result in the response to your `curl` call to the predict endp\n \n Now you've seen how easy it can be to serve a deep learning model with TorchServe! [Would you like to know more?](docs/server.md)\n \n+### Get metrics", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMjkzNQ=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA3MTE4OnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDoxNjowOFrOGvpUiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMDowMjowNVrOGwEIPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMzI1Ng==", "bodyText": "Split this into multiple comments based on the metric type to make it more readable. Also add the respective curl commands for each type as an example.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452613256", "createdAt": "2020-07-10T04:16:08Z", "author": {"login": "harshbafna"}, "path": "README.md", "diffHunk": "@@ -226,6 +226,58 @@ You will see this result in the response to your `curl` call to the predict endp\n \n Now you've seen how easy it can be to serve a deep learning model with TorchServe! [Would you like to know more?](docs/server.md)\n \n+### Get metrics\n+\n+The default metrics endpoint returns Prometheus formatted metrics. The endpoint can be set to a different port via config parameter `metrics_address`. You can query metrics using curl requests as below\n+\n+```\n+curl http://127.0.0.1:8082/metrics\n+curl \"http://127.0.0.1:8082/metrics?name[]=ts_inference_requests_total&name[]=ts_queue_latency_microseconds\" --globoff\n+```\n+\n+```\n+# HELP ts_inference_latency_microseconds Cumulative inference duration in microseconds", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjQ3OA==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453052478", "createdAt": "2020-07-10T20:02:05Z", "author": {"login": "maaquib"}, "path": "README.md", "diffHunk": "@@ -226,6 +226,58 @@ You will see this result in the response to your `curl` call to the predict endp\n \n Now you've seen how easy it can be to serve a deep learning model with TorchServe! [Would you like to know more?](docs/server.md)\n \n+### Get metrics\n+\n+The default metrics endpoint returns Prometheus formatted metrics. The endpoint can be set to a different port via config parameter `metrics_address`. You can query metrics using curl requests as below\n+\n+```\n+curl http://127.0.0.1:8082/metrics\n+curl \"http://127.0.0.1:8082/metrics?name[]=ts_inference_requests_total&name[]=ts_queue_latency_microseconds\" --globoff\n+```\n+\n+```\n+# HELP ts_inference_latency_microseconds Cumulative inference duration in microseconds", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxMzI1Ng=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA4MjIyOnYy", "diffSide": "RIGHT", "path": "frontend/server/src/test/java/org/pytorch/serve/ModelServerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDoyNDoxMVrOGvpa-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMDowMjoxNVrOGwEIkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxNDkwNA==", "bodyText": "Add UTs for all types of parameters supported by the metrics API.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452614904", "createdAt": "2020-07-10T04:24:11Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/test/java/org/pytorch/serve/ModelServerTest.java", "diffHunk": "@@ -1541,6 +1564,16 @@ private void testPredictions(String modelName, String expectedOutput, String ver\n \n         TestUtils.getLatch().await();\n         Assert.assertEquals(TestUtils.getResult(), expectedOutput);\n+\n+        Channel metricsChannel = TestUtils.getMetricsChannel(configManager);\n+        TestUtils.setResult(null);\n+        TestUtils.setLatch(new CountDownLatch(1));\n+        DefaultFullHttpRequest metricsReq =\n+                new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, \"/metrics\");\n+        metricsChannel.writeAndFlush(metricsReq);\n+        TestUtils.getLatch().await();\n+        Pattern inferLatencyMatcher = TestUtils.getTSInferLatencyMatcher(modelName, version);\n+        Assert.assertTrue(inferLatencyMatcher.matcher(TestUtils.getResult()).find());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 374}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjU2MQ==", "bodyText": "Done", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453052561", "createdAt": "2020-07-10T20:02:15Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/test/java/org/pytorch/serve/ModelServerTest.java", "diffHunk": "@@ -1541,6 +1564,16 @@ private void testPredictions(String modelName, String expectedOutput, String ver\n \n         TestUtils.getLatch().await();\n         Assert.assertEquals(TestUtils.getResult(), expectedOutput);\n+\n+        Channel metricsChannel = TestUtils.getMetricsChannel(configManager);\n+        TestUtils.setResult(null);\n+        TestUtils.setLatch(new CountDownLatch(1));\n+        DefaultFullHttpRequest metricsReq =\n+                new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, \"/metrics\");\n+        metricsChannel.writeAndFlush(metricsReq);\n+        TestUtils.getLatch().await();\n+        Pattern inferLatencyMatcher = TestUtils.getTSInferLatencyMatcher(modelName, version);\n+        Assert.assertTrue(inferLatencyMatcher.matcher(TestUtils.getResult()).find());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxNDkwNA=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 374}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgyMjA4ODA4OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/test/resources/management_open_api.json", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQwNDoyODoxNFrOGvpeOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMDowMjoyNlrOGwEIyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxNTczNw==", "bodyText": "Why are we changing this to a hard-coded value? We will need to update the expected open-api json every time we update the version. We already have UTs to ensure that the versions are correctly reflected everywhere.", "url": "https://github.com/pytorch/serve/pull/460#discussion_r452615737", "createdAt": "2020-07-10T04:28:14Z", "author": {"login": "harshbafna"}, "path": "frontend/server/src/test/resources/management_open_api.json", "diffHunk": "@@ -3,7 +3,7 @@\n   \"info\": {\n     \"title\": \"TorchServe APIs\",\n     \"description\": \"TorchServe is a flexible and easy to use tool for serving deep learning models\",\n-    \"version\": \"%s\"\n+    \"version\": \"0.1.1\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjYxOA==", "bodyText": "Reverted", "url": "https://github.com/pytorch/serve/pull/460#discussion_r453052618", "createdAt": "2020-07-10T20:02:26Z", "author": {"login": "maaquib"}, "path": "frontend/server/src/test/resources/management_open_api.json", "diffHunk": "@@ -3,7 +3,7 @@\n   \"info\": {\n     \"title\": \"TorchServe APIs\",\n     \"description\": \"TorchServe is a flexible and easy to use tool for serving deep learning models\",\n-    \"version\": \"%s\"\n+    \"version\": \"0.1.1\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjYxNTczNw=="}, "originalCommit": {"oid": "a0537a93b4b56b5d1d99e62491f57485b1f9d17c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0MDUwMjI4OnYy", "diffSide": "RIGHT", "path": "frontend/gradle.properties", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyMzo0OVrOGyTYOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyMzo0OVrOGyTYOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTM5OTQ4Mg==", "bodyText": "This ties TS with prometheus.  Can we make this pluggable?", "url": "https://github.com/pytorch/serve/pull/460#discussion_r455399482", "createdAt": "2020-07-15T22:23:49Z", "author": {"login": "vdantu"}, "path": "frontend/gradle.properties", "diffHunk": "@@ -1,9 +1,10 @@\n org.gradle.daemon=true\n org.gradle.jvmargs=-Xmx1024M\n+commons_cli_version=1.3.1\n+gson_version=2.8.5\n netty_version=4.1.24.Final\n+prometheus_version=0.9.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02b15d21de8603db4e84613afa03bbbc9b259c44"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1524, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}