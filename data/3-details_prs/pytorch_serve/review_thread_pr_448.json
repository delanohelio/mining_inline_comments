{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyMzMwNzk0", "number": 448, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMjo0MjozMFrOEH81nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMjo0MjozMFrOEH81nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzcyMjUyOnYy", "diffSide": "RIGHT", "path": "benchmarks/README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMjo0MjozMFrOGnnW8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMjo0MjozMFrOGnnW8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5MjQ5OQ==", "bodyText": "Please change these to Torch serve from MMS.\nMMS refers here to Model latency would be better if thats mentioned clearly", "url": "https://github.com/pytorch/serve/pull/448#discussion_r444192499", "createdAt": "2020-06-23T12:42:30Z", "author": {"login": "dhanainme"}, "path": "benchmarks/README.md", "diffHunk": "@@ -122,74 +145,119 @@ Run with custom options\\\n \n Run against an already running instance of TorchServe\\\n ```./benchmark.py latency --ts 127.0.0.1``` (defaults to http, port 80, management port = port + 1)\\\n-```./benchmark.py latency --ts 127.0.0.1:8080 --management-port 8081```\\\n-```./benchmark.py latency --ts https://127.0.0.1:8443```\n+```./benchmark.py latency --ts 127.0.0.1:8080 --management-port 8081```\n \n \n Run verbose with only a single loop\\\n ```./benchmark.py latency -v -l 1```\n \n+## Known Issues(Running with SSL):\n+Using ```https``` instead of  ```http``` as the choice of protocol might not work properly currently. This is not a tested option.\n+```./benchmark.py latency --ts https://127.0.0.1:8443```\n+\n \n ## Benchmark options\n \n The full list of options can be found by running with the -h or --help flags.\n \n # Benchmarking with Apache Bench\n \n-## Installation \n+Apache Bench can also be used in torchserve for Benchmarking performance of inference API's. The ApacheBench tool (ab) can load test servers by sending an arbitrary number of concurrent requests.\n+\n+The benchmarks measure the performance of torchserve on inference API for various models. It supports passed in a URL to the .mar file. It also runs various benchmarks using these models (see benchmarks section below).\n+\n+## Installation\n+\n+It assumes that you have followed quick start/installation section and have required pre-requisites i.e. python3, java and docker [if needed]. If not then please refer [quick start](https://github.com/pytorch/serve/blob/master/README.md) for setup.\n+\n+### Ubuntu\n+\n+First check if you already have Apache Bench(ab) installed on your Ubuntu box(local/EC2 instance). The following code will help verify the installation \u2212\n \n-### For Ubuntu\n+#### ab -V\n \n+If ab is not installed on your machine, then please follow the following steps:\n+\n+Refresh the package database.\n+\n+```bash\n+apt-get update\n ```\n-apt-get install apache2-utils\n+Install the apache2-utils package to get access to ApacheBench.\n \n+```bash\n+apt-get install apache2-utils\n ```\n \n-Apache Bench is installed in Mac by default. You can test by running ```ab -h```\n+### macOS\n+\n+For mac, you will be using 'ab' which is by default installed in macOS. You can test by running ```ab -h```.\n+\n+Apart from ab, You will also need to have following:\n \n-## Benchmark \n+- bc: for metric percentile calculation\n+- nvidia-docker for gpu machine\n+\n+## Models\n+\n+The pre-trained models for the benchmark can be mostly found in the [TorchServe model zoo](https://github.com/pytorch/serve/blob/master/docs/model_zoo.md)\n+\n+### Benchmarks\n+We support several basic benchmarks:\n+\n+- MMS throughput\n+- MMS latency P50\n+- MMS latency P90\n+- MMS latency P99\n+- MMS latency mean\n+- MMS HTTP error rate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a05eb5abc58bdd5dc84ffd5a02ce2c66108580b5"}, "originalPosition": 182}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1514, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}