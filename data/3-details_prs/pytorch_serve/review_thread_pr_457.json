{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0MDk5MDY4", "number": 457, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1M1rOEJNGkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzoxMTowOFrOEJNJBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MDg3MzE0OnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1M1rOGpoaiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1M1rOGpoaiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNjk1Mw==", "bodyText": "Frontend: The request/response handling component of TorchServe. This portion of the serving component handles both request/response coming from clients and manages the lifecycle of models.", "url": "https://github.com/pytorch/serve/pull/457#discussion_r446306953", "createdAt": "2020-06-26T17:08:53Z", "author": {"login": "lokeshgupta1975"}, "path": "README.md", "diffHunk": "@@ -8,7 +8,7 @@ TorchServe is a flexible and easy to use tool for serving PyTorch models.\n ![Architecture Diagram](https://user-images.githubusercontent.com/880376/83180095-c44cc600-a0d7-11ea-97c1-23abb4cdbe4d.jpg)\n \n ### Terminology:\n-* **Frontend**: The request/response handling component of TorchServe. This portion of the serving component handles both request/response coming from clients as well manages the models lifecycle.\n+* **Frontend**: The request/response handling component of TorchServe. This portion of the serving component handles both request/response coming from clients and manages the lifecycles of the models.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ee5065f79a3ec5dcc6e741620c92df66bae6333"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc4MDg3OTQwOnYy", "diffSide": "RIGHT", "path": "README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzoxMTowOFrOGpoe3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzoxMTowOFrOGpoe3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwODA2MQ==", "bodyText": "TorchServe exposes configurations that allow the user to configure the number of worker threads on CPU and GPUs. This is an important config property that can speed up the server depending on the workload.", "url": "https://github.com/pytorch/serve/pull/457#discussion_r446308061", "createdAt": "2020-06-26T17:11:08Z", "author": {"login": "lokeshgupta1975"}, "path": "README.md", "diffHunk": "@@ -237,9 +237,9 @@ You see output specifying that TorchServe has stopped.\n \n \n ### Concurrency And Number of Workers\n-TorchServe exposes configurations which allows the user to configure the number of worker threads on CPU and GPUs. This is an important config property that can speed up the server depending on the workload.\n+TorchServe exposes configurations that allow the user to configure the number of worker threads on CPU and GPUs. There is an important config property that can speed up the server depending on the workload.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ee5065f79a3ec5dcc6e741620c92df66bae6333"}, "originalPosition": 32}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1519, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}