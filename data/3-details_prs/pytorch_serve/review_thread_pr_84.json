{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NTY2NjMz", "number": 84, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMDoxMToxMFrODrYT-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMDoxMToxMFrODrYT-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ2ODEzNjkxOnYy", "diffSide": "RIGHT", "path": "start.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMDoxMToxMFrOF7sbDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNlQxMDo1OToxMFrOF8Bgjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODEzODEyNw==", "bodyText": "We should also add a client query to ensure we get some response from the server for this model.", "url": "https://github.com/pytorch/serve/pull/84#discussion_r398138127", "createdAt": "2020-03-25T20:11:10Z", "author": {"login": "mycpuorg"}, "path": "start.sh", "diffHunk": "@@ -0,0 +1,28 @@\n+#!/bin/bash\n+IMAGE_NAME=\"torchserve:1.0\"\n+\n+echo \"start torchserve:1.0 docker image\"\n+\n+docker run -d --rm -it -p 8080:8080 -p 8081:8081 torchserve:1.0 > /dev/null 2>&1\n+container_id=$(docker ps --filter=\"ancestor=$IMAGE_NAME\" -q | xargs)\n+\n+sleep 30\n+\n+echo \"Successfully started torchserve in docker\"\n+\n+echo \"Registering resnet-18 model\"\n+response=$(curl --retry 5 -X POST \"http://localhost:8081/models?url=https://torchserve.s3.amazonaws.com/mar_files/resnet-18.mar\")\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43ecd947ccba5a07cf2aa6b1020241463c7b5e60"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODQ4MzU5OA==", "bodyText": "this script is just to start torchserve in docker container with pre-registered resnet-18 model for quick start.\nI have also added torchserve_sanity.sh script which does the job of running all test suites, installing torchserve & torch-model-archiver, start torch serve, register resnet-18 model and run inference.", "url": "https://github.com/pytorch/serve/pull/84#discussion_r398483598", "createdAt": "2020-03-26T10:59:10Z", "author": {"login": "harshbafna"}, "path": "start.sh", "diffHunk": "@@ -0,0 +1,28 @@\n+#!/bin/bash\n+IMAGE_NAME=\"torchserve:1.0\"\n+\n+echo \"start torchserve:1.0 docker image\"\n+\n+docker run -d --rm -it -p 8080:8080 -p 8081:8081 torchserve:1.0 > /dev/null 2>&1\n+container_id=$(docker ps --filter=\"ancestor=$IMAGE_NAME\" -q | xargs)\n+\n+sleep 30\n+\n+echo \"Successfully started torchserve in docker\"\n+\n+echo \"Registering resnet-18 model\"\n+response=$(curl --retry 5 -X POST \"http://localhost:8081/models?url=https://torchserve.s3.amazonaws.com/mar_files/resnet-18.mar\")\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODEzODEyNw=="}, "originalCommit": {"oid": "43ecd947ccba5a07cf2aa6b1020241463c7b5e60"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1680, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}