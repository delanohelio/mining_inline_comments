{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4MDU1NTIw", "number": 258, "title": "added waveglow example", "bodyText": "Description\nFixes #60 , #105,  #186\nType of change\nPlease delete options that are not relevant.\n\n Bug fix (non-breaking change which fixes an issue)\n New feature (non-breaking change which adds functionality)\n\nFeature/Issue validation/testing\nValidated that the model works fine on multi-GPU machine [p3.8xlarge] with multiple workers.\nChecklist:\n\n Have you made corresponding changes to the documentation?", "createdAt": "2020-04-23T17:08:58Z", "url": "https://github.com/pytorch/serve/pull/258", "merged": true, "mergeCommit": {"oid": "07a408be7a9d18ddd6492d21c32eec7c12f7f309"}, "closed": true, "closedAt": "2020-05-18T21:52:41Z", "author": {"login": "harshbafna"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcaf4zigH2gAyNDA4MDU1NTIwOmRkYzgzYWZiMzQ2Yjc3NDFlMWVlMWI1Njk4NDQ5ZGFlOTE3OTNlOTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcimwpTAH2gAyNDA4MDU1NTIwOjY0NzMxNzhlY2QwZGJlYTNlODEzYzUwNTg2NGIwOTg0ZGZkOWRhYjU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ddc83afb346b7741e1ee1b5698449dae91793e99", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ddc83afb346b7741e1ee1b5698449dae91793e99", "committedDate": "2020-04-23T16:57:13Z", "message": "added waveglow example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4", "committedDate": "2020-04-24T13:18:42Z", "message": "Updated readme for waveglow example"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyMjg4NjIz", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-402288623", "createdAt": "2020-04-28T23:48:44Z", "commit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMzo0ODo0NVrOGNrHmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMzo1ODowMVrOGNrTyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ==", "bodyText": "This is a problem the first time through. It will start 4 workers by default, all four of which, during init, will try to download some resources to ~/.cache - the problem being that they'll overwrite each others' downloads, resulting in exceptions in the log. The behavior is not 100%, but I find it easiest to repro by starting without the --models arg on start, and using:\ncurl -X POST \"http://localhost:8081/models?initial_workers=4&url=wgsynth.mar\"\n\nThis results in error lines in the log, like:\nRuntimeError: unexpected EOF, expected 12400777 more bytes. The file might be corrupted.\n\nWhich results directly from trying to load files corrupted by download conflicts.", "url": "https://github.com/pytorch/serve/pull/258#discussion_r416991131", "createdAt": "2020-04-28T23:48:45Z", "author": {"login": "fbbradheintz"}, "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,49 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Download the checkpoint for NVIDIA WaveGlow model :\n+ \n+    ```bash\n+   wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth \n+   ```\n+\n+ * Create a torch model archive using the torch-model-archiver utility to archive the above files.\n+ \n+    ```bash\n+    torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5NDI0OQ==", "bodyText": "NB: https://github.com/nvidia/DeepLearningExamples/archive/torchhub.zip appears to be the problem file.\nOne possible fix: Add a manual download step at the beginning of the example, and include the necessary files in the model archive as --extra-files. The downloaded file, even unzipped, is much smaller than the model weights (I checked).", "url": "https://github.com/pytorch/serve/pull/258#discussion_r416994249", "createdAt": "2020-04-28T23:58:01Z", "author": {"login": "fbbradheintz"}, "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,49 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Download the checkpoint for NVIDIA WaveGlow model :\n+ \n+    ```bash\n+   wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth \n+   ```\n+\n+ * Create a torch model archive using the torch-model-archiver utility to archive the above files.\n+ \n+    ```bash\n+    torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk5MTEzMQ=="}, "originalCommit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyOTU1OTc0", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-402955974", "createdAt": "2020-04-29T19:04:44Z", "commit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxOTowNDo0NFrOGOM7TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxOTowNDo0NFrOGOM7TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0NTAzNw==", "bodyText": "One other item: At the team status meeting today, it was raised that this is not really a complete example, as it stashes the output in a file in /tmp - which does the requester no good if they're on another machine. To make the example truly valuable, it should package the file for download with the HTTP response.", "url": "https://github.com/pytorch/serve/pull/258#discussion_r417545037", "createdAt": "2020-04-29T19:04:44Z", "author": {"login": "fbbradheintz"}, "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,49 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Download the checkpoint for NVIDIA WaveGlow model :\n+ \n+    ```bash\n+   wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth \n+   ```\n+\n+ * Create a torch model archive using the torch-model-archiver utility to archive the above files.\n+ \n+    ```bash\n+    torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar\n+    curl -X POST http://127.0.0.1:8080/predictions/waveglow_synthesizer -T sample_text.txt\n+    ```\n+  * Response :\n+  ```text\n+    [Audio file generated successfully at /tmp/audio.wav]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c9f19269bff69bce3c8b9d39b9ea8b3e2870b8a4"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32871ad4016687a941ad629b231ec469b76ffe7b", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/32871ad4016687a941ad629b231ec469b76ffe7b", "committedDate": "2020-05-04T15:45:13Z", "message": "enhanced example to remove runtime checkpoint download"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "321711e8d72234e58c5e138948d5f07b916d4515", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/321711e8d72234e58c5e138948d5f07b916d4515", "committedDate": "2020-05-05T17:27:16Z", "message": "updated handler to return the audio file content instead of dumping it to tmp dir"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MDk3NjI5", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-407097629", "createdAt": "2020-05-07T01:44:36Z", "commit": {"oid": "321711e8d72234e58c5e138948d5f07b916d4515"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTo0NDozNlrOGRrcPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMTo0NDozNlrOGRrcPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5MDcxOA==", "bodyText": "Nice!", "url": "https://github.com/pytorch/serve/pull/258#discussion_r421190718", "createdAt": "2020-05-07T01:44:36Z", "author": {"login": "mycpuorg"}, "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,37 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Generate the model archive for waveglow speech synthesis model using following command\n+ \n+    ```bash\n+    ./create_mar.sh", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "321711e8d72234e58c5e138948d5f07b916d4515"}, "originalPosition": 25}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MDk4MTAx", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-407098101", "createdAt": "2020-05-07T01:46:19Z", "commit": {"oid": "321711e8d72234e58c5e138948d5f07b916d4515"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e", "committedDate": "2020-05-07T02:58:26Z", "message": "Merge branch 'staging_0_1_1' into issue_60"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4NzE4MDc3", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-408718077", "createdAt": "2020-05-10T08:02:45Z", "commit": {"oid": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODowMjo0NVrOGTBz2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODozNDo1OFrOGTCF1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYwNTc4Ng==", "bodyText": "@mycpuorg @harshbafna  Please provide steps for how the generated audio file will be downloaded when invoked from a remote machine or invoked by a python client application requesting the inference via the http api calls in the code.\nAlso explain if there are any limits on the size of the text that can be converted to audio. The size of audio file becomes large pretty soon, so the pipe may get broken on trying to download the generated audio file.", "url": "https://github.com/pytorch/serve/pull/258#discussion_r422605786", "createdAt": "2020-05-10T08:02:45Z", "author": {"login": "chauhang"}, "path": "examples/text_to_speech_synthesizer/README.md", "diffHunk": "@@ -0,0 +1,37 @@\n+# Text to speech synthesis using WaveGlow & Tacotron2 model.\n+\n+**This example works only on NVIDIA CUDA device and not on CPU**\n+\n+We have used the following Waveglow/Tacotron2 model for this example: \n+\n+https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/\n+\n+We have copied WaveGlow's model file from following github repo:\n+https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py\n+\n+\n+# Install pip dependencies using following commands\n+\n+```bash\n+pip install numpy scipy unidecode inflect\n+pip install librosa --user\n+```\n+\n+# Serve the WaveGlow speech synthesis model on TorchServe\n+\n+ * Generate the model archive for waveglow speech synthesis model using following command\n+ \n+    ```bash\n+    ./create_mar.sh\n+    ```\n+   \n+ * Register the model on TorchServe using the above model archive file and run digit recognition inference\n+   \n+    ```bash\n+    mkdir model_store\n+    mv waveglow_synthesizer.mar model_store/\n+    torchserve --start --model-store model_store --models waveglow_synthesizer.mar\n+    curl -X POST http://127.0.0.1:8080/predictions/waveglow_synthesizer -T sample_text.txt -o audio.wav", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMDM4OQ==", "bodyText": "@harshbafna If the torch-model-archiver is not installed, there is no error message thrown, the scripts ends silently without any .mar file. Will be better to throw and error for user in this case", "url": "https://github.com/pytorch/serve/pull/258#discussion_r422610389", "createdAt": "2020-05-10T08:34:58Z", "author": {"login": "chauhang"}, "path": "examples/text_to_speech_synthesizer/create_mar.sh", "diffHunk": "@@ -0,0 +1,15 @@\n+cd /tmp\n+rm torchhub.zip\n+wget https://github.com/nvidia/DeepLearningExamples/archive/torchhub.zip\n+rm -rf DeepLearningExamples-torchhub\n+unzip torchhub.zip\n+cd -\n+rm tacotron.zip\n+rm -rf PyTorch\n+mkdir -p PyTorch/SpeechSynthesis\n+cp -r /tmp/DeepLearningExamples-torchhub/PyTorch/SpeechSynthesis/* PyTorch/SpeechSynthesis/\n+zip -r tacotron.zip PyTorch\n+wget https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2pyt_fp32/versions/1/files/nvidia_tacotron2pyt_fp32_20190306.pth\n+wget wget https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth\n+torch-model-archiver --model-name waveglow_synthesizer --version 1.0 --model-file waveglow_model.py --serialized-file nvidia_waveglowpyt_fp32_20190306.pth --handler waveglow_handler.py --extra-files tacotron.zip,nvidia_tacotron2pyt_fp32_20190306.pth", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "91ff4a59a7de5bbb2c3be004b82bdbaf0770d71e"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "451882b2a926e2e5a4c0877e002238668b6824aa", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/451882b2a926e2e5a4c0877e002238668b6824aa", "committedDate": "2020-05-12T10:17:05Z", "message": "Merge branch 'staging_0_1_1' into issue_60"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "64eca56cf06157424e79e627e481b2654f8bd5b8", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/64eca56cf06157424e79e627e481b2654f8bd5b8", "committedDate": "2020-05-12T10:25:24Z", "message": "minor change to handler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff90b9df5a2785f5039b4eafe40ead451b642993", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/ff90b9df5a2785f5039b4eafe40ead451b642993", "committedDate": "2020-05-12T16:54:43Z", "message": "added pipefail"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwMjYyNjc4", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-410262678", "createdAt": "2020-05-12T17:24:14Z", "commit": {"oid": "ff90b9df5a2785f5039b4eafe40ead451b642993"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNzoyNDoxNFrOGURLKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxNzoyNDoxNFrOGURLKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkwNjA4OQ==", "bodyText": "@harshbafna Can you please explain the purpose of this?", "url": "https://github.com/pytorch/serve/pull/258#discussion_r423906089", "createdAt": "2020-05-12T17:24:14Z", "author": {"login": "chauhang"}, "path": "examples/text_to_speech_synthesizer/waveglow_handler.py", "diffHunk": "@@ -62,6 +62,7 @@ def initialize(self, ctx):\n         waveglow_config = waveglow_checkpoint['config']\n         self.waveglow_model = WaveGlow(**waveglow_config)\n         self.waveglow_model.load_state_dict(waveglow_state_dict)\n+        self.waveglow_model = self.waveglow_model.remove_weightnorm(self.waveglow_model)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff90b9df5a2785f5039b4eafe40ead451b642993"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e738fd0a72d7472bd36f3cb6410916b7c358811", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/1e738fd0a72d7472bd36f3cb6410916b7c358811", "committedDate": "2020-05-12T17:29:22Z", "message": "added python snippet to run inference"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "167bddd8d2286b65c0577a4e566ae0bd7cfa660d", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/167bddd8d2286b65c0577a4e566ae0bd7cfa660d", "committedDate": "2020-05-12T17:40:17Z", "message": "Merge branch 'staging_0_1_1' into issue_60"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d06f8818a46f8b77b3a8431fbb614cb150102f5", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/5d06f8818a46f8b77b3a8431fbb614cb150102f5", "committedDate": "2020-05-14T16:52:23Z", "message": "updated readme with know issue with the example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0edafd0aba760270f2e0ae33b3fbd95b259360d4", "author": {"user": {"login": "harshbafna", "name": "Harsh Bafna"}}, "url": "https://github.com/pytorch/serve/commit/0edafd0aba760270f2e0ae33b3fbd95b259360d4", "committedDate": "2020-05-14T17:02:50Z", "message": "Merge branch 'issue_60' of https://github.com/pytorch/serve into issue_60"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzMTEwODY4", "url": "https://github.com/pytorch/serve/pull/258#pullrequestreview-413110868", "createdAt": "2020-05-16T21:48:35Z", "commit": {"oid": "0edafd0aba760270f2e0ae33b3fbd95b259360d4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6473178ecd0dbea3e813c505864b0984dfd9dab5", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/6473178ecd0dbea3e813c505864b0984dfd9dab5", "committedDate": "2020-05-18T21:29:02Z", "message": "Merge branch 'staging_0_1_1' into issue_60"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2332, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}