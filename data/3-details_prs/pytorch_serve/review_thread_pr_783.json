{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIwODYyMjI3", "number": 783, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNlQwMjoxODo1OFrOFmQ5oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNlQwMjoxODo1OFrOFmQ5oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzc1NjY3MTA1OnYy", "diffSide": "RIGHT", "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xNlQwMjoxODo1OFrOI3QmdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0xOFQwMzoxMzoyNVrOI442EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA==", "bodyText": "These changes store model log in separate log files. It is much easier for user to control model log format. The only problem is that the mapping information b/w frontend worker thread id and backend worker pid is missing. It will be difficult to debug TS to detect if there is sth wrong with frontend worker thread.", "url": "https://github.com/pytorch/serve/pull/783#discussion_r594814580", "createdAt": "2021-03-16T02:18:58Z", "author": {"login": "lxning"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTEyMjk0Nw==", "bodyText": "Hi, thanks for having a look. Where do you think the PID message should end up?", "url": "https://github.com/pytorch/serve/pull/783#discussion_r595122947", "createdAt": "2021-03-16T12:30:01Z", "author": {"login": "aparmentier-coveo"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTQwNTM2NQ==", "bodyText": "current model log example as following:\n2021-03-16 17:27:09,260 [INFO ] W-9001-vgg11_v2_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\nthis pr model log example as following. Here, it is difficult to know which frontend worker thread has problem from the log.\n2021-03-16 02:02:41,569 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006\n2021-03-16 02:02:41,576 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002\n2021-03-16 02:02:41,573 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009\n2021-03-16 02:02:41,566 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015\n2021-03-16 02:02:41,562 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014\n2021-03-16 02:02:41,562 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007\n2021-03-16 02:02:41,587 [INFO ] MODEL_LOG - [PID]55\n2021-03-16 02:02:41,588 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,588 [INFO ] MODEL_LOG - Python runtime: 3.6.9\n2021-03-16 02:02:41,587 [INFO ] MODEL_LOG - [PID]54\n2021-03-16 02:02:41,589 [INFO ] MODEL_LOG - [PID]56\n2021-03-16 02:02:41,589 [INFO ] MODEL_LOG - [PID]59\n2021-03-16 02:02:41,589 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,590 [INFO ] MODEL_LOG - [PID]58\n2021-03-16 02:02:41,590 [INFO ] MODEL_LOG - [PID]57\n2021-03-16 02:02:41,590 [INFO ] MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004\n2021-03-16 02:02:41,592 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,592 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,593 [INFO ] MODEL_LOG - Python runtime: 3.6.9\n2021-03-16 02:02:41,591 [INFO ] MODEL_LOG - Python runtime: 3.6.9\n2021-03-16 02:02:41,591 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,590 [INFO ] MODEL_LOG - Torch worker started.\n2021-03-16 02:02:41,593 [INFO ] MODEL_LOG - Python runtime: 3.6.9\n2021-03-16 02:02:41,593 [INFO ] MODEL_LOG - [PID]79\nIt would be very helpful if each message contains frontend worker thread id (eg. W-9001-vgg11_v2_1.0)  information in the model log.", "url": "https://github.com/pytorch/serve/pull/783#discussion_r595405365", "createdAt": "2021-03-16T17:46:24Z", "author": {"login": "lxning"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTUzMzA0MA==", "bodyText": "Oh I see, thank you. I think that would just be a change to the log4j default settings for the MODEL_LOG. I'll experiment and probably update this PR tomorrow.", "url": "https://github.com/pytorch/serve/pull/783#discussion_r595533040", "createdAt": "2021-03-16T20:54:16Z", "author": {"login": "aparmentier-coveo"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTU1OTA1Ng==", "bodyText": "Thanks a lot.", "url": "https://github.com/pytorch/serve/pull/783#discussion_r595559056", "createdAt": "2021-03-16T21:38:56Z", "author": {"login": "lxning"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NjM3MTY5Nw==", "bodyText": "I rebased and updated the default logging pattern format for MODEL_LOG to be the same as the other logs which include a thread name.\nCheers,\nAlex", "url": "https://github.com/pytorch/serve/pull/783#discussion_r596371697", "createdAt": "2021-03-17T20:49:04Z", "author": {"login": "aparmentier-coveo"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NjUyMjUxMw==", "bodyText": "It works. Thank you!", "url": "https://github.com/pytorch/serve/pull/783#discussion_r596522513", "createdAt": "2021-03-18T03:13:25Z", "author": {"login": "lxning"}, "path": "frontend/server/src/main/java/org/pytorch/serve/wlm/WorkerLifeCycle.java", "diffHunk": "@@ -141,8 +141,10 @@ private synchronized void setPort(int port) {\n         private boolean error;\n         private WorkerLifeCycle lifeCycle;\n         private AtomicBoolean isRunning = new AtomicBoolean(true);\n-        private static final org.apache.log4j.Logger loggerModelMetrics =\n-                org.apache.log4j.Logger.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelMetrics =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_METRICS_LOGGER);\n+        private static final Logger loggerModelOutput =\n+                LoggerFactory.getLogger(ConfigManager.MODEL_LOGGER);\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDgxNDU4MA=="}, "originalCommit": {"oid": "d691dda23759a83c1d00818615bb8ded612d6e2a"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1465, "cost": 1, "resetAt": "2021-11-13T12:26:42Z"}}}