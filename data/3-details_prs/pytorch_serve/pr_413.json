{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0NzgyNDA0", "number": 413, "title": "Adding system diagram and brief explanation of workings", "bodyText": "Description\nAdding system diagram and brief explanation of workings\nCloses #206\nType of change\nPlease delete options that are not relevant.\n\n This change requires a documentation update\n\nChecklist:\n\n Have you made corresponding changes to the documentation?", "createdAt": "2020-05-28T23:04:03Z", "url": "https://github.com/pytorch/serve/pull/413", "merged": true, "mergeCommit": {"oid": "48dddc2ab2eb6cf9235ab677d1f6cce837575973"}, "closed": true, "closedAt": "2020-06-10T00:29:24Z", "author": {"login": "maaquib"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcl2GnngH2gAyNDI0NzgyNDA0OjA0NTZhZDZjYzFkMjZiYmM0NTQ0NGM5ZjIwNWJhOTc3YjU4OGYyNmE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcphKfPAFqTQyNjkyNjM3Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0456ad6cc1d26bbc45444c9f205ba977b588f26a", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/0456ad6cc1d26bbc45444c9f205ba977b588f26a", "committedDate": "2020-05-28T23:03:23Z", "message": "Adding system diagram and brief explanation of workings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3946db5421a3ba6815531cfb58d4ad9137eaca8", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/d3946db5421a3ba6815531cfb58d4ad9137eaca8", "committedDate": "2020-05-29T16:23:53Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cfcdcd07a3e698938150f1fc115539f9ad33ad7b", "author": {"user": {"login": "mycpuorg", "name": null}}, "url": "https://github.com/pytorch/serve/commit/cfcdcd07a3e698938150f1fc115539f9ad33ad7b", "committedDate": "2020-06-01T16:24:53Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d518fa085a2bc58dd60bf056a0a8e8266dcfb2d", "author": {"user": {"login": "dhanainme", "name": null}}, "url": "https://github.com/pytorch/serve/commit/6d518fa085a2bc58dd60bf056a0a8e8266dcfb2d", "committedDate": "2020-06-03T00:30:49Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "47000b37fac09496bcf74db4156f94e3908e25a0", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/47000b37fac09496bcf74db4156f94e3908e25a0", "committedDate": "2020-06-05T19:44:39Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e96e28df873b8062002529d7a6f9e800a8e38857", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/e96e28df873b8062002529d7a6f9e800a8e38857", "committedDate": "2020-06-05T21:22:31Z", "message": "Adding number of worker recommendations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "160be78cebb3bbb02dcde10ae905afaffd4367a9", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/160be78cebb3bbb02dcde10ae905afaffd4367a9", "committedDate": "2020-06-08T17:34:18Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82596ef575cc75bed2f69ed9b7b8d7a3f3842db6", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/82596ef575cc75bed2f69ed9b7b8d7a3f3842db6", "committedDate": "2020-06-08T23:32:00Z", "message": "Merge branch 'staging_0_1_1' into issue_206"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1ce19249daeb9b3183682752c7329753899e82dc", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/1ce19249daeb9b3183682752c7329753899e82dc", "committedDate": "2020-06-08T23:32:44Z", "message": "Adding description of netty configuration params"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NjkxOTgx", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426691981", "createdAt": "2020-06-08T23:37:33Z", "commit": {"oid": "1ce19249daeb9b3183682752c7329753899e82dc"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NjkzMzc0", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426693374", "createdAt": "2020-06-08T23:41:26Z", "commit": {"oid": "1ce19249daeb9b3183682752c7329753899e82dc"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d", "author": {"user": {"login": "maaquib", "name": "Aaqib"}}, "url": "https://github.com/pytorch/serve/commit/142fc595b4b8a4ed10c22f4cd100b33acc22195d", "committedDate": "2020-06-08T23:47:35Z", "message": "Update header for worker threads readme section"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NzAzMDk5", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426703099", "createdAt": "2020-06-09T00:07:49Z", "commit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2NzI2MjU3", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426726257", "createdAt": "2020-06-09T01:22:49Z", "commit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToyMjo1MFrOGg1mAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMToyMjo1MFrOGg1mAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NTY5OQ==", "bodyText": "Maybe add a bit of background about how Netty is used in TorchServe", "url": "https://github.com/pytorch/serve/pull/413#discussion_r437085699", "createdAt": "2020-06-09T01:22:50Z", "author": {"login": "mycpuorg"}, "path": "docs/configuration.md", "diffHunk": "@@ -188,8 +188,8 @@ By default, TorchServe uses all available GPUs for inference. Use `number_of_gpu\n Most of the following properties are designed for performance tuning. Adjusting these numbers will impact scalability and throughput.\n \n * `enable_envvars_config`: Enable configuring TorchServe through environment variables. When this option is set to \"true\", all the static configurations of TorchServe can come through environment variables as well. Default: false\n-* `number_of_netty_threads`: number frontend netty thread. Default: number of logical processors available to the JVM.\n-* `netty_client_threads`: number of backend netty thread. Default: number of logical processors available to the JVM.\n+* `number_of_netty_threads`: number frontend netty thread. This specifies the numer of threads in the child [EventLoopGroup](https://livebook.manning.com/book/netty-in-action/chapter-8) of the frontend netty server. This group provides EventLoops for processing Netty Channel events (namely inference and management requests) from accepted connections. Default: number of logical processors available to the JVM.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2OTIwMzM3", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426920337", "createdAt": "2020-06-09T08:48:12Z", "commit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwODo0ODoxMlrOGg_EaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwODo0ODoxMlrOGg_EaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzI0MDkzNw==", "bodyText": "In the diagram, we should name Thread1/Thread2 as Worker1/Worker2.\nAlso, will it be a good idea to define 'Model Handler' as it has been referred to in the diagram.\nAnd some reference to MAR under 'Model' terminology.", "url": "https://github.com/pytorch/serve/pull/413#discussion_r437240937", "createdAt": "2020-06-09T08:48:12Z", "author": {"login": "dhaniram-kshirsagar"}, "path": "README.md", "diffHunk": "@@ -4,6 +4,16 @@ TorchServe is a flexible and easy to use tool for serving PyTorch models.\n \n **For full documentation, see [Model Server for PyTorch Documentation](docs/README.md).**\n \n+## TorchServe Architecture\n+![Architecture Diagram](https://user-images.githubusercontent.com/880376/83180095-c44cc600-a0d7-11ea-97c1-23abb4cdbe4d.jpg)\n+\n+### Terminology:\n+* **Frontend**: The request/response handling component of TorchServe. This portion of the serving component handles both request/response coming from clients as well manages the models lifecycle.\n+* **Model Workers**: These workers are responsible for running the actual inference on the models. These are actual running instances of the models.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI2OTI2Mzcy", "url": "https://github.com/pytorch/serve/pull/413#pullrequestreview-426926372", "createdAt": "2020-06-09T08:55:18Z", "commit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwODo1NToxOFrOGg_Wig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwODo1NToxOFrOGg_Wig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzI0NTU3OA==", "bodyText": "Though not related -> 'Install Java 11' step has been repeated in 'install using pip' and 'install using conda'.", "url": "https://github.com/pytorch/serve/pull/413#discussion_r437245578", "createdAt": "2020-06-09T08:55:18Z", "author": {"login": "dhaniram-kshirsagar"}, "path": "README.md", "diffHunk": "@@ -4,6 +4,16 @@ TorchServe is a flexible and easy to use tool for serving PyTorch models.\n \n **For full documentation, see [Model Server for PyTorch Documentation](docs/README.md).**\n \n+## TorchServe Architecture\n+![Architecture Diagram](https://user-images.githubusercontent.com/880376/83180095-c44cc600-a0d7-11ea-97c1-23abb4cdbe4d.jpg)\n+\n+### Terminology:\n+* **Frontend**: The request/response handling component of TorchServe. This portion of the serving component handles both request/response coming from clients as well manages the models lifecycle.\n+* **Model Workers**: These workers are responsible for running the actual inference on the models. These are actual running instances of the models.\n+* **Model**: Models could be a `script_module` (JIT saved models) or `eager_mode_models`. These models can provide custom pre- and post-processing of data along with any other model artifacts such as state_dicts. Models can be loaded from cloud storage or from local hosts.\n+* **Plugins**: These are custom endpoints or authz/authn or batching algorithms that can be dropped into TorchServe at startup time.\n+* **Model Store**: This is a directory in which all the loadable models exist.\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "142fc595b4b8a4ed10c22f4cd100b33acc22195d"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2175, "cost": 1, "resetAt": "2021-11-01T16:37:27Z"}}}