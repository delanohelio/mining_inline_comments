{"pr_number": 785, "pr_title": "Workflow support", "pr_createdAt": "2020-11-17T12:18:05Z", "pr_url": "https://github.com/pytorch/serve/pull/785", "timeline": [{"oid": "88b1336163364d024d4ad521d4f213fe290990f6", "url": "https://github.com/pytorch/serve/commit/88b1336163364d024d4ad521d4f213fe290990f6", "message": "removed intial model loading", "committedDate": "2020-12-24T08:21:11Z", "type": "commit"}, {"oid": "c233403b5748a3020439c9f7b82ee0e9bc5b8a68", "url": "https://github.com/pytorch/serve/commit/c233403b5748a3020439c9f7b82ee0e9bc5b8a68", "message": "workflow function handler file path fix", "committedDate": "2020-12-24T11:02:46Z", "type": "commit"}, {"oid": "8e8133c173c610443ff87f9584f005750f95c8b3", "url": "https://github.com/pytorch/serve/commit/8e8133c173c610443ff87f9584f005750f95c8b3", "message": "fixed function signature", "committedDate": "2020-12-24T11:33:52Z", "type": "commit"}, {"oid": "471a70e95e84c16b25cc9254ede832472016e6f4", "url": "https://github.com/pytorch/serve/commit/471a70e95e84c16b25cc9254ede832472016e6f4", "message": "renamed example directory", "committedDate": "2020-12-24T11:47:22Z", "type": "commit"}, {"oid": "8e695bde7051a4f4ab47c31eb6a6777e47c6b356", "url": "https://github.com/pytorch/serve/commit/8e695bde7051a4f4ab47c31eb6a6777e47c6b356", "message": "fixed workflow handler file path issue on windows", "committedDate": "2020-12-24T12:27:07Z", "type": "commit"}, {"oid": "bb50e5e01b5f8ae8bd2cbe0f48d7124ab5116d05", "url": "https://github.com/pytorch/serve/commit/bb50e5e01b5f8ae8bd2cbe0f48d7124ab5116d05", "message": "enhanced torchserve_sanity script to validate pileline workflow examples", "committedDate": "2020-12-24T12:40:22Z", "type": "commit"}, {"oid": "bed28a3768f4eddd5a5b4fdda81510a1b6b02610", "url": "https://github.com/pytorch/serve/commit/bed28a3768f4eddd5a5b4fdda81510a1b6b02610", "message": "PMD fixes", "committedDate": "2020-12-24T13:07:48Z", "type": "commit"}, {"oid": "2cf7fbb1057be67a2380cec9949e96bd2b14b653", "url": "https://github.com/pytorch/serve/commit/2cf7fbb1057be67a2380cec9949e96bd2b14b653", "message": "added no config snapshot in workflow sanity", "committedDate": "2020-12-24T13:58:33Z", "type": "commit"}, {"oid": "8af6c400d8438a915cdb6740e5bbf4ab56701e34", "url": "https://github.com/pytorch/serve/commit/8af6c400d8438a915cdb6740e5bbf4ab56701e34", "message": "fixed handler path in function model archive", "committedDate": "2020-12-24T14:59:40Z", "type": "commit"}, {"oid": "acd7e47401e44264880ef149b40991c71fb817fa", "url": "https://github.com/pytorch/serve/commit/acd7e47401e44264880ef149b40991c71fb817fa", "message": "added os specific command for workflow sanity", "committedDate": "2020-12-24T15:25:26Z", "type": "commit"}, {"oid": "ee5917488e736b80d03c7f1a92bbf9fe668fe083", "url": "https://github.com/pytorch/serve/commit/ee5917488e736b80d03c7f1a92bbf9fe668fe083", "message": "replaced commands with python utilitiy calls", "committedDate": "2020-12-24T16:12:28Z", "type": "commit"}, {"oid": "8ab5c96847d8ecd39ed4983e3eadda9efdce1c86", "url": "https://github.com/pytorch/serve/commit/8ab5c96847d8ecd39ed4983e3eadda9efdce1c86", "message": "Merge branch 'master' into issue_682", "committedDate": "2020-12-24T17:14:20Z", "type": "commit"}, {"oid": "4e3a1c5d62ac1f4fe5d673f40319074e410ac0fe", "url": "https://github.com/pytorch/serve/commit/4e3a1c5d62ac1f4fe5d673f40319074e410ac0fe", "message": "added negative test cases and fixed corresponding responses", "committedDate": "2020-12-28T06:36:18Z", "type": "commit"}, {"oid": "455911fe38ba7eb78ed6ca5fd6373ee29fed47ab", "url": "https://github.com/pytorch/serve/commit/455911fe38ba7eb78ed6ca5fd6373ee29fed47ab", "message": "more negative test cases", "committedDate": "2020-12-28T07:31:12Z", "type": "commit"}, {"oid": "22faedd45d0d2660b731ed55fb9b777afe69d303", "url": "https://github.com/pytorch/serve/commit/22faedd45d0d2660b731ed55fb9b777afe69d303", "message": "improved error handling and added more test cases", "committedDate": "2020-12-28T15:17:43Z", "type": "commit"}, {"oid": "df35dd3e6630acfef85d36d32e683d2906aa7115", "url": "https://github.com/pytorch/serve/commit/df35dd3e6630acfef85d36d32e683d2906aa7115", "message": "Multi input support (#931)", "committedDate": "2020-12-29T04:57:17Z", "type": "commit"}, {"oid": "456fe55ac1e348f5568bfb4d9c41a819fda88765", "url": "https://github.com/pytorch/serve/commit/456fe55ac1e348f5568bfb4d9c41a819fda88765", "message": "updated expected output", "committedDate": "2020-12-29T05:41:01Z", "type": "commit"}, {"oid": "77ed6af4d31332de781d5c266850d1496c79a3bd", "url": "https://github.com/pytorch/serve/commit/77ed6af4d31332de781d5c266850d1496c79a3bd", "message": "more test cases", "committedDate": "2020-12-29T11:45:30Z", "type": "commit"}, {"oid": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "url": "https://github.com/pytorch/serve/commit/14627541568be02cf2ba7256c53b350d7b3ee3ad", "message": "Merge branch 'master' into issue_682", "committedDate": "2021-01-19T22:28:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2Mjk4OQ==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573262989", "bodyText": "Large method. Can be split in to small pieces.\n\nParsing manifest file.\nCreating / validating DAG", "author": "dhanainme", "createdAt": "2021-02-09T21:43:05Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;\n+            WorkflowModel wfm;\n+            if (!models.containsKey(modelName)) {\n+                wfm =\n+                        new WorkflowModel(\n+                                modelName,\n+                                null,\n+                                1,\n+                                1,\n+                                1,\n+                                0,\n+                                handlerFile.getPath() + \":\" + nodeName);\n+            } else {\n+                wfm = models.get(modelName);\n+            }\n+            Node fromNode = new Node(nodeName, wfm);\n+            dag.addNode(fromNode);\n+\n+            @SuppressWarnings(\"unchecked\")\n+            ArrayList<String> values = (ArrayList<String>) entry.getValue();\n+            for (String toNodeName : values) {\n+\n+                if (toNodeName == null || (\"\").equals(toNodeName.strip())) {\n+                    continue;\n+                }\n+                String toModelName = workFlowName + \"__\" + toNodeName;\n+                WorkflowModel toWfm;\n+                if (!models.containsKey(toModelName)) {\n+                    toWfm =\n+                            new WorkflowModel(\n+                                    toModelName,\n+                                    null,\n+                                    1,\n+                                    1,\n+                                    1,\n+                                    0,\n+                                    handlerFile.getPath() + \":\" + toNodeName);\n+                } else {\n+                    toWfm = models.get(toModelName);\n+                }\n+                Node toNode = new Node(toNodeName, toWfm);\n+                dag.addNode(toNode);\n+                dag.addEdge(fromNode, toNode);\n+            }\n+        }\n+        dag.validate();\n+    }", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzUwMg==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573263502", "bodyText": "min-workers / max-workers / others are Java constants", "author": "dhanainme", "createdAt": "2021-02-09T21:44:01Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NTYwOA==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573265608", "bodyText": "Also SnakeYML will convert a Java YML file to a object. Much better to use than parsing manually. https://bitbucket.org/asomov/snakeyaml/wiki/Documentation", "author": "dhanainme", "createdAt": "2021-02-09T21:47:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzUwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2MzY5Mg==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573263692", "bodyText": "final", "author": "dhanainme", "createdAt": "2021-02-09T21:44:19Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NDI2NQ==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573264265", "bodyText": "Lombok ?\nThis is refactoring opportunity for larger code base.", "author": "dhanainme", "createdAt": "2021-02-09T21:45:21Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;\n+            WorkflowModel wfm;\n+            if (!models.containsKey(modelName)) {\n+                wfm =\n+                        new WorkflowModel(\n+                                modelName,\n+                                null,\n+                                1,\n+                                1,\n+                                1,\n+                                0,\n+                                handlerFile.getPath() + \":\" + nodeName);\n+            } else {\n+                wfm = models.get(modelName);\n+            }\n+            Node fromNode = new Node(nodeName, wfm);\n+            dag.addNode(fromNode);\n+\n+            @SuppressWarnings(\"unchecked\")\n+            ArrayList<String> values = (ArrayList<String>) entry.getValue();\n+            for (String toNodeName : values) {\n+\n+                if (toNodeName == null || (\"\").equals(toNodeName.strip())) {\n+                    continue;\n+                }\n+                String toModelName = workFlowName + \"__\" + toNodeName;\n+                WorkflowModel toWfm;\n+                if (!models.containsKey(toModelName)) {\n+                    toWfm =\n+                            new WorkflowModel(\n+                                    toModelName,\n+                                    null,\n+                                    1,\n+                                    1,\n+                                    1,\n+                                    0,\n+                                    handlerFile.getPath() + \":\" + toNodeName);\n+                } else {\n+                    toWfm = models.get(toModelName);\n+                }\n+                Node toNode = new Node(toNodeName, toWfm);\n+                dag.addNode(toNode);\n+                dag.addEdge(fromNode, toNode);\n+            }\n+        }\n+        dag.validate();\n+    }\n+\n+    private static Map<String, Object> readSpecFile(File file)\n+            throws IOException, InvalidWorkflowException {\n+        Yaml yaml = new Yaml();\n+        try (Reader r =\n+                new InputStreamReader(\n+                        Files.newInputStream(file.toPath()), StandardCharsets.UTF_8)) {\n+            @SuppressWarnings(\"unchecked\")\n+            Map<String, Object> loadedYaml = (Map<String, Object>) yaml.load(r);\n+            return loadedYaml;\n+        } catch (YAMLException e) {\n+            throw new InvalidWorkflowException(\"Failed to parse yaml.\", e);\n+        }\n+    }\n+\n+    public Object getWorkflowSpec() {\n+        return workflowSpec;\n+    }\n+\n+    public Dag getDag() {\n+        return this.dag;\n+    }\n+\n+    public WorkflowArchive getWorkflowArchive() {\n+        return workflowArchive;\n+    }\n+\n+    public int getMinWorkers() {\n+        return minWorkers;\n+    }\n+\n+    public void setMinWorkers(int minWorkers) {\n+        this.minWorkers = minWorkers;\n+    }\n+\n+    public int getMaxWorkers() {\n+        return maxWorkers;\n+    }\n+\n+    public void setMaxWorkers(int maxWorkers) {\n+        this.maxWorkers = maxWorkers;\n+    }\n+\n+    public int getBatchSize() {\n+        return batchSize;\n+    }\n+\n+    public void setBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+    }\n+\n+    public int getMaxBatchDelay() {\n+        return maxBatchDelay;\n+    }\n+\n+    public void setMaxBatchDelay(int maxBatchDelay) {\n+        this.maxBatchDelay = maxBatchDelay;\n+    }\n+\n+    public String getWorkflowDag() {\n+        return this.workflowSpec.get(\"dag\").toString();\n+    }\n+}", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI2NjA2OA==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573266068", "bodyText": "String builder", "author": "dhanainme", "createdAt": "2021-02-09T21:48:07Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java", "diffHunk": "@@ -0,0 +1,204 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.io.Reader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import org.pytorch.serve.archive.workflow.InvalidWorkflowException;\n+import org.pytorch.serve.archive.workflow.WorkflowArchive;\n+import org.yaml.snakeyaml.Yaml;\n+import org.yaml.snakeyaml.error.YAMLException;\n+\n+public class WorkFlow {\n+\n+    private Map<String, Object> workflowSpec;\n+\n+    private WorkflowArchive workflowArchive;\n+    private int minWorkers = 1;\n+    private int maxWorkers = 1;\n+    private int batchSize = 1;\n+    private int maxBatchDelay = 50;\n+\n+    private Dag dag = new Dag();\n+\n+    public WorkFlow(WorkflowArchive workflowArchive)\n+            throws IOException, InvalidDAGException, InvalidWorkflowException {\n+        this.workflowArchive = workflowArchive;\n+        File specFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getSpecFile());\n+        File handlerFile =\n+                new File(\n+                        this.workflowArchive.getWorkflowDir(),\n+                        this.workflowArchive.getManifest().getWorkflow().getHandler());\n+\n+        String workFlowName = this.workflowArchive.getWorkflowName();\n+        Map<String, WorkflowModel> models = new HashMap<String, WorkflowModel>();\n+\n+        @SuppressWarnings(\"unchecked\")\n+        LinkedHashMap<String, Object> spec =\n+                (LinkedHashMap<String, Object>) this.readSpecFile(specFile);\n+        this.workflowSpec = spec;\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> modelsInfo = (Map<String, Object>) this.workflowSpec.get(\"models\");\n+        for (Map.Entry<String, Object> entry : modelsInfo.entrySet()) {\n+            String keyName = entry.getKey();\n+\n+            switch (keyName) {\n+                case \"min-workers\":\n+                    minWorkers = (int) entry.getValue();\n+                    break;\n+                case \"max-workers\":\n+                    maxWorkers = (int) entry.getValue();\n+                    break;\n+                case \"batch-size\":\n+                    batchSize = (int) entry.getValue();\n+                    break;\n+                case \"max-batch-delay\":\n+                    maxBatchDelay = (int) entry.getValue();\n+                    break;\n+                default:\n+                    // entry.getValue().getClass() check object type.\n+                    // assuming Map containing model info\n+                    @SuppressWarnings(\"unchecked\")\n+                    LinkedHashMap<String, Object> model =\n+                            (LinkedHashMap<String, Object>) entry.getValue();\n+                    String modelName = workFlowName + \"__\" + keyName;\n+\n+                    WorkflowModel wfm =\n+                            new WorkflowModel(\n+                                    modelName,\n+                                    (String) model.get(\"url\"),\n+                                    (int) model.getOrDefault(\"min-workers\", minWorkers),\n+                                    (int) model.getOrDefault(\"max-workers\", maxWorkers),\n+                                    (int) model.getOrDefault(\"batch-size\", batchSize),\n+                                    (int) model.getOrDefault(\"max-batch-delay\", maxBatchDelay),\n+                                    null);\n+\n+                    models.put(modelName, wfm);\n+            }\n+        }\n+\n+        @SuppressWarnings(\"unchecked\")\n+        Map<String, Object> dagInfo = (Map<String, Object>) this.workflowSpec.get(\"dag\");\n+\n+        for (Map.Entry<String, Object> entry : dagInfo.entrySet()) {\n+            String nodeName = entry.getKey();\n+            String modelName = workFlowName + \"__\" + nodeName;", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI5OTU4MA==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573299580", "bodyText": "final / Lombok", "author": "dhanainme", "createdAt": "2021-02-09T22:40:32Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/Node.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class Node {\n+\n+    private String name;\n+    private String parentName;\n+    private WorkflowModel workflowModel;", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzI5OTk1Ng==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573299956", "bodyText": "Refactor to use Guava Graph lib - https://guava.dev/releases/23.0/api/docs/com/google/common/graph/Graph.html", "author": "dhanainme", "createdAt": "2021-02-09T22:41:20Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/Dag.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+\n+/** Direct acyclic graph for ensemble */\n+public class Dag {\n+\n+    private Map<String, Node> nodes = new HashMap<>();\n+\n+    private Map<String, Map<String, Set<String>>> dagMap = new HashMap<>();\n+\n+    public void addNode(Node node) {\n+        if (!checkNodeExist(node)) {\n+            nodes.put(node.getName(), node);\n+            Map<String, Set<String>> degreeMap = new HashMap<>();\n+            degreeMap.put(\"inDegree\", new HashSet<String>());\n+            degreeMap.put(\"outDegree\", new HashSet<String>());\n+            dagMap.put(node.getName(), degreeMap);\n+        }\n+    }\n+\n+    public boolean checkNodeExist(Node node) {\n+        return nodes.containsKey(node.getName());\n+    }\n+\n+    public boolean hasEdgeTo(Node from, Node to) {\n+        return dagMap.get(from.getName()).get(\"inDegree\").contains(to.getName());\n+    }\n+\n+    public void addEdge(Node from, Node to) throws InvalidDAGException {\n+        if (!checkNodeExist(from)) {\n+            addNode(from);\n+        }\n+        if (!checkNodeExist(to)) {\n+            addNode(to);\n+        }\n+\n+        if (from.getName().equals(to.getName())) {\n+            throw new InvalidDAGException(\"Self loop exception\");\n+        }\n+\n+        if (hasEdgeTo(to, from)) {\n+            throw new InvalidDAGException(\"loop exception\");\n+        }\n+\n+        dagMap.get(from.getName()).get(\"outDegree\").add(to.getName());\n+        dagMap.get(to.getName()).get(\"inDegree\").add(from.getName());\n+    }\n+\n+    public Set<String> getEndNodeNames(String degree) {\n+        Set<String> startNodes = new HashSet<>();\n+        for (Map.Entry<String, Map<String, Set<String>>> entry : dagMap.entrySet()) {\n+            Set<String> value = entry.getValue().get(degree);\n+            if (value.isEmpty()) {\n+                startNodes.add(entry.getKey());\n+            }\n+        }\n+        return startNodes;\n+    }\n+\n+    public Set<String> getStartNodeNames() {\n+        return getEndNodeNames(\"inDegree\");\n+    }\n+\n+    public Set<String> getLeafNodeNames() {\n+        return getEndNodeNames(\"outDegree\");\n+    }\n+\n+    public Map<String, Integer> getDegreeMap(String degree) {\n+        Map<String, Integer> inDegreeMap = new HashMap<>();\n+        for (Map.Entry<String, Map<String, Set<String>>> entry : dagMap.entrySet()) {\n+            inDegreeMap.put(entry.getKey(), entry.getValue().get(degree).size());\n+        }\n+        return inDegreeMap;\n+    }\n+\n+    public Map<String, Integer> getInDegreeMap() {\n+        return getDegreeMap(\"inDegree\");\n+    }\n+\n+    public Map<String, Integer> getOutDegreeMap() {\n+        return getDegreeMap(\"outDegree\");\n+    }\n+\n+    public Map<String, Node> getNodes() {\n+        return nodes;\n+    }\n+\n+    public Map<String, Map<String, Set<String>>> getDagMap() {\n+        return dagMap;\n+    }\n+\n+    public ArrayList<String> validate() throws InvalidDAGException {\n+        Set<String> startNodes = getStartNodeNames();\n+\n+        if (startNodes.size() != 1) {\n+            throw new InvalidDAGException(\"DAG should have only one start node\");\n+        }\n+\n+        ArrayList<String> topoSortedList = new ArrayList<>();\n+        DagExecutor de = new DagExecutor(this);\n+        de.execute(null, topoSortedList);\n+        if (topoSortedList.size() != nodes.size()) {\n+            throw new InvalidDAGException(\"Not a valid DAG\");\n+        }\n+        return topoSortedList;\n+    }\n+}", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMTcwNQ==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573301705", "bodyText": "ListenableFuture may be a more appropriate\nhttps://guava.dev/releases/21.0/api/docs/com/google/common/util/concurrent/ListenableFuture.html\nhttps://stackoverflow.com/questions/19138212/how-to-implement-a-dag-like-scheduler-in-java has a good example.", "author": "dhanainme", "createdAt": "2021-02-09T22:44:53Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/DagExecutor.java", "diffHunk": "@@ -0,0 +1,161 @@\n+package org.pytorch.serve.ensemble;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.CompletionService;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorCompletionService;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import org.pytorch.serve.archive.model.ModelNotFoundException;\n+import org.pytorch.serve.archive.model.ModelVersionNotFoundException;\n+import org.pytorch.serve.http.InternalServerException;\n+import org.pytorch.serve.job.RestJob;\n+import org.pytorch.serve.util.ApiUtils;\n+import org.pytorch.serve.util.messages.InputParameter;\n+import org.pytorch.serve.util.messages.RequestInput;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class DagExecutor {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(DagExecutor.class);\n+\n+    private Dag dag;\n+    private Map<String, RequestInput> inputRequestMap;\n+\n+    public DagExecutor(Dag dag) {\n+        this.dag = dag;\n+        inputRequestMap = new ConcurrentHashMap<>();\n+    }\n+\n+    public ArrayList<NodeOutput> execute(RequestInput input, ArrayList<String> topoSortedList) {\n+\n+        CompletionService<NodeOutput> executorCompletionService = null;\n+        if (topoSortedList == null) {\n+            ExecutorService executorService = Executors.newFixedThreadPool(4);\n+            executorCompletionService = new ExecutorCompletionService<>(executorService);\n+        }\n+\n+        Map<String, Integer> inDegreeMap = this.dag.getInDegreeMap();\n+        Set<String> zeroInDegree = dag.getStartNodeNames();\n+        Set<String> executing = new HashSet<>();\n+\n+        if (topoSortedList == null) {\n+            for (String s : zeroInDegree) {\n+                RequestInput newInput = new RequestInput(UUID.randomUUID().toString());\n+                newInput.setHeaders(input.getHeaders());\n+                newInput.setParameters(input.getParameters());\n+                inputRequestMap.put(s, newInput);\n+            }\n+        }\n+\n+        ArrayList<NodeOutput> leafOutputs = new ArrayList<>();\n+\n+        while (!zeroInDegree.isEmpty()) {\n+            Set<String> readyToExecute = new HashSet<>(zeroInDegree);\n+            readyToExecute.removeAll(executing);\n+            executing.addAll(readyToExecute);\n+\n+            ArrayList<NodeOutput> outputs = new ArrayList<>();\n+            if (topoSortedList == null) {\n+                for (String name : readyToExecute) {\n+                    executorCompletionService.submit(\n+                            () ->\n+                                    invokeModel(\n+                                            name,\n+                                            this.dag.getNodes().get(name).getWorkflowModel(),\n+                                            inputRequestMap.get(name)));\n+                }\n+\n+                try {\n+                    outputs.add(executorCompletionService.take().get());\n+                } catch (InterruptedException | ExecutionException e) {\n+                    String[] error = e.getMessage().split(\":\");\n+                    throw new InternalServerException(error[error.length - 1]); // NOPMD\n+                }\n+            } else {\n+                for (String name : readyToExecute) {\n+                    outputs.add(new NodeOutput(name, null));\n+                }\n+            }\n+\n+            for (NodeOutput output : outputs) {\n+                String nodeName = output.getNodeName();\n+                executing.remove(nodeName);\n+                zeroInDegree.remove(nodeName);\n+\n+                if (topoSortedList != null) {\n+                    topoSortedList.add(nodeName);\n+                }\n+\n+                Set<String> childNodes = this.dag.getDagMap().get(nodeName).get(\"outDegree\");\n+                if (childNodes.isEmpty()) {\n+                    leafOutputs.add(output);\n+                } else {\n+                    for (String newNodeName : childNodes) {\n+\n+                        if (topoSortedList == null) {\n+                            byte[] response = (byte[]) output.getData();\n+\n+                            RequestInput newInput = this.inputRequestMap.get(newNodeName);\n+                            if (newInput == null) {\n+                                List<InputParameter> params = new ArrayList<>();\n+                                newInput = new RequestInput(UUID.randomUUID().toString());\n+                                if (inDegreeMap.get(newNodeName) == 1) {\n+                                    params.add(new InputParameter(\"body\", response));\n+                                } else {\n+                                    params.add(new InputParameter(nodeName, response));\n+                                }\n+                                newInput.setParameters(params);\n+                                newInput.setHeaders(input.getHeaders());\n+                            } else {\n+                                newInput.addParameter(new InputParameter(nodeName, response));\n+                            }\n+                            this.inputRequestMap.put(newNodeName, newInput);\n+                        }\n+\n+                        inDegreeMap.replace(newNodeName, inDegreeMap.get(newNodeName) - 1);\n+                        if (inDegreeMap.get(newNodeName) == 0) {\n+                            zeroInDegree.add(newNodeName);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+\n+        return leafOutputs;\n+    }\n+\n+    private NodeOutput invokeModel(String nodeName, WorkflowModel workflowModel, RequestInput input)\n+            throws ModelNotFoundException, ModelVersionNotFoundException, ExecutionException,\n+                    InterruptedException {\n+        try {\n+            CompletableFuture<byte[]> respFuture = new CompletableFuture<>();\n+\n+            RestJob job = ApiUtils.addRESTInferenceJob(null, workflowModel.getName(), null, input);\n+            job.setResponsePromise(respFuture);\n+            byte[] resp = respFuture.get();\n+            return new NodeOutput(nodeName, resp);\n+        } catch (InterruptedException | ExecutionException e) {\n+            logger.error(\"Failed to execute workflow Node.\");\n+            logger.error(nodeName + \" : \" + e.getMessage());\n+            String[] error = e.getMessage().split(\":\");\n+            throw new InternalServerException(nodeName + \" - \" + error[error.length - 1]); // NOPMD\n+        } catch (ModelNotFoundException e) {\n+            logger.error(\"Model not found.\");\n+            logger.error(e.getMessage());\n+            throw e;\n+        } catch (ModelVersionNotFoundException e) {\n+            logger.error(\"Model version not found.\");\n+            logger.error(e.getMessage());\n+            throw e;\n+        }\n+    }\n+}", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjAzMg==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302032", "bodyText": "Lombok", "author": "dhanainme", "createdAt": "2021-02-09T22:45:30Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/NodeOutput.java", "diffHunk": "@@ -0,0 +1,27 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class NodeOutput {\n+    private String nodeName;\n+    private Object data;\n+\n+    public NodeOutput(String nodeName, Object data) {\n+        this.nodeName = nodeName;\n+        this.data = data;\n+    }\n+\n+    public String getNodeName() {\n+        return nodeName;\n+    }\n+\n+    public void setNodeName(String nodeName) {\n+        this.nodeName = nodeName;\n+    }\n+\n+    public Object getData() {\n+        return data;\n+    }\n+\n+    public void setData(Object data) {\n+        this.data = data;\n+    }", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjQwMg==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302402", "bodyText": "final / lombok", "author": "dhanainme", "createdAt": "2021-02-09T22:46:12Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkflowManifest.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.pytorch.serve.ensemble;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class WorkflowManifest {\n+\n+    private String createdOn;\n+    private String description;\n+    private String archiverVersion;\n+    private RuntimeType runtime;\n+    private Workflow workflow;", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzMwMjU2NQ==", "url": "https://github.com/pytorch/serve/pull/785#discussion_r573302565", "bodyText": "final / lombok", "author": "dhanainme", "createdAt": "2021-02-09T22:46:33Z", "path": "frontend/server/src/main/java/org/pytorch/serve/ensemble/WorkflowModel.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package org.pytorch.serve.ensemble;\n+\n+public class WorkflowModel {\n+\n+    private String name;\n+    private String url;\n+    private int minWorkers;\n+    private int maxWorkers;\n+    private int batchSize;\n+    private int maxBatchDelay;\n+    private String handler;", "originalCommit": "14627541568be02cf2ba7256c53b350d7b3ee3ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ad264e6919f6d84536b25ae0c0bf2f92a618a307", "url": "https://github.com/pytorch/serve/commit/ad264e6919f6d84536b25ae0c0bf2f92a618a307", "message": "Merge branch 'master' into issue_682", "committedDate": "2021-03-04T00:08:58Z", "type": "commit"}, {"oid": "c3774d22f316dc7429368787ec3efee6ae3d4b03", "url": "https://github.com/pytorch/serve/commit/c3774d22f316dc7429368787ec3efee6ae3d4b03", "message": "fixed path in grpc client stub generation", "committedDate": "2020-11-26T14:23:44Z", "type": "commit"}, {"oid": "b7df082a4036b85095fd9a60d94067b305980242", "url": "https://github.com/pytorch/serve/commit/b7df082a4036b85095fd9a60d94067b305980242", "message": "Corrected exception handling", "committedDate": "2020-11-26T14:27:32Z", "type": "commit"}, {"oid": "5d62f22db63e9349a93a40c658bdde37b103fc9d", "url": "https://github.com/pytorch/serve/commit/5d62f22db63e9349a93a40c658bdde37b103fc9d", "message": "fixed path for grpc client", "committedDate": "2020-11-26T14:56:51Z", "type": "commit"}, {"oid": "94055831c28081e8aa9e769c0968e174ff1dd3ff", "url": "https://github.com/pytorch/serve/commit/94055831c28081e8aa9e769c0968e174ff1dd3ff", "message": "added list workflow API", "committedDate": "2020-11-27T04:22:34Z", "type": "commit"}, {"oid": "43a569fd6e42815d7e0addf54a292b0536ec5d31", "url": "https://github.com/pytorch/serve/commit/43a569fd6e42815d7e0addf54a292b0536ec5d31", "message": "resolved conflicts", "committedDate": "2020-11-27T05:18:38Z", "type": "commit"}, {"oid": "9a3925b8f84a53082948946bb895b4f2a864db41", "url": "https://github.com/pytorch/serve/commit/9a3925b8f84a53082948946bb895b4f2a864db41", "message": "added unregister API", "committedDate": "2020-11-27T05:20:56Z", "type": "commit"}, {"oid": "a350141e1a181e248804cda5c9d12f3036c3f79b", "url": "https://github.com/pytorch/serve/commit/a350141e1a181e248804cda5c9d12f3036c3f79b", "message": "conflicts", "committedDate": "2020-11-27T05:30:00Z", "type": "commit"}, {"oid": "cda415c3cf8fcd2ea97686d423a5c96e4004f4b2", "url": "https://github.com/pytorch/serve/commit/cda415c3cf8fcd2ea97686d423a5c96e4004f4b2", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682", "committedDate": "2020-11-27T05:30:06Z", "type": "commit"}, {"oid": "a158d14fd0e2b2d70f3b2ee353feefe080598eb6", "url": "https://github.com/pytorch/serve/commit/a158d14fd0e2b2d70f3b2ee353feefe080598eb6", "message": "fixed archive UTs", "committedDate": "2020-11-27T05:50:55Z", "type": "commit"}, {"oid": "e1f7938b64c366b403a640479816e9879130ba91", "url": "https://github.com/pytorch/serve/commit/e1f7938b64c366b403a640479816e9879130ba91", "message": "added missed checkin", "committedDate": "2020-11-27T05:53:40Z", "type": "commit"}, {"oid": "febbd9cf81c78c3bc90e08928d048f993292f740", "url": "https://github.com/pytorch/serve/commit/febbd9cf81c78c3bc90e08928d048f993292f740", "message": "temporarily lowered jacoco coverage criteria", "committedDate": "2020-11-27T06:02:14Z", "type": "commit"}, {"oid": "861ea2bc3d15eba1212eae6f3e625e03c49e7542", "url": "https://github.com/pytorch/serve/commit/861ea2bc3d15eba1212eae6f3e625e03c49e7542", "message": "PMD and checkstyle fixes", "committedDate": "2020-11-27T06:33:18Z", "type": "commit"}, {"oid": "a9a264d6b0dab03d52635b3650a06ab5a2831485", "url": "https://github.com/pytorch/serve/commit/a9a264d6b0dab03d52635b3650a06ab5a2831485", "message": "refactored modelarchive to archive in paths", "committedDate": "2020-11-27T06:48:35Z", "type": "commit"}, {"oid": "326fdd27640a585bc3def80c4880f0f4d1020865", "url": "https://github.com/pytorch/serve/commit/326fdd27640a585bc3def80c4880f0f4d1020865", "message": "small fixes", "committedDate": "2020-11-27T06:55:37Z", "type": "commit"}, {"oid": "f9436387db4dd76a9a70dfd2fc0b5d34a686f837", "url": "https://github.com/pytorch/serve/commit/f9436387db4dd76a9a70dfd2fc0b5d34a686f837", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java", "committedDate": "2020-11-27T06:56:33Z", "type": "commit"}, {"oid": "bf2a0b7f50da7ac6cc9e0750a78ff1ec6cd96be0", "url": "https://github.com/pytorch/serve/commit/bf2a0b7f50da7ac6cc9e0750a78ff1ec6cd96be0", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java", "committedDate": "2020-11-27T06:56:51Z", "type": "commit"}, {"oid": "b890657012231a555997ad703a14e9961ed13253", "url": "https://github.com/pytorch/serve/commit/b890657012231a555997ad703a14e9961ed13253", "message": "Suppressed unchecked cast warnings (#807)", "committedDate": "2020-11-27T07:01:16Z", "type": "commit"}, {"oid": "d8cc7b32829f0c15b946d533e813a1b7d6843f0a", "url": "https://github.com/pytorch/serve/commit/d8cc7b32829f0c15b946d533e813a1b7d6843f0a", "message": "workflow inference-1", "committedDate": "2020-11-27T07:01:21Z", "type": "commit"}, {"oid": "c7cc73f06b77d6648822e145eb25f8b910b76d04", "url": "https://github.com/pytorch/serve/commit/c7cc73f06b77d6648822e145eb25f8b910b76d04", "message": "Fix", "committedDate": "2020-11-27T07:01:57Z", "type": "commit"}, {"oid": "8a831890e8d5610af65d46bb65529c673a3e0305", "url": "https://github.com/pytorch/serve/commit/8a831890e8d5610af65d46bb65529c673a3e0305", "message": "fixed unregister and import issues", "committedDate": "2020-11-27T07:15:58Z", "type": "commit"}, {"oid": "eb4259913e3a5959b2812e6ec59f8845ff15f441", "url": "https://github.com/pytorch/serve/commit/eb4259913e3a5959b2812e6ec59f8845ff15f441", "message": "Merge branch 'issue_682' into issue_682", "committedDate": "2020-11-27T07:18:47Z", "type": "commit"}, {"oid": "2c746b1d6f599ac8888ff591f74b87575fea2af5", "url": "https://github.com/pytorch/serve/commit/2c746b1d6f599ac8888ff591f74b87575fea2af5", "message": "minor refactoring (#808)", "committedDate": "2020-11-27T07:19:34Z", "type": "commit"}, {"oid": "b70d7cb14ada2afb2eef52467f15d8ee0b67d6e7", "url": "https://github.com/pytorch/serve/commit/b70d7cb14ada2afb2eef52467f15d8ee0b67d6e7", "message": "java formatting fix", "committedDate": "2020-11-27T07:21:51Z", "type": "commit"}, {"oid": "52dd85edf3e3dfe3d69daf645623163a12fda767", "url": "https://github.com/pytorch/serve/commit/52dd85edf3e3dfe3d69daf645623163a12fda767", "message": "conflict resolution", "committedDate": "2020-11-27T07:27:56Z", "type": "commit"}, {"oid": "39d22e5395ecc0de2de82f65e87f2ddcd1999a39", "url": "https://github.com/pytorch/serve/commit/39d22e5395ecc0de2de82f65e87f2ddcd1999a39", "message": "Inference handler related enhancements", "committedDate": "2020-11-27T08:57:17Z", "type": "commit"}, {"oid": "be72815cde5a4e2a40a3279d70bd4d3643099edf", "url": "https://github.com/pytorch/serve/commit/be72815cde5a4e2a40a3279d70bd4d3643099edf", "message": "ModelServerTest fixes", "committedDate": "2020-11-27T09:32:21Z", "type": "commit"}, {"oid": "773b20a939d1dbf10534cfa5c740d566e30544bf", "url": "https://github.com/pytorch/serve/commit/773b20a939d1dbf10534cfa5c740d566e30544bf", "message": "PMD fixes", "committedDate": "2020-11-27T10:18:20Z", "type": "commit"}, {"oid": "fd67fb8b19b0a254de3e9a91286e77cb88766483", "url": "https://github.com/pytorch/serve/commit/fd67fb8b19b0a254de3e9a91286e77cb88766483", "message": "merged gRPC branch and resolved conflicts", "committedDate": "2020-11-27T12:27:30Z", "type": "commit"}, {"oid": "895189f4969bbdab2ea390599ad4912bb0432560", "url": "https://github.com/pytorch/serve/commit/895189f4969bbdab2ea390599ad4912bb0432560", "message": "Parallel register and error handling", "committedDate": "2020-11-27T16:07:38Z", "type": "commit"}, {"oid": "bdab465fe7e41f6f6ad8bff711b4d5a9f3cd072f", "url": "https://github.com/pytorch/serve/commit/bdab465fe7e41f6f6ad8bff711b4d5a9f3cd072f", "message": "Parallel register and error handling", "committedDate": "2020-11-27T16:09:08Z", "type": "commit"}, {"oid": "732ae6e413dccdd248b4045c696ad29979a721f2", "url": "https://github.com/pytorch/serve/commit/732ae6e413dccdd248b4045c696ad29979a721f2", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ModelServer.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/util/ApiUtils.java\n#\tfrontend/server/src/main/java/org/pytorch/serve/workflow/WorkflowManager.java", "committedDate": "2020-11-27T16:25:39Z", "type": "commit"}, {"oid": "7c283d38578aca5eb433b2fbd3e31544df95dd35", "url": "https://github.com/pytorch/serve/commit/7c283d38578aca5eb433b2fbd3e31544df95dd35", "message": "Merge upstream", "committedDate": "2020-11-27T16:29:28Z", "type": "commit"}, {"oid": "08f28402177a69a40fe9fbc8a3c216541b7d085c", "url": "https://github.com/pytorch/serve/commit/08f28402177a69a40fe9fbc8a3c216541b7d085c", "message": "Merge upstream", "committedDate": "2020-11-27T16:32:09Z", "type": "commit"}, {"oid": "fe102717cad2f71883435d07e66914727b5e75b3", "url": "https://github.com/pytorch/serve/commit/fe102717cad2f71883435d07e66914727b5e75b3", "message": "Add exception to status", "committedDate": "2020-11-27T16:38:25Z", "type": "commit"}, {"oid": "cabca403629cc88cfc20da8a510c88df10f065db", "url": "https://github.com/pytorch/serve/commit/cabca403629cc88cfc20da8a510c88df10f065db", "message": "Small fixes", "committedDate": "2020-11-27T16:41:04Z", "type": "commit"}, {"oid": "0ee63d14ce2bf537a08c00114d57a0440ab0638b", "url": "https://github.com/pytorch/serve/commit/0ee63d14ce2bf537a08c00114d57a0440ab0638b", "message": "Small fixes", "committedDate": "2020-11-27T16:42:22Z", "type": "commit"}, {"oid": "5d3b6195b5eea4bf01fd8c4a316c8729f7603d02", "url": "https://github.com/pytorch/serve/commit/5d3b6195b5eea4bf01fd8c4a316c8729f7603d02", "message": "Merge pull request #810 from maheshambule/issue_682\n\nIssue 682", "committedDate": "2020-11-27T16:44:36Z", "type": "commit"}, {"oid": "91615195a727ff6e8837d3db21a410ac1b1acca8", "url": "https://github.com/pytorch/serve/commit/91615195a727ff6e8837d3db21a410ac1b1acca8", "message": "refactored ModelRegistrationResult to a new message class", "committedDate": "2020-11-28T04:33:36Z", "type": "commit"}, {"oid": "1e6d1fa55b5a3a6513438e421301fb7622d47a62", "url": "https://github.com/pytorch/serve/commit/1e6d1fa55b5a3a6513438e421301fb7622d47a62", "message": "Changes for inference request", "committedDate": "2020-11-28T08:19:28Z", "type": "commit"}, {"oid": "8a7a9fc016442615afa6eb1c369a21255a696b67", "url": "https://github.com/pytorch/serve/commit/8a7a9fc016442615afa6eb1c369a21255a696b67", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682", "committedDate": "2020-11-28T08:19:34Z", "type": "commit"}, {"oid": "b136edd919f68d1e7b947599483c96e7b5c0d329", "url": "https://github.com/pytorch/serve/commit/b136edd919f68d1e7b947599483c96e7b5c0d329", "message": "End to end flow for workflow inference request", "committedDate": "2020-11-30T03:52:49Z", "type": "commit"}, {"oid": "49aea427ac55c4f13885a4a1e06b1286be06d426", "url": "https://github.com/pytorch/serve/commit/49aea427ac55c4f13885a4a1e06b1286be06d426", "message": "Fixed input for inference", "committedDate": "2020-11-30T04:12:05Z", "type": "commit"}, {"oid": "c0a332914d0ad2c95b5e76bfce171a0b105afd70", "url": "https://github.com/pytorch/serve/commit/c0a332914d0ad2c95b5e76bfce171a0b105afd70", "message": "Fixed few issues and added pipeline workflow example", "committedDate": "2020-11-30T05:51:15Z", "type": "commit"}, {"oid": "0af3a0713dc9ab5fe0d64135e1468bf25f030f7c", "url": "https://github.com/pytorch/serve/commit/0af3a0713dc9ab5fe0d64135e1468bf25f030f7c", "message": "fixed checkstyle and pmd issues", "committedDate": "2020-11-30T06:02:47Z", "type": "commit"}, {"oid": "e95aaf65d62bc781628912ef3db62cdc59a94a08", "url": "https://github.com/pytorch/serve/commit/e95aaf65d62bc781628912ef3db62cdc59a94a08", "message": "added workflow store config", "committedDate": "2020-11-30T07:57:12Z", "type": "commit"}, {"oid": "7c258f8d43a8234e1d999c7c413238ebeebb6fe7", "url": "https://github.com/pytorch/serve/commit/7c258f8d43a8234e1d999c7c413238ebeebb6fe7", "message": "fixed data passing through DAG nodes", "committedDate": "2020-11-30T07:57:36Z", "type": "commit"}, {"oid": "246e2a5f1b0399224bde7cb2ce1ed4e1a1ba9ab6", "url": "https://github.com/pytorch/serve/commit/246e2a5f1b0399224bde7cb2ce1ed4e1a1ba9ab6", "message": "fixed inference flow and updated test war file", "committedDate": "2020-11-30T09:59:01Z", "type": "commit"}, {"oid": "c1abac691d8a929884711e99abbf6232244335d8", "url": "https://github.com/pytorch/serve/commit/c1abac691d8a929884711e99abbf6232244335d8", "message": "Added workflow archive test cases", "committedDate": "2020-11-30T11:39:27Z", "type": "commit"}, {"oid": "ddf2c57cb7d981b93fa5f1719db56691f394152e", "url": "https://github.com/pytorch/serve/commit/ddf2c57cb7d981b93fa5f1719db56691f394152e", "message": "Added workflow test cases in frontend build", "committedDate": "2020-11-30T13:51:30Z", "type": "commit"}, {"oid": "6b6f704be417bc42f5cacd79ecbdf2a3373443a5", "url": "https://github.com/pytorch/serve/commit/6b6f704be417bc42f5cacd79ecbdf2a3373443a5", "message": "removed functions from list model api response", "committedDate": "2020-11-30T14:28:14Z", "type": "commit"}, {"oid": "bdd28133452a24c881f3d57cd73807605483ed87", "url": "https://github.com/pytorch/serve/commit/bdd28133452a24c881f3d57cd73807605483ed87", "message": "skipped snapshot generation for workflow models", "committedDate": "2020-11-30T15:02:22Z", "type": "commit"}, {"oid": "d934c393eea59527ab9994a67e295ca6eb131c8d", "url": "https://github.com/pytorch/serve/commit/d934c393eea59527ab9994a67e295ca6eb131c8d", "message": "fixed multiple inference issue", "committedDate": "2020-12-01T05:07:17Z", "type": "commit"}, {"oid": "075999c8271d187b78333197794e495ef5df626f", "url": "https://github.com/pytorch/serve/commit/075999c8271d187b78333197794e495ef5df626f", "message": "refactored max batch delay param", "committedDate": "2020-12-01T05:08:02Z", "type": "commit"}, {"oid": "9dc6feb98f6e51344e29cc13537b41f4fc5f57e9", "url": "https://github.com/pytorch/serve/commit/9dc6feb98f6e51344e29cc13537b41f4fc5f57e9", "message": "Async predict request handling", "committedDate": "2020-12-01T09:17:41Z", "type": "commit"}, {"oid": "27c8840e6941c59da43f7f66d5c851d84b29cb50", "url": "https://github.com/pytorch/serve/commit/27c8840e6941c59da43f7f66d5c851d84b29cb50", "message": "disabled html escaping", "committedDate": "2020-12-01T09:27:04Z", "type": "commit"}, {"oid": "c008365ce831016db499152b01999c2cdce2e0ff", "url": "https://github.com/pytorch/serve/commit/c008365ce831016db499152b01999c2cdce2e0ff", "message": "frontend build fixes", "committedDate": "2020-12-01T10:18:22Z", "type": "commit"}, {"oid": "497a6c8253973fa1c95167847f8fe75b69b9a6a8", "url": "https://github.com/pytorch/serve/commit/497a6c8253973fa1c95167847f8fe75b69b9a6a8", "message": "added support for single node dag", "committedDate": "2020-12-01T10:18:41Z", "type": "commit"}, {"oid": "881cb384a8aa4a819a4551015e9af263ab9bcf07", "url": "https://github.com/pytorch/serve/commit/881cb384a8aa4a819a4551015e9af263ab9bcf07", "message": "removed generated gRPC files", "committedDate": "2020-12-01T17:04:47Z", "type": "commit"}, {"oid": "0b7c1a3776d896a2c7541b7622dcdde1ccb60292", "url": "https://github.com/pytorch/serve/commit/0b7c1a3776d896a2c7541b7622dcdde1ccb60292", "message": "refactored workflow inference execuor", "committedDate": "2020-12-01T17:32:42Z", "type": "commit"}, {"oid": "ac33310b1bf6fb9e04a5124bd284135e9d7e7382", "url": "https://github.com/pytorch/serve/commit/ac33310b1bf6fb9e04a5124bd284135e9d7e7382", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-01T21:05:11Z", "type": "commit"}, {"oid": "0422f0933489ed42b4c896be042d79b6005dcade", "url": "https://github.com/pytorch/serve/commit/0422f0933489ed42b4c896be042d79b6005dcade", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-02T04:08:26Z", "type": "commit"}, {"oid": "8b68184561378807bb8b4b66fed9991915478b6c", "url": "https://github.com/pytorch/serve/commit/8b68184561378807bb8b4b66fed9991915478b6c", "message": "incorporated code review comments", "committedDate": "2020-12-02T06:53:43Z", "type": "commit"}, {"oid": "a1e7d23f6fd8471399d4fa7871a77b1f1fc24425", "url": "https://github.com/pytorch/serve/commit/a1e7d23f6fd8471399d4fa7871a77b1f1fc24425", "message": "added support for multi output", "committedDate": "2020-12-02T09:48:07Z", "type": "commit"}, {"oid": "2388a21a044ecea5ace440eb76a95635d71f4786", "url": "https://github.com/pytorch/serve/commit/2388a21a044ecea5ace440eb76a95635d71f4786", "message": "resolved conflicts", "committedDate": "2020-12-02T10:36:33Z", "type": "commit"}, {"oid": "385f92a84502652a3c66118d34129f354a967682", "url": "https://github.com/pytorch/serve/commit/385f92a84502652a3c66118d34129f354a967682", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682", "committedDate": "2020-12-02T10:37:08Z", "type": "commit"}, {"oid": "8239d5fb2817080a46e6d43d7e8fc5d2c039c2a9", "url": "https://github.com/pytorch/serve/commit/8239d5fb2817080a46e6d43d7e8fc5d2c039c2a9", "message": "reverted unwanted changes", "committedDate": "2020-12-02T10:42:53Z", "type": "commit"}, {"oid": "273863d2fad6453420699ff7eca36a2d7fd3922b", "url": "https://github.com/pytorch/serve/commit/273863d2fad6453420699ff7eca36a2d7fd3922b", "message": "added workflow documentation", "committedDate": "2020-12-02T16:13:01Z", "type": "commit"}, {"oid": "0d61852dd3a995332c244ed86c91826bc6d2d264", "url": "https://github.com/pytorch/serve/commit/0d61852dd3a995332c244ed86c91826bc6d2d264", "message": "added workflow-store flag in torchserve", "committedDate": "2020-12-02T16:31:20Z", "type": "commit"}, {"oid": "30e15d263479d9624f40bb365f338ad4f294cdb1", "url": "https://github.com/pytorch/serve/commit/30e15d263479d9624f40bb365f338ad4f294cdb1", "message": "Removed old scripts", "committedDate": "2020-12-02T16:57:44Z", "type": "commit"}, {"oid": "43f5d4f08471b34cd15190237a544def85e91d07", "url": "https://github.com/pytorch/serve/commit/43f5d4f08471b34cd15190237a544def85e91d07", "message": "updated known issues", "committedDate": "2020-12-02T16:58:09Z", "type": "commit"}, {"oid": "35af895b693a31d8bb11b7c29333e22f337a3935", "url": "https://github.com/pytorch/serve/commit/35af895b693a31d8bb11b7c29333e22f337a3935", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-03T02:54:38Z", "type": "commit"}, {"oid": "8779c5d752196099bebdae036426cededda31359", "url": "https://github.com/pytorch/serve/commit/8779c5d752196099bebdae036426cededda31359", "message": "Multi output support", "committedDate": "2020-12-04T16:46:51Z", "type": "commit"}, {"oid": "591f3ecbc0980b2b5f2da1ce0757c4a658e30b2a", "url": "https://github.com/pytorch/serve/commit/591f3ecbc0980b2b5f2da1ce0757c4a658e30b2a", "message": "merged master and resolved conflicts", "committedDate": "2020-12-09T03:46:10Z", "type": "commit"}, {"oid": "c17eee86df7f9dccfeabbf97d7d963aab367d5ea", "url": "https://github.com/pytorch/serve/commit/c17eee86df7f9dccfeabbf97d7d963aab367d5ea", "message": "Merge branch 'issue_656' of https://github.com/pytorch/serve into issue_656", "committedDate": "2020-12-09T03:46:27Z", "type": "commit"}, {"oid": "26cfa0a859bdce1cead7c39cc2d281e15261c2e5", "url": "https://github.com/pytorch/serve/commit/26cfa0a859bdce1cead7c39cc2d281e15261c2e5", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-09T03:56:50Z", "type": "commit"}, {"oid": "ccdd310e704afb8eb0c506f4ac3c554241acf1bf", "url": "https://github.com/pytorch/serve/commit/ccdd310e704afb8eb0c506f4ac3c554241acf1bf", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-09T06:53:58Z", "type": "commit"}, {"oid": "557f51e00d1c4fb5f319d6fddeff3abdfa6f875a", "url": "https://github.com/pytorch/serve/commit/557f51e00d1c4fb5f319d6fddeff3abdfa6f875a", "message": "fixed management api newman command", "committedDate": "2020-12-10T04:51:42Z", "type": "commit"}, {"oid": "d9bf3a7988df337b9aab074a09079ea792c88aa3", "url": "https://github.com/pytorch/serve/commit/d9bf3a7988df337b9aab074a09079ea792c88aa3", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-10T05:00:10Z", "type": "commit"}, {"oid": "4dfdecc607da0df3e48fa7ed36cd5a2329e5f1da", "url": "https://github.com/pytorch/serve/commit/4dfdecc607da0df3e48fa7ed36cd5a2329e5f1da", "message": "fixed import issues", "committedDate": "2020-12-10T05:24:40Z", "type": "commit"}, {"oid": "b21a174de3fa8971137a763cdc6be02267a851ae", "url": "https://github.com/pytorch/serve/commit/b21a174de3fa8971137a763cdc6be02267a851ae", "message": "fixed regression pytest issues", "committedDate": "2020-12-10T05:24:56Z", "type": "commit"}, {"oid": "5e015f40dd628eacf5a94e2fbbccd8aa96b434d6", "url": "https://github.com/pytorch/serve/commit/5e015f40dd628eacf5a94e2fbbccd8aa96b434d6", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-12-10T16:56:53Z", "type": "commit"}, {"oid": "72afd136062d744e6feddb74c973cd7c1ad0da71", "url": "https://github.com/pytorch/serve/commit/72afd136062d744e6feddb74c973cd7c1ad0da71", "message": "resolved conflicts", "committedDate": "2020-12-16T11:59:42Z", "type": "commit"}, {"oid": "b5ff103b62b77e266f025a1d3bff9520f0804bb6", "url": "https://github.com/pytorch/serve/commit/b5ff103b62b77e266f025a1d3bff9520f0804bb6", "message": "Merge branch 'master' into workflow_archiver", "committedDate": "2020-12-16T12:28:18Z", "type": "commit"}, {"oid": "2c370a99a254192587d9b7f9bd47fa18d3c24c72", "url": "https://github.com/pytorch/serve/commit/2c370a99a254192587d9b7f9bd47fa18d3c24c72", "message": "minor doc fixes", "committedDate": "2020-12-16T12:31:07Z", "type": "commit"}, {"oid": "bd8125da1868d14cdb0b4a0104b2b2de2b61b108", "url": "https://github.com/pytorch/serve/commit/bd8125da1868d14cdb0b4a0104b2b2de2b61b108", "message": "Merge branch 'issue_656' into issue_682", "committedDate": "2020-12-16T12:33:33Z", "type": "commit"}, {"oid": "c76136aa4245d042e6ebfd547e7c0a7a22569a9d", "url": "https://github.com/pytorch/serve/commit/c76136aa4245d042e6ebfd547e7c0a7a22569a9d", "message": "fixed test cases for windows", "committedDate": "2020-12-16T12:54:14Z", "type": "commit"}, {"oid": "73d6400b4f8c9ffc842480c013a645bf5528564a", "url": "https://github.com/pytorch/serve/commit/73d6400b4f8c9ffc842480c013a645bf5528564a", "message": "refactored file location", "committedDate": "2020-12-16T12:58:53Z", "type": "commit"}, {"oid": "8d4e82970f0e2ad8e4b5577d5fea1a2b7c29f3c1", "url": "https://github.com/pytorch/serve/commit/8d4e82970f0e2ad8e4b5577d5fea1a2b7c29f3c1", "message": "fixed typo", "committedDate": "2020-12-16T13:13:55Z", "type": "commit"}, {"oid": "077fe91412a58ef7a49f4bed63bf2675a972be25", "url": "https://github.com/pytorch/serve/commit/077fe91412a58ef7a49f4bed63bf2675a972be25", "message": "merged master and resloved conflicts", "committedDate": "2020-12-16T13:57:14Z", "type": "commit"}, {"oid": "d130f38aeb016d9184d9623b540293c5c25cc6bd", "url": "https://github.com/pytorch/serve/commit/d130f38aeb016d9184d9623b540293c5c25cc6bd", "message": "doc updates and test case fix", "committedDate": "2020-12-16T14:13:03Z", "type": "commit"}, {"oid": "04b40ed750fac689f909c4c0cb6d6bdd1d4ad568", "url": "https://github.com/pytorch/serve/commit/04b40ed750fac689f909c4c0cb6d6bdd1d4ad568", "message": "test case fixes", "committedDate": "2020-12-16T15:03:03Z", "type": "commit"}, {"oid": "367af7b148e40e2fbf570ba89bbc30e19edad125", "url": "https://github.com/pytorch/serve/commit/367af7b148e40e2fbf570ba89bbc30e19edad125", "message": "ModelArchiveTest fix for windows", "committedDate": "2020-12-16T15:07:47Z", "type": "commit"}, {"oid": "957a51673aa5cac688a6f00e4e6ceb1177355cbc", "url": "https://github.com/pytorch/serve/commit/957a51673aa5cac688a6f00e4e6ceb1177355cbc", "message": "Merge branch 'master' into issue_682", "committedDate": "2020-12-22T05:23:28Z", "type": "commit"}, {"oid": "11440ddca81232289e028141994edd40e1738cf5", "url": "https://github.com/pytorch/serve/commit/11440ddca81232289e028141994edd40e1738cf5", "message": "merged workflow archiver", "committedDate": "2020-12-22T06:06:05Z", "type": "commit"}, {"oid": "e4350b8bb9384b3aa90436f2030d518dc9bb2ca2", "url": "https://github.com/pytorch/serve/commit/e4350b8bb9384b3aa90436f2030d518dc9bb2ca2", "message": "fixed workflow archiver test case", "committedDate": "2020-12-22T06:33:04Z", "type": "commit"}, {"oid": "cc4634e15ddf35c27b9a2a3de6331e42a8dfe5b1", "url": "https://github.com/pytorch/serve/commit/cc4634e15ddf35c27b9a2a3de6331e42a8dfe5b1", "message": "refactored workflow test cases to a new file", "committedDate": "2020-12-24T05:23:25Z", "type": "commit"}, {"oid": "31fefab8bbe9aacde34e93e5183ebaf6fb4a1b0d", "url": "https://github.com/pytorch/serve/commit/31fefab8bbe9aacde34e93e5183ebaf6fb4a1b0d", "message": "added workflow example", "committedDate": "2020-12-24T06:20:55Z", "type": "commit"}, {"oid": "0b7e71a2db54437a5ef1497ea4d5f947bf5e2525", "url": "https://github.com/pytorch/serve/commit/0b7e71a2db54437a5ef1497ea4d5f947bf5e2525", "message": "fixed test case ordering", "committedDate": "2020-12-24T06:57:07Z", "type": "commit"}, {"oid": "5d66a40c9f5c531d1a7ac649c7396b29233e8282", "url": "https://github.com/pytorch/serve/commit/5d66a40c9f5c531d1a7ac649c7396b29233e8282", "message": "fixed load model from URI for windows", "committedDate": "2020-12-24T07:31:36Z", "type": "commit"}, {"oid": "3fe0a60932945daeeee05f8348ee63365ac6f99d", "url": "https://github.com/pytorch/serve/commit/3fe0a60932945daeeee05f8348ee63365ac6f99d", "message": "minor refactoring and cleanup", "committedDate": "2020-12-24T07:42:07Z", "type": "commit"}, {"oid": "21427156af58767dea527e1e15b557c9fc4c6816", "url": "https://github.com/pytorch/serve/commit/21427156af58767dea527e1e15b557c9fc4c6816", "message": "refactored torchserve job", "committedDate": "2020-09-17T17:19:21Z", "type": "commit"}, {"oid": "77b135601e8052efeaf3895766a274129dca874d", "url": "https://github.com/pytorch/serve/commit/77b135601e8052efeaf3895766a274129dca874d", "message": "added grpc server side implementation", "committedDate": "2020-09-17T17:21:11Z", "type": "commit"}, {"oid": "b75b81a07d4879f4e84f7a7ef3e21027f3e69125", "url": "https://github.com/pytorch/serve/commit/b75b81a07d4879f4e84f7a7ef3e21027f3e69125", "message": "added protobuff files", "committedDate": "2020-09-17T17:22:27Z", "type": "commit"}, {"oid": "d46d56a9537c13bf23771292650c550b135ed482", "url": "https://github.com/pytorch/serve/commit/d46d56a9537c13bf23771292650c550b135ed482", "message": "added grpc server startup", "committedDate": "2020-09-17T17:24:39Z", "type": "commit"}, {"oid": "fec11bfef5e9877639a5eb2cf02d17f3a1251072", "url": "https://github.com/pytorch/serve/commit/fec11bfef5e9877639a5eb2cf02d17f3a1251072", "message": "fixed valid port test case", "committedDate": "2020-09-17T17:25:02Z", "type": "commit"}, {"oid": "22734badb2627f8be501225fb6ab748221a9f31e", "url": "https://github.com/pytorch/serve/commit/22734badb2627f8be501225fb6ab748221a9f31e", "message": "automated server stub generation through gradle", "committedDate": "2020-09-17T17:27:13Z", "type": "commit"}, {"oid": "14cb1eb338b14079df737e35dc1e88b057e49de9", "url": "https://github.com/pytorch/serve/commit/14cb1eb338b14079df737e35dc1e88b057e49de9", "message": "enhanced sanity script to validate grpc inference api", "committedDate": "2020-09-17T17:30:30Z", "type": "commit"}, {"oid": "199811c627df6a19584bb324b8c533065c2ab51d", "url": "https://github.com/pytorch/serve/commit/199811c627df6a19584bb324b8c533065c2ab51d", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-09-17T17:32:21Z", "type": "commit"}, {"oid": "151cdcc39f422f64d600b2eaf8b4a2cc9aaa51bd", "url": "https://github.com/pytorch/serve/commit/151cdcc39f422f64d600b2eaf8b4a2cc9aaa51bd", "message": "Added grpcio-tools package", "committedDate": "2020-09-17T18:00:24Z", "type": "commit"}, {"oid": "d1abb5cb2b8575448a4e99c36eb849bf3fb14157", "url": "https://github.com/pytorch/serve/commit/d1abb5cb2b8575448a4e99c36eb849bf3fb14157", "message": "fixed path issue in grpc client", "committedDate": "2020-09-17T18:14:45Z", "type": "commit"}, {"oid": "48b049c3befb3c3c357a1fce92636c1bbb046211", "url": "https://github.com/pytorch/serve/commit/48b049c3befb3c3c357a1fce92636c1bbb046211", "message": "fixed incorrect exit logic in client script", "committedDate": "2020-09-17T18:27:16Z", "type": "commit"}, {"oid": "897d5d7a226f12f9dbda509db620e9d03b0f2f55", "url": "https://github.com/pytorch/serve/commit/897d5d7a226f12f9dbda509db620e9d03b0f2f55", "message": "removed json parse in python gRPC client", "committedDate": "2020-09-18T01:48:44Z", "type": "commit"}, {"oid": "0ffc689c85b2d9af523c4309f0dbb516ed3f437c", "url": "https://github.com/pytorch/serve/commit/0ffc689c85b2d9af523c4309f0dbb516ed3f437c", "message": "removed unnecessary file checkin", "committedDate": "2020-09-18T05:02:03Z", "type": "commit"}, {"oid": "3770272cbc46f99f48d7970e4869cd87a26fde5e", "url": "https://github.com/pytorch/serve/commit/3770272cbc46f99f48d7970e4869cd87a26fde5e", "message": "added regression test cases for gRPC regression APIs", "committedDate": "2020-09-18T07:16:51Z", "type": "commit"}, {"oid": "585c03f75f571f9c40766f249e20ce40082865e0", "url": "https://github.com/pytorch/serve/commit/585c03f75f571f9c40766f249e20ce40082865e0", "message": "added tolerance check", "committedDate": "2020-09-18T07:55:32Z", "type": "commit"}, {"oid": "79dd23b6ce8d1c17e42e7d59b2de3175030c3931", "url": "https://github.com/pytorch/serve/commit/79dd23b6ce8d1c17e42e7d59b2de3175030c3931", "message": "added python client stub cleanup", "committedDate": "2020-09-18T09:41:50Z", "type": "commit"}, {"oid": "7037e6cc2c8a5e0af020983f2f318de57fc4a6b5", "url": "https://github.com/pytorch/serve/commit/7037e6cc2c8a5e0af020983f2f318de57fc4a6b5", "message": "enhanced error handling for inference APIs", "committedDate": "2020-09-22T03:34:17Z", "type": "commit"}, {"oid": "5a4a69a5bbcd5001b65831ad0ded1910cfceec20", "url": "https://github.com/pytorch/serve/commit/5a4a69a5bbcd5001b65831ad0ded1910cfceec20", "message": "removed unused utility file", "committedDate": "2020-09-22T03:42:54Z", "type": "commit"}, {"oid": "438683e9df08f9c800929deef8d03fd37e24b703", "url": "https://github.com/pytorch/serve/commit/438683e9df08f9c800929deef8d03fd37e24b703", "message": "added support for datafile driven management api test collection", "committedDate": "2020-09-24T08:58:22Z", "type": "commit"}, {"oid": "90bfde4c5ea0d60600105933f7d852827182b0f8", "url": "https://github.com/pytorch/serve/commit/90bfde4c5ea0d60600105933f7d852827182b0f8", "message": "added gRPC support for management APIs", "committedDate": "2020-09-28T05:44:58Z", "type": "commit"}, {"oid": "7e3ccaaf17a5d8c9e97870c8d3c3b919f8ade848", "url": "https://github.com/pytorch/serve/commit/7e3ccaaf17a5d8c9e97870c8d3c3b919f8ade848", "message": "added minor fixes found during testing", "committedDate": "2020-09-28T07:22:12Z", "type": "commit"}, {"oid": "ee0f0579f1ddbe1559fd8f0ce59135b137b69a83", "url": "https://github.com/pytorch/serve/commit/ee0f0579f1ddbe1559fd8f0ce59135b137b69a83", "message": "enhanced grpc pytest suite to use grpc client for registering and unregistering model", "committedDate": "2020-09-28T11:44:27Z", "type": "commit"}, {"oid": "78533c249cc89785f00b511ac1a5294ddb5132e4", "url": "https://github.com/pytorch/serve/commit/78533c249cc89785f00b511ac1a5294ddb5132e4", "message": "updated command to generate python client stubs", "committedDate": "2020-09-28T11:45:32Z", "type": "commit"}, {"oid": "dfbffa36c7fddfe400a768b6531b4099639feb74", "url": "https://github.com/pytorch/serve/commit/dfbffa36c7fddfe400a768b6531b4099639feb74", "message": "removed netty http staus dependency from wlm framework", "committedDate": "2020-09-28T11:46:07Z", "type": "commit"}, {"oid": "2a529cdf55ee47a5593b8ab6ce8036ce8843c766", "url": "https://github.com/pytorch/serve/commit/2a529cdf55ee47a5593b8ab6ce8036ce8843c766", "message": "refacroted common code to utility module", "committedDate": "2020-09-28T12:13:17Z", "type": "commit"}, {"oid": "6b70abaf794eba2bc6326d921dedcb4e12a10c67", "url": "https://github.com/pytorch/serve/commit/6b70abaf794eba2bc6326d921dedcb4e12a10c67", "message": "added gRPC management api test cases in regression suite and minor fixes", "committedDate": "2020-09-28T18:23:08Z", "type": "commit"}, {"oid": "747e5068ee7009c1c733673de4c73ce1e3859a7c", "url": "https://github.com/pytorch/serve/commit/747e5068ee7009c1c733673de4c73ce1e3859a7c", "message": "added ping api", "committedDate": "2020-09-29T11:30:26Z", "type": "commit"}, {"oid": "8413651bfa100ccea09528535a4a32ec24764ba0", "url": "https://github.com/pytorch/serve/commit/8413651bfa100ccea09528535a4a32ec24764ba0", "message": "removed grpc metric api", "committedDate": "2020-09-29T11:31:36Z", "type": "commit"}, {"oid": "328bb4e7e022bb22eace1a71218743746a94749c", "url": "https://github.com/pytorch/serve/commit/328bb4e7e022bb22eace1a71218743746a94749c", "message": "added ssl support for gRPC server", "committedDate": "2020-09-29T14:50:46Z", "type": "commit"}, {"oid": "0c1795dc84065cbc908119e09e8b5a87d9bc3edb", "url": "https://github.com/pytorch/serve/commit/0c1795dc84065cbc908119e09e8b5a87d9bc3edb", "message": "added documentation", "committedDate": "2020-09-29T15:58:20Z", "type": "commit"}, {"oid": "ff2517544e8346ca602367c4820b27f6c675b3b9", "url": "https://github.com/pytorch/serve/commit/ff2517544e8346ca602367c4820b27f6c675b3b9", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-09-30T05:39:42Z", "type": "commit"}, {"oid": "1822ae336ecc25c70ef6b25a5155cfa09844438b", "url": "https://github.com/pytorch/serve/commit/1822ae336ecc25c70ef6b25a5155cfa09844438b", "message": "fixed issue after conflict resolution", "committedDate": "2020-09-30T06:36:40Z", "type": "commit"}, {"oid": "039f48c411b0758cd2035ba8c7831a9d43441554", "url": "https://github.com/pytorch/serve/commit/039f48c411b0758cd2035ba8c7831a9d43441554", "message": "added reference to python gRPC client, used in regression suite, in grpc doc", "committedDate": "2020-09-30T08:57:45Z", "type": "commit"}, {"oid": "126532e559d26dc4a976748e76290079ed207112", "url": "https://github.com/pytorch/serve/commit/126532e559d26dc4a976748e76290079ed207112", "message": "added validation for register and unregister model in sanity script", "committedDate": "2020-09-30T13:36:22Z", "type": "commit"}, {"oid": "ca76ede3b93380502f765da61aa19769164fd25b", "url": "https://github.com/pytorch/serve/commit/ca76ede3b93380502f765da61aa19769164fd25b", "message": "updated docs", "committedDate": "2020-09-30T13:36:37Z", "type": "commit"}, {"oid": "6eb737f35c9d7281aa9404743210b489a0747700", "url": "https://github.com/pytorch/serve/commit/6eb737f35c9d7281aa9404743210b489a0747700", "message": "minor fixes in grpc doc", "committedDate": "2020-09-30T14:41:49Z", "type": "commit"}, {"oid": "d27495cda48b568da8ecc10c7f907d6b0894791a", "url": "https://github.com/pytorch/serve/commit/d27495cda48b568da8ecc10c7f907d6b0894791a", "message": "updated gRPC server await termination code", "committedDate": "2020-09-30T17:09:42Z", "type": "commit"}, {"oid": "0b7eabfe6274730682707f98c564c6f87687360c", "url": "https://github.com/pytorch/serve/commit/0b7eabfe6274730682707f98c564c6f87687360c", "message": "refactored gRPC server startup code", "committedDate": "2020-09-30T17:24:31Z", "type": "commit"}, {"oid": "15322c6659a98b3f545f0d3339e400e4b163b63c", "url": "https://github.com/pytorch/serve/commit/15322c6659a98b3f545f0d3339e400e4b163b63c", "message": "added null check before terminating gRPC servers", "committedDate": "2020-09-30T18:08:39Z", "type": "commit"}, {"oid": "590fca846bc97fd1d16663ec4584bf57bb49d175", "url": "https://github.com/pytorch/serve/commit/590fca846bc97fd1d16663ec4584bf57bb49d175", "message": "minor refactoring of method name", "committedDate": "2020-10-01T12:44:49Z", "type": "commit"}, {"oid": "5b3a6b5847d6272520af7eae3b49bfba211b41ce", "url": "https://github.com/pytorch/serve/commit/5b3a6b5847d6272520af7eae3b49bfba211b41ce", "message": "skipped grpc package from jacoco verification", "committedDate": "2020-10-01T12:45:24Z", "type": "commit"}, {"oid": "63aa51ab276c76c55fb0ffc91b1aec1542412ee3", "url": "https://github.com/pytorch/serve/commit/63aa51ab276c76c55fb0ffc91b1aec1542412ee3", "message": "Fixed typo in doc", "committedDate": "2020-10-12T13:07:05Z", "type": "commit"}, {"oid": "461395bc1f624ef8f240c14d3e5931608deb83f7", "url": "https://github.com/pytorch/serve/commit/461395bc1f624ef8f240c14d3e5931608deb83f7", "message": "added error logs in gRPC client", "committedDate": "2020-10-12T13:07:37Z", "type": "commit"}, {"oid": "653276e09b8097f58c15c88203362292b61d8030", "url": "https://github.com/pytorch/serve/commit/653276e09b8097f58c15c88203362292b61d8030", "message": "added gRPC server interceptor to log api access data", "committedDate": "2020-10-12T13:09:47Z", "type": "commit"}, {"oid": "f1a62279c9c9d94041aac0150dbe60adfc690df2", "url": "https://github.com/pytorch/serve/commit/f1a62279c9c9d94041aac0150dbe60adfc690df2", "message": "added checkstyle fixes", "committedDate": "2020-10-12T13:44:56Z", "type": "commit"}, {"oid": "e78dbff1edff59a1222fb79e8e6856603ca4ff1d", "url": "https://github.com/pytorch/serve/commit/e78dbff1edff59a1222fb79e8e6856603ca4ff1d", "message": "fixed grpc command in readme", "committedDate": "2020-10-13T09:22:54Z", "type": "commit"}, {"oid": "3bb125a4374fd47552d74e306876ee34fc5956f2", "url": "https://github.com/pytorch/serve/commit/3bb125a4374fd47552d74e306876ee34fc5956f2", "message": "refactored test cases to removed code duplication", "committedDate": "2020-10-14T03:31:33Z", "type": "commit"}, {"oid": "4fa484a21838e7157fe3705b0215d3aa5d2bcdfe", "url": "https://github.com/pytorch/serve/commit/4fa484a21838e7157fe3705b0215d3aa5d2bcdfe", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-10-14T03:32:42Z", "type": "commit"}, {"oid": "2b867a0da6d1896166692e15b12991546cbd6968", "url": "https://github.com/pytorch/serve/commit/2b867a0da6d1896166692e15b12991546cbd6968", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-10-14T09:51:18Z", "type": "commit"}, {"oid": "3d7b0b9add224eee1017ca4ba0b13ba583ed5a65", "url": "https://github.com/pytorch/serve/commit/3d7b0b9add224eee1017ca4ba0b13ba583ed5a65", "message": "Fixed typo in link.\n\nCo-authored-by: Amit Agarwal <amtagrwl@gmail.com>", "committedDate": "2020-10-17T02:03:47Z", "type": "commit"}, {"oid": "8dac80c5b3279d323535da0d8694f6ac30e1b9a8", "url": "https://github.com/pytorch/serve/commit/8dac80c5b3279d323535da0d8694f6ac30e1b9a8", "message": "merge master", "committedDate": "2020-10-27T06:06:40Z", "type": "commit"}, {"oid": "700defce59120529158478d0841fbc54dab4c6d8", "url": "https://github.com/pytorch/serve/commit/700defce59120529158478d0841fbc54dab4c6d8", "message": "fixed compilation issues after conflict resolution", "committedDate": "2020-10-27T06:27:24Z", "type": "commit"}, {"oid": "dc8e410e4b1ff891f361a970ea609947324ecc0d", "url": "https://github.com/pytorch/serve/commit/dc8e410e4b1ff891f361a970ea609947324ecc0d", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-10-30T10:49:28Z", "type": "commit"}, {"oid": "7fb3d8ffc1bdba064a261a58994f06d013827954", "url": "https://github.com/pytorch/serve/commit/7fb3d8ffc1bdba064a261a58994f06d013827954", "message": "Ensemble DAG and Scheduling", "committedDate": "2020-10-30T13:25:16Z", "type": "commit"}, {"oid": "01bedc868f5f742416fe241553a140ed254973cf", "url": "https://github.com/pytorch/serve/commit/01bedc868f5f742416fe241553a140ed254973cf", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-05T04:45:28Z", "type": "commit"}, {"oid": "22d1b06b1b81f2f66efdf4191f4a26fea215c862", "url": "https://github.com/pytorch/serve/commit/22d1b06b1b81f2f66efdf4191f4a26fea215c862", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-06T03:05:32Z", "type": "commit"}, {"oid": "f5818ca248cf25b45134415c59536f6ab4326aef", "url": "https://github.com/pytorch/serve/commit/f5818ca248cf25b45134415c59536f6ab4326aef", "message": "fixed regression suite pytest issue", "committedDate": "2020-11-06T04:27:18Z", "type": "commit"}, {"oid": "410ce11a62f8fbe331298bd4bc62299fb8caab45", "url": "https://github.com/pytorch/serve/commit/410ce11a62f8fbe331298bd4bc62299fb8caab45", "message": "fixed pytest case", "committedDate": "2020-11-06T05:06:40Z", "type": "commit"}, {"oid": "1bd835d7c5e1c3ecc384e7a44e7ef0a71dabf570", "url": "https://github.com/pytorch/serve/commit/1bd835d7c5e1c3ecc384e7a44e7ef0a71dabf570", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-09T18:18:07Z", "type": "commit"}, {"oid": "d28264655f4e3f779a1f3e7370a8344b508c2e1b", "url": "https://github.com/pytorch/serve/commit/d28264655f4e3f779a1f3e7370a8344b508c2e1b", "message": "add tests", "committedDate": "2020-11-11T08:52:22Z", "type": "commit"}, {"oid": "87575f6b4cfc6155549ec10cb8158a0e84b43413", "url": "https://github.com/pytorch/serve/commit/87575f6b4cfc6155549ec10cb8158a0e84b43413", "message": "workflow archiver", "committedDate": "2020-11-11T17:38:13Z", "type": "commit"}, {"oid": "bbaeafaff1be364bd4d1509b96356c8473af80b6", "url": "https://github.com/pytorch/serve/commit/bbaeafaff1be364bd4d1509b96356c8473af80b6", "message": "removed pytest report dir", "committedDate": "2020-11-11T17:39:32Z", "type": "commit"}, {"oid": "99df5166d8f165981d642792c5ba2d954b6cda76", "url": "https://github.com/pytorch/serve/commit/99df5166d8f165981d642792c5ba2d954b6cda76", "message": "added workflow test cases to sanity suite", "committedDate": "2020-11-12T03:59:37Z", "type": "commit"}, {"oid": "58172914f0fcb632f472529f73f4cb73dafb751d", "url": "https://github.com/pytorch/serve/commit/58172914f0fcb632f472529f73f4cb73dafb751d", "message": "Added coveragerc", "committedDate": "2020-11-12T04:37:09Z", "type": "commit"}, {"oid": "fff09b3315ee299e83db8802129738ef281efbae", "url": "https://github.com/pytorch/serve/commit/fff09b3315ee299e83db8802129738ef281efbae", "message": "removed unwanted init files", "committedDate": "2020-11-12T05:09:40Z", "type": "commit"}, {"oid": "b9fc96730f6a2d54d2c73f74551861d45ff44cae", "url": "https://github.com/pytorch/serve/commit/b9fc96730f6a2d54d2c73f74551861d45ff44cae", "message": "workflow rest apis", "committedDate": "2020-11-17T12:10:10Z", "type": "commit"}, {"oid": "52288b4a3d227beba9117395bb96fc781cfe5569", "url": "https://github.com/pytorch/serve/commit/52288b4a3d227beba9117395bb96fc781cfe5569", "message": "Merged issue_656", "committedDate": "2020-11-17T12:16:13Z", "type": "commit"}, {"oid": "c70138d0b9b237055f98e9ed717daf6269e1ed4e", "url": "https://github.com/pytorch/serve/commit/c70138d0b9b237055f98e9ed717daf6269e1ed4e", "message": "Merge branch 'workflow_archiver' into issue_682", "committedDate": "2020-11-17T12:27:18Z", "type": "commit"}, {"oid": "3e44a793397572f264cc4c5963b941e4722031b3", "url": "https://github.com/pytorch/serve/commit/3e44a793397572f264cc4c5963b941e4722031b3", "message": "added dummy workflow manager", "committedDate": "2020-11-18T09:24:09Z", "type": "commit"}, {"oid": "0d7991e0ba963a8e45810eb023dbcc9d187dfb1d", "url": "https://github.com/pytorch/serve/commit/0d7991e0ba963a8e45810eb023dbcc9d187dfb1d", "message": "yaml read", "committedDate": "2020-11-18T09:24:23Z", "type": "commit"}, {"oid": "a32da3131cfae956204f3c85013b930992cfab85", "url": "https://github.com/pytorch/serve/commit/a32da3131cfae956204f3c85013b930992cfab85", "message": "change", "committedDate": "2020-11-18T09:34:49Z", "type": "commit"}, {"oid": "f4a4147904d5d95360d507575380628f9531b855", "url": "https://github.com/pytorch/serve/commit/f4a4147904d5d95360d507575380628f9531b855", "message": "Merge branch 'issue_682' into issue_682", "committedDate": "2020-11-18T09:41:31Z", "type": "commit"}, {"oid": "46a0d8488b696568e0cae27796adab88f6be683c", "url": "https://github.com/pytorch/serve/commit/46a0d8488b696568e0cae27796adab88f6be683c", "message": "Merge pull request #786 from maheshambule/issue_682\n\nEnsemble support", "committedDate": "2020-11-18T09:42:19Z", "type": "commit"}, {"oid": "7aa38ddf7363aac9f71138c83fdfb48b05255c07", "url": "https://github.com/pytorch/serve/commit/7aa38ddf7363aac9f71138c83fdfb48b05255c07", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-19T00:36:48Z", "type": "commit"}, {"oid": "0b3ba4c9e16b13bea9969fabed9120648de1c350", "url": "https://github.com/pytorch/serve/commit/0b3ba4c9e16b13bea9969fabed9120648de1c350", "message": "model registration", "committedDate": "2020-11-19T01:42:37Z", "type": "commit"}, {"oid": "23f92b60154c0e6955af5a0fc526bbd43609cd77", "url": "https://github.com/pytorch/serve/commit/23f92b60154c0e6955af5a0fc526bbd43609cd77", "message": "add response", "committedDate": "2020-11-19T01:52:33Z", "type": "commit"}, {"oid": "ab379aa191bffb7f17602af5c4d05270d53b6c7a", "url": "https://github.com/pytorch/serve/commit/ab379aa191bffb7f17602af5c4d05270d53b6c7a", "message": "Merge pull request #788 from maheshambule/issue_682\n\nmodel registration", "committedDate": "2020-11-23T05:00:28Z", "type": "commit"}, {"oid": "c6171666dbea4599055760b83ef156cad2ed075a", "url": "https://github.com/pytorch/serve/commit/c6171666dbea4599055760b83ef156cad2ed075a", "message": "merged master and resolved conflicts", "committedDate": "2020-11-23T06:33:29Z", "type": "commit"}, {"oid": "a8f3f7f9cdc53b640ae584a3b589806f6d2a26e8", "url": "https://github.com/pytorch/serve/commit/a8f3f7f9cdc53b640ae584a3b589806f6d2a26e8", "message": "fixed import", "committedDate": "2020-11-23T06:55:08Z", "type": "commit"}, {"oid": "c2c48a0a9239b27c47ea262c0d52038ef35e8c13", "url": "https://github.com/pytorch/serve/commit/c2c48a0a9239b27c47ea262c0d52038ef35e8c13", "message": "fixed sanity suite", "committedDate": "2020-11-23T07:58:08Z", "type": "commit"}, {"oid": "54c63a5264f2d73325eae78f59e745c40a99a7a7", "url": "https://github.com/pytorch/serve/commit/54c63a5264f2d73325eae78f59e745c40a99a7a7", "message": "Updates for register API", "committedDate": "2020-11-23T10:46:42Z", "type": "commit"}, {"oid": "1e83517af4856b468256f30f14be03541d68bcd9", "url": "https://github.com/pytorch/serve/commit/1e83517af4856b468256f30f14be03541d68bcd9", "message": "register api changes and formating", "committedDate": "2020-11-23T11:41:48Z", "type": "commit"}, {"oid": "2603a7db9cef908f4d942a87f597badf686861a7", "url": "https://github.com/pytorch/serve/commit/2603a7db9cef908f4d942a87f597badf686861a7", "message": "added workflow archiver in frontend", "committedDate": "2020-11-23T15:33:25Z", "type": "commit"}, {"oid": "5a90674f5d222e5a2cfc9a0b4e6329b5380aa528", "url": "https://github.com/pytorch/serve/commit/5a90674f5d222e5a2cfc9a0b4e6329b5380aa528", "message": "add", "committedDate": "2020-11-23T15:53:31Z", "type": "commit"}, {"oid": "0444dbbc38107e29055970b52fd763a6371ef3f0", "url": "https://github.com/pytorch/serve/commit/0444dbbc38107e29055970b52fd763a6371ef3f0", "message": "register refactor", "committedDate": "2020-11-23T16:49:24Z", "type": "commit"}, {"oid": "e0c82f7588da6662650575488939927977975aaf", "url": "https://github.com/pytorch/serve/commit/e0c82f7588da6662650575488939927977975aaf", "message": "refactored workflow registration api", "committedDate": "2020-11-24T15:39:57Z", "type": "commit"}, {"oid": "04662907a5e972eb7123436f243169d00a8aca05", "url": "https://github.com/pytorch/serve/commit/04662907a5e972eb7123436f243169d00a8aca05", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-24T20:53:57Z", "type": "commit"}, {"oid": "ab7be17b43621435568f1ed349c194ea91d73116", "url": "https://github.com/pytorch/serve/commit/ab7be17b43621435568f1ed349c194ea91d73116", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-24T21:37:57Z", "type": "commit"}, {"oid": "5cf2af045df267234fadd893acad31cf134c56b5", "url": "https://github.com/pytorch/serve/commit/5cf2af045df267234fadd893acad31cf134c56b5", "message": "Merge branch 'master' into issue_656", "committedDate": "2020-11-25T07:35:52Z", "type": "commit"}, {"oid": "8f9f978d65a2036f2c3b18bd547a3cae0b283139", "url": "https://github.com/pytorch/serve/commit/8f9f978d65a2036f2c3b18bd547a3cae0b283139", "message": "Resolve conflicts and Function mar changes", "committedDate": "2020-11-26T07:30:16Z", "type": "commit"}, {"oid": "bc149cf3b05c1f9a297b391a6dd82d2b5ab83578", "url": "https://github.com/pytorch/serve/commit/bc149cf3b05c1f9a297b391a6dd82d2b5ab83578", "message": "added support for pre and post process functions in workflow (#795)", "committedDate": "2020-11-26T08:33:32Z", "type": "commit"}, {"oid": "4722928effef4c8ec5c4a01e8db7c04c771b5cc3", "url": "https://github.com/pytorch/serve/commit/4722928effef4c8ec5c4a01e8db7c04c771b5cc3", "message": " refactored workflow message classes to new package", "committedDate": "2020-11-26T08:48:15Z", "type": "commit"}, {"oid": "c9c682775281aa4657125641a79f28e2b5008e93", "url": "https://github.com/pytorch/serve/commit/c9c682775281aa4657125641a79f28e2b5008e93", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java", "committedDate": "2020-11-26T09:03:28Z", "type": "commit"}, {"oid": "8fb2209f717136edd51749d17550cce4d84b8cd8", "url": "https://github.com/pytorch/serve/commit/8fb2209f717136edd51749d17550cce4d84b8cd8", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java", "committedDate": "2020-11-26T11:30:56Z", "type": "commit"}, {"oid": "733b9797e5605457ac3d82091c84a09beadf0007", "url": "https://github.com/pytorch/serve/commit/733b9797e5605457ac3d82091c84a09beadf0007", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682\n\n# Conflicts:\n#\tfrontend/server/src/main/java/org/pytorch/serve/ensemble/WorkFlow.java\n#\tfrontend/server/src/test/java/org/pytorch/serve/EnsembleTest.java", "committedDate": "2020-11-26T11:31:13Z", "type": "commit"}, {"oid": "decc037bc07974c0a925670e80b49c5ef45fc561", "url": "https://github.com/pytorch/serve/commit/decc037bc07974c0a925670e80b49c5ef45fc561", "message": "added describe workflow api", "committedDate": "2020-11-26T13:35:22Z", "type": "commit"}, {"oid": "f3a0ef8af8ec9c23602ee39ad7d638007e0d2268", "url": "https://github.com/pytorch/serve/commit/f3a0ef8af8ec9c23602ee39ad7d638007e0d2268", "message": "fixed java formatting", "committedDate": "2020-11-26T13:36:44Z", "type": "commit"}, {"oid": "fe784637dd34c4db7eb9aab1c70d6cb1ac658f67", "url": "https://github.com/pytorch/serve/commit/fe784637dd34c4db7eb9aab1c70d6cb1ac658f67", "message": "Error handling and request formatting", "committedDate": "2020-11-26T13:56:10Z", "type": "commit"}, {"oid": "fbf1b2e2bf94dd2e5296e17417a60d5b8fee6aee", "url": "https://github.com/pytorch/serve/commit/fbf1b2e2bf94dd2e5296e17417a60d5b8fee6aee", "message": "Merge branch 'issue_682' of https://github.com/pytorch/serve into issue_682", "committedDate": "2020-11-26T13:56:15Z", "type": "commit"}, {"oid": "d113274769ed7ea0f3a73eebe21f05e6c4ced7a4", "url": "https://github.com/pytorch/serve/commit/d113274769ed7ea0f3a73eebe21f05e6c4ced7a4", "message": "merged master and resolved conflicts", "committedDate": "2020-11-26T14:10:00Z", "type": "commit"}]}