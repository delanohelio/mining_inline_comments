{"pr_number": 176, "pr_title": "Queries data from the index when insufficient data in buffer to form a full shingle", "pr_createdAt": "2020-06-25T00:05:44Z", "pr_url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTI0MzcwMQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r445243701", "bodyText": "is this branch still correct?", "author": "wnbts", "createdAt": "2020-06-25T00:30:34Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,40 +119,59 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n \n         Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n             .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+\n+        Map<Long, double[]> featuresMap = shingle.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                for (int i = 0; i < missingRanges.size(); i++) {\n+                    Optional<double[]> point = points.get(i);\n+                    if (point.isPresent()) {\n+                        featuresMap.put(missingRanges.get(i).getValue(), point.get());\n+                    }\n+                }\n+                updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+            }, listener::onFailure));\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }", "originalCommit": "e8b0d2acba8e1f05bf1af60ad678f0fca2518779", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "84d4a200a14e3fed987946facf1ae7d140dc088c", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/84d4a200a14e3fed987946facf1ae7d140dc088c", "message": "Queries data from the index when insufficient data in buffer to form a full shingle.", "committedDate": "2020-06-30T18:45:15Z", "type": "forcePushed"}, {"oid": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "message": "Queries data from the index when insufficient data in buffer to form a full shingle.", "committedDate": "2020-06-30T19:17:38Z", "type": "commit"}, {"oid": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "message": "Queries data from the index when insufficient data in buffer to form a full shingle.", "committedDate": "2020-06-30T19:17:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk1MzQ5OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r447953499", "bodyText": "this method should be private to the class.", "author": "wnbts", "createdAt": "2020-06-30T20:17:28Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,67 +119,114 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n+        getCurrentFeatures(detector, startTime, endTime, true, listener);\n+    }\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+    /**\n+     * Returns to listener unprocessed features and processed features (such as shingle) for the current data point.\n+     *\n+     * @param detector anomaly detector for which the features are returned\n+     * @param startTime start time of the data point in epoch milliseconds\n+     * @param endTime end time of the data point in epoch milliseconds\n+     * @param cacheMissingDataPoints if set to true, missing data points are remembered and not re-queried later\n+     * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n+     */\n+    public void getCurrentFeatures(", "originalCommit": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzNTY2MA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r448035660", "bodyText": "The reason this is made public is to allow the unit tests to set the initial state of the shingle without caching missing data points during the setup (since the caching would affect the desired initial state of the shingle to be tested).\nI can try to find alternative ways to set the initial state of the shingle, in which case I'll just remove the cacheMissingDataPoints parameter (and just always cache missing data points) and remove the method above.", "author": "LiuJoyceC", "createdAt": "2020-06-30T23:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk1MzQ5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk1OTQ1OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r447959459", "bodyText": "note the timestamps might not have exactly the same interval. there can be some jittering around each interval. for example, the timestamps from requests can be 59 sec, 1 min 58 sec, 2 min 03 sec, etc. if the data point already exists, the range can be skipped for query.", "author": "wnbts", "createdAt": "2020-06-30T20:28:49Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,67 +119,114 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n+        getCurrentFeatures(detector, startTime, endTime, true, listener);\n+    }\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+    /**\n+     * Returns to listener unprocessed features and processed features (such as shingle) for the current data point.\n+     *\n+     * @param detector anomaly detector for which the features are returned\n+     * @param startTime start time of the data point in epoch milliseconds\n+     * @param endTime end time of the data point in epoch milliseconds\n+     * @param cacheMissingDataPoints if set to true, missing data points are remembered and not re-queried later\n+     * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n+     */\n+    public void getCurrentFeatures(\n+        AnomalyDetector detector,\n+        long startTime,\n+        long endTime,\n+        boolean cacheMissingDataPoints,\n+        ActionListener<SinglePointFeatures> listener\n+    ) throws IOException {\n+\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, Optional<double[]>>>(shingleSize));\n+\n+        Map<Long, Optional<double[]>> featuresMap = shingle.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                for (int i = 0; i < points.size(); i++) {\n+                    Optional<double[]> point = points.get(i);\n+                    if (cacheMissingDataPoints || point.isPresent()) {\n+                        featuresMap.put(missingRanges.get(i).getValue(), point);\n+                    }\n+                }\n+                updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+            }, listener::onFailure));\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }\n     }\n \n+    private List<Entry<Long, Long>> getMissingRangesInShingle(\n+        AnomalyDetector detector,\n+        Map<Long, Optional<double[]>> featuresMap,\n+        long endTime\n+    ) {\n+        long intervalMilli = getDetectorIntervalInMilliseconds(detector);\n+\n+        return getFullShingleEndTimes(endTime, intervalMilli)\n+            .filter(time -> !featuresMap.containsKey(time))", "originalCommit": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzMzc2MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r448033761", "bodyText": "Ok, I will change the implementation to also find nearby timestamps rather than requiring an exact match on the timestamp. What's an appropriate threshold for how much the time the nearest data point can be off by before we consider a data point missing? For example, if the interval is 1 minute and the nearest data point to a particular timestamp is 30 seconds away, should the data point for the desired timestamp be counted as missing and therefore need to be queried?", "author": "LiuJoyceC", "createdAt": "2020-06-30T23:27:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk1OTQ1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODA0MTA3MA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r448041070", "bodyText": "the nearest data point within +- half interval from the expected can be used such that no data point is thrown away. if an existing data point happens to be right in the middle and there are no other data points nearby, then it may potentially be used for two neighboring ranges, which is unlikely but ok.", "author": "wnbts", "createdAt": "2020-06-30T23:51:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk1OTQ1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2MTUzOQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r447961539", "bodyText": "minor. the query is from both the input and the system. if that happens, there will be no recovery for caller. usually those exceptions are caught and wrapped (abstracted) in unchecked exceptions for high-level callers, like in many other programming languages.", "author": "wnbts", "createdAt": "2020-06-30T20:32:46Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,67 +119,114 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n+        getCurrentFeatures(detector, startTime, endTime, true, listener);\n+    }\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+    /**\n+     * Returns to listener unprocessed features and processed features (such as shingle) for the current data point.\n+     *\n+     * @param detector anomaly detector for which the features are returned\n+     * @param startTime start time of the data point in epoch milliseconds\n+     * @param endTime end time of the data point in epoch milliseconds\n+     * @param cacheMissingDataPoints if set to true, missing data points are remembered and not re-queried later\n+     * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector", "originalCommit": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODAzOTg0MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r448039841", "bodyText": "Ok, I'll add a try catch block around searchFeatureDao.getFeatureSamplesForPeriods() and pass the error to listener.onFailure() instead, since that's where other failures from searchFeatureDao.getFeatureSamplesForPeriods() are being passed to.", "author": "LiuJoyceC", "createdAt": "2020-06-30T23:47:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2MTUzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM3MTA4Mg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450371082", "bodyText": "Please make sure AnomalyResultTransportAction.onFeatureResponse can handle the exception you throw.  The IOException sounds like sth you should rethrow EndRunException in AnomalyResultTransportAction and let user know.", "author": "kaituo", "createdAt": "2020-07-06T17:22:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzk2MTUzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2Njk1Mw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450366953", "bodyText": "Why do we have another method with the same signature?", "author": "kaituo", "createdAt": "2020-07-06T17:14:58Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,67 +119,114 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n+        getCurrentFeatures(detector, startTime, endTime, true, listener);", "originalCommit": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUwMDkwOA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450500908", "bodyText": "The signature is slightly different. See above comments.\nHowever, the most recent change addresses this, and there is no longer two different signatures for this method.", "author": "LiuJoyceC", "createdAt": "2020-07-06T21:57:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2Njk1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2ODc2NA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450368764", "bodyText": "What's the use case of always looking for missing data in the shingle besides starting detector running?  @wnbts", "author": "kaituo", "createdAt": "2020-07-06T17:18:26Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -118,67 +119,114 @@ public FeatureManager(\n      * @param startTime start time of the data point in epoch milliseconds\n      * @param endTime end time of the data point in epoch milliseconds\n      * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n      */\n-    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n+    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener)\n+        throws IOException {\n+        getCurrentFeatures(detector, startTime, endTime, true, listener);\n+    }\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+    /**\n+     * Returns to listener unprocessed features and processed features (such as shingle) for the current data point.\n+     *\n+     * @param detector anomaly detector for which the features are returned\n+     * @param startTime start time of the data point in epoch milliseconds\n+     * @param endTime end time of the data point in epoch milliseconds\n+     * @param cacheMissingDataPoints if set to true, missing data points are remembered and not re-queried later\n+     * @param listener onResponse is called with unprocessed features and processed features for the current data point\n+     * @throws IOException if a user gives wrong query input when defining a detector\n+     */\n+    public void getCurrentFeatures(\n+        AnomalyDetector detector,\n+        long startTime,\n+        long endTime,\n+        boolean cacheMissingDataPoints,\n+        ActionListener<SinglePointFeatures> listener\n+    ) throws IOException {\n+\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, Optional<double[]>>>(shingleSize));\n+\n+        Map<Long, Optional<double[]>> featuresMap = shingle.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);", "originalCommit": "f87ee3d547dc0ce3cce26dfe3918a584c291c4c7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQ5NTk2Ng==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450495966", "bodyText": "its for other rare edge cases that previous query results are not available possibly due to scheduled job issues or query issues.", "author": "wnbts", "createdAt": "2020-07-06T21:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM2ODc2NA=="}], "type": "inlineReview"}, {"oid": "5793db2cf153da06c59ab70f230805771aeaa98d", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/5793db2cf153da06c59ab70f230805771aeaa98d", "message": "Changes from previous commit:\n1) Allows time jitter up to half an interval.\n2) getCurrentFeatures returns all errors to the listener instead of throwing when searchFeatureDao throws.\n3) Modified unit tests to not require a public getCurrentFeatures interface that allows for not caching.", "committedDate": "2020-07-06T18:49:05Z", "type": "commit"}, {"oid": "2a071b67bfd756fa0ab4de19a319cdcfa56663fb", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/2a071b67bfd756fa0ab4de19a319cdcfa56663fb", "message": "Merge branch 'master' of https://github.com/opendistro-for-elasticsearch/anomaly-detection into fill-shingle-with-history", "committedDate": "2020-07-06T18:54:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzMDI2OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450530269", "bodyText": "minor. this data should still be final.", "author": "wnbts", "createdAt": "2020-07-06T23:29:00Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -53,7 +54,7 @@\n     private static final Logger logger = LogManager.getLogger(FeatureManager.class);\n \n     // Each anomaly detector has a queue of data points with timestamps (in epoch milliseconds).\n-    private final Map<String, ArrayDeque<Entry<Long, double[]>>> detectorIdsToTimeShingles;\n+    private Map<String, ArrayDeque<Entry<Long, Optional<double[]>>>> detectorIdsToTimeShingles;", "originalCommit": "2a071b67bfd756fa0ab4de19a319cdcfa56663fb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjM3ODEzOA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r452378138", "bodyText": "Good catch. I forgot to add back the final when I was originally experimenting with mocking private variables for unit tests.", "author": "LiuJoyceC", "createdAt": "2020-07-09T17:29:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzMDI2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzOTc1OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r450539759", "bodyText": "minor. the second condition shingle.getLast().getKey() < endTime might need some relaxation. if the existing buffer is [1min, 2min,..., 8min] and endTime is 8min1sec, the last data point would still be valid for the endTime.\nalso, this if branch may be merged with the else branch, starting with optional current point and if current point is present, then optional current shingle.", "author": "wnbts", "createdAt": "2020-07-07T00:02:08Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -121,81 +122,133 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(e);\n+            }\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }\n     }\n \n+    private List<Entry<Long, Long>> getMissingRangesInShingle(\n+        AnomalyDetector detector,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n+        long endTime\n+    ) {\n+        long intervalMilli = getDetectorIntervalInMilliseconds(detector);\n+\n+        return getFullShingleEndTimes(endTime, intervalMilli)\n+            .filter(time -> !featuresMap.containsKey(time))\n+            .mapToObj(time -> new SimpleImmutableEntry<>(time - intervalMilli, time))\n+            .collect(Collectors.toList());\n+    }\n+\n     private void updateUnprocessedFeatures(\n-        Optional<double[]> point,\n-        Deque<Entry<Long, double[]>> shingle,\n         AnomalyDetector detector,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-        if (point.isPresent()) {\n-            if (shingle.size() == shingleSize) {\n-                shingle.remove();\n-            }\n-            shingle.add(new SimpleImmutableEntry<>(endTime, point.get()));\n-            getProcessedFeatures(shingle, detector, endTime, listener);\n-        } else {\n-            listener.onResponse(new SinglePointFeatures(Optional.empty(), Optional.empty()));\n-        }\n+        shingle.clear();\n+        getFullShingleEndTimes(endTime, getDetectorIntervalInMilliseconds(detector))\n+            .filter(time -> featuresMap.containsKey(time))\n+            .mapToObj(time -> featuresMap.get(time))\n+            .forEach(e -> shingle.add(e));\n+\n+        getProcessedFeatures(shingle, detector, endTime, listener);\n     }\n \n     private void getProcessedFeatures(\n-        Deque<Entry<Long, double[]>> shingle,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n         AnomalyDetector detector,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-\n-        double[][] currentPoints = filterAndFill(shingle, endTime, detector);\n-        Optional<double[]> currentPoint = Optional.ofNullable(shingle.peekLast()).map(Entry::getValue);\n-        listener\n-            .onResponse(\n-                Optional\n-                    .ofNullable(currentPoints)\n-                    .map(points -> new SinglePointFeatures(currentPoint, Optional.of(batchShingle(points, shingleSize)[0])))\n-                    .orElse(new SinglePointFeatures(currentPoint, Optional.empty()))\n-            );\n+        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime || !shingle.getLast().getValue().isPresent()) {", "originalCommit": "2a071b67bfd756fa0ab4de19a319cdcfa56663fb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d052f0566e71c93bd3ac09faad3c7aa934ecd7a0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/d052f0566e71c93bd3ac09faad3c7aa934ecd7a0", "message": "Addresses minor comments from PR.", "committedDate": "2020-07-09T22:41:52Z", "type": "commit"}, {"oid": "cb13815a6fa0acda22512a4d932ff369da5f2663", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/cb13815a6fa0acda22512a4d932ff369da5f2663", "message": "Merge branch 'master' of https://github.com/opendistro-for-elasticsearch/anomaly-detection into fill-shingle-with-history", "committedDate": "2020-07-09T22:44:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0ODAwNQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r452548005", "bodyText": "minor. error handling can change to as kaituo suggested.", "author": "wnbts", "createdAt": "2020-07-09T23:43:00Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -121,81 +122,132 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(e);", "originalCommit": "cb13815a6fa0acda22512a4d932ff369da5f2663", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTQzMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r452549433", "bodyText": "getProcessedFeatures should be able to handle both branches.", "author": "wnbts", "createdAt": "2020-07-09T23:47:46Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -121,81 +122,132 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(e);\n+            }\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }\n     }\n \n+    private List<Entry<Long, Long>> getMissingRangesInShingle(\n+        AnomalyDetector detector,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n+        long endTime\n+    ) {\n+        long intervalMilli = getDetectorIntervalInMilliseconds(detector);\n+\n+        return getFullShingleEndTimes(endTime, intervalMilli)\n+            .filter(time -> !featuresMap.containsKey(time))\n+            .mapToObj(time -> new SimpleImmutableEntry<>(time - intervalMilli, time))\n+            .collect(Collectors.toList());\n+    }\n+\n     private void updateUnprocessedFeatures(\n-        Optional<double[]> point,\n-        Deque<Entry<Long, double[]>> shingle,\n         AnomalyDetector detector,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-        if (point.isPresent()) {\n-            if (shingle.size() == shingleSize) {\n-                shingle.remove();\n-            }\n-            shingle.add(new SimpleImmutableEntry<>(endTime, point.get()));\n+        shingle.clear();\n+        getFullShingleEndTimes(endTime, getDetectorIntervalInMilliseconds(detector))\n+            .filter(time -> featuresMap.containsKey(time))\n+            .mapToObj(time -> featuresMap.get(time))\n+            .forEach(e -> shingle.add(e));\n+\n+        if (featuresMap.containsKey(endTime)) {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         } else {\n             listener.onResponse(new SinglePointFeatures(Optional.empty(), Optional.empty()));", "originalCommit": "cb13815a6fa0acda22512a4d932ff369da5f2663", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3MzgxMA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453073810", "bodyText": "Are you suggesting to pass featuresMap as a parameter into getProcessedFeatures and check this condition in there?\nThe condition featuresMap.containsKey(endTime) is the simplest/most concise way to ensure the conditions !shingle.isEmpty() and shingle.getLast().getKey() \u2248 endTime (where \u2248 means within half an interval away as discussed, which basically means that the current point is present). The reason this check is being done in updateUnprocessedFeatures is because this check is only needed if updateUnprocessedFeatures is invoked, and not needed if getProcessedFeatures is directly invoked by getCurrentFeatures (in which case the missingRanges.size() > 0 already ensures the above conditions, so checking featuresMap is unnecessary).", "author": "LiuJoyceC", "createdAt": "2020-07-10T20:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTQzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNDE3OA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453104178", "bodyText": "no, featuremap is not needed. by the end of line 176, the collection shingle should contain exactly shingle sized data points, present or absent, the last being the most ending around endTime. getProcessedFeatures can output the same results for both if and else branches.", "author": "wnbts", "createdAt": "2020-07-10T22:25:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTQzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExNDA4Ng==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453114086", "bodyText": "With the current implementation (where results are not added to the shingle if searchFeatureDao returns Collections.emptyList()), the shingle is not guaranteed to contain an entry around endTime, which is why this check is currently being done.\nHowever, per your response on the comment below, if we go ahead and cache all missing ranges when searchFeatureDao returns Collections.emptyList(), then the shingle will be guaranteed to have the entry at or near endTime, and then checking the featureMap will no longer be needed.", "author": "LiuJoyceC", "createdAt": "2020-07-10T23:05:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTQzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU1MTA4MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r452551081", "bodyText": "minor. this first filter might not be needed since the map should contains results for all interval, present or absent. to be safe in the unlikely case that map is incomplete, the second get can return an empty if the key is absent using getOrDefault.", "author": "wnbts", "createdAt": "2020-07-09T23:53:34Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -121,81 +122,132 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(e);\n+            }\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }\n     }\n \n+    private List<Entry<Long, Long>> getMissingRangesInShingle(\n+        AnomalyDetector detector,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n+        long endTime\n+    ) {\n+        long intervalMilli = getDetectorIntervalInMilliseconds(detector);\n+\n+        return getFullShingleEndTimes(endTime, intervalMilli)\n+            .filter(time -> !featuresMap.containsKey(time))\n+            .mapToObj(time -> new SimpleImmutableEntry<>(time - intervalMilli, time))\n+            .collect(Collectors.toList());\n+    }\n+\n     private void updateUnprocessedFeatures(\n-        Optional<double[]> point,\n-        Deque<Entry<Long, double[]>> shingle,\n         AnomalyDetector detector,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-        if (point.isPresent()) {\n-            if (shingle.size() == shingleSize) {\n-                shingle.remove();\n-            }\n-            shingle.add(new SimpleImmutableEntry<>(endTime, point.get()));\n+        shingle.clear();\n+        getFullShingleEndTimes(endTime, getDetectorIntervalInMilliseconds(detector))\n+            .filter(time -> featuresMap.containsKey(time))\n+            .mapToObj(time -> featuresMap.get(time))", "originalCommit": "cb13815a6fa0acda22512a4d932ff369da5f2663", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA2ODAzMA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453068030", "bodyText": "It depends on how we want to handle this case: https://github.com/opendistro-for-elasticsearch/anomaly-detection/blob/master/src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/SearchFeatureDao.java#L211-L214. This is the case that could cause some of the times to be missing from featuresMap at this line.\nIs aggs == null in the search response equivalent to each queried time range having no data? In other words, do we want to treat Collections.emptyList() equivalent to [Optional.empty(), Optional.empty(), ..., Optional.empty()]? In the case of Collections.emptyList(), do we want to cache the null values for each of the queried time ranges so they will not get re-queried?\nIf yes, it might be cleaner to handle this logic in the callback passed to searchFeatureDao, so that the logic for determining shingle values based on the search response is located in one function rather than spread across multiple functions.", "author": "LiuJoyceC", "createdAt": "2020-07-10T20:42:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU1MTA4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNzE0OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453107149", "bodyText": "i haven't seen or know that happens in practice. if that ever happens, caching the results is ok. what i was suggesting is just simplify the implementation to one line like stream.maptoobject(time -> map.getOrDefault(time, <time, empty()>)).", "author": "wnbts", "createdAt": "2020-07-10T22:36:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU1MTA4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExNDMxMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453114313", "bodyText": "Alright, I will change the implementation to cache results for the missing ranges when the response is an empty list.", "author": "LiuJoyceC", "createdAt": "2020-07-10T23:05:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU1MTA4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk2MTg1Mg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r452961852", "bodyText": "The original code is easier to read.  Also, you do \"currentPoint.map(point -> filterAndFill(shingle, endTime, detector))\" without using currentPoint in filterAndFill, which looks strange.", "author": "kaituo", "createdAt": "2020-07-10T16:56:58Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -184,19 +188,14 @@ private void getProcessedFeatures(\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime || !shingle.getLast().getValue().isPresent()) {\n-            listener.onResponse(new SinglePointFeatures(Optional.empty(), Optional.empty()));\n-        } else {\n-            double[][] currentPoints = filterAndFill(shingle, endTime, detector);\n-            Optional<double[]> currentPoint = shingle.peekLast().getValue();\n-            listener\n-                .onResponse(\n-                    Optional\n-                        .ofNullable(currentPoints)\n-                        .map(points -> new SinglePointFeatures(currentPoint, Optional.of(batchShingle(points, shingleSize)[0])))\n-                        .orElse(new SinglePointFeatures(currentPoint, Optional.empty()))\n-                );\n-        }\n+        Optional<double[]> currentPoint = shingle.peekLast().getValue();\n+        listener\n+            .onResponse(", "originalCommit": "d052f0566e71c93bd3ac09faad3c7aa934ecd7a0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3NzkyNQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453077925", "bodyText": "This change was made to address the comments above from wnbts to simplify the code here to not use if else to ensure currentPoint is not an empty Optional. The way this is written is such that if currentPoint is an empty Optional, it triggers the orElse line, so that if the currentPoint is empty, we don't end up with a non-empty array of points in the SinglePointFeatures (if that were to happen, it would be an unexpected change in behavior from before).\nThe reason the original code didn't need to check that was because currentPoint wasn't an Optional before. Now that we are caching empty responses from the search request to ensure we don't re-query missing data, the points in the shingle are wrapped in Optionals.", "author": "LiuJoyceC", "createdAt": "2020-07-10T21:08:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk2MTg1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEyMDU2MA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453120560", "bodyText": "Another unexpected change in behavior that this is avoiding is running filterAndFill on a shingle where the current point is not present. This would result in the shingle filling in the missing current point with older data. In the original code, there were checks in getCurrentFeatures and updateUnprocessedFeature to ensure the current point is not missing. These checks were removed to address comments above about simplifying the logic.", "author": "LiuJoyceC", "createdAt": "2020-07-10T23:30:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk2MTg1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgwMTg1MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453801851", "bodyText": "The code was modified to no longer have an unused param point in a function, and now currentPoint.isPresent() is explicitly checked to make the intention clear. Does this address the concern?", "author": "LiuJoyceC", "createdAt": "2020-07-13T17:11:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk2MTg1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NzcwMg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453857702", "bodyText": "yes, thanks for the change.", "author": "kaituo", "createdAt": "2020-07-13T18:46:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk2MTg1Mg=="}], "type": "inlineReview"}, {"oid": "1680fcc0a007d167ffc1a0ddc4e72e3546a4ed0e", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/1680fcc0a007d167ffc1a0ddc4e72e3546a4ed0e", "message": "Wraps IOException in EndRunException and caches an empty list from search response.", "committedDate": "2020-07-10T23:57:08Z", "type": "commit"}, {"oid": "8e1b4fad02d8d77b39fb00d126709b16793e305d", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/8e1b4fad02d8d77b39fb00d126709b16793e305d", "message": "Merge branch 'master' of https://github.com/opendistro-for-elasticsearch/anomaly-detection into fill-shingle-with-history", "committedDate": "2020-07-11T00:01:04Z", "type": "commit"}, {"oid": "843ac796bd5372d57f01697b371c19a2485640c3", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/843ac796bd5372d57f01697b371c19a2485640c3", "message": "Wraps IOException in EndRunException and removes unused use of \"point\" in Optional map function.", "committedDate": "2020-07-11T02:30:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyMDgxNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453820814", "bodyText": "add a function-level comment (e.g., \n  \n    \n      anomaly-detection/src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java\n    \n    \n         Line 243\n      in\n      cd3bdae\n    \n    \n    \n    \n\n        \n          \n                *                 onFailure is called with EndRunException on feature query creation errors \n        \n    \n  \n\n) to say you are gonna throw this exception when certain condition is true?", "author": "kaituo", "createdAt": "2020-07-13T17:43:36Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -132,81 +133,129 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(new EndRunException(detector.getDetectorId(), CommonErrorMessages.INVALID_SEARCH_QUERY_MSG, e, true));", "originalCommit": "843ac796bd5372d57f01697b371c19a2485640c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkxNjg2NA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453916864", "bodyText": "Sure.", "author": "LiuJoyceC", "createdAt": "2020-07-13T20:36:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgyMDgxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzgzNTE5NQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453835195", "bodyText": "Have some documentation of this method since the return value is nested and not easy to understand?", "author": "kaituo", "createdAt": "2020-07-13T18:07:57Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -132,81 +133,129 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {\n \n-        Deque<Entry<Long, double[]>> shingle = detectorIdsToTimeShingles\n-            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<Entry<Long, double[]>>(shingleSize));\n-        if (shingle.isEmpty() || shingle.getLast().getKey() < endTime) {\n-            searchFeatureDao\n-                .getFeaturesForPeriod(\n-                    detector,\n-                    startTime,\n-                    endTime,\n-                    ActionListener\n-                        .wrap(point -> updateUnprocessedFeatures(point, shingle, detector, endTime, listener), listener::onFailure)\n-                );\n+        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles\n+            .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));\n+\n+        long maxTimeDifference = getDetectorIntervalInMilliseconds(detector) / 2;\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference)\n+            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);\n+\n+        if (missingRanges.size() > 0) {\n+            try {\n+                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {\n+                    for (int i = 0; i < points.size(); i++) {\n+                        Optional<double[]> point = points.get(i);\n+                        long rangeEndTime = missingRanges.get(i).getValue();\n+                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));\n+                    }\n+                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);\n+                }, listener::onFailure));\n+            } catch (IOException e) {\n+                listener.onFailure(new EndRunException(detector.getDetectorId(), CommonErrorMessages.INVALID_SEARCH_QUERY_MSG, e, true));\n+            }\n         } else {\n             getProcessedFeatures(shingle, detector, endTime, listener);\n         }\n     }\n \n+    private List<Entry<Long, Long>> getMissingRangesInShingle(\n+        AnomalyDetector detector,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n+        long endTime\n+    ) {\n+        long intervalMilli = getDetectorIntervalInMilliseconds(detector);\n+\n+        return getFullShingleEndTimes(endTime, intervalMilli)\n+            .filter(time -> !featuresMap.containsKey(time))\n+            .mapToObj(time -> new SimpleImmutableEntry<>(time - intervalMilli, time))\n+            .collect(Collectors.toList());\n+    }\n+\n     private void updateUnprocessedFeatures(\n-        Optional<double[]> point,\n-        Deque<Entry<Long, double[]>> shingle,\n         AnomalyDetector detector,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n+        Map<Long, Entry<Long, Optional<double[]>>> featuresMap,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-        if (point.isPresent()) {\n-            if (shingle.size() == shingleSize) {\n-                shingle.remove();\n-            }\n-            shingle.add(new SimpleImmutableEntry<>(endTime, point.get()));\n-            getProcessedFeatures(shingle, detector, endTime, listener);\n-        } else {\n-            listener.onResponse(new SinglePointFeatures(Optional.empty(), Optional.empty()));\n-        }\n+        shingle.clear();\n+        getFullShingleEndTimes(endTime, getDetectorIntervalInMilliseconds(detector))\n+            .mapToObj(time -> featuresMap.getOrDefault(time, new SimpleImmutableEntry<>(time, Optional.empty())))\n+            .forEach(e -> shingle.add(e));\n+\n+        getProcessedFeatures(shingle, detector, endTime, listener);\n     }\n \n     private void getProcessedFeatures(\n-        Deque<Entry<Long, double[]>> shingle,\n+        Deque<Entry<Long, Optional<double[]>>> shingle,\n         AnomalyDetector detector,\n         long endTime,\n         ActionListener<SinglePointFeatures> listener\n     ) {\n-\n-        double[][] currentPoints = filterAndFill(shingle, endTime, detector);\n-        Optional<double[]> currentPoint = Optional.ofNullable(shingle.peekLast()).map(Entry::getValue);\n+        Optional<double[]> currentPoint = shingle.peekLast().getValue();\n         listener\n             .onResponse(\n-                Optional\n-                    .ofNullable(currentPoints)\n-                    .map(points -> new SinglePointFeatures(currentPoint, Optional.of(batchShingle(points, shingleSize)[0])))\n-                    .orElse(new SinglePointFeatures(currentPoint, Optional.empty()))\n+                new SinglePointFeatures(\n+                    currentPoint,\n+                    Optional\n+                        .ofNullable(currentPoint.isPresent() ? filterAndFill(shingle, endTime, detector) : null)\n+                        .map(points -> batchShingle(points, shingleSize)[0])\n+                )\n             );\n     }\n \n-    private double[][] filterAndFill(Deque<Entry<Long, double[]>> shingle, long endTime, AnomalyDetector detector) {\n-        long intervalMilli = ((IntervalTimeConfiguration) detector.getDetectionInterval()).toDuration().toMillis();\n+    private double[][] filterAndFill(Deque<Entry<Long, Optional<double[]>>> shingle, long endTime, AnomalyDetector detector) {\n+        Deque<Entry<Long, Optional<double[]>>> filteredShingle = shingle\n+            .stream()\n+            .filter(e -> e.getValue().isPresent())\n+            .collect(Collectors.toCollection(ArrayDeque::new));\n         double[][] result = null;\n-        if (shingle.size() >= shingleSize - maxMissingPoints) {\n-            TreeMap<Long, double[]> search = new TreeMap<>(shingle.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue)));\n-            result = IntStream.rangeClosed(1, shingleSize).mapToLong(i -> endTime - (shingleSize - i) * intervalMilli).mapToObj(t -> {\n-                Optional<Entry<Long, double[]>> after = Optional.ofNullable(search.ceilingEntry(t));\n-                Optional<Entry<Long, double[]>> before = Optional.ofNullable(search.floorEntry(t));\n-                return after\n-                    .filter(a -> Math.abs(t - a.getKey()) <= before.map(b -> Math.abs(t - b.getKey())).orElse(Long.MAX_VALUE))\n-                    .map(Optional::of)\n-                    .orElse(before)\n-                    .filter(e -> Math.abs(t - e.getKey()) < intervalMilli * maxNeighborDistance)\n-                    .map(Entry::getValue)\n-                    .orElse(null);\n-            }).filter(d -> d != null).toArray(double[][]::new);\n+        if (filteredShingle.size() >= shingleSize - maxMissingPoints) {\n+            long maxMillisecondsDifference = maxNeighborDistance * getDetectorIntervalInMilliseconds(detector);\n+            result = getNearbyPointsForShingle(detector, filteredShingle, endTime, maxMillisecondsDifference)\n+                .map(e -> e.getValue().getValue().orElse(null))\n+                .filter(d -> d != null)\n+                .toArray(double[][]::new);\n+\n             if (result.length < shingleSize) {\n                 result = null;\n             }\n         }\n         return result;\n     }\n \n+    private Stream<Entry<Long, Entry<Long, Optional<double[]>>>> getNearbyPointsForShingle(", "originalCommit": "843ac796bd5372d57f01697b371c19a2485640c3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453854013", "bodyText": "Add comments on your workflow?  Is the following understanding correct?\nFirst, you interpolate using nearest points.\nThen, query for missing points.\nFinally, do another round of interpolation using nearest points.", "author": "kaituo", "createdAt": "2020-07-13T18:40:12Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/feature/FeatureManager.java", "diffHunk": "@@ -132,81 +133,129 @@ public FeatureManager(\n      */\n     public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {", "originalCommit": "843ac796bd5372d57f01697b371c19a2485640c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzkxNTgyNg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453915826", "bodyText": "The code isn't actually interpolating before querying for missing points. It is meant to account for a small amount of jitter in time (see wnbts's comment above) so that points that are not actually missing aren't re-queried simply because the millisecond timestamp doesn't exactly match up. The fact that we have to account for random time jitter does make the implementation a bit more complicated than the original code (and my original first version of this feature).\nFor example, let's say the interval is 60,000 milliseconds, and the detector ends up running at time 60,000, time 120,001, and time 179,999 (simply due to random time jitter). At time 120,001, the function shouldn't re-query historical data just because there doesn't exist a data point stored in the shingle buffer whose timestamp matches up to exactly 60,001. It should just recognize that the point at timestamp 60,000 is the point from 1 interval ago. Similarly, at time 179,999, it shouldn't re-query the previous 2 intervals just because there aren't points whose timestamps are exactly 119,999 and 59,999.\nAlso, what actually gets stored in the shingle buffer (which persists to intervals in the future) is the actual original timestamp of the data point, so no interpolation is being done. In the example above, what gets stored in the shingle is:\n[<60000, x>, <120001, y>, <179999, z>]. So the data point at time 60,000 is not getting interpolated to time 60,001. Instead, time 60,000 is just recognized as the timestamp of the previous interval.\nThe actual interpolation is done after the query for missing points. Here, missing points will be interpolated with points from neighboring intervals up to the configured maxNeighborDistance (which is currently configured to 2 intervals away). So if the shingle is missing an interval, such as [<60000, x>, <179999, z>], then the data point from time 179,999 will get interpolated to time 119,999 as if that were the actual data point from the previous interval, so the resulting double[] from filterAndFill becomes [x, z, z].", "author": "LiuJoyceC", "createdAt": "2020-07-13T20:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk1MTk5MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r453951991", "bodyText": "First of all, there is no jitter.  So the logic is unnecessary. (FYI @wnbts)\nYou called getNearbyPointsForShingle before running query that actually use nearby points for interpolation, right? getNearbyPointsForShingle returns a map whose key is 60,000, 120,000, 180,000 in your example because the key's source is what getFullShingleEndTimes returns, right?", "author": "kaituo", "createdAt": "2020-07-13T21:45:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwNjMxNg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r454006316", "bodyText": "@kaituo  i am not following this entire thread, just comment on the statement that \"there is no jiftter\". It looks like the time range comes from system clock \n  \n    \n      anomaly-detection/src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java\n    \n    \n         Line 132\n      in\n      129d249\n    \n    \n    \n    \n\n        \n          \n           Instant executionStartTime = Instant.now(); \n        \n    \n  \n\n , which has jitters. Also, scheduled job runs are not exactly evenly spaced for jitters are intentionally added to scheduler.", "author": "wnbts", "createdAt": "2020-07-13T23:33:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAxMzM3MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r454013371", "bodyText": "@wnbts  scheduled job's jitter is disabled for AD.  It's possible that a scheduled job may not happen exactly as it is scheduled (e.g., system is under heavy load).  But in normal cases, the job should run on time.\n@LiuJoyceC You can keep your code.  That should give some fault tolerance.", "author": "kaituo", "createdAt": "2020-07-13T23:48:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDA0ODk0NQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/176#discussion_r454048945", "bodyText": "You called getNearbyPointsForShingle before running query that actually use nearby points for interpolation, right? getNearbyPointsForShingle returns a map whose key is 60,000, 120,000, 180,000 in your example because the key's source is what getFullShingleEndTimes returns, right?\n\nThe key in the map is meant to allow the shingle to match up data points to intervals. The actual timestamp of the data point is stored in the value of the map along with the data point value. In updateUnprocessedFeatures, it is the actual timestamp of the data point that is added to the shingle and persisted to future intervals. So the shingle in the example will contain the timestamps 60,000, 120,001, 179,999. The data points are only associated with their actual timestamps and not imputed to other timestamps at that stage.\n\nYou can keep your code. That should give some fault tolerance.\n\n\ud83d\udc4d", "author": "LiuJoyceC", "createdAt": "2020-07-14T01:48:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDAxMw=="}], "type": "inlineReview"}, {"oid": "cf9efebefca5df7902075907f162469f61b86edd", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/cf9efebefca5df7902075907f162469f61b86edd", "message": "Adds comments/function documents for clarification.", "committedDate": "2020-07-15T01:00:34Z", "type": "commit"}, {"oid": "636f293713837599b2eddc56fea398892102b3dd", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/636f293713837599b2eddc56fea398892102b3dd", "message": "Merge branch 'master' of https://github.com/opendistro-for-elasticsearch/anomaly-detection into fill-shingle-with-history", "committedDate": "2020-07-15T01:00:46Z", "type": "commit"}, {"oid": "636f293713837599b2eddc56fea398892102b3dd", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/636f293713837599b2eddc56fea398892102b3dd", "message": "Merge branch 'master' of https://github.com/opendistro-for-elasticsearch/anomaly-detection into fill-shingle-with-history", "committedDate": "2020-07-15T01:00:46Z", "type": "forcePushed"}, {"oid": "937a74223305c615e40d6fe7f337aebe903dd220", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/937a74223305c615e40d6fe7f337aebe903dd220", "message": "Updates line in documentation causing build to fail.", "committedDate": "2020-07-15T20:54:32Z", "type": "commit"}]}