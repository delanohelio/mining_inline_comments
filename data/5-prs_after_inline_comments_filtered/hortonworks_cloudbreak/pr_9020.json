{"pr_number": 9020, "pr_title": "CB-8717 Add thunderhead datalake-dr service connector", "pr_createdAt": "2020-09-15T22:23:38Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/9020", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODExNw==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208117", "bodyText": "I guess it should be removed", "author": "doktoric", "createdAt": "2020-09-16T07:02:02Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ5NDg0Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489494842", "bodyText": "Thanks. Went back and cleaned all that up.", "author": "hreeve-cloudera", "createdAt": "2020-09-16T14:44:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODE2NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208164", "bodyText": "I guess it should be removed", "author": "doktoric", "createdAt": "2020-09-16T07:02:08Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODMxMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208313", "bodyText": "please remove if not required", "author": "doktoric", "createdAt": "2020-09-16T07:02:27Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM3OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208379", "bodyText": "I guess it should be removed", "author": "doktoric", "createdAt": "2020-09-16T07:02:35Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODQwOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208408", "bodyText": "I guess it should be removed", "author": "doktoric", "createdAt": "2020-09-16T07:02:39Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODQ3NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489208474", "bodyText": "please remove if not required", "author": "doktoric", "createdAt": "2020-09-16T07:02:49Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/DatalakeDrClient.java", "diffHunk": "@@ -0,0 +1,105 @@\n+package com.sequenceiq.cloudbreak.datalakedr;\n+\n+import static com.google.common.base.Preconditions.checkNotNull;\n+import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRGrpc.datalakeDRBlockingStub;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.BackupDatalakeStatusRequest;\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto.RestoreDatalakeStatusRequest;\n+import com.sequenceiq.cloudbreak.datalakedr.config.DatalakeDrConfig;\n+import com.sequenceiq.cloudbreak.datalakedr.converter.GrpcStatusResponseToDatalakeDrStatusResponseConverter;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import com.sequenceiq.cloudbreak.grpc.ManagedChannelWrapper;\n+import com.sequenceiq.cloudbreak.grpc.altus.AltusMetadataInterceptor;\n+\n+import io.grpc.ManagedChannel;\n+import io.grpc.ManagedChannelBuilder;\n+\n+import java.util.UUID;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class DatalakeDrClient {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DatalakeDrClient.class);\n+\n+    private final DatalakeDrConfig datalakeDrConfig;\n+\n+    private final GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter;\n+\n+    public DatalakeDrClient(DatalakeDrConfig datalakeDrConfig, GrpcStatusResponseToDatalakeDrStatusResponseConverter statusConverter) {\n+        this.datalakeDrConfig = datalakeDrConfig;\n+        this.statusConverter = statusConverter;\n+    }\n+\n+    public DatalakeDrStatusResponse getBackupStatusByBackupId(String datalakeName, String backupId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(backupId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            BackupDatalakeStatusRequest.Builder builder = BackupDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setBackupId(backupId);\n+\n+            return statusConverter.convert(\n+                newStub(channelWrapper.getChannel(), UUID.randomUUID().toString(), actorCrn)\n+                    .backupDatalakeStatus(builder.build())\n+            );\n+        }\n+    }\n+\n+    public DatalakeDrStatusResponse getRestoreStatusByRestoreId(String datalakeName, String restoreId, String actorCrn) {\n+        checkNotNull(datalakeName);\n+        checkNotNull(actorCrn);\n+        checkNotNull(restoreId);\n+\n+        actorCrn = \"crn:altus:iam:us-west-1:9d74eee4-1cad-45d7-b645-7ccf9edbb73d:user:8d1e890c-8a2e-4cf9-96bd-d50478bc027e\";\n+        datalakeName = \"biglauer-az-dr-4-dl\";\n+\n+        try (ManagedChannelWrapper channelWrapper = makeWrapper()) {\n+            RestoreDatalakeStatusRequest.Builder builder = RestoreDatalakeStatusRequest.newBuilder()\n+                .setDatalakeName(datalakeName);\n+//                .setRestoreId(restoreId);", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489210450", "bodyText": "If we would like to connect one of the cp service then we need changes in dps-k8s repo", "author": "doktoric", "createdAt": "2020-09-16T07:06:59Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "originalCommit": "1fa10da1f38d8d63832c82c2db9dece4995dac39", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTQ5OTE2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489499166", "bodyText": "I have a PR here is to add this config setting in the CSI repo: https://github.infra.cloudera.com/thunderhead/cloud-services-infra/pull/1741. Is that what you mean, or is the dps-k8s repo different?", "author": "hreeve-cloudera", "createdAt": "2020-09-16T14:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwMjc3OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489502779", "bodyText": "The CSI change alone isn't doing anything. If you want to wire up the 2 services you'll need to make changes in CB helm charts: https://github.infra.cloudera.com/thunderhead/dps-k8s/tree/master/cloudbreak/helm-charts/cloudbreak-umbrella/charts", "author": "keyki", "createdAt": "2020-09-16T14:54:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNjQ2OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489506468", "bodyText": "Thanks. I'll look into that now.", "author": "hreeve-cloudera", "createdAt": "2020-09-16T14:59:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDgwNzMyNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r490807325", "bodyText": "I think the colon should be removed and a default value must be included in the application.yaml which points to local mock, because right now it won't start locally", "author": "lacikaaa", "createdAt": "2020-09-18T09:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMDQ1MA=="}], "type": "inlineReview"}, {"oid": "3a029658a9307869a649df016c313b0874cf621e", "url": "https://github.com/hortonworks/cloudbreak/commit/3a029658a9307869a649df016c313b0874cf621e", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-16T14:43:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489507754", "bodyText": "we can not depend on just the getOverallState. Here you need to check the internal states as well.\nIf the overall status could be failed but the internal states could be still in progress.", "author": "kkalvagadda1", "createdAt": "2020-09-16T15:01:14Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );", "originalCommit": "3a029658a9307869a649df016c313b0874cf621e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUxNDU1NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489514554", "bodyText": "My thought there was that if the overall state was failed, but some operations were still in progress, that we no longer had to block the flow. At that point it doesn't matter if something interrupts the b/r operation, because even if the remaining operations succeed, we still end up in a bad state. I'm pretty confident that's true for backup flows. However, I'm not as sure about restore flows. If part of a restore has failed, but there are ongoing operations, would we wind up in a worse position if we interrupted those operations? Or would it not matter because we would have to re-attempt the restore regardless?", "author": "hreeve-cloudera", "createdAt": "2020-09-16T15:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUyODkwNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489528906", "bodyText": "I agree with you with the internal behavior. Why do we want to report that backup-restore operations are complete even when some of the internal operations are still in progress when it can be reported accurately with a simple check?", "author": "kkalvagadda1", "createdAt": "2020-09-16T15:29:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUzNDM3Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489534373", "bodyText": "It's not a question of reporting, it's a question of blocking other flows. If the Solr backup has failed, but the HBase backup is still ongoing, do we want to block other datalake flows until the HBase backup is complete? Or do we want to say that the overall backup has failed, so don't bother waiting for the HBase part to finish and go ahead and unblock the other flows?", "author": "hreeve-cloudera", "createdAt": "2020-09-16T15:36:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQyNjk1MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r490426950", "bodyText": "I'm resolving this conversation because it is likely going to be rendered a moot point but an upcoming change in the datalake-dr service.", "author": "hreeve-cloudera", "createdAt": "2020-09-17T17:15:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzc1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTUwNzg0OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r489507848", "bodyText": "we can not depend on just the getOverallState. Here you need to check the internal states as well.\nIf the overall status could be failed but the internal states could be still in progress.", "author": "kkalvagadda1", "createdAt": "2020-09-16T15:01:22Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/converter/GrpcStatusResponseToDatalakeDrStatusResponseConverter.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package com.sequenceiq.cloudbreak.datalakedr.converter;\n+\n+import com.cloudera.thunderhead.service.datalakedr.datalakeDRProto;\n+import com.sequenceiq.cloudbreak.datalakedr.model.DatalakeDrStatusResponse;\n+import java.util.Optional;\n+import org.springframework.stereotype.Component;\n+\n+@Component\n+public class GrpcStatusResponseToDatalakeDrStatusResponseConverter {\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.BackupDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())\n+        );\n+    }\n+\n+    public DatalakeDrStatusResponse convert(datalakeDRProto.RestoreDatalakeStatusResponse response) {\n+        return new DatalakeDrStatusResponse(\n+            DatalakeDrStatusResponse.State.valueOf(response.getOverallState()),\n+            Optional.ofNullable(response.getFailureReason())", "originalCommit": "3a029658a9307869a649df016c313b0874cf621e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "59f1022b7394770576969bf39b26482f8f02a2ff", "url": "https://github.com/hortonworks/cloudbreak/commit/59f1022b7394770576969bf39b26482f8f02a2ff", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-17T16:19:35Z", "type": "forcePushed"}, {"oid": "9aef76d8f484676a00909f5efa7a5e61784bb83f", "url": "https://github.com/hortonworks/cloudbreak/commit/9aef76d8f484676a00909f5efa7a5e61784bb83f", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-18T15:42:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzMzg3Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491133876", "bodyText": "The value should not have : as it will initialize it with an empty string. All these definitions should present in the application.yamls instead.", "author": "keyki", "createdAt": "2020-09-18T18:54:37Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")", "originalCommit": "9aef76d8f484676a00909f5efa7a5e61784bb83f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491135225", "bodyText": "Does this mean that the application won't start if we're not configuring this endpoint? If that's the case we will need to introduce the datalake dr application in our dev Kubernetes cluster as well along with the local CBD. I would rather create another endpoint to enable/disable this feature so it's not a hard dependency. If it's just not configured then we're skipping some of steps that you do as part of this PR. We do similar things with Cluster Proxy, Public Endpoint Management service and with other external services as well.", "author": "keyki", "createdAt": "2020-09-18T18:57:27Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint:}\")\n+    private String endpoint;\n+\n+    private String host;\n+\n+    private int port;\n+\n+    @PostConstruct\n+    public void init() {\n+        if (isConfigured()) {\n+            String[] parts = endpoint.split(\":\");\n+            if (parts.length < 1 || parts.length > 2) {\n+                throw new IllegalArgumentException(\"altus.datalakedr.endpoint must be in host or host:port format.\");\n+            }\n+            host = parts[0];\n+            port = parts.length == 2\n+                ? Integer.parseInt(parts[1])\n+                : DEFAULT_DATALAKE_DR_PORT;\n+        } else {\n+            throw new IllegalStateException(\"altus.datalakedr.endpoint is not configured\");", "originalCommit": "9aef76d8f484676a00909f5efa7a5e61784bb83f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE2Nzc0Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491167746", "bodyText": "I tried running the CB application and it fails with the endpoint not being set. Probably we should create a datalakedr.enabled variable also with a false default value and safeguard all calls to only make them if it's enabled. As a reference, you can take a look at clusterProxy.enabled var and how it's used.", "author": "keyki", "createdAt": "2020-09-18T20:12:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTE4MDg4MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r491180881", "bodyText": "I've removed the datalake-dr-connector dependency from core/build.gradle. I've also removed the colon from ${altus.datalakedr.endpoint}, included the default value of an empty string in the datalake application.yml file. Finally, I added a new setting altus.datalakedr.enabled that defaults to false if it's not set, and will prevent DatalakeDrConfig from throwing an exception on init() if it's not enabled. Please let me know if that's working for you.", "author": "hreeve-cloudera", "createdAt": "2020-09-18T20:42:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNTIyNQ=="}], "type": "inlineReview"}, {"oid": "7873d98458ec2f0ccfb73fe30aef1fedb3af0de0", "url": "https://github.com/hortonworks/cloudbreak/commit/7873d98458ec2f0ccfb73fe30aef1fedb3af0de0", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-18T20:34:47Z", "type": "forcePushed"}, {"oid": "8eade0d6948ce8efcb727d62890fdd9fc4cce847", "url": "https://github.com/hortonworks/cloudbreak/commit/8eade0d6948ce8efcb727d62890fdd9fc4cce847", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-18T20:41:38Z", "type": "forcePushed"}, {"oid": "686651139f8703f4f723522d9e449ed1752dc6dd", "url": "https://github.com/hortonworks/cloudbreak/commit/686651139f8703f4f723522d9e449ed1752dc6dd", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-18T21:00:39Z", "type": "forcePushed"}, {"oid": "63f9c788511dbcdf9ba8bcf24d43a792382c77fd", "url": "https://github.com/hortonworks/cloudbreak/commit/63f9c788511dbcdf9ba8bcf24d43a792382c77fd", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-21T18:14:33Z", "type": "forcePushed"}, {"oid": "8e77c5613cb44db169aa8cdf478d9fe0f860a3d3", "url": "https://github.com/hortonworks/cloudbreak/commit/8e77c5613cb44db169aa8cdf478d9fe0f860a3d3", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-21T19:03:13Z", "type": "forcePushed"}, {"oid": "fb2b2c9b36f2fb0b57974370320e317ad5a6721d", "url": "https://github.com/hortonworks/cloudbreak/commit/fb2b2c9b36f2fb0b57974370320e317ad5a6721d", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-21T20:08:58Z", "type": "forcePushed"}, {"oid": "a8802d5b596b77601abaee98d65198491ac47619", "url": "https://github.com/hortonworks/cloudbreak/commit/a8802d5b596b77601abaee98d65198491ac47619", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-21T22:35:27Z", "type": "forcePushed"}, {"oid": "0489294cf968466e376a4a3bda7e44f49d7efe98", "url": "https://github.com/hortonworks/cloudbreak/commit/0489294cf968466e376a4a3bda7e44f49d7efe98", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-22T03:07:35Z", "type": "forcePushed"}, {"oid": "bff9b5233efffe9c5b84e4585cac6c48bfc52150", "url": "https://github.com/hortonworks/cloudbreak/commit/bff9b5233efffe9c5b84e4585cac6c48bfc52150", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-22T03:16:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MDg3Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492540876", "bodyText": "Can you please move the default value to application.yaml?", "author": "keyki", "createdAt": "2020-09-22T07:57:16Z", "path": "datalake-dr-connector/src/main/java/com/sequenceiq/cloudbreak/datalakedr/config/DatalakeDrConfig.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package com.sequenceiq.cloudbreak.datalakedr.config;\n+\n+import javax.annotation.PostConstruct;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.context.annotation.Configuration;\n+\n+@Configuration\n+public class DatalakeDrConfig {\n+\n+    private static final int DEFAULT_DATALAKE_DR_PORT = 80;\n+\n+    @Value(\"${altus.datalakedr.endpoint}\")\n+    private String endpoint;\n+\n+    @Value(\"${altus.datalakedr.enabled:false}\")", "originalCommit": "bff9b5233efffe9c5b84e4585cac6c48bfc52150", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjgyNzEwMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/9020#discussion_r492827102", "bodyText": "Done.", "author": "hreeve-cloudera", "createdAt": "2020-09-22T15:24:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjU0MDg3Ng=="}], "type": "inlineReview"}, {"oid": "4cd5b8a4bcda85cee27dbf7ccb804ce8f0432db7", "url": "https://github.com/hortonworks/cloudbreak/commit/4cd5b8a4bcda85cee27dbf7ccb804ce8f0432db7", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-22T15:23:16Z", "type": "forcePushed"}, {"oid": "617680f35449482ac49672f70bddfb54c7cc573c", "url": "https://github.com/hortonworks/cloudbreak/commit/617680f35449482ac49672f70bddfb54c7cc573c", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-22T15:31:12Z", "type": "forcePushed"}, {"oid": "402d7dc44fc4ad73f2c4bddad86a7d28e87745cc", "url": "https://github.com/hortonworks/cloudbreak/commit/402d7dc44fc4ad73f2c4bddad86a7d28e87745cc", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-23T15:16:17Z", "type": "commit"}, {"oid": "402d7dc44fc4ad73f2c4bddad86a7d28e87745cc", "url": "https://github.com/hortonworks/cloudbreak/commit/402d7dc44fc4ad73f2c4bddad86a7d28e87745cc", "message": "CB-8717 Add thunderhead datalake-dr service connector\n\nAdds the datalakedr client to CB so the datalake backup/restore flows can query\nthe datalake-dr service for the status of the full backup. Previously CB was\nonly aware of the status of the database backup, and could not track the HBase\nand Solr backups that were happening simultaneously.\n\nTested with unit tests, and by running CB locally and connecting to the\ndatalake-dr service on mow-dev.", "committedDate": "2020-09-23T15:16:17Z", "type": "forcePushed"}]}