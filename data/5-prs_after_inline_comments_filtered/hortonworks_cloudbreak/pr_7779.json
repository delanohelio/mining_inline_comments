{"pr_number": 7779, "pr_title": "CB-5736 load based monitors evaulators", "pr_createdAt": "2020-04-13T19:23:35Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/7779", "timeline": [{"oid": "2c2a022a4d52c54977ea8121a11675cc45e2db5e", "url": "https://github.com/hortonworks/cloudbreak/commit/2c2a022a4d52c54977ea8121a11675cc45e2db5e", "message": "CB-5734 DistroX Autoscaling API\n\nIntroduce DistroX Autoscaling API.\nSupports Time Based and Load Based Alerts.", "committedDate": "2020-04-13T19:29:23Z", "type": "commit"}, {"oid": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "url": "https://github.com/hortonworks/cloudbreak/commit/2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-13T19:29:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNDUwOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408624509", "bodyText": "Doesn't seem to be used anywhere?", "author": "sidseth", "createdAt": "2020-04-15T07:06:46Z", "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/doc/ApiDescription.java", "diffHunk": "@@ -121,6 +121,10 @@\n         public static final String SCALING_CONFIGURATION = \"Scaling configuration for the cluster\";\n     }\n \n+    public static class DistroXClusterJsonsProperties {\n+        public static final String DISTROX_SCALING_MODE = \"Scaling Types supported for distrox clusters\";", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTMzNDAyNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409334026", "bodyText": "ack", "author": "smaniraju", "createdAt": "2020-04-16T07:19:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNDUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNjA2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408626066", "bodyText": "Would be a little careful with this (logging the response vs just the time). Can blow up the logs (at DEBUG level). Also, have to make sure there's no sensitive information in any of the Responses.", "author": "sidseth", "createdAt": "2020-04-15T07:10:02Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/aspects/RequestLogging.java", "diffHunk": "@@ -11,10 +11,16 @@\n \n     private static final Logger LOGGER = LoggerFactory.getLogger(RequestLogging.class);\n \n-    public <T> T logging(Supplier<T> callback, String requestName) {\n+    public <T> T logResponse(Supplier<T> callback, String requestName) {\n         long start = System.currentTimeMillis();\n-        T o = callback.get();\n-        LOGGER.debug(\"Ambari '{}' finished in {} ms\", requestName, System.currentTimeMillis() - start);\n-        return o;\n+        T response = callback.get();\n+        LOGGER.debug(\"Request '{}' finished in {} ms, Response {}\", requestName, System.currentTimeMillis() - start, response);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM0Mzc2Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409343762", "bodyText": "Updated to log only non sensitive information based on response type. In interaction with other services this response metadata is required otherwise it is very difficult to identify production issues. Logs can be rotated and purged. I think kibana can handle log purge effectively. Also changed logging this to \"info\" from \"debug\" since this would be needed in production issues..", "author": "smaniraju", "createdAt": "2020-04-16T07:37:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNjA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg5NTkzMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409895932", "bodyText": "INFO level for all YARN responses is far too much logging. With multiple clusters, and pulling data every 15odd seconds (when the windowing approach is used) - this will generate a ton of logging.\nCan we summarize the results from YARN into a much shorter log message, if this is absolutely required for debugging? Otherwise debug level is better.", "author": "sidseth", "createdAt": "2020-04-16T22:57:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNjA2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA2MjM4OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410062388", "bodyText": "yes i have over-riden tostring method of these dto to include absolute minimum fields.", "author": "smaniraju", "createdAt": "2020-04-17T08:10:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNjA2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTg1Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408629857", "bodyText": "This seems to be in 'minutes' - as per LoadAlertConfiguration variable naming. 30 seems a little too much. Maybe a 2 minute default? and rename param to include the unit.", "author": "sidseth", "createdAt": "2020-04-15T07:17:47Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/Cluster.java", "diffHunk": "@@ -29,6 +29,12 @@\n @Entity\n public class Cluster implements Monitored, Clustered {\n \n+    public static final int DEFAULT_HOSTGROUP_MIN_SIZE = 1;\n+\n+    public static final int DEFAULT_HOSTGROUP_MAX_SIZE = 50;\n+\n+    public static final int DEFAULT_HOSTGROUP_COOL_DOWN = 30;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM1NjY4MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409356681", "bodyText": "removed these default related to cooldown.", "author": "smaniraju", "createdAt": "2020-04-16T07:58:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTg1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMDY2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408630667", "bodyText": "Not sure why these 2 defaults are required? min and max are mandatory parameters while registering a LoadAlert, correct?", "author": "sidseth", "createdAt": "2020-04-15T07:19:18Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/Cluster.java", "diffHunk": "@@ -29,6 +29,12 @@\n @Entity\n public class Cluster implements Monitored, Clustered {\n \n+    public static final int DEFAULT_HOSTGROUP_MIN_SIZE = 1;\n+\n+    public static final int DEFAULT_HOSTGROUP_MAX_SIZE = 50;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM0ODYzOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409348639", "bodyText": "These are required for other types of scaling like based on percentage. Have removed these from LoadAlert Definition.", "author": "smaniraju", "createdAt": "2020-04-16T07:45:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMDY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMTc2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408631766", "bodyText": "Same as comment above. Can the defaults be skipped, since these values must be specified.", "author": "sidseth", "createdAt": "2020-04-15T07:21:25Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/LoadAlertConfiguration.java", "diffHunk": "@@ -1,12 +1,15 @@\n package com.sequenceiq.periscope.domain;\n \n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n public class LoadAlertConfiguration {\n \n-    private Integer minResourceValue;\n+    private Integer minResourceValue = Cluster.DEFAULT_HOSTGROUP_MIN_SIZE;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzgyNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408633826", "bodyText": "Nit: TimeUnit.MILLISECONDS.convert(coolDownMinutes, TimeUnit.MINUTES)", "author": "sidseth", "createdAt": "2020-04-15T07:25:15Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/LoadAlertConfiguration.java", "diffHunk": "@@ -28,6 +31,11 @@ public Integer getCoolDownMinutes() {\n         return coolDownMinutes;\n     }\n \n+    @JsonIgnore\n+    public Long getCoolDownMillis() {\n+        return coolDownMinutes  * TimeUtil.MIN_IN_MS;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM1Nzg1OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409357858", "bodyText": "ok", "author": "smaniraju", "createdAt": "2020-04-16T08:00:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMzgyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNjAzMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408636032", "bodyText": "These are used to deserialize the response from YARN?\nWOuld it make sense to ask YARN to provide a Swagger spec, and generate code from that?", "author": "sidseth", "createdAt": "2020-04-15T07:29:27Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/model/yarn/NewNodeManagerCandidates.java", "diffHunk": "@@ -0,0 +1,67 @@\n+package com.sequenceiq.periscope.model.yarn;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnore;\n+\n+public class NewNodeManagerCandidates {", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2Mjk5OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409362998", "bodyText": "they didnt have a swagger spec can be taken as a seperate jira when they provide.", "author": "smaniraju", "createdAt": "2020-04-16T08:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNjAzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTM3NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408641375", "bodyText": "This isn't a fixed name. It is set to 'compute' in our default template, but could be set to anything.\nRef the discussion in today's call about how relying on the hostname (derived from hostgroup) is temporary.\nI believe this needs to be a check on components for the hostgroup - which becomes relevant when HBase comes in. For now skip the check?", "author": "sidseth", "createdAt": "2020-04-15T07:39:21Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/LoadMonitor.java", "diffHunk": "@@ -0,0 +1,50 @@\n+package com.sequenceiq.periscope.monitor;\n+\n+import java.util.List;\n+\n+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.common.StackType;\n+import com.sequenceiq.periscope.api.model.ClusterState;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.load.YarnLoadEvaluator;\n+\n+@Component\n+@ConditionalOnProperty(prefix = \"periscope.enabledAutoscaleMonitors.load-monitor\", name = \"enabled\", havingValue = \"true\")\n+public class LoadMonitor extends ClusterMonitor {\n+\n+    @Override\n+    public String getIdentifier() {\n+        return \"load-monitor\";\n+    }\n+\n+    @Override\n+    public String getTriggerExpression() {\n+        return MonitorUpdateRate.EVERY_MIN_RATE_CRON;\n+    }\n+\n+    @Override\n+    public Class<? extends EvaluatorExecutor> getEvaluatorType(Cluster cluster) {\n+        return getLoadEvaluatorForCluster(cluster);\n+    }\n+\n+    @Override\n+    protected List<Cluster> getMonitored() {\n+        List<Long> clusterIds = getClusterService().findLoadAlertClustersForNode(StackType.WORKLOAD,\n+                ClusterState.RUNNING, true, getPeriscopeNodeConfig().getId());\n+        return clusterIds.isEmpty() ? List.of() : getClusterService().findClustersByClusterIds(clusterIds);\n+    }\n+\n+    protected Class<? extends EvaluatorExecutor> getLoadEvaluatorForCluster(Cluster cluster) {\n+        String policyHostGroup = cluster.getLoadAlerts().stream().findFirst()\n+                .get().getScalingPolicy().getHostGroup().toLowerCase();\n+\n+        switch (policyHostGroup) {\n+            case \"compute\":", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2Mzk0Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409363947", "bodyText": "yes we can add support based on services. there is a seperate jira for that.", "author": "smaniraju", "createdAt": "2020-04-16T08:10:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTM3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTk0Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408641947", "bodyText": "Will this ever be disabled?", "author": "sidseth", "createdAt": "2020-04-15T07:40:17Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/RejectedThreadMonitor.java", "diffHunk": "@@ -17,6 +18,7 @@\n import com.sequenceiq.periscope.monitor.evaluator.ClusterCreationEvaluator;\n \n @Component\n+@ConditionalOnProperty(prefix = \"periscope.enabledAutoscaleMonitors.rejected-thread-monitor\", name = \"enabled\", havingValue = \"true\")", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2NTQ4OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409365489", "bodyText": "Dont think so, can remove the ConditionalOnProperty", "author": "smaniraju", "createdAt": "2020-04-16T08:13:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MTk0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MzE2Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408643163", "bodyText": "Initial plan is memory only. YARN CPU scheduling is not enforced (likely see available CPUs go negative on the YARN UI), and Tez etc are not set up very well to handle cpu scheduling.", "author": "sidseth", "createdAt": "2020-04-15T07:42:38Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package com.sequenceiq.periscope.monitor.client;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.client.Client;\n+import javax.ws.rs.client.Entity;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.client.RestClientUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.model.TlsConfiguration;\n+import com.sequenceiq.periscope.model.yarn.HostGroupInstanceType;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Request;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.service.MachineUserService;\n+import com.sequenceiq.periscope.service.configuration.CloudInstanceTypeService;\n+import com.sequenceiq.periscope.service.configuration.ClusterProxyConfigurationService;\n+import com.sequenceiq.periscope.service.security.TlsSecurityService;\n+\n+@Component\n+public class YarnMetricsClient {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnMetricsClient.class);\n+\n+    private static final String YARN_API_URL = \"%s/proxy/%s/resourcemanager/v1/cluster/scaling\";\n+\n+    private static final String HEADER_ACTOR_CRN = \"x-cdp-actor-crn\";\n+\n+    private static final String PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE = \"upscaling-factor-in-node-resource-types\";\n+\n+    private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb,vcore\";", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM2NjA2MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409366061", "bodyText": "ack", "author": "smaniraju", "createdAt": "2020-04-16T08:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MzE2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0NDI2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408644267", "bodyText": "Where would Exceptions like this end up in a running Periscope system?", "author": "sidseth", "createdAt": "2020-04-15T07:44:29Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/client/YarnMetricsClient.java", "diffHunk": "@@ -0,0 +1,93 @@\n+package com.sequenceiq.periscope.monitor.client;\n+\n+import java.util.List;\n+import java.util.Optional;\n+\n+import javax.inject.Inject;\n+import javax.ws.rs.client.Client;\n+import javax.ws.rs.client.Entity;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.http.MediaType;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.client.RestClientUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.model.TlsConfiguration;\n+import com.sequenceiq.periscope.model.yarn.HostGroupInstanceType;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Request;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.service.MachineUserService;\n+import com.sequenceiq.periscope.service.configuration.CloudInstanceTypeService;\n+import com.sequenceiq.periscope.service.configuration.ClusterProxyConfigurationService;\n+import com.sequenceiq.periscope.service.security.TlsSecurityService;\n+\n+@Component\n+public class YarnMetricsClient {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnMetricsClient.class);\n+\n+    private static final String YARN_API_URL = \"%s/proxy/%s/resourcemanager/v1/cluster/scaling\";\n+\n+    private static final String HEADER_ACTOR_CRN = \"x-cdp-actor-crn\";\n+\n+    private static final String PARAM_UPSCALE_FACTOR_NODE_RESOURCE_TYPE = \"upscaling-factor-in-node-resource-types\";\n+\n+    private static final String DEFAULT_UPSCALE_RESOURCE_TYPE = \"memory-mb,vcore\";\n+\n+    @Inject\n+    private MachineUserService machineUserService;\n+\n+    @Inject\n+    private TlsSecurityService tlsSecurityService;\n+\n+    @Inject\n+    private ClusterProxyConfigurationService clusterProxyConfigurationService;\n+\n+    @Inject\n+    private CloudInstanceTypeService cloudInstanceTypeService;\n+\n+    @Inject\n+    private RequestLogging requestLogging;\n+\n+    public YarnScalingServiceV1Response getYarnMetricsForCluster(Cluster cluster,\n+            String hostGroupInstanceType,\n+            CloudPlatform cloudPlatform) throws Exception {\n+\n+        TlsConfiguration tlsConfig = tlsSecurityService.getTls(cluster.getId());\n+        Optional<String> clusterProxyUrl = clusterProxyConfigurationService.getClusterProxyUrl();\n+        if (!clusterProxyUrl.isPresent() || !cluster.getTunnel().useClusterProxy()) {\n+            String msg = String.format(\"ClusterProxy Not Configured for Cluster {}, cannot query YARN Metrics.\", cluster.getStackCrn());\n+            throw new RuntimeException(msg);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDIyMDg5Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410220892", "bodyText": "It would trigger a UpdateFailedEvent and handled in UpdateFailedHandler.", "author": "smaniraju", "createdAt": "2020-04-17T13:26:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0NDI2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1MzU3Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408653573", "bodyText": "From testing, this is fairly quick, correct?", "author": "sidseth", "createdAt": "2020-04-15T08:00:48Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2ODc3NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409468775", "bodyText": "local testing it is pretty quick.", "author": "smaniraju", "createdAt": "2020-04-16T11:00:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1MzU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NDM1NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408654355", "bodyText": "Can more context be sent along with this event. What caused the failrue? (Inability to talk to YARN, something else)", "author": "sidseth", "createdAt": "2020-04-15T08:02:13Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM3NDMxOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409374318", "bodyText": "the exception is logged already which includes information like YARN unavailable or YARN 500 error, UpdateFailedEvent is used to handle other flow like tracking successive failures.", "author": "smaniraju", "createdAt": "2020-04-16T08:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NDM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg5ODc1OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409898758", "bodyText": "eventPublished.publishEvent() ... is this what would eventually end up showing information on the 'Activities' page on the cluster UI?, or even to fetch scaling activity via the CLI?\nIf that is the case, it will be useful to have at least some information (Exception name, Exception message) to help with debugging without having to hunt through logs.", "author": "sidseth", "createdAt": "2020-04-16T23:05:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NDM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDIyMDM1MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410220351", "bodyText": "ScaleUp\\ScaleDown history on UI is not from periscope, that is shown from CB itself.", "author": "smaniraju", "createdAt": "2020-04-17T13:26:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NDM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NjQ1Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408656453", "bodyText": "As a future enhancement, we likely need to introduce a parameter which indicates how many nodes we will add in 1 iteration.\ne.g. if YARN says add 200 nodes (which is within max node count) - we should not attempt to add 200 nodes in 1 invocation. Instead add 50. Nexy upscale can add the next 50 and so on.", "author": "sidseth", "createdAt": "2020-04-15T08:06:01Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM3NDQ5MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409374490", "bodyText": "ok.", "author": "smaniraju", "createdAt": "2020-04-16T08:27:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NjQ1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg5ODk4Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409898987", "bodyText": "Also noticed that this is already covered somewhere in the Cloudbreak flow. Think the default is 100 at a time.", "author": "sidseth", "createdAt": "2020-04-16T23:06:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1NjQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1OTI0Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408659242", "bodyText": "This does not belong here, even as a transient entity.\nThink it is better to change the event that is being published to contain any dynamic information of this kind.\nSo instead of sending the BaseAlert in the SaclingEvent - send a new entity, which could internally contain the BaseAlert if required, but is more focussed on what scaling action needs to be taken. (decomissionNodeIds, newNodeCount, etc)", "author": "sidseth", "createdAt": "2020-04-15T08:11:08Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/domain/BaseAlert.java", "diffHunk": "@@ -32,6 +35,9 @@\n     @OneToOne(cascade = CascadeType.ALL, orphanRemoval = true)\n     private ScalingPolicy scalingPolicy;\n \n+    @Transient\n+    private List<String> decommissionNodeIds;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM5MTIyMQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409391221", "bodyText": "yes this belong to ScalingEvent, so moved it to ScalingEvent itself.", "author": "smaniraju", "createdAt": "2020-04-16T08:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY1OTI0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTQwMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408661400", "bodyText": "How efficient / inefficient is this approach? i.e. will it end up iterating over the same lists multiple times over (including string split, etc) for different nodes which need to be removed?", "author": "sidseth", "createdAt": "2020-04-15T08:14:52Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQyMzMyNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409423326", "bodyText": "new streams are produced at result generation steps like filter, map and  there will not be observable perf difference unless the list size is in 10000s. also streams processing has become standard list processing mechanism.", "author": "smaniraju", "createdAt": "2020-04-16T09:43:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTQwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTU3Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408661576", "bodyText": "See comment in BaseAlert.", "author": "sidseth", "createdAt": "2020-04-15T08:15:11Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n+                .filter(s -> hostGroupFqdns.contains(s))\n+                .limit(maxAllowedScaleDown)\n+                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .collect(Collectors.toList());\n+\n+        LOGGER.info(\"ScaleDown NodeCount {} for Cluster {}, HostGroup {], NodeIds {}\",\n+                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n+                decommissionHostGroupNodeIds);\n+\n+        if (!decommissionHostGroupNodeIds.isEmpty()) {\n+            loadAlert.setDecommissionNodeIds(decommissionHostGroupNodeIds);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2NzQyMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409467423", "bodyText": "moved it to the scalingevent.", "author": "smaniraju", "createdAt": "2020-04-16T10:57:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2MTU3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2OTYwNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408669606", "bodyText": "Why remove the final?", "author": "sidseth", "createdAt": "2020-04-15T08:28:39Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/utils/ClusterUtils.java", "diffHunk": "@@ -2,12 +2,16 @@\n \n import java.text.DecimalFormat;\n \n-public final class ClusterUtils {\n+public class ClusterUtils {", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2Nzk1Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409467956", "bodyText": "added back", "author": "smaniraju", "createdAt": "2020-04-16T10:58:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY2OTYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r408674068", "bodyText": "Can the CB returned instance types be used directly? Why define them again in Periscope.\nAlternately, if a library exists which can do this conversion - Periscope can rely on the DB entry directly.", "author": "sidseth", "createdAt": "2020-04-15T08:35:59Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/service/configuration/CloudInstanceTypeService.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package com.sequenceiq.periscope.service.configuration;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.PostConstruct;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.stereotype.Component;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.sequenceiq.cloudbreak.client.CloudbreakInternalCrnClient;\n+import com.sequenceiq.cloudbreak.common.json.JsonUtil;\n+import com.sequenceiq.cloudbreak.common.mappable.CloudPlatform;\n+import com.sequenceiq.cloudbreak.service.CloudbreakResourceReaderService;\n+import com.sequenceiq.periscope.model.CloudInstanceType;\n+import com.sequenceiq.periscope.utils.FileReaderUtils;\n+\n+@Component\n+public class CloudInstanceTypeService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(FileReaderUtils.class);\n+\n+    @Inject\n+    private CloudbreakResourceReaderService cloudbreakResourceReaderService;\n+\n+    @Inject\n+    private CloudbreakInternalCrnClient internalCrnClient;\n+\n+    private Map<String, CloudInstanceType> awsInstanceTypes = new HashMap<>();\n+\n+    private Map<String, CloudInstanceType> azureInstanceTypes = new HashMap<>();\n+\n+    @PostConstruct\n+    public void init() {\n+        readCloudInstanceTypes(\"aws\", awsInstanceTypes);\n+        readCloudInstanceTypes(\"azure\", azureInstanceTypes);\n+    }\n+\n+    public Optional<CloudInstanceType> getCloudVMInstanceType(CloudPlatform cloudPlatform, String hostGroupInstanceType) {\n+        CloudInstanceType cloudVmType;\n+        switch (cloudPlatform) {\n+            case AWS:\n+                cloudVmType = awsInstanceTypes.get(hostGroupInstanceType);\n+                break;\n+            case AZURE:\n+                cloudVmType = azureInstanceTypes.get(hostGroupInstanceType);\n+                break;\n+            default:\n+                cloudVmType = null;\n+        }\n+        return Optional.ofNullable(cloudVmType);\n+    }\n+\n+    private void readCloudInstanceTypes(String cloudPlatform, Map<String, CloudInstanceType> vmInstanceTypes) {\n+        try {\n+            String cloudInstanceTypeConfig = cloudbreakResourceReaderService.resourceDefinition(cloudPlatform, \"vm\");\n+\n+            TypeReference<HashMap<String, Set<CloudInstanceType>>> typeRef = new TypeReference<>() { };\n+            Set<CloudInstanceType> cloudInstanceTypes = JsonUtil.readValue(cloudInstanceTypeConfig, typeRef).get(\"items\");\n+\n+            for (CloudInstanceType cloudInstanceType : cloudInstanceTypes) {\n+                vmInstanceTypes.put(cloudInstanceType.getInstanceName(), cloudInstanceType);\n+            }\n+\n+            Set<String> configuredCloudInstances = cloudInstanceTypes.stream().map(CloudInstanceType::getInstanceName).collect(Collectors.toSet());\n+            Set<String> cbSupportedInstances = internalCrnClient.withInternalCrn()", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQzMjk3Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409432977", "bodyText": "commented above. I dont think this is required in DB, it is stored in resourcedefinitions, so that it can be easily updated without generating sql.", "author": "smaniraju", "createdAt": "2020-04-16T09:58:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxMjI0Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409912242", "bodyText": "Sorry. I meant the Cloudbreak DB. So specifically.\n\nAn instance type is retrieved from the hostgroup info in the Cloudbreak DB.\nPeriscope uses a library (which at the moment is backed by aws-, azure-*.json in the repo).\nThe intent being never to talk to Cloudbreak.\n\nThat is pretty much the case already. This communication to Cloudbreak to fetch instance types is only for error checking.\nOn the error checking - I think it makes sense to get Periscope to crash if information is not available for an instance type. That forces errors to be caught early.\nIf this will be maintained as these json files with look up - I think we should actually add an Integration test which ensures that what CB supports and Periscope knows about match, to fail even earlier. (Integration test is a follow up jira).", "author": "sidseth", "createdAt": "2020-04-16T23:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA2NTA3MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410065071", "bodyText": "agree created jira for integration test. i didnt crash periscope on error checking since in that case, periscope will never start if cloudbreak is not running. agree enabling integration testing is the correct approach here. will create a jira for that.", "author": "smaniraju", "createdAt": "2020-04-17T08:15:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjYyODAxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r412628019", "bodyText": "Makes sense.", "author": "sidseth", "createdAt": "2020-04-22T02:44:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY3NDA2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIyODk1OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409228958", "bodyText": "Not needed any more.", "author": "sidseth", "createdAt": "2020-04-16T01:34:14Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ1ODU2MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409458560", "bodyText": "removed", "author": "smaniraju", "createdAt": "2020-04-16T10:41:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIyODk1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzMTE2Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409231167", "bodyText": "Is there, by any chance, an alternate mechanism to fetch information like #hosts in a stack, without pulling information about the entire stack. Suspect this is a large amount of data being pulled, and not sure what load it puts on the Cloudbreak database.", "author": "sidseth", "createdAt": "2020-04-16T01:42:16Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/CloudbreakCommunicator.java", "diffHunk": "@@ -1,20 +1,36 @@\n package com.sequenceiq.periscope.monitor.handler;\n \n+import java.util.List;\n+\n import javax.inject.Inject;\n \n import org.springframework.stereotype.Service;\n \n import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n import com.sequenceiq.cloudbreak.client.CloudbreakInternalCrnClient;\n+import com.sequenceiq.periscope.aspects.RequestLogging;\n+import com.sequenceiq.periscope.domain.Cluster;\n \n @Service\n public class CloudbreakCommunicator {\n \n     @Inject\n     private CloudbreakInternalCrnClient cloudbreakInternalCrnClient;\n \n+    @Inject\n+    private RequestLogging requestLogging;\n+\n     public StackV4Response getByCrn(String stackCrn) {\n         return cloudbreakInternalCrnClient.withInternalCrn().autoscaleEndpoint().get(stackCrn);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ1OTQ0OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409459449", "bodyText": "can track it as a separate jira to remove the unwanted data in stack response.", "author": "smaniraju", "createdAt": "2020-04-16T10:43:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzMTE2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNDMyMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409234322", "bodyText": "Nit:\ns/nodeIds(s)/nodeId(s).\nAlso '{}' instead of {}.\nAlong with this, could we also publish the count of how many nodes were to be removed. Likewise in the message sent to History.", "author": "sidseth", "createdAt": "2020-04-16T01:53:36Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -139,7 +152,31 @@ private void scaleDown(int scalingAdjustment, int totalNodes) {\n             scalingStatus = ScalingStatus.FAILED;\n             metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_FAILED);\n             statusReason = \"Couldn't trigger downscaling due to: \" + e.getMessage();\n-            LOGGER.info(statusReason, e);\n+            LOGGER.info(\"Couldn't trigger downscaling for host group '{}', cluster '{}', error '{}' \",\n+                    hostGroup, cluster.getStackCrn(), e);\n+        } finally {\n+            createHistoryAndNotify(totalNodes, statusReason, scalingStatus);\n+        }\n+    }\n+\n+    private void scaleDownByNodeIds(List<String> decommissionNodeIds) {\n+        metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_TRIGGERED);\n+        String hostGroup = policy.getHostGroup();\n+        String statusReason = null;\n+        ScalingStatus scalingStatus = null;\n+        try {\n+            LOGGER.debug(\"Sending request to remove  nodeIds(s) {} from host group '{}', cluster '{}' \",\n+                    decommissionNodeIds, hostGroup, cluster.getStackCrn());\n+            cloudbreakCommunicator.decommissionInstancesForCluster(cluster, decommissionNodeIds);\n+            scalingStatus = ScalingStatus.SUCCESS;\n+            statusReason = \"Downscale successfully triggered\";\n+            metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_SUCCESSFUL);\n+        } catch (Exception e) {\n+            scalingStatus = ScalingStatus.FAILED;\n+            metricService.incrementMetricCounter(MetricType.CLUSTER_DOWNSCALE_FAILED);\n+            statusReason = \"Couldn't trigger downscaling due to: \" + e.getMessage();\n+            LOGGER.info(\"Couldn't trigger downscaling to remove  nodeIds(s) {} from host group '{}', cluster '{}', error '{}' \",", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2MTI4OQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409461289", "bodyText": "updated log message, to history node count is already sent.", "author": "smaniraju", "createdAt": "2020-04-16T10:46:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNDMyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxMzA2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409913066", "bodyText": "Still think a node count will be useful in the log message as well..", "author": "sidseth", "createdAt": "2020-04-16T23:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNDMyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA3NjE1MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410076151", "bodyText": "added", "author": "smaniraju", "createdAt": "2020-04-17T08:36:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNDMyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNTIwNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409235205", "bodyText": "Is this needed? Isn't the stack CRN already available?", "author": "sidseth", "createdAt": "2020-04-16T01:56:42Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -92,7 +102,8 @@ private void scaleUp(int scalingAdjustment, int totalNodes) {\n         String statusReason = null;\n         ScalingStatus scalingStatus = null;\n         try {\n-            LOGGER.debug(\"Sending request to add {} instance(s) into host group '{}', triggered policy '{}'\", scalingAdjustment, hostGroup, policy.getName());\n+            LOGGER.debug(\"Sending request to add {} instance(s) into host group '{}', triggered policy '{}', cluster '{}'\",\n+                    scalingAdjustment, hostGroup, policy.getName(), cluster.getStackCrn());\n             String stackCrn = internalCrnClient.withInternalCrn().autoscaleEndpoint().getStackForAmbari(ambariAddressJson).getCrn();", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2MzAxNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409463016", "bodyText": "it is not required, not sure why it was added earlier, i have removed the endpoint call.", "author": "smaniraju", "createdAt": "2020-04-16T10:49:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNTIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409237025", "bodyText": "This will be triggered in case of TimeAlerts. Will eventually have to change that over to work with the YARN API as well - so that nodes are not removed randomly. Separate jira / patch.", "author": "sidseth", "createdAt": "2020-04-16T02:03:25Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingRequest.java", "diffHunk": "@@ -56,21 +60,27 @@\n     @Inject\n     private PeriscopeMetricService metricService;\n \n-    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount) {\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    public ScalingRequest(Cluster cluster, ScalingPolicy policy, int totalNodes, int desiredNodeCount, List<String> decommissionNodeIds) {\n         this.cluster = cluster;\n         this.policy = policy;\n         this.totalNodes = totalNodes;\n         this.desiredNodeCount = desiredNodeCount;\n+        this.decommissionNodeIds = decommissionNodeIds;\n     }\n \n     @Override\n     public void run() {\n         MDCBuilder.buildMdcContext(cluster);\n         try {\n             int scalingAdjustment = desiredNodeCount - totalNodes;\n-            if (scalingAdjustment > 0) {\n+            if (!decommissionNodeIds.isEmpty()) {\n+                scaleDownByNodeIds(decommissionNodeIds);\n+            } else if (scalingAdjustment > 0) {\n                 scaleUp(scalingAdjustment, totalNodes);\n-            } else {\n+            } else if (scalingAdjustment < 0) {", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzODY0Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409238647", "bodyText": "Also, I suspect this gets triggered if the cluster has somehow managed to go above the maximum size. e.g. the max node count is reconfigured.", "author": "sidseth", "createdAt": "2020-04-16T02:09:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2Mzc5NQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409463795", "bodyText": "This is basically for TimeAlerts.", "author": "smaniraju", "createdAt": "2020-04-16T10:51:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxMzM4NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409913384", "bodyText": "Also for the change in 'max-nodes' scenario?", "author": "sidseth", "createdAt": "2020-04-16T23:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDA3ODk3Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410078977", "bodyText": "I purposefully did not downscale when the cluster has somehow gone above maximum size which was caught in my unit testing, because in this case the user might have scale up cluster manually and if autoscale reduces the node size it will override the user which i felt is not expected behaviour of autoscaling and loadbased autoscaling should work with the policy limits defined and based on yarnrecommendations which has insight into load on cluster.", "author": "smaniraju", "createdAt": "2020-04-17T08:41:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjYzMDY5NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r412630694", "bodyText": "That is an interesting point. Think we need a little more discussion on what the behaviour should be here.\nAs an end user, if I scale up a cluster manually beyond maxNodes\n\nIf there is no load on the cluster, it will be scaled down immediately - nullifying the scale up. (e.g. scale up manually to submit a large job)\nIf there a load on the cluster already, it will not be scaled down to maxNodes.\nI think it is fair to keep the cluster between minNodes and maxNodes if AutoScaling is enabled. If a user wants to change something - disable the policy and scale to whatever size is needed.", "author": "sidseth", "createdAt": "2020-04-22T02:53:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzNzAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409239266", "bodyText": "Check min/max node count constraints first? If this gets reconfigured - then how the YARN response is processed may need to be re-evaluated.\ne.g. cluster at 20 nodes. Max reconfigured to 10. YARN replies with 'need more resources'.\nLooks like scaleUp handles this - except for bringing the node count down to the maxValue.\nCould be a follow up jira as well, since you have already tested this.", "author": "sidseth", "createdAt": "2020-04-16T02:11:46Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ2NTc3Mg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409465772", "bodyText": "yes this is handled in scaleUp which is more real time.", "author": "smaniraju", "createdAt": "2020-04-16T10:54:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNDMyMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409914322", "bodyText": "Bringing the nodeCount down to a dynamically configured 'maxValue' isn't handled from what I can tell.\nYARN could end up recommending adding new nodes. maxNodes has been reduced by the end user. This will trigger scaleUp since YARN has a net positive node recommendation.\nscaleUp doesn't trigger a reduction in size.", "author": "sidseth", "createdAt": "2020-04-16T23:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDEwMjYxNQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410102615", "bodyText": "the time difference between retrieving latest load alert from db and triggering the scale up\\down is just a few milli-seconds ( time taken by yarn api), I didn't make another db hit to get the latest max configured value since this interval is very small and saves one more db hit.  the 'maxValue' can be reconfigured few ms after triggering periscope scaleUpEvent in YarnLoadEvaluator or few ms after sending request to CB even in that case scaleUp would go through.\nHowever in the next evaluation cycle, if yarn doesnt recommend any decommissionNodes and the policy has maxValue which is lesser than currentHostGroup size, if we trigger down scaling it will be forced downscaling, since yarn hasn't really found unused capacity. I dont think this would be expected behaviour because we are taking away required capacity. It will be downscaled automatically when yarn observes reduced load which i think is inline with the eventually consistent nature of autoscaling. I think this would also ensure less aggressive downscaling.", "author": "smaniraju", "createdAt": "2020-04-17T09:24:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjYzMTEyMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r412631122", "bodyText": "Same as above comment.", "author": "sidseth", "createdAt": "2020-04-22T02:54:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTIzOTI2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MTU5MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409241591", "bodyText": "Removing this check - does it affect the evaluators other than the YarnLoadEvaluator? YarnLoadEvaluator performs this check itself. The others do not - so may end up triggering way more events?", "author": "sidseth", "createdAt": "2020-04-16T02:20:24Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;\n \n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n     @Override\n     public void onApplicationEvent(ScalingEvent event) {\n         BaseAlert alert = event.getAlert();\n         Cluster cluster = clusterService.findById(alert.getCluster().getId());\n         MDCBuilder.buildMdcContext(cluster);\n-        scale(cluster, alert.getScalingPolicy());\n+        handleClusterScaling(cluster, alert);\n     }\n \n-    private void scale(Cluster cluster, ScalingPolicy policy) {\n-        long remainingTime = getRemainingCooldownTime(cluster);", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ3MTYxMw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409471613", "bodyText": "This actually doesnt belong here, since this just handles the event generated. The check should be done before sending the scalingevent. Currently it applies only to LoadEvaluator, since TimeBased Alert has to be applied at the scheduled time.", "author": "smaniraju", "createdAt": "2020-04-16T11:06:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MTU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNDY5MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409914691", "bodyText": "Metrics and Proemetheus, if they are enabled, will end up breaking. Mind putting a note into those evaluators that they need to check the cooldown before sending events forward?\nOr maybe we do that in a common base itself.", "author": "sidseth", "createdAt": "2020-04-16T23:55:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MTU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDEwMjc0MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410102740", "bodyText": "added", "author": "smaniraju", "createdAt": "2020-04-17T09:25:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MTU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MjQzMA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409242430", "bodyText": "Any chance this can be passed in to ScalingHandler? May not be possible for anything other than the YARNLoadEvaluator.", "author": "sidseth", "createdAt": "2020-04-16T02:23:38Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/handler/ScalingHandler.java", "diffHunk": "@@ -45,60 +47,72 @@\n     @Inject\n     private ClouderaManagerTotalHostsEvaluator totalHostsEvaluatorService;\n \n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n     @Override\n     public void onApplicationEvent(ScalingEvent event) {\n         BaseAlert alert = event.getAlert();\n         Cluster cluster = clusterService.findById(alert.getCluster().getId());\n         MDCBuilder.buildMdcContext(cluster);\n-        scale(cluster, alert.getScalingPolicy());\n+        handleClusterScaling(cluster, alert);\n     }\n \n-    private void scale(Cluster cluster, ScalingPolicy policy) {\n-        long remainingTime = getRemainingCooldownTime(cluster);\n-        if (remainingTime <= 0) {\n-            int totalNodes = totalHostsEvaluatorService.getTotalHosts(cluster);\n-            int desiredNodeCount = getDesiredNodeCount(cluster, policy, totalNodes);\n-            if (totalNodes != desiredNodeCount) {\n-                Runnable scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy, totalNodes, desiredNodeCount);\n-                executorService.submit(scalingRequest);\n-                rejectedThreadService.remove(cluster.getId());\n-                cluster.setLastScalingActivityCurrent();\n-                clusterService.save(cluster);\n-            } else {\n-                LOGGER.debug(\"No scaling activity required\");\n-            }\n+    private void handleClusterScaling(Cluster cluster, BaseAlert alert) {\n+\n+        ScalingPolicy policy = alert.getScalingPolicy();\n+        Runnable scalingRequest = null;\n+        if (!alert.getDecommissionNodeIds().isEmpty()) {\n+            scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy,\n+                    0, 0, alert.getDecommissionNodeIds());\n         } else {\n-            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n-                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+            int hostGroupNodeCount = getHostGroupNodeCount(cluster, policy);\n+            int desiredNodeCount = getDesiredNodeCount(cluster, policy, hostGroupNodeCount);\n+            if (hostGroupNodeCount != desiredNodeCount) {\n+                scalingRequest = (Runnable) applicationContext.getBean(\"ScalingRequest\", cluster, policy,\n+                        hostGroupNodeCount, desiredNodeCount, List.of());\n+            }\n         }\n-    }\n \n-    private long getRemainingCooldownTime(Cluster cluster) {\n-        long coolDown = cluster.getCoolDown();\n-        long lastScalingActivity = cluster.getLastScalingActivity();\n-        return lastScalingActivity == 0L ? 0L : (coolDown * TimeUtil.MIN_IN_MS) - (System.currentTimeMillis() - lastScalingActivity);\n+        if (scalingRequest != null) {\n+            executorService.submit(scalingRequest);\n+            rejectedThreadService.remove(cluster.getId());\n+            cluster.setLastScalingActivityCurrent();\n+            clusterService.save(cluster);\n+        } else {\n+            LOGGER.debug(\"No scaling activity required for cluster crn {}\", cluster.getStackCrn());\n+        }\n     }\n \n-    private int getDesiredNodeCount(Cluster cluster, ScalingPolicy policy, int totalNodes) {\n+    private int getDesiredNodeCount(Cluster cluster, ScalingPolicy policy, int hostGroupNodeCount) {\n         int scalingAdjustment = policy.getScalingAdjustment();\n-        int desiredNodeCount;\n+        int desiredHostGroupNodeCount;\n         switch (policy.getAdjustmentType()) {\n             case NODE_COUNT:\n-                desiredNodeCount = totalNodes + scalingAdjustment;\n+            case LOAD_BASED:\n+                desiredHostGroupNodeCount = hostGroupNodeCount + scalingAdjustment;\n                 break;\n             case PERCENTAGE:\n-                desiredNodeCount = totalNodes\n-                        + (int) (ceil(totalNodes * ((double) scalingAdjustment / ClusterUtils.MAX_CAPACITY)));\n+                desiredHostGroupNodeCount = hostGroupNodeCount\n+                        + (int) (ceil(hostGroupNodeCount * ((double) scalingAdjustment / ClusterUtils.MAX_CAPACITY)));\n                 break;\n             case EXACT:\n-                desiredNodeCount = policy.getScalingAdjustment();\n+                desiredHostGroupNodeCount = policy.getScalingAdjustment();\n                 break;\n             default:\n-                desiredNodeCount = totalNodes;\n+                desiredHostGroupNodeCount = hostGroupNodeCount;\n         }\n-        int minSize = cluster.getMinSize();\n-        int maxSize = cluster.getMaxSize();\n-        return desiredNodeCount < minSize ? minSize : desiredNodeCount > maxSize ? maxSize : desiredNodeCount;\n+        int minSize = cluster.getHostGroupMinSize();\n+        int maxSize = cluster.getHostGroupMaxSize();\n+\n+        return desiredHostGroupNodeCount < minSize ? minSize : desiredHostGroupNodeCount > maxSize ? maxSize : desiredHostGroupNodeCount;\n     }\n \n+    private int getHostGroupNodeCount(Cluster cluster, ScalingPolicy policy) {\n+        StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ3NDgwNg==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409474806", "bodyText": "have added cacheable to stackv4response, so it is cached for 5 mins.", "author": "smaniraju", "createdAt": "2020-04-16T11:12:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MjQzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNTA2NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409915064", "bodyText": "Can the time be adjusted to a lower value? 5 minutes can lead to incorrect information on the number of nodes. Potentially spanning across multiple scale events.\nThe intent here was to say that for a single ScalingEvent - we don't fetch this information twice. Cacheable isn't the best approach for that.", "author": "sidseth", "createdAt": "2020-04-16T23:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MjQzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDEyOTY0OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410129648", "bodyText": "agree, removed the cache and used single call for a single evaluation cycle.", "author": "smaniraju", "createdAt": "2020-04-17T10:15:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0MjQzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0Mjc4OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409242788", "bodyText": "However the event which gets published is changed - I think it'll be useful to include a timestamp in the event. That can be used to track metrics on how long from event generation to event processing - and generate alerts based on that. Will be useful for load testing as well.", "author": "sidseth", "createdAt": "2020-04-16T02:24:59Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,180 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst().map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() ->\n+                                new RuntimeException(String.format(\"Yarn Scaling API Response does not contain recommended host count \" +\n+                                                \"for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        int maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        maxAllowedScaleUp = maxAllowedScaleUp < 0 ? 0 : maxAllowedScaleUp;\n+        int scaleUpCount = Math.min(maxAllowedScaleUp, yarnRecommendedHostGroupCount);\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));\n+        }\n+    }\n+\n+    protected void handleScaleDown(List<DecommissionCandidate> decommissionCandidates, Map<String, String> hostGroupFqdnsToInstanceId) {\n+        Set<String> hostGroupFqdns = hostGroupFqdnsToInstanceId.keySet();\n+        int maxAllowedScaleDown = hostGroupFqdns.size() - loadAlert.getLoadAlertConfiguration().getMinResourceValue();\n+        maxAllowedScaleDown = maxAllowedScaleDown < 0 ? 0 : maxAllowedScaleDown;\n+\n+        List<String> decommissionHostGroupNodeIds = decommissionCandidates.stream()\n+                .sorted(Comparator.comparingInt(DecommissionCandidate::getAmCount))\n+                .map(DecommissionCandidate::getNodeId)\n+                .map(nodeFqdn -> nodeFqdn.split(\":\")[0])\n+                .filter(s -> hostGroupFqdns.contains(s))\n+                .limit(maxAllowedScaleDown)\n+                .map(nodeFqdn -> hostGroupFqdnsToInstanceId.get(nodeFqdn))\n+                .collect(Collectors.toList());\n+\n+        LOGGER.info(\"ScaleDown NodeCount {} for Cluster {}, HostGroup {], NodeIds {}\",\n+                decommissionHostGroupNodeIds.size(), cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup(),\n+                decommissionHostGroupNodeIds);\n+\n+        if (!decommissionHostGroupNodeIds.isEmpty()) {\n+            loadAlert.setDecommissionNodeIds(decommissionHostGroupNodeIds);\n+            eventPublisher.publishEvent(new ScalingEvent(loadAlert));", "originalCommit": "2764b0ed5e581d4f2f5db1740aa6097377ac4e92", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTQ3NTYxOQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409475619", "bodyText": "eventTimestamp is already present in base class.", "author": "smaniraju", "createdAt": "2020-04-16T11:13:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI0Mjc4OA=="}], "type": "inlineReview"}, {"oid": "8f201909aca9016a323c5996cdbd41c4a1752328", "url": "https://github.com/hortonworks/cloudbreak/commit/8f201909aca9016a323c5996cdbd41c4a1752328", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-16T14:32:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNTgzNA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409915834", "bodyText": "Min should be 0. It's possible for a hostGroup to run no instances.", "author": "sidseth", "createdAt": "2020-04-16T23:59:14Z", "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/api/model/LoadAlertConfigurationRequest.java", "diffHunk": "@@ -11,12 +14,19 @@\n public class LoadAlertConfigurationRequest implements Json {\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MIN_RESOUCE_VALUE)\n+    @Min(value = 1)", "originalCommit": "8f201909aca9016a323c5996cdbd41c4a1752328", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNjU4Ng==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409916586", "bodyText": "Think the 'min' should still be about 2 minutes here, to allow for enhancements in scale-up performance.\nAlso scale-down can finish within 2 minutes, or even faster.", "author": "sidseth", "createdAt": "2020-04-17T00:01:54Z", "path": "autoscale-api/src/main/java/com/sequenceiq/periscope/api/model/LoadAlertConfigurationRequest.java", "diffHunk": "@@ -11,12 +14,19 @@\n public class LoadAlertConfigurationRequest implements Json {\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MIN_RESOUCE_VALUE)\n+    @Min(value = 1)\n+    @Digits(fraction = 0, integer = 3)\n     private @Valid Integer minResourceValue;\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_MAX_RESOUCE_VALUE)\n+    @Max(value = 200)\n+    @Digits(fraction = 0, integer = 3)\n     private @Valid Integer maxResourceValue;\n \n     @ApiModelProperty(LoadAlertJsonProperties.LOAD_ALERT_CONFIGURATION_COOL_DOWN_MINS_VALUE)\n+    @Min(value = 5)", "originalCommit": "8f201909aca9016a323c5996cdbd41c4a1752328", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0MTUwOA==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410141508", "bodyText": "ok", "author": "smaniraju", "createdAt": "2020-04-17T10:40:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxNjU4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkyMDM0MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r409920341", "bodyText": "The same comment about modifying a 'Model' object applies here. Is there any chance this gets persisted to the DB accidentally?\nThe 'scaleUpCount' is essentially the same as the 'decommissionNodeIds' during scaleDown. Why not move this into ScalingRequest as well?\nFor all the other Evaluators, ScalingAdjustment is static, and is not modified by the Evaluators.", "author": "sidseth", "createdAt": "2020-04-17T00:14:42Z", "path": "autoscale/src/main/java/com/sequenceiq/periscope/monitor/evaluator/load/YarnLoadEvaluator.java", "diffHunk": "@@ -0,0 +1,187 @@\n+package com.sequenceiq.periscope.monitor.evaluator.load;\n+\n+import static com.sequenceiq.periscope.monitor.evaluator.ScalingConstants.DEFAULT_MAX_SCALE_UP_STEP_SIZE;\n+\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import javax.annotation.Nonnull;\n+import javax.inject.Inject;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.context.annotation.Scope;\n+import org.springframework.stereotype.Component;\n+\n+import com.sequenceiq.cloudbreak.api.endpoint.v4.stacks.response.StackV4Response;\n+import com.sequenceiq.cloudbreak.logger.MDCBuilder;\n+import com.sequenceiq.periscope.domain.Cluster;\n+import com.sequenceiq.periscope.domain.LoadAlert;\n+import com.sequenceiq.periscope.model.yarn.DecommissionCandidate;\n+import com.sequenceiq.periscope.model.yarn.NewNodeManagerCandidates;\n+import com.sequenceiq.periscope.model.yarn.YarnScalingServiceV1Response;\n+import com.sequenceiq.periscope.monitor.client.YarnMetricsClient;\n+import com.sequenceiq.periscope.monitor.context.ClusterIdEvaluatorContext;\n+import com.sequenceiq.periscope.monitor.context.EvaluatorContext;\n+import com.sequenceiq.periscope.monitor.evaluator.EvaluatorExecutor;\n+import com.sequenceiq.periscope.monitor.evaluator.EventPublisher;\n+import com.sequenceiq.periscope.monitor.event.ScalingEvent;\n+import com.sequenceiq.periscope.monitor.event.UpdateFailedEvent;\n+import com.sequenceiq.periscope.monitor.handler.CloudbreakCommunicator;\n+import com.sequenceiq.periscope.repository.LoadAlertRepository;\n+import com.sequenceiq.periscope.service.ClusterService;\n+import com.sequenceiq.periscope.utils.ClusterUtils;\n+import com.sequenceiq.periscope.utils.StackResponseUtils;\n+import com.sequenceiq.periscope.utils.TimeUtil;\n+\n+@Component(\"YarnLoadEvaluator\")\n+@Scope(\"prototype\")\n+public class YarnLoadEvaluator extends EvaluatorExecutor {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(YarnLoadEvaluator.class);\n+\n+    private static final String EVALUATOR_NAME = YarnLoadEvaluator.class.getName();\n+\n+    @Inject\n+    private ClusterService clusterService;\n+\n+    @Inject\n+    private LoadAlertRepository alertRepository;\n+\n+    @Inject\n+    private EventPublisher eventPublisher;\n+\n+    @Inject\n+    private YarnMetricsClient yarnMetricsClient;\n+\n+    @Inject\n+    private StackResponseUtils stackResponseUtils;\n+\n+    @Inject\n+    private CloudbreakCommunicator cloudbreakCommunicator;\n+\n+    private long clusterId;\n+\n+    private Cluster cluster;\n+\n+    private LoadAlert loadAlert;\n+\n+    @Nonnull\n+    @Override\n+    public EvaluatorContext getContext() {\n+        return new ClusterIdEvaluatorContext(clusterId);\n+    }\n+\n+    @Override\n+    public void setContext(EvaluatorContext context) {\n+        clusterId = (long) context.getData();\n+    }\n+\n+    @Override\n+    public String getName() {\n+        return EVALUATOR_NAME;\n+    }\n+\n+    @Override\n+    protected void execute() {\n+        cluster = clusterService.findById(clusterId);\n+        loadAlert = cluster.getLoadAlerts().stream().findFirst().get();\n+\n+        long remainingTime = ClusterUtils.getRemainingCooldownTime(\n+                loadAlert.getLoadAlertConfiguration().getCoolDownMillis(),\n+                cluster.getLastScalingActivity());\n+\n+        if (remainingTime <= 0) {\n+            pollYarnMetricsAndScaleCluster();\n+        } else {\n+            LOGGER.debug(\"Cluster cannot be scaled for {} min(s)\",\n+                    ClusterUtils.TIME_FORMAT.format((double) remainingTime / TimeUtil.MIN_IN_MS));\n+        }\n+    }\n+\n+    protected void pollYarnMetricsAndScaleCluster() {\n+        long start = System.currentTimeMillis();\n+        try {\n+            MDCBuilder.buildMdcContext(cluster);\n+\n+            StackV4Response stackV4Response = cloudbreakCommunicator.getByCrn(cluster.getStackCrn());\n+\n+            String hostGroupInstanceType =\n+                    stackResponseUtils.getHostGroupInstanceType(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+\n+            YarnScalingServiceV1Response yarnResponse = yarnMetricsClient\n+                    .getYarnMetricsForCluster(cluster, hostGroupInstanceType, stackV4Response.getCloudPlatform());\n+\n+            Map<String, String> hostFqdnsToInstanceId = stackResponseUtils\n+                    .getCloudInstanceIdsForHostGroup(stackV4Response, loadAlert.getScalingPolicy().getHostGroup());\n+            yarnResponse.getScaleUpCandidates().ifPresentOrElse(\n+                    scaleUpCandidates -> handleScaleUp(hostGroupInstanceType, scaleUpCandidates, hostFqdnsToInstanceId.size()),\n+                    () -> {\n+                        yarnResponse.getScaleDownCandidates().ifPresent(\n+                                scaleDownCandidates -> handleScaleDown(scaleDownCandidates, hostFqdnsToInstanceId));\n+                    });\n+\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        } catch (Exception ex) {\n+            LOGGER.info(\"Failed to process load alert for Cluster {}, exception {}\", cluster.getStackCrn(), ex);\n+            eventPublisher.publishEvent(new UpdateFailedEvent(clusterId));\n+        } finally {\n+            LOGGER.debug(\"Finished loadEvaluator for cluster {} in {} ms\", cluster.getStackCrn(), System.currentTimeMillis() - start);\n+        }\n+    }\n+\n+    protected void handleScaleUp(String hostGroupInstanceType, NewNodeManagerCandidates newNMCandidates, Integer existingHostGroupSize) {\n+        Integer yarnRecommendedHostGroupCount =\n+                newNMCandidates.getCandidates().stream()\n+                        .filter(candidate -> candidate.getModelName().equalsIgnoreCase(hostGroupInstanceType))\n+                        .findFirst()\n+                        .map(NewNodeManagerCandidates.Candidate::getCount)\n+                        .orElseThrow(() -> new RuntimeException(String.format(\n+                                \"Yarn Scaling API Response does not contain recommended node count \" +\n+                                        \" for hostGroupInstanceType %s in Cluster %s, Yarn Response %s\",\n+                                        hostGroupInstanceType, cluster.getStackCrn(), newNMCandidates)));\n+\n+        Integer maxAllowedScaleUp = loadAlert.getLoadAlertConfiguration().getMaxResourceValue() - existingHostGroupSize;\n+        Integer scaleUpCount = IntStream.of(yarnRecommendedHostGroupCount, DEFAULT_MAX_SCALE_UP_STEP_SIZE, maxAllowedScaleUp)\n+                .filter(i -> i >= 0)\n+                .min()\n+                .getAsInt();\n+\n+        LOGGER.info(\"ScaleUp NodeCount {} for Cluster {}, HostGroup {]\", scaleUpCount,\n+                cluster.getStackCrn(), loadAlert.getScalingPolicy().getHostGroup());\n+\n+        if (scaleUpCount > 0) {\n+            loadAlert.getScalingPolicy().setScalingAdjustment(scaleUpCount);", "originalCommit": "8f201909aca9016a323c5996cdbd41c4a1752328", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0MTY4Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/7779#discussion_r410141683", "bodyText": "ok", "author": "smaniraju", "createdAt": "2020-04-17T10:41:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkyMDM0MQ=="}], "type": "inlineReview"}, {"oid": "d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "url": "https://github.com/hortonworks/cloudbreak/commit/d66ab2f82203a7a9f886dcc33d929ab152f73ee9", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-17T16:45:41Z", "type": "forcePushed"}, {"oid": "02368bf722a69de52ec06c3cb1b4ecbc062743c4", "url": "https://github.com/hortonworks/cloudbreak/commit/02368bf722a69de52ec06c3cb1b4ecbc062743c4", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-18T12:17:37Z", "type": "forcePushed"}, {"oid": "4872222a46ddc17a56b66f44c5ed073684e8b7c3", "url": "https://github.com/hortonworks/cloudbreak/commit/4872222a46ddc17a56b66f44c5ed073684e8b7c3", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-18T12:40:20Z", "type": "commit"}, {"oid": "4872222a46ddc17a56b66f44c5ed073684e8b7c3", "url": "https://github.com/hortonworks/cloudbreak/commit/4872222a46ddc17a56b66f44c5ed073684e8b7c3", "message": "CB-5736 Introduce support for Load Based Alert Monitors", "committedDate": "2020-04-18T12:40:20Z", "type": "forcePushed"}]}