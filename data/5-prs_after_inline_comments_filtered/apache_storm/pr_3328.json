{"pr_number": 3328, "pr_title": "[STORM-3691] Refactor Resource Aware Strategies.", "pr_createdAt": "2020-09-02T01:22:08Z", "pr_url": "https://github.com/apache/storm/pull/3328", "timeline": [{"oid": "426f6f1bbb54dd1dd1dfc5926a64a2b73c01e5cc", "url": "https://github.com/apache/storm/commit/426f6f1bbb54dd1dd1dfc5926a64a2b73c01e5cc", "message": "[STORM-3691] Refactor Refactor Resource Aware Strategies.", "committedDate": "2020-09-02T01:12:56Z", "type": "commit"}, {"oid": "37b21cbad83559db03ddb002422724a1a9328f3e", "url": "https://github.com/apache/storm/commit/37b21cbad83559db03ddb002422724a1a9328f3e", "message": "[STORM-3691] Fix test TestConstraintSolverStrategy.testZeroExecutorScheduling()", "committedDate": "2020-09-02T14:52:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMwOTQ2Mw==", "url": "https://github.com/apache/storm/pull/3328#discussion_r482309463", "bodyText": "Where was this used before that we are now deprecating it?  It looks like this is added?", "author": "agresch", "createdAt": "2020-09-02T18:57:39Z", "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -346,6 +345,14 @@\n      */\n     @IsExactlyOneOf(valueValidatorClasses = { ListOfListOfStringValidator.class, RasConstraintsTypeValidator.class })\n     public static final String TOPOLOGY_RAS_CONSTRAINTS = \"topology.ras.constraints\";\n+    /**\n+     * Declare scheduling constraints for a topology.\n+     * @deprecated please use TOPOLOGY_RAS_CONSTRAINTS.\n+     */\n+    @Deprecated\n+    @CustomValidator(validatorClass = ListOfListOfStringValidator.class)\n+    public static final String TOPOLOGY_CONSTRAINTS = \"topology.constraints\";", "originalCommit": "37b21cbad83559db03ddb002422724a1a9328f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMxNzc2Mw==", "url": "https://github.com/apache/storm/pull/3328#discussion_r482317763", "bodyText": "Will remove this. No point adding a new deprecated variable.", "author": "bipinprasad", "createdAt": "2020-09-02T19:06:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMwOTQ2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMxMTY0NA==", "url": "https://github.com/apache/storm/pull/3328#discussion_r482311644", "bodyText": "same comment on these....", "author": "agresch", "createdAt": "2020-09-02T19:00:00Z", "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -355,12 +362,30 @@\n     @IsStringList\n     public static final String TOPOLOGY_SPREAD_COMPONENTS = \"topology.spread.components\";\n     /**\n-     * The maximum number of states that will be searched looking for a solution in the constraint solver strategy.\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy.\n      */\n     @IsInteger\n     @IsPositiveNumber\n     public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH = \"topology.ras.constraint.max.state.search\";\n     /**\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy. Backward compatibility config value for old topologies.\n+     * @deprecated please use {@link Config#TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH}\n+     */\n+    @IsInteger\n+    @IsPositiveNumber\n+    @Deprecated\n+    public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_TRAVERSAL = \"topology.ras.constraint.max.state.traversal\";", "originalCommit": "37b21cbad83559db03ddb002422724a1a9328f3e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMxODA3Mw==", "url": "https://github.com/apache/storm/pull/3328#discussion_r482318073", "bodyText": "Will remove this also. No point adding a new deprecated variable.", "author": "bipinprasad", "createdAt": "2020-09-02T19:07:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjMxMTY0NA=="}], "type": "inlineReview"}, {"oid": "90fa85f44b32c34a6f519af3b4d419daf7354c69", "url": "https://github.com/apache/storm/commit/90fa85f44b32c34a6f519af3b4d419daf7354c69", "message": "[STORM-3691] Remove new but deprecated Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH and Config,TOPOLOGY_CONSTRAINTS", "committedDate": "2020-09-02T19:43:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAxNjMzOQ==", "url": "https://github.com/apache/storm/pull/3328#discussion_r483016339", "bodyText": "is this another new deprecation?", "author": "agresch", "createdAt": "2020-09-03T14:22:06Z", "path": "storm-client/src/jvm/org/apache/storm/Config.java", "diffHunk": "@@ -355,12 +355,21 @@\n     @IsStringList\n     public static final String TOPOLOGY_SPREAD_COMPONENTS = \"topology.spread.components\";\n     /**\n-     * The maximum number of states that will be searched looking for a solution in the constraint solver strategy.\n+     * The maximum number of states that will be searched looking for a solution in resource aware strategies, e.g.\n+     * in BaseResourceAwareStrategy.\n      */\n     @IsInteger\n     @IsPositiveNumber\n     public static final String TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH = \"topology.ras.constraint.max.state.search\";\n     /**\n+     * Declare max traversal depth for find solutions that satisfy constraints.\n+     * @deprecated please use {@link Config#TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH}\n+     */\n+    @IsInteger\n+    @IsPositiveNumber\n+    @Deprecated\n+    public static final String TOPOLOGY_CONSTRAINTS_MAX_DEPTH_TRAVERSAL = \"topology.constraints.max.depth.traversal\";", "originalCommit": "90fa85f44b32c34a6f519af3b4d419daf7354c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA1NzU0Mw==", "url": "https://github.com/apache/storm/pull/3328#discussion_r483057543", "bodyText": "Removing.", "author": "bipinprasad", "createdAt": "2020-09-03T15:16:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAxNjMzOQ=="}], "type": "inlineReview"}, {"oid": "50e7cded75648a0ee2fddea697f522f630c817ed", "url": "https://github.com/apache/storm/commit/50e7cded75648a0ee2fddea697f522f630c817ed", "message": "[STORM-3691] Removed deprecated Config.TOPOLOGY_CONSTRAINTS_MAX_DEPTH_TRAVERSAL.", "committedDate": "2020-09-03T15:26:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjc5Ng==", "url": "https://github.com/apache/storm/pull/3328#discussion_r490306796", "bodyText": "This should be removed.", "author": "Ethanlm", "createdAt": "2020-09-17T14:44:30Z", "path": "storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/BaseResourceAwareStrategy.java", "diffHunk": "@@ -50,709 +37,308 @@\n import org.apache.storm.scheduler.resource.RasNodes;\n import org.apache.storm.scheduler.resource.SchedulingResult;\n import org.apache.storm.scheduler.resource.SchedulingStatus;\n-import org.apache.storm.scheduler.resource.normalization.NormalizedResourceOffer;\n-import org.apache.storm.scheduler.resource.normalization.NormalizedResourceRequest;\n-import org.apache.storm.shade.com.google.common.annotations.VisibleForTesting;\n-import org.apache.storm.shade.com.google.common.collect.Sets;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.ExecSorterByConnectionCount;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.ExecSorterByProximity;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.IExecSorter;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.INodeSorter;\n+import org.apache.storm.scheduler.resource.strategies.scheduling.sorter.NodeSorter;\n import org.apache.storm.utils.ObjectReader;\n+import org.apache.storm.utils.Time;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n public abstract class BaseResourceAwareStrategy implements IStrategy {\n     private static final Logger LOG = LoggerFactory.getLogger(BaseResourceAwareStrategy.class);\n-    protected Cluster cluster;\n-    // Rack id to list of host names in that rack\n-    private Map<String, List<String>> networkTopography;\n-    private final Map<String, String> superIdToRack = new HashMap<>();\n-    private final Map<String, String> superIdToHostname = new HashMap<>();\n-    private final Map<String, List<RasNode>> hostnameToNodes = new HashMap<>();\n-    private final Map<String, List<RasNode>> rackIdToNodes = new HashMap<>();\n-    protected RasNodes nodes;\n \n-    @VisibleForTesting\n-    void prepare(Cluster cluster) {\n-        this.cluster = cluster;\n-        nodes = new RasNodes(cluster);\n-        networkTopography = cluster.getNetworkTopography();\n-        Map<String, String> hostToRack = new HashMap<>();\n-        for (Map.Entry<String, List<String>> entry : networkTopography.entrySet()) {\n-            String rackId = entry.getKey();\n-            for (String hostName: entry.getValue()) {\n-                hostToRack.put(hostName, rackId);\n-            }\n-        }\n-        for (RasNode node: nodes.getNodes()) {\n-            String superId = node.getId();\n-            String hostName = node.getHostname();\n-            String rackId = hostToRack.getOrDefault(hostName, DNSToSwitchMapping.DEFAULT_RACK);\n-            superIdToHostname.put(superId, hostName);\n-            superIdToRack.put(superId, rackId);\n-            hostnameToNodes.computeIfAbsent(hostName, (hn) -> new ArrayList<>()).add(node);\n-            rackIdToNodes.computeIfAbsent(rackId, (hn) -> new ArrayList<>()).add(node);\n-        }\n-        logClusterInfo();\n+    /**\n+     * Different node sorting types available. Two of these are for backward compatibility.\n+     * The last one (COMMON) is the new sorting type used across the board.\n+     * Refer to {@link NodeSorter#NodeSorter(Cluster, TopologyDetails, NodeSortType)} for more details.\n+     */\n+    public enum NodeSortType {\n+        GENERIC_RAS, // for deprecation, Used by GenericResourceAwareStrategyOld\n+        DEFAULT_RAS, // for deprecation, Used by DefaultResourceAwareStrategyOld\n+        COMMON       // new and only node sorting type going forward\n     }\n \n-    @Override\n-    public void prepare(Map<String, Object> config) {\n-        //NOOP\n-    }\n+    // instance variables from class instantiation\n+    protected final boolean sortNodesForEachExecutor;\n+    protected final NodeSortType nodeSortType;\n+\n+    // instance variable set by two IStrategy methods\n+    protected Map<String, Object> config;\n+    protected Cluster cluster;\n+    protected TopologyDetails topologyDetails;\n \n-    protected SchedulingResult mkNotEnoughResources(TopologyDetails td) {\n-        return  SchedulingResult.failure(\n-            SchedulingStatus.FAIL_NOT_ENOUGH_RESOURCES,\n-            td.getExecutors().size() + \" executors not scheduled\");\n+    // Instance variables derived from Cluster.\n+    protected RasNodes nodes;\n+    private Map<String, List<String>> networkTopography;\n+    private Map<String, List<RasNode>> hostnameToNodes;\n+\n+    // Instance variables derived from TopologyDetails\n+    protected String topoName;\n+    protected Map<String, Set<ExecutorDetails>> compToExecs;\n+    protected Map<ExecutorDetails, String> execToComp;\n+    protected boolean orderExecutorsByProximity;\n+    private long maxSchedulingTimeMs;\n+\n+    // Instance variables from Cluster and TopologyDetails.\n+    Set<ExecutorDetails> unassignedExecutors;\n+    private int maxStateSearch;\n+    protected SchedulingSearcherState searcherState;\n+    protected IExecSorter execSorter;\n+    protected INodeSorter nodeSorter;\n+\n+    public BaseResourceAwareStrategy() {\n+        this(true, NodeSortType.COMMON);\n     }\n \n     /**\n-     * Schedule executor exec from topology td.\n+     * Initialize for the default implementation of schedule().\n      *\n-     * @param exec           the executor to schedule\n-     * @param td             the topology executor exec is a part of\n-     * @param scheduledTasks executors that have been scheduled\n-     * @return true if scheduled successfully, else false.\n+     * @param sortNodesForEachExecutor Sort nodes before scheduling each executor.\n+     * @param nodeSortType type of sorting to be applied to object resource collection {@link NodeSortType}.\n      */\n-    protected boolean scheduleExecutor(\n-            ExecutorDetails exec, TopologyDetails td, Collection<ExecutorDetails> scheduledTasks, Iterable<String> sortedNodes) {\n-        WorkerSlot targetSlot = findWorkerForExec(exec, td, sortedNodes);\n-        if (targetSlot != null) {\n-            RasNode targetNode = idToNode(targetSlot.getNodeId());\n-            targetNode.assignSingleExecutor(targetSlot, exec, td);\n-            scheduledTasks.add(exec);\n-            LOG.debug(\n-                \"TASK {} assigned to Node: {} avail [ mem: {} cpu: {} ] total [ mem: {} cpu: {} ] on \"\n-                + \"slot: {} on Rack: {}\",\n-                exec,\n-                targetNode.getHostname(),\n-                targetNode.getAvailableMemoryResources(),\n-                targetNode.getAvailableCpuResources(),\n-                targetNode.getTotalMemoryResources(),\n-                targetNode.getTotalCpuResources(),\n-                targetSlot,\n-                nodeToRack(targetNode));\n-            return true;\n-        } else {\n-            String comp = td.getExecutorToComponent().get(exec);\n-            NormalizedResourceRequest requestedResources = td.getTotalResources(exec);\n-            LOG.warn(\"Not Enough Resources to schedule Task {} - {} {}\", exec, comp, requestedResources);\n-            return false;\n-        }\n+    public BaseResourceAwareStrategy(boolean sortNodesForEachExecutor, NodeSortType nodeSortType) {\n+        this.sortNodesForEachExecutor = sortNodesForEachExecutor;\n+        this.nodeSortType = nodeSortType;\n     }\n \n-    protected abstract TreeSet<ObjectResources> sortObjectResources(\n-        AllResources allResources, ExecutorDetails exec, TopologyDetails topologyDetails,\n-        ExistingScheduleFunc existingScheduleFunc\n-    );\n-\n-    /**\n-     * Find a worker to schedule executor exec on.\n-     *\n-     * @param exec the executor to schedule\n-     * @param td   the topology that the executor is a part of\n-     * @return a worker to assign exec on. Returns null if a worker cannot be successfully found in cluster\n-     */\n-    protected WorkerSlot findWorkerForExec(ExecutorDetails exec, TopologyDetails td, Iterable<String> sortedNodes) {\n-        for (String id : sortedNodes) {\n-            RasNode node = nodes.getNodeById(id);\n-            if (node.couldEverFit(exec, td)) {\n-                for (WorkerSlot ws : node.getSlotsAvailableToScheduleOn()) {\n-                    if (node.wouldFit(ws, exec, td)) {\n-                        return ws;\n-                    }\n-                }\n-            }\n-        }\n-        return null;\n+    @Override\n+    public void prepare(Map<String, Object> config) {\n+        this.config = config;\n     }\n \n     /**\n-     * Nodes are sorted by two criteria.\n+     * Note that this method is not thread-safe.\n+     * Several instance variables are generated from supplied\n+     * parameters. In addition, the following instance variables are set to complete scheduling:\n+     *  <li>{@link #searcherState}</li>\n+     *  <li>{@link #execSorter} to sort executors</li>\n+     *  <li>{@link #nodeSorter} to sort nodes</li>\n+     * <p>\n+     * Scheduling consists of three main steps:\n+     *  <li>{@link #prepareForScheduling(Cluster, TopologyDetails)}</li>\n+     *  <li>{@link #checkSchedulingFeasibility()}, and</li>\n+     *  <li>{@link #scheduleExecutorsOnNodes(List, Iterable)}</li>\n+     * </p><p>\n+     * The executors and nodes are sorted in the order most conducive to scheduling for the strategy.\n+     * Those interfaces may be overridden by subclasses using mutators:\n+     *  <li>{@link #setExecSorter(IExecSorter)} and</li>\n+     *  <li>{@link #setNodeSorter(INodeSorter)}</li>\n+     *</p>\n      *\n-     * <p>1) the number executors of the topology that needs to be scheduled is already on the node in\n-     * descending order. The reasoning to sort based on criterion 1 is so we schedule the rest of a topology on the same node as the\n-     * existing executors of the topology.\n-     *\n-     * <p>2) the subordinate/subservient resource availability percentage of a node in descending\n-     * order We calculate the resource availability percentage by dividing the resource availability that have exhausted or little of one of\n-     * the resources mentioned above will be ranked after on the node by the resource availability of the entire rack By doing this\n-     * calculation, nodes nodes that have more balanced resource availability. So we will be less likely to pick a node that have a lot of\n-     * one resource but a low amount of another.\n-     *\n-     * @param availNodes a list of all the nodes we want to sort\n-     * @param rackId     the rack id availNodes are a part of\n-     * @return a sorted list of nodes.\n+     * @param cluster on which executors will be scheduled.\n+     * @param td the topology to schedule for.\n+     * @return result of scheduling (success, failure, or null when interrupted).\n      */\n-    protected TreeSet<ObjectResources> sortNodes(\n-            List<RasNode> availNodes, ExecutorDetails exec, TopologyDetails topologyDetails, String rackId,\n-            Map<String, AtomicInteger> scheduledCount) {\n-        AllResources allRackResources = new AllResources(\"RACK\");\n-        List<ObjectResources> nodes = allRackResources.objectResources;\n-\n-        for (RasNode rasNode : availNodes) {\n-            String superId = rasNode.getId();\n-            ObjectResources node = new ObjectResources(superId);\n-\n-            node.availableResources = rasNode.getTotalAvailableResources();\n-            node.totalResources = rasNode.getTotalResources();\n-\n-            nodes.add(node);\n-            allRackResources.availableResourcesOverall.add(node.availableResources);\n-            allRackResources.totalResourcesOverall.add(node.totalResources);\n-\n-        }\n-\n-        LOG.debug(\n-            \"Rack {}: Overall Avail [ {} ] Total [ {} ]\",\n-            rackId,\n-            allRackResources.availableResourcesOverall,\n-            allRackResources.totalResourcesOverall);\n-\n-        return sortObjectResources(\n-            allRackResources,\n-            exec,\n-            topologyDetails,\n-            (superId) -> {\n-                AtomicInteger count = scheduledCount.get(superId);\n-                if (count == null) {\n-                    return 0;\n-                }\n-                return count.get();\n-            });\n-    }\n-\n-    protected List<String> makeHostToNodeIds(List<String> hosts) {\n-        if (hosts == null) {\n-            return Collections.emptyList();\n-        }\n-        List<String> ret = new ArrayList<>(hosts.size());\n-        for (String host: hosts) {\n-            List<RasNode> nodes = hostnameToNodes.get(host);\n-            if (nodes != null) {\n-                for (RasNode node : nodes) {\n-                    ret.add(node.getId());\n-                }\n-            }\n-        }\n-        return ret;\n-    }\n-\n-    private static class LazyNodeSortingIterator implements Iterator<String> {\n-        private final LazyNodeSorting parent;\n-        private final Iterator<ObjectResources> rackIterator;\n-        private Iterator<ObjectResources> nodeIterator;\n-        private String nextValueFromNode = null;\n-        private final Iterator<String> pre;\n-        private final Iterator<String> post;\n-        private final Set<String> skip;\n-\n-        LazyNodeSortingIterator(LazyNodeSorting parent,\n-                                       TreeSet<ObjectResources> sortedRacks) {\n-            this.parent = parent;\n-            rackIterator = sortedRacks.iterator();\n-            pre = parent.favoredNodeIds.iterator();\n-            post = Stream.concat(parent.unFavoredNodeIds.stream(), parent.greyListedSupervisorIds.stream())\n-                            .collect(Collectors.toList())\n-                            .iterator();\n-            skip = parent.skippedNodeIds;\n-        }\n-\n-        private Iterator<ObjectResources> getNodeIterator() {\n-            if (nodeIterator != null && nodeIterator.hasNext()) {\n-                return nodeIterator;\n-            }\n-            //need to get the next node iterator\n-            if (rackIterator.hasNext()) {\n-                ObjectResources rack = rackIterator.next();\n-                final String rackId = rack.id;\n-                nodeIterator = parent.getSortedNodesFor(rackId).iterator();\n-                return nodeIterator;\n-            }\n-\n-            return null;\n-        }\n-\n-        @Override\n-        public boolean hasNext() {\n-            if (pre.hasNext()) {\n-                return true;\n-            }\n-            if (nextValueFromNode != null) {\n-                return true;\n-            }\n-            while (true) {\n-                //For the node we don't know if we have another one unless we look at the contents\n-                Iterator<ObjectResources> nodeIterator = getNodeIterator();\n-                if (nodeIterator == null || !nodeIterator.hasNext()) {\n-                    break;\n-                }\n-                String tmp = nodeIterator.next().id;\n-                if (!skip.contains(tmp)) {\n-                    nextValueFromNode = tmp;\n-                    return true;\n-                }\n-            }\n-            if (post.hasNext()) {\n-                return true;\n-            }\n-            return false;\n-        }\n-\n-        @Override\n-        public String next() {\n-            if (!hasNext()) {\n-                throw new NoSuchElementException();\n-            }\n-            if (pre.hasNext()) {\n-                return pre.next();\n-            }\n-            if (nextValueFromNode != null) {\n-                String tmp = nextValueFromNode;\n-                nextValueFromNode = null;\n-                return tmp;\n-            }\n-            return post.next();\n-        }\n-    }\n-\n-    private class LazyNodeSorting implements Iterable<String> {\n-        private final Map<String, AtomicInteger> perNodeScheduledCount = new HashMap<>();\n-        private final TreeSet<ObjectResources> sortedRacks;\n-        private final Map<String, TreeSet<ObjectResources>> cachedNodes = new HashMap<>();\n-        private final ExecutorDetails exec;\n-        private final TopologyDetails td;\n-        private final List<String> favoredNodeIds;\n-        private final List<String> unFavoredNodeIds;\n-        private final List<String> greyListedSupervisorIds;\n-        private final Set<String> skippedNodeIds = new HashSet<>();\n-\n-        LazyNodeSorting(TopologyDetails td, ExecutorDetails exec,\n-                               List<String> favoredNodeIds, List<String> unFavoredNodeIds) {\n-            this.favoredNodeIds = favoredNodeIds;\n-            this.unFavoredNodeIds = unFavoredNodeIds;\n-            this.greyListedSupervisorIds = cluster.getGreyListedSupervisors();\n-            this.unFavoredNodeIds.removeAll(favoredNodeIds);\n-            this.favoredNodeIds.removeAll(greyListedSupervisorIds);\n-            this.unFavoredNodeIds.removeAll(greyListedSupervisorIds);\n-            skippedNodeIds.addAll(favoredNodeIds);\n-            skippedNodeIds.addAll(unFavoredNodeIds);\n-            skippedNodeIds.addAll(greyListedSupervisorIds);\n-\n-            this.td = td;\n-            this.exec = exec;\n-            String topoId = td.getId();\n-            SchedulerAssignment assignment = cluster.getAssignmentById(topoId);\n-            if (assignment != null) {\n-                for (Map.Entry<WorkerSlot, Collection<ExecutorDetails>> entry :\n-                    assignment.getSlotToExecutors().entrySet()) {\n-                    String superId = entry.getKey().getNodeId();\n-                    perNodeScheduledCount.computeIfAbsent(superId, (sid) -> new AtomicInteger(0))\n-                        .getAndAdd(entry.getValue().size());\n-                }\n-            }\n-            sortedRacks = sortRacks(exec, td);\n-        }\n-\n-        private TreeSet<ObjectResources> getSortedNodesFor(String rackId) {\n-            return cachedNodes.computeIfAbsent(rackId,\n-                (rid) -> sortNodes(rackIdToNodes.getOrDefault(rid, Collections.emptyList()), exec, td, rid, perNodeScheduledCount));\n-        }\n-\n-        @Override\n-        public Iterator<String> iterator() {\n-            return new LazyNodeSortingIterator(this, sortedRacks);\n-        }\n-    }\n-\n-    protected Iterable<String> sortAllNodes(TopologyDetails td, ExecutorDetails exec,\n-                                            List<String> favoredNodeIds, List<String> unFavoredNodeIds) {\n-        return new LazyNodeSorting(td, exec, favoredNodeIds, unFavoredNodeIds);\n-    }\n-\n-    private AllResources createClusterAllResources() {\n-        AllResources allResources = new AllResources(\"Cluster\");\n-        List<ObjectResources> racks = allResources.objectResources;\n-\n-        //This is the first time so initialize the resources.\n-        for (Map.Entry<String, List<String>> entry : networkTopography.entrySet()) {\n-            String rackId = entry.getKey();\n-            List<String> nodeHosts = entry.getValue();\n-            ObjectResources rack = new ObjectResources(rackId);\n-            racks.add(rack);\n-            for (String nodeHost : nodeHosts) {\n-                for (RasNode node : hostnameToNodes(nodeHost)) {\n-                    rack.availableResources.add(node.getTotalAvailableResources());\n-                    rack.totalResources.add(node.getTotalAvailableResources());\n-                }\n-            }\n-\n-            allResources.totalResourcesOverall.add(rack.totalResources);\n-            allResources.availableResourcesOverall.add(rack.availableResources);\n+    @Override\n+    public SchedulingResult schedule(Cluster cluster, TopologyDetails td) {\n+        prepareForScheduling(cluster, td);\n+        // early detection of success or failure\n+        SchedulingResult earlyResult = checkSchedulingFeasibility();\n+        if (earlyResult != null) {\n+            return earlyResult;\n         }\n \n-        LOG.debug(\n-            \"Cluster Overall Avail [ {} ] Total [ {} ]\",\n-            allResources.availableResourcesOverall,\n-            allResources.totalResourcesOverall);\n-        return allResources;\n-    }\n+        LOG.debug(\"Topology {} {} Number of ExecutorsNeedScheduling: {}\", topoName, topologyDetails.getId(), unassignedExecutors.size());\n \n-    private Map<String, AtomicInteger> getScheduledCount(TopologyDetails topologyDetails) {\n-        String topoId = topologyDetails.getId();\n-        SchedulerAssignment assignment = cluster.getAssignmentById(topoId);\n-        Map<String, AtomicInteger> scheduledCount = new HashMap<>();\n-        if (assignment != null) {\n-            for (Map.Entry<WorkerSlot, Collection<ExecutorDetails>> entry :\n-                assignment.getSlotToExecutors().entrySet()) {\n-                String superId = entry.getKey().getNodeId();\n-                String rackId = superIdToRack.get(superId);\n-                scheduledCount.computeIfAbsent(rackId, (rid) -> new AtomicInteger(0))\n-                    .getAndAdd(entry.getValue().size());\n-            }\n+        //order executors to be scheduled\n+        List<ExecutorDetails> orderedExecutors = execSorter.sortExecutors(unassignedExecutors);\n+        Iterable<String> sortedNodes = null;\n+        if (!this.sortNodesForEachExecutor) {\n+            sortedNodes = nodeSorter.sortAllNodes(null);\n         }\n-        return scheduledCount;\n+        return scheduleExecutorsOnNodes(orderedExecutors, sortedNodes);\n     }\n \n     /**\n-     * Racks are sorted by two criteria.\n-     *\n-     * <p>1) the number executors of the topology that needs to be scheduled is already on the rack in descending order.\n-     * The reasoning to sort based on criterion 1 is so we schedule the rest of a topology on the same rack as the existing executors of the\n-     * topology.\n+     * Initialize instance variables as the first step in {@link #schedule(Cluster, TopologyDetails)}.\n+     * This method may be extended by subclasses to initialize additional variables as in\n+     * {@link ConstraintSolverStrategy#prepareForScheduling(Cluster, TopologyDetails)}.\n      *\n-     * <p>2) the subordinate/subservient resource availability percentage of a rack in descending order We calculate\n-     * the resource availability percentage by dividing the resource availability on the rack by the resource availability of the  entire\n-     * cluster By doing this calculation, racks that have exhausted or little of one of the resources mentioned above will be ranked after\n-     * racks that have more balanced resource availability. So we will be less likely to pick a rack that have a lot of one resource but a\n-     * low amount of another.\n-     *\n-     * @return a sorted list of racks\n+     * @param cluster on which executors will be scheduled.\n+     * @param topologyDetails to be scheduled.\n      */\n-    @VisibleForTesting\n-    TreeSet<ObjectResources> sortRacks(ExecutorDetails exec, TopologyDetails topologyDetails) {\n-\n-        final AllResources allResources = createClusterAllResources();\n-        final Map<String, AtomicInteger> scheduledCount = getScheduledCount(topologyDetails);\n-\n-        return sortObjectResources(\n-            allResources,\n-            exec,\n-            topologyDetails,\n-            (rackId) -> {\n-                AtomicInteger count = scheduledCount.get(rackId);\n-                if (count == null) {\n-                    return 0;\n-                }\n-                return count.get();\n-            });\n+    protected void prepareForScheduling(Cluster cluster, TopologyDetails topologyDetails) {\n+        this.cluster = cluster;\n+        this.topologyDetails = topologyDetails;\n+\n+        // from Cluster\n+        this.nodes = new RasNodes(cluster);\n+        networkTopography = cluster.getNetworkTopography();\n+        hostnameToNodes = this.nodes.getHostnameToNodes();\n+\n+        // from TopologyDetails\n+        topoName = topologyDetails.getName();\n+        execToComp = topologyDetails.getExecutorToComponent();\n+        compToExecs = topologyDetails.getComponentToExecutors();\n+        Map<String, Object> topoConf = topologyDetails.getConf();\n+        orderExecutorsByProximity = isOrderByProximity(topoConf);\n+        maxSchedulingTimeMs = computeMaxSchedulingTimeMs(topoConf);\n+\n+        // From Cluster and TopologyDetails - and cleaned-up\n+        unassignedExecutors = Collections.unmodifiableSet(new HashSet<>(cluster.getUnassignedExecutors(topologyDetails)));\n+        int confMaxStateSearch = getMaxStateSearchFromTopoConf(topologyDetails.getConf());\n+        int daemonMaxStateSearch = ObjectReader.getInt(cluster.getConf().get(DaemonConfig.RESOURCE_AWARE_SCHEDULER_MAX_STATE_SEARCH));\n+        maxStateSearch = Math.min(daemonMaxStateSearch, confMaxStateSearch);\n+        LOG.debug(\"The max state search configured by topology {} is {}\", topologyDetails.getId(), confMaxStateSearch);\n+        LOG.debug(\"The max state search that will be used by topology {} is {}\", topologyDetails.getId(), maxStateSearch);\n+\n+        searcherState = createSearcherState();\n+        setNodeSorter(new NodeSorter(cluster, topologyDetails, nodeSortType));\n+        setExecSorter(orderExecutorsByProximity\n+                ? new ExecSorterByProximity(topologyDetails)\n+                : new ExecSorterByConnectionCount(topologyDetails));\n+\n+        logClusterInfo();\n     }\n \n     /**\n-     * Get the rack on which a node is a part of.\n+     * Set the pluggable sorter for ExecutorDetails.\n      *\n-     * @param node the node to find out which rack its on\n-     * @return the rack id\n+     * @param execSorter to use for sorting executorDetails when scheduling.\n      */\n-    protected String nodeToRack(RasNode node) {\n-        return superIdToRack.get(node.getId());\n+    protected void setExecSorter(IExecSorter execSorter) {\n+        this.execSorter = execSorter;\n     }\n \n     /**\n-     * sort components by the number of in and out connections that need to be made, in descending order.\n+     * Set the pluggable sorter for Nodes.\n      *\n-     * @param componentMap The components that need to be sorted\n-     * @return a sorted set of components\n+     * @param nodeSorter to use for sorting nodes when scheduling.\n      */\n-    private Set<Component> sortComponents(final Map<String, Component> componentMap) {\n-        Set<Component> sortedComponents =\n-            new TreeSet<>((o1, o2) -> {\n-                int connections1 = 0;\n-                int connections2 = 0;\n-\n-                for (String childId : Sets.union(o1.getChildren(), o1.getParents())) {\n-                    connections1 +=\n-                        (componentMap.get(childId).getExecs().size() * o1.getExecs().size());\n-                }\n-\n-                for (String childId : Sets.union(o2.getChildren(), o2.getParents())) {\n-                    connections2 +=\n-                        (componentMap.get(childId).getExecs().size() * o2.getExecs().size());\n-                }\n-\n-                if (connections1 > connections2) {\n-                    return -1;\n-                } else if (connections1 < connections2) {\n-                    return 1;\n-                } else {\n-                    return o1.getId().compareTo(o2.getId());\n-                }\n-            });\n-        sortedComponents.addAll(componentMap.values());\n-        return sortedComponents;\n+    protected void setNodeSorter(INodeSorter nodeSorter) {\n+        this.nodeSorter = nodeSorter;\n     }\n \n-    /**\n-     * Sort a component's neighbors by the number of connections it needs to make with this component.\n-     *\n-     * @param thisComp     the component that we need to sort its neighbors\n-     * @param componentMap all the components to sort\n-     * @return a sorted set of components\n-     */\n-    private Set<Component> sortNeighbors(\n-        final Component thisComp, final Map<String, Component> componentMap) {\n-        Set<Component> sortedComponents =\n-            new TreeSet<>((o1, o2) -> {\n-                int connections1 = o1.getExecs().size() * thisComp.getExecs().size();\n-                int connections2 = o2.getExecs().size() * thisComp.getExecs().size();\n-                if (connections1 < connections2) {\n-                    return -1;\n-                } else if (connections1 > connections2) {\n-                    return 1;\n-                } else {\n-                    return o1.getId().compareTo(o2.getId());\n-                }\n-            });\n-        sortedComponents.addAll(componentMap.values());\n-        return sortedComponents;\n+    private static long computeMaxSchedulingTimeMs(Map<String, Object> topoConf) {\n+        // expect to be killed by DaemonConfig.SCHEDULING_TIMEOUT_SECONDS_PER_TOPOLOGY seconds, terminate slightly before\n+        int daemonMaxTimeSec = ObjectReader.getInt(topoConf.get(DaemonConfig.SCHEDULING_TIMEOUT_SECONDS_PER_TOPOLOGY), 60);\n+        int confMaxTimeSec = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_TIME_SECS), daemonMaxTimeSec);\n+        return (confMaxTimeSec >= daemonMaxTimeSec) ? daemonMaxTimeSec * 1000L - 200L :  confMaxTimeSec * 1000L;\n     }\n \n-    protected List<ExecutorDetails> orderExecutors(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Boolean orderByProximity = ObjectReader.getBoolean(\n-            td.getConf().get(Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS), false);\n-        if (!orderByProximity) {\n-            return orderExecutorsDefault(td, unassignedExecutors);\n+    public static int getMaxStateSearchFromTopoConf(Map<String, Object> topoConf) {\n+        int confMaxStateSearch;\n+        if (topoConf.containsKey(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH)) {\n+            //this config is always set for topologies of 2.0 or newer versions since it is in defaults.yaml file\n+            //topologies of older versions can also use it if configures it explicitly\n+            confMaxStateSearch = ObjectReader.getInt(topoConf.get(Config.TOPOLOGY_RAS_CONSTRAINT_MAX_STATE_SEARCH));\n         } else {\n-            LOG.info(\"{} is set to true\", Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n-            return orderExecutorsByProximityNeeds(td, unassignedExecutors);\n+            // For backwards compatibility\n+            confMaxStateSearch = 10_000;\n         }\n+        return confMaxStateSearch;\n     }\n \n-    /**\n-     * Order executors based on how many in and out connections it will potentially need to make, in descending order. First order\n-     * components by the number of in and out connections it will have.  Then iterate through the sorted list of components. For each\n-     * component sort the neighbors of that component by how many connections it will have to make with that component. Add an executor from\n-     * this component and then from each neighboring component in sorted order. Do this until there is nothing left to schedule.\n-     *\n-     * @param td                  The topology the executors belong to\n-     * @param unassignedExecutors a collection of unassigned executors that need to be assigned. Should only try to assign executors from\n-     *                            this list\n-     * @return a list of executors in sorted order\n-     */\n-    private List<ExecutorDetails> orderExecutorsDefault(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Map<String, Component> componentMap = td.getComponents();\n-        List<ExecutorDetails> execsScheduled = new LinkedList<>();\n-\n-        Map<String, Queue<ExecutorDetails>> compToExecsToSchedule = new HashMap<>();\n-        for (Component component : componentMap.values()) {\n-            compToExecsToSchedule.put(component.getId(), new LinkedList<>());\n-            for (ExecutorDetails exec : component.getExecs()) {\n-                if (unassignedExecutors.contains(exec)) {\n-                    compToExecsToSchedule.get(component.getId()).add(exec);\n-                }\n+    public static boolean isOrderByProximity(Map<String, Object> topoConf) {\n+        Boolean orderByProximity = (Boolean) topoConf.get(Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n+        if (orderByProximity == null) {\n+            orderByProximity = (Boolean) topoConf.get(EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n+            if (orderByProximity == null) {\n+                orderByProximity = false;\n+            } else {\n+                LOG.warn(\"{} is deprecated; please use {} instead\", EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS,\n+                        Config.TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS);\n             }\n         }\n-\n-        Set<Component> sortedComponents = sortComponents(componentMap);\n-        sortedComponents.addAll(componentMap.values());\n-\n-        for (Component currComp : sortedComponents) {\n-            Map<String, Component> neighbors = new HashMap<>();\n-            for (String compId : Sets.union(currComp.getChildren(), currComp.getParents())) {\n-                neighbors.put(compId, componentMap.get(compId));\n-            }\n-            Set<Component> sortedNeighbors = sortNeighbors(currComp, neighbors);\n-            Queue<ExecutorDetails> currCompExesToSched = compToExecsToSchedule.get(currComp.getId());\n-\n-            boolean flag = false;\n-            do {\n-                flag = false;\n-                if (!currCompExesToSched.isEmpty()) {\n-                    execsScheduled.add(currCompExesToSched.poll());\n-                    flag = true;\n-                }\n-\n-                for (Component neighborComp : sortedNeighbors) {\n-                    Queue<ExecutorDetails> neighborCompExesToSched =\n-                        compToExecsToSchedule.get(neighborComp.getId());\n-                    if (!neighborCompExesToSched.isEmpty()) {\n-                        execsScheduled.add(neighborCompExesToSched.poll());\n-                        flag = true;\n-                    }\n-                }\n-            } while (flag);\n-        }\n-        return execsScheduled;\n+        return orderByProximity;\n     }\n \n     /**\n-     * Order executors by network proximity needs.\n-     * @param td The topology the executors belong to\n-     * @param unassignedExecutors a collection of unassigned executors that need to be unassigned. Should only try to\n-     *     assign executors from this list\n-     * @return a list of executors in sorted order\n+     * Create an instance of {@link SchedulingSearcherState}. This method is called by\n+     * {@link #prepareForScheduling(Cluster, TopologyDetails)} and depends on variables initialized therein prior.\n+     *\n+     * @return a new instance of {@link SchedulingSearcherState}.\n      */\n-    private List<ExecutorDetails> orderExecutorsByProximityNeeds(\n-        TopologyDetails td, Collection<ExecutorDetails> unassignedExecutors) {\n-        Map<String, Component> componentMap = td.getComponents();\n-        List<ExecutorDetails> execsScheduled = new LinkedList<>();\n-\n-        Map<String, Queue<ExecutorDetails>> compToExecsToSchedule = new HashMap<>();\n-        for (Component component : componentMap.values()) {\n-            compToExecsToSchedule.put(component.getId(), new LinkedList<>());\n-            for (ExecutorDetails exec : component.getExecs()) {\n-                if (unassignedExecutors.contains(exec)) {\n-                    compToExecsToSchedule.get(component.getId()).add(exec);\n-                }\n-            }\n-        }\n-\n-        List<Component> sortedComponents = topologicalSortComponents(componentMap);\n-\n-        for (Component currComp: sortedComponents) {\n-            int numExecs = compToExecsToSchedule.get(currComp.getId()).size();\n-            for (int i = 0; i < numExecs; i++) {\n-                execsScheduled.addAll(takeExecutors(currComp, componentMap, compToExecsToSchedule));\n-            }\n+    private SchedulingSearcherState createSearcherState() {\n+        Map<WorkerSlot, Map<String, Integer>> workerCompCnts = new HashMap<>();\n+        Map<RasNode, Map<String, Integer>> nodeCompCnts = new HashMap<>();\n+\n+        //populate with existing assignments\n+        SchedulerAssignment existingAssignment = cluster.getAssignmentById(topologyDetails.getId());\n+        if (existingAssignment != null) {\n+            existingAssignment.getExecutorToSlot().forEach((exec, ws) -> {\n+                String compId = execToComp.get(exec);\n+                RasNode node = nodes.getNodeById(ws.getNodeId());\n+                Map<String, Integer> compCnts = nodeCompCnts.computeIfAbsent(node, (k) -> new HashMap<>());\n+                compCnts.put(compId, compCnts.getOrDefault(compId, 0) + 1); // increment\n+                //populate worker to comp assignments\n+                compCnts = workerCompCnts.computeIfAbsent(ws, (k) -> new HashMap<>());\n+                compCnts.put(compId, compCnts.getOrDefault(compId, 0) + 1); // increment\n+            });\n         }\n \n-        return execsScheduled;\n+        return new SchedulingSearcherState(workerCompCnts, nodeCompCnts,\n+                maxStateSearch, maxSchedulingTimeMs, new ArrayList<>(unassignedExecutors), topologyDetails, execToComp);\n     }\n \n     /**\n-     * Sort components topologically.\n-     * @param componentMap The map of component Id to Component Object.\n-     * @return The sorted components\n+     * Check scheduling feasibility for a quick failure as the second step in {@link #schedule(Cluster, TopologyDetails)}.\n+     * If scheduling is not possible, then return a SchedulingStatus object with a failure status.\n+     * If fully scheduled then return a successful SchedulingStatus.\n+     * This method can be extended by subclasses {@link ConstraintSolverStrategy#checkSchedulingFeasibility()}\n+     * to check for additional failure conditions.\n+     *\n+     * @return A non-null {@link SchedulingResult} to terminate scheduling, otherwise return null to continue scheduling.\n      */\n-    private List<Component> topologicalSortComponents(final Map<String, Component> componentMap) {\n-        List<Component> sortedComponents = new ArrayList<>();\n-        boolean[] visited = new boolean[componentMap.size()];\n-        int[] inDegree = new int[componentMap.size()];\n-        List<String> componentIds = new ArrayList<>(componentMap.keySet());\n-        Map<String, Integer> compIdToIndex = new HashMap<>();\n-        for (int i = 0; i < componentIds.size(); i++) {\n-            compIdToIndex.put(componentIds.get(i), i);\n-        }\n-        //initialize the in-degree array\n-        for (int i = 0; i < inDegree.length; i++) {\n-            String compId = componentIds.get(i);\n-            Component comp = componentMap.get(compId);\n-            for (String childId : comp.getChildren()) {\n-                inDegree[compIdToIndex.get(childId)] += 1;\n-            }\n-        }\n-        //sorting components topologically\n-        for (int t = 0; t < inDegree.length; t++) {\n-            for (int i = 0; i < inDegree.length; i++) {\n-                if (inDegree[i] == 0 && !visited[i]) {\n-                    String compId = componentIds.get(i);\n-                    Component comp = componentMap.get(compId);\n-                    sortedComponents.add(comp);\n-                    visited[i] = true;\n-                    for (String childId : comp.getChildren()) {\n-                        inDegree[compIdToIndex.get(childId)]--;\n-                    }\n-                    break;\n-                }\n-            }\n+    protected SchedulingResult checkSchedulingFeasibility() {\n+        if (unassignedExecutors.isEmpty()) {\n+            return SchedulingResult.success(\"Fully Scheduled by \" + this.getClass().getSimpleName());\n         }\n-        return sortedComponents;\n-    }\n \n-    /**\n-     * Take unscheduled executors from current and all its downstream components in a particular order.\n-     * First, take one executor from the current component;\n-     * then for every child (direct downstream component) of this component,\n-     *     if it's shuffle grouping from the current component to this child,\n-     *         the number of executors to take from this child is the max of\n-     *         1 and (the number of unscheduled executors this child has / the number of unscheduled executors the current component has);\n-     *     otherwise, the number of executors to take is 1;\n-     *     for every executor to take from this child, call takeExecutors(...).\n-     * @param currComp The current component.\n-     * @param componentMap The map from component Id to component object.\n-     * @param compToExecsToSchedule The map from component Id to unscheduled executors.\n-     * @return The executors to schedule in order.\n-     */\n-    private List<ExecutorDetails> takeExecutors(Component currComp,\n-                                                final Map<String, Component> componentMap,\n-                                                final Map<String, Queue<ExecutorDetails>> compToExecsToSchedule) {\n-        List<ExecutorDetails> execsScheduled = new ArrayList<>();\n-        Queue<ExecutorDetails> currQueue = compToExecsToSchedule.get(currComp.getId());\n-        int currUnscheduledNumExecs = currQueue.size();\n-        //Just for defensive programming as this won't actually happen.\n-        if (currUnscheduledNumExecs == 0) {\n-            return execsScheduled;\n-        }\n-        execsScheduled.add(currQueue.poll());\n-        Set<String> sortedChildren = getSortedChildren(currComp, componentMap);\n-        for (String childId: sortedChildren) {\n-            Component childComponent = componentMap.get(childId);\n-            Queue<ExecutorDetails> childQueue = compToExecsToSchedule.get(childId);\n-            int childUnscheduledNumExecs = childQueue.size();\n-            if (childUnscheduledNumExecs == 0) {\n-                continue;\n-            }\n-            int numExecsToTake = 1;\n-            if (hasShuffleGroupingFromParentToChild(currComp, childComponent)) {\n-                // if it's shuffle grouping, truncate\n-                numExecsToTake = Math.max(1, childUnscheduledNumExecs / currUnscheduledNumExecs);\n-            } // otherwise, one-by-one\n-            for (int i = 0; i < numExecsToTake; i++) {\n-                execsScheduled.addAll(takeExecutors(childComponent, componentMap, compToExecsToSchedule));\n-            }\n+        String err;\n+        if (nodes.getNodes().size() <= 0) {\n+            err = \"No available nodes to schedule tasks on!\";\n+            LOG.warn(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_NOT_ENOUGH_RESOURCES, err);\n         }\n-        return execsScheduled;\n-    }\n \n-    private Set<String> getSortedChildren(Component component, final Map<String, Component> componentMap) {\n-        Set<String> children = component.getChildren();\n-        Set<String> sortedChildren =\n-            new TreeSet<>((o1, o2) -> {\n-                Component child1 = componentMap.get(o1);\n-                Component child2 = componentMap.get(o2);\n-                boolean child1IsShuffle = hasShuffleGroupingFromParentToChild(component, child1);\n-                boolean child2IsShuffle = hasShuffleGroupingFromParentToChild(component, child2);\n-                if (child1IsShuffle && child2IsShuffle) {\n-                    return o1.compareTo(o2);\n-                } else if (child1IsShuffle) {\n-                    return 1;\n-                } else {\n-                    return -1;\n-                }\n-            });\n-        sortedChildren.addAll(children);\n-        return sortedChildren;\n-    }\n+        if (!topologyDetails.hasSpouts()) {\n+            err = \"Cannot find a Spout!\";\n+            LOG.error(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_INVALID_TOPOLOGY, err);\n+        }\n \n-    private boolean hasShuffleGroupingFromParentToChild(Component parent, Component child) {\n-        for (Map.Entry<GlobalStreamId, Grouping> inputEntry: child.getInputs().entrySet()) {\n-            GlobalStreamId globalStreamId = inputEntry.getKey();\n-            Grouping grouping = inputEntry.getValue();\n-            if (globalStreamId.get_componentId().equals(parent.getId())\n-                && (inputEntry.getValue().is_set_local_or_shuffle() || grouping.is_set_shuffle())) {\n-                return true;\n-            }\n+        int execCnt = unassignedExecutors.size();\n+        if (execCnt >= maxStateSearch) {\n+            err = String.format(\"Unassignerd Executor count (%d) is greater than searchable state count %d\", execCnt, maxStateSearch);\n+            LOG.error(\"Topology {}:{}\", topoName, err);\n+            return SchedulingResult.failure(SchedulingStatus.FAIL_OTHER, err);\n         }\n-        return false;\n+\n+        return null;\n     }\n \n     /**\n-     * Get a list of all the spouts in the topology.\n+     * Check if the assignment of the executor to the worker is valid. In simple cases,\n+     * this is simply a check of {@link RasNode#wouldFit(WorkerSlot, ExecutorDetails, TopologyDetails)}.\n+     * This method may be extended by subclasses to add additional checks,\n+     * see {@link ConstraintSolverStrategy#isExecAssignmentToWorkerValid(ExecutorDetails, WorkerSlot)}.\n      *\n-     * @param td topology to get spouts from\n-     * @return a list of spouts\n+     * @param exec being scheduled.\n+     * @param worker on which to schedule.\n+     * @return true if executor can be assigned to the worker, false otherwise.\n      */\n-    protected List<Component> getSpouts(TopologyDetails td) {\n-        List<Component> spouts = new ArrayList<>();\n-\n-        for (Component c : td.getComponents().values()) {\n-            if (c.getType() == ComponentType.SPOUT) {\n-                spouts.add(c);\n-            }\n+    protected boolean isExecAssignmentToWorkerValid(ExecutorDetails exec, WorkerSlot worker) {\n+        //check resources\n+        RasNode node = nodes.getNodeById(worker.getNodeId());\n+        if (!node.wouldFit(worker, exec, topologyDetails)) {\n+            LOG.trace(\"Topology {}, executor {} would not fit in resources available on worker {}\", topoName, exec, worker);\n+            return false;\n         }\n-        return spouts;\n+        return true;\n     }\n \n+    /**\n+     * If this config is set to true, unassigned executors will be sorted by topological order with network proximity needs.\n+     * @deprecated Use {@link Config#TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS} instead.\n+     */\n+    @Deprecated\n+    public static final String EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS", "originalCommit": "50e7cded75648a0ee2fddea697f522f630c817ed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxOTcyMA==", "url": "https://github.com/apache/storm/pull/3328#discussion_r490619720", "bodyText": "Removed", "author": "bipinprasad", "createdAt": "2020-09-17T23:39:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMwNjc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMxOTUzNg==", "url": "https://github.com/apache/storm/pull/3328#discussion_r490319536", "bodyText": "ObjectResourceSortType doesn't exist.", "author": "Ethanlm", "createdAt": "2020-09-17T14:56:21Z", "path": "storm-server/src/main/java/org/apache/storm/scheduler/resource/strategies/scheduling/IStrategy.java", "diffHunk": "@@ -19,21 +19,29 @@\n \n /**\n  * An interface to for implementing different scheduling strategies for the resource aware scheduling.\n+ * Scheduler should call {@link #prepare(Map)} followed by {@link #schedule(Cluster, TopologyDetails)}.\n+ * <p>\n+ *     A fully functioning implementation is in the abstract class {@link BaseResourceAwareStrategy}.\n+ *     Subclasses classes should extend {@link BaseResourceAwareStrategy#BaseResourceAwareStrategy(boolean, ObjectResourceSortType)}", "originalCommit": "50e7cded75648a0ee2fddea697f522f630c817ed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzE5OA==", "url": "https://github.com/apache/storm/pull/3328#discussion_r490617198", "bodyText": "Fixed documentation.", "author": "bipinprasad", "createdAt": "2020-09-17T23:31:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDMxOTUzNg=="}], "type": "inlineReview"}, {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "url": "https://github.com/apache/storm/commit/8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "message": "[STORM-3691] Fix javadoc and remove EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS.", "committedDate": "2020-09-18T02:07:36Z", "type": "commit"}, {"oid": "8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "url": "https://github.com/apache/storm/commit/8b47ccf6211f21b35e0c3f42a3a1dbf447a2cab5", "message": "[STORM-3691] Fix javadoc and remove EXPERIMENTAL_TOPOLOGY_RAS_ORDER_EXECUTORS_BY_PROXIMITY_NEEDS.", "committedDate": "2020-09-18T02:07:36Z", "type": "forcePushed"}]}