{"pr_number": 6144, "pr_title": "Replace Dropwizard Metrics with Micrometer", "pr_createdAt": "2020-06-23T17:06:37Z", "pr_url": "https://github.com/codice/ddf/pull/6144", "timeline": [{"oid": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "url": "https://github.com/codice/ddf/commit/cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "message": "Replace Dropwizard Metrics with Micrometer\n\nAdded new metrics\nExposed metrics through Prometheus endpoint\nReplaced CXF interceptor with servlet filter\nFixed bundle refresh of dynamically injected servlet filters", "committedDate": "2020-06-24T05:45:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2OTI3Mg==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445169272", "bodyText": "\u2753 Why not just immediately return when the predicate is valid instead of doing assignment?\n    if (query.isEnterprise())\n      return Collections.singleton(\"enterprise\");\n\n    if (query.getSourceIds() == null || query.getSourceIds().isEmpty()) {\n      return Collections.singleton(SystemInfo.getSiteName());\n\n    return query.getSourceIds();", "author": "leo-sakh", "createdAt": "2020-06-24T21:00:56Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,226 +13,288 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n+import javax.validation.constraints.NotNull;\n import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n-\n-  protected final Meter unsupportedQueryExceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter queries;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter fuzzyQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n+  private final Counter createdMetacards;\n \n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n+  private final Counter updatedMetacards;\n \n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter deletedMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n-\n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n-\n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));\n       }\n     } catch (UnsupportedQueryException e) {\n       // ignore filters not supported by the QueryTypeFilterDelegate\n     }\n \n+    addStartTime(input);\n+    return input;\n+  }\n+\n+  // PostQuery\n+  @Override\n+  public QueryResponse process(QueryResponse input)\n+      throws PluginExecutionException, StopProcessingException {\n+    recordLatency(input, QUERY_SCOPE);\n+    hits.record(input.getHits());\n+    recordExceptions(input.getProcessingDetails(), QUERY_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreCreate\n+  @Override\n+  public CreateRequest process(CreateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostCreate\n   @Override\n   public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      createdMetacards.mark(input.getCreatedMetacards().size());\n-    }\n+    recordLatency(input, CREATE_SCOPE);\n+    createdMetacards.increment(input.getCreatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), CREATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreUpdate\n+  @Override\n+  public UpdateRequest process(UpdateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostUpdate\n   @Override\n   public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      updatedMetacards.mark(input.getUpdatedMetacards().size());\n-    }\n+    recordLatency(input, UPDATE_SCOPE);\n+    updatedMetacards.increment(input.getUpdatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), UPDATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreDelete\n+  @Override\n+  public DeleteRequest process(DeleteRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostDelete\n   @Override\n   public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      deletedMetacards.mark(input.getDeletedMetacards().size());\n-    }\n+    recordLatency(input, DELETE_SCOPE);\n+    deletedMetacards.increment(input.getDeletedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), DELETE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreResource\n+  @Override\n+  public ResourceRequest process(ResourceRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostResource\n   @Override\n   public ResourceResponse process(ResourceResponse input)\n       throws PluginExecutionException, StopProcessingException {\n-    resourceRetrival.mark();\n+    recordLatency(input, RESOURCE_SCOPE);\n+    recordExceptions(input.getProcessingErrors(), RESOURCE_SCOPE);\n+\n     return input;\n   }\n \n-  private void recordSourceQueryExceptions(QueryResponse response) {\n-    Set<ProcessingDetails> processingDetails =\n-        (Set<ProcessingDetails>) response.getProcessingDetails();\n-\n-    if (processingDetails == null || processingDetails.iterator() == null) {\n+  private void recordExceptions(Set<ProcessingDetails> processingDetails, String operation) {\n+    if (processingDetails == null) {\n       return;\n     }\n \n-    Iterator<ProcessingDetails> iterator = processingDetails.iterator();\n-    while (iterator.hasNext()) {\n-      ProcessingDetails next = iterator.next();\n+    for (ProcessingDetails next : processingDetails) {\n       if (next != null && next.getException() != null) {\n-        if (next.getException() instanceof UnsupportedQueryException) {\n-          unsupportedQueryExceptions.mark();\n-        } else if (next.getException() instanceof SourceUnavailableException) {\n-          sourceUnavailableExceptions.mark();\n-        } else if (next.getException() instanceof FederationException) {\n-          federationExceptions.mark();\n-        }\n-        exceptions.mark();\n+        String exceptionName = rootCauseExceptionName(next.getException());\n+        Metrics.counter(\n+                metricName(METRIC_PREFIX, operation, EXCEPTIONS_SCOPE),\n+                \"type\",\n+                exceptionName,\n+                \"source\",\n+                next.getSourceId())\n+            .increment();\n       }\n     }\n+  }\n+\n+  private String rootCauseExceptionName(Exception exception) {\n+    Throwable rootCause = exception;\n+    while (rootCause.getCause() != null && rootCause.getCause() != rootCause) {\n+      rootCause = rootCause.getCause();\n+    }\n+    return rootCause.getClass().getName();\n+  }\n+\n+  private String metricName(String... parts) {\n+    return String.join(\".\", parts);\n+  }\n+\n+  private Set<String> getSourceIds(QueryRequest query) {\n+    Set<String> result;\n+\n+    if (query.isEnterprise()) {", "originalCommit": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY3MDEzOA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445670138", "bodyText": "https://stackoverflow.com/a/733858\nThis method is small enough so I do not think it matters either way in the context of the Code Complete advice.", "author": "pklinef", "createdAt": "2020-06-25T16:05:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2OTI3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTkxOA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445171918", "bodyText": "\u270f\ufe0f Reverse the predicate, return null early and collapse the larger nested if?\nif (input == null ) {\n     LOGGER.trace(\"EXITING: process (for PostFederatedQueryPlugin)\");\n\n    return null;\n}\n....", "author": "leo-sakh", "createdAt": "2020-06-24T21:06:27Z", "path": "catalog/core/catalog-core-sourcemetricsplugin/src/main/java/ddf/catalog/metrics/source/SourceMetricsImpl.java", "diffHunk": "@@ -172,414 +73,55 @@ public QueryRequest process(Source source, QueryRequest input)\n   public QueryResponse process(QueryResponse input)\n       throws PluginExecutionException, StopProcessingException {\n \n-    LOGGER.trace(\"ENTERING: process (for PostFederatedQueryPlugin)\");\n-\n-    if (null != input) {\n+    if (input != null) {", "originalCommit": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NTQ1Mw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445175453", "bodyText": "\u270f\ufe0f Might want to filter out null keys otherwise this will be an NPE", "author": "leo-sakh", "createdAt": "2020-06-24T21:13:57Z", "path": "catalog/core/catalog-core-sourcemetricsplugin/src/main/java/ddf/catalog/metrics/source/SourceMetricsImpl.java", "diffHunk": "@@ -172,414 +73,55 @@ public QueryRequest process(Source source, QueryRequest input)\n   public QueryResponse process(QueryResponse input)\n       throws PluginExecutionException, StopProcessingException {\n \n-    LOGGER.trace(\"ENTERING: process (for PostFederatedQueryPlugin)\");\n-\n-    if (null != input) {\n+    if (input != null) {\n       Set<ProcessingDetails> processingDetails = input.getProcessingDetails();\n       List<Result> results = input.getResults();\n-\n-      updateExceptionsMetric(processingDetails);\n-      updateTotalHitsMetric(results);\n-      updateLatencyMetric(input);\n+      Map<String, Serializable> properties = input.getProperties();\n+\n+      processingDetails\n+          .stream()\n+          .filter(ProcessingDetails::hasException)\n+          .map(ProcessingDetails::getSourceId)\n+          .forEach(\n+              id ->\n+                  Metrics.counter(\n+                          METRICS_PREFIX + \".\" + QUERY_SCOPE + \".\" + EXCEPTION_TYPE,\n+                          Tags.of(SOURCE_TAG, id))\n+                      .increment());\n+\n+      results\n+          .stream()\n+          .map(Result::getMetacard)\n+          .map(Metacard::getSourceId)\n+          .forEach(\n+              id ->\n+                  Metrics.counter(\n+                          METRICS_PREFIX + \".\" + QUERY_SCOPE + \".\" + RESULTS_TYPE,\n+                          Tags.of(SOURCE_TAG, id))\n+                      .increment());\n+\n+      properties\n+          .entrySet()\n+          .stream()\n+          .filter(e -> e.getKey().startsWith(METRICS_SOURCE_ELAPSED_PREFIX))", "originalCommit": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3OTkzOA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445179938", "bodyText": "\u2753 Looks unlikely, but could there be an exception AND a timeout? If so the status code will get 'confused'", "author": "leo-sakh", "createdAt": "2020-06-24T21:23:49Z", "path": "platform/metrics/metrics-servlet-filter/src/main/java/org/codice/ddf/metrics/servlet/ServletMetrics.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package org.codice.ddf.metrics.servlet;\n+\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.IOException;\n+import javax.servlet.AsyncEvent;\n+import javax.servlet.AsyncListener;\n+import javax.servlet.Filter;\n+import javax.servlet.FilterChain;\n+import javax.servlet.FilterConfig;\n+import javax.servlet.ServletException;\n+import javax.servlet.ServletRequest;\n+import javax.servlet.ServletResponse;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ServletMetrics implements Filter {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ServletMetrics.class);\n+\n+  private static final String METRICS_PREFIX = \"ddf.platform.http\";\n+\n+  private static final String HISTOGRAM_NAME = \"latency\";\n+\n+  @Override\n+  public void init(FilterConfig filterConfig) throws ServletException {\n+    LOGGER.debug(\"Adding metrics security filter.\");\n+  }\n+\n+  @Override\n+  public void doFilter(\n+      ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain)\n+      throws IOException, ServletException {\n+    boolean hadException = false;\n+    long startTime = System.currentTimeMillis();\n+    try {\n+      chain.doFilter(servletRequest, servletResponse);\n+    } catch (Exception ex) {\n+      hadException = true;\n+      throw ex;\n+    } finally {\n+      HttpServletRequest request = (HttpServletRequest) servletRequest;\n+      HttpServletResponse response = (HttpServletResponse) servletResponse;\n+\n+      if (!hadException && request.isAsyncStarted()) {\n+        request.getAsyncContext().addListener(new AsyncResponseListener(startTime));\n+      } else {\n+        record(request, response, startTime, hadException, false);\n+      }\n+    }\n+  }\n+\n+  private static void record(\n+      HttpServletRequest request,\n+      HttpServletResponse response,\n+      long startTime,\n+      boolean hadException,\n+      boolean hadTimeout) {\n+    long endTime = System.currentTimeMillis();\n+    long latency = endTime - startTime;\n+\n+    DistributionSummary.builder(METRICS_PREFIX + \".\" + HISTOGRAM_NAME)\n+        .baseUnit(\"milliseconds\")\n+        .tags(\n+            \"method\",\n+            request.getMethod(),\n+            \"status\",\n+            getStatusCode(response, hadException, hadTimeout))\n+        .publishPercentiles(0.5, 0.95)\n+        .register(Metrics.globalRegistry)\n+        .record(latency);\n+  }\n+\n+  private static String getStatusCode(\n+      HttpServletResponse response, boolean hadException, boolean hadTimeout) {\n+    String result = String.valueOf(response.getStatus());\n+    if (hadException && response.getStatus() != 500) {", "originalCommit": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTY4NjI3NQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445686275", "bodyText": "The API was not clear on that.\nhttps://docs.oracle.com/javaee/7/api/javax/servlet/AsyncListener.html\nCurrently it does not appear that would happen with Jetty.\nhttps://github.com/eclipse/jetty.project/blob/1d734e1daff393968b231626cf223e76f605b0c3/jetty-servlets/src/test/java/org/eclipse/jetty/servlets/AsyncTimeoutCompleteWrite.java#L38-L42\nIt is ordered so that less specific case (hadException) will log but the more specific case (hadTimeout) will log and return for metrics tagging.", "author": "pklinef", "createdAt": "2020-06-25T16:29:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3OTkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTU0MjUxOA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445542518", "bodyText": "look like this method is not being used anymore", "author": "lamhuy", "createdAt": "2020-06-25T13:05:36Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,226 +13,288 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n+import javax.validation.constraints.NotNull;\n import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n-\n-  protected final Meter unsupportedQueryExceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter queries;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter fuzzyQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n+  private final Counter createdMetacards;\n \n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n+  private final Counter updatedMetacards;\n \n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter deletedMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n-\n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n-\n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));\n       }\n     } catch (UnsupportedQueryException e) {\n       // ignore filters not supported by the QueryTypeFilterDelegate\n     }\n \n+    addStartTime(input);\n+    return input;\n+  }\n+\n+  // PostQuery\n+  @Override\n+  public QueryResponse process(QueryResponse input)\n+      throws PluginExecutionException, StopProcessingException {\n+    recordLatency(input, QUERY_SCOPE);\n+    hits.record(input.getHits());\n+    recordExceptions(input.getProcessingDetails(), QUERY_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreCreate\n+  @Override\n+  public CreateRequest process(CreateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostCreate\n   @Override\n   public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      createdMetacards.mark(input.getCreatedMetacards().size());\n-    }\n+    recordLatency(input, CREATE_SCOPE);\n+    createdMetacards.increment(input.getCreatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), CREATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreUpdate\n+  @Override\n+  public UpdateRequest process(UpdateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostUpdate\n   @Override\n   public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      updatedMetacards.mark(input.getUpdatedMetacards().size());\n-    }\n+    recordLatency(input, UPDATE_SCOPE);\n+    updatedMetacards.increment(input.getUpdatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), UPDATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreDelete\n+  @Override\n+  public DeleteRequest process(DeleteRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostDelete\n   @Override\n   public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      deletedMetacards.mark(input.getDeletedMetacards().size());\n-    }\n+    recordLatency(input, DELETE_SCOPE);\n+    deletedMetacards.increment(input.getDeletedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), DELETE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreResource\n+  @Override\n+  public ResourceRequest process(ResourceRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostResource\n   @Override\n   public ResourceResponse process(ResourceResponse input)\n       throws PluginExecutionException, StopProcessingException {\n-    resourceRetrival.mark();\n+    recordLatency(input, RESOURCE_SCOPE);\n+    recordExceptions(input.getProcessingErrors(), RESOURCE_SCOPE);\n+\n     return input;\n   }\n \n-  private void recordSourceQueryExceptions(QueryResponse response) {\n-    Set<ProcessingDetails> processingDetails =\n-        (Set<ProcessingDetails>) response.getProcessingDetails();\n-\n-    if (processingDetails == null || processingDetails.iterator() == null) {\n+  private void recordExceptions(Set<ProcessingDetails> processingDetails, String operation) {\n+    if (processingDetails == null) {\n       return;\n     }\n \n-    Iterator<ProcessingDetails> iterator = processingDetails.iterator();\n-    while (iterator.hasNext()) {\n-      ProcessingDetails next = iterator.next();\n+    for (ProcessingDetails next : processingDetails) {\n       if (next != null && next.getException() != null) {\n-        if (next.getException() instanceof UnsupportedQueryException) {\n-          unsupportedQueryExceptions.mark();\n-        } else if (next.getException() instanceof SourceUnavailableException) {\n-          sourceUnavailableExceptions.mark();\n-        } else if (next.getException() instanceof FederationException) {\n-          federationExceptions.mark();\n-        }\n-        exceptions.mark();\n+        String exceptionName = rootCauseExceptionName(next.getException());\n+        Metrics.counter(\n+                metricName(METRIC_PREFIX, operation, EXCEPTIONS_SCOPE),\n+                \"type\",\n+                exceptionName,\n+                \"source\",\n+                next.getSourceId())\n+            .increment();\n       }\n     }\n+  }\n+\n+  private String rootCauseExceptionName(Exception exception) {\n+    Throwable rootCause = exception;\n+    while (rootCause.getCause() != null && rootCause.getCause() != rootCause) {\n+      rootCause = rootCause.getCause();\n+    }\n+    return rootCause.getClass().getName();\n+  }\n+\n+  private String metricName(String... parts) {\n+    return String.join(\".\", parts);\n+  }\n+\n+  private Set<String> getSourceIds(QueryRequest query) {\n+    Set<String> result;\n+\n+    if (query.isEnterprise()) {\n+      result = Collections.singleton(\"enterprise\");\n+    } else if (query.getSourceIds() == null || query.getSourceIds().isEmpty()) {\n+      result = Collections.singleton(SystemInfo.getSiteName());\n+    } else {\n+      result = query.getSourceIds();\n+    }\n+\n+    return result;\n+  }\n+\n+  private void incrementCounter(String sourceId, String queryType) {\n+    Metrics.counter(metricName(METRIC_PREFIX, QUERY_SCOPE, queryType), \"source\", sourceId)\n+        .increment();\n+  }\n+\n+  private boolean isNone(QueryTypeFilterDelegate queryType) {\n+    return !(queryType.isComparison()\n+        || queryType.isSpatial()\n+        || queryType.isFuzzy()\n+        || queryType.isTemporal()\n+        || queryType.isFunction());\n+  }\n+\n+  private void addStartTime(Request request) {\n+    request.getProperties().put(METRICS_OPERATION_START, System.currentTimeMillis());\n+  }\n+\n+  private void recordLatency(Response<? extends Request> response, String operation) {\n+    Serializable start = response.getRequest().getPropertyValue(METRICS_OPERATION_START);\n+    long latency = calculateLatency((Long) start);\n+\n+    if (latency > 0) {\n+      DistributionSummary.builder(metricName(METRIC_PREFIX, operation, \"latency\"))\n+          .baseUnit(\"milliseconds\")\n+          .tags(\"successful\", Boolean.toString(response.getProcessingErrors().isEmpty()))\n+          .publishPercentiles(0.5, 0.95)\n+          .register(Metrics.globalRegistry)\n+          .record(latency);\n+    }\n+  }\n+\n+  private long calculateLatency(Long start) {\n+    if (start == null) {\n+      return 0;\n+    }\n \n-    return;\n+    long end = System.currentTimeMillis();\n+    return end - (Long) start;\n   }\n \n   private boolean isFederated(QueryRequest queryRequest) {", "originalCommit": "cbed6467b8b3e9e984d4507d9aae4bf27a1403bc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f9e92fcfc79223b66b3c9234c4515e6b5805f514", "url": "https://github.com/codice/ddf/commit/f9e92fcfc79223b66b3c9234c4515e6b5805f514", "message": "Replace Dropwizard Metrics with Micrometer\n\nAdded new metrics\nExposed metrics through Prometheus endpoint\nReplaced CXF interceptor with servlet filter\nFixed bundle refresh of dynamically injected servlet filters", "committedDate": "2020-06-25T15:50:48Z", "type": "forcePushed"}, {"oid": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "url": "https://github.com/codice/ddf/commit/8ff7949013e3bf581aa74ec2f78fa578b83cc121", "message": "Replace Dropwizard Metrics with Micrometer\n\nAdded new metrics\nExposed metrics through Prometheus endpoint\nReplaced CXF interceptor with servlet filter\nFixed bundle refresh of dynamically injected servlet filters", "committedDate": "2020-06-25T16:39:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5MTYyNQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445791625", "bodyText": "\u2753 If this class is final then why are the bulk of the variables protected couldn't they be private instead?", "author": "Lambeaux", "createdAt": "2020-06-25T19:33:02Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg2NzY0OQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445867649", "bodyText": "Looks like that was done to share one const with the unit tests.  I will make them private.", "author": "pklinef", "createdAt": "2020-06-25T22:12:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5MTYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5MjYzMw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445792633", "bodyText": "\u270f\ufe0f  Isn't our default assumption @NotNull unless @Nullable is present?", "author": "Lambeaux", "createdAt": "2020-06-25T19:35:10Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg2ODY5Nw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445868697", "bodyText": "That sounds correct.  Looks like this was added as part of the cherry pick.  I will clean that up.", "author": "pklinef", "createdAt": "2020-06-25T22:15:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5MjYzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5MzI2MA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445793260", "bodyText": "\u270f\ufe0f  this.*", "author": "Lambeaux", "createdAt": "2020-06-25T19:36:33Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5NTg2MA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445795860", "bodyText": "\u2753 Probably don't need DEBUG but should we add TRACE logging for these conditions?", "author": "Lambeaux", "createdAt": "2020-06-25T19:41:44Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg3MzYyMQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445873621", "bodyText": "I do not have an easy, safe way to represent the given query in this class.  We will see be able to see the none label being incremented.  I will add in logging and a counter for the unsupported case though.", "author": "pklinef", "createdAt": "2020-06-25T22:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTc5NTg2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgwNDgyMw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445804823", "bodyText": "\u2753 Is a static call the only option? Can we not inject an interface?", "author": "Lambeaux", "createdAt": "2020-06-25T19:59:30Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));\n       }\n     } catch (UnsupportedQueryException e) {\n       // ignore filters not supported by the QueryTypeFilterDelegate\n     }\n \n+    addStartTime(input);\n+    return input;\n+  }\n+\n+  // PostQuery\n+  @Override\n+  public QueryResponse process(QueryResponse input)\n+      throws PluginExecutionException, StopProcessingException {\n+    recordLatency(input, QUERY_SCOPE);\n+    hits.record(input.getHits());\n+    recordExceptions(input.getProcessingDetails(), QUERY_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreCreate\n+  @Override\n+  public CreateRequest process(CreateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostCreate\n   @Override\n   public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      createdMetacards.mark(input.getCreatedMetacards().size());\n-    }\n+    recordLatency(input, CREATE_SCOPE);\n+    createdMetacards.increment(input.getCreatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), CREATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreUpdate\n+  @Override\n+  public UpdateRequest process(UpdateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostUpdate\n   @Override\n   public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      updatedMetacards.mark(input.getUpdatedMetacards().size());\n-    }\n+    recordLatency(input, UPDATE_SCOPE);\n+    updatedMetacards.increment(input.getUpdatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), UPDATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreDelete\n+  @Override\n+  public DeleteRequest process(DeleteRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostDelete\n   @Override\n   public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      deletedMetacards.mark(input.getDeletedMetacards().size());\n-    }\n+    recordLatency(input, DELETE_SCOPE);\n+    deletedMetacards.increment(input.getDeletedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), DELETE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreResource\n+  @Override\n+  public ResourceRequest process(ResourceRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostResource\n   @Override\n   public ResourceResponse process(ResourceResponse input)\n       throws PluginExecutionException, StopProcessingException {\n-    resourceRetrival.mark();\n+    recordLatency(input, RESOURCE_SCOPE);\n+    recordExceptions(input.getProcessingErrors(), RESOURCE_SCOPE);\n+\n     return input;\n   }\n \n-  private void recordSourceQueryExceptions(QueryResponse response) {\n-    Set<ProcessingDetails> processingDetails =\n-        (Set<ProcessingDetails>) response.getProcessingDetails();\n-\n-    if (processingDetails == null || processingDetails.iterator() == null) {\n+  private void recordExceptions(Set<ProcessingDetails> processingDetails, String operation) {\n+    if (processingDetails == null) {\n       return;\n     }\n \n-    Iterator<ProcessingDetails> iterator = processingDetails.iterator();\n-    while (iterator.hasNext()) {\n-      ProcessingDetails next = iterator.next();\n+    for (ProcessingDetails next : processingDetails) {\n       if (next != null && next.getException() != null) {\n-        if (next.getException() instanceof UnsupportedQueryException) {\n-          unsupportedQueryExceptions.mark();\n-        } else if (next.getException() instanceof SourceUnavailableException) {\n-          sourceUnavailableExceptions.mark();\n-        } else if (next.getException() instanceof FederationException) {\n-          federationExceptions.mark();\n-        }\n-        exceptions.mark();\n+        String exceptionName = rootCauseExceptionName(next.getException());\n+        Metrics.counter(", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg2NTU4OQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445865589", "bodyText": "Less concerned about this after reviewing the dependencies.", "author": "Lambeaux", "createdAt": "2020-06-25T22:07:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgwNDgyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgxNDQ1Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445814456", "bodyText": "\u2753 If we encounter the opposite is there anything we could do to fix it? Or would it not matter?\nif (latency <= 0) {\n  LOGGER.trace(\"Computed a suspicious latency of {} for {}\", latency, operation);\n  return;\n}\n\nDistributionSummary.builder(...)", "author": "Lambeaux", "createdAt": "2020-06-25T20:19:02Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));\n       }\n     } catch (UnsupportedQueryException e) {\n       // ignore filters not supported by the QueryTypeFilterDelegate\n     }\n \n+    addStartTime(input);\n+    return input;\n+  }\n+\n+  // PostQuery\n+  @Override\n+  public QueryResponse process(QueryResponse input)\n+      throws PluginExecutionException, StopProcessingException {\n+    recordLatency(input, QUERY_SCOPE);\n+    hits.record(input.getHits());\n+    recordExceptions(input.getProcessingDetails(), QUERY_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreCreate\n+  @Override\n+  public CreateRequest process(CreateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostCreate\n   @Override\n   public CreateResponse process(CreateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      createdMetacards.mark(input.getCreatedMetacards().size());\n-    }\n+    recordLatency(input, CREATE_SCOPE);\n+    createdMetacards.increment(input.getCreatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), CREATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreUpdate\n+  @Override\n+  public UpdateRequest process(UpdateRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostUpdate\n   @Override\n   public UpdateResponse process(UpdateResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      updatedMetacards.mark(input.getUpdatedMetacards().size());\n-    }\n+    recordLatency(input, UPDATE_SCOPE);\n+    updatedMetacards.increment(input.getUpdatedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), UPDATE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreDelete\n+  @Override\n+  public DeleteRequest process(DeleteRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostDelete\n   @Override\n   public DeleteResponse process(DeleteResponse input) throws PluginExecutionException {\n-    if (Requests.isLocal(input.getRequest())) {\n-      deletedMetacards.mark(input.getDeletedMetacards().size());\n-    }\n+    recordLatency(input, DELETE_SCOPE);\n+    deletedMetacards.increment(input.getDeletedMetacards().size());\n+    recordExceptions(input.getProcessingErrors(), DELETE_SCOPE);\n+\n+    return input;\n+  }\n+\n+  // PreResource\n+  @Override\n+  public ResourceRequest process(ResourceRequest input)\n+      throws PluginExecutionException, StopProcessingException {\n+    addStartTime(input);\n     return input;\n   }\n \n   // PostResource\n   @Override\n   public ResourceResponse process(ResourceResponse input)\n       throws PluginExecutionException, StopProcessingException {\n-    resourceRetrival.mark();\n+    recordLatency(input, RESOURCE_SCOPE);\n+    recordExceptions(input.getProcessingErrors(), RESOURCE_SCOPE);\n+\n     return input;\n   }\n \n-  private void recordSourceQueryExceptions(QueryResponse response) {\n-    Set<ProcessingDetails> processingDetails =\n-        (Set<ProcessingDetails>) response.getProcessingDetails();\n-\n-    if (processingDetails == null || processingDetails.iterator() == null) {\n+  private void recordExceptions(Set<ProcessingDetails> processingDetails, String operation) {\n+    if (processingDetails == null) {\n       return;\n     }\n \n-    Iterator<ProcessingDetails> iterator = processingDetails.iterator();\n-    while (iterator.hasNext()) {\n-      ProcessingDetails next = iterator.next();\n+    for (ProcessingDetails next : processingDetails) {\n       if (next != null && next.getException() != null) {\n-        if (next.getException() instanceof UnsupportedQueryException) {\n-          unsupportedQueryExceptions.mark();\n-        } else if (next.getException() instanceof SourceUnavailableException) {\n-          sourceUnavailableExceptions.mark();\n-        } else if (next.getException() instanceof FederationException) {\n-          federationExceptions.mark();\n-        }\n-        exceptions.mark();\n+        String exceptionName = rootCauseExceptionName(next.getException());\n+        Metrics.counter(\n+                metricName(METRIC_PREFIX, operation, EXCEPTIONS_SCOPE),\n+                \"type\",\n+                exceptionName,\n+                \"source\",\n+                next.getSourceId())\n+            .increment();\n       }\n     }\n+  }\n+\n+  private String rootCauseExceptionName(Exception exception) {\n+    Throwable rootCause = exception;\n+    while (rootCause.getCause() != null && rootCause.getCause() != rootCause) {\n+      rootCause = rootCause.getCause();\n+    }\n+    return rootCause.getClass().getName();\n+  }\n+\n+  private String metricName(String... parts) {\n+    return String.join(\".\", parts);\n+  }\n+\n+  private Set<String> getSourceIds(QueryRequest query) {\n+    if (query.isEnterprise()) {\n+      return Collections.singleton(\"enterprise\");\n+    }\n \n-    return;\n+    if (query.getSourceIds() == null || query.getSourceIds().isEmpty()) {\n+      return Collections.singleton(SystemInfo.getSiteName());\n+    }\n+\n+    return query.getSourceIds();\n+  }\n+\n+  private void incrementCounter(String sourceId, String queryType) {\n+    Metrics.counter(metricName(METRIC_PREFIX, QUERY_SCOPE, queryType), \"source\", sourceId)\n+        .increment();\n   }\n \n-  private boolean isFederated(QueryRequest queryRequest) {\n-    Set<String> sourceIds = queryRequest.getSourceIds();\n+  private boolean isNone(QueryTypeFilterDelegate queryType) {\n+    return !(queryType.isComparison()\n+        || queryType.isSpatial()\n+        || queryType.isFuzzy()\n+        || queryType.isTemporal()\n+        || queryType.isFunction());\n+  }\n \n-    if (queryRequest.isEnterprise()) {\n-      return true;\n-    } else if (sourceIds == null) {\n-      return false;\n-    } else {\n-      return (sourceIds.size() > 1)\n-          || (sourceIds.size() == 1\n-              && sourceIds.stream().noneMatch(StringUtils::isEmpty)\n-              && !sourceIds.contains(SystemInfo.getSiteName()));\n+  private void addStartTime(Request request) {\n+    request.getProperties().put(METRICS_OPERATION_START, System.currentTimeMillis());\n+  }\n+\n+  private void recordLatency(Response<? extends Request> response, String operation) {\n+    Serializable start = response.getRequest().getPropertyValue(METRICS_OPERATION_START);\n+    long latency = calculateLatency((Long) start);\n+\n+    if (latency > 0) {", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg3NDEwMQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445874101", "bodyText": "I don't think there is much we could do but it does not hurt to log it just in case it starts to happen due to a broken source or plugin.", "author": "pklinef", "createdAt": "2020-06-25T22:30:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgxNDQ1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgxOTc0Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445819746", "bodyText": "\ud83d\udc4d  Less concerned about my comment regarding interface injection", "author": "Lambeaux", "createdAt": "2020-06-25T20:29:43Z", "path": "catalog/core/catalog-core-metricsplugin/src/test/java/ddf/catalog/metrics/CatalogMetricsTest.java", "diffHunk": "@@ -33,146 +33,119 @@\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n import ddf.catalog.operation.Update;\n import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.operation.impl.ProcessingDetailsImpl;\n import ddf.catalog.operation.impl.QueryImpl;\n import ddf.catalog.operation.impl.QueryRequestImpl;\n import ddf.catalog.operation.impl.QueryResponseImpl;\n-import ddf.catalog.source.SourceUnavailableException;\n+import ddf.catalog.source.IngestException;\n import ddf.catalog.source.UnsupportedQueryException;\n+import io.micrometer.core.instrument.MeterRegistry;\n+import io.micrometer.core.instrument.Metrics;\n+import io.micrometer.core.instrument.Tag;\n+import io.micrometer.core.instrument.Tags;\n+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;\n+import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.Arrays;\n+import java.util.Collections;\n import java.util.Date;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n import org.codice.ddf.configuration.SystemInfo;\n-import org.junit.After;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n import org.opengis.filter.Filter;\n \n-/**\n- * Tests {@link CatalogMetrics}\n- *\n- * @author Phillip Klinefelter\n- */\n public class CatalogMetricsTest {\n \n   private static FilterAdapter filterAdapter = new GeotoolsFilterAdapterImpl();\n \n   private static FilterBuilder filterBuilder = new GeotoolsFilterBuilder();\n \n+  private MeterRegistry meterRegistry;\n+\n   private static Filter idFilter =\n       filterBuilder.attribute(Metacard.ID).is().equalTo().text(\"metacardId\");\n \n-  private CatalogMetrics underTest;\n+  private CatalogMetrics catalogMetrics;\n+\n+  @Rule public ExpectedException exception = ExpectedException.none();\n \n   @Before\n   public void setup() {\n-    underTest = new CatalogMetrics(filterAdapter);\n+    meterRegistry = new SimpleMeterRegistry();\n+    Metrics.addRegistry(meterRegistry);", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyMjQ2Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445822466", "bodyText": "\u2753 Should we add a general assertThatMeterRegistryClear() or assertThatMeterRegistryClearExceptFor(\"ddf.catalog.query.comparison\", \"ddf.catalog.query.x\") to better clarify our default expectations? This applies to all tests not just this one.", "author": "Lambeaux", "createdAt": "2020-06-25T20:35:02Z", "path": "catalog/core/catalog-core-metricsplugin/src/test/java/ddf/catalog/metrics/CatalogMetricsTest.java", "diffHunk": "@@ -33,146 +33,119 @@\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n import ddf.catalog.operation.Update;\n import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.operation.impl.ProcessingDetailsImpl;\n import ddf.catalog.operation.impl.QueryImpl;\n import ddf.catalog.operation.impl.QueryRequestImpl;\n import ddf.catalog.operation.impl.QueryResponseImpl;\n-import ddf.catalog.source.SourceUnavailableException;\n+import ddf.catalog.source.IngestException;\n import ddf.catalog.source.UnsupportedQueryException;\n+import io.micrometer.core.instrument.MeterRegistry;\n+import io.micrometer.core.instrument.Metrics;\n+import io.micrometer.core.instrument.Tag;\n+import io.micrometer.core.instrument.Tags;\n+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;\n+import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.Arrays;\n+import java.util.Collections;\n import java.util.Date;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Set;\n+import java.util.concurrent.ExecutionException;\n import org.codice.ddf.configuration.SystemInfo;\n-import org.junit.After;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n import org.opengis.filter.Filter;\n \n-/**\n- * Tests {@link CatalogMetrics}\n- *\n- * @author Phillip Klinefelter\n- */\n public class CatalogMetricsTest {\n \n   private static FilterAdapter filterAdapter = new GeotoolsFilterAdapterImpl();\n \n   private static FilterBuilder filterBuilder = new GeotoolsFilterBuilder();\n \n+  private MeterRegistry meterRegistry;\n+\n   private static Filter idFilter =\n       filterBuilder.attribute(Metacard.ID).is().equalTo().text(\"metacardId\");\n \n-  private CatalogMetrics underTest;\n+  private CatalogMetrics catalogMetrics;\n+\n+  @Rule public ExpectedException exception = ExpectedException.none();\n \n   @Before\n   public void setup() {\n-    underTest = new CatalogMetrics(filterAdapter);\n+    meterRegistry = new SimpleMeterRegistry();\n+    Metrics.addRegistry(meterRegistry);\n+    catalogMetrics = new CatalogMetrics(filterAdapter);\n     System.setProperty(SystemInfo.SITE_NAME, \"testSite\");\n   }\n \n-  @After\n-  public void tearDown() {\n-\n-    // Remove the metrics created when setup() instantiated CatalogMetrics -\n-    // otherwise get lots of exceptions that metric already exists which fill\n-    // up the log to point of Travis CI build failing\n-\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"TotalResults\"));\n-\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Federated\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Comparison\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Spatial\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Fuzzy\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Temporal\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.QUERIES_SCOPE, \"Function\"));\n-\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.EXCEPTIONS_SCOPE));\n-    underTest.metrics.remove(\n-        MetricRegistry.name(CatalogMetrics.EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    underTest.metrics.remove(\n-        MetricRegistry.name(CatalogMetrics.EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.EXCEPTIONS_SCOPE, \"Federation\"));\n-\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.INGEST_SCOPE, \"Created\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.INGEST_SCOPE, \"Updated\"));\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.INGEST_SCOPE, \"Deleted\"));\n-\n-    underTest.metrics.remove(MetricRegistry.name(CatalogMetrics.RESOURCE_SCOPE));\n-\n-    underTest.reporter.stop();\n-  }\n-\n   @Test\n-  public void catalogQueryMetric() throws Exception {\n-    QueryRequest query = new QueryRequestImpl(new QueryImpl(idFilter));\n-    underTest.process(query);\n-\n-    assertThat(underTest.queries.getCount(), is(1L));\n-    assertThat(underTest.comparisonQueries.getCount(), is(1L));\n+  public void testNullFilterAdapter() {\n+    exception.expect(NullPointerException.class);\n+    exception.expectMessage(\"filterAdapter\");\n+    new CatalogMetrics(null);\n   }\n \n   @Test\n-  public void catalogFederatedQueryMetric() throws Exception {\n-    QueryRequest query = new QueryRequestImpl(new QueryImpl(idFilter), true);\n-    underTest.process(query);\n-\n-    query = new QueryRequestImpl(new QueryImpl(idFilter), Arrays.asList(\"fedSourceId\"));\n-    underTest.process(query);\n+  public void testSourceComparisonQuery() throws Exception {\n+    Iterable<Tag> tags = Tags.of(\"source\", \"testSite\");\n+    QueryRequest query =\n+        new QueryRequestImpl(new QueryImpl(idFilter), Collections.singleton(\"testSite\"));\n+    catalogMetrics.process(query);\n \n-    query =\n-        new QueryRequestImpl(\n-            new QueryImpl(idFilter), Arrays.asList(\"fedSource1Id\", \"fedSource2Id\"));\n-    underTest.process(query);\n-\n-    assertThat(underTest.federatedQueries.getCount(), is(3L));\n+    assertThat(meterRegistry.counter(\"ddf.catalog.query.comparison\", tags).count(), is(1.0));", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg4NjU2MA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445886560", "bodyText": "I tried to come up with a way to verify this without adding too much logic or coupling to unrelated implementation details.\nFor example, assertThat(meterRegistry.getMeters().size(), is(1)); failed for most tests. The values were all over the place depending on unrelated metrics that were recorded while trying to test for one specific metric.\nBased on that I think checking for the other metrics would be too brittle.", "author": "pklinef", "createdAt": "2020-06-25T23:10:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyMjQ2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwMzkxMw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445903913", "bodyText": "Ah right because it lives in static space so all the other stuff is still getting reported. Gotcha. What if we just checked the specific component under test to ensure it was zero before we ran the plugin?", "author": "Lambeaux", "createdAt": "2020-06-26T00:11:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyMjQ2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxNjQ1MQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445916451", "bodyText": "I create a new registry in setup so the metrics are always cleared for each test.", "author": "pklinef", "createdAt": "2020-06-26T01:04:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyMjQ2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyNTU1MA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445825550", "bodyText": "\u270f\ufe0f  This confused me for a second - I would add an in-line comment that you're populating the details by reference since getProcessingDetails() is not immutable.", "author": "Lambeaux", "createdAt": "2020-06-25T20:40:58Z", "path": "catalog/core/catalog-core-metricsplugin/src/test/java/ddf/catalog/metrics/CatalogMetricsTest.java", "diffHunk": "@@ -181,55 +154,122 @@ public void catalogFunctionQueryMetric() throws Exception {\n             .textArg(\"Mary little\")\n             .equalTo()\n             .bool(true);\n+    QueryRequest query =\n+        new QueryRequestImpl(new QueryImpl(functionFilter), Collections.singleton(\"testSite\"));\n \n-    QueryRequest query = new QueryRequestImpl(new QueryImpl(functionFilter));\n-    underTest.process(query);\n-\n-    assertThat(underTest.functionQueries.getCount(), is(1L));\n-  }\n-\n-  @Test\n-  public void catalogFuzzyQueryMetric() throws Exception {\n-    Filter fuzzyFilter = filterBuilder.attribute(Metacard.ANY_TEXT).like().fuzzyText(\"fuzzy\");\n+    catalogMetrics.process(query);\n \n-    QueryRequest query = new QueryRequestImpl(new QueryImpl(fuzzyFilter));\n-    underTest.process(query);\n-\n-    assertThat(underTest.fuzzyQueries.getCount(), is(1L));\n+    assertThat(meterRegistry.counter(\"ddf.catalog.query.function\", tags).count(), is(1.0));\n   }\n \n   @Test\n-  public void catalogResultCountMetric() throws Exception {\n+  public void catalogHitsCountMetric() throws Exception {\n     QueryRequest query = new QueryRequestImpl(new QueryImpl(idFilter));\n     QueryResponse response = new QueryResponseImpl(query, new ArrayList(), 50);\n \n-    underTest.process(response);\n+    catalogMetrics.process(response);\n \n-    assertThat(underTest.resultCount.getCount(), is(1L));\n-    assertThat(underTest.resultCount.getSnapshot().getMean(), is(50.0));\n+    assertThat(meterRegistry.summary(\"ddf.catalog.query.hits\").count(), is(1L));\n+    assertThat(meterRegistry.summary(\"ddf.catalog.query.hits\").mean(), is(50.0));\n   }\n \n   @Test\n-  public void catalogExceptionMetric() throws Exception {\n+  public void catalogQueryExceptionMetric() throws Exception {\n+    Iterable<Tag> unsupportedQueryExceptionTags =\n+        Tags.of(\"type\", UnsupportedQueryException.class.getName(), \"source\", \"source1\");\n+\n     QueryResponse response = new QueryResponseImpl(new QueryRequestImpl(new QueryImpl(idFilter)));\n     Set<ProcessingDetails> details = response.getProcessingDetails();", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg4ODE0Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445888146", "bodyText": "I will use the correct constructor instead.", "author": "pklinef", "createdAt": "2020-06-25T23:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyNTU1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyOTgxMw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445829813", "bodyText": "\u2753 I see this test for latency for resource requests; do we want to verify that for all paths?\n\nFor request testing, we can verify any processed requests come back with the request property being used to compute the latency later on.\nFor response tests, we can verify the latency is in the meter registry when given the appropriate service property manually, in the test itself.\n\nThe above could be separate tests if you wanted them to be.", "author": "Lambeaux", "createdAt": "2020-06-25T20:49:33Z", "path": "catalog/core/catalog-core-metricsplugin/src/test/java/ddf/catalog/metrics/CatalogMetricsTest.java", "diffHunk": "@@ -269,17 +309,25 @@ public void catalogDeleteMetric() throws Exception {\n     when(response.getRequest()).thenReturn(request);\n     when(response.getDeletedMetacards()).thenReturn(deletedList);\n \n-    underTest.process(response);\n+    catalogMetrics.process(response);\n \n-    assertThat(underTest.deletedMetacards.getCount(), is(100L));\n+    assertThat(meterRegistry.counter(\"ddf.catalog.delete\").count(), is(100.0));\n   }\n \n   @Test\n   public void catalogResourceRetrievalMetric() throws Exception {\n+    Iterable<Tag> tags = Tags.of(\"successful\", \"true\");\n+    ResourceRequest request = mock(ResourceRequest.class);\n     ResourceResponse response = mock(ResourceResponse.class);\n+    when(response.getRequest()).thenReturn(request);\n+    when(request.getPropertyValue(METRICS_OPERATION_START))\n+        .thenReturn(System.currentTimeMillis() - 1000);\n \n-    underTest.process(response);\n+    catalogMetrics.process(response);\n \n-    assertThat(underTest.resourceRetrival.getCount(), is(1L));\n+    assertThat(meterRegistry.summary(\"ddf.catalog.resource.latency\", tags).count(), is(1L));\n+    assertThat(\n+        meterRegistry.summary(\"ddf.catalog.resource.latency\", tags).max(),\n+        greaterThanOrEqualTo(1000.0));", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg5OTMwOA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445899308", "bodyText": "Adding all pre and post latency tests for query, create, update, delete, and resource.", "author": "pklinef", "createdAt": "2020-06-25T23:54:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgyOTgxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgzMDU1Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445830556", "bodyText": "\u2753 Do we have a unit test for this? We need to verify that the returned request still has the start time property even though the exception gets thrown. I didn't see validation of that.", "author": "Lambeaux", "createdAt": "2020-06-25T20:50:55Z", "path": "catalog/core/catalog-core-metricsplugin/src/main/java/ddf/catalog/metrics/CatalogMetrics.java", "diffHunk": "@@ -13,240 +13,284 @@\n  */\n package ddf.catalog.metrics;\n \n-import com.codahale.metrics.Histogram;\n-import com.codahale.metrics.JmxReporter;\n-import com.codahale.metrics.Meter;\n-import com.codahale.metrics.MetricRegistry;\n-import com.codahale.metrics.SlidingTimeWindowReservoir;\n-import ddf.catalog.federation.FederationException;\n import ddf.catalog.filter.FilterAdapter;\n+import ddf.catalog.operation.CreateRequest;\n import ddf.catalog.operation.CreateResponse;\n+import ddf.catalog.operation.DeleteRequest;\n import ddf.catalog.operation.DeleteResponse;\n import ddf.catalog.operation.ProcessingDetails;\n import ddf.catalog.operation.QueryRequest;\n import ddf.catalog.operation.QueryResponse;\n+import ddf.catalog.operation.Request;\n+import ddf.catalog.operation.ResourceRequest;\n import ddf.catalog.operation.ResourceResponse;\n+import ddf.catalog.operation.Response;\n+import ddf.catalog.operation.UpdateRequest;\n import ddf.catalog.operation.UpdateResponse;\n import ddf.catalog.plugin.PluginExecutionException;\n import ddf.catalog.plugin.PostIngestPlugin;\n import ddf.catalog.plugin.PostQueryPlugin;\n import ddf.catalog.plugin.PostResourcePlugin;\n+import ddf.catalog.plugin.PreIngestPlugin;\n import ddf.catalog.plugin.PreQueryPlugin;\n+import ddf.catalog.plugin.PreResourcePlugin;\n import ddf.catalog.plugin.StopProcessingException;\n-import ddf.catalog.source.SourceUnavailableException;\n import ddf.catalog.source.UnsupportedQueryException;\n-import ddf.catalog.util.impl.Requests;\n-import java.util.Iterator;\n+import io.micrometer.core.instrument.Counter;\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.Serializable;\n+import java.util.Collections;\n import java.util.Set;\n-import java.util.concurrent.TimeUnit;\n-import org.apache.commons.lang.StringUtils;\n+import javax.validation.constraints.NotNull;\n+import org.apache.commons.lang3.Validate;\n import org.codice.ddf.configuration.SystemInfo;\n \n-/**\n- * Catalog plug-in to capture metrics on catalog operations.\n- *\n- * @author Phillip Klinefelter\n- */\n+/** Catalog plug-in to capture metrics on catalog operations. */\n public final class CatalogMetrics\n-    implements PreQueryPlugin, PostQueryPlugin, PostIngestPlugin, PostResourcePlugin {\n-\n-  protected static final String EXCEPTIONS_SCOPE = \"Exceptions\";\n-\n-  protected static final String QUERIES_SCOPE = \"Queries\";\n-\n-  protected static final String INGEST_SCOPE = \"Ingest\";\n-\n-  protected static final String RESOURCE_SCOPE = \"Resource\";\n-\n-  protected final MetricRegistry metrics = new MetricRegistry();\n-\n-  protected final JmxReporter reporter =\n-      JmxReporter.forRegistry(metrics).inDomain(\"ddf.metrics.catalog\").build();\n-\n-  protected final Histogram resultCount;\n-\n-  protected final Meter exceptions;\n+    implements PreQueryPlugin,\n+        PostQueryPlugin,\n+        PreIngestPlugin,\n+        PostIngestPlugin,\n+        PreResourcePlugin,\n+        PostResourcePlugin {\n \n-  protected final Meter unsupportedQueryExceptions;\n+  protected static final String METRIC_PREFIX = \"ddf.catalog\";\n \n-  protected final Meter sourceUnavailableExceptions;\n+  protected static final String EXCEPTIONS_SCOPE = \"exceptions\";\n \n-  protected final Meter federationExceptions;\n+  protected static final String QUERY_SCOPE = \"query\";\n \n-  protected final Meter queries;\n+  protected static final String CREATE_SCOPE = \"create\";\n \n-  protected final Meter federatedQueries;\n+  protected static final String UPDATE_SCOPE = \"update\";\n \n-  protected final Meter comparisonQueries;\n+  protected static final String DELETE_SCOPE = \"delete\";\n \n-  protected final Meter spatialQueries;\n+  protected static final String RESOURCE_SCOPE = \"resource\";\n \n-  protected final Meter fuzzyQueries;\n-\n-  protected final Meter functionQueries;\n-\n-  protected final Meter temporalQueries;\n-\n-  protected final Meter createdMetacards;\n-\n-  protected final Meter updatedMetacards;\n-\n-  protected final Meter deletedMetacards;\n-\n-  protected final Meter resourceRetrival;\n+  protected static final String METRICS_OPERATION_START = \"metrics.catalog.operation.start\";\n \n   private final FilterAdapter filterAdapter;\n \n-  public CatalogMetrics(FilterAdapter filterAdapter) {\n+  private final DistributionSummary hits;\n \n-    this.filterAdapter = filterAdapter;\n-\n-    resultCount =\n-        metrics.register(\n-            MetricRegistry.name(QUERIES_SCOPE, \"TotalResults\"),\n-            new Histogram(new SlidingTimeWindowReservoir(1, TimeUnit.MINUTES)));\n-\n-    queries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE));\n-    federatedQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Federated\"));\n-    comparisonQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Comparison\"));\n-    spatialQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Spatial\"));\n-    fuzzyQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Fuzzy\"));\n-    temporalQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Temporal\"));\n-    functionQueries = metrics.meter(MetricRegistry.name(QUERIES_SCOPE, \"Function\"));\n+  private final Counter createdMetacards;\n \n-    exceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE));\n-    unsupportedQueryExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"UnsupportedQuery\"));\n-    sourceUnavailableExceptions =\n-        metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"SourceUnavailable\"));\n-    federationExceptions = metrics.meter(MetricRegistry.name(EXCEPTIONS_SCOPE, \"Federation\"));\n+  private final Counter updatedMetacards;\n \n-    createdMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Created\"));\n-    updatedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Updated\"));\n-    deletedMetacards = metrics.meter(MetricRegistry.name(INGEST_SCOPE, \"Deleted\"));\n+  private final Counter deletedMetacards;\n \n-    resourceRetrival = metrics.meter(MetricRegistry.name(RESOURCE_SCOPE));\n-\n-    reporter.start();\n-  }\n+  public CatalogMetrics(@NotNull FilterAdapter filterAdapter) {\n+    Validate.notNull(filterAdapter, \"Argument filterAdapter cannot be null\");\n \n-  // PostQuery\n-  @Override\n-  public QueryResponse process(QueryResponse input)\n-      throws PluginExecutionException, StopProcessingException {\n-    resultCount.update(input.getHits());\n-    recordSourceQueryExceptions(input);\n+    this.filterAdapter = filterAdapter;\n \n-    return input;\n+    hits = Metrics.summary(metricName(METRIC_PREFIX, QUERY_SCOPE, \"hits\"));\n+    createdMetacards = Metrics.counter(metricName(METRIC_PREFIX, CREATE_SCOPE));\n+    updatedMetacards = Metrics.counter(metricName(METRIC_PREFIX, UPDATE_SCOPE));\n+    deletedMetacards = Metrics.counter(metricName(METRIC_PREFIX, DELETE_SCOPE));\n   }\n \n   // PreQuery\n   @Override\n   public QueryRequest process(QueryRequest input)\n       throws PluginExecutionException, StopProcessingException {\n-    if (isFederated(input)) {\n-      federatedQueries.mark();\n-    }\n-    queries.mark();\n-\n     QueryTypeFilterDelegate queryType = new QueryTypeFilterDelegate();\n+\n+    Set<String> sourceIds = getSourceIds(input);\n+\n     try {\n       filterAdapter.adapt(input.getQuery(), queryType);\n       if (queryType.isComparison()) {\n-        comparisonQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"comparison\"));\n       }\n       if (queryType.isSpatial()) {\n-        spatialQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"spatial\"));\n       }\n       if (queryType.isFuzzy()) {\n-        fuzzyQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"fuzzy\"));\n       }\n       if (queryType.isTemporal()) {\n-        temporalQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"temporal\"));\n       }\n       if (queryType.isFunction()) {\n-        functionQueries.mark();\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"function\"));\n+      }\n+      if (isNone(queryType)) {\n+        sourceIds.forEach(sourceId -> incrementCounter(sourceId, \"none\"));\n       }\n     } catch (UnsupportedQueryException e) {\n       // ignore filters not supported by the QueryTypeFilterDelegate\n     }", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg5MjI0Mg==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445892242", "bodyText": "We do not. I will add one.", "author": "pklinef", "createdAt": "2020-06-25T23:28:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgzMDU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgzNzk1NA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445837954", "bodyText": "\u2753 I hate suggesting to expose more configuration, but given these values live upstream and are behind several iteration impediments, is there any value to exposing these through metatype? Or are these numbers fairly stable for all cases?", "author": "Lambeaux", "createdAt": "2020-06-25T21:05:49Z", "path": "catalog/core/catalog-core-sourcemetricsplugin/src/main/java/ddf/catalog/metrics/source/SourceMetricsImpl.java", "diffHunk": "@@ -172,414 +73,59 @@ public QueryRequest process(Source source, QueryRequest input)\n   public QueryResponse process(QueryResponse input)\n       throws PluginExecutionException, StopProcessingException {\n \n-    LOGGER.trace(\"ENTERING: process (for PostFederatedQueryPlugin)\");\n-\n-    if (null != input) {\n-      Set<ProcessingDetails> processingDetails = input.getProcessingDetails();\n-      List<Result> results = input.getResults();\n-\n-      updateExceptionsMetric(processingDetails);\n-      updateTotalHitsMetric(results);\n-      updateLatencyMetric(input);\n-    }\n-\n-    LOGGER.trace(\"EXITING: process (for PostFederatedQueryPlugin)\");\n+    if (input == null) {\n+      LOGGER.debug(\"Unable to process source metrics due to null input.\");\n+      return null;\n+    }\n+\n+    Set<ProcessingDetails> processingDetails = input.getProcessingDetails();\n+    List<Result> results = input.getResults();\n+    Map<String, Serializable> properties = input.getProperties();\n+\n+    processingDetails\n+        .stream()\n+        .filter(ProcessingDetails::hasException)\n+        .map(ProcessingDetails::getSourceId)\n+        .forEach(\n+            id ->\n+                Metrics.counter(\n+                        METRICS_PREFIX + \".\" + QUERY_SCOPE + \".\" + EXCEPTION_TYPE,\n+                        Tags.of(SOURCE_TAG, id))\n+                    .increment());\n+\n+    results\n+        .stream()\n+        .map(Result::getMetacard)\n+        .map(Metacard::getSourceId)\n+        .forEach(\n+            id ->\n+                Metrics.counter(\n+                        METRICS_PREFIX + \".\" + QUERY_SCOPE + \".\" + RESULTS_TYPE,\n+                        Tags.of(SOURCE_TAG, id))\n+                    .increment());\n+\n+    properties\n+        .entrySet()\n+        .stream()\n+        .filter(e -> e.getKey() != null && e.getKey().startsWith(METRICS_SOURCE_ELAPSED_PREFIX))\n+        .forEach(SourceMetricsImpl::updateLatencyMetric);\n \n     return input;\n   }\n \n-  private void updateExceptionsMetric(Set<ProcessingDetails> processingDetails) {\n-    for (ProcessingDetails next : processingDetails) {\n-      if (next != null && next.getException() != null) {\n-        String sourceId = next.getSourceId();\n-        updateMetric(sourceId, EXCEPTIONS_SCOPE, 1);\n-      }\n-    }\n-  }\n-\n-  private void updateTotalHitsMetric(List<Result> results) {\n-    Map<String, Integer> totalHitsPerSource = new HashMap<>();\n-\n-    for (Result result : results) {\n-      String sourceId = result.getMetacard().getSourceId();\n-      if (totalHitsPerSource.containsKey(sourceId)) {\n-        totalHitsPerSource.put(sourceId, totalHitsPerSource.get(sourceId) + 1);\n-      } else {\n-        // First detection of this new source ID in the results list -\n-        // initialize the Total Query Result Count for this Source\n-        totalHitsPerSource.put(sourceId, 1);\n-      }\n-    }\n-\n-    for (Map.Entry<String, Integer> source : totalHitsPerSource.entrySet()) {\n-      updateMetric(source.getKey(), QUERIES_TOTAL_RESULTS_SCOPE, source.getValue());\n-    }\n-  }\n-\n-  private void updateLatencyMetric(QueryResponse input) {\n-    for (Map.Entry<String, Serializable> property : input.getProperties().entrySet()) {\n-      String key = property.getKey();\n-      if (key.startsWith(METRICS_SOURCE_ELAPSED_PREFIX)) {\n-        String source = key.substring(METRICS_SOURCE_ELAPSED_PREFIX.length());\n-        updateMetric(source, QUERIES_LATENCY_SCOPE, (int) property.getValue());\n-        break;\n-      }\n-    }\n-  }\n-\n-  public void updateMetric(String sourceId, String name, int incrementAmount) {\n-\n-    LOGGER.debug(\"sourceId = {},   name = {}\", sourceId, name);\n-\n-    if (StringUtils.isBlank(sourceId) || StringUtils.isBlank(name)) {\n-      return;\n-    }\n-\n-    String mapKey = sourceId + \".\" + name;\n-    SourceMetric sourceMetric = metrics.get(mapKey);\n-\n-    if (sourceMetric == null) {\n-      LOGGER.debug(\"sourceMetric is null for {} - creating metric now\", mapKey);\n-      // Loop through list of all sources until find the sourceId whose metric is being\n-      // updated\n-      boolean created = createMetric(catalogProviders, sourceId);\n-      if (!created) {\n-        createMetric(federatedSources, sourceId);\n-      }\n-      sourceMetric = metrics.get(mapKey);\n-    }\n-\n-    // If this metric already exists, then just update its MBean\n-    if (sourceMetric != null) {\n-      LOGGER.debug(\"CASE 1: Metric already exists for {}\", mapKey);\n-      if (sourceMetric.isHistogram()) {\n-        Histogram metric = (Histogram) sourceMetric.getMetric();\n-        LOGGER.debug(\"Updating histogram metric {} by amount of {}\", name, incrementAmount);\n-        metric.update(incrementAmount);\n-      } else {\n-        Meter metric = (Meter) sourceMetric.getMetric();\n-        LOGGER.debug(\"Updating metric {} by amount of {}\", name, incrementAmount);\n-        metric.mark(incrementAmount);\n-      }\n-      return;\n-    }\n-  }\n-\n-  private boolean createMetric(List<? extends Source> sources, String sourceId) {\n-    for (Source source : sources) {\n-      if (source.getId().equals(sourceId)) {\n-        LOGGER.debug(\"Found sourceId = {} in sources list\", sourceId);\n-        if (sourceToSourceIdMap.containsKey(source)) {\n-          // Source's ID must have changed since it is in this map but not in the metrics\n-          // map\n-          // Delete SourceMetrics for Source's \"old\" sourceId\n-          String oldSourceId = sourceToSourceIdMap.get(source);\n-          LOGGER.debug(\"CASE 2: source {} exists but has oldSourceId = {}\", sourceId, oldSourceId);\n-          deleteMetric(oldSourceId, QUERIES_TOTAL_RESULTS_SCOPE);\n-          deleteMetric(oldSourceId, QUERIES_LATENCY_SCOPE);\n-          deleteMetric(oldSourceId, QUERIES_SCOPE);\n-          deleteMetric(oldSourceId, EXCEPTIONS_SCOPE);\n-\n-          // Create metrics for Source with new sourceId\n-          createMetric(sourceId, QUERIES_TOTAL_RESULTS_SCOPE, MetricType.HISTOGRAM);\n-          createMetric(sourceId, QUERIES_LATENCY_SCOPE, MetricType.HISTOGRAM);\n-          createMetric(sourceId, QUERIES_SCOPE, MetricType.METER);\n-          createMetric(sourceId, EXCEPTIONS_SCOPE, MetricType.METER);\n-\n-          // Add Source to map with its new sourceId\n-          sourceToSourceIdMap.put(source, sourceId);\n-        } else {\n-          // This is a brand new Source - create metrics for it\n-          // (Should rarely happen since Sources typically have their metrics created\n-          // when the Source itself is created via the addingSource() method. This could\n-          // happen if sourceId = null when Source originally created and then its metric\n-          // needs updating because client, e.g., SortedFederationStrategy, knows the\n-          // Source exists.)\n-          LOGGER.debug(\"CASE 3: New source {} detected - creating metrics\", sourceId);\n-          createMetric(sourceId, QUERIES_TOTAL_RESULTS_SCOPE, MetricType.HISTOGRAM);\n-          createMetric(sourceId, QUERIES_LATENCY_SCOPE, MetricType.HISTOGRAM);\n-          createMetric(sourceId, QUERIES_SCOPE, MetricType.METER);\n-          createMetric(sourceId, EXCEPTIONS_SCOPE, MetricType.METER);\n-\n-          sourceToSourceIdMap.put(source, sourceId);\n-        }\n-        return true;\n-      }\n-    }\n-\n-    LOGGER.debug(\"Did not find source {} in Sources - cannot create metrics\", sourceId);\n-\n-    return false;\n-  }\n-\n-  /**\n-   * Creates metrics for new CatalogProvider or FederatedSource when they are initially created.\n-   * Metrics creation includes the JMX MBeans and associated ddf.metrics.collector.JmxCollector.\n-   *\n-   * @param source\n-   * @param props\n-   */\n-  public void addingSource(final Source source, Map props) {\n-    LOGGER.trace(\"ENTERING: addingSource\");\n-\n-    if (executorPool == null) {\n-      executorPool =\n-          Executors.newCachedThreadPool(\n-              StandardThreadFactoryBuilder.newThreadFactory(\"sourceMetricThread\"));\n-    }\n-\n-    // Creating JmxCollectors for all of the source metrics can be time consuming,\n-    // so do this in a separate thread to prevent blacklisting by EventAdmin\n-    final Runnable metricsCreator =\n-        new Runnable() {\n-          public void run() {\n-            createSourceMetrics(source);\n-          }\n-        };\n-\n-    LOGGER.debug(\"Start metricsCreator thread for Source {}\", source.getId());\n-    executorPool.execute(metricsCreator);\n-\n-    LOGGER.trace(\"EXITING: addingSource\");\n-  }\n-\n-  /**\n-   * Deletes metrics for existing CatalogProvider or FederatedSource when they are deleted. Metrics\n-   * deletion includes the JMX MBeans and associated ddf.metrics.collector.JmxCollector.\n-   *\n-   * @param source\n-   * @param props\n-   */\n-  public void deletingSource(final Source source, final Map props) {\n-    LOGGER.trace(\"ENTERING: deletingSource\");\n-\n-    if (source == null || StringUtils.isBlank(source.getId())) {\n-      LOGGER.debug(\"Not deleting metrics for NULL or blank source\");\n-      return;\n-    }\n-\n-    String sourceId = source.getId();\n-\n-    LOGGER.debug(\"sourceId = {},    props = {}\", sourceId, props);\n-\n-    deleteMetric(sourceId, QUERIES_TOTAL_RESULTS_SCOPE);\n-    deleteMetric(sourceId, QUERIES_LATENCY_SCOPE);\n-    deleteMetric(sourceId, QUERIES_SCOPE);\n-    deleteMetric(sourceId, EXCEPTIONS_SCOPE);\n-\n-    // Delete source from internal map used when updating metrics by sourceId\n-    sourceToSourceIdMap.remove(source);\n-\n-    LOGGER.trace(\"EXITING: deletingSource\");\n-  }\n-\n-  // Separate, package-scope method to allow unit testing\n-  void createSourceMetrics(final Source source) {\n-\n-    if (source == null || StringUtils.isBlank(source.getId())) {\n-      LOGGER.debug(\"Not adding metrics for NULL or blank source\");\n-      return;\n-    }\n-\n-    String sourceId = source.getId();\n-\n-    LOGGER.debug(\"sourceId = {}\", sourceId);\n-\n-    createMetric(sourceId, QUERIES_TOTAL_RESULTS_SCOPE, MetricType.HISTOGRAM);\n-    createMetric(sourceId, QUERIES_LATENCY_SCOPE, MetricType.HISTOGRAM);\n-    createMetric(sourceId, QUERIES_SCOPE, MetricType.METER);\n-    createMetric(sourceId, EXCEPTIONS_SCOPE, MetricType.METER);\n-\n-    // Add new source to internal map used when updating metrics by sourceId\n-    sourceToSourceIdMap.put(source, sourceId);\n-  }\n-\n-  private void createMetric(String sourceId, String mbeanName, MetricType type) {\n-\n-    // Create source-specific metrics for this source\n-    // (Must be done prior to creating metrics collector so that\n-    // JMX MBean exists for collector to detect).\n-    String key = sourceId + \".\" + mbeanName;\n-\n-    // Do not create metric and collector if they already exist for this source.\n-    // (This can happen for ConnectedSources because they have the same sourceId\n-    // as the local catalog provider).\n-    if (!metrics.containsKey(key)) {\n-      if (type == MetricType.HISTOGRAM) {\n-        Histogram histogram = metricsRegistry.histogram(MetricRegistry.name(sourceId, mbeanName));\n-        RrdJmxCollector collector = createGaugeMetricsCollector(sourceId, mbeanName);\n-        metrics.put(key, new SourceMetric(histogram, collector, true));\n-      } else if (type == MetricType.METER) {\n-        Meter meter = metricsRegistry.meter(MetricRegistry.name(sourceId, mbeanName));\n-        RrdJmxCollector collector = createCounterMetricsCollector(sourceId, mbeanName);\n-        metrics.put(key, new SourceMetric(meter, collector));\n-      } else {\n-        LOGGER.debug(\"Metric {} not created because unknown metric type {} specified.\", key, type);\n-      }\n-    } else {\n-      LOGGER.debug(\"Metric {} already exists - not creating again\", key);\n-    }\n-  }\n-\n-  /**\n-   * Creates the Counter JMX Collector for an associated metric's JMX MBean.\n-   *\n-   * @param sourceId\n-   * @param collectorName\n-   * @return the ddf.metrics.collector.JmxCollector created\n-   */\n-  private RrdJmxCollector createCounterMetricsCollector(String sourceId, String collectorName) {\n-    return createMetricsCollector(\n-        sourceId, collectorName, COUNT_MBEAN_ATTRIBUTE_NAME, DERIVE_DATA_SOURCE_TYPE);\n-  }\n-\n-  /**\n-   * Creates the Gauge JMX Collector for an associated metric's JMX MBean.\n-   *\n-   * @param sourceId\n-   * @param collectorName\n-   * @return the ddf.metrics.collector.JmxCollector created\n-   */\n-  private RrdJmxCollector createGaugeMetricsCollector(String sourceId, String collectorName) {\n-    return createMetricsCollector(\n-        sourceId, collectorName, MEAN_MBEAN_ATTRIBUTE_NAME, GAUGE_DATA_SOURCE_TYPE);\n-  }\n-\n-  /**\n-   * Creates the JMX Collector for an associated metric's JMX MBean.\n-   *\n-   * @param sourceId\n-   * @param collectorName\n-   * @param mbeanAttributeName usually \"Count\" or \"Mean\"\n-   * @param dataSourceType only \"DERIVE\", \"COUNTER\" or \"GAUGE\" are supported\n-   * @return the ddf.metrics.collector.JmxCollector created\n-   */\n-  private RrdJmxCollector createMetricsCollector(\n-      String sourceId, String collectorName, String mbeanAttributeName, String dataSourceType) {\n-\n-    LOGGER.trace(\n-        \"ENTERING: createMetricsCollector - sourceId = {},   collectorName = {},   mbeanAttributeName = {},   dataSourceType = {}\",\n-        sourceId,\n-        collectorName,\n-        mbeanAttributeName,\n-        dataSourceType);\n-\n-    String rrdPath = getRrdFilename(sourceId, collectorName);\n-\n-    RrdJmxCollector collector =\n-        new RrdJmxCollector(\n-            MBEAN_PACKAGE_NAME + \":name=\" + sourceId + \".\" + collectorName,\n-            mbeanAttributeName,\n-            rrdPath,\n-            dataSourceType);\n-    collector.init();\n-\n-    LOGGER.trace(\"EXITING: createMetricsCollector - sourceId = {}\", sourceId);\n-\n-    return collector;\n-  }\n-\n-  protected String getRrdFilename(String sourceId, String collectorName) {\n-\n-    // Based on the sourceId and collectorName, generate the name of the RRD file.\n-    // This RRD file will be of the form \"source<sourceId><collectorName>.rrd\" with\n-    // the non-alphanumeric characters stripped out and the next character after any\n-    // non-alphanumeric capitalized.\n-    // Example:\n-    // Given sourceId = dib30rhel-58 and collectorName = Queries.TotalResults\n-    // The resulting RRD filename would be: sourceDib30rhel58QueriesTotalResults\n-    String[] sourceIdParts = sourceId.split(ALPHA_NUMERIC_REGEX);\n-    StringBuilder newSourceIdBuilder = new StringBuilder(\"\");\n-    for (String part : sourceIdParts) {\n-      newSourceIdBuilder.append(StringUtils.capitalize(part));\n-    }\n-    String rrdPath = \"source\" + newSourceIdBuilder.toString() + collectorName;\n-    LOGGER.debug(\"BEFORE: rrdPath = {}\", rrdPath);\n-\n-    // Sterilize RRD path name by removing any non-alphanumeric characters - this would confuse\n-    // the\n-    // URL being generated for this RRD path in the Metrics tab of Admin console.\n-    rrdPath = rrdPath.replaceAll(ALPHA_NUMERIC_REGEX, \"\");\n-    LOGGER.debug(\"AFTER: rrdPath = {}\", rrdPath);\n-\n-    return rrdPath;\n-  }\n-\n-  /**\n-   * Delete the metric's MBean for the specified Source.\n-   *\n-   * @param sourceId\n-   * @param mbeanName\n-   */\n-  private void deleteMetric(String sourceId, String mbeanName) {\n-\n-    String key = sourceId + \".\" + mbeanName;\n-    if (metrics.containsKey(key)) {\n-      metricsRegistry.remove(MetricRegistry.name(sourceId, mbeanName));\n-      deleteCollector(sourceId, mbeanName);\n-      metrics.remove(key);\n-    } else {\n-      LOGGER.debug(\"Did not remove metric {} because it was not in metrics map\", key);\n-    }\n-  }\n-\n-  /**\n-   * Delete the ddf.metrics.collector.JmxCollector for the specified Source and MBean.\n-   *\n-   * @param sourceId\n-   * @param metricName\n-   */\n-  private void deleteCollector(String sourceId, String metricName) {\n-    String mapKey = sourceId + \".\" + metricName;\n-    SourceMetric sourceMetric = metrics.get(mapKey);\n-    LOGGER.debug(\n-        \"Deleting {} ddf.metrics.collector.JmxCollector for source {}\", metricName, sourceId);\n-    sourceMetric.getCollector().destroy();\n-    metrics.remove(mapKey);\n-  }\n-\n-  // The types of Yammer Metrics supported\n-  private enum MetricType {\n-    HISTOGRAM,\n-    METER\n-  }\n-\n-  /**\n-   * Inner class POJO to maintain details of each metric for each Source.\n-   *\n-   * @author rodgersh\n-   */\n-  public static class SourceMetric {\n-\n-    // The Yammer Metric\n-    private Metric metric;\n-\n-    // The ddf.metrics.collector.JmxCollector polling this metric's MBean\n-    private RrdJmxCollector collector;\n-\n-    // Whether this metric is a Histogram or Meter\n-    private boolean isHistogram = false;\n-\n-    public SourceMetric(Metric metric, RrdJmxCollector collector) {\n-      this(metric, collector, false);\n-    }\n-\n-    public SourceMetric(Metric metric, RrdJmxCollector collector, boolean isHistogram) {\n-      this.metric = metric;\n-      this.collector = collector;\n-      this.isHistogram = isHistogram;\n-    }\n-\n-    public Metric getMetric() {\n-      return metric;\n-    }\n-\n-    public RrdJmxCollector getCollector() {\n-      return collector;\n-    }\n-\n-    public boolean isHistogram() {\n-      return isHistogram;\n-    }\n+  private static void updateLatencyMetric(Map.Entry<String, Serializable> property) {\n+    String key = property.getKey();\n+    String source = key.substring(METRICS_SOURCE_ELAPSED_PREFIX.length());\n+    DistributionSummary latency =\n+        LATENCY_SUMMARIES.computeIfAbsent(\n+            source,\n+            src ->\n+                DistributionSummary.builder(METRICS_PREFIX + \".\" + LATENCY_TYPE)\n+                    .description(\"Latency of catalog source requests.\")\n+                    .tag(SOURCE_TAG, src)\n+                    .baseUnit(\"milliseconds\")\n+                    .publishPercentiles(0.5, 0.95)", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwMzkwNw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445903907", "bodyText": "I think those numbers should be stable.  I based them off the defaults shown in the Micrometer examples.\nhttps://micrometer.io/docs/concepts#_histograms_and_percentiles\n\nIf it\u2019s so critical that we look at a lot of nines (and it is), why do most monitoring systems stop at the 95th or 99th percentile? The answer is simply because \u201cit\u2019s hard!\u201d The data collected by most monitoring systems is usually summarized in small, five or ten second windows. This, combined with the fact that we can\u2019t average percentiles or derive five nines from a bunch of small samples of percentiles means there\u2019s no way to know what the 99.999th percentile for the minute or hour was. We end up throwing away a lot of good data and losing fidelity.\nhttps://bravenewgeek.com/everything-you-know-about-latency-is-wrong/\n\nI think Micrometer does use HdrHistogram though.", "author": "pklinef", "createdAt": "2020-06-26T00:11:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTgzNzk1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NDYwNQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445854605", "bodyText": "\u2753 Does this mean the metrics are taking into account \"dead time\" where processing has finished but now we're just waiting for the client to retrieve the result? Do we want that? Would misbehaved clients throw off our metrics? Or is that exactly the kind of info we're looking for?", "author": "Lambeaux", "createdAt": "2020-06-25T21:41:18Z", "path": "platform/metrics/metrics-servlet-filter/src/main/java/org/codice/ddf/metrics/servlet/ServletMetrics.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package org.codice.ddf.metrics.servlet;\n+\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.IOException;\n+import javax.servlet.AsyncEvent;\n+import javax.servlet.AsyncListener;\n+import javax.servlet.Filter;\n+import javax.servlet.FilterChain;\n+import javax.servlet.FilterConfig;\n+import javax.servlet.ServletException;\n+import javax.servlet.ServletRequest;\n+import javax.servlet.ServletResponse;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ServletMetrics implements Filter {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ServletMetrics.class);\n+\n+  private static final String METRICS_PREFIX = \"ddf.platform.http\";\n+\n+  private static final String HISTOGRAM_NAME = \"latency\";\n+\n+  @Override\n+  public void init(FilterConfig filterConfig) throws ServletException {\n+    LOGGER.debug(\"Adding metrics security filter.\");\n+  }\n+\n+  @Override\n+  public void doFilter(\n+      ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain)\n+      throws IOException, ServletException {\n+    boolean hadException = false;\n+    long startTime = System.currentTimeMillis();\n+    try {\n+      chain.doFilter(servletRequest, servletResponse);\n+    } catch (Exception ex) {\n+      hadException = true;\n+      throw ex;\n+    } finally {\n+      HttpServletRequest request = (HttpServletRequest) servletRequest;\n+      HttpServletResponse response = (HttpServletResponse) servletResponse;\n+\n+      if (!hadException && request.isAsyncStarted()) {\n+        request.getAsyncContext().addListener(new AsyncResponseListener(startTime));", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwNTI5NA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445905294", "bodyText": "I don't think so.  This is to support non-blocking IO servlets. I based this on how Dropwizard Metrics handles servlet metrics.\nhttps://blogs.oracle.com/arungupta/non-blocking-io-using-servlet-31:-scalable-applications-using-java-ee-7-totd-188", "author": "pklinef", "createdAt": "2020-06-26T00:17:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NDYwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxMjM0Ng==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445912346", "bodyText": "Yeah if the servlets are still blocking the consumer but on the backend the thread ratio is no longer 1-to-1 for blocked consumer, then I think we're fine.", "author": "Lambeaux", "createdAt": "2020-06-26T00:46:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NDYwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NTAwMg==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445855002", "bodyText": "\u2753 Same question here about configuration.", "author": "Lambeaux", "createdAt": "2020-06-25T21:42:22Z", "path": "platform/metrics/metrics-servlet-filter/src/main/java/org/codice/ddf/metrics/servlet/ServletMetrics.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package org.codice.ddf.metrics.servlet;\n+\n+import io.micrometer.core.instrument.DistributionSummary;\n+import io.micrometer.core.instrument.Metrics;\n+import java.io.IOException;\n+import javax.servlet.AsyncEvent;\n+import javax.servlet.AsyncListener;\n+import javax.servlet.Filter;\n+import javax.servlet.FilterChain;\n+import javax.servlet.FilterConfig;\n+import javax.servlet.ServletException;\n+import javax.servlet.ServletRequest;\n+import javax.servlet.ServletResponse;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ServletMetrics implements Filter {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ServletMetrics.class);\n+\n+  private static final String METRICS_PREFIX = \"ddf.platform.http\";\n+\n+  private static final String HISTOGRAM_NAME = \"latency\";\n+\n+  @Override\n+  public void init(FilterConfig filterConfig) throws ServletException {\n+    LOGGER.debug(\"Adding metrics security filter.\");\n+  }\n+\n+  @Override\n+  public void doFilter(\n+      ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain)\n+      throws IOException, ServletException {\n+    boolean hadException = false;\n+    long startTime = System.currentTimeMillis();\n+    try {\n+      chain.doFilter(servletRequest, servletResponse);\n+    } catch (Exception ex) {\n+      hadException = true;\n+      throw ex;\n+    } finally {\n+      HttpServletRequest request = (HttpServletRequest) servletRequest;\n+      HttpServletResponse response = (HttpServletResponse) servletResponse;\n+\n+      if (!hadException && request.isAsyncStarted()) {\n+        request.getAsyncContext().addListener(new AsyncResponseListener(startTime));\n+      } else {\n+        record(request, response, startTime, hadException, false);\n+      }\n+    }\n+  }\n+\n+  private static void record(\n+      HttpServletRequest request,\n+      HttpServletResponse response,\n+      long startTime,\n+      boolean hadException,\n+      boolean hadTimeout) {\n+    long endTime = System.currentTimeMillis();\n+    long latency = endTime - startTime;\n+\n+    DistributionSummary.builder(METRICS_PREFIX + \".\" + HISTOGRAM_NAME)\n+        .baseUnit(\"milliseconds\")\n+        .tags(\n+            \"method\",\n+            request.getMethod(),\n+            \"status\",\n+            getStatusCode(response, hadException, hadTimeout))\n+        .publishPercentiles(0.5, 0.95)", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NzM2OQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445857369", "bodyText": "\u2753 Is this giving us similar observability to dropwizard where we can actually detect if certain thread pools are under / over utilized or thrashing needlessly based on utilization?\nAlso average time spent waiting or blocked?\nI'll do some digging to help alleviate this review in a bit I just want to get the comments out.", "author": "Lambeaux", "createdAt": "2020-06-25T21:47:44Z", "path": "platform/metrics/metrics-system-reporter/src/main/java/org/codice/ddf/metrics/SystemMetricsReporter.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package org.codice.ddf.metrics;\n+\n+import io.micrometer.core.instrument.Metrics;\n+import io.micrometer.core.instrument.binder.jvm.ClassLoaderMetrics;\n+import io.micrometer.core.instrument.binder.jvm.DiskSpaceMetrics;\n+import io.micrometer.core.instrument.binder.jvm.JvmGcMetrics;\n+import io.micrometer.core.instrument.binder.jvm.JvmHeapPressureMetrics;\n+import io.micrometer.core.instrument.binder.jvm.JvmMemoryMetrics;\n+import io.micrometer.core.instrument.binder.jvm.JvmThreadMetrics;\n+import io.micrometer.core.instrument.binder.system.FileDescriptorMetrics;\n+import io.micrometer.core.instrument.binder.system.ProcessorMetrics;\n+import io.micrometer.core.instrument.binder.system.UptimeMetrics;\n+import java.nio.file.Paths;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SystemMetricsReporter {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SystemMetricsReporter.class);\n+\n+  public SystemMetricsReporter() {\n+    LOGGER.debug(\"Adding JVM and system metrics to global registry.\");\n+    new ClassLoaderMetrics().bindTo(Metrics.globalRegistry);\n+    new DiskSpaceMetrics(Paths.get(System.getProperty(\"ddf.home\")).toFile())\n+        .bindTo(Metrics.globalRegistry);\n+    new JvmMemoryMetrics().bindTo(Metrics.globalRegistry);\n+    new JvmHeapPressureMetrics().bindTo(Metrics.globalRegistry);\n+    new JvmGcMetrics().bindTo(Metrics.globalRegistry);\n+    new JvmThreadMetrics().bindTo(Metrics.globalRegistry);", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwNzE1NA==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445907154", "bodyText": "See the screenshot section of this PR for an example of the full output.  You can see all of the metrics that do not have a ddf_ prefix which are being added here.\nHere are the JVM thread metrics.\n# HELP jvm_threads_states_threads The current number of threads having NEW state\n# TYPE jvm_threads_states_threads gauge\njvm_threads_states_threads{state=\"runnable\",} 22.0\njvm_threads_states_threads{state=\"blocked\",} 0.0\njvm_threads_states_threads{state=\"waiting\",} 111.0\njvm_threads_states_threads{state=\"timed-waiting\",} 97.0\njvm_threads_states_threads{state=\"new\",} 0.0\njvm_threads_states_threads{state=\"terminated\",} 0.0\n# HELP jvm_threads_live_threads The current number of live threads including both daemon and non-daemon threads\n# TYPE jvm_threads_live_threads gauge\njvm_threads_live_threads 230.0\n# HELP jvm_threads_daemon_threads The current number of live daemon threads\n# TYPE jvm_threads_daemon_threads gauge\njvm_threads_daemon_threads 157.0\n# HELP jvm_threads_peak_threads The peak live thread count since the Java virtual machine started or peak was reset\n# TYPE jvm_threads_peak_threads gauge\njvm_threads_peak_threads 233.0", "author": "pklinef", "createdAt": "2020-06-26T00:25:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwNzI5Mw==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445907293", "bodyText": "Looks like we still need to wrap executors if we want more granularity.\nhttps://micrometer.io/docs/ref/jvm", "author": "Lambeaux", "createdAt": "2020-06-26T00:25:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwOTA1NQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445909055", "bodyText": "Ah totally missed that originally. Perfect \ud83d\udc4d", "author": "Lambeaux", "createdAt": "2020-06-26T00:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg1NzM2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTg2MTg3NQ==", "url": "https://github.com/codice/ddf/pull/6144#discussion_r445861875", "bodyText": "\u270f\ufe0f  filters.addFirst(filter) ?\nhttps://docs.oracle.com/javase/8/docs/api/java/util/LinkedList.html#addFirst-E-", "author": "Lambeaux", "createdAt": "2020-06-25T21:58:08Z", "path": "platform/platform-paxweb-jettyconfig/src/main/java/org/codice/ddf/pax/web/jetty/SecurityFilterChain.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/**\n+ * Copyright (c) Codice Foundation\n+ *\n+ * <p>This is free software: you can redistribute it and/or modify it under the terms of the GNU\n+ * Lesser General Public License as published by the Free Software Foundation, either version 3 of\n+ * the License, or any later version.\n+ *\n+ * <p>This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;\n+ * without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n+ * GNU Lesser General Public License for more details. A copy of the GNU Lesser General Public\n+ * License is distributed along with this program and can be found at\n+ * <http://www.gnu.org/licenses/lgpl.html>.\n+ */\n+package org.codice.ddf.pax.web.jetty;\n+\n+import java.io.IOException;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import javax.servlet.ServletRequest;\n+import javax.servlet.ServletResponse;\n+import org.codice.ddf.platform.filter.AuthenticationException;\n+import org.codice.ddf.platform.filter.FilterChain;\n+import org.codice.ddf.platform.filter.SecurityFilter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Implementation of filter chain that allows the ability to add new {@link SecurityFilter}s to a\n+ * chain. The {@link SecurityFilterChain} may not be reused. That is, once the {@link\n+ * SecurityFilterChain#doFilter} method is called, no more {@link SecurityFilter}s may be added.\n+ */\n+public class SecurityFilterChain implements FilterChain {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SecurityFilterChain.class);\n+\n+  private final LinkedList<SecurityFilter> filters;\n+\n+  private Iterator<SecurityFilter> iterator;\n+\n+  /** Creates a new SecurityFilterChain */\n+  public SecurityFilterChain() {\n+    filters = new LinkedList<>();\n+  }\n+\n+  /**\n+   * Adds a single {@link SecurityFilter} to the start of the local filter chain.\n+   *\n+   * @param filter The servlet filter to add.\n+   * @throws IllegalArgumentException when the {@param filer} is null\n+   * @throws IllegalStateException when a trying to add a {@link Filter} to this when the {@link\n+   *     SecurityFilterChain#doFilter} has been called at least once. This ensures that the {@link\n+   *     SecurityFilterChain} may not be reused.\n+   */\n+  public void addSecurityFilter(SecurityFilter filter) {\n+    if (filter == null) {\n+      throw new IllegalArgumentException(\"Cannot add null filter to chain.\");\n+    }\n+\n+    // a null iterator indicates that the SecurityFilterChain is not yet running\n+    if (iterator != null) {\n+      throw new IllegalStateException(\"Cannot add filter to current running chain.\");\n+    }\n+\n+    filters.add(0, filter);", "originalCommit": "8ff7949013e3bf581aa74ec2f78fa578b83cc121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "13b0864031b8443cc28cd1bd2ea53a6486fc536c", "url": "https://github.com/codice/ddf/commit/13b0864031b8443cc28cd1bd2ea53a6486fc536c", "message": "Replace Dropwizard Metrics with Micrometer\n\nAdded new metrics\nExposed metrics through Prometheus endpoint\nReplaced CXF interceptor with servlet filter\nFixed bundle refresh of dynamically injected servlet filters", "committedDate": "2020-06-26T00:28:13Z", "type": "commit"}, {"oid": "13b0864031b8443cc28cd1bd2ea53a6486fc536c", "url": "https://github.com/codice/ddf/commit/13b0864031b8443cc28cd1bd2ea53a6486fc536c", "message": "Replace Dropwizard Metrics with Micrometer\n\nAdded new metrics\nExposed metrics through Prometheus endpoint\nReplaced CXF interceptor with servlet filter\nFixed bundle refresh of dynamically injected servlet filters", "committedDate": "2020-06-26T00:28:13Z", "type": "forcePushed"}]}