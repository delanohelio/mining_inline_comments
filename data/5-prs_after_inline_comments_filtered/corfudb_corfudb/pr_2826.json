{"pr_number": 2826, "pr_title": "CorfuStore streaming redesign part 3 - implementation and integration.", "pr_createdAt": "2020-11-13T23:13:49Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2826", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3MzM4MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523373381", "bodyText": "Consolidating the functions is ok, but would be good to retain these comments.", "author": "hisundar", "createdAt": "2020-11-14T04:19:19Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/CorfuStreamEntry.java", "diffHunk": "@@ -121,36 +112,10 @@ private static OperationType getOperationType(@Nonnull SMREntry entry) {\n                 operationType = OperationType.DELETE;\n                 break;\n             default:\n-                throw new RuntimeException(\"SMRMethod \"+entry.getSMRMethod()\n+                throw new RuntimeException(\"SMRMethod \" + entry.getSMRMethod()\n                         + \" cannot be translated to any known operation type\");\n         }\n-        return operationType;\n-    }\n-\n-    /**\n-     *  Convert an SMREntry into a CorfuStreamEntry when the SMR arguments have clear types\n-     *  (like if called from a commit callback)\n-     * @param entry - the entry to convert from.\n-     * @param epoch - the epoch this entry was written to/will be written to.\n-     */\n-    public static\n-    CorfuStreamEntry fromSMREntry(@Nonnull SMREntry entry, final long epoch) {\n-\n-        long address = entry.getGlobalAddress();\n-\n-        OperationType operationType = getOperationType(entry);\n-        Object[] args = entry.getSMRArguments();\n-        if (args.length > 0) {\n-            if (args.length > 1) {\n-                CorfuRecord record = (CorfuRecord) args[1];\n-                return new CorfuStreamEntry((Message)args[0],\n-                        record.getPayload(), record.getMetadata(), 0, address, operationType);\n-            }\n-            // this would likely be the case with \"remove\" SMR method", "originalCommit": "c907b207e87dfc799e3a605b81f2889b30566f1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM5NTA5Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523395097", "bodyText": "Will do.", "author": "WenbinZhu", "createdAt": "2020-11-14T08:45:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3MzM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTE3Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523375176", "bodyText": "use of remaining() is exactly what got us into the OOM scenario. Even with more selectivity, this will result in OOM if there is a lot of distance between the lastAddress and the tail.", "author": "hisundar", "createdAt": "2020-11-14T04:40:47Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remaining();", "originalCommit": "c907b207e87dfc799e3a605b81f2889b30566f1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM5NDU2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523394569", "bodyText": "Initially I tried to add a parameter in remaining() to limit the number of entries returned, but the current implementation makes it complicated and error-prone to make this change. However, with the try catch block and the tunable buffer size, when OOM happens it will be captured and user be able to handle it by re-process the initial snapshot and re-subscribe. Let's sync up this and other concern you might have on Monday.", "author": "WenbinZhu", "createdAt": "2020-11-14T08:39:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUxMTQxNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r524511414", "bodyText": "OOM exceptions cannot always be caught in a try-catch block - the actual OOM error can happen in a stack trace not controlled by us.\nUse of remaining() the way it is very buggy, if there are any infra issues then the stream address space can grow quickly which means remaining() will pull the entire stream history into memory.\nMaybe this loop can be change to do a next() up to the NOTIFICATION_BATCH_SIZE and then stop?", "author": "hisundar", "createdAt": "2020-11-16T19:15:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0OTM5OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r524549399", "bodyText": "In initial impl, OOM can happen in a stack trace not controlled by us because it has large buffer size, but now we can fine tine it. Using next() is too slow and not a generic approach. And if you remember even if we use next(), they still have OOM because their jvm is too small, that problem is not one our side, we don't want to do our impl for a specific case that slows down other common use cases right? The right solution is too enhance remaining()/remainingUpto() API so that it limits the number of entries returned, the current maxGlobal parameter in streaming API is not the number of entries returned for this stream, but the last GLOBAL address to look for, which might return 0 stream entries up to that address, so need another parameter to control the number of actual entries returned.", "author": "WenbinZhu", "createdAt": "2020-11-16T20:23:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTM4Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523375386", "bodyText": "If the goal of using fixed size queue and retry was to avoid starvation of other streams when the number of subscribers exceeds the number of threads. Then won't this still bring back the starvation if the number of updates are large?", "author": "hisundar", "createdAt": "2020-11-14T04:43:37Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remaining();\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());\n+            pollingExecutor.submit(this);\n+            return;\n+        }\n+\n+        // Insert polled updates to the subscription buffer, with a shared\n+        // fixed amount of time waiting for buffer being not full.\n+        long remainingBlockTime = QUEUE_FULL_BLOCK_TIME_MS.toNanos();\n+        for (ILogData update : updates) {", "originalCommit": "c907b207e87dfc799e3a605b81f2889b30566f1c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM5NTA1Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r523395053", "bodyText": "This is why the QUEUE_FULL_BLOCK_TIME_MS is being used. It is the total amount of time to wait, which is set to 2 seconds right now. It means it will wait for up to 2 seconds for all the updates polled in this cycle (only the wait time when inserting into queue). Also it's not typical that all call backs are slow, so as long as one thread is available, they won't be blocked.", "author": "WenbinZhu", "createdAt": "2020-11-14T08:44:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3NTM4Ng=="}], "type": "inlineReview"}, {"oid": "8f6ead90c884497af69486f3b9f231b9e5df9364", "url": "https://github.com/CorfuDB/CorfuDB/commit/8f6ead90c884497af69486f3b9f231b9e5df9364", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-17T08:48:33Z", "type": "forcePushed"}, {"oid": "01fbb3a6e6ddb1fad7f343c78a310868d68e7caa", "url": "https://github.com/CorfuDB/CorfuDB/commit/01fbb3a6e6ddb1fad7f343c78a310868d68e7caa", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-17T09:52:57Z", "type": "forcePushed"}, {"oid": "8f607b55ac4f40b20cf188e2111ef6fe661623d3", "url": "https://github.com/CorfuDB/CorfuDB/commit/8f607b55ac4f40b20cf188e2111ef6fe661623d3", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-17T22:23:39Z", "type": "forcePushed"}, {"oid": "6e7cfeb8113e50ec23e5cd483f8a47cb98321131", "url": "https://github.com/CorfuDB/CorfuDB/commit/6e7cfeb8113e50ec23e5cd483f8a47cb98321131", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-19T05:31:21Z", "type": "forcePushed"}, {"oid": "94f755169fe742fb2c8c26c78664f948fb2ff4f8", "url": "https://github.com/CorfuDB/CorfuDB/commit/94f755169fe742fb2c8c26c78664f948fb2ff4f8", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-19T05:33:46Z", "type": "forcePushed"}, {"oid": "594b78e9daff228d9d2be330ecd56056669dcc52", "url": "https://github.com/CorfuDB/CorfuDB/commit/594b78e9daff228d9d2be330ecd56056669dcc52", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-19T05:53:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1MDA3Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r528050073", "bodyText": "where is this used ?", "author": "medhavidhawan", "createdAt": "2020-11-21T01:39:12Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());\n+            pollingExecutor.submit(this);\n+            return;\n+        }\n+\n+        // Insert polled updates to the subscription buffer, with a shared\n+        // fixed amount of time waiting for buffer being not full.\n+        long remainingBlockTime = QUEUE_FULL_BLOCK_TIME_MS.toNanos();", "originalCommit": "594b78e9daff228d9d2be330ecd56056669dcc52", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA5MTEzMQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r529091131", "bodyText": "This is used when inserting into the queue: subscription.enqueueStreamEntry(update, remainingBlockTime)", "author": "WenbinZhu", "createdAt": "2020-11-24T00:50:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1MDA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1MjgxNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r528052815", "bodyText": "Nit: why are you holding up the thread here ? Why not submit with some delay and let the thread be used for other tasks. You will need to either use some scheduledExecutor for that or have some common data structure to keep the submissions that need to be delayed and feed the executor from there.", "author": "medhavidhawan", "createdAt": "2020-11-21T01:58:16Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());", "originalCommit": "594b78e9daff228d9d2be330ecd56056669dcc52", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA5MzA5Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r529093096", "bodyText": "In normal cases, the updates are not empty. Here by sleeping a tiny period (50 ms), we prevent cpu busy polling in rare cases that no new entries were produced. The current master impl uses scheduling, but it has extras delays for normal cases and not scalable. The sleep here is actually same as current impl, but the new model solves the aforementioned two problems.", "author": "WenbinZhu", "createdAt": "2020-11-24T00:56:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1MjgxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1NjA4MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r528056081", "bodyText": "How did we arrive at this number ?", "author": "medhavidhawan", "createdAt": "2020-11-21T02:25:19Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;", "originalCommit": "594b78e9daff228d9d2be330ecd56056669dcc52", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA5MzcwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r529093706", "bodyText": "This is based on an estimation of subscribers and and limits of threads.", "author": "WenbinZhu", "createdAt": "2020-11-24T00:57:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1NjA4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1NjI2Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r528056262", "bodyText": "do we need parameterize some of these numbers in case we need to tweak them to find the right values.", "author": "medhavidhawan", "createdAt": "2020-11-21T02:26:39Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,145 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;", "originalCommit": "594b78e9daff228d9d2be330ecd56056669dcc52", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA5NDE1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r529094155", "bodyText": "Actually the buffer size is already configurable. User can specify the buffer size on subscribe, but if it's not provided, this default value will be used.", "author": "WenbinZhu", "createdAt": "2020-11-24T00:59:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA1NjI2Mg=="}], "type": "inlineReview"}, {"oid": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "url": "https://github.com/CorfuDB/CorfuDB/commit/1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-11-24T00:46:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwMjgzOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541902839", "bodyText": "above -> below", "author": "pankti-m", "createdAt": "2020-12-13T11:13:35Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/CorfuStreamEntry.java", "diffHunk": "@@ -1,26 +1,25 @@\n package org.corfudb.runtime.collections;\n \n import com.google.protobuf.Message;\n+import lombok.EqualsAndHashCode;\n import lombok.Getter;\n import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.logprotocol.SMREntry;\n \n import javax.annotation.Nonnull;\n-import javax.annotation.Nullable;\n-\n-import org.corfudb.protocols.logprotocol.SMREntry;\n \n /**\n- * Entry returned by CorfuStore's StreamListener interface\n+ * Entry returned by CorfuStore's StreamListener interface.\n+ * NOTE: Ensure that the above protobuf generated classes are accessible to your JVM!", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMTQwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545501406", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:50:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwMjgzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwMzUwNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541903507", "bodyText": "for alphabetic order of imports, shouldnt the 'java' imports be before 'org.corfudb..'?", "author": "pankti-m", "createdAt": "2020-12-13T11:17:36Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamManager.java", "diffHunk": "@@ -1,12 +1,21 @@\n package org.corfudb.runtime.collections;\n \n import com.google.protobuf.Message;\n-\n import lombok.AllArgsConstructor;\n import lombok.Getter;\n import lombok.Setter;\n import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.logprotocol.MultiObjectSMREntry;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.runtime.view.StreamOptions;\n+import org.corfudb.runtime.view.TableRegistry;\n+import org.corfudb.runtime.view.stream.IStreamView;\n \n+import javax.annotation.Nonnull;", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMjA0MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545502040", "bodyText": "These are automatically ordered by IDEA, I hit the optimize hot key and it's still in this order, I didn't change the default ordering config, and I think we can just observe the default ordering.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:52:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwMzUwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwNDI3OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541904279", "bodyText": "order of lombok and java imports", "author": "pankti-m", "createdAt": "2020-12-13T11:22:26Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamNotificationTask.java", "diffHunk": "@@ -0,0 +1,100 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMjEyOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545502129", "bodyText": "Same reason as above", "author": "WenbinZhu", "createdAt": "2020-12-18T00:52:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwNDI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwNTQ1NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541905454", "bodyText": "do we need a log statement here?", "author": "pankti-m", "createdAt": "2020-12-13T11:29:23Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamNotificationTask.java", "diffHunk": "@@ -0,0 +1,100 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * A runnable task for a subscription to retrieve the previously\n+ * polled transaction updates from the buffer and send notifications\n+ * to client via the registered call backs. This task is executed\n+ * by the thread pool continuously until an error occurs which would\n+ * stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamNotificationTask implements Runnable {\n+\n+    // Number of transaction updates to send notification in each run.\n+    private static final int NOTIFICATION_BATCH_SIZE = 10;\n+\n+    // Total amount of time to wait for retrieving the data changes from buffer if it is empty.\n+    private static final Duration QUEUE_EMPTY_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // A warning will be raised if client call back takes longer than this time threshold.\n+    private static final Duration SLOW_NOTIFICATION_TIME_MS = Duration.ofMillis(1_500);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing client notification tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    StreamNotificationTask(StreamingManager streamingManager,\n+                           StreamSubscription subscription,\n+                           ExecutorService notificationExecutor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.notificationExecutor = notificationExecutor;\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            sendNotifications();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during client notification callback, \" +\n+                    \"listener: {}, namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Retrieve the first data change from the buffer and send notification\n+     * to the client via the pre-registered call back.\n+     */\n+    private void sendNotifications() throws Exception {\n+        // Total amount of time for the batch waiting for buffer being not empty.\n+        long remainingBlockTime = QUEUE_EMPTY_BLOCK_TIME_MS.toNanos();\n+        StreamListener listener = subscription.getListener();\n+\n+        for (int iter = 0; iter < NOTIFICATION_BATCH_SIZE; iter++) {\n+            // If listener already unsubscribed, do not process or schedule again.\n+            if (subscription.isStopped()) {", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMzAxMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545503010", "bodyText": "This could happen because of a timing race, but this race does not matter a lot, so we don't need to log here.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:55:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkwNTQ1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxMDkzMQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541910931", "bodyText": "log a message?", "author": "pankti-m", "createdAt": "2020-12-13T12:00:37Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMzA0Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545503047", "bodyText": "Same reason as above.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:55:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxMDkzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxMTkyNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r541911925", "bodyText": "already checked this on L72", "author": "pankti-m", "createdAt": "2020-12-13T12:06:28Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());\n+            pollingExecutor.submit(this);\n+            return;\n+        }\n+\n+        // Insert polled updates to the subscription buffer, with a shared\n+        // fixed amount of time waiting for buffer being not full.\n+        long remainingBlockTime = QUEUE_FULL_BLOCK_TIME_MS.toNanos();\n+        for (ILogData update : updates) {\n+            if (subscription.isStopped()) {", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMzQzNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545503436", "bodyText": "Yea, just check again here because we synchronize it, so the stop reqeust could happen after the previous check.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:56:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkxMTkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAzOTg0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543039844", "bodyText": "nit - order of imports javax vs java", "author": "pankti-m", "createdAt": "2020-12-15T04:36:10Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwMzQ4NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545503485", "bodyText": "Same reason as above.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:56:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzAzOTg0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTA0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543051044", "bodyText": "One thing I think can improve debuggability is to we have a 'name' field in the StreamListener.  It will help identify if a particular listener has subscribed or not.  Logging the listener instance reference will not help much.", "author": "pankti-m", "createdAt": "2020-12-15T05:10:30Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;\n+\n+    // Corfu runtime to interact with corfu streams.\n+    private final CorfuRuntime runtime;\n+\n+    // A map of all stream listeners and their subscription contexts.\n+    private final Map<StreamListener, StreamSubscription> subscriptions;\n+\n+    // Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Thread pool for executing client call back tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    /**\n+     * Create the stream manager, initialize the tasks pools.\n+     *\n+     * @param runtime Corfu runtime to use for streaming\n+     */\n+    public StreamingManager(@Nonnull CorfuRuntime runtime) {\n+        this.runtime = runtime;\n+        this.subscriptions = new HashMap<>();\n+\n+        this.pollingExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-poller-%d\").build());\n+        this.notificationExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-notifier-%d\").build());\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                long lastAddress) {\n+        subscribe(streamListener, namespace, streamTag, tablesOfInterest, lastAddress, DEFAULT_BUFFER_SIZE);\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     * @param bufferSize       maximum size of buffered transaction entries\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                long lastAddress, int bufferSize) {\n+        if (bufferSize < 1) {\n+            throw new IllegalArgumentException(\"subscribe: Buffer size cannot be less than 1.\");\n+        }\n+\n+        if (subscriptions.containsKey(streamListener)) {\n+            // Multiple subscribers subscribing to same namespace and table is allowed\n+            // as long as the hashcode() and equals() method of the listeners are different.\n+            throw new StreamSubscriptionException(\n+                    \"StreamingManager::subscribe: listener already registered \" + streamListener);\n+        }\n+\n+        StreamingMetrics metrics = new StreamingMetrics(\n+                streamListener, namespace, streamTag, runtime.getParameters().getMetricRegistry());\n+        StreamSubscription subscription = new StreamSubscription(\n+                runtime, streamListener, namespace, streamTag, tablesOfInterest, bufferSize, metrics);\n+        subscriptions.put(streamListener, subscription);\n+\n+        pollingExecutor.submit(new StreamPollingTask(this, lastAddress, subscription, pollingExecutor));\n+        notificationExecutor.submit(new StreamNotificationTask(this, subscription, notificationExecutor));\n+\n+        log.info(\"Subscribed stream listener {}, numSubscribers: {}, streamTag: {}, lastAddress: {}, \" +", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNDMyNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545504327", "bodyText": "Currently if user overloads toString(), then we have a meaningful identifier, and that's what we currently do in testing. I'm trying to avoid changing interfaces in this patch, but sure later we could change the interface to have better debuggability.", "author": "WenbinZhu", "createdAt": "2020-12-18T00:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTIwNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543051205", "bodyText": "can this be made private?", "author": "pankti-m", "createdAt": "2020-12-15T05:11:00Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;\n+\n+    // Corfu runtime to interact with corfu streams.\n+    private final CorfuRuntime runtime;\n+\n+    // A map of all stream listeners and their subscription contexts.\n+    private final Map<StreamListener, StreamSubscription> subscriptions;\n+\n+    // Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Thread pool for executing client call back tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    /**\n+     * Create the stream manager, initialize the tasks pools.\n+     *\n+     * @param runtime Corfu runtime to use for streaming\n+     */\n+    public StreamingManager(@Nonnull CorfuRuntime runtime) {\n+        this.runtime = runtime;\n+        this.subscriptions = new HashMap<>();\n+\n+        this.pollingExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-poller-%d\").build());\n+        this.notificationExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-notifier-%d\").build());\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                long lastAddress) {\n+        subscribe(streamListener, namespace, streamTag, tablesOfInterest, lastAddress, DEFAULT_BUFFER_SIZE);\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     * @param bufferSize       maximum size of buffered transaction entries\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                long lastAddress, int bufferSize) {\n+        if (bufferSize < 1) {\n+            throw new IllegalArgumentException(\"subscribe: Buffer size cannot be less than 1.\");\n+        }\n+\n+        if (subscriptions.containsKey(streamListener)) {\n+            // Multiple subscribers subscribing to same namespace and table is allowed\n+            // as long as the hashcode() and equals() method of the listeners are different.\n+            throw new StreamSubscriptionException(\n+                    \"StreamingManager::subscribe: listener already registered \" + streamListener);\n+        }\n+\n+        StreamingMetrics metrics = new StreamingMetrics(\n+                streamListener, namespace, streamTag, runtime.getParameters().getMetricRegistry());\n+        StreamSubscription subscription = new StreamSubscription(\n+                runtime, streamListener, namespace, streamTag, tablesOfInterest, bufferSize, metrics);\n+        subscriptions.put(streamListener, subscription);\n+\n+        pollingExecutor.submit(new StreamPollingTask(this, lastAddress, subscription, pollingExecutor));\n+        notificationExecutor.submit(new StreamNotificationTask(this, subscription, notificationExecutor));\n+\n+        log.info(\"Subscribed stream listener {}, numSubscribers: {}, streamTag: {}, lastAddress: {}, \" +\n+                \"namespace {}, tables {}\", streamListener, subscriptions.size(), streamTag, lastAddress,\n+                namespace, tablesOfInterest);\n+    }\n+\n+    /**\n+     * Unsubscribe a prior subscription.\n+     *\n+     * @param streamListener client listener to unsubscribe\n+     */\n+    synchronized void unsubscribe(@Nonnull StreamListener streamListener) {\n+        unsubscribe(streamListener, true);\n+    }\n+\n+    /**\n+     * Unsubscribe a prior subscription.\n+     *\n+     * @param streamListener            client listener to unsubscribe\n+     * @param warnIfNotSubscribedBefore whether to log warning if listener is not\n+     *                                  subscribed or already unsubscribed\n+     */\n+    synchronized void unsubscribe(@Nonnull StreamListener streamListener,", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNDcyNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545504727", "bodyText": "No, this is also used in StreamNotificationTask and StreamPollingTask.", "author": "WenbinZhu", "createdAt": "2020-12-18T01:00:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTI4MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543051281", "bodyText": "can it be made private?", "author": "pankti-m", "createdAt": "2020-12-15T05:11:16Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;\n+\n+    // Corfu runtime to interact with corfu streams.\n+    private final CorfuRuntime runtime;\n+\n+    // A map of all stream listeners and their subscription contexts.\n+    private final Map<StreamListener, StreamSubscription> subscriptions;\n+\n+    // Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Thread pool for executing client call back tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    /**\n+     * Create the stream manager, initialize the tasks pools.\n+     *\n+     * @param runtime Corfu runtime to use for streaming\n+     */\n+    public StreamingManager(@Nonnull CorfuRuntime runtime) {\n+        this.runtime = runtime;\n+        this.subscriptions = new HashMap<>();\n+\n+        this.pollingExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-poller-%d\").build());\n+        this.notificationExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,\n+                new ThreadFactoryBuilder().setNameFormat(\"streaming-notifier-%d\").build());\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                long lastAddress) {\n+        subscribe(streamListener, namespace, streamTag, tablesOfInterest, lastAddress, DEFAULT_BUFFER_SIZE);\n+    }\n+\n+    /**\n+     * Subscribe to transaction updates.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        namespace of interested tables\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables will be returned\n+     * @param lastAddress      last processed address, new notifications start from lastAddress + 1\n+     * @param bufferSize       maximum size of buffered transaction entries\n+     */\n+    synchronized void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNDg0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545504844", "bodyText": "No, this is also used in CorfuStore.", "author": "WenbinZhu", "createdAt": "2020-12-18T01:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1MTI4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1Mjg5MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543052891", "bodyText": "where will these executors be shut down?  They should always be running while Corfu server is up but do we need a method which hooks with the server shutdown and stops these executors?", "author": "pankti-m", "createdAt": "2020-12-15T05:16:04Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;\n+\n+    // Corfu runtime to interact with corfu streams.\n+    private final CorfuRuntime runtime;\n+\n+    // A map of all stream listeners and their subscription contexts.\n+    private final Map<StreamListener, StreamSubscription> subscriptions;\n+\n+    // Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Thread pool for executing client call back tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    /**\n+     * Create the stream manager, initialize the tasks pools.\n+     *\n+     * @param runtime Corfu runtime to use for streaming\n+     */\n+    public StreamingManager(@Nonnull CorfuRuntime runtime) {\n+        this.runtime = runtime;\n+        this.subscriptions = new HashMap<>();\n+\n+        this.pollingExecutor = Executors.newFixedThreadPool(NUM_THREAD_PER_POOL,", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNTY5OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545505699", "bodyText": "This is actually on client side. However this is a good suggestion, we do need to shut down the executors even on client  side, but the problem is there is no shutdown functionality in CorfuStore, so I don't know when to shut down the executors. Once we decide to add shutdown to CorfuStore, I can also shutdown the executors here.", "author": "WenbinZhu", "createdAt": "2020-12-18T01:03:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1Mjg5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1NDk0Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543054943", "bodyText": "javax imports after java?", "author": "pankti-m", "createdAt": "2020-12-15T05:21:50Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/TableRegistry.java", "diffHunk": "@@ -42,6 +32,19 @@\n \n import javax.annotation.Nonnull;\n import javax.annotation.Nullable;\n+import java.lang.reflect.InvocationTargetException;", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNTc2Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545505767", "bodyText": "Same reason as above.", "author": "WenbinZhu", "createdAt": "2020-12-18T01:03:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1NDk0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1Njg2MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r543056860", "bodyText": "can we create it in the constructor instead?", "author": "pankti-m", "createdAt": "2020-12-15T05:27:17Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/TableRegistry.java", "diffHunk": "@@ -461,6 +486,21 @@ public synchronized StreamManager getStreamManager() {\n         return this.streamManager;\n     }\n \n+    /**\n+     * Register a streaming subscription manager as a singleton.\n+     */\n+    public StreamingManager getStreamingManager() {\n+        if (streamingManager == null) {\n+            synchronized (StreamingManager.class) {\n+                if (streamingManager == null) {\n+                    streamingManager = new StreamingManager(runtime);", "originalCommit": "1d1ddfdb6eeb05fa3c3c6831821f2830e897224a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTUwNjA3MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r545506070", "bodyText": "This is lazy initialization, for clients that do not need streaming functionality, we don't need to create StreamingManager.", "author": "WenbinZhu", "createdAt": "2020-12-18T01:04:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzA1Njg2MA=="}], "type": "inlineReview"}, {"oid": "366d3349fb16da68c937e930bf3b8ae5c065e59e", "url": "https://github.com/CorfuDB/CorfuDB/commit/366d3349fb16da68c937e930bf3b8ae5c065e59e", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2020-12-18T00:32:46Z", "type": "forcePushed"}, {"oid": "6526ed062898c697f0c1c8fc695f51d7cb4bbaea", "url": "https://github.com/CorfuDB/CorfuDB/commit/6526ed062898c697f0c1c8fc695f51d7cb4bbaea", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-04T22:46:29Z", "type": "forcePushed"}, {"oid": "0d585a7f61fc34181d505ebe4d19c7ddf070ef7d", "url": "https://github.com/CorfuDB/CorfuDB/commit/0d585a7f61fc34181d505ebe4d19c7ddf070ef7d", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-06T22:29:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDIzOTk5NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554239995", "bodyText": "Deprecate the subscribe method that uses the old stream manager too ?\nhttps://github.com/CorfuDB/CorfuDB/pull/2826/files#diff-f44ea07bfcd37e9243f12f8e2e3666056f2a25d4943965e359e61a43d4e64135R257", "author": "Maithem", "createdAt": "2021-01-08T23:07:29Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/CorfuStore.java", "diffHunk": "@@ -274,21 +274,40 @@ void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace\n      *                         if null, only future updates will be returned\n      */\n     public void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n-                   @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n-                   @Nullable Timestamp timestamp) {\n-        runtime.getTableRegistry().getStreamManager()\n+                          @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,", "originalCommit": "0d585a7f61fc34181d505ebe4d19c7ddf070ef7d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI2Mzc1OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554263758", "bodyText": "Done, thanks for finding out.", "author": "WenbinZhu", "createdAt": "2021-01-09T00:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDIzOTk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI0NTA2MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554245060", "bodyText": "This looks like a leak. You are allowing subscribe to be called from StreamManager and StreamingManager but unsubscribe only invokes StreamingManager::unsubscribe", "author": "Maithem", "createdAt": "2021-01-08T23:26:19Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/CorfuStore.java", "diffHunk": "@@ -274,21 +274,40 @@ void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace\n      *                         if null, only future updates will be returned\n      */\n     public void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n-                   @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n-                   @Nullable Timestamp timestamp) {\n-        runtime.getTableRegistry().getStreamManager()\n+                          @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                          @Nullable Timestamp timestamp) {\n+        runtime.getTableRegistry().getStreamingManager()\n                 .subscribe(streamListener, namespace, streamTag, tablesOfInterest,\n                         (timestamp == null) ? getTimestamp().getSequence() : timestamp.getSequence());\n     }\n \n+    /**\n+     * Subscribe to transaction updates on specific tables with the streamTag in the namespace.\n+     * Objects returned will honor transactional boundaries.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        the CorfuStore namespace to subscribe to\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables of interest will be sent to listener\n+     * @param timestamp        if specified, all stream updates after this timestamp will be returned\n+     *                         if null, only future updates will be returned\n+     * @param bufferSize       maximum size of buffered transaction entries\n+     */\n+    public void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                          @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                          @Nullable Timestamp timestamp, int bufferSize) {\n+        runtime.getTableRegistry().getStreamingManager()\n+                .subscribe(streamListener, namespace, streamTag, tablesOfInterest,\n+                        (timestamp == null) ? getTimestamp().getSequence() : timestamp.getSequence(), bufferSize);\n+    }\n+\n     /**\n      * Gracefully shutdown a streamer.\n      * Once this call returns no further stream updates will be returned.\n      *\n      * @param streamListener - callback context.\n      */\n     public void unsubscribe(@Nonnull StreamListener streamListener) {\n-        runtime.getTableRegistry().getStreamManager()\n-                .unsubscribe(streamListener);\n+        runtime.getTableRegistry().getStreamingManager().unsubscribe(streamListener);", "originalCommit": "0d585a7f61fc34181d505ebe4d19c7ddf070ef7d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI0NjIzOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554246239", "bodyText": "There is not a lot of dependencies on StreamManager, I would suggest removing it instead of deprecating it. Its cleaner than just assuming that API won't be called.", "author": "Maithem", "createdAt": "2021-01-08T23:30:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI0NTA2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI2NDUzOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554264538", "bodyText": "Done, thanks for finding out, I renamed the new subscribe/unscribe to subscribeListener/unsubscribeListener, which is clearer name and deperated the old unscribe API.\nThe reason is we don't want to break the interface, some verticals are using the old subscribe api, and to convert to new API we need them to clean up their code, which is better to be in a separate effort to unblock merging process.", "author": "WenbinZhu", "createdAt": "2021-01-09T00:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI0NTA2MA=="}], "type": "inlineReview"}, {"oid": "f3fa07b2916b80a3a06d234e5e593689ed4850ba", "url": "https://github.com/CorfuDB/CorfuDB/commit/f3fa07b2916b80a3a06d234e5e593689ed4850ba", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-09T00:52:55Z", "type": "forcePushed"}, {"oid": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "url": "https://github.com/CorfuDB/CorfuDB/commit/5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-09T00:55:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI2ODQ0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554268444", "bodyText": "Do you need to expose this to the shim CorfuStoreShim ?", "author": "Maithem", "createdAt": "2021-01-09T01:15:44Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/CorfuStore.java", "diffHunk": "@@ -273,22 +277,52 @@ void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace\n      * @param timestamp        if specified, all stream updates from this timestamp will be returned\n      *                         if null, only future updates will be returned\n      */\n-    public void subscribe(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n-                   @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n-                   @Nullable Timestamp timestamp) {\n-        runtime.getTableRegistry().getStreamManager()\n+    public void subscribeListener(@Nonnull StreamListener streamListener, @Nonnull String namespace,\n+                                  @Nonnull String streamTag, @Nonnull List<String> tablesOfInterest,\n+                                  @Nullable Timestamp timestamp) {\n+        runtime.getTableRegistry().getStreamingManager()\n                 .subscribe(streamListener, namespace, streamTag, tablesOfInterest,\n                         (timestamp == null) ? getTimestamp().getSequence() : timestamp.getSequence());\n     }\n \n+    /**\n+     * Subscribe to transaction updates on specific tables with the streamTag in the namespace.\n+     * Objects returned will honor transactional boundaries.\n+     *\n+     * @param streamListener   client listener for callback\n+     * @param namespace        the CorfuStore namespace to subscribe to\n+     * @param streamTag        only updates of tables with the stream tag will be polled\n+     * @param tablesOfInterest only updates from these tables of interest will be sent to listener\n+     * @param timestamp        if specified, all stream updates after this timestamp will be returned\n+     *                         if null, only future updates will be returned\n+     * @param bufferSize       maximum size of buffered transaction entries\n+     */\n+    public void subscribeListener(@Nonnull StreamListener streamListener, @Nonnull String namespace,", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1NjY5Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555456697", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:43:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI2ODQ0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3MTAxOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554271018", "bodyText": "How do you stop the StreamingManager ?\nThis class is creating non-daemon threads and ignoring interrupts. A shutdown/close method should be added an invoked from CorfuStore.\nAlso, why is StreamManager::shutdown invoked from TableRegistry, it seems very strange.", "author": "Maithem", "createdAt": "2021-01-09T01:33:29Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1NjgwNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555456804", "bodyText": "Done, added shutdown logic.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:43:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3MTAxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3MTU5NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554271595", "bodyText": "These have to be configurable and exposed. We have already seen bugs where we need to be able to tune a bunch of parameters. Unfortunately, most of our configurations are not configurable and require source code changes.", "author": "Maithem", "createdAt": "2021-01-09T01:37:23Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1NzI4NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555457285", "bodyText": "The buffer size is already exposed in the subscribe() API, clients can specify a customed buffer size, or not to use this default setting.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:44:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3MTU5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3OTA2Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554279063", "bodyText": "You can improve the read performance by introducing a local variable. For example,\npublic StreamingManager getStreamingManager() {\n        StreamingManager localRef = streamingManager;\n        if (localRef == null) {\n            synchronized (this) {\n                localRef = streamingManager;\n                if (localRef == null) {\n                    localRef = streamingManager = new StreamingManager(runtime);\n                }\n            }\n        }\n        return localRef;\n    }", "author": "Maithem", "createdAt": "2021-01-09T02:40:49Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/TableRegistry.java", "diffHunk": "@@ -480,6 +505,21 @@ public synchronized StreamManager getStreamManager() {\n         return this.streamManager;\n     }\n \n+    /**\n+     * Register a streaming subscription manager as a singleton.\n+     */\n+    public StreamingManager getStreamingManager() {", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3OTIxNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554279215", "bodyText": "Alternately, you can just use Lomboks lazy annotation and it would emit the code for double checked locking.\n    @Getter(lazy = true)\n    private final StreamingManager streamingManager = create();\n    private StreamingManager create() {\n        return new StreamingManager(runtime);\n    }", "author": "Maithem", "createdAt": "2021-01-09T02:42:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3OTA2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1Nzg4Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555457883", "bodyText": "Since this is not the hot path, I switched to use the previous way that leverages synchronizes the method itself, to make it simpler as we have another shutdown() method that needs to check if it's null or not.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:46:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI3OTA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4MDg5Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554280893", "bodyText": "Not related to this PR per-se but should these types be validated when registryTable is populated ? So TableRegistry should try to load the types with the class loader and should fail with ClassNotFoundException if the type is not there, which is more appropriate than NoSuchElementException", "author": "Maithem", "createdAt": "2021-01-09T02:58:22Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/TableRegistry.java", "diffHunk": "@@ -393,19 +419,18 @@ public static String getFullyQualifiedTableName(TableName tableName) {\n             // To do so, consult the TableRegistry for an entry which indicates the table exists.\n             if (registryTable.containsKey(\n                     TableName.newBuilder()\n-                    .setNamespace(namespace)\n-                    .setTableName(tableName)\n-                    .build())\n+                            .setNamespace(namespace)\n+                            .setTableName(tableName)\n+                            .build())\n             ) {\n                 // If table does exist then the caller must use the long form of the openTable()\n                 // since there are too few arguments to open a table not seen by this runtime.\n                 throw new IllegalArgumentException(\"Please provide Key, Value & Metadata schemas to re-open\"\n-                + \" this existing table \" + tableName + \" in namespace \" + namespace);\n+                        + \" this existing table \" + tableName + \" in namespace \" + namespace);\n             } else {\n-                // If the table is completely unheard of return NoSuchElementException\n-                throw new NoSuchElementException(\n-                        String.format(\"No such table found: namespace: %s, tableName: %s\",\n-                        namespace, tableName));\n+                // If the table is completely unheard of return NoSuchElementException.\n+                throw new NoSuchElementException(String.format(\n+                        \"No such table found: namespace: %s, tableName: %s\", namespace, tableName));", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1ODg2NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555458864", "bodyText": "So the contract of CorfuStore when they designed it is that clients have to first explicitly register this table by calling openTable() and later other clients use getTable() to use the opened table.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:49:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4MDg5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4NzY1Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554287653", "bodyText": "You can simplyf this logic to\n        long lastAddress = 0;\n        while (iterator.hasNext() && --maxEntries > 0) {\n            lastAddress = iterator.next();\n        }\n\n        return lastAddress;", "author": "Maithem", "createdAt": "2021-01-09T04:09:44Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/AddressMapStreamView.java", "diffHunk": "@@ -383,7 +382,34 @@ private boolean isTrimCoveredByCheckpoint(long trimMark) {\n      * @return whether this stream is capable of being checkpointed\n      */\n     private boolean isCheckpointCapable() {\n-        return !getId().equals(ObjectsView.TRANSACTION_STREAM_ID);\n+        return !getId().equals(ObjectsView.TRANSACTION_STREAM_ID)\n+                && getStreamOptions().isCheckpointCapable();\n+    }\n+\n+    @Override\n+    protected long getMaxGlobalFromMaxEntries(int maxEntries) {\n+        if (maxEntries == Integer.MAX_VALUE) {\n+            return Address.MAX;\n+        }\n+\n+        StreamAddressSpace streamAddressSpace = runtime.getSequencerView()\n+                .getStreamAddressSpace(new StreamAddressRange(getId(), Address.MAX, getCurrentGlobalPosition()));\n+\n+        long size = streamAddressSpace.getAddressMap().getLongCardinality();\n+        if (size == 0L) {\n+            return Address.NON_ADDRESS;\n+        }\n+\n+        if (size <= maxEntries) {\n+            return streamAddressSpace.getHighestAddress();\n+        }\n+\n+        LongIterator it = streamAddressSpace.getAddressMap().getLongIterator();\n+        while (--maxEntries > 0) {\n+            it.next();\n+        }\n+\n+        return it.next();", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTIxMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555459210", "bodyText": "The first block is an optimization to avoid iteration if maxEntries is greater than the size of the bitmap, so we can directly return the highest address.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:50:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4NzY1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4ODAwNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554288007", "bodyText": "This will emit all of of unnecessary sequencer queries. A sequencer query should only be called if maxEntries + current pointer address is larger than maxResolution ?", "author": "Maithem", "createdAt": "2021-01-09T04:13:52Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/AbstractQueuedStreamView.java", "diffHunk": "@@ -397,6 +401,34 @@ private void processTrimmedException(TrimmedException te) {\n                 .collect(Collectors.toList());\n     }\n \n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public List<ILogData> remainingAtMost(int maxEntries) {\n+        // TODO: instrument remainingUpTo directly to limit the number of\n+        // of entries returned instead of calling it.\n+        if (maxEntries < 1) {\n+            throw new IllegalArgumentException(\n+                    \"remainingAtMost(): maxEntries cannot be less than 1.\");\n+        }\n+\n+        long maxGlobal = getMaxGlobalFromMaxEntries(maxEntries);\n+        if (Address.nonAddress(maxGlobal)) {\n+            return Collections.emptyList();\n+        }", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTQxMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555459413", "bodyText": "I think our maxResolution is broken as of now.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:51:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4ODAwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4ODUwMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554288502", "bodyText": "Shouldn't this be scoped to a namespace (i.e., STREAM_TAG_PREFIX + nameSpace + streamTag) ?\nThere could be an issue were subscribers can read data from a different namespace.", "author": "Maithem", "createdAt": "2021-01-09T04:18:49Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/TableRegistry.java", "diffHunk": "@@ -293,6 +302,16 @@ public static String getFullyQualifiedTableName(TableName tableName) {\n         return getFullyQualifiedTableName(tableName.getNamespace(), tableName.getTableName());\n     }\n \n+    /**\n+     * Return the stream Id for the provided stream tag.\n+     *\n+     * @param streamTag stream tag in string\n+     * @return stream Id in UUID\n+     */\n+    public static UUID getStreamIdForStreamTag(String streamTag) {\n+        return CorfuRuntime.getStreamID(STREAM_TAG_PREFIX + streamTag);\n+    }", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTU4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555459580", "bodyText": "Done, initially I expect streamTags to be unique, but yes having a namespace is better.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4ODUwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4OTM3MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554289371", "bodyText": "Instead of returning an incorrect value here and relying on remainingAtMost to throw an exception I think its cleaner to just move UnsupportedOperationException to a default implementation in the IStreamView interface.", "author": "Maithem", "createdAt": "2021-01-09T04:29:43Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/stream/BackpointerStreamView.java", "diffHunk": "@@ -178,5 +185,10 @@ protected boolean discoverAddressSpace(final UUID streamId,\n \n         return !queue.isEmpty();\n     }\n+\n+    @Override\n+    protected long getMaxGlobalFromMaxEntries(int maxEntries) {\n+        return Address.MAX;\n+    }", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ1OTY2NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555459665", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2021-01-12T01:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI4OTM3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDAzMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554290030", "bodyText": "Is this class only required for logging purposes? If the these stats can't be accessed externally and only used for logging, then I would suggest converting it to a proper Metric so that we can collect it and log it as within our metrics performance library.\nThis metric can be kept registered and kept in the StreamSubscription instance.", "author": "Maithem", "createdAt": "2021-01-09T04:37:03Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingMetrics.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.google.gson.JsonObject;\n+\n+/**\n+ * List of metrics captured for a stream listener.\n+ * <p>\n+ * Created by WenbinZhu on 11/23/20.\n+ */\n+public class StreamingMetrics {\n+\n+    private final String listenerId;\n+\n+    private final TimingHistogram deliveryDuration;", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDQxOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554290419", "bodyText": "Also, note that TimingHistogram uses a EDR histogram (histogram) underneath which is not really accurate when reporting these stats in a short interval.", "author": "Maithem", "createdAt": "2021-01-09T04:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDAzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjExMTIwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556111206", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2021-01-12T21:36:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDAzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDE3OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554290179", "bodyText": "You can just nuke this and use a histogram from Micrometer. I also think that record is a better verb than set here.", "author": "Maithem", "createdAt": "2021-01-09T04:39:15Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingMetrics.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.google.gson.JsonObject;\n+\n+/**\n+ * List of metrics captured for a stream listener.\n+ * <p>\n+ * Created by WenbinZhu on 11/23/20.\n+ */\n+public class StreamingMetrics {\n+\n+    private final String listenerId;\n+\n+    private final TimingHistogram deliveryDuration;\n+\n+    StreamingMetrics(StreamListener listener, String namespace, String streamTag, MetricRegistry registry) {\n+        this.listenerId = String.format(\"StreamListener_%s_%s_%s\", listener, namespace, streamTag);\n+        this.deliveryDuration = new TimingHistogram(registry.histogram(listenerId + \"_deliveryDuration\"));\n+    }\n+\n+    public void setDeliveryDuration(long elapsedTime) {\n+        deliveryDuration.update(elapsedTime);\n+    }", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjExMTEwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556111106", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2021-01-12T21:36:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDI5MDE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMwMzY2Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554303662", "bodyText": "This won't produce any metrics. We moved away from using dropwizard to micrometer, make sure the correct registry is passed.", "author": "Maithem", "createdAt": "2021-01-09T07:17:02Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingMetrics.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.google.gson.JsonObject;\n+\n+/**\n+ * List of metrics captured for a stream listener.\n+ * <p>\n+ * Created by WenbinZhu on 11/23/20.\n+ */\n+public class StreamingMetrics {\n+\n+    private final String listenerId;\n+\n+    private final TimingHistogram deliveryDuration;\n+\n+    StreamingMetrics(StreamListener listener, String namespace, String streamTag, MetricRegistry registry) {\n+        this.listenerId = String.format(\"StreamListener_%s_%s_%s\", listener, namespace, streamTag);", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjExMDk3Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556110973", "bodyText": "Done, switched to micrometer.", "author": "WenbinZhu", "createdAt": "2021-01-12T21:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMwMzY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554310390", "bodyText": "This is not the only way to prevent busy polling and can cause high latencies.\nIf you have 1 thread running the notification tasks and 8 subscriptions and only one that is producing data then, the listener of that active stream will take 7 * 50 milliseconds to deliver the notification. You can try to hide this by increasing the number of threads in the notification task, but then the pathological case can be really bad and it doesn't seem like its unlikely, or rather, its not clear that at most a 50ms penalty will be inured.\nDepending on the producer rate it seems really hard to reason about the worst case. It's better to just use a scheduled executor and push that sleep to the executor scheduling instead of doing it before the submit.", "author": "Maithem", "createdAt": "2021-01-09T08:34:04Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ4Nzk3MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555487971", "bodyText": "I think the calculation is not right here. It's won't wait for 7 * 50 ms. As long as one thread is available, it can pick up the next task. If you have 7 subscriptions which are not producing data, and you have 4 threads in total, the latency of the  next subscription is just 50 ms, because all threads wait in parallel, not sequentially. And if you have 8 threads, there will be no latecy at all. Actually I chose this model because the schduled exector has an intrinsic latency, which is the scheduling interval. This interval causes latecy on every poll, no matter there is data or not, while this model has no latency when there are data produced, which is the common case. Sundar tried to reduce the schduled exector's latecy by using an infinite loop in the task, but that cause scalability issues as mentioned in my Conflucence deisign doc. So I intentionally abandoned the scheduled executor when making the design decision.", "author": "WenbinZhu", "createdAt": "2021-01-12T03:30:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIyMDQxMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556220412", "bodyText": "The max blocking time for a stream that has unread data is a function of the number of threads and number of streams.\nIf you have 1 threads running the notification task and 7 subscribers with only 1 active stream then the executor queue will look like this | Active | Inactive | Inactive | Inactive | Inactive | Inactive | Inactive (processing thread). If the queue will be consumed from right to left, then the processing thread will sleep for 6 * 50ms before the active thread is discovered. If you use a scheduled executes then the tasks will incur the sleep while waiting in the min-heap of the executor, notice that cost will not be incurred on the processing thread. This means that it can pick up active streams that can be read right away.\nThe fundamental difference is do you incur the cost of the sleep on the thread (which stalls the thread), or inside a waiting queue (which allows the worker thread to do useful work for active threads).\nIs that a correct characterization of a possible pattern ?", "author": "Maithem", "createdAt": "2021-01-13T02:20:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIyNjA0Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556226043", "bodyText": "This is a pathological case where your subscriber number is 8x than your polling thread, and most of the polled data is empty. I think the optimization is not related to using a scheduled executor or not, because scheduled executor has an intrintic delay which is the schedule interval. The right optimization, as you and Medhavi both kind of mentioned, is to use a customed delay queue for the executor and we still let the thread itself submit its tasks after the previous one is done, and the tasks will be a DelayedTask in case of empty data. However for now I'm not sure if that is worthy because our workloads are not large enough to have these pathological cases.", "author": "WenbinZhu", "createdAt": "2021-01-13T02:38:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI1NDEwMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556254103", "bodyText": "However for now I'm not sure if that is worthy because our workloads are not large enough to have these pathological cases.\n\nThe max blocking time for a stream that has unread data is a function of the number of threads and number of streams. Therefore in order to determine the likelihood of the worst case happening we need to know the numbers. We currently have ~300 tables in the system (as of ~6 months ago), if we assume that 20% of the tables will be tagged then each thread will on average handle (300 * .2) / 4 = 15 streams. Since most of the data is config data (i.e. static) then its clearly not a pathological case. In the future, we can only assume that there will be more tables.\n\nexecutor has an intrintic delay which is the schedule interval\n\nI don't understand where this intrinsic delay comes from and where it is incurred. Please explain.\nI also don't see this as an optimization per-se it just seems like a natural polling strategy, that is, to let the task sleep in the queue and not block the worker.", "author": "Maithem", "createdAt": "2021-01-13T04:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI2NDgyNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556264825", "bodyText": "Sure I will explore the delayedQueue approach, but let me clarify the calculation: the blocking time is not related to number of streams, because for each tag we have only one poller. Second, the blocking time is strongly related to number of subscribers, if number of subscribers is less than or equal to the thread number (which is the common case), than there will be no delay at all. An example is If you have 8 subscribers and 4 threads, the maximum possible delay if every poller gets empty data is 8/4*50 = 100ms, not 8 * 50. The reason I'm saying it's an optimization is that our current workload is not even saturating the thread number, i.e. number of subscribers <= thread number.\n\nI don't understand where this intrinsic delay comes from and where it is incurred. Please explain.\n\nIf the scheduled executors you mean is the scheduledExecutorService, than I mean it has an scheduling interval, which is the intrinsic delay, that will be casted on the poller every time, not matter it gets data or not. You can set that interval to be 0, then it's no different than the current approach. I think what you mean is not related to scheduled executor, rather it is the queue inside the executor, that needs to be delayed queue, and that's when the min-heap come into play.", "author": "WenbinZhu", "createdAt": "2021-01-13T05:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MzU4OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556293589", "bodyText": "Sure I will explore the delayedQueue approach, but let me clarify the calculation\n\nYep. sorry my point was Subscriber/tag vs Notification threads.\n\n8/4*50 = 100ms, not 8 * 50.\n\nWe are talking about two different configs. 4 threads are currently being used, but I used 1 thread in my example to highlight the relation between notification threads and tags\n\nIf the scheduled executors you mean is the scheduledExecutorService,\n\nWhat I was referring to was ScheduledExecutorService::schedule which creates a one-shot execution that will run after a certain delay. I'm not saying that you should schedule the tasks periodically with same delay. Using the current scheme depending on whether you read yields some entries or not, you can call schedule(task, 0) or schedule(task, Delay). This way the task delay will be incurred in the queue waiting and not on the worker thread. ScheduledExecutorService internally maintains a heap ordered by the tasks delay time. Now if all the streams are active then most of your schedules will be submitted with a 0 delay and that seems to be be fine when it comes to fairness. Based on code inspection it seems like they will be in FIFO order.", "author": "Maithem", "createdAt": "2021-01-13T06:41:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5ODIzNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556298235", "bodyText": "What I was referring to was ScheduledExecutorService::schedule which creates a one-shot execution that will run after a certain delay.\n\nOk then we are talking about the same idea, but slightly different implementation.", "author": "WenbinZhu", "createdAt": "2021-01-13T06:54:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIwMTYyNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557201624", "bodyText": "It seems like you ended up using the same method. Just out of curiosity, what was the different implementation that you were referring to, explicitly managing the scheduler's min-heap?", "author": "Maithem", "createdAt": "2021-01-14T08:36:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIzOTU3Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557239576", "bodyText": "Yes, I used ScheduledExecutorService. The alternative is still using a normal executor, but give it a customed delayed queue. Initially I thought DelayedWorkQueue is a public utility class that I can use, but later I found it's internal to ScheduledThreadPoolExecutor, so using ScheduledExecutorService is easier for me.", "author": "WenbinZhu", "createdAt": "2021-01-14T09:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDM5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDc2NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554310765", "bodyText": "Can you just put a sanity check here that the lastReadAddress is not regressing ?", "author": "Maithem", "createdAt": "2021-01-09T08:37:38Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+\n+        // No new updates, take a short break and poll again.\n+        if (updates.isEmpty()) {\n+            TimeUnit.MILLISECONDS.sleep(IDLE_WAIT_TIME_MS.toMillis());\n+            pollingExecutor.submit(this);\n+            return;\n+        }\n+\n+        // Insert polled updates to the subscription buffer, with a shared\n+        // fixed amount of time waiting for buffer being not full.\n+        long remainingBlockTime = QUEUE_FULL_BLOCK_TIME_MS.toNanos();\n+        for (ILogData update : updates) {\n+            if (subscription.isStopped()) {\n+                return;\n+            }\n+\n+            // Buffer is full after max waiting time elapses, break and re-schedule.\n+            long startTime = System.nanoTime();\n+            if (!subscription.enqueueStreamEntry(update, remainingBlockTime)) {\n+                break;\n+            }\n+\n+            remainingBlockTime -= System.nanoTime() - startTime;\n+            lastReadAddress = update.getGlobalAddress();", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ2NzU3MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555467571", "bodyText": "Done, added at the place when lastReadAddress is assigned.", "author": "WenbinZhu", "createdAt": "2021-01-12T02:18:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMDc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMzUxOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554313519", "bodyText": "The logic can be simplified while also improving graceful degradation by actually trying to check if StreamSubscription::streamBuffer has enough space before issuing the read to the server. Otherwise if the system is in a degraded state and the buffers are not being consumed fast enough, then you will be issuing reads and computing all the logic in StreamSubscription::enqueueStreamEntry  and then returning false on streamBuffer.offer.\nWhen throttling is actually required its probably better assume the pessimistic case vs the optimistic case (i.e., current logic): where you hope the the queue clears up while you're doing your processing.", "author": "Maithem", "createdAt": "2021-01-09T09:11:34Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamPollingTask.java", "diffHunk": "@@ -0,0 +1,108 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * A runnable task for a subscription to poll data change from the\n+ * transaction stream and put into the subscription's buffer. This\n+ * task is executed by the thread pool continuously until an error\n+ * occurs which would stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamPollingTask implements Runnable {\n+\n+    // A period of time in ms to sleep before next cycle when poller gets no new data changes.\n+    private static final Duration IDLE_WAIT_TIME_MS = Duration.ofMillis(50);\n+\n+    // Total amount of time to wait for putting the polled data changes into buffer if it is full.\n+    private static final Duration QUEUE_FULL_BLOCK_TIME_MS = Duration.ofMillis(2_000);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The corfu transaction stream to poll data changes from.\n+    private final IStreamView txnStream;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Last address of the data successfully processed by the buffer.\n+    private long lastReadAddress;\n+\n+    StreamPollingTask(StreamingManager streamingManager, long lastAddress,\n+                      StreamSubscription subscription, ExecutorService executor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.pollingExecutor = executor;\n+        this.lastReadAddress = lastAddress;\n+        this.txnStream = subscription.getTxnStream();\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            pollTxnStream();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during txn stream polling, listener: {}, \" +\n+                    \"namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Poll new data changes from the transaction stream and put into\n+     * the subscription's buffer one by one.\n+     */\n+    private void pollTxnStream() throws Exception {\n+        // If listener already unsubscribed, do not process or schedule again.\n+        if (subscription.isStopped()) {\n+            return;\n+        }\n+\n+        // Seek to next address and poll transaction updates.\n+        txnStream.seek(lastReadAddress + 1L);\n+        List<ILogData> updates = txnStream.remainingAtMost(subscription.getStreamBufferSize());\n+", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5MDg1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555490855", "bodyText": "StreamSubscription::enqueueStreamEntry actually waits for a short period for the notification thread to consume the queue. This approach is trying to balance between differnce scenarios and consumption speed.", "author": "WenbinZhu", "createdAt": "2021-01-12T03:42:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxMzUxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxOTIyMQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r554319221", "bodyText": "There are so many use cases where the client would want to control their own threading. I think we should just allow them to pass in an executor when calling subscribe. For example, they might need to prioritize some subscriptions over other subscriptions.\nFurthermore, it makes it harder to test. For example, the application can't write a deterministic unit test if they can't control the executors in StreamingManager. If the application is able to passs their own exeuctors, then they can deterministcly test call backs using something like  MoreExecutors.newDirectExecutorService.\nFinally, if they own their threading then they have to manage the exeuctors lifecycle, which means we don't need to make a decision on their behalf on whether threads should be daemon or not, and its less code for us.", "author": "Maithem", "createdAt": "2021-01-09T09:26:03Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamingManager.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.runtime.collections;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.StreamSubscriptionException;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+\n+/**\n+ * A streaming subscription manager that allows clients to listen on\n+ * the transaction updates of interested tables. The updates will be\n+ * streamlined and clients can get notifications via the registered\n+ * call backs.\n+ * <p>\n+ * Created by WenbinZhu on 11/5/20.\n+ */\n+@Slf4j\n+public class StreamingManager {\n+\n+    // Number of thread in polling and notification pool.\n+    private static final int NUM_THREAD_PER_POOL = 4;\n+\n+    // Default buffer size for each subscription.\n+    private static final int DEFAULT_BUFFER_SIZE = 50;\n+\n+    // Corfu runtime to interact with corfu streams.\n+    private final CorfuRuntime runtime;\n+\n+    // A map of all stream listeners and their subscription contexts.\n+    private final Map<StreamListener, StreamSubscription> subscriptions;\n+\n+    // Thread pool for executing stream polling tasks.\n+    private final ExecutorService pollingExecutor;\n+\n+    // Thread pool for executing client call back tasks.\n+    private final ExecutorService notificationExecutor;", "originalCommit": "5e25ca91a6cbd59de644dbc60ca7c66eaeb6adaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTQ5Mzk3NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r555493975", "bodyText": "I think the reason that we don't want users to pass the executor is that the executor is shared by all subscribers. Usually differnent subscribers are from different verticals, the executor serves them all, so it's not so appropriate for a vertical to specify an executor when subscribing. If any subscriber can specify any an executor, the resource usage can be a problem and we need to maintain a lot of exectutors from different subscribers which is kind of messy.", "author": "WenbinZhu", "createdAt": "2021-01-12T03:46:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxOTIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjA5ODEyMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556098120", "bodyText": "Yes, that make sense, but that sharing shouldn't be expressed and hidden in our code. The entity (i.e., application code) that is creating the StreamingManager can choose how to manage the thread allocation.", "author": "Maithem", "createdAt": "2021-01-12T21:12:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxOTIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjE5NjkyOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556196929", "bodyText": "The entity that is creating CorfuStore is usually different from the veticals that are using it, so it's no better than we doing it. Also if we change that it will break a lot of application code, maybe later we can discuss with verticals to see how they are using it.", "author": "WenbinZhu", "createdAt": "2021-01-13T01:06:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxOTIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjIxODA0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r556218044", "bodyText": "That is my point. There needs to be a centralization point that figures out configuration before exposing it to verticals. That centralization point of figuring configuration shouldn't be managed by the library itself, but in upper layers.\nI guess there is two points here 1) what's a better design approach 2) what are the implications of this change (i.e., breaking existing code). I don't think that its a good idea to forgo #1 because of #2.", "author": "Maithem", "createdAt": "2021-01-13T02:12:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDMxOTIyMQ=="}], "type": "inlineReview"}, {"oid": "c65f0e24e7d42cc1df437e4ce5adea62647140c0", "url": "https://github.com/CorfuDB/CorfuDB/commit/c65f0e24e7d42cc1df437e4ce5adea62647140c0", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-11T20:43:14Z", "type": "forcePushed"}, {"oid": "d94c5119ebe39a2b8dd66ce25bfb9391a0f9e020", "url": "https://github.com/CorfuDB/CorfuDB/commit/d94c5119ebe39a2b8dd66ce25bfb9391a0f9e020", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-12T02:00:25Z", "type": "forcePushed"}, {"oid": "8ee51d4b19303bc8d0357677577d2979d0c9814d", "url": "https://github.com/CorfuDB/CorfuDB/commit/8ee51d4b19303bc8d0357677577d2979d0c9814d", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-12T02:15:01Z", "type": "forcePushed"}, {"oid": "ee314c580d475d35445cd01f4df23bb070192fd2", "url": "https://github.com/CorfuDB/CorfuDB/commit/ee314c580d475d35445cd01f4df23bb070192fd2", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-12T03:47:21Z", "type": "forcePushed"}, {"oid": "211bd1f813836bfb2068ad57bfa334f87ad052a6", "url": "https://github.com/CorfuDB/CorfuDB/commit/211bd1f813836bfb2068ad57bfa334f87ad052a6", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-12T21:34:53Z", "type": "forcePushed"}, {"oid": "1f9cc57f4944b39980512fbcb3b8f03c0c19698e", "url": "https://github.com/CorfuDB/CorfuDB/commit/1f9cc57f4944b39980512fbcb3b8f03c0c19698e", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-12T21:35:59Z", "type": "forcePushed"}, {"oid": "a80c7038cb1ae01ce89ea650437b72477072d3ff", "url": "https://github.com/CorfuDB/CorfuDB/commit/a80c7038cb1ae01ce89ea650437b72477072d3ff", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-13T19:56:37Z", "type": "forcePushed"}, {"oid": "3b658e373336d683693c685bd0bf77774b00b7a8", "url": "https://github.com/CorfuDB/CorfuDB/commit/3b658e373336d683693c685bd0bf77774b00b7a8", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-14T01:08:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIwNzg3MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557207871", "bodyText": "Can you also add metrics on the consumer side. The kvstore already has issues where the consumer callbacks consume too much time, so I'm expecting we will need to track this as well.", "author": "Maithem", "createdAt": "2021-01-14T08:40:13Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamSubscriptionMetrics.java", "diffHunk": "@@ -0,0 +1,35 @@\n+package org.corfudb.runtime.collections;\n+\n+import io.micrometer.core.instrument.Timer;\n+import org.corfudb.runtime.CorfuRuntime;\n+\n+import java.util.Optional;\n+\n+/**\n+ * List of metrics captured for a stream listener.\n+ * <p>\n+ * Created by WenbinZhu on 11/23/20.\n+ */\n+public class StreamSubscriptionMetrics {", "originalCommit": "3b658e373336d683693c685bd0bf77774b00b7a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI0MDUzOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557240539", "bodyText": "Yes we already have this metrics that records customer callback duration.", "author": "WenbinZhu", "createdAt": "2021-01-14T09:07:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIwNzg3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIyMDQ2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557220469", "bodyText": "Can you also add\nif (iter == 0 && nextUpdate == null) {\n\n notificationExecutor.schedule(this, IDLE_WAIT_TIME_MS, TimeUnit.MILLISECONDS);\nreturn;\n     }\nThis will prevent unnecessary waits on the consumer side when the stream is always empty. This improves the CPU usage for empty streams, but the ideal solution is to only submit the task if the producer enqueued entries. Going from 50ms polling to seconds should be ok for our scale, I think.", "author": "Maithem", "createdAt": "2021-01-14T08:47:42Z", "path": "runtime/src/main/java/org/corfudb/runtime/collections/StreamNotificationTask.java", "diffHunk": "@@ -0,0 +1,98 @@\n+package org.corfudb.runtime.collections;\n+\n+import lombok.extern.slf4j.Slf4j;\n+\n+import java.time.Duration;\n+import java.util.concurrent.ExecutorService;\n+\n+/**\n+ * A runnable task for a subscription to retrieve the previously\n+ * polled transaction updates from the buffer and send notifications\n+ * to client via the registered call backs. This task is executed\n+ * by the thread pool continuously until an error occurs which would\n+ * stop the subscription.\n+ * <p>\n+ * Created by WenbinZhu on 11/9/20.\n+ */\n+@Slf4j\n+class StreamNotificationTask implements Runnable {\n+\n+    // Number of transaction updates to send notification in each run.\n+    private static final int NOTIFICATION_BATCH_SIZE = 10;\n+\n+    // Total amount of time to wait for retrieving the data changes from buffer if it is empty.\n+    private static final Duration QUEUE_EMPTY_BLOCK_TIME_MS = Duration.ofMillis(1_000);\n+\n+    // A warning will be raised if client call back takes longer than this time threshold.\n+    private static final Duration SLOW_NOTIFICATION_TIME_MS = Duration.ofMillis(1_500);\n+\n+    // The streaming manager that is in charge of listener subscriptions.\n+    private final StreamingManager streamingManager;\n+\n+    // The subscription context associated with this task.\n+    private final StreamSubscription subscription;\n+\n+    // The Thread pool for executing client notification tasks.\n+    private final ExecutorService notificationExecutor;\n+\n+    StreamNotificationTask(StreamingManager streamingManager,\n+                           StreamSubscription subscription,\n+                           ExecutorService notificationExecutor) {\n+        this.streamingManager = streamingManager;\n+        this.subscription = subscription;\n+        this.notificationExecutor = notificationExecutor;\n+    }\n+\n+    @Override\n+    public void run() {\n+        try {\n+            sendNotifications();\n+        } catch (Throwable throwable) {\n+            StreamListener listener = subscription.getListener();\n+            log.error(\"Encountered exception {} during client notification callback, \" +\n+                    \"listener: {}, namespace: {}\", throwable, listener, subscription.getNamespace());\n+            streamingManager.unsubscribe(listener, false);\n+            listener.onError(throwable);\n+        }\n+    }\n+\n+    /**\n+     * Retrieve the first data change from the buffer and send notification\n+     * to the client via the pre-registered call back.\n+     */\n+    private void sendNotifications() throws Exception {\n+        // Total amount of time for the batch waiting for buffer being not empty.\n+        long remainingBlockTime = QUEUE_EMPTY_BLOCK_TIME_MS.toNanos();\n+        StreamListener listener = subscription.getListener();\n+\n+        for (int iter = 0; iter < NOTIFICATION_BATCH_SIZE; iter++) {\n+            // If listener already unsubscribed, do not process or schedule again.\n+            if (subscription.isStopped()) {\n+                return;\n+            }\n+\n+            long startTime = System.nanoTime();\n+            CorfuStreamEntries nextUpdate = subscription.dequeueStreamEntry(remainingBlockTime);\n+\n+            // No new updates after max waiting time elapses, break and re-schedule.\n+            if (nextUpdate == null) {\n+                break;", "originalCommit": "3b658e373336d683693c685bd0bf77774b00b7a8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI0MTY3OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557241679", "bodyText": "Actually I think we do not need to wait in this case. If we hit this case, that means we already waited for some time, so cpu won't busy loop.", "author": "WenbinZhu", "createdAt": "2021-01-14T09:09:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIyMDQ2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzYxMTI4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2826#discussion_r557611280", "bodyText": "I think it makes sense for the producer to wait one the enqueue to happen (i.e., on offer) because if the enqueue cannot happen right away it means means that the queue is full and the consumer is backed up and still processing. But when the consumer waits on poll, it never knows if the producer will ever enqueue or not, so it will keep waiting on the worker thread over and over again even if the stream is always empty.\nI feel like it makes to have dequeueStreamEntry return right away without waiting and then submitting the task with a delay in notificationExecutor.schedule(this, delay)", "author": "Maithem", "createdAt": "2021-01-14T18:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIyMDQ2OQ=="}], "type": "inlineReview"}, {"oid": "87013c882f049532686fde452c9b159d3902dcca", "url": "https://github.com/CorfuDB/CorfuDB/commit/87013c882f049532686fde452c9b159d3902dcca", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-15T01:08:37Z", "type": "forcePushed"}, {"oid": "4653d95650906dc470df7278b96911bf00491aad", "url": "https://github.com/CorfuDB/CorfuDB/commit/4653d95650906dc470df7278b96911bf00491aad", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-20T19:27:24Z", "type": "commit"}, {"oid": "4653d95650906dc470df7278b96911bf00491aad", "url": "https://github.com/CorfuDB/CorfuDB/commit/4653d95650906dc470df7278b96911bf00491aad", "message": "CorfuStore streaming redesign part 3 - implementation and integration.\n\nImplements the new subscription API and new threading model for\nstreaming and integrate into CorfuStore.", "committedDate": "2021-01-20T19:27:24Z", "type": "forcePushed"}]}