{"pr_number": 2552, "pr_title": "Introducing auto commit mechanism for faster read and state transfer.", "pr_createdAt": "2020-05-28T18:55:26Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2552", "timeline": [{"oid": "5dc8ee7be2d1c31640deff11f18c138c67d8e31b", "url": "https://github.com/CorfuDB/CorfuDB/commit/5dc8ee7be2d1c31640deff11f18c138c67d8e31b", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-05-30T00:58:16Z", "type": "forcePushed"}, {"oid": "1d277e87f374c3a357063d1a5f1048ef1bf9be62", "url": "https://github.com/CorfuDB/CorfuDB/commit/1d277e87f374c3a357063d1a5f1048ef1bf9be62", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-03T00:08:00Z", "type": "forcePushed"}, {"oid": "dcdb9d5c1008da0f2ea9246c5d46d7becfe7b57e", "url": "https://github.com/CorfuDB/CorfuDB/commit/dcdb9d5c1008da0f2ea9246c5d46d7becfe7b57e", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-03T00:57:31Z", "type": "forcePushed"}, {"oid": "c0e094ef16c1fe0272a34de746c2795aa6f8741c", "url": "https://github.com/CorfuDB/CorfuDB/commit/c0e094ef16c1fe0272a34de746c2795aa6f8741c", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-03T00:58:22Z", "type": "forcePushed"}, {"oid": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "url": "https://github.com/CorfuDB/CorfuDB/commit/2abe3b559d8cf02c86aaafb961b683db226fa06b", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-04T00:08:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUwNDg2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435504869", "bodyText": "I think the description of the Management Agent class should reflect that it also runs an auto-commit service", "author": "PavelZaytsev", "createdAt": "2020-06-04T19:39:38Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/ManagementAgent.java", "diffHunk": "@@ -123,6 +133,8 @@ public ManagementAgent(@NonNull SingletonResource<CorfuRuntime> runtimeSingleton\n                 localMonitoringService\n         );\n \n+        this.autoCommitService = new AutoCommitService(serverContext, runtimeSingletonResource);", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MTgzMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435641832", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:27:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUwNDg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUwOTY0OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435509649", "bodyText": "Is it safe to save a management layout here? What will happen if we don't do this?", "author": "PavelZaytsev", "createdAt": "2020-06-04T19:48:34Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    void runAutoCommit() {\n+        long lastEpoch = -1;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                if (!isNodePrimarySequencer(updateLayoutAndGet())) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.debug(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails();\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = getCorfuRuntime().getLayoutView().getLayout().getEpoch();\n+                if (lastEpoch < 0 || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle. \" +\n+                        \"New committed tail: {}.\", committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.warn(\"runAutoCommit: encountered an exception on attempt {}/{}.\",\n+                        i, MAX_COMMIT_RETRY, re);\n+\n+                if (i >= MAX_COMMIT_RETRY) {\n+                    log.warn(\"runAutoCommit: retry exhausted, abort and wait for next cycle\");\n+                }\n+\n+                Throwable cause = re.getCause();\n+                if (cause instanceof TimeoutException || cause instanceof NetworkException) {\n+                    Sleep.sleepUninterruptibly(CONN_RETRY_RATE);\n+                }\n+\n+            } catch (Throwable t) {\n+                log.error(\"runAutoCommit: encountered unexpected exception\", t);\n+                lastLogTail = getCorfuRuntime().getSequencerView().query().getSequence();\n+                throw t;\n+            }\n+        }\n+\n+        // Update lastLogTail no matter commit cycle succeeds or not.\n+        lastLogTail = getCorfuRuntime().getSequencerView().query().getSequence();\n+    }\n+\n+    private Layout updateLayoutAndGet() {\n+        return getCorfuRuntime()\n+                .invalidateLayout()\n+                .thenApply(serverContext::saveManagementLayout)", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MjA3MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435642070", "bodyText": "I kept it same as what RemoteMonitoringService does. Saving management layout helps server to recover with lastest layout.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:28:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUwOTY0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxODQyNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435518424", "bodyText": "I understand that this is an optimization, however, I am pondering if it can result in any issues. For example, what if we have a one node setup, where the epochs change infrequently, but log grows fast, so gets trimmed a lot. Will we by accident committing addresses that have already been trimmed?", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:05:57Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    void runAutoCommit() {\n+        long lastEpoch = -1;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                if (!isNodePrimarySequencer(updateLayoutAndGet())) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.debug(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails();\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = getCorfuRuntime().getLayoutView().getLayout().getEpoch();", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MjUwNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435642507", "bodyText": "The if we try to inspect the address brfore the trim mark, log unit server will throw a TrimmedException. Also committing addresses that have trimmed should be safe.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:30:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxODQyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMjU2Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435522566", "bodyText": "Are there any advantages of using this rather than a simple ArrayList/ImmutableList, for example?", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:13:57Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/AddressSpaceView.java", "diffHunk": "@@ -471,61 +472,84 @@ private ILogData cacheLoadAndGet(@NonNull Cache<Long, ILogData> cache, long addr\n \n     /**\n      * Get the first address in the address space.\n+     *\n+     * @return a token with epoch and first address\n      */\n     public Token getTrimMark() {\n-        return layoutHelper(\n-                e -> {\n-                    long trimMark = e.getLayout().segments.stream()\n-                            .flatMap(seg -> seg.getStripes().stream())\n-                            .flatMap(stripe -> stripe.getLogServers().stream())\n-                            .map(e::getLogUnitClient)\n-                            .map(LogUnitClient::getTrimMark)\n-                            .map(future -> {\n-                                // This doesn't look nice, but its required to trigger\n-                                // the retry mechanism in AbstractView. Also, getUninterruptibly\n-                                // can't be used here because it throws a UnrecoverableCorfuInterruptedError\n-                                try {\n-                                    return future.join();\n-                                } catch (CompletionException ex) {\n-                                    Throwable cause = ex.getCause();\n-                                    if (cause instanceof RuntimeException) {\n-                                        throw (RuntimeException) cause;\n-                                    } else {\n-                                        throw new RuntimeException(cause);\n-                                    }\n-                                }\n-                            })\n-                            .max(Comparator.naturalOrder()).get();\n-                    return new Token(e.getLayout().getEpoch(), trimMark);\n-                });\n+        return getTrimMark(true);\n+    }\n+\n+    /**\n+     * Get the first address in the address space.\n+     *\n+     * @param retry whether to do retry on certain failures\n+     * @return a token with epoch and first address\n+     */\n+    public Token getTrimMark(boolean retry) {\n+        return layoutHelper(Utils::getTrimMark, !retry);\n     }\n \n     /**\n      * Get the log's tail, i.e., last address in the address space.\n      */\n     public Long getLogTail() {\n-        return layoutHelper(\n-                e -> Utils.getLogTail(e.getLayout(), runtime));\n+        return layoutHelper(Utils::getLogTail);\n     }\n \n     /**\n      * Get all tails, includes: log tail and stream tails.\n      */\n     public TailsResponse getAllTails() {\n-        return layoutHelper(\n-                e -> Utils.getAllTails(e.getLayout(), runtime));\n+        return layoutHelper(Utils::getAllTails);\n     }\n \n     /**\n      * Get log address space, which includes:\n      * 1. Addresses belonging to each stream.\n      * 2. Log Tail.\n      *\n-     * @return\n+     * @return log address space\n      */\n     public StreamsAddressResponse getLogAddressSpace() {\n-        return layoutHelper(\n-                e -> Utils.getLogAddressSpace(e.getLayout(), runtime));\n+        return layoutHelper(Utils::getLogAddressSpace);\n+    }\n+\n+    /**\n+     * Get the maximum committed log tail from all log units.\n+     *\n+     * @return the maximum committed log tail\n+     */\n+    public long getCommittedTail() {\n+        return layoutHelper(Utils::getCommittedTail, true);\n+    }\n+\n+    /**\n+     * Commit the addresses in the range by first inspecting the addresses\n+     * and if data does not exist in log, hole fill the address. This is\n+     * used by management agent for log consolidation.\n+     *\n+     * @param start start of address range, inclusive\n+     * @param end   end of address range, inclusive\n+     */\n+    public void commit(long start, long end) {\n+        if (start >= end) {\n+            return;\n+        }\n+\n+        ContiguousSet<Long> range = ContiguousSet.create(", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MjcyMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435642723", "bodyText": "Here we need a fast way to create a contiguous list/set given by two endpoints.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:31:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMjU2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNjkzOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435526938", "bodyText": "I think we need JavaDoc here.", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:22:42Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/StreamLogFiles.java", "diffHunk": "@@ -1186,6 +1197,22 @@ public LogData read(long address) {\n         }\n     }\n \n+    @Override", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNzU5OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435527598", "bodyText": "Also maybe we can give a more clear name to the method.", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNjkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzIxNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435643217", "bodyText": "The JavaDoc is provided in the public interface of this class", "author": "WenbinZhu", "createdAt": "2020-06-05T01:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNjkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzNzg0OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435537848", "bodyText": "Right now when we get a token from a sequencer we do it via layoutHelper, which retries up to systemDownHandlerTriggerLimit if something goes wrong. In some cases, for example, when the sequencer requires a full bootstrap from a failure detector, this can get stuck for quite a long period of time. I am wondering if there is a possibility of this interfering with a periodically scheduled auto-commit task. For example, if this update to the lastLogTail can somehow interfere with a next scheduled runAutoCommit task because it takes longer than expected to finish it.", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:44:34Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    void runAutoCommit() {\n+        long lastEpoch = -1;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                if (!isNodePrimarySequencer(updateLayoutAndGet())) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.debug(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails();\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = getCorfuRuntime().getLayoutView().getLayout().getEpoch();\n+                if (lastEpoch < 0 || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle. \" +\n+                        \"New committed tail: {}.\", committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.warn(\"runAutoCommit: encountered an exception on attempt {}/{}.\",\n+                        i, MAX_COMMIT_RETRY, re);\n+\n+                if (i >= MAX_COMMIT_RETRY) {\n+                    log.warn(\"runAutoCommit: retry exhausted, abort and wait for next cycle\");\n+                }\n+\n+                Throwable cause = re.getCause();\n+                if (cause instanceof TimeoutException || cause instanceof NetworkException) {\n+                    Sleep.sleepUninterruptibly(CONN_RETRY_RATE);\n+                }\n+\n+            } catch (Throwable t) {\n+                log.error(\"runAutoCommit: encountered unexpected exception\", t);\n+                lastLogTail = getCorfuRuntime().getSequencerView().query().getSequence();\n+                throw t;\n+            }\n+        }\n+\n+        // Update lastLogTail no matter commit cycle succeeds or not.\n+        lastLogTail = getCorfuRuntime().getSequencerView().query().getSequence();", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzQyNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435643426", "bodyText": "I changed to use seqeuncer client instead of sequencer view", "author": "WenbinZhu", "createdAt": "2020-06-05T01:34:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzNzg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzOTE4MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435539181", "bodyText": "I think it might be beneficial to either make it public or define some public wrapper,so that other code can invoke it. Right now it can only be called from inside a package", "author": "PavelZaytsev", "createdAt": "2020-06-04T20:47:16Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,188 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    void runAutoCommit() {", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzQ1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435643455", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:34:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzOTE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4ODIwMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435588202", "bodyText": "Can we get rid of trimmed in this File?", "author": "zhangn49", "createdAt": "2020-06-04T22:32:07Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/InMemoryStreamLog.java", "diffHunk": "@@ -154,6 +174,19 @@ public LogData read(long address) {\n         return logCache.get(address);\n     }\n \n+    @Override\n+    public boolean contains(long address) throws TrimmedException {\n+        if (isTrimmed((address))) {\n+            throw new TrimmedException();\n+        }\n+", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzUyOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435643528", "bodyText": "In memory stream log still needs a notion of trimmed.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:34:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4ODIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4OTE3Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435589172", "bodyText": "Is synchronized necessary here?", "author": "zhangn49", "createdAt": "2020-06-04T22:34:37Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/InMemoryStreamLog.java", "diffHunk": "@@ -109,6 +114,21 @@ public synchronized StreamsAddressResponse getStreamsAddressSpace() {\n         return new StreamsAddressResponse(logMetadata.getGlobalTail(), logMetadata.getStreamsAddressSpaceMap());\n     }\n \n+    @Override\n+    public long getCommittedTail() {\n+        return committedTail.get();\n+    }\n+\n+    @Override\n+    public synchronized void updateCommittedTail(long newCommittedTail) {", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0MzU1Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435643553", "bodyText": "Removed, thanks.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:34:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4OTE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwMTQ4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435601480", "bodyText": "Does it only update current node's committedTail? Should it also update source node's ct?", "author": "zhangn49", "createdAt": "2020-06-04T23:11:35Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/orchestrator/actions/RestoreRedundancyMergeSegments.java", "diffHunk": "@@ -195,6 +206,28 @@ Layout restoreWithBackOff(CorfuRuntime runtime, StateTransferManager transferMan\n                 .collect(Collectors.toList());\n     }\n \n+    /**\n+     * Send the last transferred address as the committed tail to the target log unit.\n+     * This is required to prevent loss of committed tail after state transfer finishes\n+     * and then all other log units failed and auto commit service is paused.\n+     */\n+    private void transferCommittedTail(CorfuRuntime runtime, Layout layout, long committedTail) {\n+        final int maxRetry = 3;\n+        LogUnitClient logUnitClient = runtime.getLayoutView()\n+                .getRuntimeLayout(layout)\n+                .getLogUnitClient(currentNode);\n+\n+        for (int i = 0; i < maxRetry; i++) {\n+            try {\n+                CFUtils.getUninterruptibly(logUnitClient.updateCommittedTail(committedTail),\n+                        TimeoutException.class, NetworkException.class);", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwMjUwMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435602502", "bodyText": "Should we add a log info/debug here to indicate transfer CT succeed?\nupdateCommittedTail in LogUnitServer's log is in trace level, and it would be better for us to know retry exhausts or not", "author": "zhangn49", "createdAt": "2020-06-04T23:15:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwMTQ4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0NDEyNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435644127", "bodyText": "We only need to update current node's committed tail to prevent an edge case that losing all committed tails. We don't update the source because we don't want the state transfer to have too much dependency on the committed tail, if the source is not quite responsive, the state transfer on current node can not be finished.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwMTQ4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYxODU2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435618569", "bodyText": "Can we use noAutoCommit to be consistent with ServerContextBuilder?", "author": "zhangn49", "createdAt": "2020-06-04T23:50:55Z", "path": "test/src/test/java/org/corfudb/integration/AbstractIT.java", "diffHunk": "@@ -361,6 +361,7 @@ public void run() {\n \n         private boolean single = true;\n         private boolean tlsEnabled = false;\n+        private boolean autoCommit = false;", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0NDE5OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435644198", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:37:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYxODU2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYyNDYxNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435624617", "bodyText": "How it handles TrimException in inspectAddresses?", "author": "zhangn49", "createdAt": "2020-06-05T00:14:45Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/replication/ChainReplicationProtocol.java", "diffHunk": "@@ -127,6 +125,49 @@ public ILogData peek(RuntimeLayout runtimeLayout, long globalAddress) {\n         return waitOrHoleFill(runtimeLayout, readResult, waitForWrite);\n     }\n \n+    /**\n+     * Commit the addresses by first reading and then hole filling if data not existed.\n+     *\n+     * @param runtimeLayout the RuntimeLayout stamped with layout to use for commit\n+     * @param addresses     a collection of addresses to commit\n+     */\n+    @Override\n+    public void commitAll(RuntimeLayout runtimeLayout, Collection<Long> addresses) {\n+        // Group addresses by log unit client.\n+        Map<LogUnitClient, List<Long>> serverAddressMap =\n+                groupAddressByLogUnit(runtimeLayout, addresses);\n+\n+        // Send inspect addresses requests to log unit servers in parallel.\n+        List<CompletableFuture<InspectAddressesResponse>> futures = serverAddressMap\n+                .entrySet()\n+                .stream()\n+                .map(entry -> entry.getKey().inspectAddresses(entry.getValue()))\n+                .collect(Collectors.toList());\n+\n+        // Merge the inspect responses from different log unit servers.\n+        List<Long> holes = futures.stream()\n+                .flatMap(future -> CFUtils.getUninterruptibly(future).getEmptyAddresses().stream())\n+                .collect(Collectors.toList());", "originalCommit": "2abe3b559d8cf02c86aaafb961b683db226fa06b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTY0OTA3Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r435649077", "bodyText": "TrimmedException is poped up tp AddressSpaceView and then AutoCommitService. Then current commit cycle fails and retries. There's actually a bug in handling retry, I fixed will add a test case.", "author": "WenbinZhu", "createdAt": "2020-06-05T01:56:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYyNDYxNw=="}], "type": "inlineReview"}, {"oid": "9b91666924f38ec9cbe054cb72f853ebc1591528", "url": "https://github.com/CorfuDB/CorfuDB/commit/9b91666924f38ec9cbe054cb72f853ebc1591528", "message": "Address review comments.", "committedDate": "2020-06-05T01:57:08Z", "type": "forcePushed"}, {"oid": "15607f9bf20f2339524ab495d7cccd8283d7f26f", "url": "https://github.com/CorfuDB/CorfuDB/commit/15607f9bf20f2339524ab495d7cccd8283d7f26f", "message": "Address review comments.", "committedDate": "2020-06-05T04:03:36Z", "type": "forcePushed"}, {"oid": "7cc0a3049314f48858818addf69c592d800a0dd3", "url": "https://github.com/CorfuDB/CorfuDB/commit/7cc0a3049314f48858818addf69c592d800a0dd3", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-05T04:05:46Z", "type": "forcePushed"}, {"oid": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "url": "https://github.com/CorfuDB/CorfuDB/commit/d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-05T19:31:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MDYyMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437080620", "bodyText": "please make these parameters not static - it allows to make it configurable in the future. Right now this is hard coded but must be configureble", "author": "xnull", "createdAt": "2020-06-09T01:03:20Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0MzkzNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440543934", "bodyText": "They are fine tuned for now, so they are static final, later if we need to expose them, I will change it accordingly.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:03:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MDYyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MDk3Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437080976", "bodyText": "why not 0?", "author": "xnull", "createdAt": "2020-06-09T01:04:50Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NDA0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440544044", "bodyText": "It needs to be initialized to an invalid epoch.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:03:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MDk3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MTczMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437081730", "bodyText": "please write a message to the log only ones - whether it commited or failed", "author": "xnull", "createdAt": "2020-06-09T01:07:24Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;\n+        Layout currentLayout = null;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                currentLayout = updateLayoutAndGet();\n+                if (!isNodePrimarySequencer(currentLayout)) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.trace(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails(currentLayout);\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = currentLayout.getEpoch();\n+                if (lastEpoch < 0 || trimmed || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                    trimmed = false;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NDA4Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440544082", "bodyText": "Done, reduced to trace.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:03:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MTczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MzQ3NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437083475", "bodyText": "what's the motivation, why you need to update the layout?\nFD is in charge of doing it, not sure if it safe to update the layout here", "author": "xnull", "createdAt": "2020-06-09T01:13:57Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;\n+        Layout currentLayout = null;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                currentLayout = updateLayoutAndGet();\n+                if (!isNodePrimarySequencer(currentLayout)) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.trace(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails(currentLayout);\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = currentLayout.getEpoch();\n+                if (lastEpoch < 0 || trimmed || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                    trimmed = false;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle. \" +\n+                        \"New committed tail: {}.\", committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.warn(\"runAutoCommit: encountered an exception on attempt {}/{}.\",\n+                        i, MAX_COMMIT_RETRY, re);\n+\n+                if (i >= MAX_COMMIT_RETRY) {\n+                    log.warn(\"runAutoCommit: retry exhausted, abort and wait for next cycle\");\n+                    break;\n+                }\n+\n+                // When inspecting address, log unit server could throw a TrimmedException if\n+                // the address to inspect is trimmed, then we need to adjust committed tail.\n+                if (re instanceof TrimmedException) {\n+                    trimmed = true;\n+                }\n+\n+                if (re instanceof NetworkException || re.getCause() instanceof TimeoutException) {\n+                    Sleep.sleepUninterruptibly(CONN_RETRY_RATE);\n+                }\n+\n+            } catch (Throwable t) {\n+                log.error(\"runAutoCommit: encountered unexpected exception\", t);\n+                updateLastLogTail(currentLayout);\n+                throw t;\n+            }\n+        }\n+\n+        // Update lastLogTail no matter commit cycle succeeds or not.\n+        updateLastLogTail(currentLayout);\n+    }\n+\n+    private Layout updateLayoutAndGet() {", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NjA1MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440546050", "bodyText": "Layout need to be updated to handle wong epoch, and disable auto commit if not primary sequencer. Safety is guarantee by using layoutHelper. I removed saveManagementLayout as it's not necessarily needed.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:11:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4MzQ3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4Mzk2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437083969", "bodyText": "Why do we need to run it as a separate service, why we can't execute it in RemoteMonitoringService after the iteration of failure detection?", "author": "xnull", "createdAt": "2020-06-09T01:15:56Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NjUxOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440546519", "bodyText": "RemoteMonitoringService executes too often, auto commit needs its own interval\nAuto commit can block RemoteMonitoringService\nIt's cleaner to have a separate service", "author": "WenbinZhu", "createdAt": "2020-06-16T02:13:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4Mzk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDg2NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437084864", "bodyText": "don't need to print every single time this.\nJust print an error in case of you can't finish the operation", "author": "xnull", "createdAt": "2020-06-09T01:19:51Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;\n+        Layout currentLayout = null;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                currentLayout = updateLayoutAndGet();\n+                if (!isNodePrimarySequencer(currentLayout)) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.trace(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails(currentLayout);\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = currentLayout.getEpoch();\n+                if (lastEpoch < 0 || trimmed || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                    trimmed = false;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle. \" +\n+                        \"New committed tail: {}.\", committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.warn(\"runAutoCommit: encountered an exception on attempt {}/{}.\",", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NjU3MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440546570", "bodyText": "Done, lowered to trace.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:13:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDg2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDk2MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437084961", "bodyText": "no need for this", "author": "xnull", "createdAt": "2020-06-09T01:20:10Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;\n+        Layout currentLayout = null;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                currentLayout = updateLayoutAndGet();\n+                if (!isNodePrimarySequencer(currentLayout)) {\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.trace(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    initializeTails(currentLayout);\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = currentLayout.getEpoch();\n+                if (lastEpoch < 0 || trimmed || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                    trimmed = false;\n+                }\n+\n+                log.debug(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle. \" +\n+                        \"New committed tail: {}.\", committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.warn(\"runAutoCommit: encountered an exception on attempt {}/{}.\",\n+                        i, MAX_COMMIT_RETRY, re);\n+\n+                if (i >= MAX_COMMIT_RETRY) {\n+                    log.warn(\"runAutoCommit: retry exhausted, abort and wait for next cycle\");", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0Njc5OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440546799", "bodyText": "Since now we don't log on every exception, we need this.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:14:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NDk2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NjEzMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437086132", "bodyText": "The method seems too complicated. Since it is complex, it's hard to write tests for this method. Can you make it smaller and add more unit tests?", "author": "xnull", "createdAt": "2020-06-09T01:24:37Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,217 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    private static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NzEyMQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440547121", "bodyText": "It's not complited, the core logic of this method is just 30 lines, others are just exception handling and comments.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA4NjEzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MDY2OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437090669", "bodyText": "what was motivation for renaming it?", "author": "xnull", "createdAt": "2020-06-09T01:42:17Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LocalMonitoringService.java", "diffHunk": "@@ -23,7 +23,7 @@\n  * Created by zlokhandwala on 11/2/18.\n  */\n @Slf4j\n-class LocalMonitoringService implements MonitoringService {\n+class LocalMonitoringService implements ManagementService {", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTAxNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437091016", "bodyText": "code reformat please", "author": "xnull", "createdAt": "2020-06-09T01:43:38Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogUnitServer.java", "diffHunk": "@@ -308,6 +330,25 @@ public void multiRead(CorfuPayloadMsg<MultipleReadRequest> msg, ChannelHandlerCo\n         }\n     }\n \n+    @ServerHandler(type = CorfuMsgType.INSPECT_ADDRESSES_REQUEST)\n+    public void inspectAddresses(CorfuPayloadMsg<InspectAddressesRequest> msg,\n+                                 ChannelHandlerContext ctx, IServerRouter r) {\n+        log.trace(\"inspectAddresses: {}\", msg.getPayload().getAddresses());\n+        InspectAddressesResponse inspectResponse = new InspectAddressesResponse();\n+        try {\n+            for (long address : msg.getPayload().getAddresses()) {", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NzU2OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440547568", "bodyText": "There is nothing to format here, the entire method is already well formatted. Even IDE tells it's already formatted.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:17:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTAxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTMzOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437091339", "bodyText": "please make it not constant", "author": "xnull", "createdAt": "2020-06-09T01:44:53Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/ManagementAgent.java", "diffHunk": "@@ -44,6 +44,21 @@\n      */\n     private static final Duration RECOVERY_RETRY_INTERVAL = Duration.ofSeconds(1);\n \n+    /**\n+     * Locally collected server metrics polling interval.\n+     */\n+    private static final Duration METRICS_POLL_INTERVAL = Duration.ofSeconds(3);", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0NzczMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440547732", "bodyText": "This is your code, I didn't change, just moved up several lines.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:18:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTMzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTgxMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437091810", "bodyText": "please don't use the double negative, it confuses a lot", "author": "xnull", "createdAt": "2020-06-09T01:46:52Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/ManagementAgent.java", "diffHunk": "@@ -187,10 +200,15 @@ private void initializationTask() {\n             }\n         }\n \n-        // Start monitoring services that deals with failure and healing detection.\n+        // Start management services that deals with failure & healing detection and auto commit.\n         if (!shutdown) {\n             localMonitoringService.start(METRICS_POLL_INTERVAL);\n             remoteMonitoringService.start(POLICY_EXECUTE_INTERVAL);\n+            if (!serverContext.getServerConfig(Boolean.class, \"--no-auto-commit\")) {", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0ODA1MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440548051", "bodyText": "Because by default auto commit is on, then if user specifies this flag, it's disabled. So have to use double negative here.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:19:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MTgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MjY3NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437092675", "bodyText": "please don't throw an exception, just return an enum if you really need to know about trimm", "author": "xnull", "createdAt": "2020-06-09T01:50:15Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/StreamLog.java", "diffHunk": "@@ -41,6 +42,15 @@\n      */\n     LogData read(long address);\n \n+    /**\n+     * Inspect if the stream log contains the entry at given address.\n+     *\n+     * @param address the address to inspect\n+     * @return true if stream log contains the entry at the address, false otherwise\n+     * @throws TrimmedException if address less than starting address\n+     */\n+    boolean contains(long address) throws TrimmedException;", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5Mzc5Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437093793", "bodyText": "contains must not throw any exceptions, else it's is fragile and weird logic", "author": "xnull", "createdAt": "2020-06-09T01:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MjY3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0OTA3NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440549074", "bodyText": "If you look at methods, like read/write, they throw exceptions like DataCorruptionException, OverwriteException, and catch them. They just don't mention it in the interface. It's actully the same. Here TrimmedException is important for upper layer to catch, so adding it here as a heads up.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:23:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5MjY3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5NDg5OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437094898", "bodyText": "please bring builder back", "author": "xnull", "createdAt": "2020-06-09T01:59:15Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/StreamLogFiles.java", "diffHunk": "@@ -118,7 +119,7 @@ public StreamLogFiles(ServerContext serverContext, boolean noVerify) {\n         writeChannels = new ConcurrentHashMap<>();\n         channelsToSync = new HashSet<>();\n         this.verify = !noVerify;\n-        this.dataStore = StreamLogDataStore.builder().dataStore(serverContext.getDataStore()).build();\n+        this.dataStore = new StreamLogDataStore(serverContext.getDataStore());", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0OTI0Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440549243", "bodyText": "The constructor has only one parameter, having a builder is an overkill.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5NDg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5NjI3Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437096276", "bodyText": "please transform this variable into a filed (in the future probably we would like to make this parameter configurable via the app config)", "author": "xnull", "createdAt": "2020-06-09T02:04:03Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/orchestrator/actions/RestoreRedundancyMergeSegments.java", "diffHunk": "@@ -195,6 +206,30 @@ Layout restoreWithBackOff(CorfuRuntime runtime, StateTransferManager transferMan\n                 .collect(Collectors.toList());\n     }\n \n+    /**\n+     * Send the last transferred address as the committed tail to the target log unit.\n+     * This is required to prevent loss of committed tail after state transfer finishes\n+     * and then all other log units failed and auto commit service is paused.\n+     */\n+    private void transferCommittedTail(CorfuRuntime runtime, Layout layout, long committedTail) {\n+        final int maxRetry = 3;", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0OTM0OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440549348", "bodyText": "This is quite internal and not worth exposing to user.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:24:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5NjI3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5Njg4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437096880", "bodyText": "don't use @DaTa, use @getter, @Setter instead", "author": "xnull", "createdAt": "2020-06-09T02:06:19Z", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/InspectAddressesResponse.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import io.netty.buffer.ByteBuf;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;\n+import lombok.Getter;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+/**\n+ * A response message containing a list of uncommitted addresses.\n+ *\n+ * Created by WenbinZhu on 5/4/20.\n+ */\n+@Data", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0OTM5Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440549396", "bodyText": "Done.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:25:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5Njg4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5ODUyNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r437098527", "bodyText": "get rid of todo", "author": "xnull", "createdAt": "2020-06-09T02:12:37Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/replication/QuorumReplicationProtocol.java", "diffHunk": "@@ -117,6 +117,15 @@ public ILogData peek(RuntimeLayout runtimeLayout, long address) {\n                 .collect(Collectors.toMap(SimpleImmutableEntry::getKey, SimpleImmutableEntry::getValue));\n     }\n \n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void commitAll(RuntimeLayout runtimeLayout, Collection<Long> addresses) {\n+        // TODO: parallelize this operation as in chain replication.", "originalCommit": "d3f35cf9b4be3953af2e1cec6d2cd4dd7c50e974", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0OTYxOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r440549618", "bodyText": "This class is not being used, so not implementing for now, just made it compile.", "author": "WenbinZhu", "createdAt": "2020-06-16T02:25:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA5ODUyNw=="}], "type": "inlineReview"}, {"oid": "67c832e81a031f442b03d438eb6d087171ef4660", "url": "https://github.com/CorfuDB/CorfuDB/commit/67c832e81a031f442b03d438eb6d087171ef4660", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-16T02:01:35Z", "type": "forcePushed"}, {"oid": "cc8b16ae4ef768ba75de322778ffad95d88be7ed", "url": "https://github.com/CorfuDB/CorfuDB/commit/cc8b16ae4ef768ba75de322778ffad95d88be7ed", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-16T02:12:10Z", "type": "forcePushed"}, {"oid": "ae75a48b14d202f22661db78eeff7adae77d1295", "url": "https://github.com/CorfuDB/CorfuDB/commit/ae75a48b14d202f22661db78eeff7adae77d1295", "message": "Introduce Parallel Transfer (#2566)\n\n* Introduce Parallel Transfer\r\n\r\n* Fixes", "committedDate": "2020-06-26T04:00:20Z", "type": "forcePushed"}, {"oid": "04a8ab4e57653272a62c986a86a31f851c36ef71", "url": "https://github.com/CorfuDB/CorfuDB/commit/04a8ab4e57653272a62c986a86a31f851c36ef71", "message": "Introduce Parallel Transfer (#2566)\n\nIntroduce Parallel Transfer.", "committedDate": "2020-06-26T04:07:25Z", "type": "forcePushed"}, {"oid": "e1a7add94fe7f832b236e9cda8ea99ad5062094f", "url": "https://github.com/CorfuDB/CorfuDB/commit/e1a7add94fe7f832b236e9cda8ea99ad5062094f", "message": "Introducing auto commit mechanism for faster read and state transfer.", "committedDate": "2020-06-26T06:55:54Z", "type": "commit"}, {"oid": "16463324039f54f9a4340e2e61935a326874217f", "url": "https://github.com/CorfuDB/CorfuDB/commit/16463324039f54f9a4340e2e61935a326874217f", "message": "Introduce Parallel Transfer (#2566)\n\nIntroduce Parallel Transfer.", "committedDate": "2020-06-26T06:55:54Z", "type": "commit"}, {"oid": "16463324039f54f9a4340e2e61935a326874217f", "url": "https://github.com/CorfuDB/CorfuDB/commit/16463324039f54f9a4340e2e61935a326874217f", "message": "Introduce Parallel Transfer (#2566)\n\nIntroduce Parallel Transfer.", "committedDate": "2020-06-26T06:55:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE0NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004144", "bodyText": "Codacy found an issue: Avoid throwing raw exception types.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:33Z", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/log/statetransfer/StateTransferManagerTest.java", "diffHunk": "@@ -1,175 +1,549 @@\n package org.corfudb.infrastructure.log.statetransfer;\n \n import com.google.common.collect.ImmutableList;\n-import com.google.common.collect.Lists;\n-import org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegment;\n-import org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegmentStatus;\n+import org.corfudb.common.util.Tuple;\n import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchRequest;\n-import org.corfudb.infrastructure.log.statetransfer.batchprocessor.StateTransferBatchProcessor;\n+import org.corfudb.infrastructure.log.statetransfer.segment.StateTransferType;\n+import org.corfudb.infrastructure.log.statetransfer.segment.TransferSegment;\n+import org.corfudb.infrastructure.log.statetransfer.segment.TransferSegmentRange;\n+import org.corfudb.infrastructure.log.statetransfer.segment.TransferSegmentRangeSingle;\n+import org.corfudb.infrastructure.log.statetransfer.segment.TransferSegmentRangeSplit;\n+import org.corfudb.infrastructure.log.statetransfer.segment.TransferSegmentStatus;\n+import org.corfudb.infrastructure.log.statetransfer.transferprocessor.BasicTransferProcessor;\n+import org.corfudb.infrastructure.log.statetransfer.transferprocessor.ParallelTransferProcessor;\n import org.corfudb.protocols.wireprotocol.KnownAddressResponse;\n import org.corfudb.runtime.clients.LogUnitClient;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.util.NodeLocator;\n import org.junit.jupiter.api.Test;\n \n-import java.util.AbstractMap.SimpleEntry;\n-import java.util.List;\n+import java.util.Optional;\n import java.util.Set;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.LongStream;\n import java.util.stream.Stream;\n \n import static org.assertj.core.api.Assertions.assertThat;\n-import static org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegmentStatus.SegmentState.FAILED;\n-import static org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegmentStatus.SegmentState.NOT_TRANSFERRED;\n-import static org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegmentStatus.SegmentState.RESTORED;\n-import static org.corfudb.infrastructure.log.statetransfer.StateTransferManager.TransferSegmentStatus.SegmentState.TRANSFERRED;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.corfudb.infrastructure.log.statetransfer.segment.StateTransferType.CONSISTENT_READ;\n+import static org.corfudb.infrastructure.log.statetransfer.segment.TransferSegmentStatus.SegmentState.RESTORED;\n+import static org.mockito.Mockito.doAnswer;\n import static org.mockito.Mockito.doReturn;\n import static org.mockito.Mockito.mock;\n import static org.mockito.Mockito.spy;\n \n class StateTransferManagerTest implements TransferSegmentCreator {\n \n+    private StateTransferManager getDefaultInstance() {\n+        return getConfiguredInstance(mock(LogUnitClient.class),\n+                mock(BasicTransferProcessor.class), mock(ParallelTransferProcessor.class));\n+    }\n+\n+    private StateTransferManager getConfiguredInstance(LogUnitClient client,\n+                                                       BasicTransferProcessor processor1,\n+                                                       ParallelTransferProcessor processor2) {\n+        return StateTransferManager.builder()\n+                .batchSize(10)\n+                .logUnitClient(client)\n+                .basicTransferProcessor(processor1)\n+                .parallelTransferProcessor(processor2)\n+                .build();\n+    }\n+\n+    private TransferSegmentRange getSingleRange(long start,\n+                                                long end,\n+                                                StateTransferType type,\n+                                                boolean split,\n+                                                Optional<ImmutableList<String>> availableServers,\n+                                                TransferSegmentStatus status) {\n+        return TransferSegmentRangeSingle.builder()\n+                .startAddress(start)\n+                .endAddress(end)\n+                .unknownAddressesInRange(ImmutableList.of())\n+                .typeOfTransfer(type)\n+                .split(split)\n+                .availableServers(availableServers)\n+                .status(status)\n+                .build();\n+    }\n+\n+    private TransferSegmentRange getSplitRange(TransferSegmentRangeSingle first, TransferSegmentRangeSingle second) {\n+        return TransferSegmentRangeSplit.builder().splitSegments(new Tuple<>(first, second)).build();\n+    }\n+\n+    private TransferSegment getTransferSegment(long start,\n+                                               long end,\n+                                               TransferSegmentStatus status,\n+                                               ImmutableList<String> servers) {\n+        return TransferSegment.builder().startAddress(start).endAddress(end).status(status)\n+                .logUnitServers(servers)\n+                .build();\n+    }\n+\n     @Test\n-    public void getUnknownAddressesInRange() {\n-        LogUnitClient logUnitClient = mock(LogUnitClient.class);\n-        Set<Long> retVal = LongStream.range(0L, 80L).boxed().collect(Collectors.toSet());\n+    void testSingleNotTransferredRangeToSingleNotTransferredRange() {\n+        StateTransferManager manager = getDefaultInstance();\n+        ImmutableList<TransferSegmentRange> ranges = ImmutableList.of(\n+                getSingleRange(0L, 1000L,\n+                        CONSISTENT_READ,\n+                        false,\n+                        Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                        TransferSegmentStatus.builder().build())\n+        );\n+        ImmutableList<TransferSegmentRangeSingle> transferSegmentRangeSingles =\n+                manager.toSingleNotTransferredRanges(ranges);\n+\n \n-        doReturn(CompletableFuture.completedFuture(new KnownAddressResponse(retVal)))\n-                .when(logUnitClient)\n-                .requestKnownAddresses(0L, 100L);\n+        assertThat(ranges).isEqualTo(transferSegmentRangeSingles);\n \n-        StateTransferManager stateTransferManager =\n-                StateTransferManager.builder()\n-                        .logUnitClient(logUnitClient)\n-                        .batchSize(10)\n-                        .batchProcessor(new SuccessfulBatchProcessor())\n-                        .build();\n+    }\n \n-        ImmutableList<Long> unknownAddressesInRange = stateTransferManager\n-                .getUnknownAddressesInRange(0L, 100L);\n+    @Test\n+    void testSingleTransferredRangeToSingleNotTransferredRange() {\n+        StateTransferManager manager = getDefaultInstance();\n+        ImmutableList<TransferSegmentRange> ranges = ImmutableList.of(\n+                getSingleRange(0L, 1000L,\n+                        CONSISTENT_READ,\n+                        false,\n+                        Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                        TransferSegmentStatus.builder().segmentState(RESTORED).build())\n+        );\n \n-        ImmutableList<Long> expected =\n-                ImmutableList.copyOf(LongStream.range(80L, 101L)\n-                        .boxed().collect(Collectors.toList()));\n+        ImmutableList<TransferSegmentRangeSingle> transferSegmentRangeSingles =\n+                manager.toSingleNotTransferredRanges(ranges);\n \n-        assertThat(unknownAddressesInRange).isEqualTo(expected);\n+        assertThat(transferSegmentRangeSingles).isEqualTo(ImmutableList.of());\n \n     }\n \n+    @Test\n+    void testSplitNotTransferredRangeToSingleNotTransferredRange() {\n+        StateTransferManager manager = getDefaultInstance();\n+        TransferSegmentRange firstRange = getSingleRange(0L, 1000L,\n+                CONSISTENT_READ,\n+                true,\n+                Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange secondRange = getSingleRange(1001L, 2000L,\n+                StateTransferType.PROTOCOL_READ,\n+                true,\n+                Optional.empty(),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange splitRange =\n+                getSplitRange((TransferSegmentRangeSingle) firstRange, (TransferSegmentRangeSingle) secondRange);\n+\n+\n+        ImmutableList<TransferSegmentRangeSingle> transferSegmentRangeSingles =\n+                manager.toSingleNotTransferredRanges(ImmutableList.of(splitRange));\n+\n+        assertThat(transferSegmentRangeSingles.size()).isEqualTo(2);\n+        assertThat(transferSegmentRangeSingles.get(0)).isEqualTo(firstRange);\n+        assertThat(transferSegmentRangeSingles.get(1)).isEqualTo(secondRange);\n+    }\n \n     @Test\n-    public void handleTransfer() {\n-        // Any status besides NOT_TRANSFERRED should not be updated\n-        LogUnitClient logUnitClient = mock(LogUnitClient.class);\n-        StateTransferManager manager = StateTransferManager.builder()\n-                .logUnitClient(logUnitClient)\n-                .batchSize(10)\n-                .batchProcessor(new SuccessfulBatchProcessor())\n-                .build();\n-        ImmutableList<TransferSegment> segments =\n-                ImmutableList.of(\n-                        createTransferSegment(0L, 50L, TRANSFERRED),\n-                        createTransferSegment(51L, 99L, FAILED),\n-                        createTransferSegment(100L, 199L, RESTORED)\n-                );\n-\n-        List<TransferSegmentStatus> statusesExpected =\n-                segments.stream().map(segment -> segment.getStatus()).collect(Collectors.toList());\n-\n-        List<Long> totalTransferredExpected = segments.stream()\n-                .map(segment -> segment.getStatus().getTotalTransferred())\n-                .collect(Collectors.toList());\n-\n-        List<SimpleEntry<Long, Long>> rangesExpected =\n-                segments.stream().map(segment -> new SimpleEntry<>(segment.getStartAddress(),\n-                        segment.getEndAddress())).collect(Collectors.toList());\n-\n-        ImmutableList<TransferSegment> transferSegments =\n-                manager.handleTransfer(segments);\n-\n-        List<TransferSegmentStatus> statuses =\n-                transferSegments.stream()\n-                        .map(TransferSegment::getStatus)\n-                        .collect(Collectors.toList());\n-\n-        List<Long> totalTransferred =\n-                transferSegments.stream()\n-                        .map(segment -> segment.getStatus()\n-                                .getTotalTransferred()).collect(Collectors.toList());\n-\n-        List<SimpleEntry<Long, Long>> ranges =\n-                transferSegments.stream().map(segment -> new SimpleEntry<>(segment.getStartAddress(),\n-                        segment.getEndAddress())).collect(Collectors.toList());\n-\n-        assertThat(statuses).isEqualTo(statusesExpected);\n-        assertThat(totalTransferred).isEqualTo(totalTransferredExpected);\n-        assertThat(ranges).isEqualTo(rangesExpected);\n-        StateTransferManager spy = spy(manager);\n-\n-        // Segment is from 0L to 50L, all data present, segment is transferred\n-        TransferSegment transferSegment =\n-                createTransferSegment(0L, 50L, NOT_TRANSFERRED);\n-\n-        doReturn(ImmutableList.of()).when(spy).getUnknownAddressesInRange(0L, 50L);\n-        transferSegments =\n-                spy.handleTransfer(ImmutableList.of(transferSegment));\n-\n-        assertThat(transferSegments.get(0).getStatus().getSegmentState())\n-                .isEqualTo(TRANSFERRED);\n-        assertThat(transferSegments.get(0).getStatus().getTotalTransferred())\n-                .isEqualTo(51L);\n-        // Some data is not present\n-        ImmutableList<Long> unknownData =\n-                ImmutableList.copyOf(LongStream.range(25L, 51L).boxed().collect(Collectors.toList()));\n-\n-        manager = StateTransferManager.builder()\n-                .logUnitClient(logUnitClient)\n-                .batchSize(10)\n-                .batchProcessor(new FaultyBatchProcessor(10))\n+    void testSplitTransferredRangeToSingleNotTransferredRange() {\n+        StateTransferManager manager = getDefaultInstance();\n+        TransferSegmentRange firstRange = getSingleRange(0L, 1000L,\n+                CONSISTENT_READ,\n+                true,\n+                Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                TransferSegmentStatus.builder().segmentState(RESTORED).build());\n+\n+        TransferSegmentRange secondRange = getSingleRange(1001L, 2000L,\n+                StateTransferType.PROTOCOL_READ,\n+                true,\n+                Optional.empty(),\n+                TransferSegmentStatus.builder().segmentState(RESTORED).build());\n+\n+        TransferSegmentRange splitRange =\n+                getSplitRange((TransferSegmentRangeSingle) firstRange, (TransferSegmentRangeSingle) secondRange);\n+\n+\n+        ImmutableList<TransferSegmentRangeSingle> transferSegmentRangeSingles =\n+                manager.toSingleNotTransferredRanges(ImmutableList.of(splitRange));\n+\n+        assertThat(transferSegmentRangeSingles).isEmpty();\n+    }\n+\n+    @Test\n+    void testMixRangeToSingleNotTransferredRange() {\n+        // First range is a single restored\n+        // Second range is a single not transferred\n+        // Third range is a split not transferred\n+        StateTransferManager manager = getDefaultInstance();\n+\n+        TransferSegmentRange firstRange = getSingleRange(0L, 1000L,\n+                CONSISTENT_READ,\n+                false,\n+                Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                TransferSegmentStatus.builder().segmentState(RESTORED).build());\n+\n+        TransferSegmentRange secondRange = getSingleRange(1001L, 2000L,\n+                CONSISTENT_READ,\n+                false,\n+                Optional.of(ImmutableList.of(\"test3\")),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange thirdRange1 = getSingleRange(2001L, 3000L,\n+                CONSISTENT_READ,\n+                true,\n+                Optional.of(ImmutableList.of(\"test1\")),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange thirdRange2 = getSingleRange(3001L, 4000L,\n+                StateTransferType.PROTOCOL_READ,\n+                true,\n+                Optional.empty(),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange thirdRange =\n+                getSplitRange((TransferSegmentRangeSingle) thirdRange1,\n+                        (TransferSegmentRangeSingle) thirdRange2);\n+\n+        ImmutableList<TransferSegmentRange> ranges =\n+                ImmutableList.of(firstRange, secondRange, thirdRange);\n+\n+        ImmutableList<TransferSegmentRangeSingle> transferSegmentRangeSingles =\n+                manager.toSingleNotTransferredRanges(ranges);\n+\n+        assertThat(transferSegmentRangeSingles.size()).isEqualTo(3);\n+\n+        assertThat(transferSegmentRangeSingles)\n+                .isEqualTo(ImmutableList.of(secondRange, thirdRange1, thirdRange2));\n+    }\n+\n+    @Test\n+    void testToSegmentsSingle() {\n+        StateTransferManager manager = getDefaultInstance();\n+        TransferSegmentRange range = getSingleRange(0L, 1000L,\n+                CONSISTENT_READ,\n+                false,\n+                Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                TransferSegmentStatus.builder().build());\n+\n+        ImmutableList<TransferSegmentRange> ranges = ImmutableList.of(range);\n+\n+        ImmutableList<TransferSegment> transferSegments = manager.toSegments(ranges);\n+\n+        ImmutableList<TransferSegment> expected =\n+                ImmutableList.of(getTransferSegment(0L, 1000L,\n+                        TransferSegmentStatus.builder().build(), ImmutableList.of(\"test1\", \"test2\")));\n+\n+        assertThat(transferSegments).isEqualTo(expected);\n+    }\n+\n+    @Test\n+    void testToSegmentsSplit() {\n+        StateTransferManager manager = getDefaultInstance();\n+        TransferSegmentRange range1 = getSingleRange(0L, 1000L,\n+                CONSISTENT_READ,\n+                true,\n+                Optional.of(ImmutableList.of(\"test1\", \"test2\")),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange range2 = getSingleRange(1001L, 2000L,\n+                StateTransferType.PROTOCOL_READ,\n+                true,\n+                Optional.empty(),\n+                TransferSegmentStatus.builder().build());\n+\n+        TransferSegmentRange splitRange = getSplitRange((TransferSegmentRangeSingle) range1,\n+                (TransferSegmentRangeSingle) range2);\n+\n+        ImmutableList<TransferSegmentRange> ranges = ImmutableList.of(splitRange);\n+\n+        ImmutableList<TransferSegment> transferSegments = manager.toSegments(ranges);\n+\n+        ImmutableList<TransferSegment> expected =\n+                ImmutableList.of(getTransferSegment(0L, 2000L,\n+                        TransferSegmentStatus.builder().build(), ImmutableList.of(\"test1\", \"test2\")));\n+\n+        assertThat(transferSegments).isEqualTo(expected);\n+    }\n+\n+    @Test\n+    void testGetUnknownAddressesInRangeTimeOutException() {\n+        LogUnitClient client = mock(LogUnitClient.class);\n+        BasicTransferProcessor mock1 = mock(BasicTransferProcessor.class);\n+        ParallelTransferProcessor mock2 = mock(ParallelTransferProcessor.class);\n+        long rangeStart = 0L;\n+        long rangeEnd = 1000L;\n+\n+        doAnswer(invoke -> {\n+            throw new RuntimeException(new TimeoutException());", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE1MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004150", "bodyText": "Codacy found an issue: Avoid really long methods.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:34Z", "path": "test/src/test/java/org/corfudb/runtime/view/StateTransferTest.java", "diffHunk": "@@ -949,4 +961,536 @@ public void testStateTransferWithNoneDefaultCodec() {\n         }\n \n     }\n+\n+    class AutoClosableTempDirs implements AutoCloseable {\n+\n+        @Getter\n+        private final List<File> tempDirs;\n+\n+        public AutoClosableTempDirs(int numDirs) {\n+            ArrayList<File> tempDirs = new ArrayList<>();\n+            for (int i = 0; i < numDirs; i++) {\n+                tempDirs.add(Files.createTempDir());\n+            }\n+            this.tempDirs = tempDirs;\n+        }\n+\n+        @Override\n+        public void close() {\n+            try {\n+                for (File file : tempDirs) {\n+                    FileUtils.deleteDirectory(file);\n+                }\n+            } catch (IOException io) {\n+                io.printStackTrace();\n+            }\n+        }\n+    }\n+\n+    private LogData getLogData(TokenResponse token, byte[] payload) {\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.useToken(token);\n+        return ld;\n+    }\n+\n+    private void write(CorfuRuntime runtime, int numIter,\n+                       Set<Long> noWriteHoles, Set<Long> partialWriteHoles) throws Exception {\n+        for (long i = 0; i < numIter; i++) {\n+            TokenResponse token = runtime.getSequencerView().next();\n+            if (noWriteHoles.contains(i)) {\n+                // Write nothing to create a hole on all log units.\n+            } else if (partialWriteHoles.contains(i)) {\n+                // Write to head log unit to create a partial write hole.\n+                runtime.getLayoutView().getRuntimeLayout().getLogUnitClient(SERVERS.ENDPOINT_0)\n+                        .write(getLogData(token, \"partial write\".getBytes())).get();\n+            } else {\n+                runtime.getAddressSpaceView().write(token, \"Test Payload\".getBytes());\n+            }\n+        }\n+    }\n+\n+    private LogData read(CorfuRuntime runtime, long address, String server) throws Exception {\n+        return runtime.getLayoutView().getRuntimeLayout().getLogUnitClient(server)\n+                .read(address).get().getAddresses().get(address);\n+    }\n+\n+\n+    /**\n+     * Add first node. Write 100 complete records with 5 of them being holes.\n+     * Commit the addresses filling these 5 holes. Verify that CT is 99.\n+     * Add second node. It should run a parallel transfer and store the CT locally.\n+     * Verify CT is present on the second node.\n+     * Write 100 more addresses.\n+     * Add third node. It should run a parallel transfer for the first 100 addresses\n+     * and a regular transfer for the next 100 addresses.\n+     * Verify CT is present on the third node and its equal to 199.\n+     * Check all records are equal on all the three nodes and the global CT is 199.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void testBuild3NodeClusterWithParallelTransferAfterAutoCommit() throws Exception {\n+        try (AutoClosableTempDirs dirs = new AutoClosableTempDirs(3)) {\n+            List<File> tempDirs = dirs.getTempDirs();\n+            ServerContext sc0 = new ServerContextBuilder()\n+                    .setSingle(true)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_0))\n+                    .setPort(SERVERS.PORT_0)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(0).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_0, sc0);\n+            Layout currentLayout = sc0.getCurrentLayout();\n+            bootstrapAllServers(currentLayout);\n+\n+            getManagementServer(SERVERS.PORT_0).shutdown();\n+\n+            CorfuRuntime runtime = getRuntime(currentLayout).connect();\n+\n+            Set<Long> noWriteHoles = new HashSet<>(Arrays.asList(10L, 20L, 30L, 40L, 50L));\n+\n+            write(runtime, 100, noWriteHoles, new HashSet<>());\n+\n+            runtime.getAddressSpaceView().commit(0L, 99L);\n+\n+            long committedTail = runtime.getAddressSpaceView().getCommittedTail();\n+\n+            assertThat(committedTail).isEqualTo(99L);\n+\n+            ServerContext sc1 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_1))\n+                    .setPort(SERVERS.PORT_1)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(1).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_1, sc1);\n+\n+            final int addNodeRetries = 3;\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_1, addNodeRetries,\n+                            Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+            long tail = runtime.getLayoutView().getRuntimeLayout()\n+                    .getLogUnitClient(SERVERS.ENDPOINT_1).getCommittedTail().join();\n+\n+            assertThat(tail).isEqualTo(99);\n+\n+            write(runtime, 100, new HashSet<>(), new HashSet<>());\n+\n+            ServerContext sc2 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_2))\n+                    .setPort(SERVERS.PORT_2)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(2).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_2, sc2);\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_2, addNodeRetries, Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+\n+            long tail3 = runtime.getLayoutView().getRuntimeLayout()\n+                    .getLogUnitClient(SERVERS.ENDPOINT_2).getCommittedTail().join();\n+\n+            assertThat(tail3).isEqualTo(199L);\n+\n+            for (int i = 0; i < 200; i++) {\n+                LogData read1 = read(runtime, i, SERVERS.ENDPOINT_0);\n+                LogData read2 = read(runtime, i, SERVERS.ENDPOINT_1);\n+                LogData read3 = read(runtime, i, SERVERS.ENDPOINT_2);\n+\n+                assertThat(read1.getType()).isEqualTo(read2.getType());\n+                assertThat(read2.getType()).isEqualTo(read3.getType());\n+                assertThat(Arrays.equals(read1.getData(), read2.getData())).isTrue();\n+                assertThat(Arrays.equals(read2.getData(), read3.getData())).isTrue();\n+            }\n+\n+            assertThat(runtime.getAddressSpaceView().getCommittedTail()).isEqualTo(199L);\n+        }\n+    }\n+\n+    /**\n+     * Create a layout with a split segment. A: [0, 100]. A, B: [100, 200].\n+     * Commit first 150 addresses.\n+     * Add node C, this will split the layout segment like this:\n+     * A: [0, 100]. A, B: [100, 200], A, B, C: [200, -1]\n+     * Wait until the restore redundancy workflow kicks in on node B and node C is added.\n+     * Verify the segment is merged.\n+     * Verify CT is equal to 199.\n+     * Verify every record is the same on every node.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void testRestoreRedundancyParallelTransfer() throws Exception {\n+        try (AutoClosableTempDirs dirs = new AutoClosableTempDirs(3)) {\n+            List<File> tempDirs = dirs.getTempDirs();\n+\n+            ServerContext sc0 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_0))\n+                    .setPort(SERVERS.PORT_0)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(0).getAbsolutePath())\n+                    .build();\n+\n+            ServerContext sc1 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_1))\n+                    .setPort(SERVERS.PORT_1)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(1).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_0, sc0);\n+            addServer(SERVERS.PORT_1, sc1);\n+\n+            long writtenAddressesBatch1 = 100L;\n+\n+            Layout l1 = new TestLayoutBuilder()\n+                    .setEpoch(1L)\n+                    .addLayoutServer(SERVERS.PORT_0)\n+                    .addSequencer(SERVERS.PORT_0)\n+                    .buildSegment()\n+                    .setStart(0L)\n+                    .setEnd(writtenAddressesBatch1)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .buildSegment()\n+                    .setStart(writtenAddressesBatch1)\n+                    .setEnd(-1L)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addLogUnit(SERVERS.PORT_1)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .build();\n+            bootstrapAllServers(l1);\n+\n+            CorfuRuntime runtime = getRuntime(l1).connect();\n+\n+            ServerContext sc2 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_2))\n+                    .setPort(SERVERS.PORT_2)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(2).getAbsolutePath())\n+                    .build();\n+\n+            Set<Long> noWriteHoles = new HashSet<>(Arrays.asList(10L, 20L, 30L, 40L, 50L));\n+\n+            Set<Long> partialWriteHoles = new HashSet<>(Arrays.asList(11L, 21L, 32L, 43L, 55L, 155L));\n+\n+            write(runtime, 200, noWriteHoles, partialWriteHoles);\n+\n+            runtime.getAddressSpaceView().commit(0L, 149L);\n+\n+            addServer(SERVERS.PORT_2, sc2);\n+\n+            final int addNodeRetries = 3;\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_2, addNodeRetries, Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+            setAggressiveTimeouts(runtime.getLayoutView().getLayout(), runtime);\n+\n+            waitForLayoutChange(layout -> layout.getUnresponsiveServers().isEmpty() &&\n+                            layout.segments.size() == 1,\n+                    runtime);\n+\n+            long committedTail = runtime.getAddressSpaceView().getCommittedTail();\n+\n+            assertThat(committedTail).isEqualTo(199L);\n+\n+            for (int i = 0; i < 200; i++) {\n+                LogData read1 = read(runtime, i, SERVERS.ENDPOINT_0);\n+                LogData read2 = read(runtime, i, SERVERS.ENDPOINT_1);\n+                LogData read3 = read(runtime, i, SERVERS.ENDPOINT_2);\n+\n+                assertThat(read1.getType()).isEqualTo(read2.getType());\n+                assertThat(read2.getType()).isEqualTo(read3.getType());\n+                assertThat(Arrays.equals(read1.getData(), read2.getData())).isTrue();\n+                assertThat(Arrays.equals(read2.getData(), read3.getData())).isTrue();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Layout is: A: [0, 1500]. A, B: [1500, 3000]. A, B: [3000, -1]. Unresponsive: [C]\n+     * 0 - 3000: log with holes and partial writes\n+     * Run autocommit.\n+     * Allow C to heal, and B to restore redundancy.\n+     * Verify the latest committed tail.\n+     * Verify records on all the three nodes are the same.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void healAndRestoreParallelTransfer() throws Exception {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE2MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004160", "bodyText": "Codacy found an issue: Avoid reassigning parameters such as 'allFutures'", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:35Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/transferprocessor/ParallelTransferProcessor.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package org.corfudb.infrastructure.log.statetransfer.transferprocessor;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchRequest;\n+import org.corfudb.infrastructure.log.statetransfer.batchprocessor.StateTransferBatchProcessor;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.StateTransferBatchProcessorException;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.TransferSegmentException;\n+import org.corfudb.util.CFUtils;\n+\n+import java.util.Iterator;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Semaphore;\n+import java.util.stream.Stream;\n+\n+import static org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchResponse.TransferStatus.FAILED;\n+import static org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchResponse.TransferStatus.SUCCEEDED;\n+import static org.corfudb.infrastructure.log.statetransfer.transferprocessor.TransferProcessorResult.TransferProcessorStatus.TRANSFER_FAILED;\n+import static org.corfudb.infrastructure.log.statetransfer.transferprocessor.TransferProcessorResult.TransferProcessorStatus.TRANSFER_SUCCEEDED;\n+\n+/**\n+ * A transfer processor that performs state transfer by distributing and parallelizing\n+ * the workload among the source log unit servers of each segment.\n+ */\n+@Slf4j\n+public class ParallelTransferProcessor {\n+    /**\n+     * A state transfer batch processor that performs the batch transfer.\n+     */\n+    private final StateTransferBatchProcessor stateTransferBatchProcessor;\n+\n+    /**\n+     * A number of in-flight requests per one node.\n+     */\n+    private static final int NUM_REQUESTS_PER_NODE = 5;\n+\n+    public ParallelTransferProcessor(StateTransferBatchProcessor stateTransferBatchProcessor) {\n+        this.stateTransferBatchProcessor = stateTransferBatchProcessor;\n+    }\n+\n+    private CompletableFuture<Void> handleNonTransferException(CompletableFuture<Void> futures,\n+                                                               Throwable ex) {\n+        CompletableFuture<Void> failedFuture = new CompletableFuture<>();\n+        failedFuture.completeExceptionally(ex);\n+        return CFUtils.allOfOrTerminateExceptionally(futures, failedFuture);\n+    }\n+\n+    private CompletableFuture<Void> handleBatchRequest(TransferBatchRequest request,\n+                                                       CompletableFuture<Void> allFutures,", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE3MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004170", "bodyText": "Codacy found an issue: An instanceof check is being performed on the caught exception.  Create a separate catch clause for this exception type.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:36Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/AutoCommitService.java", "diffHunk": "@@ -0,0 +1,219 @@\n+package org.corfudb.infrastructure;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.util.LambdaUtils;\n+import org.corfudb.util.Sleep;\n+import org.corfudb.util.concurrent.SingletonResource;\n+\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+/**\n+ * An auto-commit service that periodically commits the unwritten addresses\n+ * in the global log, continuously consolidating the log prefix.\n+ * <p>\n+ * Created by WenbinZhu on 5/5/20.\n+ */\n+@Slf4j\n+public class AutoCommitService implements ManagementService {\n+\n+    public static final int COMMIT_BATCH_SIZE = 500;\n+    private static final int MAX_COMMIT_RETRY = 8;\n+    private static final Duration CONN_RETRY_RATE = Duration.ofMillis(500);\n+\n+    private final ServerContext serverContext;\n+    private final SingletonResource<CorfuRuntime> runtimeSingletonResource;\n+    private final ScheduledExecutorService autoCommitScheduler;\n+\n+    // Global log tail fetched at last auto commit cycle, which\n+    // would be the commit upper bound in the current cycle.\n+    private long lastLogTail = Address.NON_ADDRESS;\n+    // Cached committed tail so that we do not need to fetch every cycle.\n+    private long committedTail = Address.NON_ADDRESS;\n+\n+    AutoCommitService(@NonNull ServerContext serverContext,\n+                      @NonNull SingletonResource<CorfuRuntime> runtimeSingletonResource) {\n+        this.serverContext = serverContext;\n+        this.runtimeSingletonResource = runtimeSingletonResource;\n+        this.autoCommitScheduler = Executors.newSingleThreadScheduledExecutor(\n+                new ThreadFactoryBuilder()\n+                        .setDaemon(true)\n+                        .setNameFormat(serverContext.getThreadPrefix() + \"AutoCommitService\")\n+                        .build());\n+    }\n+\n+    CorfuRuntime getCorfuRuntime() {\n+        return runtimeSingletonResource.get();\n+    }\n+\n+    /**\n+     * Starts the long running service.\n+     *\n+     * @param interval interval to run the service\n+     */\n+    @Override\n+    public void start(Duration interval) {\n+        autoCommitScheduler.scheduleAtFixedRate(\n+                () -> LambdaUtils.runSansThrow(this::runAutoCommit),\n+                interval.toMillis() / 2,\n+                interval.toMillis(),\n+                TimeUnit.MILLISECONDS\n+        );\n+    }\n+\n+    @VisibleForTesting\n+    public synchronized void runAutoCommit() {\n+        boolean trimmed = false;\n+        long lastEpoch = -1;\n+        Layout currentLayout = null;\n+\n+        for (int i = 1; i <= MAX_COMMIT_RETRY; i++) {\n+            try {\n+                // Do not perform auto commit if current node is not primary sequencer.\n+                currentLayout = updateLayoutAndGet();\n+                if (!isNodePrimarySequencer(currentLayout)) {\n+                    log.trace(\"runAutoCommit: not primary sequencer, stop auto commit.\");\n+                    resetTails();\n+                    return;\n+                }\n+\n+                log.trace(\"runAutoCommit: start committing addresses.\");\n+\n+                // Initialize lastLogTail and committedTail if the first time. We only\n+                // commit up to the global tail at the time of last auto commit cycle.\n+                if (!Address.isAddress(lastLogTail)) {\n+                    log.info(\"runAutoCommit: initializing auto commit.\");\n+                    initializeTails(currentLayout);\n+                    log.info(\"runAutoCommit: initialized tails, committedTail: {}, \" +\n+                            \"lastLogTail: {}\", committedTail, lastLogTail);\n+                    return;\n+                }\n+\n+                // Fetch maximum trim mark from log units and compare with committed tail.\n+                // In order not to fetch trim mark for every retry, we only do this when\n+                // the epoch changes after last attempt.\n+                long currEpoch = currentLayout.getEpoch();\n+                if (lastEpoch < 0 || trimmed || currEpoch != lastEpoch) {\n+                    Token trimMark = getCorfuRuntime().getAddressSpaceView().getTrimMark(false);\n+                    // Make sure all log units have same trim mark, then we can start committing\n+                    // from the trim mark instead of the trailing committed tail.\n+                    if (committedTail < trimMark.getSequence() - 1) {\n+                        Token trimToken = new Token(trimMark.getEpoch(), trimMark.getSequence() - 1);\n+                        getCorfuRuntime().getAddressSpaceView().prefixTrim(trimToken, false);\n+                        committedTail = trimMark.getSequence() - 1;\n+                    }\n+                    lastEpoch = currEpoch;\n+                    trimmed = false;\n+                }\n+\n+                log.trace(\"runAutoCommit: trying to commit [{}, {}].\", committedTail + 1, lastLogTail);\n+\n+                // Commit addresses in batches, retry limit is shared by all batches in this cycle.\n+                // NOTE: This implementation relies on the fact that state transfer invokes the\n+                // read protocol and fill holes, otherwise the committedTail could be invalid.\n+                // (e.g. 1. State transferred a hole at address 100 from A to B; 2. Commit address\n+                // 100, which only goes to A as B is not in this address segment; 3. B finishes\n+                // state transfer and segments merged; 4. Send a new committedTail to B which is\n+                // invalid as 100 is still a hole on B.\n+                long oldCommittedTail = committedTail;\n+                while (committedTail < lastLogTail) {\n+                    long commitStart = committedTail + 1;\n+                    long commitEnd = Math.min(committedTail + COMMIT_BATCH_SIZE, lastLogTail);\n+                    getCorfuRuntime().getAddressSpaceView().commit(commitStart, commitEnd);\n+                    log.trace(\"runAutoCommit: successfully committed batch [{}, {}]\", committedTail, commitEnd);\n+                    committedTail = commitEnd;\n+                }\n+\n+                log.debug(\"runAutoCommit: successfully finished auto commit cycle, [{}, {}].\",\n+                        oldCommittedTail + 1, committedTail);\n+                break;\n+\n+            } catch (RuntimeException re) {\n+                log.trace(\"runAutoCommit: encountered an exception on attempt {}/{}.\",\n+                        i, MAX_COMMIT_RETRY, re);\n+\n+                if (i >= MAX_COMMIT_RETRY) {\n+                    log.error(\"runAutoCommit: retry exhausted, abort and wait for next cycle.\", re);\n+                    break;\n+                }\n+\n+                // When inspecting address, log unit server could throw a TrimmedException if\n+                // the address to inspect is trimmed, then we need to adjust committed tail.\n+                if (re instanceof TrimmedException) {\n+                    trimmed = true;\n+                }\n+\n+                if (re instanceof NetworkException || re.getCause() instanceof TimeoutException) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE3NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004174", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:37Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/StateTransferManager.java", "diffHunk": "@@ -81,228 +91,227 @@\n     }\n \n     /**\n-     * Performs the state transfer for the current transfer segments and also\n-     * updates their state as a result.\n+     * Return a range with the updated list of unknown addresses.\n      *\n-     * @param beforeTransferSegments A list of segments before a transfer.\n-     * @return A list of segments after a transfer.\n+     * @param range A transfer segment range.\n+     * @return An updated transfer segment range.\n      */\n-    public ImmutableList<TransferSegment> handleTransfer(List<TransferSegment> beforeTransferSegments) {\n-\n-        List<TransferSegment> afterTransferSegments = new ArrayList<>();\n-\n-        for (TransferSegment segment : beforeTransferSegments) {\n-            TransferSegmentStatus newStatus = segment.getStatus();\n-\n-            // If a segment is not NOT_TRANSFERRED -> return it as is.\n-            if (newStatus.getSegmentState() != NOT_TRANSFERRED) {\n-                afterTransferSegments.add(segment);\n-                continue;\n-            }\n-\n-            // Get all the unknown addresses for this segment.\n-            List<Long> unknownAddressesInRange =\n-                    getUnknownAddressesInRange(segment.getStartAddress(),\n-                            segment.getEndAddress());\n-\n-            // If no addresses to transfer - mark a segment as transferred.\n-            if (unknownAddressesInRange.isEmpty()) {\n-                log.debug(\"All addresses are present in the range: [{}, {}], skipping transfer.\",\n-                        segment.getStartAddress(), segment.getEndAddress());\n-                long totalTransferred = segment.getTotal();\n+    TransferSegmentRangeSingle getUnknownAddressesInRangeForRange(TransferSegmentRangeSingle range) {\n+        long startAddress = range.getStartAddress();\n+        long endAddress = range.getEndAddress();\n+        ImmutableList<Long> unknownAddressesInRange =\n+                getUnknownAddressesInRange(startAddress, endAddress);\n+        return range.toBuilder()\n+                .unknownAddressesInRange(unknownAddressesInRange)\n+                .build();\n+    }\n \n-                newStatus = TransferSegmentStatus\n+    /**\n+     * Transform the given range into a stream of batch requests.\n+     *\n+     * @param range A transfer segment range that contains unknown addresses and maybe available\n+     *              log unit servers.\n+     * @return A stream of transfer batch requests.\n+     */\n+    Stream<TransferBatchRequest> rangeToBatchRequestStream(TransferSegmentRangeSingle range) {\n+        ImmutableList<Long> unknownAddressesInRange = range.getUnknownAddressesInRange();\n+        Optional<ImmutableList<String>> availableServers = range.getAvailableServers();\n+        return Lists.partition(unknownAddressesInRange, batchSize).stream()\n+                .map(partition -> TransferBatchRequest\n                         .builder()\n-                        .segmentState(TRANSFERRED)\n-                        .totalTransferred(totalTransferred)\n-                        .build();\n-            } else {\n-                // Get total number of addresses needed to transfer.\n-                long numAddressesToTransfer = unknownAddressesInRange.size();\n-                // Create a transferBatchRequest stream.\n-                Stream<TransferBatchRequest> batchStream = Lists\n-                        .partition(unknownAddressesInRange, batchSize)\n-                        .stream()\n-                        .map(groupedAddresses ->\n-                                new TransferBatchRequest(groupedAddresses, Optional.empty())\n-                        );\n-                // Execute state transfer synchronously.\n-                newStatus = synchronousStateTransfer(batchStream, numAddressesToTransfer);\n-            }\n-\n-            TransferSegment currentSegment = TransferSegment\n-                    .builder()\n-                    .startAddress(segment.getStartAddress())\n-                    .endAddress(segment.getEndAddress())\n-                    .status(newStatus)\n-                    .build();\n-\n-            afterTransferSegments.add(currentSegment);\n+                        .addresses(partition)\n+                        .destinationNodes(availableServers)\n+                        .build());\n+    }\n \n-            if (currentSegment.getStatus().getSegmentState() == FAILED) {\n-                // A segment failed -> short circuit.\n-                break;\n-            }\n-        }\n-        return ImmutableList.copyOf(afterTransferSegments);\n+    /**\n+     * Create a batch workload for a single segment.\n+     *\n+     * @param range A single range\n+     * @return A stream of transfer batch requests from  range.\n+     */\n+    private Stream<TransferBatchRequest> createBatchWorkloadForSegment(\n+            TransferSegmentRangeSingle range) {\n+        TransferSegmentRangeSingle rangeWithUnknownAddresses =\n+                getUnknownAddressesInRangeForRange(range);\n+        return rangeToBatchRequestStream(rangeWithUnknownAddresses);\n     }\n \n     /**\n-     * Given a stream of batch requests, and a total number\n-     * of transferred addresses needed, execute a state transfer synchronously.\n+     * Go over all the single transfer segment ranges, filter them by the provided type,\n+     * get all the unknown addresses in range, and then turn the unknown addresses in range into\n+     * the transfer batch request stream - ready to be consumed by the appropriate\n+     * state transfer processor.\n      *\n-     * @param batchStream A stream of batch requests.\n-     * @param totalNeeded A total number of addresses needed for transfer.\n-     * @return A status representing a final status of a transferred segment.\n+     * @param ranges         A list of single transfer segment ranges.\n+     * @param typeOfTransfer A provided type of transfer - protocol read or consistent read.\n+     * @return A lists of streams of transfer batch requests.\n      */\n-    @VisibleForTesting\n-    TransferSegmentStatus synchronousStateTransfer(\n-            Stream<TransferBatchRequest> batchStream, long totalNeeded) {\n-        long accTransferred = 0L;\n+    List<Stream<TransferBatchRequest>> createBatchWorkload(List<TransferSegmentRangeSingle> ranges,\n+                                                           StateTransferType typeOfTransfer) {\n+        return ranges.stream()\n+                .filter(range -> range.getTypeOfTransfer() == typeOfTransfer)\n+                .map(this::createBatchWorkloadForSegment)\n+                .collect(ImmutableList.toImmutableList());\n+    }\n \n-        Iterator<TransferBatchRequest> iterator = batchStream.iterator();\n+    /**\n+     * Transform the transfer segment ranges into the single ones and filter all the non transferred\n+     * ones.\n+     *\n+     * @param beforeTransferRanges Ranges before the transfer, some single and some split.\n+     * @return Ranges before the transfer, not transferred and single.\n+     */\n+    ImmutableList<TransferSegmentRangeSingle> toSingleNotTransferredRanges(", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004180", "bodyText": "Codacy found an issue: Avoid empty if statements", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:38Z", "path": "test/src/test/java/org/corfudb/runtime/view/StateTransferTest.java", "diffHunk": "@@ -949,4 +961,536 @@ public void testStateTransferWithNoneDefaultCodec() {\n         }\n \n     }\n+\n+    class AutoClosableTempDirs implements AutoCloseable {\n+\n+        @Getter\n+        private final List<File> tempDirs;\n+\n+        public AutoClosableTempDirs(int numDirs) {\n+            ArrayList<File> tempDirs = new ArrayList<>();\n+            for (int i = 0; i < numDirs; i++) {\n+                tempDirs.add(Files.createTempDir());\n+            }\n+            this.tempDirs = tempDirs;\n+        }\n+\n+        @Override\n+        public void close() {\n+            try {\n+                for (File file : tempDirs) {\n+                    FileUtils.deleteDirectory(file);\n+                }\n+            } catch (IOException io) {\n+                io.printStackTrace();\n+            }\n+        }\n+    }\n+\n+    private LogData getLogData(TokenResponse token, byte[] payload) {\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.useToken(token);\n+        return ld;\n+    }\n+\n+    private void write(CorfuRuntime runtime, int numIter,\n+                       Set<Long> noWriteHoles, Set<Long> partialWriteHoles) throws Exception {\n+        for (long i = 0; i < numIter; i++) {\n+            TokenResponse token = runtime.getSequencerView().next();\n+            if (noWriteHoles.contains(i)) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE4Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004183", "bodyText": "Codacy found an issue: Avoid unused imports such as 'lombok.Data'", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:38Z", "path": "runtime/src/main/java/org/corfudb/protocols/wireprotocol/InspectAddressesResponse.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package org.corfudb.protocols.wireprotocol;\n+\n+import io.netty.buffer.ByteBuf;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE4OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004189", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:39Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/StateTransferManager.java", "diffHunk": "@@ -81,228 +91,227 @@\n     }\n \n     /**\n-     * Performs the state transfer for the current transfer segments and also\n-     * updates their state as a result.\n+     * Return a range with the updated list of unknown addresses.\n      *\n-     * @param beforeTransferSegments A list of segments before a transfer.\n-     * @return A list of segments after a transfer.\n+     * @param range A transfer segment range.\n+     * @return An updated transfer segment range.\n      */\n-    public ImmutableList<TransferSegment> handleTransfer(List<TransferSegment> beforeTransferSegments) {\n-\n-        List<TransferSegment> afterTransferSegments = new ArrayList<>();\n-\n-        for (TransferSegment segment : beforeTransferSegments) {\n-            TransferSegmentStatus newStatus = segment.getStatus();\n-\n-            // If a segment is not NOT_TRANSFERRED -> return it as is.\n-            if (newStatus.getSegmentState() != NOT_TRANSFERRED) {\n-                afterTransferSegments.add(segment);\n-                continue;\n-            }\n-\n-            // Get all the unknown addresses for this segment.\n-            List<Long> unknownAddressesInRange =\n-                    getUnknownAddressesInRange(segment.getStartAddress(),\n-                            segment.getEndAddress());\n-\n-            // If no addresses to transfer - mark a segment as transferred.\n-            if (unknownAddressesInRange.isEmpty()) {\n-                log.debug(\"All addresses are present in the range: [{}, {}], skipping transfer.\",\n-                        segment.getStartAddress(), segment.getEndAddress());\n-                long totalTransferred = segment.getTotal();\n+    TransferSegmentRangeSingle getUnknownAddressesInRangeForRange(TransferSegmentRangeSingle range) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDE5NA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004194", "bodyText": "Codacy found an issue: Avoid unused method parameters such as 'r'.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:40Z", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -199,12 +213,33 @@ private static Object handleTailResponse(CorfuPayloadMsg<TailsResponse> msg,\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a LOG_ADDRESS_SPACE_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n     @ClientHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE)\n     private static Object handleStreamsAddressResponse(CorfuPayloadMsg<TailsResponse> msg,\n                                              ChannelHandlerContext ctx, IClientRouter r) {\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a COMMITTED_TAIL_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n+    @ClientHandler(type = CorfuMsgType.COMMITTED_TAIL_RESPONSE)\n+    private static Object handleCommittedTailResponse(CorfuPayloadMsg<Long> msg,\n+                                                      ChannelHandlerContext ctx,\n+                                                      IClientRouter r) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIwMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004202", "bodyText": "Codacy found an issue: Avoid unused private methods such as 'handleCommittedTailResponse(CorfuPayloadMsg,ChannelHandlerContext,IClientRouter)'.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:41Z", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -199,12 +213,33 @@ private static Object handleTailResponse(CorfuPayloadMsg<TailsResponse> msg,\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a LOG_ADDRESS_SPACE_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n     @ClientHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE)\n     private static Object handleStreamsAddressResponse(CorfuPayloadMsg<TailsResponse> msg,\n                                              ChannelHandlerContext ctx, IClientRouter r) {\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a COMMITTED_TAIL_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n+    @ClientHandler(type = CorfuMsgType.COMMITTED_TAIL_RESPONSE)\n+    private static Object handleCommittedTailResponse(CorfuPayloadMsg<Long> msg,", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIxMA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004210", "bodyText": "Codacy found an issue: Avoid unused method parameters such as 'ctx'.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:42Z", "path": "runtime/src/main/java/org/corfudb/runtime/clients/LogUnitHandler.java", "diffHunk": "@@ -199,12 +213,33 @@ private static Object handleTailResponse(CorfuPayloadMsg<TailsResponse> msg,\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a LOG_ADDRESS_SPACE_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n     @ClientHandler(type = CorfuMsgType.LOG_ADDRESS_SPACE_RESPONSE)\n     private static Object handleStreamsAddressResponse(CorfuPayloadMsg<TailsResponse> msg,\n                                              ChannelHandlerContext ctx, IClientRouter r) {\n         return msg.getPayload();\n     }\n \n+    /**\n+     * Handle a COMMITTED_TAIL_RESPONSE message.\n+     *\n+     * @param msg Incoming Message\n+     * @param ctx Context\n+     * @param r   Router\n+     */\n+    @ClientHandler(type = CorfuMsgType.COMMITTED_TAIL_RESPONSE)\n+    private static Object handleCommittedTailResponse(CorfuPayloadMsg<Long> msg,\n+                                                      ChannelHandlerContext ctx,", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIxNQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004215", "bodyText": "Codacy found an issue: Avoid throwing raw exception types.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:43Z", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/log/statetransfer/batchprocessor/committedbatchprocessor/CommittedBatchProcessorTest.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.corfudb.infrastructure.log.statetransfer.batchprocessor.committedbatchprocessor;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.corfudb.infrastructure.log.statetransfer.DataTest;\n+import org.corfudb.infrastructure.log.statetransfer.batch.ReadBatch;\n+import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchRequest;\n+import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchRequestForNode;\n+import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchResponse;\n+import org.corfudb.infrastructure.log.statetransfer.batchprocessor.committedbatchprocessor.CommittedBatchProcessor.RandomNodeIterator;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.ReadBatchException;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.StateTransferBatchProcessorException;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.runtime.clients.LogUnitClient;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.RetryExhaustedException;\n+import org.corfudb.runtime.exceptions.WrongEpochException;\n+import org.corfudb.runtime.view.RuntimeLayout;\n+import org.corfudb.util.NodeLocator;\n+import org.junit.jupiter.api.Test;\n+import org.mockito.Matchers;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchResponse.TransferStatus.FAILED;\n+import static org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchResponse.TransferStatus.SUCCEEDED;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.doReturn;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.when;\n+\n+class CommittedBatchProcessorTest extends DataTest {\n+    @Test\n+    public void testNextNodeSelectorNodesEmpty() {\n+        TransferBatchRequest request = TransferBatchRequest.builder().build();\n+        RandomNodeIterator rand = new RandomNodeIterator(request);\n+        assertThat(rand.hasNext()).isFalse();\n+    }\n+\n+    @Test\n+    public void testNextNodeSelectorChooseFromOne() {\n+        TransferBatchRequest request = TransferBatchRequest.builder()\n+                .addresses(ImmutableList.of(1L, 2L, 3L))\n+                .destinationNodes(Optional.of(ImmutableList.of(\"test1\"))).build();\n+        RandomNodeIterator rand = new RandomNodeIterator(request);\n+\n+        assertThat(rand.hasNext()).isTrue();\n+        assertThat(rand.next()).isEqualTo(new TransferBatchRequestForNode(request.getAddresses(),\n+                \"test1\"));\n+        assertThat(rand.hasNext()).isFalse();\n+    }\n+\n+    @Test\n+    public void testNextNodeSelectorChooseFromTwo() {\n+        TransferBatchRequest request = TransferBatchRequest.builder()\n+                .addresses(ImmutableList.of(1L, 2L, 3L))\n+                .destinationNodes(Optional.of(ImmutableList.of(\"test1\", \"test2\")))\n+                .build();\n+\n+        TransferBatchRequestForNode expected1 = new TransferBatchRequestForNode(request.getAddresses(),\n+                \"test1\");\n+        TransferBatchRequestForNode expected2 = new TransferBatchRequestForNode(request.getAddresses(),\n+                \"test2\");\n+\n+        RandomNodeIterator rand = new RandomNodeIterator(request);\n+        assertThat(rand.hasNext()).isTrue();\n+        assertThat(rand.next()).isIn(expected1, expected2);\n+        assertThat(rand.hasNext()).isTrue();\n+        assertThat(rand.next()).isIn(expected1, expected2);\n+        assertThat(rand.hasNext()).isFalse();\n+    }\n+\n+    @Test\n+    public void testReadRecordsWrongEpochExceptionIsNotRetried() {\n+        LogUnitClient logUnitClient = mock(LogUnitClient.class);\n+        TransferBatchRequest batch = mock(TransferBatchRequest.class);\n+        RuntimeLayout runtimeLayout = mock(RuntimeLayout.class);\n+        List<Long> addresses = Arrays.asList(0L, 1L, 2L, 3L, 4L, 5L);\n+        when(batch.getAddresses()).thenReturn(addresses);\n+        AtomicInteger retries = new AtomicInteger(0);\n+        doAnswer(invoke -> {\n+            retries.incrementAndGet();\n+            throw new WrongEpochException(0L);\n+        }).when(logUnitClient).readAll(addresses);\n+        CommittedBatchProcessor testProcessor = CommittedBatchProcessor.builder()\n+                .currentNode(\"test\").runtimeLayout(runtimeLayout).build();\n+        assertThatThrownBy(() -> testProcessor.readRecords(batch.getAddresses(), Optional.empty(), logUnitClient))\n+                .isInstanceOf(WrongEpochException.class);\n+        assertThat(retries.get()).isEqualTo(1);\n+    }\n+\n+    @Test\n+    public void testTimeOutExceptionIsRetried() {\n+        LogUnitClient logUnitClient = mock(LogUnitClient.class);\n+        TransferBatchRequest batch = mock(TransferBatchRequest.class);\n+        RuntimeLayout runtimeLayout = mock(RuntimeLayout.class);\n+        List<Long> addresses = Arrays.asList(0L, 1L, 2L, 3L, 4L, 5L);\n+        when(batch.getAddresses()).thenReturn(addresses);\n+        AtomicInteger retries = new AtomicInteger(0);\n+        doAnswer(invocation -> {\n+            retries.incrementAndGet();\n+            throw new RuntimeException(new TimeoutException());", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIxNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004217", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:44Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/StateTransferManager.java", "diffHunk": "@@ -81,228 +91,227 @@\n     }\n \n     /**\n-     * Performs the state transfer for the current transfer segments and also\n-     * updates their state as a result.\n+     * Return a range with the updated list of unknown addresses.\n      *\n-     * @param beforeTransferSegments A list of segments before a transfer.\n-     * @return A list of segments after a transfer.\n+     * @param range A transfer segment range.\n+     * @return An updated transfer segment range.\n      */\n-    public ImmutableList<TransferSegment> handleTransfer(List<TransferSegment> beforeTransferSegments) {\n-\n-        List<TransferSegment> afterTransferSegments = new ArrayList<>();\n-\n-        for (TransferSegment segment : beforeTransferSegments) {\n-            TransferSegmentStatus newStatus = segment.getStatus();\n-\n-            // If a segment is not NOT_TRANSFERRED -> return it as is.\n-            if (newStatus.getSegmentState() != NOT_TRANSFERRED) {\n-                afterTransferSegments.add(segment);\n-                continue;\n-            }\n-\n-            // Get all the unknown addresses for this segment.\n-            List<Long> unknownAddressesInRange =\n-                    getUnknownAddressesInRange(segment.getStartAddress(),\n-                            segment.getEndAddress());\n-\n-            // If no addresses to transfer - mark a segment as transferred.\n-            if (unknownAddressesInRange.isEmpty()) {\n-                log.debug(\"All addresses are present in the range: [{}, {}], skipping transfer.\",\n-                        segment.getStartAddress(), segment.getEndAddress());\n-                long totalTransferred = segment.getTotal();\n+    TransferSegmentRangeSingle getUnknownAddressesInRangeForRange(TransferSegmentRangeSingle range) {\n+        long startAddress = range.getStartAddress();\n+        long endAddress = range.getEndAddress();\n+        ImmutableList<Long> unknownAddressesInRange =\n+                getUnknownAddressesInRange(startAddress, endAddress);\n+        return range.toBuilder()\n+                .unknownAddressesInRange(unknownAddressesInRange)\n+                .build();\n+    }\n \n-                newStatus = TransferSegmentStatus\n+    /**\n+     * Transform the given range into a stream of batch requests.\n+     *\n+     * @param range A transfer segment range that contains unknown addresses and maybe available\n+     *              log unit servers.\n+     * @return A stream of transfer batch requests.\n+     */\n+    Stream<TransferBatchRequest> rangeToBatchRequestStream(TransferSegmentRangeSingle range) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIxOQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004219", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:45Z", "path": "infrastructure/src/test/java/org/corfudb/infrastructure/log/statetransfer/transferprocessor/ParallelTransferProcessorTest.java", "diffHunk": "@@ -0,0 +1,147 @@\n+package org.corfudb.infrastructure.log.statetransfer.transferprocessor;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.corfudb.infrastructure.log.statetransfer.FaultyBatchProcessor;\n+import org.corfudb.infrastructure.log.statetransfer.SuccessfulBatchProcessor;\n+import org.corfudb.infrastructure.log.statetransfer.batch.TransferBatchRequest;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.StateTransferBatchProcessorException;\n+import org.corfudb.infrastructure.log.statetransfer.exceptions.TransferSegmentException;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.stream.IntStream;\n+import java.util.stream.Stream;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.corfudb.infrastructure.log.statetransfer.transferprocessor.TransferProcessorResult.TransferProcessorStatus.TRANSFER_FAILED;\n+import static org.corfudb.infrastructure.log.statetransfer.transferprocessor.TransferProcessorResult.TransferProcessorStatus.TRANSFER_SUCCEEDED;\n+\n+\n+class ParallelTransferProcessorTest {\n+\n+\n+    private final Stream<TransferBatchRequest> createStream(int numBatches,\n+                                                            Optional<ImmutableList<String>> nodes) {\n+        return IntStream.range(0, numBatches)\n+                .boxed()\n+                .map(x -> TransferBatchRequest\n+                        .builder().destinationNodes(nodes)\n+                        .build());\n+    }\n+\n+    @Test", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIyNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004226", "bodyText": "Codacy found an issue: Avoid unused imports such as 'org.corfudb.runtime.exceptions.UnreachableClusterException'", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:46Z", "path": "test/src/test/java/org/corfudb/integration/AbstractIT.java", "diffHunk": "@@ -10,8 +8,10 @@\n import org.apache.commons.io.FileUtils;\n import org.corfudb.AbstractCorfuTest;\n import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuRuntime.CorfuRuntimeParameters;\n import org.corfudb.runtime.collections.CorfuTable;\n import org.corfudb.runtime.collections.StreamingMap;\n+import org.corfudb.runtime.exceptions.UnreachableClusterException;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDIzNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004234", "bodyText": "Codacy found an issue: An instanceof check is being performed on the caught exception.  Create a separate catch clause for this exception type.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:47Z", "path": "runtime/src/main/java/org/corfudb/runtime/view/AddressSpaceView.java", "diffHunk": "@@ -555,30 +594,29 @@ public void prefixTrim(final Token address) {\n                 runtime.getSequencerView().trimCache(address.getSequence());\n \n                 layoutHelper(e -> {\n-                    e.getLayout().getPrefixSegments(address.getSequence()).stream()\n-                            .flatMap(seg -> seg.getStripes().stream())\n-                            .flatMap(stripe -> stripe.getLogServers().stream())\n-                            .map(e::getLogUnitClient)\n-                            .map(client -> client.prefixTrim(address))\n-                            .forEach(cf -> {\n-                                CFUtils.getUninterruptibly(cf,\n-                                        NetworkException.class, TimeoutException.class,\n-                                        WrongEpochException.class);\n-                            });\n+                    Utils.prefixTrim(e, address);\n                     return null;\n                 }, true);\n+\n                 break;\n-            } catch (NetworkException | TimeoutException e) {\n-                log.warn(\"prefixTrim: encountered a network error on try {}\", x, e);\n-                Duration retryRate = runtime.getParameters().getConnectionRetryRate();\n-                Sleep.sleepUninterruptibly(retryRate);\n-            } catch (WrongEpochException wee) {\n-                long serverEpoch = wee.getCorrectEpoch();\n-                long runtimeEpoch = runtime.getLayoutView().getLayout().getEpoch();\n-                log.warn(\"prefixTrim[{}]: wrongEpochException, runtime is in epoch {}, while server is in epoch {}. \"\n-                                + \"Invalidate layout for this client and retry, attempt: {}/{}\",\n-                        address, runtimeEpoch, serverEpoch, x + 1, numRetries);\n-                runtime.invalidateLayout();\n+            } catch (RuntimeException e) {\n+                // NetworkException is RuntimeException, CFUtils casts it into a RuntimeException.\n+                // TimeoutException is a checked exception, CFUtils wraps it in a RuntimeException.\n+                if (e instanceof NetworkException || e.getCause() instanceof TimeoutException) {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI0MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004240", "bodyText": "Codacy found an issue: Avoid throwing raw exception types.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:48Z", "path": "test/src/test/java/org/corfudb/integration/StateTransferIT.java", "diffHunk": "@@ -0,0 +1,334 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.collect.ContiguousSet;\n+import com.google.common.collect.DiscreteDomain;\n+import com.google.common.collect.Range;\n+import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.ReadResponse;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.BootstrapUtil;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Layout;\n+import org.corfudb.util.Sleep;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+public class StateTransferIT extends AbstractIT {\n+\n+    private static String corfuSingleNodeHost;\n+    private final int basePort = 9000;\n+    private final int retries = 10;\n+    private CorfuRuntime firstRuntime;\n+    private CorfuRuntime secondRuntime;\n+    private CorfuRuntime writerRuntime;\n+    private String getServerEndpoint(int port) {\n+        return corfuSingleNodeHost + \":\" + port;\n+    }\n+\n+    private Layout getLayout(int numNodes) {\n+        List<String> servers = new ArrayList<>();\n+\n+        for (int x = 0; x < numNodes; x++) {\n+            String serverAddress = getServerEndpoint(basePort + x);\n+            servers.add(serverAddress);\n+        }\n+\n+        return new Layout(\n+                new ArrayList<>(servers),\n+                new ArrayList<>(servers),\n+                Collections.singletonList(new Layout.LayoutSegment(\n+                        Layout.ReplicationMode.CHAIN_REPLICATION,\n+                        0L,\n+                        -1L,\n+                        Collections.singletonList(new Layout.LayoutStripe(servers)))),\n+                0L,\n+                UUID.randomUUID());\n+    }\n+\n+    @Before\n+    public void loadProperties() {\n+        corfuSingleNodeHost = (String) PROPERTIES.get(\"corfuSingleNodeHost\");\n+    }\n+\n+    @After\n+    public void tearDown() {\n+        if (firstRuntime != null) {\n+            firstRuntime.shutdown();\n+        }\n+        if (secondRuntime != null) {\n+            secondRuntime.shutdown();\n+        }\n+        if (writerRuntime != null) {\n+            writerRuntime.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void verifyStateTransferWithChainHeadFailure() throws Exception {\n+        verifyStateTransferWithNodeFailure(0);\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void verifyStateTransferWithChainTailFailure() throws Exception {\n+        verifyStateTransferWithNodeFailure(1);\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void verifyStateTransferWithChainHeadRestart() throws Exception {\n+        verifyStateTransferWithNodeRestart(0);\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void verifyStateTransferWithChainTailRestart() throws Exception {\n+        verifyStateTransferWithNodeRestart(1);\n+    }\n+\n+\n+    /**\n+     * A cluster of two nodes is started - 9000, 9001.\n+     * Then a block of data entries is written to the cluster.\n+     * 1 node - 9002 is added to the cluster, and triggers parallel transfer from two nodes.\n+     * Fail a node during transfer to verify it does not fail the transfer process.\n+     * Finally the addition of node 9002 in the layout is verified.\n+     *\n+     * @throws Exception\n+     */\n+    private void verifyStateTransferWithNodeFailure(int killNode) throws Exception {\n+        final int PORT_0 = 9000;\n+        final int PORT_1 = 9001;\n+        final int PORT_2 = 9002;\n+        final Duration timeout = Duration.ofMinutes(5);\n+        final Duration pollPeriod = Duration.ofSeconds(5);\n+        final int workflowNumRetry = 3;\n+        final int nodesCount = 3;\n+\n+        Process corfuServer_1 = runPersistentServer(corfuSingleNodeHost, PORT_0, false);\n+        Process corfuServer_2 = runPersistentServer(corfuSingleNodeHost, PORT_1, false);\n+        Process corfuServer_3 = runPersistentServer(corfuSingleNodeHost, PORT_2, false);\n+        List<Process> corfuServers = Arrays.asList(corfuServer_1, corfuServer_2, corfuServer_3);\n+\n+        // bootstrap cluster with 2 nodes\n+        final Layout twoNodeLayout = getLayout(2);\n+        BootstrapUtil.bootstrap(twoNodeLayout, retries, PARAMETERS.TIMEOUT_SHORT);\n+\n+        firstRuntime = createDefaultRuntime();\n+\n+        writerRuntime = createDefaultRuntime();\n+\n+        secondRuntime = createDefaultRuntime();\n+\n+        waitForLayoutChange(layout -> layout.getAllServers().size() == 2\n+                        && layout.getSegments().size() == 1,\n+                firstRuntime);\n+\n+\n+        // write records to the 2 node cluster\n+        final String data = createStringOfSize(100);\n+        for (int i = 0; i < PARAMETERS.NUM_ITERATIONS_MODERATE; i++) {\n+            TokenResponse token = writerRuntime.getSequencerView().next();\n+            writerRuntime.getAddressSpaceView().write(token, data.getBytes());\n+        }\n+\n+        firstRuntime.getAddressSpaceView().commit(0, PARAMETERS.NUM_ITERATIONS_MODERATE - 1);\n+\n+        // start a writer future\n+        final AtomicBoolean moreDataToBeWritten = new AtomicBoolean(true);\n+        CompletableFuture<Void> writerFuture = startWriter(moreDataToBeWritten);\n+\n+        // use another thread to wait for layout change and fail node\n+        final Process killedServer = corfuServers.get(killNode);\n+        CompletableFuture<Void> killerFuture = CompletableFuture.runAsync(() -> {\n+            try {\n+                waitForLayoutChange(layout -> layout.getAllServers().size() == nodesCount, secondRuntime);\n+                assertThat(shutdownCorfuServer(killedServer)).isTrue();\n+            } catch (Exception e) {\n+                throw new RuntimeException(e);", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI1MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004251", "bodyText": "Codacy found an issue: Unused import - com.google.common.collect.ImmutableList.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:49Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/batchprocessor/protocolbatchprocessor/ProtocolBatchProcessor.java", "diffHunk": "@@ -1,8 +1,7 @@\n package org.corfudb.infrastructure.log.statetransfer.batchprocessor.protocolbatchprocessor;\n \n import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.collect.Ordering;\n-import com.google.common.collect.Sets;\n+import com.google.common.collect.ImmutableList;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004255", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:50Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/StateTransferManager.java", "diffHunk": "@@ -81,228 +91,227 @@\n     }\n \n     /**\n-     * Performs the state transfer for the current transfer segments and also\n-     * updates their state as a result.\n+     * Return a range with the updated list of unknown addresses.\n      *\n-     * @param beforeTransferSegments A list of segments before a transfer.\n-     * @return A list of segments after a transfer.\n+     * @param range A transfer segment range.\n+     * @return An updated transfer segment range.\n      */\n-    public ImmutableList<TransferSegment> handleTransfer(List<TransferSegment> beforeTransferSegments) {\n-\n-        List<TransferSegment> afterTransferSegments = new ArrayList<>();\n-\n-        for (TransferSegment segment : beforeTransferSegments) {\n-            TransferSegmentStatus newStatus = segment.getStatus();\n-\n-            // If a segment is not NOT_TRANSFERRED -> return it as is.\n-            if (newStatus.getSegmentState() != NOT_TRANSFERRED) {\n-                afterTransferSegments.add(segment);\n-                continue;\n-            }\n-\n-            // Get all the unknown addresses for this segment.\n-            List<Long> unknownAddressesInRange =\n-                    getUnknownAddressesInRange(segment.getStartAddress(),\n-                            segment.getEndAddress());\n-\n-            // If no addresses to transfer - mark a segment as transferred.\n-            if (unknownAddressesInRange.isEmpty()) {\n-                log.debug(\"All addresses are present in the range: [{}, {}], skipping transfer.\",\n-                        segment.getStartAddress(), segment.getEndAddress());\n-                long totalTransferred = segment.getTotal();\n+    TransferSegmentRangeSingle getUnknownAddressesInRangeForRange(TransferSegmentRangeSingle range) {\n+        long startAddress = range.getStartAddress();\n+        long endAddress = range.getEndAddress();\n+        ImmutableList<Long> unknownAddressesInRange =\n+                getUnknownAddressesInRange(startAddress, endAddress);\n+        return range.toBuilder()\n+                .unknownAddressesInRange(unknownAddressesInRange)\n+                .build();\n+    }\n \n-                newStatus = TransferSegmentStatus\n+    /**\n+     * Transform the given range into a stream of batch requests.\n+     *\n+     * @param range A transfer segment range that contains unknown addresses and maybe available\n+     *              log unit servers.\n+     * @return A stream of transfer batch requests.\n+     */\n+    Stream<TransferBatchRequest> rangeToBatchRequestStream(TransferSegmentRangeSingle range) {\n+        ImmutableList<Long> unknownAddressesInRange = range.getUnknownAddressesInRange();\n+        Optional<ImmutableList<String>> availableServers = range.getAvailableServers();\n+        return Lists.partition(unknownAddressesInRange, batchSize).stream()\n+                .map(partition -> TransferBatchRequest\n                         .builder()\n-                        .segmentState(TRANSFERRED)\n-                        .totalTransferred(totalTransferred)\n-                        .build();\n-            } else {\n-                // Get total number of addresses needed to transfer.\n-                long numAddressesToTransfer = unknownAddressesInRange.size();\n-                // Create a transferBatchRequest stream.\n-                Stream<TransferBatchRequest> batchStream = Lists\n-                        .partition(unknownAddressesInRange, batchSize)\n-                        .stream()\n-                        .map(groupedAddresses ->\n-                                new TransferBatchRequest(groupedAddresses, Optional.empty())\n-                        );\n-                // Execute state transfer synchronously.\n-                newStatus = synchronousStateTransfer(batchStream, numAddressesToTransfer);\n-            }\n-\n-            TransferSegment currentSegment = TransferSegment\n-                    .builder()\n-                    .startAddress(segment.getStartAddress())\n-                    .endAddress(segment.getEndAddress())\n-                    .status(newStatus)\n-                    .build();\n-\n-            afterTransferSegments.add(currentSegment);\n+                        .addresses(partition)\n+                        .destinationNodes(availableServers)\n+                        .build());\n+    }\n \n-            if (currentSegment.getStatus().getSegmentState() == FAILED) {\n-                // A segment failed -> short circuit.\n-                break;\n-            }\n-        }\n-        return ImmutableList.copyOf(afterTransferSegments);\n+    /**\n+     * Create a batch workload for a single segment.\n+     *\n+     * @param range A single range\n+     * @return A stream of transfer batch requests from  range.\n+     */\n+    private Stream<TransferBatchRequest> createBatchWorkloadForSegment(\n+            TransferSegmentRangeSingle range) {\n+        TransferSegmentRangeSingle rangeWithUnknownAddresses =\n+                getUnknownAddressesInRangeForRange(range);\n+        return rangeToBatchRequestStream(rangeWithUnknownAddresses);\n     }\n \n     /**\n-     * Given a stream of batch requests, and a total number\n-     * of transferred addresses needed, execute a state transfer synchronously.\n+     * Go over all the single transfer segment ranges, filter them by the provided type,\n+     * get all the unknown addresses in range, and then turn the unknown addresses in range into\n+     * the transfer batch request stream - ready to be consumed by the appropriate\n+     * state transfer processor.\n      *\n-     * @param batchStream A stream of batch requests.\n-     * @param totalNeeded A total number of addresses needed for transfer.\n-     * @return A status representing a final status of a transferred segment.\n+     * @param ranges         A list of single transfer segment ranges.\n+     * @param typeOfTransfer A provided type of transfer - protocol read or consistent read.\n+     * @return A lists of streams of transfer batch requests.\n      */\n-    @VisibleForTesting\n-    TransferSegmentStatus synchronousStateTransfer(\n-            Stream<TransferBatchRequest> batchStream, long totalNeeded) {\n-        long accTransferred = 0L;\n+    List<Stream<TransferBatchRequest>> createBatchWorkload(List<TransferSegmentRangeSingle> ranges,", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI2MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004260", "bodyText": "Codacy found an issue: Avoid unused imports such as 'org.assertj.core.api.Assertions.assertThatCode'", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:51Z", "path": "test/src/test/java/org/corfudb/runtime/view/replication/ChainReplicationProtocolTest.java", "diffHunk": "@@ -1,34 +1,45 @@\n package org.corfudb.runtime.view.replication;\n \n+import com.google.common.collect.ContiguousSet;\n+import com.google.common.collect.DiscreteDomain;\n+import com.google.common.collect.Range;\n import org.corfudb.infrastructure.TestLayoutBuilder;\n import org.corfudb.protocols.wireprotocol.ILogData;\n import org.corfudb.protocols.wireprotocol.LogData;\n+import org.corfudb.protocols.wireprotocol.Token;\n import org.corfudb.runtime.CorfuRuntime;\n import org.corfudb.runtime.exceptions.OverwriteException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n import org.corfudb.runtime.exceptions.WrongEpochException;\n-import org.corfudb.runtime.view.RuntimeLayout;\n import org.corfudb.runtime.view.Layout;\n+import org.corfudb.runtime.view.RuntimeLayout;\n import org.junit.Test;\n \n+import java.util.Collections;\n+\n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI2Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004267", "bodyText": "Codacy found an issue: Unused import - org.corfudb.runtime.CorfuRuntime.CorfuRuntimeParameters.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:52Z", "path": "test/src/test/java/org/corfudb/integration/AbstractIT.java", "diffHunk": "@@ -10,8 +8,10 @@\n import org.apache.commons.io.FileUtils;\n import org.corfudb.AbstractCorfuTest;\n import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuRuntime.CorfuRuntimeParameters;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI3MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004270", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:53Z", "path": "test/src/test/java/org/corfudb/infrastructure/ServerContextBuilder.java", "diffHunk": "@@ -18,6 +18,7 @@\n     String logPath = null;\n     boolean noVerify = false;\n     boolean noSync = false;\n+    boolean noAutoCommit = true;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI3Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004276", "bodyText": "Codacy found an issue: Unused import - org.corfudb.runtime.exceptions.UnreachableClusterException.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:54Z", "path": "test/src/test/java/org/corfudb/integration/AbstractIT.java", "diffHunk": "@@ -10,8 +8,10 @@\n import org.apache.commons.io.FileUtils;\n import org.corfudb.AbstractCorfuTest;\n import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuRuntime.CorfuRuntimeParameters;\n import org.corfudb.runtime.collections.CorfuTable;\n import org.corfudb.runtime.collections.StreamingMap;\n+import org.corfudb.runtime.exceptions.UnreachableClusterException;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004280", "bodyText": "Codacy found an issue: Avoid really long methods.", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:54Z", "path": "test/src/test/java/org/corfudb/runtime/view/StateTransferTest.java", "diffHunk": "@@ -949,4 +961,536 @@ public void testStateTransferWithNoneDefaultCodec() {\n         }\n \n     }\n+\n+    class AutoClosableTempDirs implements AutoCloseable {\n+\n+        @Getter\n+        private final List<File> tempDirs;\n+\n+        public AutoClosableTempDirs(int numDirs) {\n+            ArrayList<File> tempDirs = new ArrayList<>();\n+            for (int i = 0; i < numDirs; i++) {\n+                tempDirs.add(Files.createTempDir());\n+            }\n+            this.tempDirs = tempDirs;\n+        }\n+\n+        @Override\n+        public void close() {\n+            try {\n+                for (File file : tempDirs) {\n+                    FileUtils.deleteDirectory(file);\n+                }\n+            } catch (IOException io) {\n+                io.printStackTrace();\n+            }\n+        }\n+    }\n+\n+    private LogData getLogData(TokenResponse token, byte[] payload) {\n+        LogData ld = new LogData(DataType.DATA, payload);\n+        ld.useToken(token);\n+        return ld;\n+    }\n+\n+    private void write(CorfuRuntime runtime, int numIter,\n+                       Set<Long> noWriteHoles, Set<Long> partialWriteHoles) throws Exception {\n+        for (long i = 0; i < numIter; i++) {\n+            TokenResponse token = runtime.getSequencerView().next();\n+            if (noWriteHoles.contains(i)) {\n+                // Write nothing to create a hole on all log units.\n+            } else if (partialWriteHoles.contains(i)) {\n+                // Write to head log unit to create a partial write hole.\n+                runtime.getLayoutView().getRuntimeLayout().getLogUnitClient(SERVERS.ENDPOINT_0)\n+                        .write(getLogData(token, \"partial write\".getBytes())).get();\n+            } else {\n+                runtime.getAddressSpaceView().write(token, \"Test Payload\".getBytes());\n+            }\n+        }\n+    }\n+\n+    private LogData read(CorfuRuntime runtime, long address, String server) throws Exception {\n+        return runtime.getLayoutView().getRuntimeLayout().getLogUnitClient(server)\n+                .read(address).get().getAddresses().get(address);\n+    }\n+\n+\n+    /**\n+     * Add first node. Write 100 complete records with 5 of them being holes.\n+     * Commit the addresses filling these 5 holes. Verify that CT is 99.\n+     * Add second node. It should run a parallel transfer and store the CT locally.\n+     * Verify CT is present on the second node.\n+     * Write 100 more addresses.\n+     * Add third node. It should run a parallel transfer for the first 100 addresses\n+     * and a regular transfer for the next 100 addresses.\n+     * Verify CT is present on the third node and its equal to 199.\n+     * Check all records are equal on all the three nodes and the global CT is 199.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void testBuild3NodeClusterWithParallelTransferAfterAutoCommit() throws Exception {\n+        try (AutoClosableTempDirs dirs = new AutoClosableTempDirs(3)) {\n+            List<File> tempDirs = dirs.getTempDirs();\n+            ServerContext sc0 = new ServerContextBuilder()\n+                    .setSingle(true)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_0))\n+                    .setPort(SERVERS.PORT_0)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(0).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_0, sc0);\n+            Layout currentLayout = sc0.getCurrentLayout();\n+            bootstrapAllServers(currentLayout);\n+\n+            getManagementServer(SERVERS.PORT_0).shutdown();\n+\n+            CorfuRuntime runtime = getRuntime(currentLayout).connect();\n+\n+            Set<Long> noWriteHoles = new HashSet<>(Arrays.asList(10L, 20L, 30L, 40L, 50L));\n+\n+            write(runtime, 100, noWriteHoles, new HashSet<>());\n+\n+            runtime.getAddressSpaceView().commit(0L, 99L);\n+\n+            long committedTail = runtime.getAddressSpaceView().getCommittedTail();\n+\n+            assertThat(committedTail).isEqualTo(99L);\n+\n+            ServerContext sc1 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_1))\n+                    .setPort(SERVERS.PORT_1)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(1).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_1, sc1);\n+\n+            final int addNodeRetries = 3;\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_1, addNodeRetries,\n+                            Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+            long tail = runtime.getLayoutView().getRuntimeLayout()\n+                    .getLogUnitClient(SERVERS.ENDPOINT_1).getCommittedTail().join();\n+\n+            assertThat(tail).isEqualTo(99);\n+\n+            write(runtime, 100, new HashSet<>(), new HashSet<>());\n+\n+            ServerContext sc2 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_2))\n+                    .setPort(SERVERS.PORT_2)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(2).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_2, sc2);\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_2, addNodeRetries, Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+\n+            long tail3 = runtime.getLayoutView().getRuntimeLayout()\n+                    .getLogUnitClient(SERVERS.ENDPOINT_2).getCommittedTail().join();\n+\n+            assertThat(tail3).isEqualTo(199L);\n+\n+            for (int i = 0; i < 200; i++) {\n+                LogData read1 = read(runtime, i, SERVERS.ENDPOINT_0);\n+                LogData read2 = read(runtime, i, SERVERS.ENDPOINT_1);\n+                LogData read3 = read(runtime, i, SERVERS.ENDPOINT_2);\n+\n+                assertThat(read1.getType()).isEqualTo(read2.getType());\n+                assertThat(read2.getType()).isEqualTo(read3.getType());\n+                assertThat(Arrays.equals(read1.getData(), read2.getData())).isTrue();\n+                assertThat(Arrays.equals(read2.getData(), read3.getData())).isTrue();\n+            }\n+\n+            assertThat(runtime.getAddressSpaceView().getCommittedTail()).isEqualTo(199L);\n+        }\n+    }\n+\n+    /**\n+     * Create a layout with a split segment. A: [0, 100]. A, B: [100, 200].\n+     * Commit first 150 addresses.\n+     * Add node C, this will split the layout segment like this:\n+     * A: [0, 100]. A, B: [100, 200], A, B, C: [200, -1]\n+     * Wait until the restore redundancy workflow kicks in on node B and node C is added.\n+     * Verify the segment is merged.\n+     * Verify CT is equal to 199.\n+     * Verify every record is the same on every node.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void testRestoreRedundancyParallelTransfer() throws Exception {\n+        try (AutoClosableTempDirs dirs = new AutoClosableTempDirs(3)) {\n+            List<File> tempDirs = dirs.getTempDirs();\n+\n+            ServerContext sc0 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_0))\n+                    .setPort(SERVERS.PORT_0)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(0).getAbsolutePath())\n+                    .build();\n+\n+            ServerContext sc1 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_1))\n+                    .setPort(SERVERS.PORT_1)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(1).getAbsolutePath())\n+                    .build();\n+\n+            addServer(SERVERS.PORT_0, sc0);\n+            addServer(SERVERS.PORT_1, sc1);\n+\n+            long writtenAddressesBatch1 = 100L;\n+\n+            Layout l1 = new TestLayoutBuilder()\n+                    .setEpoch(1L)\n+                    .addLayoutServer(SERVERS.PORT_0)\n+                    .addSequencer(SERVERS.PORT_0)\n+                    .buildSegment()\n+                    .setStart(0L)\n+                    .setEnd(writtenAddressesBatch1)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .buildSegment()\n+                    .setStart(writtenAddressesBatch1)\n+                    .setEnd(-1L)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addLogUnit(SERVERS.PORT_1)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .build();\n+            bootstrapAllServers(l1);\n+\n+            CorfuRuntime runtime = getRuntime(l1).connect();\n+\n+            ServerContext sc2 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_2))\n+                    .setPort(SERVERS.PORT_2)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(2).getAbsolutePath())\n+                    .build();\n+\n+            Set<Long> noWriteHoles = new HashSet<>(Arrays.asList(10L, 20L, 30L, 40L, 50L));\n+\n+            Set<Long> partialWriteHoles = new HashSet<>(Arrays.asList(11L, 21L, 32L, 43L, 55L, 155L));\n+\n+            write(runtime, 200, noWriteHoles, partialWriteHoles);\n+\n+            runtime.getAddressSpaceView().commit(0L, 149L);\n+\n+            addServer(SERVERS.PORT_2, sc2);\n+\n+            final int addNodeRetries = 3;\n+\n+            runtime.getManagementView()\n+                    .addNode(SERVERS.ENDPOINT_2, addNodeRetries, Duration.ofMinutes(1L), Duration.ofSeconds(1));\n+\n+            setAggressiveTimeouts(runtime.getLayoutView().getLayout(), runtime);\n+\n+            waitForLayoutChange(layout -> layout.getUnresponsiveServers().isEmpty() &&\n+                            layout.segments.size() == 1,\n+                    runtime);\n+\n+            long committedTail = runtime.getAddressSpaceView().getCommittedTail();\n+\n+            assertThat(committedTail).isEqualTo(199L);\n+\n+            for (int i = 0; i < 200; i++) {\n+                LogData read1 = read(runtime, i, SERVERS.ENDPOINT_0);\n+                LogData read2 = read(runtime, i, SERVERS.ENDPOINT_1);\n+                LogData read3 = read(runtime, i, SERVERS.ENDPOINT_2);\n+\n+                assertThat(read1.getType()).isEqualTo(read2.getType());\n+                assertThat(read2.getType()).isEqualTo(read3.getType());\n+                assertThat(Arrays.equals(read1.getData(), read2.getData())).isTrue();\n+                assertThat(Arrays.equals(read2.getData(), read3.getData())).isTrue();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Layout is: A: [0, 1500]. A, B: [1500, 3000]. A, B: [3000, -1]. Unresponsive: [C]\n+     * 0 - 3000: log with holes and partial writes\n+     * Run autocommit.\n+     * Allow C to heal, and B to restore redundancy.\n+     * Verify the latest committed tail.\n+     * Verify records on all the three nodes are the same.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void healAndRestoreParallelTransfer() throws Exception {\n+        try (AutoClosableTempDirs dirs = new AutoClosableTempDirs(3)) {\n+            List<File> tempDirs = dirs.getTempDirs();\n+            ServerContext sc0 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_0))\n+                    .setPort(SERVERS.PORT_0)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(0).getAbsolutePath())\n+                    .build();\n+\n+            ServerContext sc1 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_1))\n+                    .setPort(SERVERS.PORT_1)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(1).getAbsolutePath())\n+                    .build();\n+\n+            ServerContext sc2 = new ServerContextBuilder()\n+                    .setSingle(false)\n+                    .setServerRouter(new TestServerRouter(SERVERS.PORT_2))\n+                    .setPort(SERVERS.PORT_2)\n+                    .setMemory(false)\n+                    .setCacheSizeHeapRatio(\"0.0\")\n+                    .setLogPath(tempDirs.get(2).getAbsolutePath())\n+                    .build();\n+\n+            // Add three servers\n+            addServer(SERVERS.PORT_0, sc0);\n+            addServer(SERVERS.PORT_1, sc1);\n+            addServer(SERVERS.PORT_2, sc2);\n+\n+            // Add rule to drop all msgs except for service discovery ones\n+            addServerRule(SERVERS.PORT_2, new TestRule().matches(\n+                    msg -> !msg.getMsgType().equals(CorfuMsgType.LAYOUT_BOOTSTRAP)\n+                            && !msg.getMsgType().equals(CorfuMsgType.MANAGEMENT_BOOTSTRAP_REQUEST))\n+                    .drop());\n+\n+            final long writtenAddressesBatch1 = 1500L;\n+            final long writtenAddressesBatch2 = 3000L;\n+            Layout l1 = new TestLayoutBuilder()\n+                    .setEpoch(1L)\n+                    .addLayoutServer(SERVERS.PORT_0)\n+                    .addLayoutServer(SERVERS.PORT_1)\n+                    .addLayoutServer(SERVERS.PORT_2)\n+                    .addSequencer(SERVERS.PORT_0)\n+                    .addSequencer(SERVERS.PORT_1)\n+                    .addSequencer(SERVERS.PORT_2)\n+                    .buildSegment()\n+                    .setStart(0L)\n+                    .setEnd(writtenAddressesBatch1)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .buildSegment()\n+                    .setStart(writtenAddressesBatch1)\n+                    .setEnd(writtenAddressesBatch2)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addLogUnit(SERVERS.PORT_1)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .buildSegment()\n+                    .setStart(writtenAddressesBatch2)\n+                    .setEnd(-1L)\n+                    .buildStripe()\n+                    .addLogUnit(SERVERS.PORT_0)\n+                    .addLogUnit(SERVERS.PORT_1)\n+                    .addToSegment()\n+                    .addToLayout()\n+                    .addUnresponsiveServer(SERVERS.PORT_2)\n+                    .build();\n+\n+\n+            bootstrapAllServers(l1);\n+            CorfuRuntime rt = getRuntime(l1).connect();\n+            setAggressiveTimeouts(l1, rt,\n+                    getManagementServer(SERVERS.PORT_0).getManagementAgent().getCorfuRuntime());\n+            setAggressiveDetectorTimeouts(SERVERS.PORT_0);\n+\n+            // write a non-consolidated logs\n+            Set<Long> noWriteHoles = new HashSet<>(Arrays.asList(10L, 100L, 1000L, 2000L, 2500L, 2550L));\n+\n+            Set<Long> partialWriteHoles = new HashSet<>(Arrays.asList(11L, 101L, 1002L, 2043L, 2055L, 2555L));\n+\n+            write(rt, 3000, noWriteHoles, partialWriteHoles);\n+\n+            rt.getAddressSpaceView().commit(0L, 1999L);\n+\n+            // Allow node 2 to be healed.\n+            clearServerRules(SERVERS.PORT_2);\n+\n+            rt.invalidateLayout();\n+\n+            // Wait until all the nodes are restored.\n+            waitForLayoutChange(layout -> layout.getUnresponsiveServers().isEmpty() &&\n+                            layout.segments.size() == 1,\n+                    rt);\n+\n+            // Verify CT and data\n+            long committedTail = rt.getAddressSpaceView().getCommittedTail();\n+\n+            assertThat(committedTail).isEqualTo(2999L);\n+\n+            for (int i = 0; i < 3000; i++) {\n+                LogData read1 = read(rt, i, SERVERS.ENDPOINT_0);\n+                LogData read2 = read(rt, i, SERVERS.ENDPOINT_1);\n+                LogData read3 = read(rt, i, SERVERS.ENDPOINT_2);\n+\n+                assertThat(read1.getType()).isEqualTo(read2.getType());\n+                assertThat(read2.getType()).isEqualTo(read3.getType());\n+                assertThat(Arrays.equals(read1.getData(), read2.getData())).isTrue();\n+                assertThat(Arrays.equals(read2.getData(), read3.getData())).isTrue();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Layout is: A, B: [0, 1500]. A, B, C: [1500, -1].\n+     * Trim mark on A is 90, trim mark on B is 120, trim mark on C is 150\n+     * Commit addresses 150 - 749.\n+     * Restore redundancy for a node C and verify that the CT and TM are the latest\n+     * and records on all the three nodes are the same.\n+     */\n+    @Test\n+    @SuppressWarnings(\"checkstyle:magicnumber\")\n+    public void restoreRedundancyOldAndNewTrimMarksParallelTransfer() throws Exception {", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjAwNDI4Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2552#discussion_r446004287", "bodyText": "Codacy found an issue: Avoid unused imports such as 'com.google.common.collect.ImmutableList'", "author": "corfudb-bot", "createdAt": "2020-06-26T07:02:55Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/log/statetransfer/batchprocessor/protocolbatchprocessor/ProtocolBatchProcessor.java", "diffHunk": "@@ -1,8 +1,7 @@\n package org.corfudb.infrastructure.log.statetransfer.batchprocessor.protocolbatchprocessor;\n \n import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.collect.Ordering;\n-import com.google.common.collect.Sets;\n+import com.google.common.collect.ImmutableList;", "originalCommit": "16463324039f54f9a4340e2e61935a326874217f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}