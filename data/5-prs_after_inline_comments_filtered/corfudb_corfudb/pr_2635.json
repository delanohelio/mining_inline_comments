{"pr_number": 2635, "pr_title": "Log Replication Feature", "pr_createdAt": "2020-07-15T02:45:37Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2635", "timeline": [{"oid": "ecbc4eb33e2e29879b7b1cecea63afcb1af9ed7b", "url": "https://github.com/CorfuDB/CorfuDB/commit/ecbc4eb33e2e29879b7b1cecea63afcb1af9ed7b", "message": "Add Support for Selected Stream Replication.\n\n- Remove hard-coded stream names and read them from system table.\n- Add Version Check for System Table with Stream Names\n\nPopulate only active node names from Default Site Manager config file.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "a1a739b330ce4e83c9a9cab99862be55ca4e91af", "url": "https://github.com/CorfuDB/CorfuDB/commit/a1a739b330ce4e83c9a9cab99862be55ca4e91af", "message": "Config the message size for both snapshot full sync and delta sync. (#2643)\n\n* Make snapshot message size configurable.\r\n   * Make the message size configurable.\r\n   * While reading a SMR entry, setup its size.\r\n   * While processing an opaque entry, get its size.\r\n   * Send snapshot message with the maxMessageSize\r\n   * The function getSerializedSize works only for an opaque smr entry.\r\n   * While passing buffer, truncate it to the proper size\r\n   * Add unit tests to verify the data message size is correctly set.", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "feada0c865b8144fa187ac62ceb68676591a0d78", "url": "https://github.com/CorfuDB/CorfuDB/commit/feada0c865b8144fa187ac62ceb68676591a0d78", "message": "Handle Trim Exceptions on Shadow Streams (#2640)\n\n1. Implement a callback mechanism, where snapshot sync start/end is notified\nto a plugin, so checkpoint/trim is disabled for the duration of snapshot sync.\n2. Bug Fix: properly set base snapshot on renegotiation for two different log entry (delta) sync cycles\n3. Tests to verify 1 and 2\n4. Pass CorfuRuntime instance to the onSnapshotSyncStart/End() calls\n\nFix FSM Unit Test and Snapshot Plugin Condition (#2663)\n\n- Fix Intermittent Failure on FSM Unit Test\n- Fix onSnapshotEnd condition to check for an ack SNAPSHOT_END instead of SNAPSHOT_REPLICATED (intermediate acks)\n- Log Entry Reader Bug Fix (#2666)\n\nWhen finding streams that we are not interested in replicating\ndo not modify original Entries from OpaqueEntry.", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "e18d68342ade28525a311463ac8ad99f9eae5cdd", "url": "https://github.com/CorfuDB/CorfuDB/commit/e18d68342ade28525a311463ac8ad99f9eae5cdd", "message": "CorfuStoreBrowser: add option to load data into a table (#2673)\n\nthis is useful for testing checkpoint issues in live setups.", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "3dcb2025bbfdf71bbda5560b077eeb88aac9854e", "url": "https://github.com/CorfuDB/CorfuDB/commit/3dcb2025bbfdf71bbda5560b077eeb88aac9854e", "message": "Log Entry Sync allow mixed Transactions (#2675)\n\nAllow replication when a transaction is executed across\r\nreplicated and non-replicated streams. Filter out the streams\r\nof interest and disregard all other streams.", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "7196c01ae8e264920ab9636437ba77894c54351a", "url": "https://github.com/CorfuDB/CorfuDB/commit/7196c01ae8e264920ab9636437ba77894c54351a", "message": "Support queryReplicationStatus() on non-leader node. (#2641)", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "12bfcbb3eb0ef56c32323cd849b3221f365c4d0a", "url": "https://github.com/CorfuDB/CorfuDB/commit/12bfcbb3eb0ef56c32323cd849b3221f365c4d0a", "message": "Standby Connection Loss Fix (#2683)\n\n1. Fix Issue when Standby connection is lost\r\n2. Fix replication server graceful shutdown\r\n3. Add logging\r\n4. Adjust default and configurable lock values: monitor, renewal, lease duration and lease check", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "01d0bad190c95929178e41f29c6549a86c3108a5", "url": "https://github.com/CorfuDB/CorfuDB/commit/01d0bad190c95929178e41f29c6549a86c3108a5", "message": "Sync Status API improvements. (#2681)", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "url": "https://github.com/CorfuDB/CorfuDB/commit/b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "message": "Dedicated Executor for acquired lock monitoring (#2684)\n\n- Address Static Analysis Comments\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T16:54:55Z", "type": "commit"}, {"oid": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "url": "https://github.com/CorfuDB/CorfuDB/commit/b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "message": "Dedicated Executor for acquired lock monitoring (#2684)\n\n- Address Static Analysis Comments\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T16:54:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE3OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484178", "bodyText": "Codacy found an issue: Use equals() to compare object references.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:02:58Z", "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "diffHunk": "@@ -0,0 +1,588 @@\n+package org.corfudb.infrastructure.logreplication;\n+\n+import com.google.common.reflect.TypeToken;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptyDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptySnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.InSnapshotSyncState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestReaderConfiguration;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestSnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.DefaultReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.runtime.view.Address;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Observable;\n+import java.util.Observer;\n+import java.util.Queue;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+/**\n+ * Test Log Replication FSM.\n+ */\n+public class LogReplicationFSMTest extends AbstractViewTest implements Observer {\n+\n+    // Parameters for writes\n+    private static final int NUM_ENTRIES = 10;\n+    private static final int LARGE_NUM_ENTRIES = 100;\n+    private static final String PAYLOAD_FORMAT = \"%s hello world\";\n+    private static final String TEST_STREAM_NAME = \"StreamA\";\n+    private static final int BATCH_SIZE = 2;\n+    private static final int WAIT_TIME = 100;\n+    private static final int CORFU_PORT = 9000;\n+    private static final int TEST_TOPOLOGY_CONFIG_ID = 1;\n+    private static final String TEST_LOCAL_CLUSTER_ID = \"local_cluster\";\n+\n+    // This semaphore is used to block until the triggering event causes the transition to a new state\n+    private final Semaphore transitionAvailable = new Semaphore(1, true);\n+    // We observe the transition counter to know that a transition occurred.\n+    private ObservableValue transitionObservable;\n+\n+    // Flag indicating if we should observer a snapshot sync, this is to interrupt it at any given stage\n+    private boolean observeSnapshotSync = false;\n+    private int limitSnapshotMessages = 0;\n+    private ObservableValue snapshotMessageCounterObservable;\n+\n+    private LogReplicationFSM fsm;\n+    private CorfuRuntime runtime;\n+    private DataSender dataSender;\n+    private SnapshotReader snapshotReader;\n+    private LogEntryReader logEntryReader;\n+    private LogReplicationAckReader ackReader;\n+\n+    @Before\n+    public void setRuntime() {\n+        runtime = getDefaultRuntime();\n+        runtime.getParameters().setCodecType(Codec.Type.NONE);\n+    }\n+\n+    @After\n+    public void stopAckReader() {\n+        ackReader.shutdown();\n+    }\n+\n+    /**\n+     * Verify state machine behavior in the most simple (no error) path.\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) None -> verify FSM initial state is INITIALIZED\n+     * (2) Replication Stop -> verify it stays in the INITIALIZED state as replication has not been started\n+     * (3) Replication Start -> IN_LOG_ENTRY_SYNC state\n+     * (4) Snapshot Sync Request -> IN_SNAPSHOT_SYNC state\n+     * (5) Snapshot Sync Complete -> IN_LOG_ENTRY_SYNC state\n+     * (6) Replication Stop -> back to INITIALIZED state\n+     *\n+     */\n+    @Test\n+    public void testLogReplicationFSMTransitions() throws Exception {\n+\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial state: Initialized\n+        LogReplicationState initState = fsm.getState();\n+        assertThat(initState.getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Stop (without any replication having started)\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED);\n+\n+        // Transition #2: Replication Start\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #3: Snapshot Sync Request\n+        UUID snapshotSyncId = transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Transition #4: Snapshot Sync Complete\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE, LogReplicationStateType.IN_LOG_ENTRY_SYNC, snapshotSyncId, false);\n+\n+        // Transition #5: Stop Replication\n+        // Next transition might not be to INITIALIZED, as IN_LOG_ENTRY_SYNC state might have enqueued\n+        // a continuation before the stop is enqueued.\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED, true);\n+    }\n+\n+    /**\n+     * Test Trim Exception Events for Log Replication FSM\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) Snapshot Sync Request => IN_SNAPSHOT_SYNC state\n+     * (2) Trimmed Exception (incorrect id) => IN_LOG_ENTRY_SYNC\n+     * (3) Trimmed Exception (for state in (5)) => IN_REQUIRE_SNAPSHOT_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testTrimExceptionFSM() throws Exception {\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial acquire of the semaphore, so the occurrence of the transition releases it for the transition itself.\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // A SYNC_CANCEL due to a trimmed exception, is an internal event generated during read in the log entry or\n+        // snapshot sync state, to ensure it is triggered during the state, and not before the task is\n+        // actually started on the worker thread, let's insert a delay.\n+        insertDelay(WAIT_TIME);\n+\n+        // Transition #2: Trimmed Exception on Log Entry Sync for an invalid event id, this should not be taken as\n+        // a valid trimmed exception for the current state, hence it remains in the same state\n+        transition(LogReplicationEventType.SYNC_CANCEL, LogReplicationStateType.IN_LOG_ENTRY_SYNC, UUID.randomUUID(), false);\n+\n+        // Transition #3: Trimmed Exception\n+        // Because this is an internal state, we need to capture the actual event id internally generated\n+        UUID logEntrySyncID = fsm.getStates().get(LogReplicationStateType.IN_LOG_ENTRY_SYNC).getTransitionEventId();\n+        transition(LogReplicationEventType.SYNC_CANCEL, LogReplicationStateType.IN_SNAPSHOT_SYNC, logEntrySyncID, true);\n+    }\n+\n+    private void insertDelay(int timeMilliseconds) throws InterruptedException {\n+        sleep(timeMilliseconds);\n+    }\n+\n+    /**\n+     * Test SnapshotSender through dummy implementations of the SnapshotReader and DataSender.\n+     *\n+     * (1) Initiate the Log Replication State Machine (which defaults to the INITIALIZED State)\n+     * (2) Write NUM_ENTRIES to the database in a consecutive address space for a given stream.\n+     * (3) Enforce event to initialize SNAPSHOT_SYNC.\n+     * (4) When SNAPSHOT_SYNC is completed the FSM should transition to a new state IN_LOG_ENTRY_SYNC. Block until\n+     * this transition occurs.\n+     * (5) Once this transition occurs verify that the Listener has received the same data written in (2).\n+     *\n+     * In this test we assume the SnapshotReader reads all NUM_ENTRIES in a single call (no batching)\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testLogReplicationSnapshotTransmitterNoBatch() throws Exception {\n+        testSnapshotSender(NUM_ENTRIES);\n+    }\n+\n+    /**\n+     * Test SnapshotSender through dummy implementations of the SnapshotReader and DataSender.\n+     *\n+     * (1) Initiate the Log Replication State Machine (which defaults to the INITIALIZED State)\n+     * (2) Write NUM_ENTRIES to the database in a consecutive address space for a given stream.\n+     * (3) Enforce event to initialize SNAPSHOT_SYNC.\n+     * (4) When SNAPSHOT_SYNC is completed the FSM should transition to a new state IN_LOG_ENTRY_SYNC. Block until\n+     * this transition occurs.\n+     * (5) Once this transition occurs verify that the Listener has received the same data written in (2).\n+     *\n+     * In this test we assume the SnapshotReader reads NUM_ENTRIES in batches, and confirm all NUM_ENTRIES are\n+     * received by the listener.\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testLogReplicationSnapshotTransmitterBatch() throws Exception {\n+        testSnapshotSender(BATCH_SIZE);\n+    }\n+\n+    private void testSnapshotSender(int batchSize) throws Exception {\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.TEST);\n+\n+        // Modify test configuration to the specified batch size\n+        ((TestSnapshotReader)snapshotReader).setBatchSize(batchSize);\n+\n+        // Write NUM_ENTRIES to streamA\n+        List<TokenResponse> writeTokens = writeToStream();\n+\n+        List<Long> seqNums = new ArrayList<>();\n+        writeTokens.forEach(token -> seqNums.add(token.getSequence()));\n+\n+        // Write to Stream will write to some addresses.  SnapshotReader should only read from those addresses\n+        ((TestSnapshotReader) snapshotReader).setSeqNumsToRead(seqNums);\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC);\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        // The transition should happen to IN_LOG_ENTRY_SYNC state.\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        while(!fsm.getState().getType().equals(LogReplicationStateType.IN_LOG_ENTRY_SYNC)) {\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+        assertThat(listenerQueue.size()).isEqualTo(NUM_ENTRIES);\n+\n+        for (int i = 0; i < NUM_ENTRIES; i++) {\n+            assertThat(listenerQueue.poll().getPayload())\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+    }\n+\n+    /**\n+     * This test verifies that canceling a snapshot sync which is in progress, takes log replication\n+     * back to the INITIALIZED state and that snapshot sync can be retried and completed successfully.\n+     *\n+     * (1) Write NUM_ENTRIES to StreamA\n+     * (2) Trigger start of SNAPSHOT_SYNC\n+     * (3) Interrupt/Stop snapshot sync when 2 messages have been sent to the remote site.\n+     * (4) Re-trigger SNAPSHOT_SYNC\n+     * (5) Check for completeness, i.e., that state has changed to IN_LOG_ENTRY_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void cancelSnapshotSyncInProgressAndRetry() throws Exception {\n+        // This test needs to observe the number of messages generated during snapshot sync to interrupt/stop it,\n+        // before it completes.\n+        observeSnapshotSync = true;\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.TEST);\n+\n+        // Modify test configuration to the specified batch size (since we write NUM_ENTRIES = 10) and we send in\n+        // batches of BATCH_SIZE = 2, we will stop snapshot sync at 2 sent messages.\n+        ((TestSnapshotReader)snapshotReader).setBatchSize(BATCH_SIZE);\n+        limitSnapshotMessages = 2;\n+\n+        // Write NUM_ENTRIES to streamA\n+        List<TokenResponse> writeTokens = writeToStream();\n+\n+        List<Long> seqNums = new ArrayList<>();\n+        writeTokens.forEach(token -> seqNums.add(token.getSequence()));\n+\n+        // Write to Stream will write to some addresses.  SnapshotReader should only read from those addresses\n+        ((TestSnapshotReader) snapshotReader).setSeqNumsToRead(seqNums);\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC);\n+\n+        // We observe the number of transmitted messages and force a REPLICATION_STOP, when 2 messages have been sent\n+        // so we verify the state moves to INITIALIZED again.\n+        transitionAvailable.acquire();\n+        fsm.input(new LogReplicationEvent(LogReplicationEventType.REPLICATION_STOP));\n+\n+        transitionAvailable.acquire();\n+\n+        while (fsm.getState().getType() != LogReplicationStateType.INITIALIZED) {\n+            // Wait on a FSM transition to occur\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        ((TestDataSender) dataSender).reset();\n+\n+        // Stop observing number of messages in snapshot sync, so this time it completes\n+        observeSnapshotSync = false;\n+\n+        // Transition #2: This time the snapshot sync completes\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        while (fsm.getState().getType() != LogReplicationStateType.IN_LOG_ENTRY_SYNC) {\n+            // Block until FSM moves back to in log entry (delta) sync state\n+            transitionAvailable.acquire();\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        assertThat(listenerQueue.size()).isEqualTo(NUM_ENTRIES);\n+\n+        for (int i=0; i<NUM_ENTRIES; i++) {\n+            assertThat(listenerQueue.poll().getPayload())\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+    }\n+\n+\n+    /**\n+     * Test Snapshot Sync for Default Stream-based implementations.\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testSnapshotSyncStreamImplementation() throws Exception {\n+\n+        // Initialize State Machine\n+        initLogReplicationFSM(ReaderImplementation.STREAMS);\n+\n+        // Write LARGE_NUM_ENTRIES to streamA\n+        writeToMap();\n+\n+        // Initial acquire of semaphore, the transition method will block until a transition occurs\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Start\n+        // transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #2: Snapshot Sync Request\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        // The transition should happen to IN_LOG_ENTRY_SYNC state.\n+        System.out.println(\"**** Wait for snapshot sync to complete\");\n+\n+        // Block until the snapshot sync completes and next transition occurs.\n+        while (fsm.getState().getType() != LogReplicationStateType.IN_LOG_ENTRY_SYNC) {\n+            log.trace(\"stateType {} expected type {}\", fsm.getState().getType(), LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        Queue<LogReplicationEntry> listenerQueue = ((TestDataSender) dataSender).getEntryQueue();\n+\n+        // Transactional puts into the stream (incremental updates)\n+        writeTxIncrementalUpdates();\n+\n+        int incrementalUpdates = 0;\n+\n+        while(incrementalUpdates < NUM_ENTRIES) {\n+           ((TestDataSender)dataSender).getEntryQueue().poll();\n+           incrementalUpdates++;\n+        }\n+\n+        assertThat(incrementalUpdates).isEqualTo(NUM_ENTRIES);\n+    }\n+\n+    private void writeTxIncrementalUpdates() {\n+        CorfuTable<String, String> map = runtime.getObjectsView()\n+                .build()\n+                .setStreamName(TEST_STREAM_NAME)\n+                .setTypeToken(new TypeToken<CorfuTable<String, String>>() {})\n+                .open();\n+\n+        for(int i=0; i<NUM_ENTRIES; i++) {\n+            runtime.getObjectsView().TXBegin();\n+            map.put(String.valueOf(i), String.valueOf(i));\n+            runtime.getObjectsView().TXEnd();\n+        }\n+    }\n+\n+    private List<TokenResponse> writeToStream() {\n+        UUID streamA = UUID.nameUUIDFromBytes(TEST_STREAM_NAME.getBytes());\n+        List<TokenResponse> writeTokens = new ArrayList<>();\n+        // Write\n+        for (int i=0; i < NUM_ENTRIES; i++) {\n+            TokenResponse response = runtime.getSequencerView().next(streamA);\n+            writeTokens.add(response);\n+            runtime.getAddressSpaceView().write(response, String.format(PAYLOAD_FORMAT, i).getBytes());\n+        }\n+\n+        // Read to verify data is there\n+        int index = 0;\n+        for (TokenResponse token : writeTokens) {\n+            assertThat(runtime.getAddressSpaceView().read((long)token.getSequence()).getPayload(getRuntime()))\n+                    .isEqualTo( String.format(PAYLOAD_FORMAT, index).getBytes());\n+            index++;\n+        }\n+        return writeTokens;\n+    }\n+\n+    private void writeToMap() {\n+        CorfuTable<String, String> map = runtime.getObjectsView()\n+                .build()\n+                .setStreamName(TEST_STREAM_NAME)\n+                .setTypeToken(new TypeToken<CorfuTable<String, String>>() {})\n+                .open();\n+\n+        for (int i=0; i<LARGE_NUM_ENTRIES; i++) {\n+            map.put(String.valueOf(i), String.valueOf(i));\n+        }\n+    }\n+\n+    /**\n+     * Initialize Log Replication FSM\n+     *\n+     * Use empty implementations for those cases where you want to verify the behavior of the state machine.\n+     *\n+     * @param readerImpl implementation to use for readers.\n+     */\n+    private void initLogReplicationFSM(ReaderImplementation readerImpl) {\n+\n+        logEntryReader = new TestLogEntryReader();\n+\n+        switch(readerImpl) {\n+            case EMPTY:\n+                // Empty implementations of log reader and listener - used for testing transitions\n+                snapshotReader = new EmptySnapshotReader();\n+                dataSender = new EmptyDataSender();\n+                break;\n+            case TEST:\n+                // Dummy implementations of log reader and listener for testing\n+                // The log reader queries the log for the config provided (stream name, number of entries)\n+                // The listener inserts what it receives into a queue\n+                TestReaderConfiguration testConfig = TestReaderConfiguration.builder()\n+                        .endpoint(getDefaultEndpoint())\n+                        .numEntries(NUM_ENTRIES)\n+                        .payloadFormat(PAYLOAD_FORMAT)\n+                        .streamName(TEST_STREAM_NAME)\n+                        .batchSize(BATCH_SIZE).build();\n+\n+                snapshotReader = new TestSnapshotReader(testConfig);\n+                dataSender = new TestDataSender();\n+                break;\n+            case STREAMS:\n+                // Default implementation used for Log Replication (stream-based)\n+                LogReplicationConfig logReplicationConfig = new LogReplicationConfig(Collections.singleton(TEST_STREAM_NAME));\n+                snapshotReader = new StreamsSnapshotReader(getNewRuntime(getDefaultNode()).connect(),\n+                        logReplicationConfig);\n+                dataSender = new TestDataSender();\n+                break;\n+            default:\n+                break;\n+        }\n+\n+        LogReplicationMetadataManager metadataManager = new LogReplicationMetadataManager(runtime, TEST_TOPOLOGY_CONFIG_ID,\n+                TEST_LOCAL_CLUSTER_ID);\n+        LogReplicationConfig config = new LogReplicationConfig(new HashSet<>(Arrays.asList(TEST_STREAM_NAME)));\n+        ackReader = new LogReplicationAckReader(metadataManager, config, runtime, TEST_LOCAL_CLUSTER_ID);\n+        fsm = new LogReplicationFSM(runtime, snapshotReader, dataSender, logEntryReader,\n+                new DefaultReadProcessor(runtime), config, new ClusterDescriptor(\"Cluster-Local\",\n+                LogReplicationClusterInfo.ClusterRole.ACTIVE, CORFU_PORT),\n+                Executors.newSingleThreadExecutor(new ThreadFactoryBuilder().setNameFormat(\"fsm-worker\").build()),\n+                ackReader);\n+        transitionObservable = fsm.getNumTransitions();\n+        transitionObservable.addObserver(this);\n+\n+        if (observeSnapshotSync) {\n+            System.out.println(\"Observe snapshot sync\");\n+            snapshotMessageCounterObservable = ((InSnapshotSyncState) fsm.getStates()\n+                    .get(LogReplicationStateType.IN_SNAPSHOT_SYNC)).getSnapshotSender().getObservedCounter();\n+            snapshotMessageCounterObservable.addObserver(this);\n+        }\n+    }\n+\n+    /**\n+     * It performs a transition, based on the given event type and asserts the FSM has moved to the expected state\n+     *\n+     * @param eventType log replication event.\n+     * @param expectedState expected state after transition is completed.\n+     * @param eventId identifier of the event.\n+     */\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState,\n+                            UUID eventId, boolean waitUntilExpected)\n+            throws InterruptedException {\n+\n+        System.out.println(\"Insert event: \" + eventType);\n+\n+        LogReplicationEvent event;\n+\n+        if (eventId != null) {\n+            // For testing we are enforcing internal events (like Trimmed Exception or Snapshot Complete),\n+            // for this reason we must set the id of the event that preceded it, so it corresponds to the same state.\n+            event = new LogReplicationEvent(eventType, new LogReplicationEventMetadata(eventId));\n+        } else {\n+            event = new LogReplicationEvent(eventType);\n+        }\n+\n+        fsm.input(event);\n+\n+        transitionAvailable.acquire();\n+\n+        // Wait until the expected state\n+        while (waitUntilExpected) {\n+            if (fsm.getState().getType() == expectedState) {\n+                return event.getEventID();\n+            } else {\n+                transitionAvailable.acquire();\n+            }\n+        }\n+\n+        assertThat(fsm.getState().getType()).isEqualTo(expectedState);\n+\n+        return event.getEventID();\n+    }\n+\n+    /**\n+     * Insert an event of eventType into the Log Replication FSM and assert on the expected state.\n+     *\n+     * This method blocks until an actual transition occurs in the FSM.\n+     *\n+     * @param eventType the type of the event to input into the state machine\n+     * @param expectedState the expected state to transition to\n+     *\n+     * @return UUID of the input event\n+     *\n+     * @throws InterruptedException\n+     */\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState, boolean waitUntilExpected) throws InterruptedException {\n+        return transition(eventType, expectedState, null, waitUntilExpected);\n+    }\n+\n+    private UUID transition(LogReplicationEventType eventType,\n+                            LogReplicationStateType expectedState) throws InterruptedException {\n+        return transition(eventType, expectedState, null, false);\n+    }\n+\n+    /**\n+     * Observer callback, will be called on every transition of the log replication FSM.\n+     */\n+    @Override\n+    public void update(Observable obs, Object arg) {\n+        if (obs == transitionObservable)\n+        {\n+            while (!transitionAvailable.hasQueuedThreads()) {\n+                // Wait until some thread is waiting to acquire...\n+            }\n+            transitionAvailable.release();\n+            // System.out.println(\"Transition::#\"  + transitionObservable.getValue() + \"::\" + fsm.getState().getType());\n+        } else if (obs == snapshotMessageCounterObservable) {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484180", "bodyText": "Codacy found an issue: Use explicit scoping instead of the default package private level", "author": "corfudb-bot", "createdAt": "2020-08-08T17:02:59Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/DiscoveryServiceEvent.java", "diffHunk": "@@ -0,0 +1,33 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+\n+public class DiscoveryServiceEvent {\n+    DiscoveryServiceEventType type;\n+\n+    @Getter", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4MQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484181", "bodyText": "Codacy found an issue: Avoid reassigning parameters such as 'blockOnce'", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:00Z", "path": "test/src/test/java/org/corfudb/integration/ReplicationReaderWriterIT.java", "diffHunk": "@@ -0,0 +1,752 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogEntryWriter;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.StreamsSnapshotWriter;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReadMessage;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.logprotocol.SMREntry;\n+import org.corfudb.protocols.wireprotocol.ILogData;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.MultiCheckpointWriter;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.exceptions.SerializerException;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.Address;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.runtime.view.StreamOptions;\n+import org.corfudb.runtime.view.stream.IStreamView;\n+import org.corfudb.util.serializer.ISerializer;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+import java.util.stream.Stream;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+public class ReplicationReaderWriterIT extends AbstractIT {\n+    private static final String DEFAULT_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String WRITER_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+    private static final int START_VAL = 11;\n+    private static final int NUM_KEYS = 10;\n+    private static final int NUM_STREAMS = 2;\n+    public static final int NUM_TRANSACTIONS = 20;\n+    public static final String PRIMARY_SITE_ID = \"Cluster-Paris\";\n+    public static final int BATCH_SIZE = 2;\n+\n+    // Enforce to read each entry for each message\n+    // each log entry size is 62, there are 2 log entry per dataMsg\n+    // each snapshot entry is 33, there are 4 snapshot entry per dataMsg\n+    public static final int MAX_MSG_SIZE = 160;\n+\n+    private static Semaphore waitSem = new Semaphore(1);\n+\n+    private static UUID snapshotSyncId = UUID.randomUUID();\n+\n+    private Process server1;\n+    private Process server2;\n+\n+    // Connect with server1 to generate data\n+    private CorfuRuntime srcDataRuntime = null;\n+\n+    // Connect with server1 to read snapshot data\n+    private CorfuRuntime readerRuntime = null;\n+\n+    // Connect with server2 to write snapshot data\n+    private CorfuRuntime writerRuntime = null;\n+\n+    // Connect with server2 to verify data\n+    private CorfuRuntime dstDataRuntime = null;\n+\n+    private HashMap<String, CorfuTable<Long, Long>> srcTables = new HashMap<>();\n+    private HashMap<String, CorfuTable<Long, Long>> dstTables = new HashMap<>();\n+    private HashMap<String, CorfuTable<Long, Long>> shadowTables = new HashMap<>();\n+\n+    private CorfuRuntime srcTestRuntime;\n+\n+    private CorfuRuntime dstTestRuntime;\n+\n+    /*\n+     * the in-memory data for corfu tables for verification.\n+     */\n+    private HashMap<String, HashMap<Long, Long>> srcHashMap = new HashMap<>();\n+    private HashMap<String, HashMap<Long, Long>> dstHashMap = new HashMap<>();\n+\n+    /*\n+     * store message generated by stream snapshot reader and will play it at the writer side.\n+     */\n+    private List<LogReplicationEntry> msgQ = new ArrayList<>();\n+\n+    private void setupEnv() throws IOException {\n+        // Start node one and populate it with data\n+        server1 = new CorfuServerRunner()\n+                .setHost(DEFAULT_HOST)\n+                .setPort(DEFAULT_PORT)\n+                .setSingle(true)\n+                .runServer();\n+\n+        server2 = new CorfuServerRunner()\n+                .setHost(DEFAULT_HOST)\n+                .setPort(WRITER_PORT)\n+                .setSingle(true)\n+                .runServer();\n+\n+        CorfuRuntime.CorfuRuntimeParameters params = CorfuRuntime.CorfuRuntimeParameters\n+                .builder()\n+                .build();\n+\n+        srcDataRuntime = CorfuRuntime.fromParameters(params);\n+        srcDataRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        srcDataRuntime.setTransactionLogging(true).connect();\n+\n+        srcTestRuntime = CorfuRuntime.fromParameters(params);\n+        srcTestRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        srcTestRuntime.setTransactionLogging(true).connect();\n+\n+        readerRuntime = CorfuRuntime.fromParameters(params);\n+        readerRuntime.parseConfigurationString(DEFAULT_ENDPOINT);\n+        readerRuntime.setTransactionLogging(true).connect();\n+\n+        writerRuntime = CorfuRuntime.fromParameters(params);\n+        writerRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        writerRuntime.setTransactionLogging(true).connect();\n+\n+        dstDataRuntime = CorfuRuntime.fromParameters(params);\n+        dstDataRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        dstDataRuntime.setTransactionLogging(true).connect();\n+\n+        dstTestRuntime = CorfuRuntime.fromParameters(params);\n+        dstTestRuntime.parseConfigurationString(WRITER_ENDPOINT);\n+        dstTestRuntime.setTransactionLogging(true).connect();\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt) {\n+        openStreams(tables, rt, NUM_STREAMS, Serializers.PRIMITIVE, false);\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams) {\n+        openStreams(tables, rt, num_streams, Serializers.PRIMITIVE);\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams,\n+                                   ISerializer serializer, boolean shadow) {\n+        for (int i = 0; i < num_streams; i++) {\n+            String name = \"test\" + i;\n+            if (shadow) {\n+                name = name + \"_shadow\";\n+            }\n+            CorfuTable<Long, Long> table = rt.getObjectsView()\n+                    .build()\n+                    .setStreamName(name)\n+                    .setTypeToken(new TypeToken<CorfuTable<Long, Long>>() {\n+                    })\n+                    .setSerializer(serializer)\n+                    .open();\n+            tables.put(name, table);\n+        }\n+    }\n+\n+    public static void openStreams(HashMap<String, CorfuTable<Long, Long>> tables, CorfuRuntime rt, int num_streams,\n+                                                 ISerializer serializer) {\n+        openStreams(tables, rt, num_streams, serializer, false);\n+    }\n+\n+\n+    public static void generateData(HashMap<String, CorfuTable<Long, Long>> tables,\n+                      HashMap<String, HashMap<Long, Long>> hashMap,\n+                      int numKeys, CorfuRuntime rt, long startVal) {\n+        for (int i = 0; i < numKeys; i++) {\n+            for (String name : tables.keySet()) {\n+                hashMap.putIfAbsent(name, new HashMap<>());\n+                long key = i + startVal;\n+                rt.getObjectsView().TXBegin();\n+                tables.get(name).put(key, key);\n+                rt.getObjectsView().TXEnd();\n+                log.trace(\"tail \" + rt.getAddressSpaceView().getLogTail() + \" seq \" + rt.getSequencerView().query().getSequence());\n+                hashMap.get(name).put(key, key);\n+            }\n+        }\n+    }\n+\n+    // Generate data with transactions and the same time push the data to the hashtable\n+    public static void generateTransactions(HashMap<String, CorfuTable<Long, Long>> tables,\n+                      HashMap<String, HashMap<Long, Long>> hashMap,\n+                      int numT, CorfuRuntime rt, long startval) {\n+        int j = 0;\n+        for (int i = 0; i < numT; i++) {\n+            rt.getObjectsView().TXBegin();\n+            for (String name : tables.keySet()) {\n+                hashMap.putIfAbsent(name, new HashMap<>());\n+                long key = j + startval;\n+                tables.get(name).put(key, key);\n+                log.trace(\"tail \" + rt.getAddressSpaceView().getLogTail() + \" seq \" + rt.getSequencerView().query().getSequence());\n+                hashMap.get(name).put(key, key);\n+                j++;\n+            }\n+            rt.getObjectsView().TXEnd();\n+        }\n+        System.out.println(\"\\ngenerate transactions num \" + numT);\n+    }\n+\n+    public static void verifyData(String tag, HashMap<String, CorfuTable<Long, Long>> tables, HashMap<String, HashMap<Long, Long>> hashMap) {\n+        System.out.println(\"\\n\" + tag);\n+        for (String name : hashMap.keySet()) {\n+            CorfuTable<Long, Long> table = tables.get(name);\n+            HashMap<Long, Long> mapKeys = hashMap.get(name);\n+            System.out.println(\"table \" + name + \" key size \" + table.keySet().size() +\n+                    \" hashMap size \" + mapKeys.size());\n+\n+            assertThat(mapKeys.keySet().containsAll(table.keySet())).isTrue();\n+            assertThat(table.keySet().containsAll(mapKeys.keySet())).isTrue();\n+            assertThat(table.keySet().size() == mapKeys.keySet().size()).isTrue();\n+\n+            for (Long key : mapKeys.keySet()) {\n+                assertThat(table.get(key)).isEqualTo(mapKeys.get(key));\n+            }\n+        }\n+    }\n+\n+    public static void verifyTable(String tag, HashMap<String, CorfuTable<Long, Long>> tables, HashMap<String, CorfuTable<Long, Long>> hashMap) {\n+        System.out.println(\"\\n\" + tag);\n+        for (String name : hashMap.keySet()) {\n+            CorfuTable<Long, Long> table = tables.get(name);\n+            CorfuTable<Long, Long> mapKeys = hashMap.get(name);\n+            System.out.println(\"table \" + name + \" key size \" + table.keySet().size() +\n+                    \" hashMap size \" + mapKeys.size());\n+\n+            assertThat(mapKeys.keySet().containsAll(table.keySet())).isTrue();\n+            assertThat(table.keySet().containsAll(mapKeys.keySet())).isTrue();\n+            assertThat(table.keySet().size() == mapKeys.keySet().size()).isTrue();\n+\n+            for (Long key : mapKeys.keySet()) {\n+                assertThat(table.get(key)).isEqualTo(mapKeys.get(key));\n+            }\n+        }\n+    }\n+\n+    public static void verifyNoData(HashMap<String, CorfuTable<Long, Long>> tables) {\n+        for (CorfuTable table : tables.values()) {\n+            assertThat(table.keySet().isEmpty()).isTrue();\n+        }\n+    }\n+\n+\n+    void verifyTxStream(CorfuRuntime rt) {\n+        StreamOptions options = StreamOptions.builder()\n+                .cacheEntries(false)\n+                .build();\n+\n+        IStreamView txStream = rt.getStreamsView().getUnsafe(ObjectsView.TRANSACTION_STREAM_ID, options);\n+        List<ILogData> dataList = txStream.remaining();\n+        System.out.println(\"\\ndataList size \" + dataList.size());\n+        for (ILogData data : txStream.remaining()) {\n+            System.out.println(data);\n+        }\n+    }\n+\n+    public static void printTails(String tag, CorfuRuntime rt0, CorfuRuntime rt1) {\n+        System.out.println(\"\\n\" + tag);\n+        System.out.println(\"src dataTail \" + rt0.getAddressSpaceView().getLogTail());\n+        System.out.println(\"dst dataTail \" + rt1.getAddressSpaceView().getLogTail());\n+\n+    }\n+\n+    public static void readSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) {\n+        readSnapLogMsgs(msgQ, streams, rt, false);\n+    }\n+\n+    public static void readSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt, boolean blockOnSem)  {\n+        int cnt = 0;\n+        LogReplicationConfig config = new LogReplicationConfig(streams, BATCH_SIZE, MAX_MSG_SIZE);\n+        StreamsSnapshotReader reader = new StreamsSnapshotReader(rt, config);\n+\n+        reader.reset(rt.getAddressSpaceView().getLogTail());\n+        while (true) {\n+            cnt++;\n+\n+            SnapshotReadMessage snapshotReadMessage = reader.read(snapshotSyncId);\n+            for (LogReplicationEntry data : snapshotReadMessage.getMessages()) {\n+                msgQ.add(data);\n+                System.out.println(\"generate msg \" + cnt);\n+            }\n+\n+            if (snapshotReadMessage.isEndRead()) {\n+                break;\n+            }\n+\n+            if  (blockOnSem) {\n+                try {\n+                    waitSem.acquire();\n+                } catch (InterruptedException e) {\n+                    log.info(\"Caught an interrupted exception \", e);\n+                }\n+                blockOnSem = false;\n+            }\n+        }\n+    }\n+\n+    public static void writeSnapLogMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) {\n+        LogReplicationConfig config = new LogReplicationConfig(streams, BATCH_SIZE, MAX_MSG_SIZE);\n+        LogReplicationMetadataManager logReplicationMetadataManager = new LogReplicationMetadataManager(rt, 0, PRIMARY_SITE_ID);\n+        StreamsSnapshotWriter writer = new StreamsSnapshotWriter(rt, config, logReplicationMetadataManager);\n+\n+        if (msgQ.isEmpty()) {\n+            System.out.println(\"msgQ is empty\");\n+        }\n+\n+        long topologyConfigId = msgQ.get(0).getMetadata().getTopologyConfigId();\n+        long snapshot = msgQ.get(0).getMetadata().getSnapshotTimestamp();\n+        logReplicationMetadataManager.setSrcBaseSnapshotStart(topologyConfigId, snapshot);\n+        writer.reset(topologyConfigId, snapshot);\n+\n+        for (LogReplicationEntry msg : msgQ) {\n+            writer.apply(msg);\n+        }\n+\n+        Long seq = writer.getLogReplicationMetadataManager().getLastSnapSeqNum() + 1;\n+        writer.applyShadowStreams(seq);\n+    }\n+\n+    public static void readLogEntryMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt) throws TrimmedException {\n+        readLogEntryMsgs(msgQ, streams, rt, false);\n+    }\n+\n+    public static void readLogEntryMsgs(List<LogReplicationEntry> msgQ, Set<String> streams, CorfuRuntime rt, boolean blockOnce) throws", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484183", "bodyText": "Codacy found an issue: Avoid throwing raw exception types.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:01Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterManager.java", "diffHunk": "@@ -0,0 +1,393 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n+\n+import lombok.Getter;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.infrastructure.NodeDescriptor;\n+import org.corfudb.infrastructure.logreplication.infrastructure.TopologyDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.ClusterRole;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo.TopologyConfigurationMsg;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.CorfuStoreMetadata;\n+import org.corfudb.runtime.Messages;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.CorfuStreamEntries;\n+import org.corfudb.runtime.collections.CorfuStreamEntry;\n+import org.corfudb.runtime.collections.StreamListener;\n+import org.corfudb.runtime.collections.Table;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TableSchema;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.utils.CommonTypes;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+/**\n+ * This class extends CorfuReplicationClusterManagerAdapter, provides topology config API\n+ * for integration tests. The initial topology config should be valid, which means it has only\n+ * one active cluster, and one or more standby clusters.\n+ */\n+@Slf4j\n+public class DefaultClusterManager extends CorfuReplicationClusterManagerBaseAdapter {\n+    public static final String CONFIG_FILE_PATH = \"src/test/resources/corfu_replication_config.properties\";\n+    private static final String DEFAULT_ACTIVE_CLUSTER_NAME = \"primary_site\";\n+    private static final String DEFAULT_STANDBY_CLUSTER_NAME = \"standby_site\";\n+\n+    private static final int NUM_NODES_PER_CLUSTER = 3;\n+\n+    private static final String ACTIVE_CLUSTER_NAME = \"primary_site\";\n+    private static final String STANDBY_CLUSTER_NAME = \"standby_site\";\n+    private static final String ACTIVE_CLUSTER_CORFU_PORT = \"primary_site_corfu_portnumber\";\n+    private static final String STANDBY_CLUSTER_CORFU_PORT = \"standby_site_corfu_portnumber\";\n+    private static final String LOG_REPLICATION_SERVICE_ACTIVE_PORT_NUM = \"primary_site_portnumber\";\n+    private static final String LOG_REPLICATION_SERVICE_STANDBY_PORT_NUM = \"standby_site_portnumber\";\n+\n+    private static final String ACTIVE_CLUSTER_NODE = \"primary_site_node\";\n+    private static final String STANDBY_CLUSTER_NODE = \"standby_site_node\";\n+\n+\n+    public static final String CONFIG_NAMESPACE = \"ns_lr_config_it\";\n+    public static final String CONFIG_TABLE_NAME = \"lr_config_it\";\n+    public static final CommonTypes.Uuid OP_RESUME = CommonTypes.Uuid.newBuilder().setLsb(0L).setMsb(0L).build();\n+    public static final CommonTypes.Uuid OP_SWITCH = CommonTypes.Uuid.newBuilder().setLsb(1L).setMsb(1L).build();\n+    public static final CommonTypes.Uuid OP_TWO_ACTIVE = CommonTypes.Uuid.newBuilder().setLsb(2L).setMsb(2L).build();\n+    public static final CommonTypes.Uuid OP_ALL_STANDBY = CommonTypes.Uuid.newBuilder().setLsb(3L).setMsb(3L).build();\n+    public static final CommonTypes.Uuid OP_INVALID = CommonTypes.Uuid.newBuilder().setLsb(4L).setMsb(4L).build();\n+\n+    @Getter\n+    private long configId;\n+\n+    @Getter\n+    private boolean shutdown;\n+\n+    @Getter\n+    public ClusterManagerCallback clusterManagerCallback;\n+\n+    private Thread thread;\n+\n+    private CorfuRuntime corfuRuntime;\n+\n+    private CorfuStore corfuStore;\n+\n+    private ConfigStreamListener configStreamListener;\n+\n+    public void start() {\n+        configId = 0L;\n+        shutdown = false;\n+        topologyConfig = constructTopologyConfigMsg();\n+        clusterManagerCallback = new ClusterManagerCallback(this);\n+        corfuRuntime = CorfuRuntime.fromParameters(CorfuRuntime.CorfuRuntimeParameters.builder().build())\n+                .parseConfigurationString(\"localhost:9000\")\n+                .setTransactionLogging(true)\n+                .connect();\n+        corfuStore = new CorfuStore(corfuRuntime);\n+        CorfuStoreMetadata.Timestamp ts = corfuStore.getTimestamp();\n+        try {\n+            Table<Messages.Uuid, Messages.Uuid, Messages.Uuid> table = corfuStore.openTable(\n+                    CONFIG_NAMESPACE, CONFIG_TABLE_NAME,\n+                    Messages.Uuid.class, Messages.Uuid.class, Messages.Uuid.class,\n+                    TableOptions.builder().build()\n+            );\n+            table.clear();\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4Ng==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484186", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:02Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/client/IClientChannelAdapter.java", "diffHunk": "@@ -0,0 +1,143 @@\n+package org.corfudb.infrastructure.logreplication.transport.client;\n+\n+import lombok.Getter;\n+\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationClientRouter;\n+\n+import javax.annotation.Nonnull;\n+import java.util.Optional;\n+\n+\n+/**\n+ * Client Transport Adapter.\n+ *\n+ * Log Replication allows the definition of a custom transport layer for communication across clusters.\n+ * This interface must be extended by the client-side adapter to implement a custom channel.\n+ *\n+ * @author annym 05/15/2020\n+ */\n+public abstract class IClientChannelAdapter {\n+\n+\n+    @Getter\n+    private final String localClusterId;\n+\n+    @Getter\n+    private final ClusterDescriptor remoteClusterDescriptor;\n+\n+    @Getter\n+    private final LogReplicationClientRouter router;\n+\n+    @Getter\n+    private IChannelContext channelContext;\n+\n+    /**\n+     * Default Constructor\n+     *\n+     * @param localClusterId local cluster unique identifier\n+     * @param remoteClusterDescriptor descriptor of the remote cluster (standby)\n+     * @param router interface to forward\n+     */\n+    public IClientChannelAdapter(@Nonnull String localClusterId,\n+                                 @Nonnull ClusterDescriptor remoteClusterDescriptor,\n+                                 @Nonnull LogReplicationClientRouter router) {\n+        this.localClusterId = localClusterId;\n+        this.remoteClusterDescriptor = remoteClusterDescriptor;\n+        this.router = router;\n+    }\n+\n+    /**\n+     * Connect Asynchronously to all endpoints specified in the Cluster Descriptor.\n+     */\n+    public void connectAsync() {}\n+\n+    /**\n+     * If connection is lost to a specific endpoint, attempt to reconnect to the specific endpoint.\n+     */\n+    public void connectAsync(String endpoint) {}", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE4OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484189", "bodyText": "Codacy found an issue: Avoid unnecessary if..then..else statements when returning booleans", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:03Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/utils/LogReplicationStreamNameTableManager.java", "diffHunk": "@@ -0,0 +1,187 @@\n+package org.corfudb.infrastructure.logreplication.utils;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.ILogReplicationConfigAdapter;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuStore;\n+import org.corfudb.runtime.collections.Query;\n+import org.corfudb.runtime.collections.TableOptions;\n+import org.corfudb.runtime.collections.TxBuilder;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.utils.CommonTypes;\n+import org.corfudb.utils.LogReplicationStreams;\n+\n+import java.io.File;\n+import java.lang.reflect.InvocationTargetException;\n+import java.net.URL;\n+import java.net.URLClassLoader;\n+import java.util.*;\n+\n+import static org.corfudb.runtime.view.TableRegistry.CORFU_SYSTEM_NAMESPACE;\n+\n+/**\n+ * Handle creation and maintenance of the Corfu table/s containing names of tables\n+ * to be replicated.\n+ * @author pankti-m\n+ */\n+@Slf4j\n+public class LogReplicationStreamNameTableManager {\n+\n+    public static final String LOG_REPLICATION_STREAMS_NAME_TABLE = \"LogReplicationStreams\";\n+    public static final String LOG_REPLICATION_PLUGIN_VERSION_TABLE = \"LogReplicationPluginVersion\";\n+\n+    private ILogReplicationConfigAdapter logReplicationConfigAdapter;\n+\n+    private CorfuRuntime corfuRuntime;\n+\n+    private String pluginConfigFilePath;\n+\n+    public LogReplicationStreamNameTableManager(CorfuRuntime runtime, String pluginConfigFilePath) {\n+        this.pluginConfigFilePath = pluginConfigFilePath;\n+        this.corfuRuntime = runtime;\n+\n+        initStreamNameFetcherPlugin();\n+    }\n+\n+    public Set<String> getStreamsToReplicate() {\n+        // Initialize the streamsToReplicate\n+        if (verifyTableExists(LOG_REPLICATION_PLUGIN_VERSION_TABLE) &&\n+            verifyTableExists(LOG_REPLICATION_STREAMS_NAME_TABLE)) {\n+            // The tables exist but may have been created by another runtime in which case they have to be opened with\n+            // key/value/metadata type info\n+            openExistingTable(LOG_REPLICATION_PLUGIN_VERSION_TABLE);\n+            openExistingTable(LOG_REPLICATION_STREAMS_NAME_TABLE);\n+            if (!tableVersionMatchesPlugin()) {\n+                // delete the tables and recreate them\n+                deleteExistingStreamNameAndVersionTables();\n+                createStreamNameAndVersionTables(\n+                    logReplicationConfigAdapter.fetchStreamsToReplicate());\n+            }\n+        } else {\n+            // If any 1 of the 2 tables does not exist, delete and recreate them both as they may have been corrupted.\n+            deleteExistingStreamNameAndVersionTables();\n+            createStreamNameAndVersionTables(\n+                logReplicationConfigAdapter.fetchStreamsToReplicate());\n+        }\n+        return readStreamsToReplicateFromTable();\n+    }\n+\n+    public boolean isUpgraded() {\n+        if (verifyTableExists(LOG_REPLICATION_PLUGIN_VERSION_TABLE)) {\n+            openExistingTable(LOG_REPLICATION_PLUGIN_VERSION_TABLE);\n+            if (tableVersionMatchesPlugin()) {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5MA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484190", "bodyText": "Codacy found an issue: Class cannot be instantiated and does not provide any static methods or fields", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:04Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/infrastructure/plugins/DefaultClusterConfig.java", "diffHunk": "@@ -0,0 +1,70 @@\n+package org.corfudb.infrastructure.logreplication.infrastructure.plugins;\n+\n+import lombok.Getter;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+public final class DefaultClusterConfig {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Mg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484192", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'MSG_SIZE'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:05Z", "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -0,0 +1,1369 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.Data;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.ObservableAckMsg;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.*;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import static org.corfudb.integration.ReplicationReaderWriterIT.ckStreamsAndTrim;\n+\n+/**\n+ * Test the core components of log replication, namely, Snapshot Sync and Log Entry Sync,\n+ * i.e., the ability to transfer a full view (snapshot) or incremental view of the datastore\n+ * from a source to a destination. In these tests we disregard communication channels between\n+ * clusters (sites) or CorfuLogReplicationServer.\n+ *\n+ * We emulate the channel by implementing a test data plane which directly forwards the data\n+ * to the SinkManager. Overall, these tests bring up two CorfuServers (datastore components),\n+ * one performing as the active and the other as the standby. We write different patterns of data\n+ * on the source (transactional and non transactional, as well as polluted and non-polluted transactions, i.e.,\n+ * transactions containing federated and non-federated streams) and verify that complete data\n+ * reaches the destination after initiating log replication.\n+ */\n+@Slf4j\n+public class LogReplicationIT extends AbstractIT implements Observer {\n+\n+    public final static String nettyConfig = \"src/test/resources/transport/nettyConfig.properties\";\n+\n+    private static final String SOURCE_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String DESTINATION_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+\n+    private static final String ACTIVE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final String REMOTE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final int CORFU_PORT = 9000;\n+    private static final String TABLE_PREFIX = \"test\";\n+\n+    static private final int NUM_KEYS = 10;\n+\n+    static private final int NUM_KEYS_LARGE = 1000;\n+    static private final int NUM_KEYS_VERY_LARGE = 20000;\n+\n+    static private final int NUM_STREAMS = 1;\n+    static private final int TOTAL_STREAM_COUNT = 3;\n+    static private final int WRITE_CYCLES = 4;\n+\n+    static private final int STATE_CHANGE_CHECKS = 20;\n+    static private final int WAIT_STATE_CHANGE = 300;\n+\n+    // If testConfig set deleteOp enabled, will have one delete operation for four put operations.\n+    static private final int DELETE_PACE = 4;\n+\n+    // Number of messages per batch\n+    static private final int BATCH_SIZE = 4;\n+\n+    // each snapshot entry is 33 bytes\n+    // log entry size is 66 bytes or more according to how many streams in one transactions\n+    static private final int MSG_SIZE = 524288;", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484193", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:06Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import java.util.UUID;\n+\n+/**\n+ * An interface for log replication state classes.\n+ *\n+ * All log replication states implement this interface.\n+ */\n+public interface LogReplicationState {\n+\n+    /**\n+     * Get LogReplicationState type.\n+     */\n+    LogReplicationStateType getType();\n+\n+    /**\n+     * Method to process a log replication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationState processEvent(LogReplicationEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationState transitioning from.\n+     */\n+    default void onEntry(LogReplicationState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationState transitioning to.\n+     */\n+    default void onExit(LogReplicationState to) {}\n+\n+    /**\n+     * Provides capability to clear/clean state information onEntry.\n+     */\n+    default void clear() {}", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5Nw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484197", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'delegate'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:07Z", "path": "test/src/test/java/org/corfudb/integration/TestSerializer.java", "diffHunk": "@@ -0,0 +1,42 @@\n+package org.corfudb.integration;\n+\n+import io.netty.buffer.ByteBuf;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.util.serializer.ISerializer;\n+\n+public class TestSerializer implements ISerializer {\n+\n+    private byte typeIdentifier;\n+    private ISerializer delegate = null;", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5OA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484198", "bodyText": "Codacy found an issue: Unnecessary use of fully qualified name 'java.lang.System.currentTimeMillis' due to existing implicit import 'java.lang.*'", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:08Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/receive/SinkBufferManager.java", "diffHunk": "@@ -0,0 +1,184 @@\n+package org.corfudb.infrastructure.logreplication.replication.receive;\n+\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntryMetadata;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import java.util.HashMap;\n+\n+@Slf4j\n+/**\n+ * For snapshot sync and log entry sync, it is possible that the messages generated by the primary cluster will\n+ * be delivered out of order due to message loss due to network connect loss or congestion.\n+ * At the backup/receiver cluster we keep a buffer to store the out of order messages and apply them in order.\n+ * For snapshot sync, the message will be applied according to the message's snapshotSeqNumber.\n+ * For log entry sync, each message has a pre pointer that is a timestamp of the previous message, this guarantees that\n+ * the messages will be applied in order.\n+ *\n+ * At the same time, it eill send an ACK to the primary cluster to notify any possible data loss.\n+ */\n+public abstract class SinkBufferManager {\n+\n+    /*\n+     * The buffer is implemented as a hashmap.\n+     * For logEntry buffer, the key is the entry's previousTimeStamp\n+     * For Snapshot buffer, the key is the previous entry's snapshotSeqNumber\n+     */\n+    public HashMap<Long, LogReplicationEntry> buffer;\n+\n+    /*\n+     * While processing a message in the buffer, it will call\n+     * sinkManager to handle it.\n+     */\n+    public LogReplicationSinkManager sinkManager;\n+\n+    /*\n+     * Could be LOG_ENTRY or SNAPSHOT\n+     */\n+    public MessageType type;\n+\n+    /*\n+     * The max number of entries in the buffer.\n+     */\n+    public int maxSize;\n+\n+    /*\n+     * How frequent in time, the ack will be sent.\n+     */\n+    private int ackCycleTime;\n+\n+    /*\n+     * How frequent in number of messages it has received.\n+     */\n+    private int ackCycleCnt;\n+\n+    /*\n+     * Count the number of messages it has received since last sent ACK.\n+     */\n+    public int ackCnt = 0;\n+\n+    /*\n+     * Time last ack sent.\n+     */\n+    public long ackTime = 0;\n+\n+    /*\n+     * The lastProcessedSeq message's ack value.\n+     * For snapshot, it is the entry's seqNumber.\n+     * For log entry, it is the entry's timestamp.\n+     */\n+    public long lastProcessedSeq;\n+\n+    /**\n+     *\n+     * @param type\n+     * @param ackCycleTime\n+     * @param ackCycleCnt\n+     * @param size\n+     * @param lastProcessedSeq\n+     * @param sinkManager\n+     */\n+    public SinkBufferManager(MessageType type, int ackCycleTime, int ackCycleCnt, int size, long lastProcessedSeq, LogReplicationSinkManager sinkManager) {\n+        this.type = type;\n+        this.ackCycleTime = ackCycleTime;\n+        this.ackCycleCnt = ackCycleCnt;\n+        this.maxSize = size;\n+        this.sinkManager = sinkManager;\n+        this.lastProcessedSeq = lastProcessedSeq;\n+        buffer = new HashMap<>();\n+    }\n+\n+    /**\n+     * After receiving a message, it will decide to send an Ack or not\n+     * according to the predefined metrics.\n+     *\n+     * @return\n+     */\n+    public boolean shouldAck() {\n+        long currentTime = java.lang.System.currentTimeMillis();", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDE5OQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484199", "bodyText": "Codacy found an issue: Fields should be declared at the top of the class, before any method declarations, constructors, initializers or inner classes.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:09Z", "path": "runtime/src/main/java/org/corfudb/runtime/CorfuRuntime.java", "diffHunk": "@@ -77,254 +74,154 @@\n     /**\n      * A class which holds parameters and settings for the {@link CorfuRuntime}.\n      */\n-    @Builder\n     @Data\n     @ToString\n-    public static class CorfuRuntimeParameters {\n-        @Default\n-        private final long nettyShutdownQuitePeriod = 100;\n-        @Default\n-        private final long nettyShutdownTimeout = 300;\n+    public static class CorfuRuntimeParameters extends RuntimeParameters {\n \n-        // region Object Layer Parameters\n+        public static CorfuRuntimeParametersBuilder builder() {\n+            return new CorfuRuntimeParametersBuilder();\n+        }\n \n-        /**\n+        /*\n          * Max size for a write request.\n          */\n-        @Default\n+\n         int maxWriteSize = 0;\n \n-        /**\n+        /*\n          * Set the bulk read size.\n          */\n-        @Default\n+        //@Default\n         int bulkReadSize = 10;\n \n-        /**\n+        /*\n          * How much time the Fast Loader has to get the maps up to date.\n          *\n          * <p>Once the timeout is reached, the Fast Loader gives up. Every map that is\n          * not up to date will be loaded through normal path.\n          */\n-        @Default\n+        //@Default\n         Duration fastLoaderTimeout = Duration.ofMinutes(30);\n         // endregion\n \n         // region Address Space Parameters\n-        /**\n+        /*\n          * Number of times to attempt to read before hole filling.\n          * @deprecated This is a no-op. Use holeFillWait\n-         * */\n+         */\n         @Deprecated\n-        @Default int holeFillRetry = 10;\n+        //@Default\n+        int holeFillRetry = 10;\n \n-        /** Time to wait between read requests reattempts before hole filling. */\n-        @Default Duration holeFillRetryThreshold = Duration.ofSeconds(1L);\n+        /* Time to wait between read requests reattempts before hole filling. */\n+        //@Default\n+        Duration holeFillRetryThreshold = Duration.ofSeconds(1L);\n \n-        /**\n+       /*\n          * Time limit after which the reader gives up and fills the hole.\n          */\n-        @Default Duration holeFillTimeout = Duration.ofSeconds(10);\n+        //@Default\n+        Duration holeFillTimeout = Duration.ofSeconds(10);", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484201", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:10Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationState.java", "diffHunk": "@@ -0,0 +1,57 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import java.util.UUID;\n+\n+/**\n+ * An interface for log replication state classes.\n+ *\n+ * All log replication states implement this interface.\n+ */\n+public interface LogReplicationState {\n+\n+    /**\n+     * Get LogReplicationState type.\n+     */\n+    LogReplicationStateType getType();\n+\n+    /**\n+     * Method to process a log replication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationState processEvent(LogReplicationEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationState transitioning from.\n+     */\n+    default void onEntry(LogReplicationState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationState transitioning to.\n+     */\n+    default void onExit(LogReplicationState to) {}", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484202", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'remoteCluster'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:11Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/fsm/LogReplicationFSM.java", "diffHunk": "@@ -0,0 +1,383 @@\n+package org.corfudb.infrastructure.logreplication.replication.fsm;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.DataSender;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogEntrySender;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.ReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.SnapshotSender;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.view.Address;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.LinkedBlockingQueue;\n+\n+\n+/**\n+ * This class implements the Log Replication Finite State Machine.\n+ *\n+ * CorfuDB provides a Log Replication functionality, which allows logs to be automatically replicated from a primary\n+ * to a remote cluster. This feature is particularly useful in the event of failure or data corruption, so the system\n+ * can failover to the standby/secondary data-store.\n+ *\n+ * This functionality is initiated by the application through the LogReplicationSourceManager on the primary cluster and handled\n+ * through the LogReplicationSinkManager on the destination cluster. This implementation assumes that the application provides its own\n+ * communication channels.\n+ *\n+ * Log Replication on the source cluster is defined by an event-driven finite state machine, with 5 states\n+ * and 8 events/messages---which can trigger the transition between states.\n+ *\n+ * States:\n+ * ------\n+ *  - Initialized (initial state)\n+ *  - In_Log_Entry_Sync\n+ *  - In_Snapshot_Sync\n+ *  - Snapshot_Sync_Required\n+ *  - Stopped\n+ *\n+ * Events:\n+ * ------\n+ *  - replication_start\n+ *  - replication_stop\n+ *  - snapshot_sync_request\n+ *  - snapshot_sync_complete\n+ *  - snapshot_sync_continue\n+ *  - sync_cancel\n+ *  - log_entry_sync_replicated\n+ *  - replication_shutdown\n+ *\n+ *\n+ * The following diagram illustrates the Log Replication FSM state transition:\n+ *\n+ *\n+ *                                       replication_stop\n+ *                      +-------------------------------------------------+\n+ *    replication_stop  |                                                 |\n+ *             +-----+  |              replication_stop                   |\n+ *             |     |  v      v-----------------------------+            |\n+ *             |    ++--+---------+                          |        +---+--------------------+\n+ *             +--->+ INITIALIZED +------------------------+ |        | SNAPSHOT_SYNC_REQUIRED +<---+\n+ *                  +---+----+----+ snapshot_sync_request  | |        +---+---------------+----+    |\n+ *                      ^    |                             | |            |               ^         |\n+ *                      |    |                             | |   snapshot |               |         |\n+ *                      |    |                             | |    sync    |               |         |\n+ *     replication_stop |    | replication_start           | |    request |               |         |\n+ *                      |    |                             | |            |               |         |\n+ *                      |    v                             v |            v               |         |\n+ *               +------+----+-------+  snapshot_sync    +-+-+------------+-+             |         |\n+ *         +-----| IN_LOG_ENTRY_SYNC |     request       | IN_SNAPSHOT_SYNC +             |         |\n+ *         |     |                   +------------------>+                  |             |         |\n+ *         |     +----+----+---------+                   +---+---+----------+-------------+         |\n+ *         |       ^  |   ^                                 |    |        ^        sync             |\n+ *         |       |  |   +---------------------------------+    |        |       cancel            |\n+ *         + ----- +  |                snapshot_sync             + -------+                         |\n+ *  log_entry_sync    |                  complete               snapshot_sync                       |\n+ *    continue        |                                           continue                          |\n+ *                    +-----------------------------------------------------------------------------+\n+ *                                                     sync_cancel\n+ *               replication\n+ * +---------+    shutdown    +------------+\n+ * | STOPPED +<---------------+ ALL_STATES |\n+ * +---------+                +------------+\n+ *\n+ *\n+ */\n+// TODO(Anny): insert new state to comply with SNAPSHOT_WAIT_COMPLETE event\n+@Slf4j\n+public class LogReplicationFSM {\n+\n+    @Getter\n+    private long topologyConfigId;\n+\n+    /**\n+     * Current state of the FSM.\n+     */\n+    @Getter\n+    private volatile LogReplicationState state;\n+\n+    /**\n+     * Map of all Log Replication FSM States (reuse single instance for each state)\n+     */\n+    @Getter\n+    private Map<LogReplicationStateType, LogReplicationState> states = new HashMap<>();\n+\n+    /**\n+     * Executor service for FSM state tasks (it can be shared across several LogReplicationFSMs)\n+     */\n+    @Getter\n+    private ExecutorService logReplicationFSMWorkers;\n+\n+    /**\n+     * Executor service for FSM event queue consume\n+     */\n+    private ExecutorService logReplicationFSMConsumer;\n+\n+    /**\n+     * A queue of events.\n+     */\n+    private final LinkedBlockingQueue<LogReplicationEvent> eventQueue = new LinkedBlockingQueue<>();\n+\n+    /**\n+     * An observable object on the number of transitions of this state machine (for testing & visibility)\n+     */\n+    @VisibleForTesting\n+    @Getter\n+    private ObservableValue numTransitions = new ObservableValue(0);\n+\n+    /**\n+     * Log Entry Reader (read incremental updated from Corfu Datatore)\n+     */\n+    private LogEntryReader logEntryReader;\n+\n+    /**\n+     * Snapshot Reader (read data from Corfu Datastore)\n+     */\n+    private SnapshotReader snapshotReader;\n+\n+    /**\n+     * Version on which snapshot sync is based on.\n+     */\n+    @Getter\n+    private long baseSnapshot = Address.NON_ADDRESS;\n+\n+    /**\n+     * Acknowledged timestamp\n+     */\n+    @Getter\n+    private long ackedTimestamp = Address.NON_ADDRESS;\n+\n+    /**\n+     * Log Entry Sender (send incremental updates to remote cluster)\n+     */\n+    private LogEntrySender logEntrySender;\n+\n+    /**\n+     * Snapshot Sender (send snapshot cut to remote cluster)\n+     */\n+    private SnapshotSender snapshotSender;\n+\n+    /**\n+     * Remote Cluster Descriptor to which this FSM drives the log replication\n+     */\n+    private final ClusterDescriptor remoteCluster;", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484203", "bodyText": "Codacy found an issue: Avoid unused private fields such as 'sourceServer'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:12Z", "path": "test/src/test/java/org/corfudb/integration/LogReplicationIT.java", "diffHunk": "@@ -0,0 +1,1369 @@\n+package org.corfudb.integration;\n+\n+import com.google.common.reflect.TypeToken;\n+import lombok.Data;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationSourceManager;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.ObservableAckMsg;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.util.serializer.Serializers;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.*;\n+\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+\n+import static org.corfudb.integration.ReplicationReaderWriterIT.ckStreamsAndTrim;\n+\n+/**\n+ * Test the core components of log replication, namely, Snapshot Sync and Log Entry Sync,\n+ * i.e., the ability to transfer a full view (snapshot) or incremental view of the datastore\n+ * from a source to a destination. In these tests we disregard communication channels between\n+ * clusters (sites) or CorfuLogReplicationServer.\n+ *\n+ * We emulate the channel by implementing a test data plane which directly forwards the data\n+ * to the SinkManager. Overall, these tests bring up two CorfuServers (datastore components),\n+ * one performing as the active and the other as the standby. We write different patterns of data\n+ * on the source (transactional and non transactional, as well as polluted and non-polluted transactions, i.e.,\n+ * transactions containing federated and non-federated streams) and verify that complete data\n+ * reaches the destination after initiating log replication.\n+ */\n+@Slf4j\n+public class LogReplicationIT extends AbstractIT implements Observer {\n+\n+    public final static String nettyConfig = \"src/test/resources/transport/nettyConfig.properties\";\n+\n+    private static final String SOURCE_ENDPOINT = DEFAULT_HOST + \":\" + DEFAULT_PORT;\n+    private static final int WRITER_PORT = DEFAULT_PORT + 1;\n+    private static final String DESTINATION_ENDPOINT = DEFAULT_HOST + \":\" + WRITER_PORT;\n+\n+    private static final String ACTIVE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final String REMOTE_CLUSTER_ID = UUID.randomUUID().toString();\n+    private static final int CORFU_PORT = 9000;\n+    private static final String TABLE_PREFIX = \"test\";\n+\n+    static private final int NUM_KEYS = 10;\n+\n+    static private final int NUM_KEYS_LARGE = 1000;\n+    static private final int NUM_KEYS_VERY_LARGE = 20000;\n+\n+    static private final int NUM_STREAMS = 1;\n+    static private final int TOTAL_STREAM_COUNT = 3;\n+    static private final int WRITE_CYCLES = 4;\n+\n+    static private final int STATE_CHANGE_CHECKS = 20;\n+    static private final int WAIT_STATE_CHANGE = 300;\n+\n+    // If testConfig set deleteOp enabled, will have one delete operation for four put operations.\n+    static private final int DELETE_PACE = 4;\n+\n+    // Number of messages per batch\n+    static private final int BATCH_SIZE = 4;\n+\n+    // each snapshot entry is 33 bytes\n+    // log entry size is 66 bytes or more according to how many streams in one transactions\n+    static private final int MSG_SIZE = 524288;\n+\n+    static private final int SMALL_MSG_SIZE = 200;\n+\n+    static private TestConfig testConfig = new TestConfig();\n+\n+    private Process sourceServer;", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484204", "bodyText": "Codacy found an issue: JUnit tests should include assert() or fail()", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:13Z", "path": "test/src/test/java/org/corfudb/infrastructure/logreplication/LogReplicationFSMTest.java", "diffHunk": "@@ -0,0 +1,588 @@\n+package org.corfudb.infrastructure.logreplication;\n+\n+import com.google.common.reflect.TypeToken;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.common.compression.Codec;\n+import org.corfudb.common.util.ObservableValue;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.proto.LogReplicationClusterInfo;\n+import org.corfudb.infrastructure.logreplication.replication.LogReplicationAckReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptyDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.EmptySnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.InSnapshotSyncState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationFSM;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationState;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationStateType;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestDataSender;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestLogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestReaderConfiguration;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.TestSnapshotReader;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.infrastructure.logreplication.replication.send.LogReplicationEventMetadata;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.DefaultReadProcessor;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.LogEntryReader;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.StreamsSnapshotReader;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.infrastructure.logreplication.replication.send.logreader.SnapshotReader;\n+import org.corfudb.protocols.wireprotocol.TokenResponse;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.infrastructure.logreplication.replication.fsm.LogReplicationEvent.LogReplicationEventType;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.runtime.view.Address;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Observable;\n+import java.util.Observer;\n+import java.util.Queue;\n+import java.util.UUID;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Semaphore;\n+\n+import static java.lang.Thread.sleep;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+@Slf4j\n+/**\n+ * Test Log Replication FSM.\n+ */\n+public class LogReplicationFSMTest extends AbstractViewTest implements Observer {\n+\n+    // Parameters for writes\n+    private static final int NUM_ENTRIES = 10;\n+    private static final int LARGE_NUM_ENTRIES = 100;\n+    private static final String PAYLOAD_FORMAT = \"%s hello world\";\n+    private static final String TEST_STREAM_NAME = \"StreamA\";\n+    private static final int BATCH_SIZE = 2;\n+    private static final int WAIT_TIME = 100;\n+    private static final int CORFU_PORT = 9000;\n+    private static final int TEST_TOPOLOGY_CONFIG_ID = 1;\n+    private static final String TEST_LOCAL_CLUSTER_ID = \"local_cluster\";\n+\n+    // This semaphore is used to block until the triggering event causes the transition to a new state\n+    private final Semaphore transitionAvailable = new Semaphore(1, true);\n+    // We observe the transition counter to know that a transition occurred.\n+    private ObservableValue transitionObservable;\n+\n+    // Flag indicating if we should observer a snapshot sync, this is to interrupt it at any given stage\n+    private boolean observeSnapshotSync = false;\n+    private int limitSnapshotMessages = 0;\n+    private ObservableValue snapshotMessageCounterObservable;\n+\n+    private LogReplicationFSM fsm;\n+    private CorfuRuntime runtime;\n+    private DataSender dataSender;\n+    private SnapshotReader snapshotReader;\n+    private LogEntryReader logEntryReader;\n+    private LogReplicationAckReader ackReader;\n+\n+    @Before\n+    public void setRuntime() {\n+        runtime = getDefaultRuntime();\n+        runtime.getParameters().setCodecType(Codec.Type.NONE);\n+    }\n+\n+    @After\n+    public void stopAckReader() {\n+        ackReader.shutdown();\n+    }\n+\n+    /**\n+     * Verify state machine behavior in the most simple (no error) path.\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) None -> verify FSM initial state is INITIALIZED\n+     * (2) Replication Stop -> verify it stays in the INITIALIZED state as replication has not been started\n+     * (3) Replication Start -> IN_LOG_ENTRY_SYNC state\n+     * (4) Snapshot Sync Request -> IN_SNAPSHOT_SYNC state\n+     * (5) Snapshot Sync Complete -> IN_LOG_ENTRY_SYNC state\n+     * (6) Replication Stop -> back to INITIALIZED state\n+     *\n+     */\n+    @Test\n+    public void testLogReplicationFSMTransitions() throws Exception {\n+\n+        initLogReplicationFSM(ReaderImplementation.EMPTY);\n+\n+        // Initial state: Initialized\n+        LogReplicationState initState = fsm.getState();\n+        assertThat(initState.getType()).isEqualTo(LogReplicationStateType.INITIALIZED);\n+\n+        transitionAvailable.acquire();\n+\n+        // Transition #1: Replication Stop (without any replication having started)\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED);\n+\n+        // Transition #2: Replication Start\n+        transition(LogReplicationEventType.REPLICATION_START, LogReplicationStateType.IN_LOG_ENTRY_SYNC);\n+\n+        // Transition #3: Snapshot Sync Request\n+        UUID snapshotSyncId = transition(LogReplicationEventType.SNAPSHOT_SYNC_REQUEST, LogReplicationStateType.IN_SNAPSHOT_SYNC, true);\n+\n+        // Transition #4: Snapshot Sync Complete\n+        transition(LogReplicationEventType.SNAPSHOT_SYNC_COMPLETE, LogReplicationStateType.IN_LOG_ENTRY_SYNC, snapshotSyncId, false);\n+\n+        // Transition #5: Stop Replication\n+        // Next transition might not be to INITIALIZED, as IN_LOG_ENTRY_SYNC state might have enqueued\n+        // a continuation before the stop is enqueued.\n+        transition(LogReplicationEventType.REPLICATION_STOP, LogReplicationStateType.INITIALIZED, true);\n+    }\n+\n+    /**\n+     * Test Trim Exception Events for Log Replication FSM\n+     *\n+     * This is the sequence of events triggered and expected state change:\n+     *\n+     * (1) Snapshot Sync Request => IN_SNAPSHOT_SYNC state\n+     * (2) Trimmed Exception (incorrect id) => IN_LOG_ENTRY_SYNC\n+     * (3) Trimmed Exception (for state in (5)) => IN_REQUIRE_SNAPSHOT_SYNC\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testTrimExceptionFSM() throws Exception {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484206", "bodyText": "Codacy found an issue: Avoid unused private methods such as 'calculateOpaqueSMREntrySerializedSize()'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:14Z", "path": "runtime/src/main/java/org/corfudb/protocols/logprotocol/SMREntry.java", "diffHunk": "@@ -103,26 +112,64 @@ public SMREntry(String smrMethod, @NonNull Object[] smrArguments, ISerializer se\n      */\n     @Override\n     void deserializeBuffer(ByteBuf b, CorfuRuntime rt) {\n+        int readIndex = b.readerIndex();\n+\n         super.deserializeBuffer(b, rt);\n         short methodLength = b.readShort();\n         byte[] methodBytes = new byte[methodLength];\n         b.readBytes(methodBytes, 0, methodLength);\n         SMRMethod = new String(methodBytes);\n-        serializerType = Serializers.getSerializer(b.readByte());\n+        byte serializerId = b.readByte();\n         byte numArguments = b.readByte();\n         Object[] arguments = new Object[numArguments];\n+\n+        if (!opaque) {\n+            serializerType = Serializers.getSerializer(serializerId);\n+        } else {\n+            this.serializerId = serializerId;\n+        }\n+\n         for (byte arg = 0; arg < numArguments; arg++) {\n             int len = b.readInt();\n             ByteBuf objBuf = b.slice(b.readerIndex(), len);\n-            arguments[arg] = serializerType.deserialize(objBuf, rt);\n+            if (opaque) {\n+                byte[] argBytes = new byte[len];\n+                objBuf.readBytes(argBytes);\n+                arguments[arg] = argBytes;\n+            } else {\n+                arguments[arg] = serializerType.deserialize(objBuf, rt);\n+            }\n             b.skipBytes(len);\n         }\n         SMRArguments = arguments;\n+        serializedSize = b.readerIndex() - readIndex + 1;\n+    }\n+\n+\n+    /**\n+     * Calculate an Opaque SMR entry's serialized size.\n+     * @throws IllegalAccessException\n+     */\n+    private int calculateOpaqueSMREntrySerializedSize() {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484207", "bodyText": "Codacy found an issue: Avoid unused private methods such as 'handleLogReplicationEntry(CorfuPayloadMsg,ChannelHandlerContext,IServerRouter)'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:15Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelHandlerContext;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationLeadershipLoss;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationQueryLeaderShipResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import javax.annotation.Nonnull;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * This class represents the Log Replication Server, which is\n+ * responsible of providing Log Replication across sites.\n+ *\n+ * The Log Replication Server, handles log replication entries--which\n+ * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n+ * and also handles negotiation messages, which allows the Source Replicator\n+ * to get a view of the last synchronized point at the remote cluster.\n+ */\n+@Slf4j\n+public class LogReplicationServer extends AbstractServer {\n+\n+    private final ServerContext serverContext;\n+\n+    private final ExecutorService executor;\n+\n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    @Getter\n+    private final LogReplicationSinkManager sinkManager;\n+\n+    private final AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private final AtomicBoolean isActive = new AtomicBoolean(false);\n+\n+    @Getter\n+    private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n+\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull LogReplicationMetadataManager metadataManager, String corfuEndpoint,\n+                                long topologyConfigId) {\n+        this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext, topologyConfigId);\n+\n+        this.executor = Executors.newFixedThreadPool(1,\n+                new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));\n+    }\n+\n+    /* ************ Override Methods ************ */\n+\n+    @Override\n+    public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n+        return getState() == ServerState.READY;\n+    }\n+\n+    @Override\n+    protected void processRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n+        executor.submit(() -> getHandler().handle(msg, ctx, r));\n+    }\n+\n+    @Override\n+    public void shutdown() {\n+        super.shutdown();\n+        executor.shutdown();\n+    }\n+\n+    /* ************ Server Handlers ************ */\n+\n+    @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n+    private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIwOA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484208", "bodyText": "Codacy found an issue: JUnit tests should include assert() or fail()", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:16Z", "path": "test/src/test/java/org/corfudb/runtime/view/stream/OpaqueStreamTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+package org.corfudb.runtime.view.stream;\n+\n+import com.google.common.reflect.TypeToken;\n+import org.corfudb.CustomSerializer;\n+import org.corfudb.protocols.logprotocol.MultiSMREntry;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.wireprotocol.Token;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.MultiCheckpointWriter;\n+import org.corfudb.runtime.collections.CorfuTable;\n+import org.corfudb.runtime.exceptions.SerializerException;\n+import org.corfudb.runtime.view.AbstractViewTest;\n+import org.corfudb.util.serializer.ISerializer;\n+import org.corfudb.util.serializer.Serializers;\n+\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import org.junit.Test;\n+\n+import java.util.UUID;\n+import java.util.stream.Stream;\n+\n+public class OpaqueStreamTest extends AbstractViewTest {\n+\n+    @Test\n+    public void testMagicByte() {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIxNA==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484214", "bodyText": "Codacy found an issue: Avoid unused method parameters such as 'ctx'.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:17Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationServer.java", "diffHunk": "@@ -0,0 +1,165 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelHandlerContext;\n+import lombok.Getter;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationSinkManager;\n+import org.corfudb.infrastructure.logreplication.replication.receive.LogReplicationMetadataManager;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.protocols.wireprotocol.CorfuPayloadMsg;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationLeadershipLoss;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationNegotiationResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationQueryLeaderShipResponse;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+\n+import javax.annotation.Nonnull;\n+import java.lang.invoke.MethodHandles;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+/**\n+ * This class represents the Log Replication Server, which is\n+ * responsible of providing Log Replication across sites.\n+ *\n+ * The Log Replication Server, handles log replication entries--which\n+ * represent parts of a Snapshot (full) sync or a Log Entry (delta) sync\n+ * and also handles negotiation messages, which allows the Source Replicator\n+ * to get a view of the last synchronized point at the remote cluster.\n+ */\n+@Slf4j\n+public class LogReplicationServer extends AbstractServer {\n+\n+    private final ServerContext serverContext;\n+\n+    private final ExecutorService executor;\n+\n+    @Getter\n+    private final LogReplicationMetadataManager metadataManager;\n+\n+    @Getter\n+    private final LogReplicationSinkManager sinkManager;\n+\n+    private final AtomicBoolean isLeader = new AtomicBoolean(false);\n+\n+    private final AtomicBoolean isActive = new AtomicBoolean(false);\n+\n+    @Getter\n+    private final HandlerMethods handler = HandlerMethods.generateHandler(MethodHandles.lookup(), this);\n+\n+    public LogReplicationServer(@Nonnull ServerContext context, @Nonnull  LogReplicationConfig logReplicationConfig,\n+                                @Nonnull LogReplicationMetadataManager metadataManager, String corfuEndpoint,\n+                                long topologyConfigId) {\n+        this.serverContext = context;\n+        this.metadataManager = metadataManager;\n+        this.sinkManager = new LogReplicationSinkManager(corfuEndpoint, logReplicationConfig, metadataManager, serverContext, topologyConfigId);\n+\n+        this.executor = Executors.newFixedThreadPool(1,\n+                new ServerThreadFactory(\"LogReplicationServer-\", new ServerThreadFactory.ExceptionHandler()));\n+    }\n+\n+    /* ************ Override Methods ************ */\n+\n+    @Override\n+    public boolean isServerReadyToHandleMsg(CorfuMsg msg) {\n+        return getState() == ServerState.READY;\n+    }\n+\n+    @Override\n+    protected void processRequest(CorfuMsg msg, ChannelHandlerContext ctx, IServerRouter r) {\n+        executor.submit(() -> getHandler().handle(msg, ctx, r));\n+    }\n+\n+    @Override\n+    public void shutdown() {\n+        super.shutdown();\n+        executor.shutdown();\n+    }\n+\n+    /* ************ Server Handlers ************ */\n+\n+    @ServerHandler(type = CorfuMsgType.LOG_REPLICATION_ENTRY)\n+    private void handleLogReplicationEntry(CorfuPayloadMsg<LogReplicationEntry> msg, ChannelHandlerContext ctx, IServerRouter r) {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIyMg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484222", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:18Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/LogReplicationClientRouter.java", "diffHunk": "@@ -0,0 +1,436 @@\n+package org.corfudb.infrastructure.logreplication.runtime;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n+\n+import org.corfudb.infrastructure.LogReplicationRuntimeParameters;\n+import org.corfudb.infrastructure.logreplication.infrastructure.plugins.LogReplicationPluginConfig;\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.infrastructure.logreplication.runtime.fsm.LogReplicationRuntimeEvent;\n+import org.corfudb.infrastructure.logreplication.utils.CorfuMessageConverterUtils;\n+import org.corfudb.protocols.wireprotocol.CorfuMsg;\n+import org.corfudb.protocols.wireprotocol.CorfuMsgType;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.runtime.clients.IClient;\n+import org.corfudb.runtime.clients.IClientRouter;\n+import org.corfudb.runtime.exceptions.NetworkException;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuError;\n+import org.corfudb.runtime.exceptions.unrecoverable.UnrecoverableCorfuInterruptedError;\n+import org.corfudb.infrastructure.logreplication.transport.client.ChannelAdapterException;\n+import org.corfudb.infrastructure.logreplication.transport.client.IClientChannelAdapter;\n+import org.corfudb.util.CFUtils;\n+import org.corfudb.utils.common.CorfuMessageProtoBufException;\n+\n+import java.io.File;\n+import java.net.URL;\n+import java.net.URLClassLoader;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+/**\n+ * This Client Router is used when a custom (client-defined) transport layer is specified for\n+ * Log Replication Server communication.\n+ *\n+ */\n+@Slf4j\n+public class LogReplicationClientRouter implements IClientRouter {\n+\n+    @Getter\n+    private LogReplicationRuntimeParameters parameters;\n+\n+    /**\n+     * The handlers registered to this router.\n+     */\n+    private final Map<CorfuMsgType, IClient> handlerMap;\n+\n+    /**\n+     * The clients registered to this router.\n+     */\n+    public final List<IClient> clientList;\n+\n+    /**\n+     * Whether or not this router is shutdown.\n+     */\n+    public volatile boolean shutdown;\n+\n+    /**\n+     * A {@link CompletableFuture} which is completed when a connection,\n+     * including a successful handshake completes and messages can be sent\n+     * to the remote node.\n+     */\n+    @Getter\n+    private volatile CompletableFuture<Void> remoteLeaderConnectionFuture;\n+\n+    /**\n+     * The current request ID.\n+     */\n+    @Getter\n+    @SuppressWarnings(\"checkstyle:abbreviation\")\n+    public AtomicLong requestID;\n+\n+    /**\n+     * Sync call response timeout (milliseconds).\n+     */\n+    @Getter\n+    @Setter\n+    public long timeoutResponse;\n+\n+    /**\n+     * The outstanding requests on this router.\n+     */\n+    public final Map<Long, CompletableFuture> outstandingRequests;\n+\n+    /**\n+     * Adapter to the channel implementation\n+     */\n+    private IClientChannelAdapter channelAdapter;\n+\n+    /**\n+     * Remote Cluster/Site Full Descriptor\n+     */\n+    private ClusterDescriptor remoteClusterDescriptor;\n+\n+    /**\n+     * Remote Cluster/Site unique identifier\n+     */\n+    private String remoteClusterId;\n+\n+    /**\n+     * Runtime FSM, to insert connectivity events\n+     */\n+    private CorfuLogReplicationRuntime runtimeFSM;\n+\n+    /**\n+     * Log Replication Client Constructor\n+     *\n+     * @param parameters runtime parameters (including connection settings)\n+     * @param runtimeFSM runtime state machine, insert connection related events\n+     */\n+    public LogReplicationClientRouter(LogReplicationRuntimeParameters parameters,\n+                                      CorfuLogReplicationRuntime runtimeFSM) {\n+        this.remoteClusterDescriptor = parameters.getRemoteClusterDescriptor();\n+        this.remoteClusterId = remoteClusterDescriptor.getClusterId();\n+        this.parameters = parameters;\n+        this.timeoutResponse = parameters.getRequestTimeout().toMillis();\n+        this.runtimeFSM = runtimeFSM;\n+\n+        this.handlerMap = new ConcurrentHashMap<>();\n+        this.clientList = new ArrayList<>();\n+        this.requestID = new AtomicLong();\n+        this.outstandingRequests = new ConcurrentHashMap<>();\n+        this.remoteLeaderConnectionFuture = new CompletableFuture<>();\n+    }\n+\n+    // ------------------- IClientRouter Interface ----------------------\n+\n+    @Override\n+    public IClientRouter addClient(IClient client) {\n+        // Set the client's router to this instance.\n+        client.setRouter(this);\n+\n+        // Iterate through all types of CorfuMsgType, registering the handler\n+        client.getHandledTypes().stream()\n+                .forEach(x -> {\n+                    handlerMap.put(x, client);\n+                    log.info(\"Registered {} to handle messages of type {}\", client, x);\n+                });\n+\n+        // Register this type\n+        clientList.add(client);\n+        return this;\n+    }\n+\n+    @Override\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message) {\n+        return sendMessageAndGetCompletable(message, null);\n+    }\n+\n+    public <T> CompletableFuture<T> sendMessageAndGetCompletable(CorfuMsg message, String endpoint) {\n+        if (isValidMessage(message)) {\n+            // Get the next request ID.\n+            final long requestId = requestID.getAndIncrement();\n+\n+            // Generate a future and put it in the completion table.\n+            final CompletableFuture<T> cf = new CompletableFuture<>();\n+            outstandingRequests.put(requestId, cf);\n+\n+            try {\n+                message.setClientID(parameters.getClientId());\n+                message.setRequestID(requestId);\n+\n+                // If no endpoint is specified, the message is to be sent to the remote leader node.\n+                // We should block until a connection to the leader is established.\n+                if (endpoint == null || endpoint.length() == 0) {\n+                    // Check the connection future. If connected, continue with sending the message.\n+                    // If timed out, return a exceptionally completed with the timeout.\n+                    // Because in Log Replication, messages are sent to the leader node, the connection future\n+                    // represents a connection to the leader.\n+                    try {\n+                        remoteLeaderConnectionFuture\n+                                .get(getParameters().getConnectionTimeout().toMillis(), TimeUnit.MILLISECONDS);\n+                    } catch (InterruptedException e) {\n+                        throw new UnrecoverableCorfuInterruptedError(e);\n+                    } catch (TimeoutException | ExecutionException te) {\n+                        cf.completeExceptionally(te);\n+                        return cf;\n+                    }\n+\n+                    // Get Remote Leader\n+                    if(runtimeFSM.getRemoteLeader().isPresent()) {\n+                        endpoint = runtimeFSM.getRemoteLeader().get();\n+                    } else {\n+                        log.error(\"Leader not found to remote cluster {}\", remoteClusterId);\n+                        runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+                        throw new ChannelAdapterException(\n+                                String.format(\"Leader not found to remote cluster %s\", remoteClusterDescriptor.getClusterId()));\n+                    }\n+                }\n+\n+                // In the case the message is intended for a specific endpoint, we do not\n+                // block on connection future, this is the case of leader verification.\n+                log.info(\"Send message to {}, type={}\", endpoint, message.getMsgType());\n+                channelAdapter.send(endpoint, CorfuMessageConverterUtils.toProtoBuf(message));\n+\n+            } catch (NetworkException ne) {\n+                log.error(\"Caught Network Exception while trying to send message to remote leader {}\", endpoint);\n+                runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.ON_CONNECTION_DOWN,\n+                        endpoint));\n+                throw ne;\n+            } catch (Exception e) {\n+                outstandingRequests.remove(requestId);\n+                log.error(\"sendMessageAndGetCompletable: Remove request {} to {} due to exception! Message:{}\",\n+                        requestId, remoteClusterId, message, e);\n+                cf.completeExceptionally(e);\n+                return cf;\n+            }\n+\n+            // Generate a timeout future, which will complete exceptionally\n+            // if the main future is not completed.\n+            final CompletableFuture<T> cfTimeout =\n+                    CFUtils.within(cf, Duration.ofMillis(timeoutResponse));\n+            cfTimeout.exceptionally(e -> {\n+                if (e.getCause() instanceof TimeoutException) {\n+                    outstandingRequests.remove(requestId);\n+                    log.debug(\"sendMessageAndGetCompletable: Remove request {} to {} due to timeout! Message:{}\",\n+                            requestId, remoteClusterId, message);\n+                }\n+                return null;\n+            });\n+\n+            return cfTimeout;\n+        }\n+\n+        log.error(\"Invalid message type {}. Currently only log replication messages are processed.\");\n+        CompletableFuture<T> f = new CompletableFuture<>();\n+        f.completeExceptionally(new Throwable(\"Invalid message type\"));\n+        return f;\n+    }\n+\n+    /**\n+     * Send a one way message, without adding a completable future.\n+     *\n+     * @param message The message to send.\n+     */\n+    @Override\n+    public void sendMessage(CorfuMsg message) {\n+        // Get the next request ID.\n+        message.setRequestID(requestID.getAndIncrement());\n+        // Get Remote Leader\n+        if(runtimeFSM.getRemoteLeader().isPresent()) {\n+            String remoteLeader = runtimeFSM.getRemoteLeader().get();\n+            channelAdapter.send(remoteLeader, CorfuMessageConverterUtils.toProtoBuf(message));\n+            log.trace(\"Sent one-way message: {}\", message);\n+        } else {\n+            log.error(\"Leader not found to remote cluster {}, dropping {}\", remoteClusterId, message.getMsgType());\n+            runtimeFSM.input(new LogReplicationRuntimeEvent(LogReplicationRuntimeEvent.LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS));\n+        }\n+    }\n+\n+    @Override\n+    public <T> void completeRequest(long requestID, T completion) {\n+        log.trace(\"Complete request: {}\", requestID);\n+        CompletableFuture<T> cf;\n+        if ((cf = (CompletableFuture<T>) outstandingRequests.remove(requestID)) != null) {\n+            cf.complete(completion);\n+        } else {\n+            log.warn(\"Attempted to complete request {}, but request not outstanding!\", requestID);\n+        }\n+    }\n+\n+    @Override\n+    public void completeExceptionally(long requestID, Throwable cause) {\n+        CompletableFuture cf;\n+        if ((cf = outstandingRequests.remove(requestID)) != null) {\n+            cf.completeExceptionally(cause);\n+            log.debug(\"completeExceptionally: Remove request {} to {} due to {}.\", requestID, remoteClusterId,\n+                    cause.getClass().getSimpleName(), cause);\n+        } else {\n+            log.warn(\"Attempted to exceptionally complete request {}, but request not outstanding!\",\n+                    requestID);\n+        }\n+    }\n+\n+    @Override\n+    public void stop() {\n+        log.debug(\"stop: Shutting down router for {}\", remoteClusterId);\n+        shutdown = true;\n+        channelAdapter.stop();\n+        remoteLeaderConnectionFuture = new CompletableFuture<>();\n+        remoteLeaderConnectionFuture.completeExceptionally(new NetworkException(\"Router stopped\", remoteClusterId));\n+    }\n+\n+    @Override\n+    public Integer getPort() {\n+        // For logging purposes return one port (as this abstraction does not make sense for a Log Replication\n+        // Client Router) as it is a router to an entire cluster/site.\n+        return Integer.valueOf(remoteClusterDescriptor.getNodesDescriptors().iterator().next().getPort());\n+    }\n+\n+    @Override\n+    public String getHost() {\n+        String host = \"\";\n+        // For logging purposes return all remote cluster nodes host in a concatenated form\n+        remoteClusterDescriptor.getNodesDescriptors().forEach(node -> host.concat(node.getHost() + \":\"));\n+        return host;\n+    }\n+\n+    @Override\n+    public void setTimeoutConnect(long timeoutConnect) {", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIyNw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484227", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:19Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/transport/server/IServerChannelAdapter.java", "diffHunk": "@@ -0,0 +1,64 @@\n+package org.corfudb.infrastructure.logreplication.transport.server;\n+\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.corfudb.infrastructure.ServerContext;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.runtime.Messages.CorfuMessage;\n+import org.corfudb.infrastructure.logreplication.runtime.LogReplicationServerRouter;\n+\n+import java.util.concurrent.CompletableFuture;\n+\n+/**\n+ * Server Transport Adapter.\n+ *\n+ * If Log Replication relies on a custom transport protocol for communication across servers,\n+ * this interface must be extended by the server-side adapter to implement a custom channel.\n+ *\n+ * @author annym 05/15/2020\n+ */\n+public abstract class IServerChannelAdapter {\n+\n+    @Getter\n+    private final LogReplicationServerRouter router;\n+\n+    @Getter\n+    private final ServerContext serverContext;\n+\n+    @Getter\n+    @Setter\n+    private IChannelContext channelContext;\n+\n+    public IServerChannelAdapter(ServerContext serverContext, LogReplicationServerRouter adapter) {\n+        this.serverContext = serverContext;\n+        this.router = adapter;\n+    }\n+\n+    /**\n+     * Send message across channel.\n+     *\n+     * @param msg corfu message (protoBuf definition)\n+     */\n+    public abstract void send(CorfuMessage msg);\n+\n+    /**\n+     * Receive a message from Client.\n+     *\n+     * @param msg received corfu message\n+     */\n+    public void receive(CorfuMessage msg) {\n+        getRouter().receive(msg);\n+    }\n+\n+    /**\n+     * Initialize adapter.\n+     *\n+     * @return Completable Future on connection start\n+     */\n+    public abstract CompletableFuture<Boolean> start();\n+\n+    /**\n+     * Close connections or gracefully shutdown the channel.\n+     */\n+    public void stop() {}", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIzMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484233", "bodyText": "Codacy found an issue: Document empty method body", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:20Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/runtime/fsm/LogReplicationRuntimeState.java", "diffHunk": "@@ -0,0 +1,43 @@\n+package org.corfudb.infrastructure.logreplication.runtime.fsm;\n+\n+/**\n+ * An interface for log replication runtime state classes.\n+ *\n+ * All log replication runtime states implement this interface.\n+ *\n+ * @author amartinezman\n+ */\n+public interface LogReplicationRuntimeState {\n+\n+    /**\n+     * Get LogReplicationRuntimeState type.\n+     */\n+    LogReplicationRuntimeStateType getType();\n+\n+    /**\n+     * Method to process a communication event.\n+     *\n+     * @return next LogReplicationState to transition to.\n+     */\n+    LogReplicationRuntimeState processEvent(LogReplicationRuntimeEvent event) throws IllegalTransitionException;\n+\n+    /**\n+     * On Entry\n+     *\n+     * @param from  LogReplicationRuntimeState transitioning from.\n+     */\n+    default void onEntry(LogReplicationRuntimeState from) {}\n+\n+    /**\n+     * On Exit\n+     *\n+     * @param to  LogReplicationRuntimeState transitioning to.\n+     */\n+    default void onExit(LogReplicationRuntimeState to) {}\n+\n+    /**\n+     * Provides capability to clear/clean state information onEntry.\n+     */\n+    default void clear() {}", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4NDIzNg==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467484236", "bodyText": "Codacy found an issue: Perhaps 'rt' could be replaced by a local variable.", "author": "corfudb-bot", "createdAt": "2020-08-08T17:03:21Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/logreplication/replication/send/logreader/StreamsLogEntryReader.java", "diffHunk": "@@ -0,0 +1,305 @@\n+package org.corfudb.infrastructure.logreplication.replication.send.logreader;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import lombok.Getter;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.protocols.logprotocol.OpaqueEntry;\n+import org.corfudb.protocols.logprotocol.SMREntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.LogReplicationEntry;\n+import org.corfudb.protocols.wireprotocol.logreplication.MessageType;\n+import org.corfudb.runtime.CorfuRuntime;\n+import org.corfudb.runtime.exceptions.TrimmedException;\n+import org.corfudb.runtime.view.ObjectsView;\n+import org.corfudb.runtime.view.stream.OpaqueStream;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+import static org.corfudb.infrastructure.logreplication.LogReplicationConfig.MAX_DATA_MSG_SIZE_SUPPORTED;\n+\n+@Slf4j\n+@NotThreadSafe\n+/**\n+ * Reading transaction log changes after a snapshot transfer for a specific set of streams.\n+ */\n+public class StreamsLogEntryReader implements LogEntryReader {\n+\n+    private CorfuRuntime rt;", "originalCommit": "b9c052c46b3f3d1e439baf8cd4909d8eb6aefc8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "18af742fb07ba77a9d436107af7f8f97210568fd", "url": "https://github.com/CorfuDB/CorfuDB/commit/18af742fb07ba77a9d436107af7f8f97210568fd", "message": "Resolve Conflicts to merge into master", "committedDate": "2020-07-15T19:27:45Z", "type": "forcePushed"}, {"oid": "d0134d72284cbbb84177d2b8303a171606d2752d", "url": "https://github.com/CorfuDB/CorfuDB/commit/d0134d72284cbbb84177d2b8303a171606d2752d", "message": "Rebase with Master\n\n- Rebase again against master\n- Move GRPC service out of messages.proto", "committedDate": "2020-07-19T03:36:20Z", "type": "forcePushed"}, {"oid": "7831d5430162b1dc0cb43f283933a55bc692cc51", "url": "https://github.com/CorfuDB/CorfuDB/commit/7831d5430162b1dc0cb43f283933a55bc692cc51", "message": "ebase with Master\n\n- Rebase again against master\n- Move GRPC service out of messages.proto", "committedDate": "2020-07-19T04:04:01Z", "type": "forcePushed"}, {"oid": "ee7632e874f7371a260b1a18eac560f57804169a", "url": "https://github.com/CorfuDB/CorfuDB/commit/ee7632e874f7371a260b1a18eac560f57804169a", "message": "Rebase with Master\n\n- Rebase again against master\n- Move GRPC service out of messages.proto", "committedDate": "2020-07-20T17:54:33Z", "type": "forcePushed"}, {"oid": "8cce88e479a63f259a40cc1d00f307cfcc946e50", "url": "https://github.com/CorfuDB/CorfuDB/commit/8cce88e479a63f259a40cc1d00f307cfcc946e50", "message": "Fix IT", "committedDate": "2020-07-25T04:16:22Z", "type": "forcePushed"}, {"oid": "897ee30474e6ce50e5a346c237b909834e312eef", "url": "https://github.com/CorfuDB/CorfuDB/commit/897ee30474e6ce50e5a346c237b909834e312eef", "message": "Fix IT", "committedDate": "2020-07-25T05:32:39Z", "type": "forcePushed"}, {"oid": "70406c1e6d33d83c92eae2b599a3b02a011ab310", "url": "https://github.com/CorfuDB/CorfuDB/commit/70406c1e6d33d83c92eae2b599a3b02a011ab310", "message": "Fix IT", "committedDate": "2020-07-25T05:42:13Z", "type": "forcePushed"}, {"oid": "fa9678c048e6690a5486278c6ca140226bbc83df", "url": "https://github.com/CorfuDB/CorfuDB/commit/fa9678c048e6690a5486278c6ca140226bbc83df", "message": "Log Replication Support\n\nIntroducing a new feature for site to site log replication.", "committedDate": "2020-08-08T00:14:11Z", "type": "commit"}, {"oid": "5aa1b199c4022144c9effc6f2c06845473e739de", "url": "https://github.com/CorfuDB/CorfuDB/commit/5aa1b199c4022144c9effc6f2c06845473e739de", "message": "Draft for SnapshotReader and Snapshot Writer.", "committedDate": "2020-08-08T00:14:11Z", "type": "commit"}, {"oid": "77f8f534eb87c218a4271350e7ef09e39a43ce5f", "url": "https://github.com/CorfuDB/CorfuDB/commit/77f8f534eb87c218a4271350e7ef09e39a43ce5f", "message": "Fix package name on SnapshotReader (#2345)\n\n* Fix package name on SnapshotReader\n* State and Events redefined\n* Add Log Replication Event Support\n* Add Logger + Missing Definitions", "committedDate": "2020-08-08T00:14:11Z", "type": "commit"}, {"oid": "7f52c8018fd65d34057a13dbd234b954af409383", "url": "https://github.com/CorfuDB/CorfuDB/commit/7f52c8018fd65d34057a13dbd234b954af409383", "message": "Add sync function for logentry_reader.", "committedDate": "2020-08-08T00:14:11Z", "type": "commit"}, {"oid": "c0f2992cbf71ce4b6282948c49823ac2ede6e231", "url": "https://github.com/CorfuDB/CorfuDB/commit/c0f2992cbf71ce4b6282948c49823ac2ede6e231", "message": "Dedicated Executor for acquired lock monitoring (#2684)", "committedDate": "2020-08-08T00:16:06Z", "type": "forcePushed"}, {"oid": "cf651f19f0e9e8540d3b89e25b7bfe612cb6dd00", "url": "https://github.com/CorfuDB/CorfuDB/commit/cf651f19f0e9e8540d3b89e25b7bfe612cb6dd00", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T03:09:58Z", "type": "forcePushed"}, {"oid": "a82296171569ad00e41451775abe0e378d0a9576", "url": "https://github.com/CorfuDB/CorfuDB/commit/a82296171569ad00e41451775abe0e378d0a9576", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T03:43:42Z", "type": "forcePushed"}, {"oid": "322b04220ed7c9a0c7584834e6ba78f7dba09a00", "url": "https://github.com/CorfuDB/CorfuDB/commit/322b04220ed7c9a0c7584834e6ba78f7dba09a00", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T04:09:34Z", "type": "forcePushed"}, {"oid": "ebbc81bec93398148722d16d68b33bc9a288a2b1", "url": "https://github.com/CorfuDB/CorfuDB/commit/ebbc81bec93398148722d16d68b33bc9a288a2b1", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T04:16:04Z", "type": "forcePushed"}, {"oid": "c99da671f2fcd85c1268037e8e17e358026d12c4", "url": "https://github.com/CorfuDB/CorfuDB/commit/c99da671f2fcd85c1268037e8e17e358026d12c4", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T04:27:01Z", "type": "forcePushed"}, {"oid": "94a897597b66a4bd6c119313244c71eabd88af9d", "url": "https://github.com/CorfuDB/CorfuDB/commit/94a897597b66a4bd6c119313244c71eabd88af9d", "message": "Address Static Analysis Comments\n\n- Bug Fix update topology config id onStandbyClusterAddRemove", "committedDate": "2020-08-08T04:40:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2NDgyMw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467364823", "bodyText": "Code reformat please", "author": "xnull", "createdAt": "2020-08-08T05:26:24Z", "path": "common/src/main/java/org/corfudb/common/util/ObservableValue.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package org.corfudb.common.util;\n+\n+import java.util.Observable;\n+\n+/**\n+ * This class represents an observable value of type int, i.e.,\n+ * an object that the application will mark as observable, in order\n+ * to receive notifications on change.\n+ *\n+ * This is used to block and control tests.\n+ */\n+public class ObservableValue extends Observable\n+{", "originalCommit": "94a897597b66a4bd6c119313244c71eabd88af9d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2NTI1NQ==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2635#discussion_r467365255", "bodyText": "Is this delombok-ed? Please use @builder instead", "author": "xnull", "createdAt": "2020-08-08T05:32:09Z", "path": "infrastructure/src/main/java/org/corfudb/infrastructure/LogReplicationRuntimeParameters.java", "diffHunk": "@@ -0,0 +1,270 @@\n+package org.corfudb.infrastructure;\n+\n+import io.netty.channel.ChannelOption;\n+import io.netty.channel.EventLoopGroup;\n+import lombok.Data;\n+import org.corfudb.comm.ChannelImplementation;\n+import org.corfudb.infrastructure.logreplication.LogReplicationConfig;\n+import org.corfudb.infrastructure.logreplication.transport.IChannelContext;\n+import org.corfudb.protocols.wireprotocol.MsgHandlingFilter;\n+\n+import org.corfudb.infrastructure.logreplication.infrastructure.ClusterDescriptor;\n+import org.corfudb.runtime.RuntimeParameters;\n+import org.corfudb.runtime.RuntimeParametersBuilder;\n+import org.corfudb.util.MetricsUtils;\n+\n+import java.lang.Thread.UncaughtExceptionHandler;\n+import java.time.Duration;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Log Replication Runtime Parameters (a runtime is specific per remote cluster)\n+ */\n+@Data\n+public class LogReplicationRuntimeParameters extends RuntimeParameters {\n+\n+    // Remote Cluster Descriptor\n+    private ClusterDescriptor remoteClusterDescriptor;\n+\n+    // Local Corfu Endpoint (used for database access)\n+    private String localCorfuEndpoint;\n+\n+    // Local Cluster Identifier\n+    private String localClusterId;\n+\n+    // Log Replication Configuration (streams to replicate)\n+    private LogReplicationConfig replicationConfig;\n+\n+    // Plugin File Path (file with plugin configurations - absolute paths of JAR and canonical name of classes)\n+    private String pluginFilePath;\n+\n+    // Topology Configuration Identifier (configuration epoch)\n+    private long topologyConfigId;\n+\n+    // Log Replication Channel Context\n+    private IChannelContext channelContext;\n+\n+    public static LogReplicationRuntimeParametersBuilder builder() {\n+        return new LogReplicationRuntimeParametersBuilder();\n+    }\n+\n+    public static class LogReplicationRuntimeParametersBuilder extends RuntimeParametersBuilder {", "originalCommit": "94a897597b66a4bd6c119313244c71eabd88af9d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "60ba318b6933fd0ef4ca11060d4aa8c67a664632", "url": "https://github.com/CorfuDB/CorfuDB/commit/60ba318b6933fd0ef4ca11060d4aa8c67a664632", "message": "Add onExit logic for SnapshotSync and LogEntrySync (#2352)\n\n* Rename entry classes and change cancelation entry point (#2354)\n* Add accessors to TxMessage (#2357)", "committedDate": "2020-08-08T16:38:20Z", "type": "commit"}, {"oid": "2592b4e89b15d3f251aa7df0bf3501775844dc42", "url": "https://github.com/CorfuDB/CorfuDB/commit/2592b4e89b15d3f251aa7df0bf3501775844dc42", "message": "More changes + Initial Test (not working yet) (#2358)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "9c7c4b23e21570eca2a7725bb1afde9a96236c4c", "url": "https://github.com/CorfuDB/CorfuDB/commit/9c7c4b23e21570eca2a7725bb1afde9a96236c4c", "message": "Implementation of SnapshotWriter.\n\n- Draft for delta sync.", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "1bea63c13dfeb6e932f8b47183e76e15042eadb6", "url": "https://github.com/CorfuDB/CorfuDB/commit/1bea63c13dfeb6e932f8b47183e76e15042eadb6", "message": "Log Listener Interface Changes + Test running (#2359)\n\n- Introduce Observable Values", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "9ce4b50f50e99614132dc4c15739fc2771b7c11b", "url": "https://github.com/CorfuDB/CorfuDB/commit/9ce4b50f50e99614132dc4c15739fc2771b7c11b", "message": "Add comments to reader/writer. (#2360)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "176d7d29adc9ad5001f7033169b8f2b89630e5b3", "url": "https://github.com/CorfuDB/CorfuDB/commit/176d7d29adc9ad5001f7033169b8f2b89630e5b3", "message": "Snapshot Reader Interface and Implementation (#2361)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "c2baac9209aee22c6e1feec9dfb8228eb995e46e", "url": "https://github.com/CorfuDB/CorfuDB/commit/c2baac9209aee22c6e1feec9dfb8228eb995e46e", "message": "Opaque Streams", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "eb980c1822a799b9ba003e852abdfce88bde1a1c", "url": "https://github.com/CorfuDB/CorfuDB/commit/eb980c1822a799b9ba003e852abdfce88bde1a1c", "message": "Add LogReplicationError + Transition Event Id for Error Handling (#2367)\n\n- Expose StartSnapshot call on ReplicationRxManager (#2368)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "31c592da77866031a4317798d0d6e366baba5ea8", "url": "https://github.com/CorfuDB/CorfuDB/commit/31c592da77866031a4317798d0d6e366baba5ea8", "message": "Implementation of StreamSnapshotReader with Opaquestream. (#2371)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "d3273ea48f9f430e9f45d4edf3d3aac5f96a8eb2", "url": "https://github.com/CorfuDB/CorfuDB/commit/d3273ea48f9f430e9f45d4edf3d3aac5f96a8eb2", "message": "Support shared Thread Pool for multiple Log Replication FSMs (#2374)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "370c87e2ec09d75ea5c5a36cb075ef1aa8ebe791", "url": "https://github.com/CorfuDB/CorfuDB/commit/370c87e2ec09d75ea5c5a36cb075ef1aa8ebe791", "message": "Implementation StreamSnapshotWriter, StreamLogEntryReader/Writer. (#2375)\n\n* Implementation of StreamSnapshotReader with Opaquestream.\n\n* Implementation StreamSnapshotWriter, StreamLogEntryReader, StreamLogEntryWriter.\n\n* Some code cleanup.\n\n* Address comments.\n\n* Add exception class for reader/writer.\n\n* Adding persistent metadata for log reader/writer. (#2382)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "db79c35a9b70b5d423600105d0010d5f8cd9f3c6", "url": "https://github.com/CorfuDB/CorfuDB/commit/db79c35a9b70b5d423600105d0010d5f8cd9f3c6", "message": "More Changes, tests and ReadProcessor Interface (#2383)", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "a0f28ed7609aba8bdb1cb1af9166ab21da3b1433", "url": "https://github.com/CorfuDB/CorfuDB/commit/a0f28ed7609aba8bdb1cb1af9166ab21da3b1433", "message": "Put persistent metadata in manager.", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "ddc7ff5bcfb0e7ad46ca03c892214b9237396757", "url": "https://github.com/CorfuDB/CorfuDB/commit/ddc7ff5bcfb0e7ad46ca03c892214b9237396757", "message": "Log Replication Events added (#2389)\n\n* More Changes\r\n\r\n* Log Replication Events added", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "da78a05a3aa611f5972af093605e9191377532c8", "url": "https://github.com/CorfuDB/CorfuDB/commit/da78a05a3aa611f5972af093605e9191377532c8", "message": "Xq/fed06 (#2390)\n\n* Adding snapshot reader/writer test.\r\n\r\n* Add log entry reader/writer test.\r\n\r\n* Rename test.", "committedDate": "2020-08-08T16:38:54Z", "type": "commit"}, {"oid": "e2640cde819dbe7672b5fcad5b563bd9116c7250", "url": "https://github.com/CorfuDB/CorfuDB/commit/e2640cde819dbe7672b5fcad5b563bd9116c7250", "message": "Read Processor Change (#2392)\n\n* Read Processor Change\n\n* Change Packages", "committedDate": "2020-08-08T16:38:55Z", "type": "commit"}, {"oid": "f4d669b7dbbf462efef76039bfa068a32b261ab8", "url": "https://github.com/CorfuDB/CorfuDB/commit/f4d669b7dbbf462efef76039bfa068a32b261ab8", "message": "Add Tests (#2395)\n\n* Implement logentry reader/writer test.\n* Adding log entry reader/writer test case.\n* Add frame work for cluster IT test.\n* Testing streamview append.\n* Verify IT can bring up two corfu clusters with each clusting having one node.", "committedDate": "2020-08-08T16:39:07Z", "type": "commit"}, {"oid": "3b3d9b361494a089f43966a8215848d54c0691ed", "url": "https://github.com/CorfuDB/CorfuDB/commit/3b3d9b361494a089f43966a8215848d54c0691ed", "message": "Introduce Data Receiver Interface (#2400)\n\n- Replaced SnapshotListener and LogEntryListener for DataSender Interface", "committedDate": "2020-08-08T16:39:07Z", "type": "commit"}, {"oid": "091bc113535fe2968ff0a45c86615e9f022f696c", "url": "https://github.com/CorfuDB/CorfuDB/commit/091bc113535fe2968ff0a45c86615e9f022f696c", "message": "Fix the opaque entry bug and pass the StreamSnapshotIT test.\n\n* Add LogEntry IT test.\n* Testing streamview append.\n* Verify IT can bring up two corfu clusters with each clusting having one node.\n* Fix the opaque entry bug and pass the StreamSnapshotIT test.", "committedDate": "2020-08-08T16:39:07Z", "type": "commit"}, {"oid": "c6a8c8331c94fd9ec135b2be656411ee857d7ac6", "url": "https://github.com/CorfuDB/CorfuDB/commit/c6a8c8331c94fd9ec135b2be656411ee857d7ac6", "message": "New Interface Definitions and Renamings (#2403)\n\n- Race Bug Fix (#2404)\n- Change DataSender Interface (#2405)", "committedDate": "2020-08-08T16:39:08Z", "type": "commit"}, {"oid": "79f12f29d4607e0e7f36940d08df720c1e4fad34", "url": "https://github.com/CorfuDB/CorfuDB/commit/79f12f29d4607e0e7f36940d08df720c1e4fad34", "message": "Fix log entry writer with streamview.append.\n\n* Some cleanup and adding trigger clearTable.\nWhile writer starting to write a snapshot, it will\nclear all tables with stream api.", "committedDate": "2020-08-08T16:39:23Z", "type": "commit"}, {"oid": "d63a0e5ec33b4bf8a4db8faf2a1ecfc8def76236", "url": "https://github.com/CorfuDB/CorfuDB/commit/d63a0e5ec33b4bf8a4db8faf2a1ecfc8def76236", "message": "Integration Tests Source and Sink Manager (#2412)\n\n- Add Integration Test Tx across tables (#2413)\n- Seek Opaque Stream only on Snapshot Sync Transition (#2415)\n- Fix SinkManager sending ACK after apply", "committedDate": "2020-08-08T16:39:23Z", "type": "commit"}, {"oid": "168f4d8d2dffaa6943c5712aec1990fe65257209", "url": "https://github.com/CorfuDB/CorfuDB/commit/168f4d8d2dffaa6943c5712aec1990fe65257209", "message": "Fixes (#2419)\n\n* Implement a sliding window with arraylist for log entry reader.\nFor each data message, we records the time the message is sent and number of\nretries for resending. While it reaches the max retries, it will generate a\nreplication exception.\n* Provide serializer and deserializer for DataMessage.", "committedDate": "2020-08-08T16:40:07Z", "type": "commit"}, {"oid": "82a987652fe8aa9d67ad6db4878dd594c3f762a5", "url": "https://github.com/CorfuDB/CorfuDB/commit/82a987652fe8aa9d67ad6db4878dd594c3f762a5", "message": "Limit ByteBuf Size on Deserialize (#2421)\n\n* Limit ByteBuf Size on Deserialize\n* Optimize OpaqueEntry Serialization\n* Fix an FSM Test", "committedDate": "2020-08-08T16:40:31Z", "type": "commit"}, {"oid": "3bbfb1ac3dc023931ff290b7a5f4cea617a258af", "url": "https://github.com/CorfuDB/CorfuDB/commit/3bbfb1ac3dc023931ff290b7a5f4cea617a258af", "message": "Add tracing for debug the null payload. (#2424)\n\nFix the log entry seek offset.", "committedDate": "2020-08-08T16:40:31Z", "type": "commit"}, {"oid": "2176bf86ee7f9e2ac854b3cc803adabccc48cbca", "url": "https://github.com/CorfuDB/CorfuDB/commit/2176bf86ee7f9e2ac854b3cc803adabccc48cbca", "message": "Rename Log Replication IT (#2425)\n\n- Fix NullPointer Bug on SinkManager\r\n- Add log entry sync cross table (invalid) test", "committedDate": "2020-08-08T16:40:31Z", "type": "commit"}, {"oid": "a16d5eb10a0c1e47e8fead7c21b9ab3cfcddce60", "url": "https://github.com/CorfuDB/CorfuDB/commit/a16d5eb10a0c1e47e8fead7c21b9ab3cfcddce60", "message": "Test Case Message Loss (#2426)\n\n* Add tracing for debug the null payload.\nFix the log entry seek offset.\n\n* Add test case for msg loss.", "committedDate": "2020-08-08T16:53:28Z", "type": "commit"}, {"oid": "b4a8bf33dd191c7a52f19a2360d65dba9c652f2f", "url": "https://github.com/CorfuDB/CorfuDB/commit/b4a8bf33dd191c7a52f19a2360d65dba9c652f2f", "message": "Introduce Snapshot Start Message for Snapshot Sync (#2427)", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "be16042c62c1e406246f8e89211b544a68c46d92", "url": "https://github.com/CorfuDB/CorfuDB/commit/be16042c62c1e406246f8e89211b544a68c46d92", "message": "Bug Fixes (#2429)\n\n* Add tracing for debug the null payload.\nFix the log entry seek offset.\n\n* Add test case for msg loss.\n\n* Fix bug at the log entry writer.\nUsing the preMsg address to remove the entry in the buffer.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "3ec205d211c7c6ba274ca94764b368a6c0e74799", "url": "https://github.com/CorfuDB/CorfuDB/commit/3ec205d211c7c6ba274ca94764b368a6c0e74799", "message": "Data Control + Specific Exception Handling (#2431)\n\n- Introduce new exceptions for Log Entry Sync\n- Add Data Control support\n- Add test snapshot sync no replicated data present", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "779be1ec1e8aab2cffa2d65b6174f9d483772fe0", "url": "https://github.com/CorfuDB/CorfuDB/commit/779be1ec1e8aab2cffa2d65b6174f9d483772fe0", "message": "Add configuration for LogEntrySender and SinkManager. (#2434)\n\n  - Pass the id for log entry sync. Add timeout test.\n  - Timeout test at sender will trigger state machine transition.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "2b80039183937f9124813f1ef35a1c1e018e3178", "url": "https://github.com/CorfuDB/CorfuDB/commit/2b80039183937f9124813f1ef35a1c1e018e3178", "message": "Add Log Entry Sync Request Id on Ack (#2435)", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "5600dbee057249eb3d124f9b624323766e785d44", "url": "https://github.com/CorfuDB/CorfuDB/commit/5600dbee057249eb3d124f9b624323766e785d44", "message": "Adding test cases for writing to src corfu along with replication. (#2436)\n\n* Add delete operations too.\n\n* Adding test cases for writing to src corfu along with replication.\nAdd delete operations too.\n\n* Some cleanup of code.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "2056b714f4ff2afa50ca8b4d76c4038d842b416b", "url": "https://github.com/CorfuDB/CorfuDB/commit/2056b714f4ff2afa50ca8b4d76c4038d842b416b", "message": "Add Snapshot Sync Required re-scheduling (#2439)\n\n- If Source stays in InRequireSnapshotSync state, it re-issues a request to the\r\napp, in case messages were dropped so log replication can continue.\r\n- Add logging", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "ab4977056d6844698ad3b5f9585a6bbf6c024cfc", "url": "https://github.com/CorfuDB/CorfuDB/commit/ab4977056d6844698ad3b5f9585a6bbf6c024cfc", "message": "Add SMR changes for not OpaqueEntry.\n\n - Fix opaque entry bug at writer side.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "2954deb67530a3e4d88f8488434fdf1167a8928c", "url": "https://github.com/CorfuDB/CorfuDB/commit/2954deb67530a3e4d88f8488434fdf1167a8928c", "message": "Fix ReplicationReaderWriterTest (#2441)", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "eccdc68f433aa02f4b57b0fb55a3faad590ad23f", "url": "https://github.com/CorfuDB/CorfuDB/commit/eccdc68f433aa02f4b57b0fb55a3faad590ad23f", "message": "Proper opaque stream branch fix\n\n- restore address space default", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "ea0955b05310638833197f318d0adfa45ae8351f", "url": "https://github.com/CorfuDB/CorfuDB/commit/ea0955b05310638833197f318d0adfa45ae8351f", "message": "Add Observable for AckMessage. (#2443)\n\n* Verify log replication persisted metadata. (#2445)\n\n* Add Observable for AckMessage.\n\n* Verify persisted metadata at replication reader/writer.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "d7ad74bd7115286188dba302c7ff1af841e4e197", "url": "https://github.com/CorfuDB/CorfuDB/commit/d7ad74bd7115286188dba302c7ff1af841e4e197", "message": "SinkManager Ack Bug Fix + TrimmedException Tests (#2446)", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "7f0b572f3a05dfc0d8f599d61b27449c37144d26", "url": "https://github.com/CorfuDB/CorfuDB/commit/7f0b572f3a05dfc0d8f599d61b27449c37144d26", "message": "Fix the failed test by set testConfig.waitOn correctly.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "cb94bc6ab7617aead1f76808c7c779c93efde4f7", "url": "https://github.com/CorfuDB/CorfuDB/commit/cb94bc6ab7617aead1f76808c7c779c93efde4f7", "message": "Fix pom.xml and fix broken tests by metadata change (#2448)", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "5497f69bfc02dfe80123e87471c421be23bfb8bc", "url": "https://github.com/CorfuDB/CorfuDB/commit/5497f69bfc02dfe80123e87471c421be23bfb8bc", "message": "Add simple logreplication test script", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "7cc4fdd07afa9dcf533e80875a42d0ac63dd9863", "url": "https://github.com/CorfuDB/CorfuDB/commit/7cc4fdd07afa9dcf533e80875a42d0ac63dd9863", "message": "Trim Exception Test (#2449)\n\n* Add trimmed exception test for snapshot sync and log entry sync.\n* Move out some tests.\n* Add cleanEnv to shutdown runtime.\n* Make snapshot sync and long entry sync test work properly with trimmed exception.", "committedDate": "2020-08-08T16:53:59Z", "type": "commit"}, {"oid": "fdecab00ec2efc1aebf63293d480c352a3d32cbc", "url": "https://github.com/CorfuDB/CorfuDB/commit/fdecab00ec2efc1aebf63293d480c352a3d32cbc", "message": "opaque streams sync", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "354b211f9899f9007f641a26ce1a8a472664e845", "url": "https://github.com/CorfuDB/CorfuDB/commit/354b211f9899f9007f641a26ce1a8a472664e845", "message": "Fix Tests, add logging (#2450)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "20de33a08d35ef487e749c563e321f68ac2e3b7a", "url": "https://github.com/CorfuDB/CorfuDB/commit/20de33a08d35ef487e749c563e321f68ac2e3b7a", "message": "Fix the runtime issues. (#2451)\n\n* Add shutdown runtime\n* Add serializer test.\n* Add SinkBufferManager to handle message delivered out of order. (#2456)\n* Fix bug in sender, clean up pending queue while restart log entry sync.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "0de6792155f1263009794896604959097b834058", "url": "https://github.com/CorfuDB/CorfuDB/commit/0de6792155f1263009794896604959097b834058", "message": "Transactional Support for Streams\n\nAdd the ability for a transaction to span and objects and stream\nappends.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "2ec00b8e8764b3f30a188fd28029c791743c0b77", "url": "https://github.com/CorfuDB/CorfuDB/commit/2ec00b8e8764b3f30a188fd28029c791743c0b77", "message": "Replace append with logupdate in log_entry_writer.\n\n* Make streamsnapshot writer using logUpdate transaction interface.\n* Some code cleanup.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "38799c93e3a175e684bdf2650889b39a904469bf", "url": "https://github.com/CorfuDB/CorfuDB/commit/38799c93e3a175e684bdf2650889b39a904469bf", "message": "Log Replication Server (#2467)\n\nRun Log Replication as a dedicated Server\n\n- Move Log Replication triggers to CorfuReplicationManager (#2468)\n- Remove DataControl (#2469)\n\n- Remove DataControl no longer needed, remove IN_REQUIRE_SNAPSHOT sync\nfrom LogReplication FSM. Fix tests to new FSM.\n\nLog Replication Using Corfu as Communication Channel Part 1 (#2479)\n\n- Fix Log Entry Sync Ack (#2481)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "318435393e896d0ddcf06dac243a5a0a1bb14a17", "url": "https://github.com/CorfuDB/CorfuDB/commit/318435393e896d0ddcf06dac243a5a0a1bb14a17", "message": "Implement discovery log replication topology service. (#2488)\n\n* Implement discovery log replication topology service.\r\n\r\n* For reach run, need to copy log-replication/resources/corfu_replication_config.properties\r\nto /config/corfu/corfu_replication_config.properties.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "4ac089eb2ec7fbb95dcc0ed270e8689285e789c4", "url": "https://github.com/CorfuDB/CorfuDB/commit/4ac089eb2ec7fbb95dcc0ed270e8689285e789c4", "message": "Make Source/Sink order of boot independent for Site Discovery (#2505)\n\n* Test Fix + Cleanup\n* More Changes\n* Make Source/Sink order of boot independent for Site Discovery\n* Fix Log Replication FSM Diagram (#2507)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "8a029cd22e0c0575aef1e49d7b45f839579841c0", "url": "https://github.com/CorfuDB/CorfuDB/commit/8a029cd22e0c0575aef1e49d7b45f839579841c0", "message": "Fix tests. (#2511)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "6c8d68b635b776059e49cad0d056d0d1c52ed063", "url": "https://github.com/CorfuDB/CorfuDB/commit/6c8d68b635b776059e49cad0d056d0d1c52ed063", "message": "Fix IT Tests (#2512)\n\n- Return empty CompletableFuture when message is dropped (test)\r\n- On Log Entry Message Resend register CF for completion", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "ab4bf4401611432241f4af2a2c4924cf07b1520b", "url": "https://github.com/CorfuDB/CorfuDB/commit/ab4bf4401611432241f4af2a2c4924cf07b1520b", "message": "Add writing to shadow streams. (#2513)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "982b152e657503e3f882b59f8d3256100c302a86", "url": "https://github.com/CorfuDB/CorfuDB/commit/982b152e657503e3f882b59f8d3256100c302a86", "message": "Lock implementation using corfu table.\n\n- LockClient to monitor registered locks.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "0b2800850eb89b5917b1235388bdd1f336e600be", "url": "https://github.com/CorfuDB/CorfuDB/commit/0b2800850eb89b5917b1235388bdd1f336e600be", "message": "Optimized applying shadow streams. (#2517)\n\n* Only apply SMR entries that with higher address than the cleartable.", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "14aa03624808f96246fc99bc01bc6dab5e9b2b5e", "url": "https://github.com/CorfuDB/CorfuDB/commit/14aa03624808f96246fc99bc01bc6dab5e9b2b5e", "message": "Remove system.out so code compiles\n\n- Lock Integration Test + Fixes", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "750c10d4eb6ad7d79578dece53e1db71b73f358f", "url": "https://github.com/CorfuDB/CorfuDB/commit/750c10d4eb6ad7d79578dece53e1db71b73f358f", "message": "Add SiteManager Adapter and default implementation. (#2526)\n\n* Add site change notification schema. (#2528)\n* Add a test case for site role type change. (#2529)\n* Add epoch to cross site config and log message. (#2531)\n* Add eventQueue for corfu replication discovery service. (#2540)\n* Add logUpdate API for CorfuStore TxBuilder. (#2539)\n* Add logUpdate API for CorfuStore TxBuilder.\n* Remove reader's metadata file.\n* Define proto buf for SiteConfigMsg.\n* Stop log replication properly. (#2542)", "committedDate": "2020-08-08T16:54:22Z", "type": "commit"}, {"oid": "bd19107b92688ad8b953e74f1d037f4f29e46da9", "url": "https://github.com/CorfuDB/CorfuDB/commit/bd19107b92688ad8b953e74f1d037f4f29e46da9", "message": "Corfu Log Replication Plugin Transport Layer (#2543)\n\nCommunication between Corfu Log Replication Servers can run by default on Netty\nor any custom transport layer.\n\n- Support of protobuf on custom transport layer.\n- GRPC-based plugin as default implementation", "committedDate": "2020-08-08T16:54:23Z", "type": "commit"}, {"oid": "2366fe25badc2c64ca4de4530a89f08ac4fa5a50", "url": "https://github.com/CorfuDB/CorfuDB/commit/2366fe25badc2c64ca4de4530a89f08ac4fa5a50", "message": "Implement persistent writer metadata with UFO API. (#2548)\n\n* Implement persistent writer metadata with UFO API.\r\n\r\n* Some cleanup.", "committedDate": "2020-08-08T16:54:23Z", "type": "commit"}, {"oid": "a66258ab7cb7bc10e04a98481a3b8ec6b8b12af7", "url": "https://github.com/CorfuDB/CorfuDB/commit/a66258ab7cb7bc10e04a98481a3b8ec6b8b12af7", "message": "Lock Integration\n\n- Addressing of some initial comments", "committedDate": "2020-08-08T16:54:23Z", "type": "commit"}, {"oid": "22957d0dd9f531190f6c992b58969f5e5e27e92a", "url": "https://github.com/CorfuDB/CorfuDB/commit/22957d0dd9f531190f6c992b58969f5e5e27e92a", "message": "Enhance site manager functionality\n\n- Handle lock acquire/release.\n- Handle standby transition from invalid to valid and otherwise.", "committedDate": "2020-08-08T16:54:43Z", "type": "commit"}, {"oid": "ecbc4eb33e2e29879b7b1cecea63afcb1af9ed7b", "url": "https://github.com/CorfuDB/CorfuDB/commit/ecbc4eb33e2e29879b7b1cecea63afcb1af9ed7b", "message": "Add Support for Selected Stream Replication.\n\n- Remove hard-coded stream names and read them from system table.\n- Add Version Check for System Table with Stream Names\n\nPopulate only active node names from Default Site Manager config file.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "2f47152ed576ecf7fbdafaa7cb3be5fb384e8455", "url": "https://github.com/CorfuDB/CorfuDB/commit/2f47152ed576ecf7fbdafaa7cb3be5fb384e8455", "message": "Add site flip test. (#2551)\n\n* Add site flip test.\r\n\r\n* Fix compiling issue.\r\n\r\n* Fix issue with SourceForwordingDataSender.\r\n   * Setup sink manager as the leader in the test case.\r\n\r\n* Fix the readConfig issue.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "1f02b645f85e67f521d9753aeab8aae440fb097a", "url": "https://github.com/CorfuDB/CorfuDB/commit/1f02b645f85e67f521d9753aeab8aae440fb097a", "message": "Use separate version table in System namespace to store external plugin version.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "ba6e75eeb999cbfb1d8c80110d2327422eb38b3d", "url": "https://github.com/CorfuDB/CorfuDB/commit/ba6e75eeb999cbfb1d8c80110d2327422eb38b3d", "message": "Add Query of log replication status API. (#2559)\n\n* Add Query transfer percentage API.\n* Add shutdown of DiscoveryService and SiteManagerAdapter.\n* Add bootstrap from property file for SiteManagerAdapter.\n* Add the LogReplicationSenderBuffer mechanism. (#2562)", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "3d521ae3c9204e39b51fedc80fba1c6f3331a727", "url": "https://github.com/CorfuDB/CorfuDB/commit/3d521ae3c9204e39b51fedc80fba1c6f3331a727", "message": "Move Transport Adapters to separate package", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "ab8721e7329debca77babb3bc00767fe0c310fcc", "url": "https://github.com/CorfuDB/CorfuDB/commit/ab8721e7329debca77babb3bc00767fe0c310fcc", "message": "Create Table Names and Version Tables on both Source and Sink sites.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "ab1e20a0c98fb53ad681b4f55a658dd2e4b95fff", "url": "https://github.com/CorfuDB/CorfuDB/commit/ab1e20a0c98fb53ad681b4f55a658dd2e4b95fff", "message": "Add Local Site ID and Remote Site ID to Transport Adapters", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "926dd7f33ea7c566e311f8a6a38c0d7d304bb0df", "url": "https://github.com/CorfuDB/CorfuDB/commit/926dd7f33ea7c566e311f8a6a38c0d7d304bb0df", "message": "Provide Buffer API for both sender and receiver. (#2563)\n\n* Fix bugs in the LogReplicationIT tests.\r\n   * Wait the number of acks in snapshot tests are not correct anymore.\r\n   * Setup ackTs values correctly for buffers.\r\n\r\n* Add SnapshotSinkBuffer and LogEntrySinkBuffer API.\r\n\r\n* Fix some test cases and add more comments.\r\n\r\n* Add more comments and some cleanup.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "2b3dd0a1e87a84e905864d664410011d566fb4f6", "url": "https://github.com/CorfuDB/CorfuDB/commit/2b3dd0a1e87a84e905864d664410011d566fb4f6", "message": "Pass DiscoveryService when creating ReplicationManager (#2568)\n\n* Move the logic of Corfu table creation in a utility file.\r\n\r\n* Pass DiscoveryService when constructing ReplicationManager.\r\n\r\n* Create 'upgrade' event for DiscoveryService when a new version is detected.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "47a19cfed80f64788d1d6972fe7d46e14c60057d", "url": "https://github.com/CorfuDB/CorfuDB/commit/47a19cfed80f64788d1d6972fe7d46e14c60057d", "message": "Fix compiling errors.\n\nSet correct negotiation result according to the receiver state. (#2573)\n\n* Set correct negotiation result according to the receiver state.\n* Add API to update version number.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "9048b41fd7585b2c9e92bc7ae387d9c108434339", "url": "https://github.com/CorfuDB/CorfuDB/commit/9048b41fd7585b2c9e92bc7ae387d9c108434339", "message": "Remove Lombok SuperBuilder and Builder for Runtime params. (#2582)", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "9d1e0d0079e4b1ec1a854db14f8b5181c960289c", "url": "https://github.com/CorfuDB/CorfuDB/commit/9d1e0d0079e4b1ec1a854db14f8b5181c960289c", "message": "Log Replication Design Redefinition (#2578)\n\n* Log Replication Design Redefinition\r\n\r\n- Single CorfuLogReplicationRuntime per Cluster\r\n- Leadership Verification as integrated part of Corfu\r\n- Cluster/Site Discovery/Changes managed through Corfu\r\n- Rename site -> cluster (Corfu terminology)\r\n- Cleanup\r\n\r\n* Move Log-Replication and Transport Package\r\n\r\n- Move LR and Transport to Infrastructure Package\r\n- Re-organize code structure within package infrastructure/logreplication\r\n\r\n* Model Log Replication Runtime as FSM\r\n\r\n* Integrate Discovery Service to Sink Workflow\r\n\r\n- Discovery Service interacting with Receiving Side (LogReplicationServer -> Sink)\r\n- No Hard coded IPs/Ports\r\n- Moved Corfu Port info to ClusterDescriptor\r\n- LogReplicationConfig Logic moved to Service Discovery to be shared across Source and Sink\r\n- MetadataManager created from DiscoveryService and sent to Source and Sink\r\n\r\n* Introduce IChannelContext\r\n\r\n- Share context between Server and Client Channel\r\nrequired by certain transport implementations", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "6e5e13a5d6c578852ed69c8a93a9a829cd05273f", "url": "https://github.com/CorfuDB/CorfuDB/commit/6e5e13a5d6c578852ed69c8a93a9a829cd05273f", "message": "Fix topology config change logic (#2591)\n\n* Fix site change", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}, {"oid": "e3aedf822f648f32852c64d54265536f10f5af6a", "url": "https://github.com/CorfuDB/CorfuDB/commit/e3aedf822f648f32852c64d54265536f10f5af6a", "message": "Correct Behavior of Failed Negotiation + Leadership Retry (#2604)\n\n- If negotiation fails due to version or topologyConfigId mismatch\r\nthe behavior will be to retry negotiation.\r\n- Retry Leadership request if failed to query for a leader.", "committedDate": "2020-08-08T16:54:54Z", "type": "commit"}]}