{"pr_number": 2466, "pr_title": "Revert \"Revert \"Xq/seqcache01 (#2300)\" (#2464)\"", "pr_createdAt": "2020-03-09T23:21:19Z", "pr_url": "https://github.com/CorfuDB/CorfuDB/pull/2466", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDU0Mjk4Mw==", "url": "https://github.com/CorfuDB/CorfuDB/pull/2466#discussion_r390542983", "bodyText": "FYI, I did experiment about assertThat and looks assertThat does not assert its parameter is true.", "author": "zhangn49", "createdAt": "2020-03-10T18:59:21Z", "path": "test/src/test/java/org/corfudb/runtime/object/transactions/SequencerServerCacheTest.java", "diffHunk": "@@ -68,36 +64,152 @@ public void testSequencerCacheTrim() {\n     public void testCache() {\n         final AtomicBoolean criticalVariable = new AtomicBoolean();\n \n-        SequencerServerCache cache = new SequencerServerCache(1, new CacheWriter<ConflictTxStream, Long>() {\n-            @Override\n-            public void write(@Nonnull ConflictTxStream key, @Nonnull Long value) {\n-                log.info(\"Write: [{}, {}]. Thread: {}\", key, value, Thread.currentThread().getName());\n-            }\n-\n-            @Override\n-            public void delete(@Nonnull ConflictTxStream key, @Nullable Long value, @Nonnull RemovalCause cause) {\n-                log.info(\"Delete record: {}. Thread: {}\", key, Thread.currentThread().getName());\n-                criticalVariable.set(true);\n-            }\n-        });\n-\n-        final ConflictTxStream firstKey = new ConflictTxStream(UUID.randomUUID(), new byte[]{});\n-        final ConflictTxStream secondKey = new ConflictTxStream(UUID.randomUUID(), new byte[]{});\n+        SequencerServerCache cache = new SequencerServerCache(1, Address.NOT_FOUND);\n         final long firstValue = 1L;\n         final long secondValue = 2L;\n         final int iterations = 10;\n+        final ConflictTxStream firstKey = new ConflictTxStream(UUID.randomUUID(), new byte[]{}, firstValue);\n+        final ConflictTxStream secondKey = new ConflictTxStream(UUID.randomUUID(), new byte[]{}, secondValue);\n \n         for (int i = 0; i < iterations; i++) {\n-            criticalVariable.set(false);\n-\n-            cache.put(firstKey, firstValue);\n-            cache.put(secondKey, secondValue);\n+            cache.put(firstKey);\n+            cache.put(secondKey);\n \n             assertThat(cache.size()).isOne();\n-            assertThat(cache.getIfPresent(firstKey)).isNull();\n+            assertThat(cache.get(firstKey)).isEqualTo(Address.NON_ADDRESS);\n+        }\n+    }\n+\n+    public static final int entryPerAddress = 20;\n+    public static final int iterations = 100;\n+    public static final int cacheSize = iterations * entryPerAddress;\n+    public static final int numRemains = 10;\n+\n+    /**\n+     * generate data with given address and verify that the entries with firstAddress are correctly evicted\n+     */\n+    void generateData(HashMap recordMap, SequencerServerCache cache, long address, boolean verifyFirst) {\n+        final ConflictTxStream key = new ConflictTxStream(UUID.randomUUID(), new byte[]{}, address);\n+        if (verifyFirst) {\n+            log.debug(\"cache.firstAddress: \" + cache.firstAddress() + \" cacheSize: \" + cache.size());\n+            assertThat(cache.firstAddress() == address - cacheSize);\n+        }\n+        cache.put(key);\n+        assertThat(cache.get(key) != Address.NON_ADDRESS);\n+        recordMap.put(key, address);\n+        assertThat(cache.size() <= cacheSize);\n+    }\n+\n+    /**\n+     * Verify cache contains all the data in recordMap that address >= firstAddress.\n+     * @param recordMap\n+     * @param cache\n+     */\n+    void verifyData(HashMap<ConflictTxStream, Long> recordMap, SequencerServerCache cache) {\n+        for (ConflictTxStream oldKey : recordMap.keySet()) {\n+            long oldAddress = oldKey.txVersion;\n+            if (oldAddress < cache.firstAddress()) {\n+                continue;\n+            }\n+            ConflictTxStream key = new ConflictTxStream(oldKey.getStreamId(), oldKey.getConflictParam(), 0);\n+            log.debug(\"address \" + cache.get(key) + \" expected \" + oldAddress);\n+            assertThat(cache.get(key) == oldAddress);\n+        }\n+    }\n+\n+    @Test\n+    /*\n+        Test the evication the firstAddress while the cache is full, by generating address out of order\n+     */\n+    public void testSequencerCacheEvict1() {\n+        SequencerServerCache cache = new SequencerServerCache(cacheSize, Address.NOT_FOUND);\n+        long address = 0;\n+        HashMap<ConflictTxStream, Long> recordMap = new HashMap<>();\n+\n+        // put entries to the cache with duplicate address not in order\n+        while (cache.size() < cacheSize) {\n+            address = 0;\n+            for (int i = 0; i < cacheSize / entryPerAddress; i++) {\n+                generateData(recordMap, cache, address++, false);\n+            }\n+        }\n+\n+        assertThat(cache.size() == cacheSize);\n+        verifyData(recordMap, cache);\n+\n+        // Each put should evict all streams with the same address\n+        for (int i = 0; i < iterations; i++, address++) {\n+            generateData(recordMap, cache, address, true);\n+        }\n+\n+        verifyData(recordMap, cache);\n+\n+        cache.invalidateUpTo(address - 1);\n+        assertThat(cache.size() == 1);\n+        cache.invalidateUpTo(address);\n+        assertThat(cache.size() == 0);\n+    }\n+\n+    @Test\n+    /*\n+        Test the evication the firstAddress while the cache is full, by generating address in order\n+     */\n+    public void testSequencerCacheEvict2() {\n+        SequencerServerCache cache = new SequencerServerCache(cacheSize, Address.NOT_FOUND);\n+        long address = 0;\n+        HashMap<ConflictTxStream, Long> recordMap = new HashMap<>();\n+\n+        // put entries to the cache, make it full, some entries have the same address\n+        while (cache.size() < cacheSize) {\n+            for (int j = 0; j < entryPerAddress; j++) {\n+                generateData(recordMap, cache, address++, false);\n+            }\n+        }\n+\n+        verifyData(recordMap, cache);\n+\n+        assertThat(cache.size() == cacheSize);\n+        // Each put should evict all streams with the same address\n+        for (int i = 0; i < iterations; i++, address++) {\n+            generateData(recordMap, cache, address, true);\n+        }\n+\n+        verifyData(recordMap, cache);\n+        log.info(\"cacheSize {} cacheByteSize {} cacheEntriesBytes {} \", cache.size(), cache.byteSize(), cache.byteSize());\n+        long entrySize = cache.byteSize() / cache.size();\n+\n+        cache.invalidateUpTo(address - numRemains);\n+        assertThat(cache.size() == numRemains);\n+\n+        // this assume that the all conflickstreams has the same size of the parameters.\n+        assertThat(entrySize == cache.byteSize() / cache.size());", "originalCommit": "c4ccfe076428584613a2a670732513fbfb977f77", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5b9e43f4b741fab13c5d949ecec2741c04f76f34", "url": "https://github.com/CorfuDB/CorfuDB/commit/5b9e43f4b741fab13c5d949ecec2741c04f76f34", "message": "Revert \"Revert \"Xq/seqcache01 (#2300)\" (#2464)\"\n\nThis reverts commit 7f9c3fef9fcca6b0ced3f1ea92c3b42af67525b3.", "committedDate": "2020-03-30T03:00:21Z", "type": "commit"}, {"oid": "24ead4675cfec58b4a95021226cef428e7246551", "url": "https://github.com/CorfuDB/CorfuDB/commit/24ead4675cfec58b4a95021226cef428e7246551", "message": "Use proper assert function.\n* Add the element first before eviction.", "committedDate": "2020-03-30T03:00:21Z", "type": "commit"}, {"oid": "24ead4675cfec58b4a95021226cef428e7246551", "url": "https://github.com/CorfuDB/CorfuDB/commit/24ead4675cfec58b4a95021226cef428e7246551", "message": "Use proper assert function.\n* Add the element first before eviction.", "committedDate": "2020-03-30T03:00:21Z", "type": "forcePushed"}]}