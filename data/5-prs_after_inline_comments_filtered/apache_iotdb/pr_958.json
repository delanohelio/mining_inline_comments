{"pr_number": 958, "pr_title": "[IOTDB-351] Serialize raft log", "pr_createdAt": "2020-03-30T07:22:19Z", "pr_url": "https://github.com/apache/iotdb/pull/958", "timeline": [{"oid": "b54bf74bd8f65ad19228af525197718be89c316e", "url": "https://github.com/apache/iotdb/commit/b54bf74bd8f65ad19228af525197718be89c316e", "message": "add serializable raft log component", "committedDate": "2020-03-06T17:11:32Z", "type": "commit"}, {"oid": "9478e69875e2599a1d5f89b0420250d71c1b4fb9", "url": "https://github.com/apache/iotdb/commit/9478e69875e2599a1d5f89b0420250d71c1b4fb9", "message": "fix bugs", "committedDate": "2020-03-07T09:06:15Z", "type": "commit"}, {"oid": "ccc55df96b080b5070fa4f0d6b8afe87c58f73c7", "url": "https://github.com/apache/iotdb/commit/ccc55df96b080b5070fa4f0d6b8afe87c58f73c7", "message": "add log view tool", "committedDate": "2020-03-07T10:53:08Z", "type": "commit"}, {"oid": "fd786590ca1b9f162a064d10c07b4231b1da92dd", "url": "https://github.com/apache/iotdb/commit/fd786590ca1b9f162a064d10c07b4231b1da92dd", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log", "committedDate": "2020-03-12T12:05:34Z", "type": "commit"}, {"oid": "00898a7fccdf9fcd9d351351aae452cc96d18b34", "url": "https://github.com/apache/iotdb/commit/00898a7fccdf9fcd9d351351aae452cc96d18b34", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log", "committedDate": "2020-03-16T12:27:35Z", "type": "commit"}, {"oid": "e4f88eac8e287c044d3799403fbcbacd71fa406f", "url": "https://github.com/apache/iotdb/commit/e4f88eac8e287c044d3799403fbcbacd71fa406f", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log", "committedDate": "2020-03-16T12:28:14Z", "type": "commit"}, {"oid": "6579104139e98a7f9cdf25b65fdf4dca13800b77", "url": "https://github.com/apache/iotdb/commit/6579104139e98a7f9cdf25b65fdf4dca13800b77", "message": "add truncate logs", "committedDate": "2020-03-18T08:42:25Z", "type": "commit"}, {"oid": "82076dd13c8cfb009f1585ccf71023bbaecc7206", "url": "https://github.com/apache/iotdb/commit/82076dd13c8cfb009f1585ccf71023bbaecc7206", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/test/java/org/apache/iotdb/cluster/common/TestUtils.java", "committedDate": "2020-03-24T04:03:49Z", "type": "commit"}, {"oid": "b21730ee75ea529e4d872be639b2f1a4f0cc1bb3", "url": "https://github.com/apache/iotdb/commit/b21730ee75ea529e4d872be639b2f1a4f0cc1bb3", "message": "add log batch append", "committedDate": "2020-03-24T06:31:43Z", "type": "commit"}, {"oid": "d269c65b54c380fa8772e8f3f18d9a0d7f3b17c0", "url": "https://github.com/apache/iotdb/commit/d269c65b54c380fa8772e8f3f18d9a0d7f3b17c0", "message": "fix bugs", "committedDate": "2020-03-24T06:49:52Z", "type": "commit"}, {"oid": "ea9bd6646faa30580a939c58894f0b448aae90f3", "url": "https://github.com/apache/iotdb/commit/ea9bd6646faa30580a939c58894f0b448aae90f3", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/FilePartitionedSnapshotLogManager.java\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MetaSingleSnapshotLogManager.java", "committedDate": "2020-03-26T15:25:47Z", "type": "commit"}, {"oid": "10d4757bbdfdd3fe7731a2800fdc1c086b53e8a5", "url": "https://github.com/apache/iotdb/commit/10d4757bbdfdd3fe7731a2800fdc1c086b53e8a5", "message": "Add license", "committedDate": "2020-03-30T03:35:03Z", "type": "commit"}, {"oid": "737c944e2959465cb77f92319d587faff2c8979f", "url": "https://github.com/apache/iotdb/commit/737c944e2959465cb77f92319d587faff2c8979f", "message": "Add license", "committedDate": "2020-03-31T01:12:21Z", "type": "commit"}, {"oid": "b52ed3255d2293f3547124d69d3b81075ee50e8d", "url": "https://github.com/apache/iotdb/commit/b52ed3255d2293f3547124d69d3b81075ee50e8d", "message": "add license", "committedDate": "2020-03-31T01:17:55Z", "type": "commit"}, {"oid": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "url": "https://github.com/apache/iotdb/commit/a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "message": "add license", "committedDate": "2020-03-31T05:38:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMDI0MA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401310240", "bodyText": "Maybe you can use the @TestOnly annotation, so it will provide some convenience if we want to track all test methods.", "author": "jt2594838", "createdAt": "2020-04-01T01:46:10Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java", "diffHunk": "@@ -159,21 +181,32 @@ public boolean logValid(long logIndex) {\n \n   @Override\n   public Log getLastLog() {\n-    return logBuffer.isEmpty()? null : logBuffer.get(logBuffer.size() - 1);\n+    return logBuffer.isEmpty() ? null : logBuffer.get(logBuffer.size() - 1);\n   }\n \n   @Override\n   public LogApplier getApplier() {\n     return logApplier;\n   }\n \n-  @Override\n-  public void setLastLogId(long lastLogId) {\n-    this.lastLogId = lastLogId;\n+  public void removeFromHead(int length) {\n+    logBuffer.subList(0, length).clear();\n   }\n \n-  @Override\n-  public void setLastLogTerm(long lastLogTerm) {\n-    this.lastLogTerm = lastLogTerm;\n+  /**\n+   * only for test\n+   */\n+  public LogManagerMeta getMeta() {", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNTU3Nw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401335577", "bodyText": "Fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:28:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMDI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjIxMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312211", "bodyText": "This name seems unused.", "author": "jt2594838", "createdAt": "2020-04-01T01:53:55Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjM0OA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401336348", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:31:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjIxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjY0Ng==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312646", "bodyText": "The second should be metaFile.", "author": "jt2594838", "createdAt": "2020-04-01T01:55:31Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjU0MA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401336540", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:32:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjY0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjczMA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401312730", "bodyText": "Use log, the same as below.", "author": "jt2594838", "createdAt": "2020-04-01T01:55:52Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzQ2Mg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401337462", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:36:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMjczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzI5Mw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401313293", "bodyText": "Why is metaOutputStream also in an append mode?", "author": "jt2594838", "createdAt": "2020-04-01T01:58:18Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzQ2OA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401337468", "bodyText": "because if we not use append mode, file will be overwrite(truncated) and we can't recovery from file", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:36:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzI5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyNDI1Nw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r402024257", "bodyText": "But you manually truncate it in serializeMeta, but that is not a big issue, I will ignore this.", "author": "jt2594838", "createdAt": "2020-04-02T02:57:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzgzMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401313831", "bodyText": "I think \"removeLast\" is no longer used, you may remove it too.", "author": "jt2594838", "createdAt": "2020-04-01T02:00:24Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.util.List;\n+import org.apache.iotdb.cluster.log.Log;\n+\n+public interface LogDequeSerializer {\n+\n+  /**\n+   * append a log\n+   * @param log appended log\n+   */\n+  public void addLast(Log log, LogManagerMeta meta);\n+\n+  /**\n+   * remove last log\n+   * @param meta metadata\n+   */\n+  public void removeLast(LogManagerMeta meta);", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzgwNg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401337806", "bodyText": "I think we should just keep it may be we will use it after.", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:37:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxMzgzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzMxMw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401317313", "bodyText": "Since you have recorded the sizes of each log, you can surely the total size of removed logs, why not just use \"FileInputStream.skip()\" (be sure to check the actually skipped bytes)?", "author": "jt2594838", "createdAt": "2020-04-01T02:14:12Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }\n+      logReader.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader, boolean canSkip) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    if (canSkip) {\n+      logReader.skip(logSize);\n+      removedLogSize += totalSize;\n+      return null;\n+    }\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);\n+      ReadWriteIOUtils.write(firstLogPosition, metaOutputStream);\n+      ReadWriteIOUtils.write(meta.serialize(), metaOutputStream);\n+\n+      this.meta = meta;\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      logOutputStream.close();\n+      metaOutputStream.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  // actually delete removed logs, this may take lots of times\n+  // TODO : use an async method to delete file\n+  private void deleteRemovedLog() {\n+    try {\n+      FileInputStream reader = new FileInputStream(logFile);\n+      // skip removed file\n+      for (int i = 0; i < firstLogPosition; i++) {\n+        readLog(reader, true);\n+      }", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTUzMg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401339532", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:45:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzMxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzgwMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401317801", "bodyText": "It is a little misleading to use the word \"total\" and the operator \"+=\", it seems that you are adding some things up, but actually there is only one item.", "author": "jt2594838", "createdAt": "2020-04-01T02:16:28Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzc5Mw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401337793", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:37:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxNzgwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxODI4MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401318281", "bodyText": "I do not believe this is \"write into disk\".", "author": "jt2594838", "createdAt": "2020-04-01T02:18:26Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzg2MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401337861", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMxODI4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMDI0OQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401320249", "bodyText": "Are there any countermeasures against the situation that the logs are removed but the meta is not serialized?", "author": "jt2594838", "createdAt": "2020-04-01T02:25:56Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzODEwMA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401338100", "bodyText": "May be error log is the only method. Is there any suggestions?", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:39:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMDI0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyNzMwNg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r402027306", "bodyText": "It would be easy if you use multiple files, in that case, you can serialize the metadata first and then remove the useless file. If the system crashes in between, during recovery you can know from the metadata that the log file is useless and still delete it.", "author": "jt2594838", "createdAt": "2020-04-02T03:09:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMDI0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMTAzNg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401321036", "bodyText": "I think if you can also save the file position of the first log (just another 8 bytes in the meta), it will be much easier to skip the removed logs.", "author": "jt2594838", "createdAt": "2020-04-01T02:28:51Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTYwMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401339601", "bodyText": "Sure~ Fixed", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyMTAzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDAzMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401324031", "bodyText": "There is a much easier way to do this, it is FileChannel.transferTo(), you may have a look.", "author": "jt2594838", "createdAt": "2020-04-01T02:40:25Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import java.util.List;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    String name = logFile.getAbsolutePath();\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is\n+   * size of log | log buffer\n+   * meta in disk is\n+   * firstLogPosition | size of log meta | log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  // only for test\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!logFile.getParentFile().exists()) {\n+        logFile.getParentFile().mkdir();\n+        logFile.createNewFile();\n+        logFile.createNewFile();\n+      }\n+\n+      logOutputStream = new FileOutputStream(logFile, true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void addLast(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize += ReadWriteIOUtils.write(data, logOutputStream);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta){\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private void truncateLogIntern(int count){\n+    if(logSizeDeque.size() > count){\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // write into disk\n+    try {\n+      logOutputStream.getChannel().truncate(logFile.length() - size);\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      deleteRemovedLog();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+\n+    if (!logFile.exists()) {\n+      return new ArrayList<>();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    long count = 0;\n+    try {\n+      FileInputStream logReader = new FileInputStream(logFile);\n+      FileChannel logChannel = logReader.getChannel();\n+      while (logChannel.position() < logFile.length()) {\n+        // actual log\n+        if (count >= firstLogPosition) {\n+          Log log = readLog(logReader, false);\n+          result.add(log);\n+        }\n+        // removed log, skip\n+        else {\n+          readLog(logReader, true);\n+        }\n+        count++;\n+      }\n+      logReader.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader, boolean canSkip) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    if (canSkip) {\n+      logReader.skip(logSize);\n+      removedLogSize += totalSize;\n+      return null;\n+    }\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      e.printStackTrace();\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);\n+      ReadWriteIOUtils.write(firstLogPosition, metaOutputStream);\n+      ReadWriteIOUtils.write(meta.serialize(), metaOutputStream);\n+\n+      this.meta = meta;\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      logOutputStream.close();\n+      metaOutputStream.close();\n+    } catch (IOException e) {\n+      e.printStackTrace();\n+    }\n+  }\n+\n+  // actually delete removed logs, this may take lots of times\n+  // TODO : use an async method to delete file\n+  private void deleteRemovedLog() {\n+    try {\n+      FileInputStream reader = new FileInputStream(logFile);\n+      // skip removed file\n+      for (int i = 0; i < firstLogPosition; i++) {\n+        readLog(reader, true);\n+      }\n+\n+      // begin to write\n+      File tempLogFile = SystemFileFactory.INSTANCE\n+          .getFile(\n+              IoTDBDescriptor.getInstance().getConfig().getSystemDir() + File.separator + \"raftLog\"\n+                  + File.separator + \"logData.temp\");\n+\n+      logOutputStream.close();\n+      logOutputStream = new FileOutputStream(tempLogFile);\n+      int blockSize = 4096;\n+      long curPosition = reader.getChannel().position();\n+      while (curPosition < logFile.length()) {\n+        long size = Math.min(blockSize, logFile.length() - curPosition);\n+        logOutputStream.write(ReadWriteIOUtils.readBytes(reader, (int) size));\n+        curPosition = reader.getChannel().position();\n+      }", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzMzczOA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401333738", "bodyText": "Fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDAzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDc1Ng==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401324756", "bodyText": "Why are these commented\uff1f", "author": "jt2594838", "createdAt": "2020-04-01T02:43:36Z", "path": "cluster/src/test/java/org/apache/iotdb/cluster/query/ClusterAggregateExecutorTest.java", "diffHunk": "@@ -29,40 +47,40 @@\n \n   private ClusterAggregateExecutor executor;\n \n-  @Test\n-  public void testNoFilter()\n-      throws QueryProcessException, StorageEngineException, IOException {\n-    AggregationPlan plan = new AggregationPlan();\n-    List<Path> paths = Arrays.asList(\n-        new Path(TestUtils.getTestSeries(0, 0)),\n-        new Path(TestUtils.getTestSeries(0, 1)),\n-        new Path(TestUtils.getTestSeries(0, 2)),\n-        new Path(TestUtils.getTestSeries(0, 3)),\n-        new Path(TestUtils.getTestSeries(0, 4)));\n-    List<TSDataType> dataTypes = Arrays.asList(TSDataType.DOUBLE, TSDataType.DOUBLE,\n-        TSDataType.DOUBLE, TSDataType.DOUBLE, TSDataType.DOUBLE);\n-    List<String> aggregations = Arrays.asList(SQLConstant.MIN_TIME, SQLConstant.MAX_VALUE,\n-        SQLConstant.AVG, SQLConstant.COUNT, SQLConstant.SUM);\n-    plan.setPaths(paths);\n-    plan.setDeduplicatedPaths(paths);\n-    plan.setDataTypes(dataTypes);\n-    plan.setDeduplicatedDataTypes(dataTypes);\n-    plan.setAggregations(aggregations);\n-    plan.setDeduplicatedAggregations(aggregations);\n-\n-    QueryContext context = new RemoteQueryContext(QueryResourceManager.getInstance().assignQueryId(true));\n-    executor = new ClusterAggregateExecutor(plan, testMetaMember);\n-    QueryDataSet queryDataSet = executor.executeWithoutValueFilter(context);\n-    assertTrue(queryDataSet.hasNext());\n-    RowRecord record = queryDataSet.next();\n-    List<Field> fields = record.getFields();\n-    assertEquals(5, fields.size());\n-    Object[] answers = new Object[] {0.0, 19.0, 9.5, 20.0, 190.0};\n-    for (int i = 0; i < 5; i++) {\n-      assertEquals((double)answers[i], Double.parseDouble(fields.get(i).toString()), 0.00001);\n-    }\n-    assertFalse(queryDataSet.hasNext());\n-  }\n+//  @Test\n+//  public void testNoFilter()\n+//      throws QueryProcessException, StorageEngineException, IOException {\n+//    AggregationPlan plan = new AggregationPlan();\n+//    List<Path> paths = Arrays.asList(\n+//        new Path(TestUtils.getTestSeries(0, 0)),\n+//        new Path(TestUtils.getTestSeries(0, 1)),\n+//        new Path(TestUtils.getTestSeries(0, 2)),\n+//        new Path(TestUtils.getTestSeries(0, 3)),\n+//        new Path(TestUtils.getTestSeries(0, 4)));\n+//    List<TSDataType> dataTypes = Arrays.asList(TSDataType.DOUBLE, TSDataType.DOUBLE,\n+//        TSDataType.DOUBLE, TSDataType.DOUBLE, TSDataType.DOUBLE);\n+//    List<String> aggregations = Arrays.asList(SQLConstant.MIN_TIME, SQLConstant.MAX_VALUE,\n+//        SQLConstant.AVG, SQLConstant.COUNT, SQLConstant.SUM);\n+//    plan.setPaths(paths);\n+//    plan.setDeduplicatedPaths(paths);\n+//    plan.setDataTypes(dataTypes);\n+//    plan.setDeduplicatedDataTypes(dataTypes);\n+//    plan.setAggregations(aggregations);\n+//    plan.setDeduplicatedAggregations(aggregations);\n+//\n+//    QueryContext context = new RemoteQueryContext(QueryResourceManager.getInstance().assignQueryId(true));\n+//    executor = new ClusterAggregateExecutor(plan, testMetaMember);\n+//    QueryDataSet queryDataSet = executor.executeWithoutValueFilter(context);\n+//    assertTrue(queryDataSet.hasNext());\n+//    RowRecord record = queryDataSet.next();\n+//    List<Field> fields = record.getFields();\n+//    assertEquals(5, fields.size());\n+//    Object[] answers = new Object[] {0.0, 19.0, 9.5, 20.0, 190.0};\n+//    for (int i = 0; i < 5; i++) {\n+//      assertEquals((double)answers[i], Double.parseDouble(fields.get(i).toString()), 0.00001);\n+//    }\n+//    assertFalse(queryDataSet.hasNext());\n+//  }", "originalCommit": "a792cb4ab42cafa96b1189eed1dd5d2388d4bb33", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzODY0Ng==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r401338646", "bodyText": "I don't know why but I will fix it", "author": "SilverNarcissus", "createdAt": "2020-04-01T03:41:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNDc1Ng=="}], "type": "inlineReview"}, {"oid": "b6a79aeb4835282f312276e9e370138750a07df2", "url": "https://github.com/apache/iotdb/commit/b6a79aeb4835282f312276e9e370138750a07df2", "message": "fix bugs", "committedDate": "2020-04-01T03:51:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTI1Mg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403701252", "bodyText": "The truncate function can be achieved at this level by taking advantage of the fact that the indexes of the raft logs must be contiguous, rather than being invoked from above. Truncate should be a function of append function rather than an interface.I'm sorry that I misdescribed it in a way that led to this implementation.", "author": "LebronAl", "createdAt": "2020-04-05T13:22:24Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/DiskLogManager.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage;\n+\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogApplier;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogDequeSerializer;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogManagerMeta;\n+import org.apache.iotdb.cluster.log.manage.serializable.SyncLogDequeSerializer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public abstract class DiskLogManager extends MemoryLogManager {\n+  private static final Logger logger = LoggerFactory.getLogger(DiskLogManager.class);\n+\n+  // manage logs in disk\n+  private LogDequeSerializer logDequeSerializer;\n+\n+  private LogManagerMeta managerMeta = new LogManagerMeta();\n+\n+\n+  protected DiskLogManager(LogApplier logApplier) {\n+    super(logApplier);\n+    logDequeSerializer = new SyncLogDequeSerializer();\n+    recovery();\n+  }\n+\n+  private void recovery(){\n+    // recover meta\n+    LogManagerMeta logManagerMeta = logDequeSerializer.recoverMeta();\n+    if(logManagerMeta != null){\n+      setCommitLogIndex(logManagerMeta.getCommitLogIndex());\n+      setLastLogId(logManagerMeta.getLastLogId());\n+      setLastLogTerm(logManagerMeta.getLastLogTerm());\n+    }\n+    // recover logs\n+    setLogBuffer(logDequeSerializer.recoverLog());\n+  }\n+\n+\n+  @Override\n+  public long getLastLogIndex() {\n+    return lastLogId;\n+  }\n+\n+  @Override\n+  public long getLastLogTerm() {\n+    return lastLogTerm;\n+  }\n+\n+  @Override\n+  public void setLastLogTerm(long lastLogTerm) {\n+    this.lastLogTerm = lastLogTerm;\n+  }\n+\n+  @Override\n+  public long getCommitLogIndex() {\n+    return commitLogIndex;\n+  }\n+\n+  @Override\n+  public boolean appendLog(Log log) {\n+    boolean result = super.appendLog(log);\n+    if(result) {\n+      logDequeSerializer.addLast(log, getMeta());\n+    }\n+\n+    return result;\n+  }\n+\n+\n+  public void truncateLog(int count) {", "originalCommit": "b6a79aeb4835282f312276e9e370138750a07df2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY2MTQ3Nw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404661477", "bodyText": "Sure, truncate and append can be easily achieved by calling truncate method and append method", "author": "SilverNarcissus", "createdAt": "2020-04-07T09:18:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTI1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg4MzIyOA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404883228", "bodyText": "Ok~Furthermore, the upper layer doesn't call the truncate interface with the current implementation. If the memoryLogManager is going to truncate wrong logs at append function then the diskLogManager also needs to have the corresponding implementation, so the diskLogManager\u2019s append function should also need some changes, such as calling the truncate function. Of course, you won't need to implement this for append if it's embedded in new design in the future.Just for reminding ~", "author": "LebronAl", "createdAt": "2020-04-07T15:05:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTI1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTgxNA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403701814", "bodyText": "In fact, for the implementation of memoryLogManager, the lastLogTerm does not need to be maintained this way manually, because you can simply take the index of the last log in bufffer. If memoryLogManager could make this small change, here would be no need to serialize the meta data.This may require further discussion.", "author": "LebronAl", "createdAt": "2020-04-05T13:27:07Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/DiskLogManager.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage;\n+\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogApplier;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogDequeSerializer;\n+import org.apache.iotdb.cluster.log.manage.serializable.LogManagerMeta;\n+import org.apache.iotdb.cluster.log.manage.serializable.SyncLogDequeSerializer;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public abstract class DiskLogManager extends MemoryLogManager {\n+  private static final Logger logger = LoggerFactory.getLogger(DiskLogManager.class);\n+\n+  // manage logs in disk\n+  private LogDequeSerializer logDequeSerializer;\n+\n+  private LogManagerMeta managerMeta = new LogManagerMeta();\n+\n+\n+  protected DiskLogManager(LogApplier logApplier) {\n+    super(logApplier);\n+    logDequeSerializer = new SyncLogDequeSerializer();\n+    recovery();\n+  }\n+\n+  private void recovery(){\n+    // recover meta\n+    LogManagerMeta logManagerMeta = logDequeSerializer.recoverMeta();\n+    if(logManagerMeta != null){\n+      setCommitLogIndex(logManagerMeta.getCommitLogIndex());\n+      setLastLogId(logManagerMeta.getLastLogId());\n+      setLastLogTerm(logManagerMeta.getLastLogTerm());\n+    }\n+    // recover logs\n+    setLogBuffer(logDequeSerializer.recoverLog());\n+  }\n+\n+\n+  @Override\n+  public long getLastLogIndex() {\n+    return lastLogId;\n+  }\n+\n+  @Override\n+  public long getLastLogTerm() {\n+    return lastLogTerm;\n+  }\n+\n+  @Override\n+  public void setLastLogTerm(long lastLogTerm) {\n+    this.lastLogTerm = lastLogTerm;\n+  }\n+\n+  @Override\n+  public long getCommitLogIndex() {\n+    return commitLogIndex;\n+  }\n+\n+  @Override\n+  public boolean appendLog(Log log) {\n+    boolean result = super.appendLog(log);\n+    if(result) {\n+      logDequeSerializer.addLast(log, getMeta());\n+    }\n+\n+    return result;\n+  }\n+\n+\n+  public void truncateLog(int count) {\n+    if (logBuffer.size() > count) {\n+      // do super truncate log\n+      // super.truncateLog();\n+      logDequeSerializer.truncateLog(count, getMeta());\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void commitLog(long maxLogIndex) {\n+    super.commitLog(maxLogIndex);\n+    // save commit log index\n+    serializeMeta();\n+  }\n+  \n+\n+  @Override\n+  public void setLastLogId(long lastLogId) {\n+    super.setLastLogId(lastLogId);\n+    // save meta\n+    serializeMeta();", "originalCommit": "b6a79aeb4835282f312276e9e370138750a07df2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY2MjQ0MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404662441", "bodyText": "Yes, but this class may be discard when integrating with your code. You can decide whether to hold this", "author": "SilverNarcissus", "createdAt": "2020-04-07T09:19:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg3NjAyOA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404876028", "bodyText": "OK~", "author": "LebronAl", "createdAt": "2020-04-07T14:56:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwMTgxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNTkwMA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403705900", "bodyText": "Actually, I don't find out the meaning of persisting lastLogId and lastLogTerm because both of them are available from the lastLog after recoverLog", "author": "LebronAl", "createdAt": "2020-04-05T13:59:55Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogManagerMeta.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.nio.ByteBuffer;\n+import org.apache.commons.lang3.builder.EqualsBuilder;\n+import org.apache.commons.lang3.builder.HashCodeBuilder;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+\n+public class LogManagerMeta {\n+\n+  private long commitLogIndex = -1;\n+  private long lastLogId = -1;\n+  private long lastLogTerm = -1;", "originalCommit": "b6a79aeb4835282f312276e9e370138750a07df2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY2Nzc2MA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404667760", "bodyText": "Yes, but considering the nature of the disk (write two more long will cause almost no impact to the performance) and the abstract level of SyncLogDequeSerializer. I just see all the variable of memoryLogManager as meta", "author": "SilverNarcissus", "createdAt": "2020-04-07T09:28:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNTkwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg3NjI0NA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404876244", "bodyText": "Fine~", "author": "LebronAl", "createdAt": "2020-04-07T14:57:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNTkwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNjYwOQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r403706609", "bodyText": "Sorry,I don't figure out the comment here. Is this the format of file\uff1f", "author": "LebronAl", "createdAt": "2020-04-05T14:06:01Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,310 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  File logFile;\n+  File metaFile;\n+  FileOutputStream logOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logData\");\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is size of log | log buffer meta in disk is firstLogPosition | size of log meta |", "originalCommit": "b6a79aeb4835282f312276e9e370138750a07df2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDY1Nzk2MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404657961", "bodyText": "Yes this is the format of the log file. I will make it clearly later", "author": "SilverNarcissus", "createdAt": "2020-04-07T09:12:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNjYwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDg3NjcwNw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r404876707", "bodyText": "Thanks~", "author": "LebronAl", "createdAt": "2020-04-07T14:57:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcwNjYwOQ=="}], "type": "inlineReview"}, {"oid": "0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542", "url": "https://github.com/apache/iotdb/commit/0cfa6c55b6d7474c9489fc1786cf7bf8e43f4542", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/log/manage/MemoryLogManager.java", "committedDate": "2020-04-07T09:28:50Z", "type": "commit"}, {"oid": "fc4a65b967de1c7677513d059c8da0bb5d19c973", "url": "https://github.com/apache/iotdb/commit/fc4a65b967de1c7677513d059c8da0bb5d19c973", "message": "use log list to store log data", "committedDate": "2020-04-08T11:03:38Z", "type": "commit"}, {"oid": "a86f4b455ce72f1f0d5869c6499893e562ec07da", "url": "https://github.com/apache/iotdb/commit/a86f4b455ce72f1f0d5869c6499893e562ec07da", "message": "fix bugs", "committedDate": "2020-04-09T01:09:08Z", "type": "commit"}, {"oid": "a3189d91a9f70a30bc88a24716cf74199f6f3fec", "url": "https://github.com/apache/iotdb/commit/a3189d91a9f70a30bc88a24716cf74199f6f3fec", "message": "Merge branch 'cluster_new' of https://github.com/apache/incubator-iotdb into IOTDB-351-serialize-raft-log\n\n# Conflicts:\n#\tcluster/src/main/java/org/apache/iotdb/cluster/config/ClusterDescriptor.java", "committedDate": "2020-04-10T11:46:52Z", "type": "commit"}, {"oid": "e1427a6ac0d03604235d0b0a2752e60d052d69f8", "url": "https://github.com/apache/iotdb/commit/e1427a6ac0d03604235d0b0a2752e60d052d69f8", "message": "fix conflict solving", "committedDate": "2020-04-10T16:32:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NDk1NQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407044955", "bodyText": "I want to add a new function \u201cvoid append(List entries)\u201d to support batch append so that it can be easily embedded with new design.You can do it without thinking about efficiency, and you can rewrite it after I've merged it. Of course, it would be better to focus on efficiency in the first place.", "author": "LebronAl", "createdAt": "2020-04-11T10:09:16Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/LogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.util.List;\n+import org.apache.iotdb.cluster.log.Log;\n+\n+public interface LogDequeSerializer {\n+", "originalCommit": "e1427a6ac0d03604235d0b0a2752e60d052d69f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NTUzNQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407045535", "bodyText": "I would like to add another function \"void removeCompactedEntries(long index)\" which means the persisted logs which index prior to index is able to be deleted.Of course, you can delete it lazily.But as we are not clear when to delete persisted raft logs so far,so you can implement it later.Just for reminding~", "author": "LebronAl", "createdAt": "2020-04-11T10:15:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NDk1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE0MDMzNg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407140336", "bodyText": "Thanks~, I will add  \u201cvoid append(List entries)\u201d and removeCompactedEntries can be achieved by remove function. In LogDequeSerializer, we don't know index but only the location of the logs. So it's memory log manager's responsibility to use index to find how many log we should remove.", "author": "SilverNarcissus", "createdAt": "2020-04-12T03:32:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NDk1NQ=="}], "type": "inlineReview"}, {"oid": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "url": "https://github.com/apache/iotdb/commit/3756f5cb9bd5965e40005ec0b02986242cbd53c3", "message": "add append log list", "committedDate": "2020-04-12T04:38:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4MzM0NA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407283344", "bodyText": "In fact, each raft member will have its own logs as they are in different groups. So I cannot figure out how it works if you put them all in one folder.\nMy suggestion is: for each member, create a folder like systemDir + File.separator + \"raftLog\" + File.separator + headerNode.identifier + File.separator + \"logMeta\". Notice that only data groups use header, so you can replace headerNode.identifier with string \"meta\" for the meta group.", "author": "jt2594838", "createdAt": "2020-04-13T01:53:04Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2Mjk2OA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407362968", "bodyText": "Sure~", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:48:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4MzM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NTA0OA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407285048", "bodyText": "Use logger.", "author": "jt2594838", "createdAt": "2020-04-13T02:03:21Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2Mjk3NQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407362975", "bodyText": "Sure~", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:48:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NTA0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjAzOA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286038", "bodyText": "I think you are opening the same file because you do not remove the deleted file from the list.", "author": "jt2594838", "createdAt": "2020-04-13T02:09:03Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2MzI4Mw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407363283", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:49:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjQ5Mw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286493", "bodyText": "init() is called during the initialization and it is not likely recoverMeta() is called before so I think minAvailableTime and maxAvailableTime are in the initial state.", "author": "jt2594838", "createdAt": "2020-04-13T02:12:07Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2MzUyNg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407363526", "bodyText": "fixed~", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:50:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4NjQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4Njc3Nw==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407286777", "bodyText": "Maybe here should be <=.", "author": "jt2594838", "createdAt": "2020-04-13T02:13:47Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2MzkzMQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407363931", "bodyText": "Use \"<\" means if the size of truncate is equal to file, we just truncate file rather than delete it.", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI4Njc3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MTU0NA==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407291544", "bodyText": "After openNewLogFile()\uff0cremovedLogSize > maxRemovedLogSize is still true. Consider the case, assuming the size of each log is 1:\ninitially: removedLogSize=50, maxRemovedLogSize=50, currentLogFileSize=100\nIf I call removeFirst(1) for ten times, each time removedLogSize > maxRemovedLogSize will be true and a new file will be open, even if the last log file may be empty.\nMy suggestion is: do not open new files during removals but during appending.\nFor example, each time the size of the current file >= maxRemovedLogSize after appending, open a new file, so the log files will have sizes around maxRemovedLogSize. And each time when removedLogSize > firstLogFile.length() after removal, you can just remove the first one or more files and set removedLogSize -= removedFile.length().", "author": "jt2594838", "createdAt": "2020-04-13T02:40:35Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();\n+        }\n+\n+        logFileList.remove(logFileList.size() - 1);\n+      }\n+      // else we just truncate it\n+      else {\n+        try {\n+          currentLogOutputStream.getChannel().truncate(getCurrentLogFile().length() - size);\n+          break;\n+        } catch (IOException e) {\n+          logger.error(\"Error in log serialization: \" + e.getMessage());\n+        }\n+      }\n+    }\n+\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      openNewLogFile();", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2NTYwOQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407365609", "bodyText": "That won't happen because in openNewLogFile, we firstly call actuallyDeleteFile, in this function we call adjustNextThreshold, maxRemovedLogSize will become the first log file length.", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:57:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MTU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgyMTY2MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407821661", "bodyText": "Is it possible that the log file becomes very small?\nFor example:\nWhen you close the 1st file, the length of the 1st file is 100, so you set maxRemovedLogSize to 100. But when removedLogSize reaches 100, the length of the 2nd file may only be 10, so you will set maxRemovedLogSize to 10.", "author": "jt2594838", "createdAt": "2020-04-14T02:02:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MTU0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MjY4MQ==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407292681", "bodyText": "It is not recommended to just override the origin file because if the system is down just after truncate, then everything is over.\nIt would be better to write a temporary file first and replace the old one with the new one such that at least the system can roll back to a previous state instead of a blank state. But during recovery, you will have to consider 3 cases: 1. both old file and new file exist; 2. only old file exists 3. only new file exists", "author": "jt2594838", "createdAt": "2020-04-13T02:47:37Z", "path": "cluster/src/main/java/org/apache/iotdb/cluster/log/manage/serializable/SyncLogDequeSerializer.java", "diffHunk": "@@ -0,0 +1,438 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.cluster.log.manage.serializable;\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.Deque;\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.iotdb.cluster.config.ClusterDescriptor;\n+import org.apache.iotdb.cluster.exception.UnknownLogTypeException;\n+import org.apache.iotdb.cluster.log.Log;\n+import org.apache.iotdb.cluster.log.LogParser;\n+import org.apache.iotdb.db.conf.IoTDBDescriptor;\n+import org.apache.iotdb.db.engine.fileSystem.SystemFileFactory;\n+import org.apache.iotdb.db.utils.TestOnly;\n+import org.apache.iotdb.tsfile.utils.ReadWriteIOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class SyncLogDequeSerializer implements LogDequeSerializer {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(SyncLogDequeSerializer.class);\n+\n+  List<File> logFileList;\n+  File metaFile;\n+  FileOutputStream currentLogOutputStream;\n+  FileOutputStream metaOutputStream;\n+  LogParser parser = LogParser.getINSTANCE();\n+  private Deque<Integer> logSizeDeque = new ArrayDeque<>();\n+  private LogManagerMeta meta;\n+  // mark first log position\n+  private long firstLogPosition = 0;\n+  // removed log size\n+  private long removedLogSize = 0;\n+  // when the removedLogSize larger than this, we actually delete logs\n+  private long maxRemovedLogSize = ClusterDescriptor.getINSTANCE().getConfig()\n+      .getMaxRemovedLogSize();\n+  // min time of available log\n+  private long minAvailableTime = 0;\n+  // max time of available log\n+  private long maxAvailableTime = Long.MAX_VALUE;\n+\n+\n+  /**\n+   * for log tools\n+   *\n+   * @param logPath log dir path\n+   */\n+  public SyncLogDequeSerializer(String logPath) {\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(logPath + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  /**\n+   * log in disk is [size of log1 | log1 buffer] [size of log2 | log2 buffer]... log meta buffer\n+   */\n+  public SyncLogDequeSerializer() {\n+    String systemDir = IoTDBDescriptor.getInstance().getConfig().getSystemDir();\n+    logFileList = new ArrayList<>();\n+    metaFile = SystemFileFactory.INSTANCE\n+        .getFile(systemDir + File.separator + \"raftLog\" + File.separator + \"logMeta\");\n+    init();\n+  }\n+\n+  @TestOnly\n+  public void setMaxRemovedLogSize(long maxRemovedLogSize) {\n+    this.maxRemovedLogSize = maxRemovedLogSize;\n+  }\n+\n+  public Deque<Integer> getLogSizeDeque() {\n+    return logSizeDeque;\n+  }\n+\n+  // init output stream\n+  private void init() {\n+    try {\n+      if (!metaFile.getParentFile().exists()) {\n+        metaFile.getParentFile().mkdir();\n+        metaFile.createNewFile();\n+      } else {\n+        for (File file : metaFile.getParentFile().listFiles()) {\n+          if (file.getName().startsWith(\"data\")) {\n+            long fileTime = getFileTime(file);\n+            // this means system down between save meta and data\n+            if (fileTime <= minAvailableTime || fileTime >= maxAvailableTime) {\n+              file.delete();\n+            } else {\n+              logFileList.add(file);\n+            }\n+          }\n+        }\n+        logFileList.sort(new Comparator<File>() {\n+          @Override\n+          public int compare(File o1, File o2) {\n+            return Long.compare(Long.parseLong(o1.getName().split(\"-\")[1]),\n+                Long.parseLong(o2.getName().split(\"-\")[1]));\n+          }\n+        });\n+      }\n+\n+      // add init log file\n+      if (logFileList.isEmpty()) {\n+        logFileList.add(createNewLogFile(metaFile.getParentFile().getPath()));\n+      }\n+\n+      currentLogOutputStream = new FileOutputStream(getCurrentLogFile(), true);\n+      metaOutputStream = new FileOutputStream(metaFile, true);\n+    } catch (IOException e) {\n+      logger.error(\"Error in init log file: \" + e.getMessage());\n+    }\n+  }\n+\n+  private File createNewLogFile(String dirName) throws IOException {\n+    File logFile = SystemFileFactory.INSTANCE\n+        .getFile(dirName + File.separator + \"data\" + \"-\" + System.currentTimeMillis());\n+    logFile.createNewFile();\n+    return logFile;\n+  }\n+\n+  @Override\n+  public void append(Log log, LogManagerMeta meta) {\n+    ByteBuffer data = log.serialize();\n+    int totalSize = 0;\n+    // write into disk\n+    try {\n+      totalSize = ReadWriteIOUtils.write(data, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void append(List<Log> logs, LogManagerMeta meta) {\n+    int bufferSize = 0;\n+    List<ByteBuffer> bufferList = new ArrayList<>(logs.size());\n+    for (Log log : logs) {\n+      ByteBuffer data = log.serialize();\n+      int size = data.capacity() + Integer.BYTES;\n+      logSizeDeque.addLast(size);\n+      bufferSize += size;\n+\n+      bufferList.add(data);\n+    }\n+\n+    ByteBuffer finalBuffer = ByteBuffer.allocate(bufferSize);\n+    for (ByteBuffer byteBuffer : bufferList) {\n+      finalBuffer.putInt(byteBuffer.capacity());\n+      finalBuffer.put(byteBuffer.array());\n+    }\n+\n+    // write into disk\n+    try {\n+      ReadWriteIOUtils.writeWithoutSize(finalBuffer, currentLogOutputStream);\n+    } catch (IOException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void removeLast(LogManagerMeta meta) {\n+    truncateLogIntern(1);\n+    serializeMeta(meta);\n+  }\n+\n+  @Override\n+  public void truncateLog(int count, LogManagerMeta meta) {\n+    truncateLogIntern(count);\n+    serializeMeta(meta);\n+  }\n+\n+  private File getCurrentLogFile() {\n+    return logFileList.get(logFileList.size() - 1);\n+  }\n+\n+  private void truncateLogIntern(int count) {\n+    if (logSizeDeque.size() < count) {\n+      throw new IllegalArgumentException(\"truncate log count is bigger than total log count\");\n+    }\n+\n+    int size = 0;\n+    for (int i = 0; i < count; i++) {\n+      size += logSizeDeque.removeLast();\n+    }\n+    // truncate file\n+    while (size > 0) {\n+      File currentLogFile = getCurrentLogFile();\n+      // if the last file is smaller than truncate size, we can delete it directly\n+      if (currentLogFile.length() < size) {\n+        size -= currentLogFile.length();\n+        try {\n+          currentLogOutputStream.close();\n+          // if system down before delete, we can use this to delete file during recovery\n+          maxAvailableTime = getFileTime(currentLogFile);\n+          serializeMeta(meta);\n+\n+          currentLogFile.delete();\n+          currentLogOutputStream = new FileOutputStream(getCurrentLogFile());\n+        } catch (IOException e) {\n+          e.printStackTrace();\n+        }\n+\n+        logFileList.remove(logFileList.size() - 1);\n+      }\n+      // else we just truncate it\n+      else {\n+        try {\n+          currentLogOutputStream.getChannel().truncate(getCurrentLogFile().length() - size);\n+          break;\n+        } catch (IOException e) {\n+          logger.error(\"Error in log serialization: \" + e.getMessage());\n+        }\n+      }\n+    }\n+\n+  }\n+\n+  @Override\n+  public void removeFirst(int num) {\n+    firstLogPosition += num;\n+    for (int i = 0; i < num; i++) {\n+      removedLogSize += logSizeDeque.removeFirst();\n+    }\n+\n+    // firstLogPosition changed\n+    serializeMeta(meta);\n+\n+    // do actual deletion\n+    if (removedLogSize > maxRemovedLogSize) {\n+      openNewLogFile();\n+    }\n+  }\n+\n+  @Override\n+  public List<Log> recoverLog() {\n+    if (meta == null) {\n+      recoverMeta();\n+    }\n+    // if we can totally remove some old file, remove them\n+    if (removedLogSize > 0) {\n+      actuallyDeleteFile();\n+    }\n+\n+    List<Log> result = new ArrayList<>();\n+    // skip removal file\n+    boolean shouldSkip = true;\n+\n+    for (File logFile : logFileList) {\n+      try {\n+        FileInputStream logReader = new FileInputStream(logFile);\n+        FileChannel logChannel = logReader.getChannel();\n+        if (shouldSkip) {\n+          long actuallySkippedBytes = logReader.skip(removedLogSize);\n+          if (actuallySkippedBytes != removedLogSize) {\n+            logger.info(\n+                \"Error in log serialization, skipped file length isn't consistent with removedLogSize!\");\n+            return result;\n+          }\n+          shouldSkip = false;\n+        }\n+\n+        while (logChannel.position() < logFile.length()) {\n+          // actual log\n+          Log log = readLog(logReader);\n+          result.add(log);\n+        }\n+        logReader.close();\n+      } catch (IOException e) {\n+        logger.error(\"Error in log serialization: \" + e.getMessage());\n+      }\n+    }\n+\n+    return result;\n+  }\n+\n+  // read single log\n+  private Log readLog(FileInputStream logReader) throws IOException {\n+    int logSize = ReadWriteIOUtils.readInt(logReader);\n+    int totalSize = Integer.BYTES + logSize;\n+\n+    Log log = null;\n+\n+    try {\n+      log = parser.parse(ByteBuffer.wrap(ReadWriteIOUtils.readBytes(logReader, logSize)));\n+    } catch (UnknownLogTypeException e) {\n+      logger.error(\"Error in log serialization: \" + e.getMessage());\n+    }\n+\n+    logSizeDeque.addLast(totalSize);\n+\n+    return log;\n+  }\n+\n+  @Override\n+  public LogManagerMeta recoverMeta() {\n+    if (meta == null && metaFile.exists() && metaFile.length() > 0) {\n+      try {\n+        FileInputStream metaReader = new FileInputStream(metaFile);\n+        firstLogPosition = ReadWriteIOUtils.readLong(metaReader);\n+        removedLogSize = ReadWriteIOUtils.readLong(metaReader);\n+        minAvailableTime = ReadWriteIOUtils.readLong(metaReader);\n+        maxAvailableTime = ReadWriteIOUtils.readLong(metaReader);\n+        meta = LogManagerMeta.deserialize(\n+            ByteBuffer.wrap(ReadWriteIOUtils.readBytesWithSelfDescriptionLength(metaReader)));\n+        metaReader.close();\n+      } catch (IOException e) {\n+        logger.error(\"Error in log serialization: \" + e.getMessage());\n+      }\n+    }\n+\n+    return meta;\n+  }\n+\n+  @Override\n+  public void serializeMeta(LogManagerMeta meta) {\n+    try {\n+      metaOutputStream.getChannel().truncate(0);", "originalCommit": "3756f5cb9bd5965e40005ec0b02986242cbd53c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM2NTgwMg==", "url": "https://github.com/apache/iotdb/pull/958#discussion_r407365802", "bodyText": "Sure, I see this problem, I will fix it.", "author": "SilverNarcissus", "createdAt": "2020-04-13T07:57:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5MjY4MQ=="}], "type": "inlineReview"}, {"oid": "eb1854152a60fa5ced6f332f3fa75e728b7154b8", "url": "https://github.com/apache/iotdb/commit/eb1854152a60fa5ced6f332f3fa75e728b7154b8", "message": "fix meta file bug and add more test", "committedDate": "2020-04-13T10:25:26Z", "type": "commit"}]}