{"pr_number": 931, "pr_title": "[IOTDB-540] Accelerate Previous Fill", "pr_createdAt": "2020-03-22T19:23:04Z", "pr_url": "https://github.com/apache/iotdb/pull/931", "timeline": [{"oid": "91970572163863374eff0cb9c3b52f4efe5caff6", "url": "https://github.com/apache/iotdb/commit/91970572163863374eff0cb9c3b52f4efe5caff6", "message": "Refactor previous fill phase 1", "committedDate": "2020-03-22T19:12:53Z", "type": "commit"}, {"oid": "7a60fb46cf6df7e3291d87d55fdccb80d1fb7790", "url": "https://github.com/apache/iotdb/commit/7a60fb46cf6df7e3291d87d55fdccb80d1fb7790", "message": "Refactor previous fill phase 1", "committedDate": "2020-03-22T19:12:53Z", "type": "commit"}, {"oid": "4939130dd0b91200eb5dd70f1fa5573e0eeb6931", "url": "https://github.com/apache/iotdb/commit/4939130dd0b91200eb5dd70f1fa5573e0eeb6931", "message": "Fix fillTest fail bug", "committedDate": "2020-03-23T17:10:57Z", "type": "commit"}, {"oid": "bc142aaede148e6db7431d3fa3c9d73716aba4c0", "url": "https://github.com/apache/iotdb/commit/bc142aaede148e6db7431d3fa3c9d73716aba4c0", "message": "Fix last with disable align bug", "committedDate": "2020-03-24T02:39:52Z", "type": "commit"}, {"oid": "88d812333047ec54004346b0745c52aa7368b861", "url": "https://github.com/apache/iotdb/commit/88d812333047ec54004346b0745c52aa7368b861", "message": "Revert \"Fix last with disable align bug\"\n\nThis reverts commit bc142aaede148e6db7431d3fa3c9d73716aba4c0.", "committedDate": "2020-03-27T01:16:50Z", "type": "commit"}, {"oid": "a1f4d08313751286798cf2812933002cb6142c6b", "url": "https://github.com/apache/iotdb/commit/a1f4d08313751286798cf2812933002cb6142c6b", "message": "Revert \"Fix fillTest fail bug\"\n\nThis reverts commit 4939130dd0b91200eb5dd70f1fa5573e0eeb6931.", "committedDate": "2020-03-27T01:17:04Z", "type": "commit"}, {"oid": "3914106033cdfaee555a20c1a32c00a700319848", "url": "https://github.com/apache/iotdb/commit/3914106033cdfaee555a20c1a32c00a700319848", "message": "Revert \"Refactor previous fill phase 1\"\n\nThis reverts commit 7a60fb46cf6df7e3291d87d55fdccb80d1fb7790.", "committedDate": "2020-03-27T01:17:15Z", "type": "commit"}, {"oid": "deffe39669d80b8b83eec62680a7ab4b9b59a790", "url": "https://github.com/apache/iotdb/commit/deffe39669d80b8b83eec62680a7ab4b9b59a790", "message": "Revert \"Refactor previous fill phase 1\"\n\nThis reverts commit 91970572163863374eff0cb9c3b52f4efe5caff6.", "committedDate": "2020-03-27T01:17:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2MTc5NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396961795", "bodyText": "false?", "author": "qiaojialin", "createdAt": "2020-03-24T08:02:33Z", "path": "server/src/main/java/org/apache/iotdb/db/qp/strategy/PhysicalGenerator.java", "diffHunk": "@@ -388,7 +383,11 @@ private PhysicalPlan transformQuery(QueryOperator queryOperator)\n \n       queryPlan = alignByDevicePlan;\n     } else {\n-      queryPlan.setAlignByTime(queryOperator.isAlignByTime());\n+      if (queryPlan instanceof LastQueryPlan) {\n+        queryPlan.setAlignByTime(true);", "originalCommit": "bc142aaede148e6db7431d3fa3c9d73716aba4c0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2NDEyMQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396964121", "bodyText": "what if the filter is time > 0 ?\nor the latest time point is 10 and the filter is time< 20?", "author": "qiaojialin", "createdAt": "2020-03-24T08:07:27Z", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/LastQueryExecutor.java", "diffHunk": "@@ -115,55 +116,47 @@ private TimeValuePair calculateLastPairForOneSeries(\n     } catch (MetadataException e) {\n       throw new QueryProcessException(e);\n     }\n-    if (((LeafMNode) node).getCachedLast() != null) {\n+    if (((LeafMNode) node).getCachedLast() != null && timeFilter == null) {\n       return ((LeafMNode) node).getCachedLast();\n     }\n \n-    QueryDataSource dataSource =\n-        QueryResourceManager.getInstance().getQueryDataSource(seriesPath, context, null);\n-\n-    List<TsFileResource> seqFileResources = dataSource.getSeqResources();\n-    List<TsFileResource> unseqFileResources = dataSource.getUnseqResources();\n-\n     TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n-\n-    if (!seqFileResources.isEmpty()) {\n-      for (int i = seqFileResources.size() - 1; i >= 0; i--) {\n-        List<ChunkMetaData> chunkMetadata =\n-            FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n-                seqFileResources.get(i), seriesPath, context);\n-        if (!chunkMetadata.isEmpty()) {\n-          ChunkMetaData lastChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n-          Statistics chunkStatistics = lastChunkMetaData.getStatistics();\n-          resultPair =\n-              constructLastPair(\n+    QueryDataSource queryDataSource =\n+        QueryResourceManager.getInstance().getQueryDataSource(seriesPath, context, timeFilter);\n+    timeFilter = queryDataSource.updateFilterUsingTTL(timeFilter);\n+\n+    InvertedSeriesReader seriesReader =\n+        new InvertedSeriesReader(\n+            seriesPath, tsDataType, context, queryDataSource, timeFilter, null, null);\n+\n+    while (seriesReader.hasNextChunk()) {\n+      // cal by chunk statistics\n+      if (seriesReader.canUseCurrentChunkStatistics()) {\n+        Statistics chunkStatistics = seriesReader.currentChunkStatistics();\n+        if (resultPair == null || resultPair.getTimestamp() < chunkStatistics.getEndTime()) {\n+          resultPair = constructLastPair(\n                   chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), tsDataType);\n-          break;\n         }\n-      }\n-    }\n+        seriesReader.skipCurrentChunk();\n+      } else {\n+        BatchData lastBatchData = null;\n+        while (seriesReader.hasNextPage()) {\n+          lastBatchData = seriesReader.nextPage();\n+        }\n \n-    long version = 0;\n-    for (TsFileResource resource : unseqFileResources) {\n-      if (resource.getEndTimeMap().get(seriesPath.getDevice()) < resultPair.getTimestamp()) {\n-        continue;\n-      }\n-      List<ChunkMetaData> chunkMetadata =\n-          FileLoaderUtils.loadChunkMetadataFromTsFileResource(resource, seriesPath, context);\n-      for (ChunkMetaData chunkMetaData : chunkMetadata) {\n-        if (chunkMetaData.getEndTime() == resultPair.getTimestamp()\n-            && chunkMetaData.getVersion() > version) {\n-          Statistics chunkStatistics = chunkMetaData.getStatistics();\n-          resultPair =\n-              constructLastPair(\n-                  chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), tsDataType);\n-          version = chunkMetaData.getVersion();\n+        if (lastBatchData != null) {\n+          if (resultPair == null || resultPair.getTimestamp() < lastBatchData.getMaxTimestamp()) {\n+            resultPair = new TimeValuePair(\n+                lastBatchData.getMaxTimestamp(),\n+                lastBatchData.getTsPrimitiveTypeByIndex(lastBatchData.length() - 1));\n+          }\n         }\n       }\n     }\n \n     // Update cached last value with low priority\n-    ((LeafMNode) node).updateCachedLast(resultPair, false, Long.MIN_VALUE);\n+    if (timeFilter == null)", "originalCommit": "bc142aaede148e6db7431d3fa3c9d73716aba4c0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODY3Mg==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396968672", "bodyText": "update  ttl?", "author": "qiaojialin", "createdAt": "2020-03-24T08:16:46Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +67,51 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    dataReader = new InvertedSeriesReader(path, dataType, context,\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter),", "originalCommit": "bc142aaede148e6db7431d3fa3c9d73716aba4c0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MDc2Mw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r401580763", "bodyText": "Fixed", "author": "wshao08", "createdAt": "2020-04-01T12:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODY3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njk2ODkyMg==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r396968922", "bodyText": "remove", "author": "qiaojialin", "createdAt": "2020-03-24T08:17:12Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -18,19 +18,27 @@\n  */\n package org.apache.iotdb.db.query.fill;\n \n+import org.apache.iotdb.db.exception.StorageEngineException;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.control.QueryResourceManager;\n+import org.apache.iotdb.db.query.reader.series.InvertedSeriesReader;\n import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n import org.apache.iotdb.tsfile.read.TimeValuePair;\n import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Path;\n import org.apache.iotdb.tsfile.read.filter.TimeFilter;\n import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n import org.apache.iotdb.tsfile.read.filter.factory.FilterFactory;\n \n import java.io.IOException;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n \n public class PreviousFill extends IFill {\n \n   private long beforeRange;\n   private BatchData batchData;", "originalCommit": "bc142aaede148e6db7431d3fa3c9d73716aba4c0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c0a684992c0339f95af72492e0e0dba4d6c9f4b0", "url": "https://github.com/apache/iotdb/commit/c0a684992c0339f95af72492e0e0dba4d6c9f4b0", "message": "refactor previous fill with simple reader", "committedDate": "2020-03-27T01:38:18Z", "type": "commit"}, {"oid": "4235a639a70907e042124adf409b80bba3c04be6", "url": "https://github.com/apache/iotdb/commit/4235a639a70907e042124adf409b80bba3c04be6", "message": "add PreviousFillExecutor and remove InvertedSeriesReader", "committedDate": "2020-03-29T17:07:58Z", "type": "commit"}, {"oid": "42c42e7623db6f88d48a272bc8f0969de233dccf", "url": "https://github.com/apache/iotdb/commit/42c42e7623db6f88d48a272bc8f0969de233dccf", "message": "Add update ttl before constructing PreviousFillExecutor", "committedDate": "2020-03-30T01:53:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NDM1MA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399894350", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n          \n          \n            \n                        lastSeqChunkMetaData = chunkMetadata.get(i);", "author": "qiaojialin", "createdAt": "2020-03-30T02:14:01Z", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);", "originalCommit": "42c42e7623db6f88d48a272bc8f0969de233dccf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExNTgzNg==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r400115836", "bodyText": "Fixed", "author": "wshao08", "createdAt": "2020-03-30T11:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NDM1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NjM5MA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399896390", "bodyText": "Suppose the queried time is 100.\nseq files: [1,10], [11,20], [200, 300]\nunseq files: [30, 40], [41, 50], [51, 60]\nIt's better not to find the lastSeqChunkMetadata but the last chunkmetadata between seq and unseq.", "author": "qiaojialin", "createdAt": "2020-03-30T02:24:57Z", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+    } else {\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetaData metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n+    }\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * unpack all overlapped seq/unseq files and find the first chunk metadata\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas() throws IOException {\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.remove(index);\n+      List<ChunkMetaData> chunkMetadata = FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+          resource, seriesPath, context);\n+      if (!chunkMetadata.isEmpty()) {\n+        for (int i = chunkMetadata.size() - 1; i >= 0; i--) {\n+          if (chunkMetadata.get(i).getStartTime() <= queryTime) {\n+            lastSeqChunkMetaData = chunkMetadata.get(chunkMetadata.size() - 1);\n+            chunkMetadatas.add(lastSeqChunkMetaData);\n+            break;\n+          }\n+        }\n+        break;\n+      }\n+    }\n+\n+    while (!unseqFileResource.isEmpty()\n+        && (lastSeqChunkMetaData == null || (lastSeqChunkMetaData.getStartTime()\n+        <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())))) {\n+      chunkMetadatas.addAll(", "originalCommit": "42c42e7623db6f88d48a272bc8f0969de233dccf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwNzU0OQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402007549", "bodyText": "modified", "author": "wshao08", "createdAt": "2020-04-02T01:49:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NjM5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5Njg3MQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399896871", "bodyText": "the pageReader must satisfy this timeFilter, otherwise it will be removed when unpack the ChunkMetadata. This check is not needed.", "author": "qiaojialin", "createdAt": "2020-03-30T02:27:18Z", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/PreviousFillExecutor.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.iotdb.db.query.executor;\n+\n+import java.sql.Time;\n+import org.apache.iotdb.db.engine.querycontext.QueryDataSource;\n+import org.apache.iotdb.db.engine.storagegroup.TsFileResource;\n+import org.apache.iotdb.db.query.context.QueryContext;\n+import org.apache.iotdb.db.query.filter.TsFileFilter;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkLoader;\n+import org.apache.iotdb.db.query.reader.chunk.MemChunkReader;\n+import org.apache.iotdb.db.utils.FileLoaderUtils;\n+import org.apache.iotdb.db.utils.QueryUtils;\n+import org.apache.iotdb.tsfile.file.metadata.ChunkMetaData;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.statistics.Statistics;\n+import org.apache.iotdb.tsfile.read.TimeValuePair;\n+import org.apache.iotdb.tsfile.read.common.BatchData;\n+import org.apache.iotdb.tsfile.read.common.Chunk;\n+import org.apache.iotdb.tsfile.read.common.Path;\n+import org.apache.iotdb.tsfile.read.controller.IChunkLoader;\n+import org.apache.iotdb.tsfile.read.filter.basic.Filter;\n+import org.apache.iotdb.tsfile.read.reader.IChunkReader;\n+import org.apache.iotdb.tsfile.read.reader.IPageReader;\n+import org.apache.iotdb.tsfile.read.reader.chunk.ChunkReader;\n+\n+import java.io.IOException;\n+import java.util.*;\n+import org.apache.iotdb.tsfile.utils.TsPrimitiveType;\n+\n+public class PreviousFillExecutor {\n+\n+  private final Path seriesPath;\n+  private final TSDataType dataType;\n+  private final QueryContext context;\n+  private long queryTime;\n+\n+  private final Filter timeFilter;\n+\n+  /*\n+   * file cache\n+   */\n+  private final List<TsFileResource> seqFileResource;\n+  private final PriorityQueue<TsFileResource> unseqFileResource;\n+\n+  /*\n+   * chunk cache\n+   */\n+  private ChunkMetaData lastSeqChunkMetaData;\n+  private final List<ChunkMetaData> chunkMetadatas;\n+\n+  public PreviousFillExecutor(Path seriesPath, TSDataType dataType, QueryContext context,\n+      QueryDataSource dataSource, Filter timeFilter, Filter valueFilter, TsFileFilter fileFilter,\n+      long queryTime) {\n+    this.seriesPath = seriesPath;\n+    this.dataType = dataType;\n+    this.context = context;\n+    QueryUtils.filterQueryDataSource(dataSource, fileFilter);\n+    this.seqFileResource = dataSource.getSeqResources();\n+    this.unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    this.chunkMetadatas = new ArrayList<>();\n+    this.timeFilter = timeFilter;\n+    this.queryTime = queryTime;\n+  }\n+\n+  public TimeValuePair getLastPoint() throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas();\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetaData chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n+      }\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetaData chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n+      }\n+      return lastPoint;\n+    }\n+  }\n+\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {", "originalCommit": "42c42e7623db6f88d48a272bc8f0969de233dccf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzEzMg==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399897132", "bodyText": "Is this method used?", "author": "qiaojialin", "createdAt": "2020-03-30T02:28:41Z", "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,35 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TsPrimitiveType getTsPrimitiveTypeByIndex(int idx) {", "originalCommit": "42c42e7623db6f88d48a272bc8f0969de233dccf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExNTc1MA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r400115750", "bodyText": "This is legacy code, removed", "author": "wshao08", "createdAt": "2020-03-30T11:22:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzEzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzY4OA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r399897688", "bodyText": "Move these to the constructor of PreviousFill, leave empty for the constructReaders. The LinearFill should also be refactored, then this method will be removed", "author": "qiaojialin", "createdAt": "2020-03-30T02:31:48Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -61,26 +68,19 @@ public long getBeforeRange() {\n \n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n-      }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n-        break;\n-      }\n-    }\n+    return executor.getLastPoint();\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n-    }\n-    return beforePair;\n+  @Override\n+  public void constructReaders(Path path, QueryContext context)\n+      throws StorageEngineException {\n+    Filter timeFilter = constructFilter();\n+    QueryDataSource queryDataSource =\n+        QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = queryDataSource.updateFilterUsingTTL(timeFilter);\n+    executor = new PreviousFillExecutor(\n+        path, dataType, context, queryDataSource, timeFilter, null, null, queryTime);", "originalCommit": "42c42e7623db6f88d48a272bc8f0969de233dccf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU5NDY3MQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r401594671", "bodyText": "Removed, move these init code into configureFill", "author": "wshao08", "createdAt": "2020-04-01T12:58:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTg5NzY4OA=="}], "type": "inlineReview"}, {"oid": "412a4e63da95742dd6cbec153270d581cfae141c", "url": "https://github.com/apache/iotdb/commit/412a4e63da95742dd6cbec153270d581cfae141c", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-03-31T09:43:00Z", "type": "commit"}, {"oid": "980c1428def2449998289d26b51bdc0f0e1ede1f", "url": "https://github.com/apache/iotdb/commit/980c1428def2449998289d26b51bdc0f0e1ede1f", "message": "integrate previousFill with new tsFile interfaces", "committedDate": "2020-03-31T17:26:12Z", "type": "commit"}, {"oid": "f3fbf89e9044d49672a21bff9d4cbb56fbb8d31a", "url": "https://github.com/apache/iotdb/commit/f3fbf89e9044d49672a21bff9d4cbb56fbb8d31a", "message": "Fix null pointer crash bug", "committedDate": "2020-04-01T03:50:21Z", "type": "commit"}, {"oid": "29274740bf094251783352e353104549df530932", "url": "https://github.com/apache/iotdb/commit/29274740bf094251783352e353104549df530932", "message": "Add more integration tests for fill", "committedDate": "2020-04-01T12:20:46Z", "type": "commit"}, {"oid": "1a04a5255b1ab02808b3caef84998e7b9224c178", "url": "https://github.com/apache/iotdb/commit/1a04a5255b1ab02808b3caef84998e7b9224c178", "message": "modify configureFill as an initiator", "committedDate": "2020-04-01T12:56:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAxMTQ5Mw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402011493", "bodyText": "store context in FIll, remove the parameter in getFillResult", "author": "qiaojialin", "createdAt": "2020-04-02T02:06:09Z", "path": "server/src/main/java/org/apache/iotdb/db/query/executor/FillQueryExecutor.java", "diffHunk": "@@ -89,9 +89,10 @@ public QueryDataSet execute(QueryContext context, FillQueryPlan fillQueryPlan)\n       } else {\n         fill = typeIFillMap.get(dataType).copy();\n       }\n-      configureFill(fill, dataType, path, fillQueryPlan.getAllSensorsInDevice(path.getDevice()), context, queryTime);\n+      fill.configureFill(path, dataType, queryTime,\n+          fillQueryPlan.getAllSensorsInDevice(path.getDevice()), context);\n \n-      TimeValuePair timeValuePair = fill.getFillResult();\n+      TimeValuePair timeValuePair = fill.getFillResult(context);", "originalCommit": "1a04a5255b1ab02808b3caef84998e7b9224c178", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyMDEyOQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402020129", "bodyText": "the timeFilter  can not be null", "author": "qiaojialin", "createdAt": "2020-04-02T02:41:04Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +98,162 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas(context);\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetadata chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {\n+        lastPoint = lastChunkPoint;\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n-        break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    } else {\n+      List<IPageReader> pageReaders = unpackChunkReaderToPageReaderList(chunkMetaData);\n+      TimeValuePair lastPoint = new TimeValuePair(0, null);\n+      for (IPageReader pageReader : pageReaders) {\n+        TimeValuePair lastPagePoint = getPageLastPoint(pageReader);\n+        if (lastPoint.getTimestamp() < lastPagePoint.getTimestamp()) {\n+          lastPoint = lastPagePoint;\n+        }\n       }\n+      return lastPoint;\n     }\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n+  private TimeValuePair getPageLastPoint(IPageReader pageReader) throws IOException {\n+    Statistics pageStatistics = pageReader.getStatistics();\n+    if (!timeFilter.satisfy(pageStatistics)) {\n+      return null;\n+    }\n+    if (containedByTimeFilter(pageStatistics)) {\n+      return constructLastPair(\n+          pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n     } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+      BatchData batchData = pageReader.getAllSatisfiedPageData();\n+      return batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+    }\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private List<IPageReader> unpackChunkReaderToPageReaderList(ChunkMetadata metaData) throws IOException {\n+    if (metaData == null) {\n+      throw new IOException(\"Can't init null chunkMeta\");\n     }\n-    return beforePair;\n+    IChunkReader chunkReader;\n+    IChunkLoader chunkLoader = metaData.getChunkLoader();\n+    if (chunkLoader instanceof MemChunkLoader) {\n+      MemChunkLoader memChunkLoader = (MemChunkLoader) chunkLoader;\n+      chunkReader = new MemChunkReader(memChunkLoader.getChunk(), timeFilter);\n+    } else {\n+      Chunk chunk = chunkLoader.getChunk(metaData);\n+      chunkReader = new ChunkReader(chunk, timeFilter);\n+      chunkReader.hasNextSatisfiedPage();\n+    }\n+    return chunkReader.getPageReaderList();\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * find the last chunk metadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackAllOverlappedFilesToChunkMetadatas(QueryContext context) throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    PriorityQueue<TsFileResource> unseqFileResource = sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata = FileLoaderUtils.loadTimeSeriesMetadata(\n+          resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        // The last seq file satisfies timeFilter, pick up the last chunk\n+        List<ChunkMetadata> chunkMetadata = timeseriesMetadata.getChunkMetadataList();\n+        lastChunkMetadata = chunkMetadata.get(chunkMetadata.size() - 1);\n+        chunkMetadatas.addAll(chunkMetadata);\n+        break;\n+      }\n+      seqFileResource.remove(index);\n+    }\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      TsFileResource resource = unseqFileResource.peek();\n+      TimeseriesMetadata timeseriesMetadata = FileLoaderUtils.loadTimeSeriesMetadata(\n+          resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        List<ChunkMetadata> chunkMetadatas = timeseriesMetadata.getChunkMetadataList();\n+        ChunkMetadata lastUnseqChunkMetadata = chunkMetadatas.get(chunkMetadatas.size() - 1);\n+        if (lastChunkMetadata == null) {\n+          lastChunkMetadata = lastUnseqChunkMetadata;\n+        } else if (lastChunkMetadata.getEndTime() < lastUnseqChunkMetadata.getEndTime()) {\n+          lastChunkMetadata = lastUnseqChunkMetadata;\n+        }\n+        break;\n+      }\n+      unseqFileResource.poll();\n+    }\n+\n+    // unpack all overlapped unseq files and fill chunkMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lastChunkMetadata == null || (lastChunkMetadata.getStartTime()\n+        <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())))) {\n+      chunkMetadatas.addAll(\n+          FileLoaderUtils.loadChunkMetadataFromTsFileResource(\n+              unseqFileResource.poll(), seriesPath, context));\n+    }\n+  }\n+\n+  private boolean containedByTimeFilter(Statistics statistics) {\n+    return timeFilter == null", "originalCommit": "1a04a5255b1ab02808b3caef84998e7b9224c178", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAyMDI2NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r402020265", "bodyText": "this may produce NullPointerException", "author": "qiaojialin", "createdAt": "2020-04-02T02:41:40Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +98,162 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackAllOverlappedFilesToChunkMetadatas(context);\n+\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!chunkMetadatas.isEmpty()) {\n+      ChunkMetadata chunkMetaData = chunkMetadatas.remove(0);\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetaData);\n+      if (shouldUpdate(\n+          lastPoint.getTimestamp(), chunkMetaData.getVersion(),\n+          lastChunkPoint.getTimestamp(), lastVersion)) {", "originalCommit": "1a04a5255b1ab02808b3caef84998e7b9224c178", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ae6bbcdb26cb08cc2b851c50661871887373cdba", "url": "https://github.com/apache/iotdb/commit/ae6bbcdb26cb08cc2b851c50661871887373cdba", "message": "Fix previous fill bugs", "committedDate": "2020-04-02T17:07:05Z", "type": "commit"}, {"oid": "7a6b644868d27a5c1ba3ff0bb479a831e024e6f5", "url": "https://github.com/apache/iotdb/commit/7a6b644868d27a5c1ba3ff0bb479a831e024e6f5", "message": "Move load chunkMetadata to PageReader into utils", "committedDate": "2020-04-03T03:19:41Z", "type": "commit"}, {"oid": "0319b167f8fd5fc4712c3b3ae17844e1b33f9af4", "url": "https://github.com/apache/iotdb/commit/0319b167f8fd5fc4712c3b3ae17844e1b33f9af4", "message": "Revert \"Move load chunkMetadata to PageReader into utils\"\n\nThis reverts commit 7a6b644868d27a5c1ba3ff0bb479a831e024e6f5.", "committedDate": "2020-04-03T03:27:19Z", "type": "commit"}, {"oid": "1cf87059279df922b5fa4bb2c50eacaaa23228e9", "url": "https://github.com/apache/iotdb/commit/1cf87059279df922b5fa4bb2c50eacaaa23228e9", "message": "Revert \"Fix previous fill bugs\"\n\nThis reverts commit ae6bbcdb26cb08cc2b851c50661871887373cdba.", "committedDate": "2020-04-03T03:27:31Z", "type": "commit"}, {"oid": "f1f3194f0a6966cd14eeef64bd386d010d2a9980", "url": "https://github.com/apache/iotdb/commit/f1f3194f0a6966cd14eeef64bd386d010d2a9980", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-04-03T03:43:49Z", "type": "commit"}, {"oid": "5a215a22cbe34512dde1a6f507459d3a9f4895ce", "url": "https://github.com/apache/iotdb/commit/5a215a22cbe34512dde1a6f507459d3a9f4895ce", "message": "Fix compile bug", "committedDate": "2020-04-03T07:53:14Z", "type": "commit"}, {"oid": "cc34c32cc920ab31ab1ce6d33e8e217fbf63a5a7", "url": "https://github.com/apache/iotdb/commit/cc34c32cc920ab31ab1ce6d33e8e217fbf63a5a7", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-04-03T08:15:48Z", "type": "commit"}, {"oid": "7a3bff6ef582dd1d9ed52e63549431ccdcb1dbbb", "url": "https://github.com/apache/iotdb/commit/7a3bff6ef582dd1d9ed52e63549431ccdcb1dbbb", "message": "use timeseries metadata in previous fill", "committedDate": "2020-04-03T09:07:00Z", "type": "commit"}, {"oid": "562e08cac4dc3c4cfc86afefcf9b06d58b45ef1d", "url": "https://github.com/apache/iotdb/commit/562e08cac4dc3c4cfc86afefcf9b06d58b45ef1d", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-04-03T09:28:29Z", "type": "commit"}, {"oid": "28a28564114167718e966e34439a8ba12a8dcf24", "url": "https://github.com/apache/iotdb/commit/28a28564114167718e966e34439a8ba12a8dcf24", "message": "Modify timeseries usage in previous fill", "committedDate": "2020-04-03T11:43:08Z", "type": "commit"}, {"oid": "232af072667edebda97a3df85eab822dbab5bfbd", "url": "https://github.com/apache/iotdb/commit/232af072667edebda97a3df85eab822dbab5bfbd", "message": "Fix repeatedly call getChunkMetadataList() in TsFileResource crash bug", "committedDate": "2020-04-03T12:13:18Z", "type": "commit"}, {"oid": "f0b44d5f2aacad05f3e761255e3d8e93c68b723a", "url": "https://github.com/apache/iotdb/commit/f0b44d5f2aacad05f3e761255e3d8e93c68b723a", "message": "remove unused methods and imports", "committedDate": "2020-04-03T12:19:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzAxNDU1NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r403014555", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * find the last chunk metadata and unpack all overlapped seq/unseq files\n          \n          \n            \n               * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files", "author": "qiaojialin", "createdAt": "2020-04-03T13:43:40Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -60,27 +87,143 @@ public long getBeforeRange() {\n   }\n \n   @Override\n-  public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n+  @Override\n+  public TimeValuePair getFillResult(QueryContext context) throws IOException {\n+    UnpackOverlappedFilesToTimeseriesMetadata(context);\n+    return getTimeseriesLastPoint();\n+  }\n+\n+  private  TimeValuePair getTimeseriesLastPoint() throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    long lastVersion = 0;\n+    while (!timeseriesMetadataList.isEmpty()) {\n+      TimeseriesMetadata timeseriesMetadata = timeseriesMetadataList.remove(0);\n+      List<ChunkMetadata> chunkMetadataList = timeseriesMetadata.loadChunkMetadataList();\n+      for (ChunkMetadata chunkMetadata : chunkMetadataList) {\n+        TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+        if (shouldUpdate(lastPoint.getTimestamp(), lastVersion,\n+            lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+          lastPoint = lastChunkPoint;\n+          lastVersion = chunkMetadata.getVersion();\n+        }\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+    if (!timeFilter.satisfy(chunkStatistics)) {\n+      return lastPoint;\n+    }\n+    if (containedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReader(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }\n+      if (containedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n       } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n+\n+  /**\n+   * find the last chunk metadata and unpack all overlapped seq/unseq files", "originalCommit": "f0b44d5f2aacad05f3e761255e3d8e93c68b723a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bf019511d7f9f9809e63661dcc9563e8e3c4e42f", "url": "https://github.com/apache/iotdb/commit/bf019511d7f9f9809e63661dcc9563e8e3c4e42f", "message": "further optimize previous fill", "committedDate": "2020-04-06T14:08:22Z", "type": "commit"}, {"oid": "c63a6ade2969b49aa5812a70cd4c50c0a1056d4c", "url": "https://github.com/apache/iotdb/commit/c63a6ade2969b49aa5812a70cd4c50c0a1056d4c", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-04-07T01:08:32Z", "type": "commit"}, {"oid": "54bae77cddd5e9671912c5aaf54a73ff2b623aa8", "url": "https://github.com/apache/iotdb/commit/54bae77cddd5e9671912c5aaf54a73ff2b623aa8", "message": "Fix compile issue after merge with master", "committedDate": "2020-04-07T01:13:02Z", "type": "commit"}, {"oid": "02e53496fa2f7a07f806fd5d0c79e3feba8c74e2", "url": "https://github.com/apache/iotdb/commit/02e53496fa2f7a07f806fd5d0c79e3feba8c74e2", "message": "Update server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java\n\nCo-Authored-By: Jialin Qiao <qjl16@mails.tsinghua.edu.cn>", "committedDate": "2020-04-07T03:36:08Z", "type": "commit"}, {"oid": "708cff19d8889ce6dbf1a016332ec4f6b6f490e6", "url": "https://github.com/apache/iotdb/commit/708cff19d8889ce6dbf1a016332ec4f6b6f490e6", "message": "Optimize tsFile filtering routine", "committedDate": "2020-04-09T02:03:45Z", "type": "commit"}, {"oid": "236159ef6b005062e1e36ca396786b507548f875", "url": "https://github.com/apache/iotdb/commit/236159ef6b005062e1e36ca396786b507548f875", "message": "refactor previous fill again", "committedDate": "2020-04-09T06:34:37Z", "type": "commit"}, {"oid": "0a0ece4e8d7f0818309bbbed1e7a5185d5c87d21", "url": "https://github.com/apache/iotdb/commit/0a0ece4e8d7f0818309bbbed1e7a5185d5c87d21", "message": "Format minor changes", "committedDate": "2020-04-09T06:49:49Z", "type": "commit"}, {"oid": "9e5607afcd9149d33662155c8c7aa13d8140db1f", "url": "https://github.com/apache/iotdb/commit/9e5607afcd9149d33662155c8c7aa13d8140db1f", "message": "change all default fill types to previous fill", "committedDate": "2020-04-09T07:23:00Z", "type": "commit"}, {"oid": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "url": "https://github.com/apache/iotdb/commit/b355ad25834a7ea21bb73922c2f5013f0b1f5694", "message": "Change test case result as the default fill type is changed to previous fill", "committedDate": "2020-04-09T09:04:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MTU1NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406251555", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(0, null);\n          \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);", "author": "qiaojialin", "createdAt": "2020-04-09T14:36:52Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MjMwMw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252303", "bodyText": "Suppose two unseq files have the same endTime, they should all be unpacked.", "author": "qiaojialin", "createdAt": "2020-04-09T14:38:03Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MjUwNw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252507", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(0, null);\n          \n          \n            \n                TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);", "author": "qiaojialin", "createdAt": "2020-04-09T14:38:19Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1Mjk3Mg==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406252972", "bodyText": "no need to check, pageReaders got from chunkmetadata should satisfy the timeFilter already", "author": "qiaojialin", "createdAt": "2020-04-09T14:38:56Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1MzU5Mw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406253593", "bodyText": "no need to remove(0),just traverse is ok. Otherwise, use LinkedList for higher efficiency", "author": "qiaojialin", "createdAt": "2020-04-09T14:39:44Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+        break;\n+      }\n+    }\n+\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n         break;\n       }\n     }\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(0, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (!timeFilter.satisfy(pageStatistics)) {\n+        continue;\n+      }\n+      if (endtimeContainedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+      } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }\n+    return lastPoint;\n+  }\n+\n+  private boolean shouldUpdate(long time, long version, long newTime, long newVersion) {\n+    return time < newTime || (time == newTime && version < newVersion);\n+  }\n+\n+  private PriorityQueue<TsFileResource> sortUnSeqFileResourcesInDecendingOrder(\n+      List<TsFileResource> tsFileResources) {\n+    PriorityQueue<TsFileResource> unseqTsFilesSet =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              Map<String, Long> startTimeMap = o1.getEndTimeMap();\n+              Long minTimeOfO1 = startTimeMap.get(seriesPath.getDevice());\n+              Map<String, Long> startTimeMap2 = o2.getEndTimeMap();\n+              Long minTimeOfO2 = startTimeMap2.get(seriesPath.getDevice());\n+\n+              return Long.compare(minTimeOfO2, minTimeOfO1);\n+            });\n+    unseqTsFilesSet.addAll(tsFileResources);\n+    return unseqTsFilesSet;\n+  }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+  private PriorityQueue<ChunkMetadata> sortUnseqChunkMetadatasByEndtime() throws IOException {\n+    PriorityQueue<ChunkMetadata> chunkMetadataList =\n+        new PriorityQueue<>(\n+            (o1, o2) -> {\n+              long endTime1 = o1.getEndTime();\n+              long endTime2 = o2.getEndTime();\n+              if (endTime1 < endTime2) {\n+                return 1;\n+              } else if (endTime1 > endTime2) {\n+                return -1;\n+              }\n+              return Long.compare(o2.getVersion(), o1.getVersion());\n+            });\n+    while (!unseqTimeseriesMetadataList.isEmpty()) {\n+      chunkMetadataList.addAll(unseqTimeseriesMetadataList.remove(0).loadChunkMetadataList());", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjI1NDA5Nw==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406254097", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {\n          \n          \n            \n                    && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {", "author": "qiaojialin", "createdAt": "2020-04-09T14:40:26Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,184 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() < sortedChunkMetatdataList.peek().getEndTime()) {", "originalCommit": "b355ad25834a7ea21bb73922c2f5013f0b1f5694", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "64c1308be1ab1bcdf2a28ec505f93bb2e542ba21", "url": "https://github.com/apache/iotdb/commit/64c1308be1ab1bcdf2a28ec505f93bb2e542ba21", "message": "Update server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java\n\nCo-Authored-By: Jialin Qiao <qjl16@mails.tsinghua.edu.cn>", "committedDate": "2020-04-09T16:18:27Z", "type": "commit"}, {"oid": "5e19a98bb8e1b04b187e03f90f9a86beea720d62", "url": "https://github.com/apache/iotdb/commit/5e19a98bb8e1b04b187e03f90f9a86beea720d62", "message": "Update server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java\n\nCo-Authored-By: Jialin Qiao <qjl16@mails.tsinghua.edu.cn>", "committedDate": "2020-04-09T16:18:50Z", "type": "commit"}, {"oid": "473071057f8af80ce2d9688d9077a9cedaa4905a", "url": "https://github.com/apache/iotdb/commit/473071057f8af80ce2d9688d9077a9cedaa4905a", "message": "Update server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java\n\nCo-Authored-By: Jialin Qiao <qjl16@mails.tsinghua.edu.cn>", "committedDate": "2020-04-09T16:19:39Z", "type": "commit"}, {"oid": "a85361808d9dad8c659b2335ce59acfeab9015b8", "url": "https://github.com/apache/iotdb/commit/a85361808d9dad8c659b2335ce59acfeab9015b8", "message": "correct review issues", "committedDate": "2020-04-09T16:29:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406565069", "bodyText": "What if the currentTime is not at the first index before i call the getLastPairBeforeOrEqualTimestamp method.\nSo, you should call the resetBatchData() method at the beginning of the method or you should add a javadoc for this method to remind caller that function caller should ensure the current place.", "author": "JackieTien97", "createdAt": "2020-04-10T01:50:42Z", "path": "tsfile/src/main/java/org/apache/iotdb/tsfile/read/common/BatchData.java", "diffHunk": "@@ -533,6 +534,16 @@ public boolean getBooleanByIndex(int idx) {\n     return booleanRet.get(idx / capacity)[idx % capacity];\n   }\n \n+  public TimeValuePair getLastPairBeforeOrEqualTimestamp(long queryTime) {\n+    TimeValuePair resultPair = new TimeValuePair(Long.MIN_VALUE, null);\n+    while (hasCurrent() && (currentTime() <= queryTime)) {\n+      resultPair.setTimestamp(currentTime());\n+      resultPair.setValue(currentTsPrimitiveType());\n+      next();\n+    }\n+    return resultPair;\n+  }\n+", "originalCommit": "a85361808d9dad8c659b2335ce59acfeab9015b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTM2NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406565365", "bodyText": "And BTW, i think you can improve your search way like using binary search instead of the linear search way because the time array is in order and are all loaded into memory.", "author": "JackieTien97", "createdAt": "2020-04-10T01:52:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTQ4MA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711480", "bodyText": "Added resetBatchData() at the beginning.", "author": "wshao08", "createdAt": "2020-04-10T11:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2NTA2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2OTA5NQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406569095", "bodyText": "Before you use the statistics info you should use the canUseStatistics() method in the Statistics class to judge whether the statistics can be used. Because may be the chunk has been modified.\nNot only here, chunk statistics and page statistics are the same", "author": "JackieTien97", "createdAt": "2020-04-10T02:07:37Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);", "originalCommit": "a85361808d9dad8c659b2335ce59acfeab9015b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTQwNA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711404", "bodyText": "Fixed", "author": "wshao08", "createdAt": "2020-04-10T11:06:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU2OTA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU3MTEyOQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406571129", "bodyText": "same as above, remember use canUseStatistics()", "author": "JackieTien97", "createdAt": "2020-04-10T02:16:15Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {", "originalCommit": "a85361808d9dad8c659b2335ce59acfeab9015b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTM4OA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711388", "bodyText": "Fixed", "author": "wshao08", "createdAt": "2020-04-10T11:06:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjU3MTEyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3NDU4OQ==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406674589", "bodyText": "with a break, the for loop is not used", "author": "samperson1997", "createdAt": "2020-04-10T09:09:17Z", "path": "server/src/main/java/org/apache/iotdb/db/query/fill/PreviousFill.java", "diffHunk": "@@ -59,28 +84,183 @@ public long getBeforeRange() {\n     return beforeRange;\n   }\n \n+  @Override\n+  public void configureFill(Path path, TSDataType dataType, long queryTime,\n+      Set<String> sensors, QueryContext context)\n+      throws StorageEngineException, QueryProcessException {\n+    this.seriesPath = path;\n+    this.dataType = dataType;\n+    this.context = context;\n+    this.queryTime = queryTime;\n+    this.allSensors = sensors;\n+    this.timeFilter = constructFilter();\n+    this.dataSource = QueryResourceManager.getInstance().getQueryDataSource(path, context, timeFilter);\n+    // update filter by TTL\n+    timeFilter = dataSource.updateFilterUsingTTL(timeFilter);\n+  }\n+\n   @Override\n   public TimeValuePair getFillResult() throws IOException {\n-    TimeValuePair beforePair = null;\n-    TimeValuePair cachedPair;\n-    while (batchData.hasCurrent() || allDataReader.hasNextBatch()) {\n-      if (!batchData.hasCurrent() && allDataReader.hasNextBatch()) {\n-        batchData = allDataReader.nextBatch();\n+    TimeValuePair lastPointResult = retrieveValidLastPointFromSeqFiles();\n+    UnpackOverlappedUnseqFiles(lastPointResult.getTimestamp());\n+\n+    long lastVersion = 0;\n+    PriorityQueue<ChunkMetadata> sortedChunkMetatdataList = sortUnseqChunkMetadatasByEndtime();\n+    while (!sortedChunkMetatdataList.isEmpty()\n+        && lastPointResult.getTimestamp() <= sortedChunkMetatdataList.peek().getEndTime()) {\n+      ChunkMetadata chunkMetadata = sortedChunkMetatdataList.poll();\n+      TimeValuePair lastChunkPoint = getChunkLastPoint(chunkMetadata);\n+      if (shouldUpdate(lastPointResult.getTimestamp(), lastVersion,\n+          lastChunkPoint.getTimestamp(), chunkMetadata.getVersion())) {\n+        lastPointResult = lastChunkPoint;\n+        lastVersion = chunkMetadata.getVersion();\n       }\n-      cachedPair = new TimeValuePair(batchData.currentTime(), batchData.currentTsPrimitiveType());\n-      batchData.next();\n-      if (cachedPair.getTimestamp() <= queryTime) {\n-        beforePair = cachedPair;\n-      } else {\n+    }\n+    return lastPointResult;\n+  }\n+\n+  /** Pick up and cache the last sequence TimeseriesMetadata that satisfies timeFilter */\n+  private TimeValuePair retrieveValidLastPointFromSeqFiles() throws IOException {\n+    List<TsFileResource> seqFileResource = dataSource.getSeqResources();\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    for (int index = seqFileResource.size() - 1; index >= 0; index--) {\n+      TsFileResource resource = seqFileResource.get(index);\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              resource, seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null) {\n+        if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())) {\n+          return constructLastPair(\n+              timeseriesMetadata.getStatistics().getEndTime(),\n+              timeseriesMetadata.getStatistics().getLastValue(),\n+              dataType);\n+        } else {\n+          List<ChunkMetadata> seqChunkMetadataList =\n+              FileLoaderUtils.loadChunkMetadataList(timeseriesMetadata);\n+\n+          for (int i = seqChunkMetadataList.size() - 1; i >= 0; i--) {\n+            lastPoint = getChunkLastPoint(seqChunkMetadataList.get(i));\n+            // last point of this sequence chunk is valid, quit the loop\n+            if (lastPoint.getValue() != null) {\n+              return lastPoint;\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    return lastPoint;\n+  }\n+\n+  /**\n+   * find the last TimeseriesMetadata and unpack all overlapped seq/unseq files\n+   */\n+  private void UnpackOverlappedUnseqFiles(long lBoundTime) throws IOException {\n+    PriorityQueue<TsFileResource> unseqFileResource =\n+        sortUnSeqFileResourcesInDecendingOrder(dataSource.getUnseqResources());\n+\n+    while (!unseqFileResource.isEmpty()) {\n+      // The very end time of unseq files is smaller than lBoundTime,\n+      // then skip all the rest unseq files\n+      if (unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()) < lBoundTime) {\n+        return;\n+      }\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      if (timeseriesMetadata != null\n+          && lBoundTime <= timeseriesMetadata.getStatistics().getEndTime()) {\n+        lBoundTime = Math.max(lBoundTime, timeseriesMetadata.getStatistics().getStartTime());\n+        unseqTimeseriesMetadataList.add(timeseriesMetadata);\n         break;\n       }\n     }\n \n-    if (beforePair != null) {\n-      beforePair.setTimestamp(queryTime);\n-    } else {\n-      beforePair = new TimeValuePair(queryTime, null);\n+    // unpack all overlapped unseq files and fill unseqTimeseriesMetadata list\n+    while (!unseqFileResource.isEmpty()\n+        && (lBoundTime <= unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice()))) {\n+      TimeseriesMetadata timeseriesMetadata =\n+          FileLoaderUtils.loadTimeSeriesMetadata(\n+              unseqFileResource.poll(), seriesPath, context, timeFilter, allSensors);\n+      unseqTimeseriesMetadataList.add(timeseriesMetadata);\n+      // current unseq timeseriesMetadata's last point is a valid result,\n+      // then skip the rest unseq files\n+      if (endtimeContainedByTimeFilter(timeseriesMetadata.getStatistics())\n+          && timeseriesMetadata.getStatistics().getEndTime()\n+              > unseqFileResource.peek().getEndTimeMap().get(seriesPath.getDevice())) {\n+        break;\n+      }\n     }\n-    return beforePair;\n+  }\n+\n+  private TimeValuePair getChunkLastPoint(ChunkMetadata chunkMetaData) throws IOException {\n+    TimeValuePair lastPoint = new TimeValuePair(Long.MIN_VALUE, null);\n+    Statistics chunkStatistics = chunkMetaData.getStatistics();\n+\n+    if (endtimeContainedByTimeFilter(chunkStatistics)) {\n+      return constructLastPair(\n+          chunkStatistics.getEndTime(), chunkStatistics.getLastValue(), dataType);\n+    }\n+    List<IPageReader> pageReaders = FileLoaderUtils.loadPageReaderList(chunkMetaData, timeFilter);\n+    for (int i = pageReaders.size() - 1; i >= 0; i--) {\n+      IPageReader pageReader = pageReaders.get(i);\n+      Statistics pageStatistics = pageReader.getStatistics();\n+      if (endtimeContainedByTimeFilter(pageStatistics)) {\n+        lastPoint = constructLastPair(\n+            pageStatistics.getEndTime(), pageStatistics.getLastValue(), dataType);\n+      } else {\n+        BatchData batchData = pageReader.getAllSatisfiedPageData();\n+        lastPoint = batchData.getLastPairBeforeOrEqualTimestamp(queryTime);\n+      }\n+      break;\n+    }", "originalCommit": "a85361808d9dad8c659b2335ce59acfeab9015b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjcxMTM1MA==", "url": "https://github.com/apache/iotdb/pull/931#discussion_r406711350", "bodyText": "Fixed", "author": "wshao08", "createdAt": "2020-04-10T11:06:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjY3NDU4OQ=="}], "type": "inlineReview"}, {"oid": "59dd0b669031cbe81c87bc89f6e14f8e09fbd164", "url": "https://github.com/apache/iotdb/commit/59dd0b669031cbe81c87bc89f6e14f8e09fbd164", "message": "Fix a potential bug and add more previous fill tests", "committedDate": "2020-04-10T10:45:28Z", "type": "commit"}, {"oid": "e8126f48fc63b0210ccab7c717a206ea01621f0a", "url": "https://github.com/apache/iotdb/commit/e8126f48fc63b0210ccab7c717a206ea01621f0a", "message": "Merge remote-tracking branch 'upstream/master' into new_previous_fill", "committedDate": "2020-04-10T10:50:03Z", "type": "commit"}, {"oid": "ef45ba301c8fd288176d4ed4dfb7665161109220", "url": "https://github.com/apache/iotdb/commit/ef45ba301c8fd288176d4ed4dfb7665161109220", "message": "Fix merge issue", "committedDate": "2020-04-10T11:05:16Z", "type": "commit"}, {"oid": "a3b96be9ba35ec6ea44d3a17d49fbd852a8632f4", "url": "https://github.com/apache/iotdb/commit/a3b96be9ba35ec6ea44d3a17d49fbd852a8632f4", "message": "fix misbehavior", "committedDate": "2020-04-10T13:24:03Z", "type": "commit"}, {"oid": "0f1e6ed961b3e27e11083359f0120af28c6288db", "url": "https://github.com/apache/iotdb/commit/0f1e6ed961b3e27e11083359f0120af28c6288db", "message": "Update site/src/main/.vuepress/config.js", "committedDate": "2020-04-10T14:23:07Z", "type": "commit"}, {"oid": "509b3a8616524d6cb171eac66f5e9c1ae5a2e0ba", "url": "https://github.com/apache/iotdb/commit/509b3a8616524d6cb171eac66f5e9c1ae5a2e0ba", "message": "Update site/src/main/.vuepress/config.js", "committedDate": "2020-04-10T14:23:25Z", "type": "commit"}]}