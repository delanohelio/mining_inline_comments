{"pr_number": 821, "pr_title": "add \"nodes\" metadata for backends", "pr_createdAt": "2020-01-09T03:40:21Z", "pr_url": "https://github.com/hugegraph/hugegraph/pull/821", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU3ODQwMg==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364578402", "bodyText": "don't override regions of one table", "author": "javeme", "createdAt": "2020-01-09T06:39:42Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(Connection hbase) {\n+        this.hbase = hbase;\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try {\n+            Admin admin = this.hbase.getAdmin();\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           e.getValue(), regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private Map<String, Object> getRegionServerMetrics(\n+                                ServerMetrics serverMetrics,\n+                                List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",\n+                    serverMetrics.getUsedHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"request_count\", serverMetrics.getRequestCount());\n+        metrics.put(\"request_count_per_second\",\n+                    serverMetrics.getRequestCountPerSecond());\n+        for (RegionMetrics region : regions) {\n+            String table = region.getNameAsString().split(\",\")[0];\n+            metrics.put(table, this.getRegionMetrics(region));", "originalCommit": "861807e2c0c4bfc7672bb8364fa6d6afed09b153", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU3ODc3NQ==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364578775", "bodyText": "try(Admin admin = this.hbase.getAdmin())", "author": "javeme", "createdAt": "2020-01-09T06:41:26Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(Connection hbase) {\n+        this.hbase = hbase;\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try {\n+            Admin admin = this.hbase.getAdmin();", "originalCommit": "861807e2c0c4bfc7672bb8364fa6d6afed09b153", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU4MDEzMw==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364580133", "bodyText": "NODES", "author": "javeme", "createdAt": "2020-01-09T06:47:30Z", "path": "hugegraph-mysql/src/main/java/com/baidu/hugegraph/backend/store/mysql/MysqlMetrics.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.mysql;\n+\n+import java.util.Map;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.google.common.collect.ImmutableMap;\n+\n+public class MysqlMetrics implements BackendMetrics {\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        return ImmutableMap.of(\"nodes\", 1);", "originalCommit": "861807e2c0c4bfc7672bb8364fa6d6afed09b153", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU4MDIxMg==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364580212", "bodyText": "NODES", "author": "javeme", "createdAt": "2020-01-09T06:47:56Z", "path": "hugegraph-core/src/main/java/com/baidu/hugegraph/backend/store/memory/InMemoryMetrics.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.memory;\n+\n+import java.util.Map;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.google.common.collect.ImmutableMap;\n+\n+public class InMemoryMetrics implements BackendMetrics {\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        return ImmutableMap.of(\"nodes\", 1);", "originalCommit": "861807e2c0c4bfc7672bb8364fa6d6afed09b153", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU4OTcyNA==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364589724", "bodyText": "define a var for e.getValue()", "author": "javeme", "createdAt": "2020-01-09T07:28:08Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(Connection hbase) {\n+        this.hbase = hbase;\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try {\n+            Admin admin = this.hbase.getAdmin();\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           e.getValue(), regions));", "originalCommit": "861807e2c0c4bfc7672bb8364fa6d6afed09b153", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU5NzkxMA==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364597910", "bodyText": "this.sessions\nCassandra protected Cluster cluster()", "author": "javeme", "createdAt": "2020-01-09T07:55:00Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseStore.java", "diffHunk": "@@ -73,12 +74,26 @@ public HbaseStore(final BackendStoreProvider provider,\n         this.namespace = namespace;\n         this.store = store;\n         this.sessions = null;\n+\n+        this.registerMetaHandlers();\n+        LOG.debug(\"Store loaded: {}\", store);\n+    }\n+\n+    private void registerMetaHandlers() {\n+        this.registerMetaHandler(\"metrics\", (session, meta, args) -> {\n+            HbaseMetrics metrics = new HbaseMetrics(hbase());", "originalCommit": "c6aeb94e62dd279dcee4a0da0573fccc7244627f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU5ODE1Ng==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364598156", "bodyText": "set package access or protected\ncheck this.hbase != null", "author": "javeme", "createdAt": "2020-01-09T07:55:52Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseSessions.java", "diffHunk": "@@ -85,6 +85,10 @@ public HbaseSessions(HugeConfig config, String namespace, String store) {\n         this.namespace = namespace;\n     }\n \n+    public Connection hbase() {", "originalCommit": "c6aeb94e62dd279dcee4a0da0573fccc7244627f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDU5ODI2NA==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364598264", "bodyText": "delete it", "author": "javeme", "createdAt": "2020-01-09T07:56:11Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseStore.java", "diffHunk": "@@ -73,12 +74,26 @@ public HbaseStore(final BackendStoreProvider provider,\n         this.namespace = namespace;\n         this.store = store;\n         this.sessions = null;\n+\n+        this.registerMetaHandlers();\n+        LOG.debug(\"Store loaded: {}\", store);\n+    }\n+\n+    private void registerMetaHandlers() {\n+        this.registerMetaHandler(\"metrics\", (session, meta, args) -> {\n+            HbaseMetrics metrics = new HbaseMetrics(hbase());\n+            return metrics.getMetrics();\n+        });\n     }\n \n     protected void registerTableManager(HugeType type, HbaseTable table) {\n         this.tables.put(type, table);\n     }\n \n+    private Connection hbase() {", "originalCommit": "c6aeb94e62dd279dcee4a0da0573fccc7244627f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDY0NTMwNg==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364645306", "bodyText": "move to line 64", "author": "javeme", "createdAt": "2020-01-09T09:50:49Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -63,8 +64,9 @@ public HbaseMetrics(Connection hbase) {\n                 ServerName server = e.getKey();\n                 String address = server.getAddress().toString();\n                 List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                ServerMetrics serverMetrics = e.getValue();", "originalCommit": "7566bc066903696d624aad1862c97c7fb47d37d9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDY0Nzc2OA==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364647768", "bodyText": "set static and rename formatMetrics", "author": "javeme", "createdAt": "2020-01-09T09:55:38Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                ServerMetrics serverMetrics = e.getValue();\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private Map<String, Object> getRegionServerMetrics(\n+                                ServerMetrics serverMetrics,\n+                                List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",\n+                    serverMetrics.getUsedHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"request_count\", serverMetrics.getRequestCount());\n+        metrics.put(\"request_count_per_second\",\n+                    serverMetrics.getRequestCountPerSecond());\n+        for (RegionMetrics region : regions) {\n+            metrics.put(region.getNameAsString(),\n+                        this.getRegionMetrics(region));\n+        }\n+        return metrics;\n+    }\n+\n+    private Map<String, Object> getRegionMetrics(RegionMetrics region) {", "originalCommit": "7566bc066903696d624aad1862c97c7fb47d37d9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDY0ODg4MQ==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364648881", "bodyText": "set static\nand rename to formatMetrics", "author": "javeme", "createdAt": "2020-01-09T09:57:58Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                ServerMetrics serverMetrics = e.getValue();\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private Map<String, Object> getRegionServerMetrics(", "originalCommit": "7566bc066903696d624aad1862c97c7fb47d37d9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDY1MTEzNg==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364651136", "bodyText": "add regions layer", "author": "javeme", "createdAt": "2020-01-09T10:02:21Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                ServerMetrics serverMetrics = e.getValue();\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private Map<String, Object> getRegionServerMetrics(\n+                                ServerMetrics serverMetrics,\n+                                List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",\n+                    serverMetrics.getUsedHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"request_count\", serverMetrics.getRequestCount());\n+        metrics.put(\"request_count_per_second\",\n+                    serverMetrics.getRequestCountPerSecond());\n+        for (RegionMetrics region : regions) {\n+            metrics.put(region.getNameAsString(),\n+                        this.getRegionMetrics(region));", "originalCommit": "7566bc066903696d624aad1862c97c7fb47d37d9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDY1MTkzMg==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r364651932", "bodyText": "regionServers.put(server.getAddress().toString(), \n                  formatMetri(csserverMetrics, regions));", "author": "javeme", "createdAt": "2020-01-09T10:04:07Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                String address = server.getAddress().toString();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                ServerMetrics serverMetrics = e.getValue();\n+                regionServers.put(address, this.getRegionServerMetrics(\n+                                           serverMetrics, regions));", "originalCommit": "7566bc066903696d624aad1862c97c7fb47d37d9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTAwMzI5MA==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r371003290", "bodyText": "add \"heap_size_unit: MB\"", "author": "javeme", "createdAt": "2020-01-26T14:26:01Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                ServerMetrics serverMetrics = e.getValue();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                regionServers.put(server.getAddress().toString(),\n+                                  formatMetrics(serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(\n+                                       ServerMetrics serverMetrics,\n+                                       List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",", "originalCommit": "83b5fb42f32ac90210968c65d9a266c31be459ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTAwMzQxNQ==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r371003415", "bodyText": "prefer file_store_size", "author": "javeme", "createdAt": "2020-01-26T14:27:49Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                ServerMetrics serverMetrics = e.getValue();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                regionServers.put(server.getAddress().toString(),\n+                                  formatMetrics(serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(\n+                                       ServerMetrics serverMetrics,\n+                                       List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",\n+                    serverMetrics.getUsedHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"request_count\", serverMetrics.getRequestCount());\n+        metrics.put(\"request_count_per_second\",\n+                    serverMetrics.getRequestCountPerSecond());\n+        metrics.put(\"regions\", formatMetrics(regions));\n+        return metrics;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(\n+                                       List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        for (RegionMetrics region : regions) {\n+            metrics.put(region.getNameAsString(), formatMetrics(region));\n+        }\n+        return metrics;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(RegionMetrics region) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"mem_store_size\",\n+                    region.getMemStoreSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"mem_store_file_size\",", "originalCommit": "83b5fb42f32ac90210968c65d9a266c31be459ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTAwMzQyNw==", "url": "https://github.com/hugegraph/hugegraph/pull/821#discussion_r371003427", "bodyText": "also add unit", "author": "javeme", "createdAt": "2020-01-26T14:28:02Z", "path": "hugegraph-hbase/src/main/java/com/baidu/hugegraph/backend/store/hbase/HbaseMetrics.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright 2017 HugeGraph Authors\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with this\n+ * work for additional information regarding copyright ownership. The ASF\n+ * licenses this file to You under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package com.baidu.hugegraph.backend.store.hbase;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hadoop.hbase.ClusterMetrics;\n+import org.apache.hadoop.hbase.RegionMetrics;\n+import org.apache.hadoop.hbase.ServerMetrics;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.Size;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.Connection;\n+\n+import com.baidu.hugegraph.backend.store.BackendMetrics;\n+import com.baidu.hugegraph.util.E;\n+import com.baidu.hugegraph.util.InsertionOrderUtil;\n+\n+public class HbaseMetrics implements BackendMetrics {\n+\n+    private final Connection hbase;\n+\n+    public HbaseMetrics(HbaseSessions hbase) {\n+        E.checkArgumentNotNull(hbase, \"HBase connection is not opened\");\n+        this.hbase = hbase.hbase();\n+    }\n+\n+    @Override\n+    public Map<String, Object> getMetrics() {\n+        Map<String, Object> results = InsertionOrderUtil.newMap();\n+        try (Admin admin = this.hbase.getAdmin()) {\n+            // Cluster info\n+            ClusterMetrics clusterMetrics = admin.getClusterMetrics();\n+            results.put(\"cluster_id\", clusterMetrics.getClusterId());\n+            results.put(\"average_load\", clusterMetrics.getAverageLoad());\n+            results.put(\"hbase_version\", clusterMetrics.getHBaseVersion());\n+            results.put(\"region_count\", clusterMetrics.getRegionCount());\n+            // Region servers info\n+            Collection<ServerName> servers = admin.getRegionServers();\n+            results.put(NODES, servers.size());\n+            Map<ServerName, ServerMetrics> metrics =\n+                            clusterMetrics.getLiveServerMetrics();\n+            Map<String, Object> regionServers = InsertionOrderUtil.newMap();\n+            for (Map.Entry<ServerName, ServerMetrics> e : metrics.entrySet()) {\n+                ServerName server = e.getKey();\n+                ServerMetrics serverMetrics = e.getValue();\n+                List<RegionMetrics> regions = admin.getRegionMetrics(server);\n+                regionServers.put(server.getAddress().toString(),\n+                                  formatMetrics(serverMetrics, regions));\n+            }\n+            results.put(\"region_servers\", regionServers);\n+        } catch (Throwable e) {\n+            results.put(EXCEPTION, e.getMessage());\n+        }\n+        return results;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(\n+                                       ServerMetrics serverMetrics,\n+                                       List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"max_heap_size\",\n+                    serverMetrics.getMaxHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"used_heap_size\",\n+                    serverMetrics.getUsedHeapSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"request_count\", serverMetrics.getRequestCount());\n+        metrics.put(\"request_count_per_second\",\n+                    serverMetrics.getRequestCountPerSecond());\n+        metrics.put(\"regions\", formatMetrics(regions));\n+        return metrics;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(\n+                                       List<RegionMetrics> regions) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        for (RegionMetrics region : regions) {\n+            metrics.put(region.getNameAsString(), formatMetrics(region));\n+        }\n+        return metrics;\n+    }\n+\n+    private static Map<String, Object> formatMetrics(RegionMetrics region) {\n+        Map<String, Object> metrics = InsertionOrderUtil.newMap();\n+        metrics.put(\"mem_store_size\",\n+                    region.getMemStoreSize().get(Size.Unit.MEGABYTE));\n+        metrics.put(\"mem_store_file_size\",\n+                    region.getStoreFileSize().get(Size.Unit.MEGABYTE));", "originalCommit": "83b5fb42f32ac90210968c65d9a266c31be459ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "41a9cc716f1273b9ff9fe60bd49a95e78583bbef", "url": "https://github.com/hugegraph/hugegraph/commit/41a9cc716f1273b9ff9fe60bd49a95e78583bbef", "message": "add \"nodes\" metadata for backends\n\nimplemented: #816\n\nChange-Id: Ica7be59f1af1f290342b010c0c018cc541a1122b", "committedDate": "2020-02-04T09:04:35Z", "type": "commit"}, {"oid": "e164e746bd965c394542936d18d80151a0b4de64", "url": "https://github.com/hugegraph/hugegraph/commit/e164e746bd965c394542936d18d80151a0b4de64", "message": "update api test for metrics/backend\n\nChange-Id: I7538d76682d0e6620eefc3ce53c787e111ba1dcf", "committedDate": "2020-02-04T09:04:35Z", "type": "commit"}, {"oid": "d4f5d0d8d962613d04d1fb30be4395d4cbe5aa59", "url": "https://github.com/hugegraph/hugegraph/commit/d4f5d0d8d962613d04d1fb30be4395d4cbe5aa59", "message": "avoid expose Cassandra cluster and Hbase connection\n\nChange-Id: I041cf915e565b4ba90c94b73d938ff9e27abf905", "committedDate": "2020-02-04T09:04:35Z", "type": "commit"}, {"oid": "936b2b214c835b48164af269f8a851786fa6bd2d", "url": "https://github.com/hugegraph/hugegraph/commit/936b2b214c835b48164af269f8a851786fa6bd2d", "message": "improve\n\nChange-Id: Ia8abda118a0cf181b31ff39cb0a7a0a9d94996e8", "committedDate": "2020-02-04T09:04:35Z", "type": "commit"}, {"oid": "835e70b570552df857d60d6e0647ab57ca399f64", "url": "https://github.com/hugegraph/hugegraph/commit/835e70b570552df857d60d6e0647ab57ca399f64", "message": "improve\n\nChange-Id: I538eb57a52873c139a3302428f61851c1040ab5a", "committedDate": "2020-02-04T09:17:39Z", "type": "commit"}, {"oid": "835e70b570552df857d60d6e0647ab57ca399f64", "url": "https://github.com/hugegraph/hugegraph/commit/835e70b570552df857d60d6e0647ab57ca399f64", "message": "improve\n\nChange-Id: I538eb57a52873c139a3302428f61851c1040ab5a", "committedDate": "2020-02-04T09:17:39Z", "type": "forcePushed"}]}