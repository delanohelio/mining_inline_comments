{"pr_number": 3370, "pr_title": "Introduce backward analysis to dataflow framework.", "pr_createdAt": "2020-06-13T05:41:11Z", "pr_url": "https://github.com/typetools/checker-framework/pull/3370", "timeline": [{"oid": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "url": "https://github.com/typetools/checker-framework/commit/737e03ef9e90ec686ea1233f2302c64d37c284aa", "message": "Refactor dataflow framework. Introduce backward analysis.\n\nCo-authored-by: Charles Chen <Charleszhuochen@gmail.com>", "committedDate": "2020-06-13T03:44:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNDc5Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441134796", "bodyText": "is node in this line referring to the input node or to nodes generally? The given text isn't clear.", "author": "kelloggm", "createdAt": "2020-06-16T20:52:14Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNDk3Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441134976", "bodyText": "create->creates\nstore->stores", "author": "kelloggm", "createdAt": "2020-06-16T20:52:36Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441135760", "bodyText": "This comment about before isn't very helpful. The text earlier about which store is returned depending on this value is much more informative, and I suggest you move that information here.", "author": "kelloggm", "createdAt": "2020-06-16T20:54:08Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n+     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n      *\n-     * @param cfg the control flow graph to use\n-     */\n-    @EnsuresNonNull(\"this.cfg\")\n-    protected void init(ControlFlowGraph cfg) {\n-        thenStores.clear();\n-        elseStores.clear();\n-        if (blockCount != null) {\n-            blockCount.clear();\n-        }\n-        inputs.clear();\n-        storesAtReturnStatements.clear();\n-        nodeValues.clear();\n-        finalLocalValues.clear();\n-\n-        this.cfg = cfg;\n-        worklist.process(cfg);\n-        worklist.add(cfg.getEntryBlock());\n-\n-        List<LocalVariableNode> parameters = null;\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        if (underlyingAST.getKind() == Kind.METHOD) {\n-            MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : tree.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-        } else if (underlyingAST.getKind() == Kind.LAMBDA) {\n-            LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : lambda.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-\n-        } else {\n-            // nothing to do\n-        }\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n-        Block entry = cfg.getEntryBlock();\n-        thenStores.put(entry, initialStore);\n-        elseStores.put(entry, initialStore);\n-        inputs.put(entry, new TransferInput<>(null, this, initialStore));\n-    }\n-\n-    /**\n-     * Add a basic block to the worklist. If {@code b} is already present, the method does nothing.\n+     * @param node the node to analyze\n+     * @param before the boolean value to indicate which store to return", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzODI2Mg==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441138262", "bodyText": "I would also consider changing before to an enum, so that callsites say Store.BEFORE and Store.AFTER rather than just true and false. Distinguishing between true and false at callsites makes them harder to read.", "author": "kelloggm", "createdAt": "2020-06-16T20:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTgyOTUwMw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441829503", "bodyText": "I would also consider changing before to an enum, so that callsites say Store.BEFORE and Store.AFTER rather than just true and false. Distinguishing between true and false at callsites makes them harder to read.\n\nThis is a separate change, not related to the change of this pull request (introducing backward analysis). I will open an issue for future reference.", "author": "xingweitian", "createdAt": "2020-06-17T20:56:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNTc2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNjA2OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441136069", "bodyText": "The value of before also decides which store is returned, so this comment is ambiguous.", "author": "kelloggm", "createdAt": "2020-06-16T20:54:44Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java", "diffHunk": "@@ -1,898 +1,116 @@\n package org.checkerframework.dataflow.analysis;\n \n-import com.sun.source.tree.ClassTree;\n-import com.sun.source.tree.LambdaExpressionTree;\n-import com.sun.source.tree.MethodTree;\n-import com.sun.source.tree.Tree;\n-import com.sun.source.tree.VariableTree;\n-import java.util.ArrayList;\n-import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.IdentityHashMap;\n-import java.util.List;\n import java.util.Map;\n-import java.util.Objects;\n-import java.util.PriorityQueue;\n-import java.util.Set;\n-import javax.lang.model.element.Element;\n-import javax.lang.model.type.TypeMirror;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNull;\n-import org.checkerframework.checker.nullness.qual.EnsuresNonNullIf;\n-import org.checkerframework.checker.nullness.qual.MonotonicNonNull;\n import org.checkerframework.checker.nullness.qual.Nullable;\n-import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n-import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n import org.checkerframework.dataflow.cfg.block.Block;\n-import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n-import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n-import org.checkerframework.dataflow.cfg.block.RegularBlock;\n-import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n-import org.checkerframework.dataflow.cfg.node.AssignmentNode;\n-import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n import org.checkerframework.dataflow.cfg.node.Node;\n-import org.checkerframework.dataflow.cfg.node.ReturnNode;\n-import org.checkerframework.javacutil.ElementUtils;\n-import org.checkerframework.javacutil.Pair;\n \n /**\n- * An implementation of an iterative algorithm to solve a org.checkerframework.dataflow problem,\n- * given a control flow graph and a transfer function.\n+ * This interface defines a dataflow analysis, given a control flow graph and a transfer function. A\n+ * dataflow analysis has a direction, either forward or backward. The direction of corresponding\n+ * transfer function is consistent with the analysis, i.e. a forward analysis has a forward transfer\n+ * function, and a backward analysis has a backward transfer function.\n  *\n  * @param <V> the abstract value type to be tracked by the analysis\n  * @param <S> the store type used in the analysis\n  * @param <T> the transfer function type that is used to approximated runtime behavior\n  */\n-public class Analysis<\n+public interface Analysis<\n         V extends AbstractValue<V>, S extends Store<S>, T extends TransferFunction<V, S>> {\n \n-    /** Is the analysis currently running? */\n-    protected boolean isRunning = false;\n-\n-    /** The transfer function for regular nodes. */\n-    // TODO: make final. Currently, the transferFunction has a reference to the analysis, so it\n-    // can't be created until the Analysis is initialized.\n-    protected @Nullable T transferFunction;\n-\n-    /** The current control flow graph to perform the analysis on. */\n-    protected @MonotonicNonNull ControlFlowGraph cfg;\n-\n-    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> thenStores;\n-\n-    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n-    protected final IdentityHashMap<Block, S> elseStores;\n-\n-    /**\n-     * Number of times every block has been analyzed since the last time widening was applied. Null,\n-     * if maxCountBeforeWidening is -1 which implies widening isn't used for this analysis.\n-     */\n-    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n-\n-    /**\n-     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n-     * be used.\n-     */\n-    protected final int maxCountBeforeWidening;\n-\n-    /**\n-     * The transfer inputs before every basic block (assumed to be 'no information' if not present).\n-     */\n-    protected final IdentityHashMap<Block, TransferInput<V, S>> inputs;\n-\n-    /** The stores after every return statement. */\n-    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n-\n-    /** The worklist used for the fix-point iteration. */\n-    protected final Worklist worklist;\n-\n-    /** Abstract values of nodes. */\n-    protected final IdentityHashMap<Node, V> nodeValues;\n-\n-    /** Map from (effectively final) local variable elements to their abstract value. */\n-    public final HashMap<Element, V> finalLocalValues;\n-\n-    /**\n-     * The node that is currently handled in the analysis (if it is running). The following\n-     * invariant holds:\n-     *\n-     * <pre>\n-     *   !isRunning &rArr; (currentNode == null)\n-     * </pre>\n-     */\n-    protected @Nullable Node currentNode;\n-\n-    /**\n-     * The tree that is currently being looked at. The transfer function can set this tree to make\n-     * sure that calls to {@code getValue} will not return information for this given tree.\n-     */\n-    protected @Nullable Tree currentTree;\n-\n-    /** The current transfer input when the analysis is running. */\n-    protected @Nullable TransferInput<V, S> currentInput;\n-\n-    /** The tree that is currently being looked at. */\n-    public @Nullable Tree getCurrentTree() {\n-        return currentTree;\n-    }\n-\n-    public void setCurrentTree(Tree currentTree) {\n-        this.currentTree = currentTree;\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     */\n-    public Analysis() {\n-        this(null, -1);\n-    }\n-\n-    // `@code`, not `@link`, because dataflow module doesn't depend on framework moduel.\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph. The transfer function is set by the subclass, e.g., {@code\n-     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n-     *\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n-     */\n-    public Analysis(int maxCountBeforeWidening) {\n-        this(null, maxCountBeforeWidening);\n-    }\n-\n-    /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n-     *\n-     * @param transfer transfer function\n-     */\n-    public Analysis(T transfer) {\n-        this(transfer, -1);\n+    /** The direction of an analysis instance. */\n+    enum Direction {\n+        /** The forward direction. */\n+        FORWARD,\n+        /** The backward direction. */\n+        BACKWARD\n     }\n \n     /**\n-     * Construct an object that can perform a org.checkerframework.dataflow analysis over a control\n-     * flow graph, given a transfer function.\n+     * Get the direction of this analysis.\n      *\n-     * @param transfer transfer function\n-     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     * @return the direction of this analysis\n      */\n-    public Analysis(@Nullable T transfer, int maxCountBeforeWidening) {\n-        this.transferFunction = transfer;\n-        this.maxCountBeforeWidening = maxCountBeforeWidening;\n-        this.thenStores = new IdentityHashMap<>();\n-        this.elseStores = new IdentityHashMap<>();\n-        this.blockCount = maxCountBeforeWidening == -1 ? null : new IdentityHashMap<>();\n-        this.inputs = new IdentityHashMap<>();\n-        this.storesAtReturnStatements = new IdentityHashMap<>();\n-        this.worklist = new Worklist();\n-        this.nodeValues = new IdentityHashMap<>();\n-        this.finalLocalValues = new HashMap<>();\n-    }\n+    Direction getDirection();\n \n     /**\n-     * The current transfer function.\n+     * Is the analysis currently running?\n      *\n-     * @return {@link #transferFunction}\n+     * @return true if the analysis is running currently, else false\n      */\n-    public @Nullable T getTransferFunction() {\n-        return transferFunction;\n-    }\n+    boolean isRunning();\n \n     /**\n      * Perform the actual analysis.\n      *\n-     * @param cfg the control flow graph used to perform analysis\n+     * @param cfg the control flow graph\n      */\n-    public void performAnalysis(ControlFlowGraph cfg) {\n-        assert !isRunning;\n-        isRunning = true;\n-\n-        try {\n-            init(cfg);\n-\n-            while (!worklist.isEmpty()) {\n-                Block b = worklist.poll();\n-                performAnalysisBlock(b);\n-            }\n-        } finally {\n-            assert isRunning;\n-            // In case performAnalysisBlock crashed, reset isRunning to false.\n-            isRunning = false;\n-        }\n-    }\n-\n-    /** Perform the actual analysis on one block. */\n-    protected void performAnalysisBlock(Block b) {\n-        switch (b.getType()) {\n-            case REGULAR_BLOCK:\n-                {\n-                    RegularBlock rb = (RegularBlock) b;\n-\n-                    // apply transfer function to contents\n-                    TransferInput<V, S> inputBefore = getInputBefore(rb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    TransferResult<V, S> transferResult = null;\n-                    Node lastNode = null;\n-                    boolean addToWorklistAgain = false;\n-                    for (Node n : rb.getContents()) {\n-                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                        transferResult = callTransferFunction(n, currentInput);\n-                        addToWorklistAgain |= updateNodeValues(n, transferResult);\n-                        currentInput = new TransferInput<>(n, this, transferResult);\n-                        lastNode = n;\n-                    }\n-                    assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n-                    // loop will run at least once, making transferResult non-null\n-\n-                    // propagate store to successors\n-                    Block succ = rb.getSuccessor();\n-                    assert succ != null\n-                            : \"@AssumeAssertion(nullness): regular basic block without non-exceptional successor unexpected\";\n-                    propagateStoresTo(\n-                            succ, lastNode, currentInput, rb.getFlowRule(), addToWorklistAgain);\n-                    break;\n-                }\n-\n-            case EXCEPTION_BLOCK:\n-                {\n-                    ExceptionBlock eb = (ExceptionBlock) b;\n-\n-                    // apply transfer function to content\n-                    TransferInput<V, S> inputBefore = getInputBefore(eb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    currentInput = inputBefore.copy();\n-                    Node node = eb.getNode();\n-                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n-                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n-\n-                    // propagate store to successor\n-                    Block succ = eb.getSuccessor();\n-                    if (succ != null) {\n-                        currentInput = new TransferInput<>(node, this, transferResult);\n-                        // TODO? Variable wasn't used.\n-                        // Store.FlowRule storeFlow = eb.getFlowRule();\n-                        propagateStoresTo(\n-                                succ, node, currentInput, eb.getFlowRule(), addToWorklistAgain);\n-                    }\n-\n-                    // propagate store to exceptional successors\n-                    for (Map.Entry<TypeMirror, Set<Block>> e :\n-                            eb.getExceptionalSuccessors().entrySet()) {\n-                        TypeMirror cause = e.getKey();\n-                        S exceptionalStore = transferResult.getExceptionalStore(cause);\n-                        if (exceptionalStore != null) {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        exceptionalStore,\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        } else {\n-                            for (Block exceptionSucc : e.getValue()) {\n-                                addStoreBefore(\n-                                        exceptionSucc,\n-                                        node,\n-                                        inputBefore.copy().getRegularStore(),\n-                                        Store.Kind.BOTH,\n-                                        addToWorklistAgain);\n-                            }\n-                        }\n-                    }\n-                    break;\n-                }\n-\n-            case CONDITIONAL_BLOCK:\n-                {\n-                    ConditionalBlock cb = (ConditionalBlock) b;\n-\n-                    // get store before\n-                    TransferInput<V, S> inputBefore = getInputBefore(cb);\n-                    assert inputBefore != null : \"@AssumeAssertion(nullness): invariant\";\n-                    TransferInput<V, S> input = inputBefore.copy();\n-\n-                    // propagate store to successor\n-                    Block thenSucc = cb.getThenSuccessor();\n-                    Block elseSucc = cb.getElseSuccessor();\n-\n-                    propagateStoresTo(thenSucc, null, input, cb.getThenFlowRule(), false);\n-                    propagateStoresTo(elseSucc, null, input, cb.getElseFlowRule(), false);\n-                    break;\n-                }\n-\n-            case SPECIAL_BLOCK:\n-                {\n-                    // special basic blocks are empty and cannot throw exceptions,\n-                    // thus there is no need to perform any analysis.\n-                    SpecialBlock sb = (SpecialBlock) b;\n-                    Block succ = sb.getSuccessor();\n-                    if (succ != null) {\n-                        TransferInput<V, S> input = getInputBefore(b);\n-                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n-                        propagateStoresTo(succ, null, input, sb.getFlowRule(), false);\n-                    }\n-                    break;\n-                }\n-\n-            default:\n-                assert false;\n-                break;\n-        }\n-    }\n+    void performAnalysis(ControlFlowGraph cfg);\n \n     /**\n-     * Propagate the stores in currentInput to the successor block, succ, according to the flowRule.\n-     */\n-    protected void propagateStoresTo(\n-            Block succ,\n-            @Nullable Node node,\n-            TransferInput<V, S> currentInput,\n-            Store.FlowRule flowRule,\n-            boolean addToWorklistAgain) {\n-        switch (flowRule) {\n-            case EACH_TO_EACH:\n-                if (currentInput.containsTwoStores()) {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getThenStore(),\n-                            Store.Kind.THEN,\n-                            addToWorklistAgain);\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getElseStore(),\n-                            Store.Kind.ELSE,\n-                            addToWorklistAgain);\n-                } else {\n-                    addStoreBefore(\n-                            succ,\n-                            node,\n-                            currentInput.getRegularStore(),\n-                            Store.Kind.BOTH,\n-                            addToWorklistAgain);\n-                }\n-                break;\n-            case THEN_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_BOTH:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.BOTH,\n-                        addToWorklistAgain);\n-                break;\n-            case THEN_TO_THEN:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getThenStore(),\n-                        Store.Kind.THEN,\n-                        addToWorklistAgain);\n-                break;\n-            case ELSE_TO_ELSE:\n-                addStoreBefore(\n-                        succ,\n-                        node,\n-                        currentInput.getElseStore(),\n-                        Store.Kind.ELSE,\n-                        addToWorklistAgain);\n-                break;\n-        }\n-    }\n-\n-    /**\n-     * Updates the value of node {@code node} to the value of the {@code transferResult}. Returns\n-     * true if the node's value changed, or a store was updated.\n-     *\n-     * @param node a node\n-     * @param transferResult the new transfer result to use as {@code node}'s value\n-     * @return true if the node's value changed, or a store was updated\n-     */\n-    protected boolean updateNodeValues(Node node, TransferResult<V, S> transferResult) {\n-        V newVal = transferResult.getResultValue();\n-        boolean nodeValueChanged = false;\n-\n-        if (newVal != null) {\n-            V oldVal = nodeValues.get(node);\n-            nodeValues.put(node, newVal);\n-            nodeValueChanged = !Objects.equals(oldVal, newVal);\n-        }\n-\n-        return nodeValueChanged || transferResult.storeChanged();\n-    }\n-\n-    /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Perform the actual analysis on one block.\n      *\n-     * @param node a node\n-     * @param store the input of a transfer function\n-     * @return the transfer result for the node\n+     * @param b the block to analyze\n      */\n-    protected TransferResult<V, S> callTransferFunction(Node node, TransferInput<V, S> store) {\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        if (node.isLValue()) {\n-            // TODO: should the default behavior be to return either a regular\n-            // transfer result or a conditional transfer result (depending on\n-            // store.hasTwoStores()), or is the following correct?\n-            return new RegularTransferResult<>(null, store.getRegularStore());\n-        }\n-        store.node = node;\n-        currentNode = node;\n-        TransferResult<V, S> transferResult = node.accept(transferFunction, store);\n-        currentNode = null;\n-        if (node instanceof ReturnNode) {\n-            // save a copy of the store to later check if some property held at\n-            // a given return statement\n-            storesAtReturnStatements.put((ReturnNode) node, transferResult);\n-        }\n-        if (node instanceof AssignmentNode) {\n-            // store the flow-refined value for effectively final local variables\n-            AssignmentNode assignment = (AssignmentNode) node;\n-            Node lhst = assignment.getTarget();\n-            if (lhst instanceof LocalVariableNode) {\n-                LocalVariableNode lhs = (LocalVariableNode) lhst;\n-                Element elem = lhs.getElement();\n-                if (ElementUtils.isEffectivelyFinal(elem)) {\n-                    V resval = transferResult.getResultValue();\n-                    if (resval != null) {\n-                        finalLocalValues.put(elem, resval);\n-                    }\n-                }\n-            }\n-        }\n-        return transferResult;\n-    }\n+    void performAnalysisBlock(Block b);\n \n     /**\n-     * Initialize the analysis with a new control flow graph.\n+     * Runs the analysis again within the block of {@code node} and returns the store at the\n+     * location of {@code node}. If {@code before} is true, then the store immediately before the\n+     * {@link Node} {@code node} is returned. Otherwise, the store after {@code node} is returned.\n+     * If {@code analysisCaches} is not null, this method uses a cache. {@code analysisCaches} is a\n+     * map of a block of node to the cached analysis result. If the cache for {@code transferInput}\n+     * is not in {@code analysisCaches}, this method create new cache and store it in {@code\n+     * analysisCaches}. The cache is a map of a node to the analysis result of the node.\n      *\n-     * @param cfg the control flow graph to use\n-     */\n-    @EnsuresNonNull(\"this.cfg\")\n-    protected void init(ControlFlowGraph cfg) {\n-        thenStores.clear();\n-        elseStores.clear();\n-        if (blockCount != null) {\n-            blockCount.clear();\n-        }\n-        inputs.clear();\n-        storesAtReturnStatements.clear();\n-        nodeValues.clear();\n-        finalLocalValues.clear();\n-\n-        this.cfg = cfg;\n-        worklist.process(cfg);\n-        worklist.add(cfg.getEntryBlock());\n-\n-        List<LocalVariableNode> parameters = null;\n-        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n-        if (underlyingAST.getKind() == Kind.METHOD) {\n-            MethodTree tree = ((CFGMethod) underlyingAST).getMethod();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : tree.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-        } else if (underlyingAST.getKind() == Kind.LAMBDA) {\n-            LambdaExpressionTree lambda = ((CFGLambda) underlyingAST).getLambdaTree();\n-            parameters = new ArrayList<>();\n-            for (VariableTree p : lambda.getParameters()) {\n-                LocalVariableNode var = new LocalVariableNode(p);\n-                parameters.add(var);\n-                // TODO: document that LocalVariableNode has no block that it\n-                // belongs to\n-            }\n-\n-        } else {\n-            // nothing to do\n-        }\n-        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n-        S initialStore = transferFunction.initialStore(underlyingAST, parameters);\n-        Block entry = cfg.getEntryBlock();\n-        thenStores.put(entry, initialStore);\n-        elseStores.put(entry, initialStore);\n-        inputs.put(entry, new TransferInput<>(null, this, initialStore));\n-    }\n-\n-    /**\n-     * Add a basic block to the worklist. If {@code b} is already present, the method does nothing.\n+     * @param node the node to analyze\n+     * @param before the boolean value to indicate which store to return\n+     * @param transferInput the transfer input of the block of this node\n+     * @param nodeValues abstract values of nodes\n+     * @param analysisCaches caches of analysis results\n+     * @return the store at the location of node after running the analysis", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzNjk1Ng==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441136956", "bodyText": "I'm not sure what \"waiting for being merged\" means here. I think it can be replaced with \"another treeLookup that will be merged into {@code treeLookup}\"", "author": "kelloggm", "createdAt": "2020-06-16T20:56:22Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/AnalysisResult.java", "diffHunk": "@@ -127,7 +129,12 @@ public void combine(AnalysisResult<V, S> other) {\n         finalLocalValues.putAll(other.finalLocalValues);\n     }\n \n-    // Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n+    /**\n+     * Merge all entries from otherTreeLookup into treeLookup. Merge sets if already present.\n+     *\n+     * @param treeLookup a map from abstract syntax trees to sets of nodes\n+     * @param otherTreeLookup another treeLookup waiting for being merged into {@code treeLookup}", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE0MTcyNw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r441141727", "bodyText": "Why does the forward analysis contain widening support, but the backwards analysis does not? I know that there is no need for a widening operator in the liveness analysis, but to be generally useful I would expect that there will be times when a widening operator is needed - otherwise a dataflow problem might not terminate. The backwards analysis is not immune to this (as far as I can tell); it must re-add blocks to the worklist just as the forward analysis does. Am I missing something, or is widening support in the backwards analysis future work?", "author": "kelloggm", "createdAt": "2020-06-16T21:05:52Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/ForwardAnalysisImpl.java", "diffHunk": "@@ -0,0 +1,585 @@\n+package org.checkerframework.dataflow.analysis;\n+\n+import com.sun.source.tree.LambdaExpressionTree;\n+import com.sun.source.tree.MethodTree;\n+import com.sun.source.tree.VariableTree;\n+import java.util.ArrayList;\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import javax.lang.model.type.TypeMirror;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGLambda;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.CFGMethod;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST.Kind;\n+import org.checkerframework.dataflow.cfg.block.Block;\n+import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n+import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n+import org.checkerframework.dataflow.cfg.block.RegularBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n+import org.checkerframework.dataflow.cfg.node.LocalVariableNode;\n+import org.checkerframework.dataflow.cfg.node.Node;\n+import org.checkerframework.dataflow.cfg.node.ReturnNode;\n+import org.checkerframework.javacutil.BugInCF;\n+import org.checkerframework.javacutil.Pair;\n+\n+/**\n+ * An implementation of a forward analysis to solve a org.checkerframework.dataflow problem given a\n+ * control flow graph and a forward transfer function.\n+ *\n+ * @param <V> the abstract value type to be tracked by the analysis\n+ * @param <S> the store type used in the analysis\n+ * @param <T> the transfer function type that is used to approximate runtime behavior\n+ */\n+public class ForwardAnalysisImpl<\n+                V extends AbstractValue<V>,\n+                S extends Store<S>,\n+                T extends ForwardTransferFunction<V, S>>\n+        extends AbstractAnalysis<V, S, T> implements ForwardAnalysis<V, S, T> {\n+\n+    /**\n+     * Number of times each block has been analyzed since the last time widening was applied. Null\n+     * if maxCountBeforeWidening is -1, which implies widening isn't used for this analysis.\n+     */\n+    protected final @Nullable IdentityHashMap<Block, Integer> blockCount;\n+\n+    /**\n+     * Number of times a block can be analyzed before widening. -1 implies that widening shouldn't\n+     * be used.\n+     */\n+    protected final int maxCountBeforeWidening;\n+\n+    /** Then stores before every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> thenStores;\n+\n+    /** Else stores before every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> elseStores;\n+\n+    /** The stores after every return statement. */\n+    protected final IdentityHashMap<ReturnNode, TransferResult<V, S>> storesAtReturnStatements;\n+\n+    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow forward analysis over a\n+     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n+     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n+     *\n+     * @param maxCountBeforeWidening number of times a block can be analyzed before widening\n+     */\n+    public ForwardAnalysisImpl(int maxCountBeforeWidening) {", "originalCommit": "737e03ef9e90ec686ea1233f2302c64d37c284aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "url": "https://github.com/typetools/checker-framework/commit/066c7d395ed53a70f83b4a1a1ecdc8ca06769eb0", "message": "Resolve comments.\nReduce the differences between forward and backward analysis implementation.", "committedDate": "2020-06-17T20:34:26Z", "type": "commit"}, {"oid": "720123f017c5e0c47688c5fae5c05ab01677eb8c", "url": "https://github.com/typetools/checker-framework/commit/720123f017c5e0c47688c5fae5c05ab01677eb8c", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-17T20:34:35Z", "type": "commit"}, {"oid": "0d8664d081e7cdfede1f38ffd18a93091d1c9ff9", "url": "https://github.com/typetools/checker-framework/commit/0d8664d081e7cdfede1f38ffd18a93091d1c9ff9", "message": "Remove unused import.", "committedDate": "2020-06-17T20:37:27Z", "type": "commit"}, {"oid": "741e968c009f94182ff6738a9f47b930b0a1967f", "url": "https://github.com/typetools/checker-framework/commit/741e968c009f94182ff6738a9f47b930b0a1967f", "message": "Add a TODO comment for widening support for backward analysis.\nTweaks the javadoc.", "committedDate": "2020-06-17T21:40:54Z", "type": "commit"}, {"oid": "9880400eb6f4354105fea809e8254a071a0120a2", "url": "https://github.com/typetools/checker-framework/commit/9880400eb6f4354105fea809e8254a071a0120a2", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-21T01:33:52Z", "type": "commit"}, {"oid": "247c6d8dae718be3332e623306f323a483815c13", "url": "https://github.com/typetools/checker-framework/commit/247c6d8dae718be3332e623306f323a483815c13", "message": "Pull latest code from typetools.", "committedDate": "2020-06-25T03:45:21Z", "type": "commit"}, {"oid": "ef29c77cfb9ae52d669e60eaf0c076c2e4e91fdb", "url": "https://github.com/typetools/checker-framework/commit/ef29c77cfb9ae52d669e60eaf0c076c2e4e91fdb", "message": "Tweaks.", "committedDate": "2020-06-26T17:05:53Z", "type": "commit"}, {"oid": "0c2faaf3647ef05cfd2b70fff2785cc152fa5819", "url": "https://github.com/typetools/checker-framework/commit/0c2faaf3647ef05cfd2b70fff2785cc152fa5819", "message": "Revert \"Tweaks.\"\n\nThis reverts commit ef29c77c", "committedDate": "2020-06-26T17:10:01Z", "type": "commit"}, {"oid": "d996fd0760d700aa6b962c1c3188cfa22df75b14", "url": "https://github.com/typetools/checker-framework/commit/d996fd0760d700aa6b962c1c3188cfa22df75b14", "message": "Merge branch 'master' into typetools-backward-analysis", "committedDate": "2020-06-26T22:19:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446440383", "bodyText": "I don't fully understand this comment. I think it means that store should not be side-effected, because it is a copy of a store used elsewhere. If that's correct, can you change the documentation to say it directly.\nAlso, I find store to be a misleading name, because I would expect it to be a Store, but it is a TransferInput. Should we change the name?", "author": "kelloggm", "createdAt": "2020-06-26T22:41:19Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/AbstractAnalysis.java", "diffHunk": "@@ -307,7 +307,9 @@ public Direction getDirection() {\n     }\n \n     /**\n-     * Call the transfer function for node {@code node}, and set that node as current node first.\n+     * Call the transfer function for node {@code node}, and set that node as current node first. Be\n+     * careful that {@code store} may be shared between nodes in a block. Passing a copied store to\n+     * avoid the accident changing.", "originalCommit": "d996fd0760d700aa6b962c1c3188cfa22df75b14", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ1NDg4OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446454889", "bodyText": "What I intend to say here is that we should remember to pass a copied store when calling this method, otherwise the node's transfer input may be changed in the future. Here is an example: https://github.com/typetools/checker-framework/pull/3370/files#diff-9f052b8cabea4817c69534ba908adc75R349. The node in the next iteration maybe change the transfer input of the previous node. Could you please give me some advice?\nstore does not mean Store here, one parameter's name of this method is store. I can make it clear in Javadoc.", "author": "xingweitian", "createdAt": "2020-06-26T23:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ2NDYxMQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446464611", "bodyText": "store does not mean Store here, one parameter's name of this method is store. I can make it clear in Javadoc.\n\nMartin suggested that you rename the formal parameter.  It is better to give the variable a meaningful name, rather than retain a bad name and add documentation to explain how it is bad.", "author": "mernst", "createdAt": "2020-06-27T00:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ2NzQ2NQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r446467465", "bodyText": "Most of the code in AbstractAnalysis is what previously was in Analysis.\nhttps://github.com/typetools/checker-framework/blob/master/dataflow/src/main/java/org/checkerframework/dataflow/analysis/Analysis.java#L427\nInstead of just locally renaming this parameter, we can perform a clean-up later and make sure there are no TransferInput parameters with name store and that also the arguments have appropriate names.", "author": "wmdietl", "createdAt": "2020-06-27T01:26:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ0MDM4Mw=="}], "type": "inlineReview"}, {"oid": "78454288079939bbb75eb938d578a6e3572bf3d1", "url": "https://github.com/typetools/checker-framework/commit/78454288079939bbb75eb938d578a6e3572bf3d1", "message": "Add getLastNode() back.", "committedDate": "2020-06-27T04:20:35Z", "type": "commit"}, {"oid": "f7298ee2715c2da7fcb3d510ee89878eedb30146", "url": "https://github.com/typetools/checker-framework/commit/f7298ee2715c2da7fcb3d510ee89878eedb30146", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-27T04:20:53Z", "type": "commit"}, {"oid": "c7290abc9cc7704ff2cf34c8034753f972c9f5ff", "url": "https://github.com/typetools/checker-framework/commit/c7290abc9cc7704ff2cf34c8034753f972c9f5ff", "message": "Use preconditions instead of asserts.", "committedDate": "2020-06-29T12:35:47Z", "type": "commit"}, {"oid": "3c7229253b54ebd86292433f273624c05f6f71b5", "url": "https://github.com/typetools/checker-framework/commit/3c7229253b54ebd86292433f273624c05f6f71b5", "message": "Simplify changelog.", "committedDate": "2020-06-29T12:39:06Z", "type": "commit"}, {"oid": "e01fec3e3fe530a67434640331750f1d23fd158d", "url": "https://github.com/typetools/checker-framework/commit/e01fec3e3fe530a67434640331750f1d23fd158d", "message": "Merge remote-tracking branch 'typetools/master' into typetools-backward-analysis", "committedDate": "2020-06-29T17:21:19Z", "type": "commit"}, {"oid": "01a49af69fafd5eebe41b4df64cf8ce48e6f7375", "url": "https://github.com/typetools/checker-framework/commit/01a49af69fafd5eebe41b4df64cf8ce48e6f7375", "message": "Resolve comments.", "committedDate": "2020-06-29T17:26:42Z", "type": "commit"}, {"oid": "d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "url": "https://github.com/typetools/checker-framework/commit/d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "message": "Tweaks.", "committedDate": "2020-06-29T18:21:17Z", "type": "commit"}, {"oid": "3d10dff362872a7111fb5f751f9216b5f9d6d8aa", "url": "https://github.com/typetools/checker-framework/commit/3d10dff362872a7111fb5f751f9216b5f9d6d8aa", "message": "Merge remote-tracking branch 'origin/master' into typetools-backward-analysis", "committedDate": "2020-06-30T15:38:38Z", "type": "commit"}, {"oid": "cbebd6c7d27f1ebe7d10a365df08895e0b25a32d", "url": "https://github.com/typetools/checker-framework/commit/cbebd6c7d27f1ebe7d10a365df08895e0b25a32d", "message": "Use block instead of bb as parameter name.", "committedDate": "2020-06-30T15:54:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc5MTI1OQ==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r447791259", "bodyText": "Can this be removed?", "author": "smillst", "createdAt": "2020-06-30T15:51:42Z", "path": "dataflow/src/main/java/org/checkerframework/dataflow/analysis/BackwardAnalysisImpl.java", "diffHunk": "@@ -0,0 +1,392 @@\n+package org.checkerframework.dataflow.analysis;\n+\n+import java.util.IdentityHashMap;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.Map;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.checkerframework.checker.nullness.qual.RequiresNonNull;\n+import org.checkerframework.dataflow.analysis.Store.FlowRule;\n+import org.checkerframework.dataflow.cfg.ControlFlowGraph;\n+import org.checkerframework.dataflow.cfg.UnderlyingAST;\n+import org.checkerframework.dataflow.cfg.block.Block;\n+import org.checkerframework.dataflow.cfg.block.BlockImpl;\n+import org.checkerframework.dataflow.cfg.block.ConditionalBlock;\n+import org.checkerframework.dataflow.cfg.block.ExceptionBlock;\n+import org.checkerframework.dataflow.cfg.block.RegularBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock;\n+import org.checkerframework.dataflow.cfg.block.SpecialBlock.SpecialBlockType;\n+import org.checkerframework.dataflow.cfg.node.Node;\n+import org.checkerframework.dataflow.cfg.node.ReturnNode;\n+import org.checkerframework.javacutil.BugInCF;\n+\n+/**\n+ * An implementation of a backward analysis to solve a org.checkerframework.dataflow problem given a\n+ * control flow graph and a backward transfer function.\n+ *\n+ * @param <V> the abstract value type to be tracked by the analysis\n+ * @param <S> the store type used in the analysis\n+ * @param <T> the transfer function type that is used to approximate runtime behavior\n+ */\n+public class BackwardAnalysisImpl<\n+                V extends AbstractValue<V>,\n+                S extends Store<S>,\n+                T extends BackwardTransferFunction<V, S>>\n+        extends AbstractAnalysis<V, S, T> implements BackwardAnalysis<V, S, T> {\n+\n+    // TODO: Add widening support like what the forward analysis does.\n+\n+    /** Out stores after every basic block (assumed to be 'no information' if not present). */\n+    protected final IdentityHashMap<Block, S> outStores;\n+\n+    /**\n+     * Exception store of an exception block, propagated by exceptional successors of its exception\n+     * block, and merged with the normal {@link TransferResult}.\n+     */\n+    protected final IdentityHashMap<ExceptionBlock, S> exceptionStores;\n+\n+    /** The store right before the entry block. */\n+    protected @Nullable S storeAtEntry;\n+\n+    // `@code`, not `@link`, because dataflow module doesn't depend on framework module.\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+     * control flow graph. The transfer function is set by the subclass, e.g., {@code\n+     * org.checkerframework.framework.flow.CFAbstractAnalysis}, later.\n+     */\n+    public BackwardAnalysisImpl() {\n+        super(Direction.BACKWARD);\n+        this.outStores = new IdentityHashMap<>();\n+        this.exceptionStores = new IdentityHashMap<>();\n+        this.storeAtEntry = null;\n+    }\n+\n+    /**\n+     * Construct an object that can perform a org.checkerframework.dataflow backward analysis over a\n+     * control flow graph given a transfer function.\n+     *\n+     * @param transfer the transfer function\n+     */\n+    public BackwardAnalysisImpl(@Nullable T transfer) {\n+        this();\n+        this.transferFunction = transfer;\n+    }\n+\n+    @Override\n+    public void performAnalysis(ControlFlowGraph cfg) {\n+        if (isRunning) {\n+            throw new BugInCF(\n+                    \"performAnalysis() shouldn't be called when the analysis is running.\");\n+        }\n+        isRunning = true;\n+        try {\n+            init(cfg);\n+            while (!worklist.isEmpty()) {\n+                Block b = worklist.poll();\n+                performAnalysisBlock(b);\n+            }\n+        } finally {\n+            assert isRunning;\n+            // In case performAnalysisBlock crashed, reset isRunning to false.\n+            isRunning = false;\n+        }\n+    }\n+\n+    @Override\n+    public void performAnalysisBlock(Block b) {\n+        switch (b.getType()) {\n+            case REGULAR_BLOCK:\n+                {\n+                    RegularBlock rb = (RegularBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(rb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    currentInput = inputAfter.copy();\n+                    Node firstNode = null;\n+                    boolean addToWorklistAgain = false;\n+                    List<Node> nodeList = rb.getContents();\n+                    ListIterator<Node> reverseIter = nodeList.listIterator(nodeList.size());\n+                    while (reverseIter.hasPrevious()) {\n+                        Node node = reverseIter.previous();\n+                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+                        TransferResult<V, S> transferResult =\n+                                callTransferFunction(node, currentInput);\n+                        addToWorklistAgain |= updateNodeValues(node, transferResult);\n+                        currentInput = new TransferInput<>(node, this, transferResult);\n+                        firstNode = node;\n+                    }\n+                    // Propagate store to predecessors\n+                    for (BlockImpl pred : rb.getPredecessors()) {\n+                        assert currentInput != null : \"@AssumeAssertion(nullness): invariant\";\n+                        propagateStoresTo(\n+                                pred,\n+                                firstNode,\n+                                currentInput,\n+                                FlowRule.EACH_TO_EACH,\n+                                addToWorklistAgain);\n+                    }\n+                    break;\n+                }\n+            case EXCEPTION_BLOCK:\n+                {\n+                    ExceptionBlock eb = (ExceptionBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(eb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    currentInput = inputAfter.copy();\n+                    Node node = eb.getNode();\n+                    TransferResult<V, S> transferResult = callTransferFunction(node, currentInput);\n+                    boolean addToWorklistAgain = updateNodeValues(node, transferResult);\n+                    // Merge transferResult with exceptionStore if there exists one\n+                    S exceptionStore = exceptionStores.get(eb);\n+                    S mergedStore =\n+                            exceptionStore != null\n+                                    ? transferResult\n+                                            .getRegularStore()\n+                                            .leastUpperBound(exceptionStore)\n+                                    : transferResult.getRegularStore();\n+                    for (BlockImpl pred : eb.getPredecessors()) {\n+                        addStoreAfter(pred, node, mergedStore, addToWorklistAgain);\n+                    }\n+                    break;\n+                }\n+            case CONDITIONAL_BLOCK:\n+                {\n+                    ConditionalBlock cb = (ConditionalBlock) b;\n+                    TransferInput<V, S> inputAfter = getInput(cb);\n+                    assert inputAfter != null : \"@AssumeAssertion(nullness): invariant\";\n+                    TransferInput<V, S> input = inputAfter.copy();\n+                    for (BlockImpl pred : cb.getPredecessors()) {\n+                        propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n+                    }\n+                    break;\n+                }\n+            case SPECIAL_BLOCK:\n+                {\n+                    // Special basic blocks are empty and cannot throw exceptions,\n+                    // thus there is no need to perform any analysis.\n+                    SpecialBlock sb = (SpecialBlock) b;\n+                    final SpecialBlockType sType = sb.getSpecialType();\n+                    if (sType == SpecialBlockType.ENTRY) {\n+                        // storage the store at entry\n+                        storeAtEntry = outStores.get(sb);\n+                    } else {\n+                        assert sType == SpecialBlockType.EXIT\n+                                || sType == SpecialBlockType.EXCEPTIONAL_EXIT;\n+                        TransferInput<V, S> input = getInput(sb);\n+                        assert input != null : \"@AssumeAssertion(nullness): invariant\";\n+                        for (BlockImpl pred : sb.getPredecessors()) {\n+                            propagateStoresTo(pred, null, input, FlowRule.EACH_TO_EACH, false);\n+                        }\n+                    }\n+                    break;\n+                }\n+            default:\n+                throw new BugInCF(\"Unexpected block type: \" + b.getType());\n+        }\n+    }\n+\n+    @Override\n+    public @Nullable TransferInput<V, S> getInput(Block b) {\n+        return inputs.get(b);\n+    }\n+\n+    @Override\n+    public @Nullable S getEntryStore() {\n+        return storeAtEntry;\n+    }\n+\n+    @Override\n+    protected void initFields(ControlFlowGraph cfg) {\n+        super.initFields(cfg);\n+        outStores.clear();\n+        exceptionStores.clear();\n+        // storeAtEntry is null before analysis begin\n+        storeAtEntry = null;\n+    }\n+\n+    @Override\n+    @RequiresNonNull(\"cfg\")\n+    protected void initInitialInputs() {\n+        worklist.process(cfg);\n+        SpecialBlock regularExitBlock = cfg.getRegularExitBlock();\n+        SpecialBlock exceptionExitBlock = cfg.getExceptionalExitBlock();\n+        if (worklist.depthFirstOrder.get(regularExitBlock) == null\n+                && worklist.depthFirstOrder.get(exceptionExitBlock) == null) {\n+            throw new BugInCF(\n+                    \"regularExitBlock and exceptionExitBlock should never both be null at the same time.\");\n+        }\n+        UnderlyingAST underlyingAST = cfg.getUnderlyingAST();\n+        List<ReturnNode> returnNodes = cfg.getReturnNodes();\n+        assert transferFunction != null : \"@AssumeAssertion(nullness): invariant\";\n+        S normalInitialStore = transferFunction.initialNormalExitStore(underlyingAST, returnNodes);\n+        S exceptionalInitialStore = transferFunction.initialExceptionalExitStore(underlyingAST);\n+        // If regularExitBlock or exceptionExitBlock is reachable in the control flow graph, then\n+        // initialize it as a start point of the analysis.\n+        if (worklist.depthFirstOrder.get(regularExitBlock) != null) {\n+            worklist.add(regularExitBlock);\n+            inputs.put(regularExitBlock, new TransferInput<>(null, this, normalInitialStore));\n+            outStores.put(regularExitBlock, normalInitialStore);\n+        }\n+        if (worklist.depthFirstOrder.get(exceptionExitBlock) != null) {\n+            worklist.add(exceptionExitBlock);\n+            inputs.put(\n+                    exceptionExitBlock, new TransferInput<>(null, this, exceptionalInitialStore));\n+            outStores.put(exceptionExitBlock, exceptionalInitialStore);\n+        }\n+        if (worklist.isEmpty()) {\n+            throw new BugInCF(\"The worklist needs at least one exit block as starting point.\");\n+        }\n+        if (inputs.isEmpty() || outStores.isEmpty()) {\n+            throw new BugInCF(\"At least one input and one output store are required.\");\n+        }\n+    }\n+\n+    @Override\n+    protected void propagateStoresTo(\n+            Block pred,\n+            @Nullable Node node,\n+            TransferInput<V, S> currentInput,\n+            FlowRule flowRule,\n+            boolean addToWorklistAgain) {\n+        if (flowRule != FlowRule.EACH_TO_EACH) {\n+            throw new BugInCF(\n+                    \"Backward analysis always propagates EACH to EACH, because there is no control flow.\");\n+        }\n+\n+        addStoreAfter(pred, node, currentInput.getRegularStore(), addToWorklistAgain);\n+    }\n+\n+    /**\n+     * Add a store after the basic block {@code pred} by merging with the existing stores for that\n+     * location.\n+     *\n+     * @param pred the basic block\n+     * @param node the node of the basic block {@code b}\n+     * @param s the store being added\n+     * @param addBlockToWorklist whether the basic block {@code b} should be added back to {@code\n+     *     Worklist}\n+     */\n+    protected void addStoreAfter(Block pred, @Nullable Node node, S s, boolean addBlockToWorklist) {\n+        // If the block pred is an exception block, decide whether the block of passing node is an\n+        // exceptional successor of the block pred\n+        if (pred instanceof ExceptionBlock\n+                && ((ExceptionBlock) pred).getSuccessor() != null\n+                && node != null) {\n+            @Nullable Block succBlock = ((ExceptionBlock) pred).getSuccessor();\n+            @Nullable Block block = node.getBlock();\n+            if (succBlock != null && block != null && succBlock.getId() == block.getId()) {\n+                // If the block of passing node is an exceptional successor of Block pred, propagate\n+                // store to the exceptionStores. Currently it doesn't track the label of an\n+                // exceptional edge from exception block to its exceptional successors in backward\n+                // direction. Instead, all exception stores of exceptional successors of an\n+                // exception block will merge to one exception store at the exception block\n+                ExceptionBlock ebPred = (ExceptionBlock) pred;\n+                S exceptionStore = exceptionStores.get(ebPred);\n+                S newExceptionStore =\n+                        (exceptionStore != null) ? exceptionStore.leastUpperBound(s) : s;\n+                if (!newExceptionStore.equals(exceptionStore)) {\n+                    exceptionStores.put(ebPred, newExceptionStore);\n+                    addBlockToWorklist = true;\n+                }\n+            }\n+        } else {\n+            S predOutStore = getStoreAfter(pred);\n+            S newPredOutStore = (predOutStore != null) ? predOutStore.leastUpperBound(s) : s;\n+            if (!newPredOutStore.equals(predOutStore)) {\n+                outStores.put(pred, newPredOutStore);\n+                inputs.put(pred, new TransferInput<>(node, this, newPredOutStore));\n+                addBlockToWorklist = true;\n+            }\n+        }\n+        if (addBlockToWorklist) {\n+            addToWorklist(pred);\n+        }\n+    }\n+\n+    /**\n+     * Returns the store corresponding to the location right after the basic block {@code b}.\n+     *\n+     * @param b the given block\n+     * @return the store right after the given block\n+     */\n+    protected @Nullable S getStoreAfter(Block b) {\n+        return readFromStore(outStores, b);\n+    }\n+\n+    @Override\n+    public S runAnalysisFor(\n+            Node node,\n+            boolean before,\n+            TransferInput<V, S> transferInput,\n+            IdentityHashMap<Node, V> nodeValues,\n+            Map<TransferInput<V, S>, IdentityHashMap<Node, TransferResult<V, S>>> analysisCaches) {\n+        Block block = node.getBlock();\n+        assert block != null : \"@AssumeAssertion(nullness): invariant\";\n+        Node oldCurrentNode = currentNode;\n+        // TODO: Understand why the Store of passing node is analysis.currentInput.getRegularStore()", "originalCommit": "d411396f4c40aab75beb6d3dbad4e74ddc103c5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzgwNjQ0MA==", "url": "https://github.com/typetools/checker-framework/pull/3370#discussion_r447806440", "bodyText": "Yes, thanks a lot! I have removed it.", "author": "xingweitian", "createdAt": "2020-06-30T16:13:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc5MTI1OQ=="}], "type": "inlineReview"}, {"oid": "77f50dfe960804603bdad6da8ea256f3a0c3da64", "url": "https://github.com/typetools/checker-framework/commit/77f50dfe960804603bdad6da8ea256f3a0c3da64", "message": "Merge pull request #13 from smillst/typetools-backward-analysis\n\nUse block instead of bb as parameter name.", "committedDate": "2020-06-30T16:01:51Z", "type": "commit"}, {"oid": "f549ff7f77e296cf6c0aca2a3582916b5fb15776", "url": "https://github.com/typetools/checker-framework/commit/f549ff7f77e296cf6c0aca2a3582916b5fb15776", "message": "Resolve comment.", "committedDate": "2020-06-30T16:10:16Z", "type": "commit"}, {"oid": "5ab4d76c269424673723e7dee8f143a118416961", "url": "https://github.com/typetools/checker-framework/commit/5ab4d76c269424673723e7dee8f143a118416961", "message": "Merge remote-tracking branch 'origin/typetools-backward-analysis' into typetools-backward-analysis", "committedDate": "2020-06-30T16:12:06Z", "type": "commit"}]}