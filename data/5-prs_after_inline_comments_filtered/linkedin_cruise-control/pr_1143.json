{"pr_number": 1143, "pr_title": "Make slow broker finder more configurable and improve detection accuracy", "pr_createdAt": "2020-03-12T20:32:40Z", "pr_url": "https://github.com/linkedin/cruise-control/pull/1143", "timeline": [{"oid": "10fcf958ab937e814e6c114c374a662b34d9e19e", "url": "https://github.com/linkedin/cruise-control/commit/10fcf958ab937e814e6c114c374a662b34d9e19e", "message": "Make slow broker finder more configurable and improve detection accuracy.", "committedDate": "2020-03-12T20:28:33Z", "type": "commit"}, {"oid": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "url": "https://github.com/linkedin/cruise-control/commit/9b53bbf068847bd8e7667b4481a7b828cebf4251", "message": "Add test.", "committedDate": "2020-03-13T00:11:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzNjUyNw==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392536527", "bodyText": "Bad config name: SlOW_BROKERS_XXX -> SLOW_BROKERS_XXX?", "author": "efeg", "createdAt": "2020-03-14T00:25:10Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -72,28 +72,51 @@\n  * Note: if there are too many brokers being confirmed as slow broker in the same run, the finder will report the {@link SlowBrokers}\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n+ *\n+ * Required configurations for this class.\n+ * <ul>\n+ *   <li>{@link #SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold to determine whether to include broker\n+ *   in slow broker detection. If the broker only serves negligible traffic, its derived metric wil be abnormally high since\n+ *   bytes in rate is used as divisor in metric calculation. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n+ *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n+ *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n+ *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n+ *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DEMOTION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE}.</li>\n+ *   <li>{@link #SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow brokers in the cluster to trigger self-healing\n+ *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n+ * </ul>\n  */\n public class SlowBrokerFinder implements MetricAnomalyFinder<BrokerEntity> {\n   private static final Logger LOG = LoggerFactory.getLogger(SlowBrokerFinder.class);\n   // The config to enable finder reporting slow broker anomaly with broker removal as self-healing proposal.\n   public static final String SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG = \"self.healing.slow.brokers.removal.enabled\";\n   // The config finder uses to indicate anomaly to perform broker demotion or broker removal for self-healing.\n   public static final String REMOVE_SLOW_BROKERS_CONFIG = \"remove.slow.brokers\";\n-  // Todo: make following configs configurable.\n-  // The percentile threshold used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_PERCENTILE_THRESHOLD = 90.0;\n-  // The margin used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_MARGIN = 3.0;\n-  // The percentile threshold used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n-  // The margin used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_MARGIN = 5.0;\n-  // The score threshold to trigger a demotion for slow broker.\n-  private static final int SLOW_BROKER_DEMOTION_SCORE = 5;\n-  // The score threshold to trigger a removal for slow broker.\n-  private static final int SLOW_BROKER_DECOMMISSION_SCORE = 50;\n-  // The maximum ratio of slow brokers in the cluster to trigger self-healing operation.\n-  private static final double SELF_HEALING_UNFIXABLE_RATIO = 0.1;\n+  public static final String SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG = \"slow.brokers.bytes.in.rate.detection.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD = 1024.0 * 1024.0;\n+  public static final String SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.metric.history.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD = 90.0;\n+  public static final String SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG = \"slow.brokers.metric.history.margin\";\n+  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN = 3.0;\n+  public static final String SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.peer.metric.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n+  public static final String SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG = \"slow.brokers.peer.metric.margin\";\n+  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN = 10.0;\n+  public static final String SLOW_BROKERS_DEMOTION_SCORE_CONFIG = \"slow.brokers.demotion.score\";\n+  public static final int DEFAULT_SLOW_BROKERS_DEMOTION_SCORE = 5;\n+  public static final String SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG = \"slow.brokers.decommission.score\";\n+  public static final int DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE = 50;\n+  public static final String SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG = \"slow.brokers.self.healing.unfixable.ratio\";", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzNjgyNA==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392536824", "bodyText": "Nit: Can we use singular names in config -- i.e. SLOW_BROKERS_XXX -> SLOW_BROKER_XXX?", "author": "efeg", "createdAt": "2020-03-14T00:27:01Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -72,28 +72,51 @@\n  * Note: if there are too many brokers being confirmed as slow broker in the same run, the finder will report the {@link SlowBrokers}\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n+ *\n+ * Required configurations for this class.\n+ * <ul>\n+ *   <li>{@link #SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold to determine whether to include broker\n+ *   in slow broker detection. If the broker only serves negligible traffic, its derived metric wil be abnormally high since\n+ *   bytes in rate is used as divisor in metric calculation. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n+ *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n+ *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n+ *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n+ *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DEMOTION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE}.</li>\n+ *   <li>{@link #SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow brokers in the cluster to trigger self-healing\n+ *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n+ * </ul>\n  */\n public class SlowBrokerFinder implements MetricAnomalyFinder<BrokerEntity> {\n   private static final Logger LOG = LoggerFactory.getLogger(SlowBrokerFinder.class);\n   // The config to enable finder reporting slow broker anomaly with broker removal as self-healing proposal.\n   public static final String SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG = \"self.healing.slow.brokers.removal.enabled\";\n   // The config finder uses to indicate anomaly to perform broker demotion or broker removal for self-healing.\n   public static final String REMOVE_SLOW_BROKERS_CONFIG = \"remove.slow.brokers\";\n-  // Todo: make following configs configurable.\n-  // The percentile threshold used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_PERCENTILE_THRESHOLD = 90.0;\n-  // The margin used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_MARGIN = 3.0;\n-  // The percentile threshold used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n-  // The margin used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_MARGIN = 5.0;\n-  // The score threshold to trigger a demotion for slow broker.\n-  private static final int SLOW_BROKER_DEMOTION_SCORE = 5;\n-  // The score threshold to trigger a removal for slow broker.\n-  private static final int SLOW_BROKER_DECOMMISSION_SCORE = 50;\n-  // The maximum ratio of slow brokers in the cluster to trigger self-healing operation.\n-  private static final double SELF_HEALING_UNFIXABLE_RATIO = 0.1;\n+  public static final String SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG = \"slow.brokers.bytes.in.rate.detection.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD = 1024.0 * 1024.0;\n+  public static final String SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.metric.history.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD = 90.0;\n+  public static final String SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG = \"slow.brokers.metric.history.margin\";\n+  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN = 3.0;\n+  public static final String SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.peer.metric.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n+  public static final String SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG = \"slow.brokers.peer.metric.margin\";\n+  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN = 10.0;\n+  public static final String SLOW_BROKERS_DEMOTION_SCORE_CONFIG = \"slow.brokers.demotion.score\";\n+  public static final int DEFAULT_SLOW_BROKERS_DEMOTION_SCORE = 5;\n+  public static final String SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG = \"slow.brokers.decommission.score\";\n+  public static final int DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE = 50;\n+  public static final String SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG = \"slow.brokers.self.healing.unfixable.ratio\";", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzODA5NQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392538095", "bodyText": "Doesn't the phrase required configurations imply \"if the user does not configure, then the thing to be configured will not function\"? However, we seem to have default values if the configs are not set by users.\nShould we rephrase it to indicate that they are optional?", "author": "efeg", "createdAt": "2020-03-14T00:35:32Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -72,28 +72,51 @@\n  * Note: if there are too many brokers being confirmed as slow broker in the same run, the finder will report the {@link SlowBrokers}\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n+ *\n+ * Required configurations for this class.", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzOTA4NQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392539085", "bodyText": "Nit: It is difficult to fully understand the functionality of configs from provided descriptions. Can we add some numerical examples to descriptions to make them more clear?", "author": "efeg", "createdAt": "2020-03-14T00:38:25Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -72,28 +72,51 @@\n  * Note: if there are too many brokers being confirmed as slow broker in the same run, the finder will report the {@link SlowBrokers}\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n+ *\n+ * Required configurations for this class.\n+ * <ul>\n+ *   <li>{@link #SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold to determine whether to include broker\n+ *   in slow broker detection. If the broker only serves negligible traffic, its derived metric wil be abnormally high since\n+ *   bytes in rate is used as divisor in metric calculation. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n+ *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n+ *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n+ *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n+ *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DEMOTION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE}.</li>\n+ *   <li>{@link #SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow brokers in the cluster to trigger self-healing\n+ *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n+ * </ul>", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjY5ODMyNg==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392698326", "bodyText": "I think the default value serves that purpose.", "author": "kidkun", "createdAt": "2020-03-15T18:12:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzOTA4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzOTM5Nw==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392539397", "bodyText": "What is the unit of this config and the default value -- e.g. is it bytes per second? Can we indicate this in description?", "author": "efeg", "createdAt": "2020-03-14T00:40:27Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -72,28 +72,51 @@\n  * Note: if there are too many brokers being confirmed as slow broker in the same run, the finder will report the {@link SlowBrokers}\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n+ *\n+ * Required configurations for this class.\n+ * <ul>\n+ *   <li>{@link #SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold to determine whether to include broker\n+ *   in slow broker detection. If the broker only serves negligible traffic, its derived metric wil be abnormally high since\n+ *   bytes in rate is used as divisor in metric calculation. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n+ *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n+ *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n+ *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n+ *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DEMOTION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE}.</li>\n+ *   <li>{@link #SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow brokers in the cluster to trigger self-healing\n+ *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n+ * </ul>\n  */\n public class SlowBrokerFinder implements MetricAnomalyFinder<BrokerEntity> {\n   private static final Logger LOG = LoggerFactory.getLogger(SlowBrokerFinder.class);\n   // The config to enable finder reporting slow broker anomaly with broker removal as self-healing proposal.\n   public static final String SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG = \"self.healing.slow.brokers.removal.enabled\";\n   // The config finder uses to indicate anomaly to perform broker demotion or broker removal for self-healing.\n   public static final String REMOVE_SLOW_BROKERS_CONFIG = \"remove.slow.brokers\";\n-  // Todo: make following configs configurable.\n-  // The percentile threshold used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_PERCENTILE_THRESHOLD = 90.0;\n-  // The margin used to compare latest metric value against historical value.\n-  private static final double HISTORY_METRIC_MARGIN = 3.0;\n-  // The percentile threshold used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n-  // The margin used to compare last metric value against peers' latest value.\n-  private static final double PEER_METRIC_MARGIN = 5.0;\n-  // The score threshold to trigger a demotion for slow broker.\n-  private static final int SLOW_BROKER_DEMOTION_SCORE = 5;\n-  // The score threshold to trigger a removal for slow broker.\n-  private static final int SLOW_BROKER_DECOMMISSION_SCORE = 50;\n-  // The maximum ratio of slow brokers in the cluster to trigger self-healing operation.\n-  private static final double SELF_HEALING_UNFIXABLE_RATIO = 0.1;\n+  public static final String SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG = \"slow.brokers.bytes.in.rate.detection.threshold\";\n+  public static final double DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD = 1024.0 * 1024.0;", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MDI5Nw==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392540297", "bodyText": "(Applies to the other similar uses): I am not sure if it is intuitive to use the default if there is a NumberFormatException. Wouldn't this happen, for example, in case the user has a typo in config value? Shouldn't we throw a ConfigException in such cases?", "author": "efeg", "createdAt": "2020-03-14T00:47:48Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -297,7 +328,71 @@ public void configure(Map<String, ?> configs) {\n       throw new IllegalArgumentException(\"Slow broker detector is missing \" + KAFKA_CRUISE_CONTROL_OBJECT_CONFIG);\n     }\n     // Config for slow broker removal.\n-    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) _kafkaCruiseControl.config().originals()\n-                                                                                 .get(SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG));\n+    Map<String, Object> originalConfig = _kafkaCruiseControl.config().originals();\n+    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) originalConfig.get(SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG));\n+    try {\n+      _bytesInRateDetectionThreshold = Double.parseDouble((String) originalConfig.get(SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG));\n+      if (_bytesInRateDetectionThreshold < 0) {\n+        throw new IllegalArgumentException(String.format(\"%s config of slow broker finder should not be set to negative.\",\n+                                                         SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG));\n+      }\n+    } catch (NumberFormatException | NullPointerException e) {", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MDQyNQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392540425", "bodyText": "(Applies to other exceptions in configuration method) -> For consistency with typical use across the project, can we throw ConfigException rather than IllegalArgumentException?", "author": "efeg", "createdAt": "2020-03-14T00:48:56Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -297,7 +328,71 @@ public void configure(Map<String, ?> configs) {\n       throw new IllegalArgumentException(\"Slow broker detector is missing \" + KAFKA_CRUISE_CONTROL_OBJECT_CONFIG);\n     }\n     // Config for slow broker removal.\n-    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) _kafkaCruiseControl.config().originals()\n-                                                                                 .get(SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG));\n+    Map<String, Object> originalConfig = _kafkaCruiseControl.config().originals();\n+    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) originalConfig.get(SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG));\n+    try {\n+      _bytesInRateDetectionThreshold = Double.parseDouble((String) originalConfig.get(SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG));\n+      if (_bytesInRateDetectionThreshold < 0) {\n+        throw new IllegalArgumentException(String.format(\"%s config of slow broker finder should not be set to negative.\",", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MDY5NQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392540695", "bodyText": "The previous comment on the handling of NumberFormatException exceptions applies to here.", "author": "efeg", "createdAt": "2020-03-14T00:51:10Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/TopicReplicationFactorAnomalyFinder.java", "diffHunk": "@@ -220,7 +220,7 @@ public void configure(Map<String, ?> configs) {\n         throw new IllegalArgumentException(String.format(\"%s config of replication factor anomaly finder should be set to positive,\"\n             + \" provided %d.\", TOPIC_MIN_ISR_RECORD_RETENTION_TIME_MS_CONFIG, _topicMinISRRecordRetentionTimeMs));\n       }\n-    } catch (NumberFormatException e) {\n+    } catch (NumberFormatException | NullPointerException e) {", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MTAxOQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392541019", "bodyText": "With these changes, is @SuppressWarnings(\"unchecked\") still needed?", "author": "efeg", "createdAt": "2020-03-14T00:54:07Z", "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/detector/KafkaMetricAnomalyFinderTest.java", "diffHunk": "@@ -156,20 +84,6 @@ private ValuesAndExtrapolations createCurrentValuesAndExtrapolations(long window\n                       \"BROKER_PRODUCE_LOCAL_TIME_MS_50TH,BROKER_PRODUCE_LOCAL_TIME_MS_999TH,BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_50TH,\"\n                       + \"BROKER_CONSUMER_FETCH_LOCAL_TIME_MS_999TH,BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_50TH,\"\n                       + \"BROKER_FOLLOWER_FETCH_LOCAL_TIME_MS_999TH,BROKER_LOG_FLUSH_TIME_MS_50TH,BROKER_LOG_FLUSH_TIME_MS_999TH\");\n-\n-    KafkaCruiseControlConfig config = new KafkaCruiseControlConfig(props);\n-\n-    KafkaCruiseControl mockKafkaCruiseControl = EasyMock.mock(KafkaCruiseControl.class);\n-    EasyMock.expect(mockKafkaCruiseControl.config()).andReturn(config);\n-    EasyMock.expect(mockKafkaCruiseControl.timeMs()).andReturn(_anomalyDetectionTimeMs).anyTimes();\n-    EasyMock.replay(mockKafkaCruiseControl);\n-    Map<String, Object> originalConfigs = new HashMap<>(config.originals());\n-    originalConfigs.put(KAFKA_CRUISE_CONTROL_OBJECT_CONFIG, mockKafkaCruiseControl);\n-\n-    List<MetricAnomalyFinder> kafkaMetricAnomalyFinders = config.getConfiguredInstances(\n-        AnomalyDetectorConfig.METRIC_ANOMALY_FINDER_CLASSES_CONFIG,\n-        MetricAnomalyFinder.class,\n-        originalConfigs);\n-    return kafkaMetricAnomalyFinders.get(0);\n+    return createMetricAnomalyFinder(props);", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0Mjk1Mw==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392542953", "bodyText": "Is this suppression needed?", "author": "efeg", "createdAt": "2020-03-14T01:11:51Z", "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinderTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+package com.linkedin.kafka.cruisecontrol.detector;\n+\n+import com.linkedin.cruisecontrol.detector.metricanomaly.MetricAnomaly;\n+import com.linkedin.cruisecontrol.monitor.sampling.aggregator.ValuesAndExtrapolations;\n+import com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUnitTestUtils;\n+import com.linkedin.kafka.cruisecontrol.config.constants.AnomalyDetectorConfig;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerEntity;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.junit.Test;\n+\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createHistory;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createCurrentMetrics;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.BROKER_ENTITIES;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.ANOMALY_DETECTION_TIME_MS;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createMetricAnomalyFinder;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertEquals;\n+\n+\n+public class SlowBrokerFinderTest {\n+  private final static double NORMAL_BYTES_IN_RATE = 1024.0 * 1024.0;\n+  private final static double SMALL_BYTES_IN_RATE = 1024.0;\n+  private final static double NORMAL_LOG_FLUSH_TIME_MS = 100.0;\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromHistory() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> history =\n+        createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0));\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics =\n+        createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 5),\n+                      11, BROKER_ENTITIES.get(0));\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromPeer() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                          11, BROKER_ENTITIES.get(0)));\n+    history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                   10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                     10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testExcludingSmallTrafficBroker() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(\n+        createCurrentMetrics(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 11, BROKER_ENTITIES.get(0)));\n+    history.putAll(\n+        createHistory(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(\n+          createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(anomalies.isEmpty());\n+  }\n+\n+  @Test\n+  public void testInsufficientData() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> history =\n+        createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 5, BROKER_ENTITIES.get(0));\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics =\n+        createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 2),\n+                             6, BROKER_ENTITIES.get(0));\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(anomalies.isEmpty());\n+  }\n+\n+  private Map<Short, Double> populateMetricValues(double leaderBytesInRate, double replicationBytesInRate, double logFlushTimeMs) {\n+    Map<Short, Double> res = new HashMap<>(3);\n+    res.put(KafkaMetricDef.brokerMetricDef().metricInfo(KafkaMetricDef.BROKER_LOG_FLUSH_TIME_MS_999TH.name()).id(), logFlushTimeMs);\n+    res.put(KafkaMetricDef.brokerMetricDef().metricInfo(KafkaMetricDef.LEADER_BYTES_IN.name()).id(), leaderBytesInRate);\n+    res.put(KafkaMetricDef.brokerMetricDef().metricInfo(KafkaMetricDef.REPLICATION_BYTES_IN_RATE.name()).id(), replicationBytesInRate);\n+    return res;\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MzAwOA==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392543008", "bodyText": "What is res -- can we spell it out?", "author": "efeg", "createdAt": "2020-03-14T01:12:31Z", "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinderTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+package com.linkedin.kafka.cruisecontrol.detector;\n+\n+import com.linkedin.cruisecontrol.detector.metricanomaly.MetricAnomaly;\n+import com.linkedin.cruisecontrol.monitor.sampling.aggregator.ValuesAndExtrapolations;\n+import com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUnitTestUtils;\n+import com.linkedin.kafka.cruisecontrol.config.constants.AnomalyDetectorConfig;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerEntity;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.junit.Test;\n+\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createHistory;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createCurrentMetrics;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.BROKER_ENTITIES;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.ANOMALY_DETECTION_TIME_MS;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createMetricAnomalyFinder;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertEquals;\n+\n+\n+public class SlowBrokerFinderTest {\n+  private final static double NORMAL_BYTES_IN_RATE = 1024.0 * 1024.0;\n+  private final static double SMALL_BYTES_IN_RATE = 1024.0;\n+  private final static double NORMAL_LOG_FLUSH_TIME_MS = 100.0;\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromHistory() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> history =\n+        createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0));\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics =\n+        createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 5),\n+                      11, BROKER_ENTITIES.get(0));\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromPeer() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                          11, BROKER_ENTITIES.get(0)));\n+    history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                   10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                     10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testExcludingSmallTrafficBroker() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(\n+        createCurrentMetrics(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 11, BROKER_ENTITIES.get(0)));\n+    history.putAll(\n+        createHistory(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(\n+          createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(anomalies.isEmpty());\n+  }\n+\n+  @Test\n+  public void testInsufficientData() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> history =\n+        createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 5, BROKER_ENTITIES.get(0));\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics =\n+        createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 2),\n+                             6, BROKER_ENTITIES.get(0));\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(anomalies.isEmpty());\n+  }\n+\n+  private Map<Short, Double> populateMetricValues(double leaderBytesInRate, double replicationBytesInRate, double logFlushTimeMs) {\n+    Map<Short, Double> res = new HashMap<>(3);", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0MzE2MQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r392543161", "bodyText": "(applies to other unit tests) The tested scenario is not clear, can we add comments or JavaDoc to give a high-level overview of what is being tested?", "author": "efeg", "createdAt": "2020-03-14T01:14:11Z", "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinderTest.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+package com.linkedin.kafka.cruisecontrol.detector;\n+\n+import com.linkedin.cruisecontrol.detector.metricanomaly.MetricAnomaly;\n+import com.linkedin.cruisecontrol.monitor.sampling.aggregator.ValuesAndExtrapolations;\n+import com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUnitTestUtils;\n+import com.linkedin.kafka.cruisecontrol.config.constants.AnomalyDetectorConfig;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerEntity;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import org.junit.Test;\n+\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createHistory;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createCurrentMetrics;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.BROKER_ENTITIES;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.ANOMALY_DETECTION_TIME_MS;\n+import static com.linkedin.kafka.cruisecontrol.detector.AnomalyDetectorTestUtils.createMetricAnomalyFinder;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.assertEquals;\n+\n+\n+public class SlowBrokerFinderTest {\n+  private final static double NORMAL_BYTES_IN_RATE = 1024.0 * 1024.0;\n+  private final static double SMALL_BYTES_IN_RATE = 1024.0;\n+  private final static double NORMAL_LOG_FLUSH_TIME_MS = 100.0;\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromHistory() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> history =\n+        createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0));\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics =\n+        createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 5),\n+                      11, BROKER_ENTITIES.get(0));\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testDetectingSlowBrokerFromPeer() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                          11, BROKER_ENTITIES.get(0)));\n+    history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS * 11),\n+                   10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                     10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(\"There should be exactly a single slow broker\", anomalies.size() == 1);\n+    MetricAnomaly<BrokerEntity> anomaly = anomalies.iterator().next();\n+    assertTrue(anomaly.entities().containsKey(BROKER_ENTITIES.get(0)));\n+    assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n+  }\n+\n+  @Test\n+  public void testExcludingSmallTrafficBroker() {\n+    SlowBrokerFinder slowBrokerFinder = createSlowBrokerFinder();\n+    Map<BrokerEntity, ValuesAndExtrapolations> currentMetrics = new HashMap<>(BROKER_ENTITIES.size());\n+    Map<BrokerEntity, ValuesAndExtrapolations> history = new HashMap<>(BROKER_ENTITIES.size());\n+    currentMetrics.putAll(\n+        createCurrentMetrics(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 11, BROKER_ENTITIES.get(0)));\n+    history.putAll(\n+        createHistory(populateMetricValues(SMALL_BYTES_IN_RATE, SMALL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(0)));\n+    for (int i = 1; i < BROKER_ENTITIES.size(); i++) {\n+      currentMetrics.putAll(createCurrentMetrics(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS),\n+                            11, BROKER_ENTITIES.get(i)));\n+      history.putAll(\n+          createHistory(populateMetricValues(NORMAL_BYTES_IN_RATE, NORMAL_BYTES_IN_RATE, NORMAL_LOG_FLUSH_TIME_MS), 10, BROKER_ENTITIES.get(i)));\n+    }\n+    Collection<MetricAnomaly<BrokerEntity>> anomalies = slowBrokerFinder.metricAnomalies(history, currentMetrics);\n+    assertTrue(anomalies.isEmpty());\n+  }\n+\n+  @Test\n+  public void testInsufficientData() {", "originalCommit": "9b53bbf068847bd8e7667b4481a7b828cebf4251", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "719e1772c237237444d5509afcd5c2850e7e1cba", "url": "https://github.com/linkedin/cruise-control/commit/719e1772c237237444d5509afcd5c2850e7e1cba", "message": "Address the feedback.", "committedDate": "2020-03-15T18:59:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2MjE5OA==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393162198", "bodyText": "Bad variable name -- i.e. please note the lower case l.", "author": "efeg", "createdAt": "2020-03-16T16:44:15Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -73,50 +74,50 @@\n  * anomaly as unfixable. Because this often indicates some serious issue in the cluster and probably requires administrator's\n  * intervention to decide the right remediation strategy.\n  *\n- * Required configurations for this class.\n+ * Related configurations for this class.\n  * <ul>\n- *   <li>{@link #SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold to determine whether to include broker\n- *   in slow broker detection. If the broker only serves negligible traffic, its derived metric wil be abnormally high since\n- *   bytes in rate is used as divisor in metric calculation. Default value is set to\n- *   {@link #DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n- *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n- *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n- *   <li>{@link #SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n- *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN}.</li>\n- *   <li>{@link #SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n- *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n- *   <li>{@link #SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n- *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN}.</li>\n- *   <li>{@link #SLOW_BROKERS_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n- *   {@link #DEFAULT_SLOW_BROKERS_DEMOTION_SCORE}.</li>\n- *   <li>{@link #SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n- *   {@link #DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE}.</li>\n- *   <li>{@link #SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow brokers in the cluster to trigger self-healing\n- *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n+ *   <li>{@link #SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG}: the bytes in rate threshold in unit of bytes per second to\n+ *   determine whether to include broker in slow broker detection. If the broker only serves negligible traffic, its derived metric\n+ *   wil be abnormally high since bytes in rate is used as divisor in metric calculation. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKER_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare latest metric value against\n+ *   historical value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKER_METRIC_HISTORY_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKER_METRIC_HISTORY_MARGIN_CONFIG}: the margin used to compare latest metric value against historical value in\n+ *   slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKER_METRIC_HISTORY_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKER_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG}: the percentile threshold used to compare last metric value against\n+ *   peers' latest value in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKER_PEER_METRIC_PERCENTILE_THRESHOLD}.</li>\n+ *   <li>{@link #SLOW_BROKER_PEER_METRIC_MARGIN_CONFIG}: the margin used to compare last metric value against peers' latest value\n+ *   in slow broker detection. Default value is set to {@link #DEFAULT_SLOW_BROKER_PEER_METRIC_MARGIN}.</li>\n+ *   <li>{@link #SLOW_BROKER_DEMOTION_SCORE_CONFIG}: the score threshold to trigger a demotion for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKER_DEMOTION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKER_DECOMMISSION_SCORE_CONFIG}: the score threshold to trigger a removal for slow broker. Default value is set to\n+ *   {@link #DEFAULT_SLOW_BROKER_DECOMMISSION_SCORE}.</li>\n+ *   <li>{@link #SLOW_BROKER_SELF_HEALING_UNFIXABLE_RATIO_CONFIG}: the maximum ratio of slow broker in the cluster to trigger self-healing\n+ *   operation. Default value is set to {@link #DEFAULT_SlOW_BROKER_SELF_HEALING_UNFIXABLE_RATIO}.</li>\n  * </ul>\n  */\n public class SlowBrokerFinder implements MetricAnomalyFinder<BrokerEntity> {\n   private static final Logger LOG = LoggerFactory.getLogger(SlowBrokerFinder.class);\n   // The config to enable finder reporting slow broker anomaly with broker removal as self-healing proposal.\n-  public static final String SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG = \"self.healing.slow.brokers.removal.enabled\";\n+  public static final String SELF_HEALING_SLOW_BROKER_REMOVAL_ENABLED_CONFIG = \"self.healing.slow.broker.removal.enabled\";\n   // The config finder uses to indicate anomaly to perform broker demotion or broker removal for self-healing.\n-  public static final String REMOVE_SLOW_BROKERS_CONFIG = \"remove.slow.brokers\";\n-  public static final String SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG = \"slow.brokers.bytes.in.rate.detection.threshold\";\n-  public static final double DEFAULT_SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD = 1024.0 * 1024.0;\n-  public static final String SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.metric.history.percentile.threshold\";\n-  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_PERCENTILE_THRESHOLD = 90.0;\n-  public static final String SLOW_BROKERS_METRIC_HISTORY_MARGIN_CONFIG = \"slow.brokers.metric.history.margin\";\n-  public static final double DEFAULT_SLOW_BROKERS_METRIC_HISTORY_MARGIN = 3.0;\n-  public static final String SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG = \"slow.brokers.peer.metric.percentile.threshold\";\n-  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n-  public static final String SLOW_BROKERS_PEER_METRIC_MARGIN_CONFIG = \"slow.brokers.peer.metric.margin\";\n-  public static final double DEFAULT_SLOW_BROKERS_PEER_METRIC_MARGIN = 10.0;\n-  public static final String SLOW_BROKERS_DEMOTION_SCORE_CONFIG = \"slow.brokers.demotion.score\";\n-  public static final int DEFAULT_SLOW_BROKERS_DEMOTION_SCORE = 5;\n-  public static final String SLOW_BROKERS_DECOMMISSION_SCORE_CONFIG = \"slow.brokers.decommission.score\";\n-  public static final int DEFAULT_SLOW_BROKERS_DECOMMISSION_SCORE = 50;\n-  public static final String SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO_CONFIG = \"slow.brokers.self.healing.unfixable.ratio\";\n-  private static final double DEFAULT_SlOW_BROKERS_SELF_HEALING_UNFIXABLE_RATIO = 0.1;\n+  public static final String REMOVE_SLOW_BROKER_CONFIG = \"remove.slow.broker\";\n+  public static final String SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG = \"slow.broker.bytes.in.rate.detection.threshold\";\n+  public static final double DEFAULT_SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD = 1024.0 * 1024.0;\n+  public static final String SLOW_BROKER_METRIC_HISTORY_PERCENTILE_THRESHOLD_CONFIG = \"slow.broker.metric.history.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKER_METRIC_HISTORY_PERCENTILE_THRESHOLD = 90.0;\n+  public static final String SLOW_BROKER_METRIC_HISTORY_MARGIN_CONFIG = \"slow.broker.metric.history.margin\";\n+  public static final double DEFAULT_SLOW_BROKER_METRIC_HISTORY_MARGIN = 3.0;\n+  public static final String SLOW_BROKER_PEER_METRIC_PERCENTILE_THRESHOLD_CONFIG = \"slow.broker.peer.metric.percentile.threshold\";\n+  public static final double DEFAULT_SLOW_BROKER_PEER_METRIC_PERCENTILE_THRESHOLD = 50.0;\n+  public static final String SLOW_BROKER_PEER_METRIC_MARGIN_CONFIG = \"slow.broker.peer.metric.margin\";\n+  public static final double DEFAULT_SLOW_BROKER_PEER_METRIC_MARGIN = 10.0;\n+  public static final String SLOW_BROKER_DEMOTION_SCORE_CONFIG = \"slow.broker.demotion.score\";\n+  public static final int DEFAULT_SLOW_BROKER_DEMOTION_SCORE = 5;\n+  public static final String SLOW_BROKER_DECOMMISSION_SCORE_CONFIG = \"slow.broker.decommission.score\";\n+  public static final int DEFAULT_SLOW_BROKER_DECOMMISSION_SCORE = 50;\n+  public static final String SLOW_BROKER_SELF_HEALING_UNFIXABLE_RATIO_CONFIG = \"slow.broker.self.healing.unfixable.ratio\";\n+  private static final double DEFAULT_SlOW_BROKER_SELF_HEALING_UNFIXABLE_RATIO = 0.1;", "originalCommit": "719e1772c237237444d5509afcd5c2850e7e1cba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2MzgwMg==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393163802", "bodyText": "Applies to the other NumberFormatException -> can we indicate why it is invalid?", "author": "efeg", "createdAt": "2020-03-16T16:46:40Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -329,70 +330,126 @@ public void configure(Map<String, ?> configs) {\n     }\n     // Config for slow broker removal.\n     Map<String, Object> originalConfig = _kafkaCruiseControl.config().originals();\n-    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) originalConfig.get(SELF_HEALING_SLOW_BROKERS_REMOVAL_ENABLED_CONFIG));\n-    try {\n-      _bytesInRateDetectionThreshold = Double.parseDouble((String) originalConfig.get(SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG));\n-      if (_bytesInRateDetectionThreshold < 0) {\n-        throw new IllegalArgumentException(String.format(\"%s config of slow broker finder should not be set to negative.\",\n-                                                         SLOW_BROKERS_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG));\n+    _slowBrokerRemovalEnabled = Boolean.parseBoolean((String) originalConfig.get(SELF_HEALING_SLOW_BROKER_REMOVAL_ENABLED_CONFIG));\n+\n+    String bytesInRateDetectionThreshold = (String) originalConfig.get(SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG);\n+    if (bytesInRateDetectionThreshold == null) {\n+      _bytesInRateDetectionThreshold = DEFAULT_SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD;\n+    } else {\n+      try {\n+        _bytesInRateDetectionThreshold = Double.parseDouble(bytesInRateDetectionThreshold);\n+        if (_bytesInRateDetectionThreshold < 0) {\n+          throw new ConfigException(String.format(\"%s config of slow broker finder should not be set to negative, provided: %f.\",\n+                                                  SLOW_BROKER_BYTES_IN_RATE_DETECTION_THRESHOLD_CONFIG, _bytesInRateDetectionThreshold));\n+        }\n+      } catch (NumberFormatException e) {\n+        throw new ConfigException(String.format(\"%s config of slow broker finder is invalid, provided: %s.\",", "originalCommit": "719e1772c237237444d5509afcd5c2850e7e1cba", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2NjAwMg==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393166002", "bodyText": "Is this consistently abnormally high compared to the other brokers in the cluster? Does this comparison take excluded brokers for (1) demotion and (2) replica movement?\nA broker can be up but does not accept replica moves during its lifetime (this can change dynamically. Do we keep track of its historical changes. If not can we do that to avoid false positives?)", "author": "efeg", "createdAt": "2020-03-16T16:50:09Z", "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinderTest.java", "diffHunk": "@@ -44,6 +47,9 @@ public void testDetectingSlowBrokerFromHistory() {\n     assertEquals(ANOMALY_DETECTION_TIME_MS, (long) anomaly.entities().get(BROKER_ENTITIES.get(0)));\n   }\n \n+  /**\n+   * Test slow broker finder can detect broker with abnormally high metric in the cluster.", "originalCommit": "719e1772c237237444d5509afcd5c2850e7e1cba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4MDI5MQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393180291", "bodyText": "A broker which is excluded brokers for demotion and replica movement can still be detected as a  slow broker if it serves large traffic and performs at lower capacity.\nIn this situation, self-healing can still move replicas/leadership off this broker.", "author": "kidkun", "createdAt": "2020-03-16T17:06:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2NjAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4NjY5Nw==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393186697", "bodyText": "I was thinking about the case, where a non-excluded broker is detected as having an abnormally high metric due to other few brokers being excluded; hence, having comparably lower metric.\nIn this scenario, would excluding such excluded brokers from peer comparison be needed?", "author": "efeg", "createdAt": "2020-03-16T17:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2NjAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4ODY2MA==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393188660", "bodyText": "I see, that's a good point!", "author": "kidkun", "createdAt": "2020-03-16T17:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE2NjAwMg=="}], "type": "inlineReview"}, {"oid": "63d6b40132ff99106fc07d2e9a4ae5ca03f9ba75", "url": "https://github.com/linkedin/cruise-control/commit/63d6b40132ff99106fc07d2e9a4ae5ca03f9ba75", "message": "Address the feedback.", "committedDate": "2020-03-16T17:08:07Z", "type": "commit"}, {"oid": "1f9f51cfa7b8bdcdabc3b5281f78c7283914dc0c", "url": "https://github.com/linkedin/cruise-control/commit/1f9f51cfa7b8bdcdabc3b5281f78c7283914dc0c", "message": "Address the feedback,", "committedDate": "2020-03-17T03:39:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk5MzgzNQ==", "url": "https://github.com/linkedin/cruise-control/pull/1143#discussion_r393993835", "bodyText": "Should we eliminate infinitesimal log flush metric values?", "author": "efeg", "createdAt": "2020-03-17T21:56:22Z", "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/detector/SlowBrokerFinder.java", "diffHunk": "@@ -146,44 +146,101 @@ public SlowBrokerFinder() {\n \n   private Set<BrokerEntity> detectMetricAnomalies(Map<BrokerEntity, ValuesAndExtrapolations> metricsHistoryByBroker,\n                                                   Map<BrokerEntity, ValuesAndExtrapolations> currentMetricsByBroker) {\n-    // Preprocess raw metrics to get the derived metrics for each broker.\n-    Map<BrokerEntity, List<Double>> historicalValueByBroker = new HashMap<>();\n-    Map<BrokerEntity, Double> currentValueByBroker = new HashMap<>();\n+    // Preprocess raw metrics to get the metrics of interest for each broker.\n+    Map<BrokerEntity, List<Double>> historicalLogFlushTimeMetricValues = new HashMap<>();\n+    Map<BrokerEntity, Double> currentLogFlushTimeMetricValues = new HashMap<>();\n+    Map<BrokerEntity, List<Double>> historicalPerByteLogFlushTimeMetricValues = new HashMap<>();\n+    Map<BrokerEntity, Double> currentPerByteLogFlushTimeMetricValues = new HashMap<>();\n     Set<Integer> skippedBrokers = new HashSet<>();\n-    for (Map.Entry<BrokerEntity, ValuesAndExtrapolations> entry : currentMetricsByBroker.entrySet()) {\n-      BrokerEntity entity = entry.getKey();\n-      AggregatedMetricValues aggregatedMetricValues = entry.getValue().metricValues();\n-      double latestLogFlushTime = aggregatedMetricValues.valuesFor(BROKER_LOG_FLUSH_TIME_MS_999TH_ID).latest();\n-      double latestTotalBytesIn = aggregatedMetricValues.valuesFor(LEADER_BYTES_IN_ID).latest() +\n-                                  aggregatedMetricValues.valuesFor(REPLICATION_BYTES_IN_RATE_ID).latest();\n-      // Ignore brokers which currently serve negligible traffic.\n-      if (latestTotalBytesIn >= _bytesInRateDetectionThreshold && latestLogFlushTime > 0) {\n-        currentValueByBroker.put(entity, latestLogFlushTime / latestTotalBytesIn);\n-        aggregatedMetricValues = metricsHistoryByBroker.get(entity).metricValues();\n-        double[] historicalBytesIn = aggregatedMetricValues.valuesFor(LEADER_BYTES_IN_ID).doubleArray();\n-        double[] historicalReplicationBytesIn = aggregatedMetricValues.valuesFor(REPLICATION_BYTES_IN_RATE_ID).doubleArray();\n-        double[] historicalLogFlushTime = aggregatedMetricValues.valuesFor(BROKER_LOG_FLUSH_TIME_MS_999TH_ID).doubleArray();\n-        List<Double> historicalValue = new ArrayList<>(historicalBytesIn.length);\n-        for (int i = 0; i < historicalBytesIn.length; i++) {\n-          double totalBytesIn = historicalBytesIn[i] + historicalReplicationBytesIn[i];\n-          if (totalBytesIn >= _bytesInRateDetectionThreshold) {\n-            historicalValue.add(historicalLogFlushTime[i] / totalBytesIn);\n-          }\n-        }\n-        historicalValueByBroker.put(entity, historicalValue);\n+    for (BrokerEntity broker : currentMetricsByBroker.keySet()) {\n+      if (!brokerHasNegligibleTraffic(broker, currentMetricsByBroker)) {\n+        collectLogFlushTimeMetric(broker,\n+                                  metricsHistoryByBroker,\n+                                  currentMetricsByBroker,\n+                                  historicalLogFlushTimeMetricValues,\n+                                  currentLogFlushTimeMetricValues);\n+        collectPerByteLogFlushTimeMetric(broker,\n+                                         metricsHistoryByBroker,\n+                                         currentMetricsByBroker,\n+                                         historicalPerByteLogFlushTimeMetricValues,\n+                                         currentPerByteLogFlushTimeMetricValues);\n       } else {\n-        skippedBrokers.add(entity.brokerId());\n+        skippedBrokers.add(broker.brokerId());\n       }\n     }\n \n     if (!skippedBrokers.isEmpty()) {\n       LOG.info(\"Skip broker slowness checking for brokers {} because they serve negligible traffic.\", skippedBrokers);\n     }\n \n+    Set<BrokerEntity> detectMetricAnomalies = getMetricAnomalies(historicalLogFlushTimeMetricValues, currentLogFlushTimeMetricValues);\n+    detectMetricAnomalies.retainAll(getMetricAnomalies(historicalPerByteLogFlushTimeMetricValues, currentPerByteLogFlushTimeMetricValues));\n+    return detectMetricAnomalies;\n+  }\n+\n+  /**\n+   * Whether broker is currently serving negligible traffic or not.\n+   * @param broker The broker to check.\n+   * @param currentMetricsByBroker The subject broker's latest metrics.\n+   * @return True if broker's current traffic is negligible.\n+   */\n+  private boolean brokerHasNegligibleTraffic(BrokerEntity broker,\n+                                             Map<BrokerEntity, ValuesAndExtrapolations> currentMetricsByBroker) {\n+    AggregatedMetricValues aggregatedMetricValues = currentMetricsByBroker.get(broker).metricValues();\n+    double latestTotalBytesIn = aggregatedMetricValues.valuesFor(LEADER_BYTES_IN_ID).latest() +\n+                                aggregatedMetricValues.valuesFor(REPLICATION_BYTES_IN_RATE_ID).latest();\n+    return latestTotalBytesIn < _bytesInRateDetectionThreshold;\n+  }\n+\n+  private void collectLogFlushTimeMetric(BrokerEntity broker,\n+                                         Map<BrokerEntity, ValuesAndExtrapolations> metricsHistoryByBroker,\n+                                         Map<BrokerEntity, ValuesAndExtrapolations> currentMetricsByBroker,\n+                                         Map<BrokerEntity, List<Double>> historicalLogFlushTimeMetricValues,\n+                                         Map<BrokerEntity, Double> currentLogFlushTimeMetricValues) {\n+    AggregatedMetricValues aggregatedMetricValues = currentMetricsByBroker.get(broker).metricValues();\n+    double latestLogFlushTime = aggregatedMetricValues.valuesFor(BROKER_LOG_FLUSH_TIME_MS_999TH_ID).latest();\n+    currentLogFlushTimeMetricValues.put(broker, latestLogFlushTime);\n+    aggregatedMetricValues = metricsHistoryByBroker.get(broker).metricValues();\n+    double[] historicalLogFlushTime = aggregatedMetricValues.valuesFor(BROKER_LOG_FLUSH_TIME_MS_999TH_ID).doubleArray();\n+    List<Double> historicalValue = new ArrayList<>(historicalLogFlushTime.length);\n+    for (int i = 0; i < historicalLogFlushTime.length; i++) {\n+      if (historicalLogFlushTime[i] > 0) {", "originalCommit": "1f9f51cfa7b8bdcdabc3b5281f78c7283914dc0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1ac2c774dd779653a541e4acd04a3c3cdea73236", "url": "https://github.com/linkedin/cruise-control/commit/1ac2c774dd779653a541e4acd04a3c3cdea73236", "message": "Address the feedback.", "committedDate": "2020-03-17T22:24:54Z", "type": "commit"}]}