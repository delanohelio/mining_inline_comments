{"pr_number": 1591, "pr_title": "Add offset checkpoints for persistent stores", "pr_createdAt": "2020-08-20T06:14:52Z", "pr_url": "https://github.com/confluentinc/schema-registry/pull/1591", "timeline": [{"oid": "314779b6cc8bb154993fbd664c99fecbae715349", "url": "https://github.com/confluentinc/schema-registry/commit/314779b6cc8bb154993fbd664c99fecbae715349", "message": "Add offset checkpoints for persistent stores", "committedDate": "2020-08-20T06:13:04Z", "type": "commit"}, {"oid": "9b1bf019dc07f457044db559acd4d6100ce2973f", "url": "https://github.com/confluentinc/schema-registry/commit/9b1bf019dc07f457044db559acd4d6100ce2973f", "message": "Minor cleanup", "committedDate": "2020-08-20T06:15:47Z", "type": "commit"}, {"oid": "e53256c4d9fc191ded055ad2e109604d4e2dca5e", "url": "https://github.com/confluentinc/schema-registry/commit/e53256c4d9fc191ded055ad2e109604d4e2dca5e", "message": "Minor cleanup", "committedDate": "2020-08-20T06:48:43Z", "type": "commit"}, {"oid": "90f2d0bd20f7b733d05a32cddff8727fddfc4d9c", "url": "https://github.com/confluentinc/schema-registry/commit/90f2d0bd20f7b733d05a32cddff8727fddfc4d9c", "message": "Fix typo", "committedDate": "2020-08-22T03:03:38Z", "type": "commit"}, {"oid": "c94c762f81fd83d94fe050d9e0bf38eed0747361", "url": "https://github.com/confluentinc/schema-registry/commit/c94c762f81fd83d94fe050d9e0bf38eed0747361", "message": "Minor cleanup", "committedDate": "2020-08-22T03:26:51Z", "type": "commit"}, {"oid": "56b427456b73bca97817e46325ccaebfe1d18f69", "url": "https://github.com/confluentinc/schema-registry/commit/56b427456b73bca97817e46325ccaebfe1d18f69", "message": "Checkpoint offsets after handlers", "committedDate": "2020-08-22T05:22:09Z", "type": "commit"}, {"oid": "ec498c393dfcba2159ec86290b81b7a1e4363b97", "url": "https://github.com/confluentinc/schema-registry/commit/ec498c393dfcba2159ec86290b81b7a1e4363b97", "message": "Add flush", "committedDate": "2020-08-22T05:39:57Z", "type": "commit"}, {"oid": "3ec301d494509f8a763b06e3c8ff4139ecee5685", "url": "https://github.com/confluentinc/schema-registry/commit/3ec301d494509f8a763b06e3c8ff4139ecee5685", "message": "Minor cleanup", "committedDate": "2020-08-22T05:55:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0NzA5MA==", "url": "https://github.com/confluentinc/schema-registry/pull/1591#discussion_r477047090", "bodyText": "What if it exists but it's a file instead ?", "author": "dragosvictor", "createdAt": "2020-08-26T05:43:29Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/OffsetCheckpoint.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.kafka.schemaregistry.storage;\n+\n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.Closeable;\n+import java.io.EOFException;\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.channels.FileChannel;\n+import java.nio.channels.FileLock;\n+import java.nio.channels.OverlappingFileLockException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.utils.Utils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class saves out a map of topic/partition=&gt;offsets to a file.\n+ * The format of the file is UTF-8 text containing the following:\n+ * <pre>\n+ *   &lt;version&gt;\n+ *   &lt;n&gt;\n+ *   &lt;topic_name_1&gt; &lt;partition_1&gt; &lt;offset_1&gt;\n+ *   .\n+ *   .\n+ *   .\n+ *   &lt;topic_name_n&gt; &lt;partition_n&gt; &lt;offset_n&gt;\n+ * </pre>\n+ * The first line contains a number designating the format version (currently 0),\n+ * the get line contains a number giving the total number of offsets.\n+ * Each successive line gives a topic/partition/offset triple separated by spaces.\n+ */\n+public class OffsetCheckpoint implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(OffsetCheckpoint.class);\n+\n+  public static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+\n+  public static final String LOCK_FILE_NAME = \".lock\";\n+\n+  private static final Pattern WHITESPACE_MINIMUM_ONCE = Pattern.compile(\"\\\\s+\");\n+\n+  private final File file;\n+  private final Object lock;\n+  private FileChannel channel;\n+  private FileLock fileLock;\n+  private int version;\n+\n+  public OffsetCheckpoint(String checkpointDir, int version, String topic) throws IOException {\n+    File baseDir = baseDir(checkpointDir, topic);\n+    this.file = new File(baseDir, CHECKPOINT_FILE_NAME);\n+    lock = new Object();\n+\n+    final File lockFile = new File(baseDir, LOCK_FILE_NAME);\n+    final FileChannel channel =\n+        FileChannel.open(lockFile.toPath(), StandardOpenOption.CREATE, StandardOpenOption.WRITE);\n+    final FileLock fileLock = tryLock(channel);\n+    if (fileLock == null) {\n+      channel.close();\n+      throw new IOException(\"Could not obtain file lock\");\n+    }\n+    this.channel = channel;\n+    this.fileLock = fileLock;\n+    this.version = version;\n+  }\n+\n+  private File baseDir(final String checkpointDir, String topic) throws IOException {\n+    final File dir = new File(checkpointDir, topic);\n+    if (!dir.exists() && !dir.mkdirs()) {", "originalCommit": "3ec301d494509f8a763b06e3c8ff4139ecee5685", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQyNjA3Mg==", "url": "https://github.com/confluentinc/schema-registry/pull/1591#discussion_r477426072", "bodyText": "Thanks, I'll fix", "author": "rayokota", "createdAt": "2020-08-26T16:20:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0NzA5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0OTgzOQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1591#discussion_r477049839", "bodyText": "Does fileOutputStream need to be closed as well ?", "author": "dragosvictor", "createdAt": "2020-08-26T05:52:03Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/OffsetCheckpoint.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.kafka.schemaregistry.storage;\n+\n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.Closeable;\n+import java.io.EOFException;\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.channels.FileChannel;\n+import java.nio.channels.FileLock;\n+import java.nio.channels.OverlappingFileLockException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.StandardOpenOption;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.utils.Utils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class saves out a map of topic/partition=&gt;offsets to a file.\n+ * The format of the file is UTF-8 text containing the following:\n+ * <pre>\n+ *   &lt;version&gt;\n+ *   &lt;n&gt;\n+ *   &lt;topic_name_1&gt; &lt;partition_1&gt; &lt;offset_1&gt;\n+ *   .\n+ *   .\n+ *   .\n+ *   &lt;topic_name_n&gt; &lt;partition_n&gt; &lt;offset_n&gt;\n+ * </pre>\n+ * The first line contains a number designating the format version (currently 0),\n+ * the get line contains a number giving the total number of offsets.\n+ * Each successive line gives a topic/partition/offset triple separated by spaces.\n+ */\n+public class OffsetCheckpoint implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(OffsetCheckpoint.class);\n+\n+  public static final String CHECKPOINT_FILE_NAME = \".checkpoint\";\n+\n+  public static final String LOCK_FILE_NAME = \".lock\";\n+\n+  private static final Pattern WHITESPACE_MINIMUM_ONCE = Pattern.compile(\"\\\\s+\");\n+\n+  private final File file;\n+  private final Object lock;\n+  private FileChannel channel;\n+  private FileLock fileLock;\n+  private int version;\n+\n+  public OffsetCheckpoint(String checkpointDir, int version, String topic) throws IOException {\n+    File baseDir = baseDir(checkpointDir, topic);\n+    this.file = new File(baseDir, CHECKPOINT_FILE_NAME);\n+    lock = new Object();\n+\n+    final File lockFile = new File(baseDir, LOCK_FILE_NAME);\n+    final FileChannel channel =\n+        FileChannel.open(lockFile.toPath(), StandardOpenOption.CREATE, StandardOpenOption.WRITE);\n+    final FileLock fileLock = tryLock(channel);\n+    if (fileLock == null) {\n+      channel.close();\n+      throw new IOException(\"Could not obtain file lock\");\n+    }\n+    this.channel = channel;\n+    this.fileLock = fileLock;\n+    this.version = version;\n+  }\n+\n+  private File baseDir(final String checkpointDir, String topic) throws IOException {\n+    final File dir = new File(checkpointDir, topic);\n+    if (!dir.exists() && !dir.mkdirs()) {\n+      throw new IOException(\n+          String.format(\n+              \"checkpoint directory [%s] doesn't exist and couldn't be created\", dir.getPath()));\n+    }\n+    return dir;\n+  }\n+\n+  private FileLock tryLock(final FileChannel channel) throws IOException {\n+    try {\n+      return channel.tryLock();\n+    } catch (final OverlappingFileLockException e) {\n+      return null;\n+    }\n+  }\n+\n+  /**\n+   * Write the given offsets to the checkpoint file. All offsets should be non-negative.\n+   *\n+   * @throws IOException if any file operation fails with an IO exception\n+   */\n+  public void write(final Map<TopicPartition, Long> offsets) throws IOException {\n+    // if the version is negative, skip\n+    if (version < 0) {\n+      return;\n+    }\n+    // if there is no offsets, skip writing the file to save disk IOs\n+    if (offsets.isEmpty()) {\n+      return;\n+    }\n+\n+    synchronized (lock) {\n+      // write to temp file and then swap with the existing file\n+      final File temp = new File(file.getAbsolutePath() + \".tmp\");\n+      LOG.trace(\"Writing tmp checkpoint file {}\", temp.getAbsolutePath());\n+\n+      final FileOutputStream fileOutputStream = new FileOutputStream(temp);\n+      try (final BufferedWriter writer = new BufferedWriter(\n+          new OutputStreamWriter(fileOutputStream, StandardCharsets.UTF_8))) {\n+        writeIntLine(writer, version);\n+        writeIntLine(writer, offsets.size());\n+\n+        for (final Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\n+          final TopicPartition tp = entry.getKey();\n+          final Long offset = entry.getValue();\n+          if (offset >= 0L) {\n+            writeEntry(writer, tp, offset);\n+          } else {\n+            LOG.warn(\"Received offset={} to write to checkpoint file for {}\", offset, tp);\n+          }\n+        }\n+\n+        writer.flush();\n+        fileOutputStream.getFD().sync();", "originalCommit": "3ec301d494509f8a763b06e3c8ff4139ecee5685", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQyNjUwOA==", "url": "https://github.com/confluentinc/schema-registry/pull/1591#discussion_r477426508", "bodyText": "No, it will be closed by the wrapping BufferedWriter", "author": "rayokota", "createdAt": "2020-08-26T16:20:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzA0OTgzOQ=="}], "type": "inlineReview"}, {"oid": "45d942c622fbf02d7faff698dbebfd38cd03873c", "url": "https://github.com/confluentinc/schema-registry/commit/45d942c622fbf02d7faff698dbebfd38cd03873c", "message": "Ensure checkpoint dir is not file", "committedDate": "2020-08-26T16:21:32Z", "type": "commit"}]}