{"pr_number": 8532, "pr_title": "ISPN-11723 Cluster Backup/Restore tool", "pr_createdAt": "2020-07-07T15:53:26Z", "pr_url": "https://github.com/infinispan/infinispan/pull/8532", "timeline": [{"oid": "b2e1e963cf535ecf1e3bcb990b342e53a1738756", "url": "https://github.com/infinispan/infinispan/commit/b2e1e963cf535ecf1e3bcb990b342e53a1738756", "message": "ISPN-11723 Cluster Backup/Restore tool\n\n- BackupManager interface exposed via ServerManagement\n- /v2/cluster/backup exposes cointainer backup\n- /v2/cluster/restore exposes cointainer restore\n- BackupManagerImplTest added\n- ClusterBackupIT added", "committedDate": "2020-07-08T16:52:08Z", "type": "forcePushed"}, {"oid": "fead33ed2934588be06b2246c559531ff5d35df6", "url": "https://github.com/infinispan/infinispan/commit/fead33ed2934588be06b2246c559531ff5d35df6", "message": "ISPN-11723 Cluster Backup/Restore tool\n\n- BackupManager interface exposed via ServerManagement\n- /v2/cluster/backup exposes cointainer backup\n- /v2/cluster/restore exposes cointainer restore\n- BackupManagerImplTest added\n- ClusterBackupIT added", "committedDate": "2020-07-09T09:09:12Z", "type": "forcePushed"}, {"oid": "01d48dd061fe91831a2ba93352be630f1e3a8916", "url": "https://github.com/infinispan/infinispan/commit/01d48dd061fe91831a2ba93352be630f1e3a8916", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T11:30:28Z", "type": "forcePushed"}, {"oid": "548a6c9d81e4ec1feca3dd2270e0dc148c779555", "url": "https://github.com/infinispan/infinispan/commit/548a6c9d81e4ec1feca3dd2270e0dc148c779555", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T12:54:31Z", "type": "forcePushed"}, {"oid": "eb18a78b0989bec9090e874f3867e3ceca7a1487", "url": "https://github.com/infinispan/infinispan/commit/eb18a78b0989bec9090e874f3867e3ceca7a1487", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T12:58:18Z", "type": "forcePushed"}, {"oid": "870674768f73027512fec040a2cc52ec6d70ee6e", "url": "https://github.com/infinispan/infinispan/commit/870674768f73027512fec040a2cc52ec6d70ee6e", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-10T14:26:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r452922681", "bodyText": "@param backup the bytes of the uploaded backup file. <= what is this exactly? is the full data in a single byte{]?", "author": "pruivo", "createdAt": "2020-07-10T15:41:36Z", "path": "server/core/src/main/java/org/infinispan/server/core/BackupManager.java", "diffHunk": "@@ -0,0 +1,31 @@\n+package org.infinispan.server.core;\n+\n+import java.nio.file.Path;\n+import java.util.concurrent.CompletionStage;\n+\n+import org.infinispan.factories.scopes.Scope;\n+import org.infinispan.factories.scopes.Scopes;\n+\n+/**\n+ * Handles all tasks related to the creation/restoration of server backups.\n+ *\n+ * @author Ryan Emerson\n+ * @since 11.0\n+ */\n+@Scope(Scopes.GLOBAL)\n+public interface BackupManager {\n+   /**\n+    * Create a backup of all containers configured on the server.\n+    *\n+    * @return a {@link CompletionStage} that on completion returns the {@link Path} to the created backup file.\n+    */\n+   CompletionStage<Path> create();\n+\n+   /**\n+    * Restore container content from the provided backup bytes.\n+    *\n+    * @param backup the bytes of the uploaded backup file.\n+    * @return a {@link CompletionStage} that completes when all of the entries in the backup have been restored.\n+    */\n+   CompletionStage<Void> restore(byte[] backup);", "originalCommit": "870674768f73027512fec040a2cc52ec6d70ee6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI0Mzg0OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457243848", "bodyText": "This should really be an InputStream or a ReadableByteChannel", "author": "tristantarrant", "createdAt": "2020-07-20T10:03:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzI0OTcwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457249707", "bodyText": "Sorry I forgot to get back to your original comment Pedro.\nAgreed it shouldn't be byte[], I will update this in the interface. We do have a bigger issue at the moment though, which is AFAIK we can only receive the bytes from a RestRequest via ContentSource#rawContent() which returns a byte[]. As backups will most likely be large, we should support Streams for uploads/downloads with HTTP2, maybe with a fallback of chunked transfer encoding for HTTP/1.1\n\\cc @gustavonalle", "author": "ryanemerson", "createdAt": "2020-07-20T10:12:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA3ODk3OQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458078979", "bodyText": "Do we really need to send a giant amount of data to the server?  Can't you just accept a Path to a file somewhere?\nIf we really need it, it's a great opportunity to expand the REST framework to support a stream of data, using chunked transfer, as it'd be supported both for HTTP/1 and HTTP/2", "author": "gustavonalle", "createdAt": "2020-07-21T13:04:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExNjg1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458116851", "bodyText": "Do we really need to send a giant amount of data to the server? Can't you just accept a Path to a file somewhere?\n\nHow do you get the file from the various clients to the server if you don't upload it? The idea is that this will work in Openshift and can be triggered via the Cli and eventually the console.\nWe could also add the option of the server importing the contents of a local backup file on server startup. In which case the server can pass a InputStream of the local file to the restore method.", "author": "ryanemerson", "createdAt": "2020-07-21T13:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODExOTcxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458119713", "bodyText": "If we really need it, it's a great opportunity to expand the REST framework to support a stream of data, using chunked transfer, as it'd be supported both for HTTP/1 and HTTP/2\n\nMy understanding is that chunked transfer was removed in HTTP/2 https://en.wikipedia.org/wiki/Chunked_transfer_encoding.", "author": "ryanemerson", "createdAt": "2020-07-21T14:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyMzg4Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458123887", "bodyText": "Our REST server is using HTTP/1 tunnelled in HTTP/2 frames, so it should work.", "author": "gustavonalle", "createdAt": "2020-07-21T14:06:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODEyNTE4Mw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458125183", "bodyText": "How do you get the file from the various clients to the server if you don't upload it?\n\nI was just wondering 1 TB backups being sent through HTTP from the client to the server and got a bit worried :)", "author": "gustavonalle", "createdAt": "2020-07-21T14:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE0MjgwNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458142806", "bodyText": "One question: the other way around, i.e., producing the backup, does it first create it on disk and then send it to the client? If so, maybe chunking is not the best but https://en.wikipedia.org/wiki/Byte_serving", "author": "gustavonalle", "createdAt": "2020-07-21T14:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2NTY3OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458165678", "bodyText": "does it first create it on disk and then send it to the client\n\nYep. Currently this is a very simple implementation where it's stored as staging.zip, however if we take advantange of byte serving and assign an Id per backup request, we could allow for failed downloads to be resumed. Although we would probably need some form of garbage collection for backups whom's downloads never complete.", "author": "ryanemerson", "createdAt": "2020-07-21T15:00:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODE2OTkyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458169920", "bodyText": "ok, we can always revisit it later and change from chunked -> bytes", "author": "gustavonalle", "createdAt": "2020-07-21T15:05:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODczOTc2NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458739764", "bodyText": "I've created https://issues.redhat.com/browse/ISPN-12145 to track the implementation of chunked transfer encoding.", "author": "ryanemerson", "createdAt": "2020-07-22T12:00:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjkyMjY4MQ=="}], "type": "inlineReview"}, {"oid": "cba11f350f146453d2822f03c1baa48707a53912", "url": "https://github.com/infinispan/infinispan/commit/cba11f350f146453d2822f03c1baa48707a53912", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-16T16:35:30Z", "type": "forcePushed"}, {"oid": "82bd52a4ad5d4704767bed064483b437bf8f9391", "url": "https://github.com/infinispan/infinispan/commit/82bd52a4ad5d4704767bed064483b437bf8f9391", "message": "ISPN-12095 CLI: Add support for cluster backup/restore", "committedDate": "2020-07-20T12:39:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzU5MjIyMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457592223", "bodyText": "We should probably add at least minor documentation to these.", "author": "wburns", "createdAt": "2020-07-20T17:58:33Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,8 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   CompletionStage<RestResponse> backup();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNTExMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457605113", "bodyText": "This isn't quite true. We should invoke Runnable in a blocking thread if the stage is completed on a non blocking thread. Looking closer whenCompleteBlocking has the same problem, maybe we should log a JIRA to take care of that though. We really need to add a blocking executor that checks the invoking thread if it is blocking or not before submitting.", "author": "wburns", "createdAt": "2020-07-20T18:21:53Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java", "diffHunk": "@@ -106,6 +106,21 @@\n    <I, O> CompletionStage<O> handleBlocking(CompletionStage<? extends I> stage,\n          BiFunction<? super I, Throwable, ? extends O> function, Object traceId);\n \n+   /**\n+    * Replacement for {@link CompletionStage#thenRunAsync(Runnable)} that invokes the {@code Runnable} in a blocking thread\n+    * (if the current thread is non-blocking) or in the current thread (if the current thread is blocking).", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk0NTM1NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457945355", "bodyText": "I definitely think this is a fix for a different PR. In this case I just used thenApplyBlocking as a basis of this implementation, so I assume that also has the same issue.", "author": "ryanemerson", "createdAt": "2020-07-21T08:59:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNTExMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzYwNzQwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457607407", "bodyText": "You can change all of this to just return stage.thenRun(runnable);", "author": "wburns", "createdAt": "2020-07-20T18:26:06Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java", "diffHunk": "@@ -187,6 +187,23 @@ protected void start() {\n       return continueOnNonBlockingThread(stage.thenApplyAsync(function, blockingExecutor), traceId);\n    }\n \n+   @Override\n+   public <I> CompletionStage<Void> thenRun(CompletionStage<? extends I> stage, Runnable runnable, Object traceId) {\n+      if (isCurrentThreadBlocking()) {\n+         if (trace) {\n+            log.tracef(\"Invoked thenRun on a blocking thread, joining %s in same blocking thread\", traceId);\n+         }\n+         try {\n+            CompletionStages.join(stage);", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY0NDQ2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457644467", "bodyText": "No need for this variable.", "author": "wburns", "createdAt": "2020-07-20T19:34:26Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n+   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n+\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final BackupWriter writer;\n+   final BlockingManager blockingManager;", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1MjIzMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457652233", "bodyText": "I have never been a fan of doing stuff like this in a constructor. Maybe add a makeDirectories method to BackupManager?", "author": "wburns", "createdAt": "2020-07-20T19:49:03Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupManagerImpl.java", "diffHunk": "@@ -0,0 +1,117 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.WORKING_DIR;\n+\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.stream.Collectors;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletableFutures;\n+import org.infinispan.util.logging.LogFactory;\n+\n+/**\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class BackupManagerImpl implements BackupManager {\n+\n+   private static final Log log = LogFactory.getLog(BackupManagerImpl.class, Log.class);\n+\n+   private final AtomicBoolean backupInProgress = new AtomicBoolean();\n+   private final AtomicBoolean restoreInProgress = new AtomicBoolean();\n+\n+   final Path rootDir;\n+   final BackupReader reader;\n+   final BackupWriter writer;\n+   final BlockingManager blockingManager;\n+   final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   public BackupManagerImpl(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers,\n+                            Path dataRoot) {\n+      this.blockingManager = blockingManager;\n+      this.rootDir = dataRoot.resolve(WORKING_DIR);\n+      this.cacheManagers = cacheManagers;\n+      this.reader = new BackupReader(blockingManager, cacheManagers, rootDir);\n+      this.writer = new BackupWriter(blockingManager, cacheManagers, rootDir);\n+      rootDir.toFile().mkdir();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk2ODAyNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457968026", "bodyText": "Good catch. As the rootDir is provided via Server.java I have moved the creation there.\nI've add a BackupManager#init method that can be used for all resource initialisation.", "author": "ryanemerson", "createdAt": "2020-07-21T09:38:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1MjIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Njk2MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457656960", "bodyText": "Is there a reason this isn't in the same code block as below? Unfortunately this will hand off the processing to a non blocking thread which will then just hand back off to a different blocking thread. If instead it is just one lambda it won't do this handoff.", "author": "wburns", "createdAt": "2020-07-20T19:58:11Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java", "diffHunk": "@@ -0,0 +1,140 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.STAGING_ZIP;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final Path rootDir;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+   }\n+\n+   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n+      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n+\n+      CompletionStage<Void> createStagingFile = blockingManager.runBlocking(() -> {", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1MDAxOA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457950018", "bodyText": "I was trying to make it more fine-grained, but after your explanation I can see that doesn't really make sense as the operations obviously depend on each other \ud83d\ude42", "author": "ryanemerson", "createdAt": "2020-07-21T09:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Njk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Nzg5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457657891", "bodyText": "Same here, this should be able to just be one big blockingManager.thenSupply call which returns a CompletionStage and then use thenCompose to flatten it.", "author": "wburns", "createdAt": "2020-07-20T19:59:52Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupReader.java", "diffHunk": "@@ -0,0 +1,140 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.STAGING_ZIP;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.logging.LogFactory;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.server.core.logging.Log;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for reading backup bytes and restoring the contents to the appropriate cache manager.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupReader {\n+\n+   private static final Log log = LogFactory.getLog(BackupReader.class, Log.class);\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+   private final Path rootDir;\n+\n+   public BackupReader(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+   }\n+\n+   CompletionStage<Void> restore(InputStream is, Map<String, BackupManager.ContainerResources> params) {\n+      final Path stagingFile = rootDir.resolve(STAGING_ZIP);\n+\n+      CompletionStage<Void> createStagingFile = blockingManager.runBlocking(() -> {\n+         try {\n+            Files.copy(is, stagingFile);\n+         } catch (IOException e) {\n+            throw new CacheException(e);\n+         }\n+      }, \"create-staging\");\n+\n+      CompletionStage<?> processContainers = blockingManager.thenApplyBlocking(createStagingFile, Void -> {\n+         try (ZipFile zip = new ZipFile(stagingFile.toFile())) {\n+            Properties manifest = readManifestAndValidate(zip);\n+\n+            List<String> backupContainers = Arrays.asList(manifest.getProperty(CONTAINER_KEY).split(\",\"));\n+            Set<String> requestedContainers = new HashSet<>(params.keySet());\n+            requestedContainers.removeAll(backupContainers);\n+            if (!requestedContainers.isEmpty()) {\n+               throw log.unableToFindBackupResource(\"Containers\", requestedContainers);\n+            }\n+\n+            return CompletionStages.allOf(\n+                  params.entrySet().stream()\n+                        .map(e -> restoreContainer(e.getKey(), e.getValue(), zip))\n+                        .collect(Collectors.toList())\n+            );\n+         } catch (IOException e) {\n+            throw new CacheException(String.format(\"Unable to read zip file '%s'\", stagingFile));\n+         }\n+      }, \"read-manifest\");\n+\n+      return blockingManager.thenRun(processContainers, () -> {", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1NDk0MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457954940", "bodyText": "I have updated it to return processContainers.thenRun(() -> {...}); as we only require CompletionStage<Void>.", "author": "ryanemerson", "createdAt": "2020-07-21T09:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY1Nzg5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457670055", "bodyText": "Just use an AggregateCompletionStage instead of creating this list.", "author": "wburns", "createdAt": "2020-07-20T20:23:53Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java", "diffHunk": "@@ -0,0 +1,177 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   private final Path rootDir;\n+   private final ParserRegistry parserRegistry;\n+\n+   BackupWriter(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+      this.parserRegistry = new ParserRegistry();\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n+      List<CompletionStage<?>> stages = new ArrayList<>(params.size() + 1);", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk1NjUzNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457956535", "bodyText": "I completely forgot that existed \ud83d\ude42", "author": "ryanemerson", "createdAt": "2020-07-21T09:18:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk2MjYxOQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457962619", "bodyText": "I have updated all instances that were previously using CompletionStages#allOf(Collection) and removed that static method.", "author": "ryanemerson", "createdAt": "2020-07-21T09:28:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3MDA1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY3NDI5Ng==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457674296", "bodyText": "So should this method throw an exception when it isn't valid? I would expect the exception to be defined as being able to be thrown in the interface then.", "author": "wburns", "createdAt": "2020-07-20T20:32:10Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/ContainerResource.java", "diffHunk": "@@ -0,0 +1,64 @@\n+package org.infinispan.server.core.backup;\n+\n+import java.util.Properties;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.server.core.BackupManager;\n+\n+/**\n+ * An interface that defines how a {@link org.infinispan.server.core.BackupManager.ResourceType} is backed up and\n+ * restored by the {@link org.infinispan.server.core.BackupManager}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public interface ContainerResource {\n+\n+   /**\n+    * A method to ensure that the resources requested in the {@link BackupManager.ContainerResources}\n+    * are valid and can be included in a backup. This method is called for all {@link ContainerResource} implementations\n+    * before the backup process begins in order to allow a backup to fail-fast before any data is processed.\n+    */\n+   void prepareAndValidateBackup();", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzY4NzA3OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r457687078", "bodyText": "We should be able to use an AggregateCompletionStage here as well.", "author": "wburns", "createdAt": "2020-07-20T20:57:03Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/BackupWriter.java", "diffHunk": "@@ -0,0 +1,177 @@\n+package org.infinispan.server.core.backup;\n+\n+import static org.infinispan.server.core.backup.Constants.CONTAINERS_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.CONTAINER_KEY;\n+import static org.infinispan.server.core.backup.Constants.GLOBAL_CONFIG_FILE;\n+import static org.infinispan.server.core.backup.Constants.MANIFEST_PROPERTIES_FILE;\n+import static org.infinispan.server.core.backup.Constants.VERSION_KEY;\n+\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.file.FileVisitResult;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.SimpleFileVisitor;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.time.LocalDateTime;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipOutputStream;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.util.Version;\n+import org.infinispan.configuration.global.GlobalConfiguration;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.server.core.backup.resources.ContainerResourceFactory;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+/**\n+ * Responsible for creating backup files that can be used to restore a container/cache on a new cluster.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+class BackupWriter {\n+\n+   private final BlockingManager blockingManager;\n+   private final Map<String, DefaultCacheManager> cacheManagers;\n+\n+   private final Path rootDir;\n+   private final ParserRegistry parserRegistry;\n+\n+   BackupWriter(BlockingManager blockingManager, Map<String, DefaultCacheManager> cacheManagers, Path rootDir) {\n+      this.blockingManager = blockingManager;\n+      this.cacheManagers = cacheManagers;\n+      this.rootDir = rootDir;\n+      this.parserRegistry = new ParserRegistry();\n+   }\n+\n+   CompletionStage<Path> create(Map<String, BackupManager.ContainerResources> params) {\n+      List<CompletionStage<?>> stages = new ArrayList<>(params.size() + 1);\n+      for (Map.Entry<String, BackupManager.ContainerResources> e : params.entrySet()) {\n+         String container = e.getKey();\n+         EmbeddedCacheManager cm = cacheManagers.get(container);\n+         stages.add(createBackup(container, cm, e.getValue()));\n+      }\n+\n+      stages.add(writeManifest(cacheManagers.keySet()));\n+      return blockingManager.thenApplyBlocking(CompletionStages.allOf(stages), Void -> createZip(), \"create\");\n+   }\n+\n+   /**\n+    * Create a backup of the specified container.\n+    *\n+    * @param containerName the name of container to backup.\n+    * @param cm            the container to backup.\n+    * @param params        the {@link BackupManager.ContainerResources} object that determines what resources are included in\n+    *                      the backup for this container.\n+    * @return a {@link CompletionStage} that completes once the backup has finished.\n+    */\n+   private CompletionStage<Void> createBackup(String containerName, EmbeddedCacheManager cm, BackupManager.ContainerResources params) {\n+      Path containerRoot = rootDir.resolve(CONTAINER_KEY).resolve(containerName);\n+      containerRoot.toFile().mkdirs();\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      BlockingManager blockingManager = gcr.getComponent(BlockingManager.class);\n+\n+      Collection<ContainerResource> resources = ContainerResourceFactory.getInstance()\n+            .getResources(params, blockingManager, cm, containerRoot);\n+\n+      // Prepare and ensure all requested resources are valid before starting the backup process\n+      resources.forEach(ContainerResource::prepareAndValidateBackup);\n+\n+      List<CompletionStage<?>> stages = resources.stream()", "originalCommit": "350a0de8d92deed38601adbc2d869144da87502d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4MzU1MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458083550", "bodyText": "Jackson databind is being killed, please avoid using it and use the internal mJson instead", "author": "gustavonalle", "createdAt": "2020-07-21T13:11:11Z", "path": "server/tests/src/test/java/org/infinispan/server/functional/ClusterBackupIT.java", "diffHunk": "@@ -0,0 +1,186 @@\n+package org.infinispan.server.functional;\n+\n+import static org.infinispan.functional.FunctionalTestUtils.await;\n+import static org.infinispan.util.concurrent.CompletionStages.join;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.io.File;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.StandardCopyOption;\n+import java.util.Arrays;\n+\n+import org.infinispan.client.rest.RestCacheClient;\n+import org.infinispan.client.rest.RestClient;\n+import org.infinispan.client.rest.RestCounterClient;\n+import org.infinispan.client.rest.RestEntity;\n+import org.infinispan.client.rest.RestResponse;\n+import org.infinispan.client.rest.RestTaskClient;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.test.CommonsTestingUtil;\n+import org.infinispan.commons.util.Util;\n+import org.infinispan.configuration.cache.ConfigurationBuilder;\n+import org.infinispan.counter.api.Storage;\n+import org.infinispan.counter.configuration.Element;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;", "originalCommit": "82bd52a4ad5d4704767bed064483b437bf8f9391", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA4NTA3MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r458085070", "bodyText": "Please add documentation in the REST API for those two methods", "author": "gustavonalle", "createdAt": "2020-07-21T13:13:29Z", "path": "server/rest/src/main/java/org/infinispan/rest/resources/ClusterResource.java", "diffHunk": "@@ -1,33 +1,52 @@\n package org.infinispan.rest.resources;\n \n+import static io.netty.handler.codec.http.HttpResponseStatus.INTERNAL_SERVER_ERROR;\n import static io.netty.handler.codec.http.HttpResponseStatus.NO_CONTENT;\n+import static io.netty.handler.codec.http.HttpResponseStatus.UNSUPPORTED_MEDIA_TYPE;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+import static org.infinispan.rest.framework.Method.GET;\n import static org.infinispan.rest.framework.Method.POST;\n \n+import java.io.ByteArrayInputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n import java.util.List;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n \n+import org.infinispan.commons.dataconversion.MediaType;\n import org.infinispan.rest.InvocationHelper;\n import org.infinispan.rest.NettyRestResponse;\n import org.infinispan.rest.framework.ResourceHandler;\n import org.infinispan.rest.framework.RestRequest;\n import org.infinispan.rest.framework.RestResponse;\n import org.infinispan.rest.framework.impl.Invocations;\n+import org.infinispan.rest.logging.Log;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.logging.LogFactory;\n \n /**\n  * @since 10.0\n  */\n public class ClusterResource implements ResourceHandler {\n+\n+   private final static Log LOG = LogFactory.getLog(ClusterResource.class, Log.class);\n+\n    private final InvocationHelper invocationHelper;\n+   private final BackupManager backupManager;\n \n    public ClusterResource(InvocationHelper invocationHelper) {\n       this.invocationHelper = invocationHelper;\n+      this.backupManager = invocationHelper.getServer().getBackupManager();\n    }\n \n    @Override\n    public Invocations getInvocations() {\n       return new Invocations.Builder()\n             .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"stop\").handleWith(this::stop)\n+            .invocation().methods(GET).path(\"/v2/cluster\").withAction(\"backup\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cluster\").withAction(\"restore\").handleWith(this::restore)", "originalCommit": "82bd52a4ad5d4704767bed064483b437bf8f9391", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8c8a308c8256384661fae7f02f8091259132d0e5", "url": "https://github.com/infinispan/infinispan/commit/8c8a308c8256384661fae7f02f8091259132d0e5", "message": "Address wburns comments", "committedDate": "2020-07-21T13:49:34Z", "type": "forcePushed"}, {"oid": "dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "url": "https://github.com/infinispan/infinispan/commit/dfc9e3acfa4c0fe8da6a3caec9f73679d0c69718", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-22T16:48:18Z", "type": "forcePushed"}, {"oid": "c6b1e7bfba81442df11dcd327c276e245ac98e21", "url": "https://github.com/infinispan/infinispan/commit/c6b1e7bfba81442df11dcd327c276e245ac98e21", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-22T17:05:18Z", "type": "forcePushed"}, {"oid": "cd56ef01031bc2d4b948b04110698f2eb4d80595", "url": "https://github.com/infinispan/infinispan/commit/cd56ef01031bc2d4b948b04110698f2eb4d80595", "message": "ISPN-11723 REST API docs", "committedDate": "2020-07-23T10:09:38Z", "type": "forcePushed"}, {"oid": "efedcd6e4718f909ec002c586f289f19d8703c3c", "url": "https://github.com/infinispan/infinispan/commit/efedcd6e4718f909ec002c586f289f19d8703c3c", "message": "Updated to allow for new RESTful api that splits resource creation and\nretrieval", "committedDate": "2020-07-30T10:08:24Z", "type": "forcePushed"}, {"oid": "76138ebd042977a2d0f72f2d73e7a611212ae9d8", "url": "https://github.com/infinispan/infinispan/commit/76138ebd042977a2d0f72f2d73e7a611212ae9d8", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-04T10:21:19Z", "type": "forcePushed"}, {"oid": "dc8e76f5c9749882ec867ed84d90e7fa95b373fa", "url": "https://github.com/infinispan/infinispan/commit/dc8e76f5c9749882ec867ed84d90e7fa95b373fa", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-05T10:31:28Z", "type": "forcePushed"}, {"oid": "5a7bffb7ec8256f0abb5a1623fc802849983a640", "url": "https://github.com/infinispan/infinispan/commit/5a7bffb7ec8256f0abb5a1623fc802849983a640", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-05T10:39:48Z", "type": "forcePushed"}, {"oid": "273d51d75ac24b6893868ce0a373c07e368e1f24", "url": "https://github.com/infinispan/infinispan/commit/273d51d75ac24b6893868ce0a373c07e368e1f24", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-06T10:04:01Z", "type": "forcePushed"}, {"oid": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "url": "https://github.com/infinispan/infinispan/commit/c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-06T13:54:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzgyNzc5NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467827795", "bodyText": "The REST related changes LGTM!", "author": "gustavonalle", "createdAt": "2020-08-10T10:58:42Z", "path": "server/rest/src/main/java/org/infinispan/rest/resources/CacheManagerResource.java", "diffHunk": "@@ -108,6 +111,11 @@ public Invocations getInvocations() {\n \n             // Caches\n             .invocation().methods(GET).path(\"/v2/cache-managers/{name}/caches\").handleWith(this::getCaches)\n+\n+            // BackupManager\n+            .invocation().methods(GET).path(\"/v2/cache-managers/{name}/backups\").handleWith(this::getAllBackupNames)\n+            .invocation().methods(DELETE, GET, HEAD, POST).path(\"/v2/cache-managers/{name}/backups/{backupName}\").handleWith(this::backup)\n+            .invocation().methods(POST).path(\"/v2/cache-managers/{name}/backups\").withAction(\"restore\").handleWith(this::restore)", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDUxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467984513", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Retrieve a backup file with the given name from the server.\n          \n          \n            \n                * Retrieves a backup file with the given name from the server.", "author": "oraNod", "createdAt": "2020-08-10T15:27:43Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NDYyOA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467984628", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Delete a backup file from the server.\n          \n          \n            \n                * Deletes a backup file from the server.", "author": "oraNod", "createdAt": "2020-08-10T15:27:53Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Delete a backup file from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NTYzMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467985633", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Retrieve a backup file with the given name from the server.\n          \n          \n            \n                * Retrieves a backup file with the given name from the server.", "author": "oraNod", "createdAt": "2020-08-10T15:29:24Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Nzk4NTcwOQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r467985709", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                * Delete a backup file from the server.\n          \n          \n            \n                * Deletes a backup file from the server.", "author": "oraNod", "createdAt": "2020-08-10T15:29:32Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestClusterClient.java", "diffHunk": "@@ -17,4 +18,41 @@\n     * Shuts down the specified servers\n     */\n    CompletionStage<RestResponse> stop(List<String> server);\n+\n+   /**\n+    * Creates a backup file containing the content of all containers in the cluster.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name);\n+\n+   /**\n+    * Retrieve a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Delete a backup file from the server.", "originalCommit": "c3d4a897db3ee4133a93c1032fefa531fb3fc27f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2f57736b5792ba572c18792f105772d7eeea0b78", "url": "https://github.com/infinispan/infinispan/commit/2f57736b5792ba572c18792f105772d7eeea0b78", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-11T08:55:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1MzgwNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469453807", "bodyText": "We don't specify what null does here. I am guessing it means everything? I only ask one of the default methods passes it.", "author": "wburns", "createdAt": "2020-08-12T18:21:22Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1Mzg5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469453891", "bodyText": "Same about null here.", "author": "wburns", "createdAt": "2020-08-12T18:21:31Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/RestCacheManagerClient.java", "diffHunk": "@@ -46,4 +49,74 @@\n    CompletionStage<RestResponse> cancelPushState(String backup);\n \n    CompletionStage<RestResponse> caches();\n+\n+   /**\n+    * Creates a backup file containing all resources in this container.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name) {\n+      return createBackup(name, null);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                  list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   default CompletionStage<RestResponse> createBackup(String name, Map<String, List<String>> resources) {\n+      return createBackup(name, null, resources);\n+   }\n+\n+   /**\n+    * Creates a backup file containing only the resources specified in the provided {@link Map}.\n+    *\n+    * @param workingDir the path of the server directory to be used to create the backup content and store the final\n+    *                   backup file. A null value indicates that the server default should be used.\n+    * @param resources  a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided\n+    *                   list only contains \"*\" then all available resources of that type are backed up.\n+    */\n+   CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources);\n+\n+   /**\n+    * Retrieves a backup file with the given name from the server.\n+    *\n+    * @param name     the name of the backup.\n+    * @param skipBody if true, then a HEAD request is issued to the server and only the HTTP headers are returned.\n+    */\n+   CompletionStage<RestResponse> getBackup(String name, boolean skipBody);\n+\n+   /**\n+    * Deletes a backup file from the server.\n+    *\n+    * @param name the name of the backup.\n+    */\n+   CompletionStage<RestResponse> deleteBackup(String name);\n+\n+   /**\n+    * Restores all content associated with this containers name contained within the provided backup file. The backup\n+    * file is uploaded via the server endpoint for processing, returning once the restoration has completed.\n+    *\n+    * @param backup the backup {@link File} containing the data to be restored.\n+    */\n+   default CompletionStage<RestResponse> restore(File backup) {\n+      return restore(backup, null);\n+   }\n+\n+   /**\n+    * Restores the specified content from the backup file that's associated with this container's name.\n+    *\n+    * @param backup    the backup {@link File} containing the data to be restored.\n+    * @param resources a map of BackupManager.Resources.Type with the names of the resources to backup. If the provided", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NTIxNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469455214", "bodyText": "Do we need to escape any json characters here? Could the String contain valid json delimiters?\nGuessing the Json object does that for us.\nAlso does Json.factory().make(resources) not do what we want?", "author": "wburns", "createdAt": "2020-08-12T18:23:59Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java", "diffHunk": "@@ -121,4 +128,75 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null) {\n+         Json resourcesJson = Json.object();\n+         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));\n+         json.set(\"resources\", resourcesJson);\n+      }\n+      RequestBody body = new StringRestEntityOkHttp(MediaType.APPLICATION_JSON, json.toString()).toRequestBody();\n+      Request.Builder builder = backup(name).post(body);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> getBackup(String name, boolean skipBody) {\n+      Request.Builder builder = backup(name);\n+      if (skipBody)\n+         builder.head();\n+\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> deleteBackup(String name) {\n+      return client.execute(backup(name).delete());\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(File backup, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (resources != null) {\n+         resources.forEach((k, v) -> json.set(k, v.toArray(new String[0])));\n+      }\n+      RequestBody zipBody = new FileRestEntityOkHttp(MediaType.APPLICATION_ZIP, backup).toRequestBody();\n+\n+      RequestBody multipartBody = new MultipartBody.Builder()\n+            .addFormDataPart(\"resources\", json.toString())\n+            .addFormDataPart(\"backup\", backup.getName(), zipBody)\n+            .setType(MultipartBody.FORM)\n+            .build();\n+\n+      Request.Builder builder = restore().post(multipartBody);\n+      return client.execute(builder);\n+   }\n+\n+   @Override\n+   public CompletionStage<RestResponse> restore(String backupLocation, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      json.set(\"location\", backupLocation);\n+\n+      if (resources != null) {\n+         Json resourcesJson = Json.object();\n+         resources.forEach((k, v) -> resourcesJson.set(k, v.toArray(new String[0])));", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgwMTAwNg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469801006", "bodyText": "Do we need to escape any json characters here? Could the String contain valid json delimiters?\n\nI don't think so, there shouldn't be any JSON passed in the Map.\n\nAlso does Json.factory().make(resources) not do what we want?\n\nYes \ud83d\ude42. I didn't know about that before.", "author": "ryanemerson", "createdAt": "2020-08-13T08:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NTIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469457397", "bodyText": "Do we not want the info from the stores?", "author": "wburns", "createdAt": "2020-08-12T18:27:49Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTc4MzM5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469783391", "bodyText": "This is something that I have been in two minds about. Originally I was thinking that if data is already persisted, then the stores can also be migrated by the user, but this isn't very user-friendly especially if stores are not shared and we have a large cluster. Having a centralised backup greatly simplifies this, so including stores by default makes more sense on second thought.\nIn the case of a large shared store, probably JDBC based, it's probably not desired to have the store content in the backup. Once the core backup/restore pieces are in place (CLI, Operator etc) we can add a parameter to toggle this behaviour.", "author": "ryanemerson", "createdAt": "2020-08-13T08:27:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAyMzI2NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470023264", "bodyText": "Makes sense. This makes me wonder if we should have the default value be if the store it uses is shared or not.\nAlso I wonder if we should add support for the Flag SKIP_SHARED_CACHE_STORE in the ClusterPublisherManager", "author": "wburns", "createdAt": "2020-08-13T15:08:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzMDE1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470030151", "bodyText": "This makes me wonder if we should have the default value be if the store it uses is shared or not\n\nTbh I think this could be difficult to explain to the user in a transparent way. Having a consistent default and then documenting that it's possible to backup in-memory contents only is much simpler IMO. We can then add a note explaining that for larger shared stores it's probably desirable to enable this option.", "author": "ryanemerson", "createdAt": "2020-08-13T15:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNzQwMQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470037401", "bodyText": "Also I wonder if we should add support for the Flag SKIP_SHARED_CACHE_STORE in the ClusterPublisherManager\n\nMakes sense. It would be perfect for this use-case", "author": "ryanemerson", "createdAt": "2020-08-13T15:27:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1NzM5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1ODEzNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469458137", "bodyText": "This is redundant. You can just return the value returned from invoking entryPublisher.", "author": "wburns", "createdAt": "2020-08-12T18:29:07Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469459134", "bodyText": "I am thinking it would be better to use BlockingManager#supplyBlocking and thenCompose invoke thenCompose on it. This way we won't be blocking a blocking thread unless it is processing a response to write to disk.", "author": "wburns", "createdAt": "2020-08-12T18:30:51Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg0NTIwMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469845203", "bodyText": "I'm not sure what you mean here. I have updated createCacheBackup to use BlockingManager#blockingPublisherToVoidStage, does ^ suggestion still apply with my latest changes?", "author": "ryanemerson", "createdAt": "2020-08-13T10:10:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAyMzkyNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470023924", "bodyText": "I suggested this originally and didn't go back to change this one. So using the new method is preferred.", "author": "wburns", "createdAt": "2020-08-13T15:09:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ1OTEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469463176", "bodyText": "Can we not do this in subscribe instead?", "author": "wburns", "createdAt": "2020-08-12T18:38:00Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .buffer(BUFFER_SIZE)\n+                           .flatMap(Flowable::fromIterable)\n+                           .map(e -> {\n+                              CacheBackupEntry be = new CacheBackupEntry();\n+                              be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                              be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                              be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                              be.internalMetadata = e.getInternalMetadata();\n+                              be.created = e.getCreated();\n+                              be.lastUsed = e.getLastUsed();\n+                              return be;\n+                           })\n+                           .doOnNext(e -> writeMessageStream(e, serCtx, output))", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgwODcxMw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469808713", "bodyText": "I don't think so, because subscribe returns a Disposable but we need to return a Publisher so that it can be consumed as the Flowable.using sourceSupplier. This is similar to the JpaStore#createBatchFlowable code.", "author": "ryanemerson", "createdAt": "2020-08-13T09:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzOTk2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470039967", "bodyText": "\ud83d\udc4d Forgot it returns a Disposable :(", "author": "wburns", "createdAt": "2020-08-13T15:31:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzIyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469463220", "bodyText": "This buffer and flatMap looks extraneous. What was the reason for them?", "author": "wburns", "createdAt": "2020-08-12T18:38:04Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      return blockingManager.runBlocking(() -> {\n+         AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+         Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+         // Create the cache backup dir and parents\n+         Path cacheRoot = root.resolve(cacheName);\n+         mkdirs(cacheRoot);\n+\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+\n+         // Write in-memory cache contents to .dat file if the cache is not empty\n+         if (cache.isEmpty())\n+            return;\n+\n+         ComponentRegistry cr = cache.getComponentRegistry();\n+         ClusterPublisherManager<?, ?> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+         SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+         ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+         String dataFileName = dataFile(cacheName);\n+         Path datFile = cacheRoot.resolve(dataFileName);\n+\n+         Publisher<CacheEntry<?, ?>> p = s -> clusterPublisherManager.entryPublisher(null, null, null, false,\n+               DeliveryGuarantee.EXACTLY_ONCE, BUFFER_SIZE, PublisherTransformers.identity())\n+               .subscribe(s);\n+\n+         StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+         boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+         boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+         PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+         Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+         Flowable.using(\n+               () -> Files.newOutputStream(datFile),\n+               output ->\n+                     Flowable.fromPublisher(p)\n+                           .buffer(BUFFER_SIZE)", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTgxMTQyNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469811425", "bodyText": "I honestly can't remember. Removed.", "author": "ryanemerson", "createdAt": "2020-08-13T09:12:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2MzIyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469464074", "bodyText": "I noticed that we do an unbounded run of this. Should we limit how many blocking threads we are using? I worry about delaying actual operations on the server or even worse possibly getting some sort of livelock.", "author": "wburns", "createdAt": "2020-08-12T18:39:37Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?\n+   private static final int BUFFER_SIZE = 100;\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ3OTI1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469479251", "bodyText": "It makes me wonder if we should add some extra methods to BlockingManager#BlockingExecutor to handle these types of cases.", "author": "wburns", "createdAt": "2020-08-12T19:07:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg2MDAwMg==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469860002", "bodyText": "Agreed that we should limit the number of blocking threads are used by this, as even if there is a reasonably modest number of caches this could cause issues.\nI think BlockingManager.BlockingExecutor could provide all of the BlockingManager methods with the exception of limitedBlockingExecutor. That way we can do something like:\n     BlockingManager.BlockingExecutor executor = blockingManager.limitedBlockingExecutor(\"cache-backup-executor\", 5);\n     for (String cache : resources)\n         stages.dependsOn(createCacheBackup(cache, executor));\nTo reduce repetition in the BlockingManager interface, we can create another interface BlockingOperations and then do the following:\npublic interface BlockingManager extends BlockingOperations {\n\n    BlockingExecutor limitedBlockingExecutor(String name, int concurrency);\n\n    interface BlockingExecutor extends BlockingOperations {\n    }\n}\nBlockingManagerImpl would then just provide versions of the BlockingOperations methods that take a Scheduler|Executor as an additional parameter.", "author": "ryanemerson", "createdAt": "2020-08-13T10:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTg2Mjg2Nw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469862867", "bodyText": "Similarly we could avoid BlockingOperations by adding a method that returns a BackupManager implementation that utilies a LimitedExecutor:\nBlockingManager limitedBlockingManager(int concurrency);", "author": "ryanemerson", "createdAt": "2020-08-13T10:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA3NzAxNw==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470077017", "bodyText": "I look forward to seeing this change in another PR \ud83d\udc4d", "author": "wburns", "createdAt": "2020-08-13T16:29:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA3ODYxMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470078610", "bodyText": "I have created ISPN-12226 to track the BlockingManager enhancements and ISPN-12227 for the changes to the BackupManager.", "author": "ryanemerson", "createdAt": "2020-08-13T16:32:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDA3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ2NDU3MA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469464570", "bodyText": "Can we not just use state transfer chunk size? This is what the publisher will use whenever we make an actual user facing API for it ;)", "author": "wburns", "createdAt": "2020-08-12T18:40:29Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,282 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   // TODO what size?", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQ3MzIyMA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r469473220", "bodyText": "So what you have here is handled a lot better if you add a method like the following to the BlockingManager\n   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n      CompletionStage<Void> stage = Flowable.defer(() -> {\n         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n         if (isCurrentThreadBlocking()) {\n            return flowable;\n         }\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Subscribing to %s on blocking thread\"));\n         }\n         flowable = flowable.subscribeOn(blockingScheduler);\n         if (trace) {\n            flowable = flowable.doOnSubscribe(subscription -> log.tracef(\"Publisher subscribing thread is %s\"));\n         }\n         return flowable;\n      }).ignoreElements().toCompletionStage(null);\n\n      return continueOnNonBlockingThread(stage, traceId);\n   }\nI believe the doOnSubscribe is in the correct spot, but you may want to verify. The goal is to print it in the blocking thread so you can match operations between.\nThen you can just replace with this method and remove the subscribe below. This way it will properly resume on a non blocking thread. To be honest you may want to evaluate all your usages of runBlocking to see if you want to use this instead.", "author": "wburns", "createdAt": "2020-08-12T18:55:57Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CounterResource.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.COUNTERS;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.counter.api.CounterConfiguration;\n+import org.infinispan.counter.api.CounterManager;\n+import org.infinispan.counter.api.CounterType;\n+import org.infinispan.counter.api.StrongCounter;\n+import org.infinispan.counter.api.WeakCounter;\n+import org.infinispan.factories.GlobalComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#COUNTERS}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CounterResource extends AbstractContainerResource {\n+\n+   private static final String COUNTERS_FILE = \"counters.dat\";\n+\n+   private final CounterManager counterManager;\n+   private final ImmutableSerializationContext serCtx;\n+\n+   CounterResource(BlockingManager blockingManager, EmbeddedCacheManager cm,\n+                   BackupManager.Resources params, Path root) {\n+      super(COUNTERS, params, blockingManager, root);\n+      GlobalComponentRegistry gcr = cm.getGlobalComponentRegistry();\n+      this.counterManager = gcr.getComponent(CounterManager.class);\n+      this.serCtx = gcr.getComponent(SerializationContextRegistry.class).getPersistenceCtx();\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      if (wildcard) {\n+         resources.addAll(counterManager.getCounterNames());\n+         return;\n+      }\n+\n+      for (String counterName : resources) {\n+         if (counterManager.getConfiguration(counterName) == null)\n+            throw log.unableToFindResource(type.toString(), counterName);\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      return blockingManager.runBlocking(() -> {", "originalCommit": "2f57736b5792ba572c18792f105772d7eeea0b78", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "url": "https://github.com/infinispan/infinispan/commit/ca1605d5abf808eb41677c2f4a028aea86d931a4", "message": "Don docs feedback", "committedDate": "2020-08-13T10:57:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAxMTg1OA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470011858", "bodyText": "Looks like you can use\n      if (resources != null)\n         json.set(\"resources\", Json.factory().make(resources));\nfrom the other method.", "author": "wburns", "createdAt": "2020-08-13T14:52:32Z", "path": "client/rest-client/src/main/java/org/infinispan/client/rest/impl/okhttp/RestCacheManagerClientOkHttp.java", "diffHunk": "@@ -121,4 +128,70 @@ public String name() {\n    public CompletionStage<RestResponse> caches() {\n       return client.execute(baseCacheManagerUrl, \"caches\");\n    }\n+\n+   @Override\n+   public CompletionStage<RestResponse> createBackup(String name, String workingDir, Map<String, List<String>> resources) {\n+      Json json = Json.object();\n+      if (workingDir != null)\n+         json.set(\"directory\", workingDir);\n+\n+      if (resources != null) {", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjUzMQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470036531", "bodyText": "Technically this method can block as well. I would say we could use Cache#sizeAsync but that requires getting all elements. TBH, until we have a Cache#isEmptyAsync I would recommend just removing this if block. Although it would be quite simple to add this method to the cache if you wanted.", "author": "wburns", "createdAt": "2020-08-13T15:26:40Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+      Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+      // Create the cache backup dir and parents\n+      Path cacheRoot = root.resolve(cacheName);\n+      mkdirs(cacheRoot);\n+\n+      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTU2NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041565", "bodyText": "I'll remove the if block ... this PR is already pretty large", "author": "ryanemerson", "createdAt": "2020-08-13T15:34:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzNjUzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAzOTQzNQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470039435", "bodyText": "Sorry I didn't notice this earlier, but this doesn't do what you want sadly.\nYou need to do something like \n  \n    \n      infinispan/core/src/main/java/org/infinispan/stream/impl/DistributedCacheStream.java\n    \n    \n         Line 378\n      in\n      37abd44\n    \n    \n    \n    \n\n        \n          \n           .onErrorResumeNext(RxJavaInterop.cacheExceptionWrapper()), distributedBatchSize);", "author": "wburns", "createdAt": "2020-08-13T15:30:57Z", "path": "server/core/src/main/java/org/infinispan/server/core/backup/resources/CacheResource.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package org.infinispan.server.core.backup.resources;\n+\n+import static org.infinispan.server.core.BackupManager.Resources.Type.CACHES;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Set;\n+import java.util.concurrent.CompletionStage;\n+import java.util.zip.ZipEntry;\n+import java.util.zip.ZipFile;\n+\n+import javax.xml.stream.XMLStreamException;\n+\n+import org.infinispan.AdvancedCache;\n+import org.infinispan.cache.impl.InvocationHelper;\n+import org.infinispan.commands.CommandsFactory;\n+import org.infinispan.commands.write.PutKeyValueCommand;\n+import org.infinispan.commons.CacheException;\n+import org.infinispan.commons.dataconversion.MediaType;\n+import org.infinispan.commons.marshall.Marshaller;\n+import org.infinispan.commons.marshall.MarshallingException;\n+import org.infinispan.commons.marshall.ProtoStreamTypeIds;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;\n+import org.infinispan.configuration.parsing.ParserRegistry;\n+import org.infinispan.container.entries.CacheEntry;\n+import org.infinispan.context.impl.FlagBitSets;\n+import org.infinispan.distribution.ch.KeyPartitioner;\n+import org.infinispan.encoding.impl.StorageConfigurationManager;\n+import org.infinispan.factories.ComponentRegistry;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+import org.infinispan.marshall.persistence.PersistenceMarshaller;\n+import org.infinispan.marshall.protostream.impl.SerializationContextRegistry;\n+import org.infinispan.metadata.Metadata;\n+import org.infinispan.metadata.impl.InternalMetadataImpl;\n+import org.infinispan.metadata.impl.PrivateMetadata;\n+import org.infinispan.protostream.ImmutableSerializationContext;\n+import org.infinispan.protostream.annotations.ProtoField;\n+import org.infinispan.protostream.annotations.ProtoTypeId;\n+import org.infinispan.reactive.publisher.PublisherTransformers;\n+import org.infinispan.reactive.publisher.impl.ClusterPublisherManager;\n+import org.infinispan.reactive.publisher.impl.DeliveryGuarantee;\n+import org.infinispan.registry.InternalCacheRegistry;\n+import org.infinispan.server.core.BackupManager;\n+import org.infinispan.util.concurrent.AggregateCompletionStage;\n+import org.infinispan.util.concurrent.BlockingManager;\n+import org.infinispan.util.concurrent.CompletionStages;\n+import org.reactivestreams.Publisher;\n+\n+import io.reactivex.rxjava3.core.Flowable;\n+\n+/**\n+ * {@link org.infinispan.server.core.backup.ContainerResource} implementation for {@link\n+ * BackupManager.Resources.Type#CACHES}.\n+ *\n+ * @author Ryan Emerson\n+ * @since 12.0\n+ */\n+public class CacheResource extends AbstractContainerResource {\n+\n+   private static final String MEMCACHED_CACHE = \"memcachedCache\";\n+\n+   private final EmbeddedCacheManager cm;\n+   private final ParserRegistry parserRegistry;\n+\n+   CacheResource(BlockingManager blockingManager, ParserRegistry parserRegistry, EmbeddedCacheManager cm,\n+                 BackupManager.Resources params, Path root) {\n+      super(CACHES, params, blockingManager, root);\n+      this.cm = cm;\n+      this.parserRegistry = parserRegistry;\n+   }\n+\n+   @Override\n+   public void prepareAndValidateBackup() {\n+      InternalCacheRegistry icr = cm.getGlobalComponentRegistry().getComponent(InternalCacheRegistry.class);\n+\n+      Set<String> caches = wildcard ? cm.getCacheConfigurationNames() : resources;\n+      for (String cache : caches) {\n+         Configuration config = cm.getCacheConfiguration(cache);\n+\n+         if (wildcard) {\n+            // For wildcard resources, we ignore internal caches, however explicitly requested internal caches are allowed\n+            if (config == null || config.isTemplate() || icr.isInternalCache(cache) || MEMCACHED_CACHE.equals(cache)) {\n+               continue;\n+            }\n+            resources.add(cache);\n+         } else if (config == null) {\n+            throw log.unableToFindResource(type.toString(), cache);\n+         } else if (config.isTemplate()) {\n+            throw new CacheException(String.format(\"Unable to backup %s '%s' as it is a template not a cache\", type, cache));\n+         }\n+      }\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> backup() {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cache : resources)\n+         stages.dependsOn(createCacheBackup(cache));\n+      return stages.freeze();\n+   }\n+\n+   @Override\n+   public CompletionStage<Void> restore(ZipFile zip) {\n+      AggregateCompletionStage<Void> stages = CompletionStages.aggregateCompletionStage();\n+      for (String cacheName : resources) {\n+         stages.dependsOn(blockingManager.runBlocking(() -> {\n+            Path cacheRoot = root.resolve(cacheName);\n+\n+            // Process .xml\n+            String configFile = configFile(cacheName);\n+            String zipPath = cacheRoot.resolve(configFile).toString();\n+            try (InputStream is = zip.getInputStream(zip.getEntry(zipPath))) {\n+               ConfigurationBuilderHolder builderHolder = parserRegistry.parse(is, null);\n+               Configuration cfg = builderHolder.getNamedConfigurationBuilders().get(cacheName).build();\n+               cm.defineConfiguration(cacheName, cfg);\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+\n+            // Process .dat\n+            String dataFile = dataFile(cacheName);\n+            String data = cacheRoot.resolve(dataFile).toString();\n+            ZipEntry zipEntry = zip.getEntry(data);\n+            if (zipEntry == null)\n+               return;\n+\n+            AdvancedCache<Object, Object> cache = cm.getCache(cacheName).getAdvancedCache();\n+            ComponentRegistry cr = cache.getComponentRegistry();\n+            CommandsFactory commandsFactory = cr.getCommandsFactory();\n+            KeyPartitioner keyPartitioner = cr.getComponent(KeyPartitioner.class);\n+            InvocationHelper invocationHelper = cr.getComponent(InvocationHelper.class);\n+            StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+            PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+            Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+            boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+            boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+\n+            SerializationContextRegistry ctxRegistry = cm.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+            ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+            try (InputStream is = zip.getInputStream(zipEntry)) {\n+               while (is.available() > 0) {\n+                  CacheBackupEntry entry = readMessageStream(serCtx, CacheBackupEntry.class, is);\n+                  Object key = keyMarshalling ? unmarshall(entry.key, userMarshaller) : scm.getKeyWrapper().wrap(entry.key);\n+                  Object value = valueMarshalling ? unmarshall(entry.value, userMarshaller) : scm.getKeyWrapper().wrap(entry.value);\n+                  Metadata metadata = unmarshall(entry.metadata, persistenceMarshaller);\n+                  Metadata internalMetadataImpl = new InternalMetadataImpl(metadata, entry.created, entry.lastUsed);\n+\n+                  PutKeyValueCommand cmd = commandsFactory.buildPutKeyValueCommand(key, value, keyPartitioner.getSegment(key),\n+                        internalMetadataImpl, FlagBitSets.IGNORE_RETURN_VALUES);\n+                  cmd.setInternalMetadata(entry.internalMetadata);\n+                  invocationHelper.invoke(cmd, 1);\n+               }\n+            } catch (IOException e) {\n+               throw new CacheException(e);\n+            }\n+         }, \"restore-cache-\" + cacheName));\n+      }\n+      return stages.freeze();\n+   }\n+\n+   private CompletionStage<Void> createCacheBackup(String cacheName) {\n+      AdvancedCache<?, ?> cache = cm.getCache(cacheName).getAdvancedCache();\n+      Configuration configuration = cm.getCacheConfiguration(cacheName);\n+\n+      // Create the cache backup dir and parents\n+      Path cacheRoot = root.resolve(cacheName);\n+      mkdirs(cacheRoot);\n+\n+      CompletionStage<Void> configStage = blockingManager.runBlocking(() -> {\n+         // Write configuration file\n+         String xmlFileName = configFile(cacheName);\n+         Path xmlPath = cacheRoot.resolve(xmlFileName);\n+         try (OutputStream os = Files.newOutputStream(xmlPath)) {\n+            parserRegistry.serialize(os, cacheName, configuration);\n+         } catch (XMLStreamException | IOException e) {\n+            throw new CacheException(String.format(\"Unable to create backup file '%s'\", xmlFileName), e);\n+         }\n+      }, \"write-cache-config\");\n+\n+      if (cache.isEmpty())\n+         return configStage;\n+\n+      ComponentRegistry cr = cache.getComponentRegistry();\n+      ClusterPublisherManager<Object, Object> clusterPublisherManager = cr.getClusterPublisherManager().running();\n+      SerializationContextRegistry ctxRegistry = cr.getGlobalComponentRegistry().getComponent(SerializationContextRegistry.class);\n+      ImmutableSerializationContext serCtx = ctxRegistry.getPersistenceCtx();\n+\n+      String dataFileName = dataFile(cacheName);\n+      Path datFile = cacheRoot.resolve(dataFileName);\n+\n+      int bufferSize = configuration.clustering().stateTransfer().chunkSize();\n+      Publisher<CacheEntry<Object, Object>> p = clusterPublisherManager.entryPublisher(null, null, null, true,\n+            DeliveryGuarantee.EXACTLY_ONCE, bufferSize, PublisherTransformers.identity());\n+\n+      StorageConfigurationManager scm = cr.getComponent(StorageConfigurationManager.class);\n+      boolean keyMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getKeyStorageMediaType());\n+      boolean valueMarshalling = MediaType.APPLICATION_OBJECT.equals(scm.getValueStorageMediaType());\n+      PersistenceMarshaller persistenceMarshaller = cr.getPersistenceMarshaller();\n+      Marshaller userMarshaller = persistenceMarshaller.getUserMarshaller();\n+\n+      CompletionStage<Void> contentStage = blockingManager.blockingPublisherToVoidStage(\n+            Flowable.using(\n+                  () -> Files.newOutputStream(datFile),\n+                  output ->\n+                        Flowable.fromPublisher(p)\n+                              .map(e -> {\n+                                 CacheBackupEntry be = new CacheBackupEntry();\n+                                 be.key = keyMarshalling ? marshall(e.getKey(), userMarshaller) : (byte[]) scm.getKeyWrapper().unwrap(e.getKey());\n+                                 be.value = valueMarshalling ? marshall(e.getValue(), userMarshaller) : (byte[]) scm.getValueWrapper().unwrap(e.getKey());\n+                                 be.metadata = marshall(e.getMetadata(), persistenceMarshaller);\n+                                 be.internalMetadata = e.getInternalMetadata();\n+                                 be.created = e.getCreated();\n+                                 be.lastUsed = e.getLastUsed();\n+                                 return be;\n+                              })\n+                              .doOnNext(e -> writeMessageStream(e, serCtx, output))\n+                              .doOnError(t -> {\n+                                 throw new CacheException(\"Unable to create cache backup\", t);", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTQ0NQ==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041445", "bodyText": "We can add an if (trace)", "author": "wburns", "createdAt": "2020-08-13T15:34:04Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManagerImpl.java", "diffHunk": "@@ -246,6 +261,26 @@ protected void start() {\n       });\n    }\n \n+   public <V> CompletionStage<Void> blockingPublisherToVoidStage(Publisher<V> publisher, Object traceId) {\n+      CompletionStage<Void> stage = Flowable.defer(() -> {\n+         Flowable<V> flowable = Flowable.fromPublisher(publisher);\n+         if (isCurrentThreadBlocking()) {\n+            log.tracef(\"Invoked on a blocking thread, running %s in same blocking thread\", traceId);", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDA0MTgxNA==", "url": "https://github.com/infinispan/infinispan/pull/8532#discussion_r470041814", "bodyText": "We should note the stage will always be completed upon a non blocking thread if the current thread is not a blocking one.", "author": "wburns", "createdAt": "2020-08-13T15:34:42Z", "path": "core/src/main/java/org/infinispan/util/concurrent/BlockingManager.java", "diffHunk": "@@ -169,6 +184,19 @@\n     */\n    <V> Publisher<V> blockingPublisher(Publisher<V> publisher);\n \n+   /**\n+    * Subscribes to the provided blocking publisher using the the blocking executor, ignoring all elements and returning\n+    * a {@link CompletionStage} with a value of null when complete.\n+    * <p>\n+    * Note that if the current thread is blocking everything including subscription, publication and collection of\n+    * values will be done on the current thread.\n+    *", "originalCommit": "ca1605d5abf808eb41677c2f4a028aea86d931a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3e0b7319afa90ef8dda846de3624827eebbbd964", "url": "https://github.com/infinispan/infinispan/commit/3e0b7319afa90ef8dda846de3624827eebbbd964", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-13T16:20:43Z", "type": "forcePushed"}, {"oid": "afb9ba558954d23cc966607b1405019ca56cced9", "url": "https://github.com/infinispan/infinispan/commit/afb9ba558954d23cc966607b1405019ca56cced9", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-18T09:10:22Z", "type": "forcePushed"}, {"oid": "83f0706eabce639bc97dab9171bd0656f0ecde11", "url": "https://github.com/infinispan/infinispan/commit/83f0706eabce639bc97dab9171bd0656f0ecde11", "message": "Process cache config and content as a single blocking task", "committedDate": "2020-08-19T09:23:06Z", "type": "forcePushed"}, {"oid": "637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "url": "https://github.com/infinispan/infinispan/commit/637fa21fdd20258708c49687dfcd0b7a0a4ec14b", "message": "ISPN-11723 Serialize modules default namespace\n\nThis allows the xml from a backup created in a past major version to be\ncorrectly parsed when imported by a future major version.", "committedDate": "2020-08-19T15:41:38Z", "type": "commit"}, {"oid": "f491132143ab0b421e0fd0cd84c2efdd436d27cc", "url": "https://github.com/infinispan/infinispan/commit/f491132143ab0b421e0fd0cd84c2efdd436d27cc", "message": "Utilise blockingPublisher", "committedDate": "2020-08-19T15:41:38Z", "type": "forcePushed"}, {"oid": "d5029152cd0b6edfd07cec7312e98e17295d88c6", "url": "https://github.com/infinispan/infinispan/commit/d5029152cd0b6edfd07cec7312e98e17295d88c6", "message": "ISPN-11723 Cluster Backup/Restore tool", "committedDate": "2020-08-19T16:15:10Z", "type": "commit"}, {"oid": "14fbe3fe8e53f935f107954343c563549308348f", "url": "https://github.com/infinispan/infinispan/commit/14fbe3fe8e53f935f107954343c563549308348f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-19T16:15:10Z", "type": "commit"}, {"oid": "14fbe3fe8e53f935f107954343c563549308348f", "url": "https://github.com/infinispan/infinispan/commit/14fbe3fe8e53f935f107954343c563549308348f", "message": "ISPN-11723 REST API docs added", "committedDate": "2020-08-19T16:15:10Z", "type": "forcePushed"}]}