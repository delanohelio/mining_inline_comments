{"pr_number": 1730, "pr_title": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "pr_createdAt": "2020-05-18T07:35:53Z", "pr_url": "https://github.com/apache/hbase/pull/1730", "timeline": [{"oid": "764ea151e9bedfd7aa398456fc982bd4d17ebec8", "url": "https://github.com/apache/hbase/commit/764ea151e9bedfd7aa398456fc982bd4d17ebec8", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-05-19T02:09:57Z", "type": "forcePushed"}, {"oid": "e3508fd533f9c9392494aff807c1270f306fc081", "url": "https://github.com/apache/hbase/commit/e3508fd533f9c9392494aff807c1270f306fc081", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-05-25T08:00:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI0NDgyMg==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r430244822", "bodyText": "Can be removed.", "author": "infraio", "createdAt": "2020-05-26T08:33:00Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DateTieredMultiFileWriter.java", "diffHunk": "@@ -38,23 +38,34 @@\n \n   private final boolean needEmptyFile;\n \n+  private final Map<Long, String> lowerBoundariesPolicies;\n+\n   /**\n+   * @param lowerBoundariesPolicies each window to storage policy map.\n    * @param needEmptyFile whether need to create an empty store file if we haven't written out\n    *          anything.\n    */\n-  public DateTieredMultiFileWriter(List<Long> lowerBoundaries, boolean needEmptyFile) {\n+  public DateTieredMultiFileWriter(List<Long> lowerBoundaries,\n+      Map<Long, String> lowerBoundariesPolicies, boolean needEmptyFile) {\n     for (Long lowerBoundary : lowerBoundaries) {\n       lowerBoundary2Writer.put(lowerBoundary, null);\n     }\n     this.needEmptyFile = needEmptyFile;\n+    this.lowerBoundariesPolicies = lowerBoundariesPolicies;\n   }\n \n   @Override\n   public void append(Cell cell) throws IOException {\n     Map.Entry<Long, StoreFileWriter> entry = lowerBoundary2Writer.floorEntry(cell.getTimestamp());\n     StoreFileWriter writer = entry.getValue();\n     if (writer == null) {\n-      writer = writerFactory.createWriter();\n+      String lowerBoundaryStoragePolicy = lowerBoundariesPolicies.get(entry.getKey());\n+      if (lowerBoundaryStoragePolicy != null) {\n+        writer = writerFactory.createWriterWithStoragePolicy(lowerBoundaryStoragePolicy);\n+      } else {\n+        writer = writerFactory.createWriter();\n+      }\n+      //writer = writerFactory.createWriter();", "originalCommit": "e3508fd533f9c9392494aff807c1270f306fc081", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMDcxMw==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r430830713", "bodyText": "Will remove later.", "author": "pengmq1", "createdAt": "2020-05-27T03:00:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI0NDgyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI0NTU3NQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r430245575", "bodyText": "Only log once when region created? If so, can use info log.", "author": "infraio", "createdAt": "2020-05-26T08:34:16Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java", "diffHunk": "@@ -547,6 +553,22 @@ public StoreFileWriter build() throws IOException {\n       CommonFSUtils.setStoragePolicy(this.fs, dir, policyName);\n \n       if (filePath == null) {\n+        // The stored file and related blocks will used the directory based StoragePolicy.\n+        // Because HDFS DistributedFileSystem does not support create files with storage policy\n+        // before version 3.3.0 (See HDFS-13209). Use child dir here is to make stored files\n+        // satisfy the specific storage policy when writing. So as to avoid later data movement.\n+        // We don't want to change whole temp dir to 'fileStoragePolicy'.\n+        if (fileStoragePolicy != null && !fileStoragePolicy.isEmpty()) {\n+          dir = new Path(dir, HConstants.STORAGE_POLICY_PREFIX + fileStoragePolicy);\n+          if (!fs.exists(dir)) {\n+            HRegionFileSystem.mkdirs(fs, conf, dir);\n+          }\n+          CommonFSUtils.setStoragePolicy(this.fs, dir, fileStoragePolicy);\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(", "originalCommit": "e3508fd533f9c9392494aff807c1270f306fc081", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDgzMjY3Mg==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r430832672", "bodyText": "yes, I think each type storage policy will create tmp dir once.  CommonFSUtils.setStoragePolicy(this.fs, dir, fileStoragePolicy); should follow HRegionFileSystem.mkdirs?", "author": "pengmq1", "createdAt": "2020-05-27T03:08:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDI0NTU3NQ=="}], "type": "inlineReview"}, {"oid": "f4d513daf5dbd75478320db6ab983fbd58920287", "url": "https://github.com/apache/hbase/commit/f4d513daf5dbd75478320db6ab983fbd58920287", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-06-02T03:20:55Z", "type": "forcePushed"}, {"oid": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "url": "https://github.com/apache/hbase/commit/c6322b4bf2a4f15a4168c82b283367584e85ebe0", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-06-08T09:55:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTQ4NQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443201485", "bodyText": "ImmutableMap?", "author": "Apache9", "createdAt": "2020-06-21T09:40:05Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DateTieredMultiFileWriter.java", "diffHunk": "@@ -38,23 +38,33 @@\n \n   private final boolean needEmptyFile;\n \n+  private final Map<Long, String> lowerBoundariesPolicies;", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4NDU1Nw==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443384557", "bodyText": "lowerBoundariesPolicies is HashMap", "author": "pengmq1", "createdAt": "2020-06-22T08:06:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTQ4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTU4MQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443201581", "bodyText": "Cast it to DateTieredCompactionRequest with a locl variable and then make use of the casted instance?", "author": "Apache9", "createdAt": "2020-06-21T09:41:18Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/DateTieredStoreEngine.java", "diffHunk": "@@ -94,6 +94,7 @@ public void forceSelect(CompactionRequestImpl request) {\n         throws IOException {\n       if (request instanceof DateTieredCompactionRequest) {\n         return compactor.compact(request, ((DateTieredCompactionRequest) request).getBoundaries(),\n+          ((DateTieredCompactionRequest) request).getBoundariesPolicies(),", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4Nzc1Nw==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443387757", "bodyText": "Yeah... I follow the use of ((DateTieredCompactionRequest) request).getBoundaries() previous line of code.", "author": "pengmq1", "createdAt": "2020-06-22T08:12:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTU4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NDc2NQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446474765", "bodyText": "Use a local variable and no need to cast twice...", "author": "infraio", "createdAt": "2020-06-27T02:44:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTU4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTcyMQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443201721", "bodyText": "Just use Strings.isNullOrEmpty in guava.", "author": "Apache9", "createdAt": "2020-06-21T09:43:00Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileWriter.java", "diffHunk": "@@ -547,6 +553,20 @@ public StoreFileWriter build() throws IOException {\n       CommonFSUtils.setStoragePolicy(this.fs, dir, policyName);\n \n       if (filePath == null) {\n+        // The stored file and related blocks will used the directory based StoragePolicy.\n+        // Because HDFS DistributedFileSystem does not support create files with storage policy\n+        // before version 3.3.0 (See HDFS-13209). Use child dir here is to make stored files\n+        // satisfy the specific storage policy when writing. So as to avoid later data movement.\n+        // We don't want to change whole temp dir to 'fileStoragePolicy'.\n+        if (fileStoragePolicy != null && !fileStoragePolicy.isEmpty()) {", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzM4Nzg3MA==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r443387870", "bodyText": "OK", "author": "pengmq1", "createdAt": "2020-06-22T08:13:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzIwMTcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NTI0Nw==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446475247", "bodyText": "Method name start with \"test\"? incomingWindowHot => testIncomingWindowHot", "author": "infraio", "createdAt": "2020-06-27T02:50:47Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDateTieredCompactionPolicyHeterogeneousStorage.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration;\n+import org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory;\n+import org.apache.hadoop.hbase.testclassification.RegionServerTests;\n+import org.apache.hadoop.hbase.testclassification.SmallTests;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+@Category({ RegionServerTests.class, SmallTests.class })\n+public class TestDateTieredCompactionPolicyHeterogeneousStorage\n+    extends AbstractTestDateTieredCompactionPolicy {\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+      HBaseClassTestRule.forClass(TestDateTieredCompactionPolicyHeterogeneousStorage.class);\n+  public static final String HOT_WINDOW_SP = \"ALL_SSD\";\n+  public static final String WARM_WINDOW_SP = \"ONE_SSD\";\n+  public static final String COLD_WINDOW_SP = \"HOT\";\n+\n+  @Override\n+  protected void config() {\n+    super.config();\n+\n+    // Set up policy\n+    conf.set(StoreEngine.STORE_ENGINE_CLASS_KEY,\n+      \"org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine\");\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_MAX_AGE_MILLIS_KEY, 100);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_INCOMING_WINDOW_MIN_KEY, 3);\n+    conf.setLong(ExponentialCompactionWindowFactory.BASE_WINDOW_MILLIS_KEY, 6);\n+    conf.setInt(ExponentialCompactionWindowFactory.WINDOWS_PER_TIER_KEY, 4);\n+    conf.setBoolean(CompactionConfiguration.DATE_TIERED_SINGLE_OUTPUT_FOR_MINOR_COMPACTION_KEY,\n+      false);\n+\n+    // Special settings for compaction policy per window\n+    this.conf.setInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MIN_KEY, 2);\n+    this.conf.setInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MAX_KEY, 12);\n+    this.conf.setFloat(CompactionConfiguration.HBASE_HSTORE_COMPACTION_RATIO_KEY, 1.2F);\n+\n+    conf.setInt(HStore.BLOCKING_STOREFILES_KEY, 20);\n+    conf.setLong(HConstants.MAJOR_COMPACTION_PERIOD, 5);\n+\n+    // Set Storage Policy for different type window\n+    conf.setBoolean(CompactionConfiguration.DATE_TIERED_STORAGE_POLICY_ENABLE_KEY, true);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_HOT_WINDOW_AGE_MILLIS_KEY, 6);\n+    conf.set(CompactionConfiguration.DATE_TIERED_HOT_WINDOW_STORAGE_POLICY_KEY, HOT_WINDOW_SP);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_WARM_WINDOW_AGE_MILLIS_KEY, 12);\n+    conf.set(CompactionConfiguration.DATE_TIERED_WARM_WINDOW_STORAGE_POLICY_KEY, WARM_WINDOW_SP);\n+    conf.set(CompactionConfiguration.DATE_TIERED_COLD_WINDOW_STORAGE_POLICY_KEY, COLD_WINDOW_SP);\n+  }\n+\n+  /**\n+   * Test for incoming window and is HOT window\n+   * window start >= now - hot age\n+   * @throws IOException with error\n+   */\n+  @Test\n+  public void incomingWindowHot() throws IOException {", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NTQ1OQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446475459", "bodyText": "Set storage policy for a file? This is not work before hdfs 3.3.0?", "author": "infraio", "createdAt": "2020-06-27T02:52:54Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "diffHunk": "@@ -1564,6 +1568,18 @@ public void deleteChangedReaderObserver(ChangedReadersObserver o) {\n     return sfs;\n   }\n \n+  // Set correct storage policy from the file name of DTCP.\n+  // Rename file will not change the storage policy.\n+  private void setStoragePolicyFromFileName(List<Path> newFiles) throws IOException {\n+    String prefix = HConstants.STORAGE_POLICY_PREFIX;\n+    for (Path newFile : newFiles) {\n+      if (newFile.getParent().getName().startsWith(prefix)) {\n+        CommonFSUtils.setStoragePolicy(fs.getFileSystem(), newFile,", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjYxMjIyNg==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446612226", "bodyText": "newFiles\u662f\u5df2\u7ecfcompact\u7ed3\u675f\u5c06\u8981\u88abrename\u5230region\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\uff0c\u4f46\u5b83\u4eec\u7684storage policy\u8fd8\u672a\u6307\u5b9a\uff0c\u6587\u4ef6storage policy\u5c5e\u6027\u4fdd\u5b58\u5728INode\u4e2d\u3002rename\u4e4b\u540e\uff0c\u672a\u6307\u5b9astorage policy\u7684\u6587\u4ef6\u81ea\u52a8\u7ee7\u627f\u65b0\u7684\u7236\u76ee\u5f55\u3002\u5728rename\u4e4b\u524d\u8c03\u7528setStoragePolicy()\u662f\u4e3a\u4e86\u4f7f\u6570\u636e\u548cstorage policy\u4fdd\u6301\u4e00\u81f4\uff0c\u907f\u514dstorage policy\u56e0\u4e3a\u7ee7\u627f\u53d1\u751f\u53d8\u5316\u3002HDFS\u5141\u8bb8\u5bf9\u5df2\u7ecfclose\u7684\u6587\u4ef6\u8bbe\u7f6estorage policy, \u5e76\u4e0d\u4f1a\u53d1\u751f\u6570\u636e\u79fb\u52a8\u3002\u800c\u4e14newFiles\u7684\u6570\u636e\u548c\u4e34\u65f6\u7236\u76ee\u5f55\u7684storage policy\u5df2\u7ecf\u662f\u4e00\u81f4\u7684\u4e86(\u56e0\u4e3a\u5728compact\u4e4b\u524dtmp\u4e0b\u5df2\u521b\u5efa\u4e86\u4e0d\u540c\u5b58\u50a8\u7b56\u7565\u7684\u4e34\u65f6\u76ee\u5f55)\nnewFiles are files that have been compacted and will be renamed to the region directory, but their storage policy has not been specified. The file storage policy attribute is saved in INode. After renaming, files that do not specify a storage policy automatically inherit the new parent directory. Before renaming call to setStoragePolicy() here is to keep the data consistent with the storage policy and avoid the storage policy changing due to inheritance. HDFS allows storage policy to be set on files that have been closed, and no data movement will occur. Moreover, the data of newFiles and the storage policy of tmp parent dir are already consistent (because tmp directories of different storage strategies have been created under tmp dir before compact).", "author": "pengmq1", "createdAt": "2020-06-28T07:19:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NTQ1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NTc5OQ==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446475799", "bodyText": "Explain more about the unit test? What is the different between this and other tests? And there are some duplicate code in these test methods?", "author": "infraio", "createdAt": "2020-06-27T02:56:47Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestDateTieredCompactionPolicyHeterogeneousStorage.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.regionserver;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.regionserver.compactions.CompactionConfiguration;\n+import org.apache.hadoop.hbase.regionserver.compactions.ExponentialCompactionWindowFactory;\n+import org.apache.hadoop.hbase.testclassification.RegionServerTests;\n+import org.apache.hadoop.hbase.testclassification.SmallTests;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+@Category({ RegionServerTests.class, SmallTests.class })\n+public class TestDateTieredCompactionPolicyHeterogeneousStorage\n+    extends AbstractTestDateTieredCompactionPolicy {\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+      HBaseClassTestRule.forClass(TestDateTieredCompactionPolicyHeterogeneousStorage.class);\n+  public static final String HOT_WINDOW_SP = \"ALL_SSD\";\n+  public static final String WARM_WINDOW_SP = \"ONE_SSD\";\n+  public static final String COLD_WINDOW_SP = \"HOT\";\n+\n+  @Override\n+  protected void config() {\n+    super.config();\n+\n+    // Set up policy\n+    conf.set(StoreEngine.STORE_ENGINE_CLASS_KEY,\n+      \"org.apache.hadoop.hbase.regionserver.DateTieredStoreEngine\");\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_MAX_AGE_MILLIS_KEY, 100);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_INCOMING_WINDOW_MIN_KEY, 3);\n+    conf.setLong(ExponentialCompactionWindowFactory.BASE_WINDOW_MILLIS_KEY, 6);\n+    conf.setInt(ExponentialCompactionWindowFactory.WINDOWS_PER_TIER_KEY, 4);\n+    conf.setBoolean(CompactionConfiguration.DATE_TIERED_SINGLE_OUTPUT_FOR_MINOR_COMPACTION_KEY,\n+      false);\n+\n+    // Special settings for compaction policy per window\n+    this.conf.setInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MIN_KEY, 2);\n+    this.conf.setInt(CompactionConfiguration.HBASE_HSTORE_COMPACTION_MAX_KEY, 12);\n+    this.conf.setFloat(CompactionConfiguration.HBASE_HSTORE_COMPACTION_RATIO_KEY, 1.2F);\n+\n+    conf.setInt(HStore.BLOCKING_STOREFILES_KEY, 20);\n+    conf.setLong(HConstants.MAJOR_COMPACTION_PERIOD, 5);\n+\n+    // Set Storage Policy for different type window\n+    conf.setBoolean(CompactionConfiguration.DATE_TIERED_STORAGE_POLICY_ENABLE_KEY, true);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_HOT_WINDOW_AGE_MILLIS_KEY, 6);\n+    conf.set(CompactionConfiguration.DATE_TIERED_HOT_WINDOW_STORAGE_POLICY_KEY, HOT_WINDOW_SP);\n+    conf.setLong(CompactionConfiguration.DATE_TIERED_WARM_WINDOW_AGE_MILLIS_KEY, 12);\n+    conf.set(CompactionConfiguration.DATE_TIERED_WARM_WINDOW_STORAGE_POLICY_KEY, WARM_WINDOW_SP);\n+    conf.set(CompactionConfiguration.DATE_TIERED_COLD_WINDOW_STORAGE_POLICY_KEY, COLD_WINDOW_SP);\n+  }\n+\n+  /**\n+   * Test for incoming window and is HOT window\n+   * window start >= now - hot age\n+   * @throws IOException with error\n+   */\n+  @Test\n+  public void incomingWindowHot() throws IOException {\n+    long[] minTimestamps = new long[] { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n+    long[] maxTimestamps = new long[] { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 };\n+    long[] sizes = new long[] { 30, 31, 32, 33, 34, 20, 21, 22, 23, 24, 25, 10, 11, 12, 13 };\n+    Map<Long, String> expected = new HashMap<>();\n+    // boundaries = { Long.MIN_VALUE, 12 }\n+    expected.put(12L, HOT_WINDOW_SP);", "originalCommit": "c6322b4bf2a4f15a4168c82b283367584e85ebe0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjYxNjUxMg==", "url": "https://github.com/apache/hbase/pull/1730#discussion_r446616512", "bodyText": "fix duplicate code", "author": "pengmq1", "createdAt": "2020-06-28T08:04:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ3NTc5OQ=="}], "type": "inlineReview"}, {"oid": "4577978d43d5ed92d4ae12f86398d62216cac704", "url": "https://github.com/apache/hbase/commit/4577978d43d5ed92d4ae12f86398d62216cac704", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-06-28T08:02:22Z", "type": "forcePushed"}, {"oid": "42c1fc016c9c324f34dce416ef333dcb1e0ebc63", "url": "https://github.com/apache/hbase/commit/42c1fc016c9c324f34dce416ef333dcb1e0ebc63", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-06-29T01:33:19Z", "type": "commit"}, {"oid": "42c1fc016c9c324f34dce416ef333dcb1e0ebc63", "url": "https://github.com/apache/hbase/commit/42c1fc016c9c324f34dce416ef333dcb1e0ebc63", "message": "HBASE-24289 Heterogeneous Storage for Date Tiered Compaction", "committedDate": "2020-06-29T01:33:19Z", "type": "forcePushed"}]}