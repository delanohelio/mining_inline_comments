{"pr_number": 1753, "pr_title": "HBASE-24408 Introduce a general 'local region' to store data on master", "pr_createdAt": "2020-05-21T15:34:15Z", "pr_url": "https://github.com/apache/hbase/pull/1753", "timeline": [{"oid": "b5ecafb52606eee213d26073237598a04d7736f6", "url": "https://github.com/apache/hbase/commit/b5ecafb52606eee213d26073237598a04d7736f6", "message": "HBAE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-21T23:38:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzA1OA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033058", "bodyText": "Need to be volatile?", "author": "saintstack", "createdAt": "2020-05-22T04:11:33Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzE5OQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033199", "bodyText": "s/valiate/validate/", "author": "saintstack", "createdAt": "2020-05-22T04:12:07Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNDE1MA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429034150", "bodyText": "Why a second time? Just-in-case? Can you say why we do it twice in comment? What you are afraid of?", "author": "saintstack", "createdAt": "2020-05-22T04:16:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzE5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NjE2NQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429086165", "bodyText": "Just need to make sure that we are only dealing with the correct files. The cleaner chain works with 'AND', that means, if one of the cleaners return false, then we will not delete the file.\nFor example, we have two wal files, one is the normal one, the other is the local store one. The former one has a TTL of 1 hour, and the latter one has a TTL of 7 days. If we do not have the test here, then for all files, the latter cleaner will always return false within 7 days, and the former one will have no effect. So here we need to make sure that, each cleaner just test the file that should be checked by it.", "author": "Apache9", "createdAt": "2020-05-22T07:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzM2OQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033369", "bodyText": "Someone logs the 'why'?", "author": "saintstack", "createdAt": "2020-05-22T04:12:52Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/BaseTimeToLiveFileCleaner.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.cleaner;\n+\n+import java.time.Instant;\n+import java.time.ZoneOffset;\n+import java.time.format.DateTimeFormatter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Base class for time to live file cleaner.\n+ */\n+@InterfaceAudience.Private\n+public abstract class BaseTimeToLiveFileCleaner extends BaseLogCleanerDelegate {\n+\n+  private static final Logger LOG =\n+    LoggerFactory.getLogger(BaseTimeToLiveFileCleaner.class.getName());\n+\n+  private static final DateTimeFormatter FORMATTER =\n+    DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneOffset.systemDefault());\n+\n+  // Configured time a log can be kept after it was closed\n+  private long ttlMs;\n+\n+  private boolean stopped = false;\n+\n+  @Override\n+  public final void setConf(Configuration conf) {\n+    super.setConf(conf);\n+    this.ttlMs = getTtlMs(conf);\n+  }\n+\n+  @Override\n+  public boolean isFileDeletable(FileStatus status) {\n+    // Files are validated for the second time here,\n+    // if it causes a bottleneck this logic needs refactored\n+    if (!valiateFilename(status.getPath())) {\n+      return true;\n+    }\n+    long currentTime = EnvironmentEdgeManager.currentTime();\n+    long time = status.getModificationTime();\n+    long life = currentTime - time;\n+\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"File life:{}ms, ttl:{}ms, current:{}, from{}\", life, ttlMs,\n+        FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+    }\n+    if (life < 0) {\n+      LOG.warn(\"Found a file ({}) newer than current time ({} < {}), probably a clock skew\",\n+        status.getPath(), FORMATTER.format(Instant.ofEpochMilli(currentTime)),\n+        FORMATTER.format(Instant.ofEpochMilli(time)));\n+      return false;\n+    }\n+    return life > ttlMs;\n+  }\n+\n+  @Override\n+  public void stop(String why) {\n+    this.stopped = true;", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzQzNg==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033436", "bodyText": "Maybe it is not important enough to log.", "author": "saintstack", "createdAt": "2020-05-22T04:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzM2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4NjQ3Mw==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429086473", "bodyText": "I think the outer class will do this? Log it at every cleaners will generate too many logs.", "author": "Apache9", "createdAt": "2020-05-22T07:27:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzM2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzg4NA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429033884", "bodyText": "Man, we should have called this file the WALCleaner, not LogCleaner. Not your fault.", "author": "saintstack", "createdAt": "2020-05-22T04:15:19Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/LogCleaner.java", "diffHunk": "@@ -86,8 +87,9 @@ public LogCleaner(final int period, final Stoppable stopper, Configuration conf,\n \n   @Override\n   protected boolean validate(Path file) {\n-    return AbstractFSWALProvider.validateWALFilename(file.getName())\n-        || MasterProcedureUtil.validateProcedureWALFilename(file.getName());\n+    return AbstractFSWALProvider.validateWALFilename(file.getName()) ||\n+      MasterProcedureUtil.validateProcedureWALFilename(file.getName()) ||\n+      file.getName().endsWith(LocalStore.ARCHIVED_WAL_SUFFIX);\n   }\n \n   @Override", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4Njc0MQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429086741", "bodyText": "Not sure if it is safe to change the name. Can be another issue?", "author": "Apache9", "createdAt": "2020-05-22T07:28:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzg4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NjYyMA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429346620", "bodyText": "Yes. Of course.", "author": "saintstack", "createdAt": "2020-05-22T16:38:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzMzg4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI0Mw==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429035243", "bodyText": "Whats this?", "author": "saintstack", "createdAt": "2020-05-22T04:22:06Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalRegion.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.apache.hadoop.hbase.HConstants.HREGION_LOGDIR_NAME;\n+\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseIOException;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.RegionInfoBuilder;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.FSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.apache.hadoop.hbase.util.RecoverLeaseFSUtils;\n+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.wal.WALFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.common.math.IntMath;\n+\n+/**\n+ * A region that stores data in a separated directory.\n+ * <p/>\n+ * FileSystem layout:\n+ *\n+ * <pre>\n+ * hbase\n+ *   |\n+ *   --&lt;region dir&gt;\n+ *       |\n+ *       --data\n+ *       |  |\n+ *       |  --/&lt;ns&gt/&lt;table&gt/&lt;encoded-region-name&gt; <---- The region data\n+ *       |      |\n+ *       |      --replay <---- The edits to replay\n+ *       |\n+ *       --WALs\n+ *          |\n+ *          --&lt;master-server-name&gt; <---- The WAL dir for active master\n+ *          |\n+ *          --&lt;master-server-name&gt;-dead <---- The WAL dir for dead master\n+ * </pre>\n+ *\n+ * Notice that, you can use different root file system and WAL file system. Then the above directory\n+ * will be on two file systems, the root file system will have the data directory while the WAL\n+ * filesystem will have the WALs directory. The archived HFile will be moved to the global HFile\n+ * archived directory with the {@link LocalRegionParams#archivedWalSuffix()} suffix. The archived\n+ * WAL will be moved to the global WAL archived directory with the\n+ * {@link LocalRegionParams#archivedHFileSuffix()} suffix.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalRegion {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(LocalRegion.class);\n+\n+  private static final String REPLAY_EDITS_DIR = \"recovered.wals\";\n+\n+  private static final String DEAD_WAL_DIR_SUFFIX = \"-dead\";", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4Nzk5MQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429087991", "bodyText": "The \"-dead\" is just like what we have done when processing dead region servers, where the suffix is '-splitting'. This is to prevent dead master to write procedure data again.\nAnd on the 'recovered.wals' directory, it is used to hold the recovered wal files for the local region. As there is only one region, we do not need to split the wal during recovery, just move it to 'recovered.wals' directory and replay it.\nI've explain this in HBASE-23326.", "author": "Apache9", "createdAt": "2020-05-22T07:31:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NzM2OA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429347368", "bodyText": "ok", "author": "saintstack", "createdAt": "2020-05-22T16:40:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI4MQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429035281", "bodyText": "What goes here?", "author": "saintstack", "createdAt": "2020-05-22T04:22:18Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalRegion.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.apache.hadoop.hbase.HConstants.HREGION_LOGDIR_NAME;\n+\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseIOException;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.RegionInfo;\n+import org.apache.hadoop.hbase.client.RegionInfoBuilder;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.regionserver.HRegion;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.HRegionFileSystem;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.FSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.apache.hadoop.hbase.util.RecoverLeaseFSUtils;\n+import org.apache.hadoop.hbase.wal.AbstractFSWALProvider;\n+import org.apache.hadoop.hbase.wal.WAL;\n+import org.apache.hadoop.hbase.wal.WALFactory;\n+import org.apache.yetus.audience.InterfaceAudience;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+import org.apache.hbase.thirdparty.com.google.common.math.IntMath;\n+\n+/**\n+ * A region that stores data in a separated directory.\n+ * <p/>\n+ * FileSystem layout:\n+ *\n+ * <pre>\n+ * hbase\n+ *   |\n+ *   --&lt;region dir&gt;\n+ *       |\n+ *       --data\n+ *       |  |\n+ *       |  --/&lt;ns&gt/&lt;table&gt/&lt;encoded-region-name&gt; <---- The region data\n+ *       |      |\n+ *       |      --replay <---- The edits to replay\n+ *       |\n+ *       --WALs\n+ *          |\n+ *          --&lt;master-server-name&gt; <---- The WAL dir for active master\n+ *          |\n+ *          --&lt;master-server-name&gt;-dead <---- The WAL dir for dead master\n+ * </pre>\n+ *\n+ * Notice that, you can use different root file system and WAL file system. Then the above directory\n+ * will be on two file systems, the root file system will have the data directory while the WAL\n+ * filesystem will have the WALs directory. The archived HFile will be moved to the global HFile\n+ * archived directory with the {@link LocalRegionParams#archivedWalSuffix()} suffix. The archived\n+ * WAL will be moved to the global WAL archived directory with the\n+ * {@link LocalRegionParams#archivedHFileSuffix()} suffix.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalRegion {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(LocalRegion.class);\n+\n+  private static final String REPLAY_EDITS_DIR = \"recovered.wals\";", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4ODAyMg==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429088022", "bodyText": "See above.", "author": "Apache9", "createdAt": "2020-05-22T07:31:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNTI4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037002", "bodyText": "Good", "author": "saintstack", "createdAt": "2020-05-22T04:30:22Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/store/TestLocalRegionOnTwoFileSystems.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.ChoreService;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HBaseCommonTestingUtility;\n+import org.apache.hadoop.hbase.HBaseTestingUtility;\n+import org.apache.hadoop.hbase.HConstants;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.ServerName;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.master.cleaner.DirScanPool;\n+import org.apache.hadoop.hbase.regionserver.MemStoreLAB;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.apache.hadoop.hbase.testclassification.MediumTests;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.CommonFSUtils;\n+import org.apache.hadoop.hbase.util.HFileArchiveUtil;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import org.apache.hbase.thirdparty.com.google.common.collect.Iterables;\n+\n+@Category({ MasterTests.class, MediumTests.class })\n+public class TestLocalRegionOnTwoFileSystems {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestLocalRegionOnTwoFileSystems.class);\n+\n+  private static final HBaseCommonTestingUtility HFILE_UTIL = new HBaseCommonTestingUtility();\n+\n+  private static final HBaseTestingUtility WAL_UTIL = new HBaseTestingUtility();\n+\n+  private static ChoreService CHORE_SERVICE;\n+\n+  private static DirScanPool CLEANER_POOL;\n+\n+  private static LocalRegion REGION;\n+\n+  private static byte[] CF = Bytes.toBytes(\"f\");\n+\n+  private static byte[] QUALIFIER = Bytes.toBytes(\"q\");\n+\n+  private static String REGION_DIR_NAME = \"local\";\n+\n+  private static TableDescriptor TD =\n+    TableDescriptorBuilder.newBuilder(TableName.valueOf(\"test:local\"))\n+      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(CF)).build();\n+\n+  private static int COMPACT_MIN = 4;\n+\n+  @BeforeClass\n+  public static void setUp() throws Exception {\n+    WAL_UTIL.startMiniCluster(3);\n+    Configuration conf = HFILE_UTIL.getConfiguration();\n+    conf.setBoolean(MemStoreLAB.USEMSLAB_KEY, false);\n+    CHORE_SERVICE = new ChoreService(\"TestLocalRegionOnTwoFileSystems\");\n+    CLEANER_POOL = new DirScanPool(conf);\n+    Server server = mock(Server.class);\n+    when(server.getConfiguration()).thenReturn(conf);\n+    when(server.getServerName())\n+      .thenReturn(ServerName.valueOf(\"localhost\", 12345, System.currentTimeMillis()));\n+    when(server.getChoreService()).thenReturn(CHORE_SERVICE);\n+    Path rootDir = HFILE_UTIL.getDataTestDir();\n+    CommonFSUtils.setRootDir(conf, rootDir);\n+    Path walRootDir = WAL_UTIL.getDataTestDirOnTestFS();\n+    FileSystem walFs = WAL_UTIL.getTestFileSystem();\n+    CommonFSUtils.setWALRootDir(conf,\n+      walRootDir.makeQualified(walFs.getUri(), walFs.getWorkingDirectory()));\n+    LocalRegionParams params = new LocalRegionParams();\n+    params.server(server).regionDirName(REGION_DIR_NAME).tableDescriptor(TD)\n+      .flushSize(TableDescriptorBuilder.DEFAULT_MEMSTORE_FLUSH_SIZE).flushPerChanges(1_000_000)\n+      .flushIntervalMs(TimeUnit.MINUTES.toMillis(15)).compactMin(COMPACT_MIN).maxWals(32)\n+      .useHsync(false).ringBufferSlotCount(16).rollPeriodMs(TimeUnit.MINUTES.toMillis(15))\n+      .archivedWalSuffix(LocalStore.ARCHIVED_WAL_SUFFIX)\n+      .archivedHFileSuffix(LocalStore.ARCHIVED_HFILE_SUFFIX);\n+    REGION = LocalRegion.create(params);", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzA4Ng==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037086", "bodyText": "Are there params to set for local regions walfs and hfilefs?", "author": "saintstack", "createdAt": "2020-05-22T04:30:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4ODE2Ng==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429088166", "bodyText": "No, there are set in Configuration.", "author": "Apache9", "createdAt": "2020-05-22T07:31:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NDgwMg==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429344802", "bodyText": "Where are the keys defined?", "author": "saintstack", "createdAt": "2020-05-22T16:34:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzc1OQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429037759", "bodyText": "Is this the right place to stop this? Should the localStore be made by the Master, owned and shutdown by the Master? It passes it in here to the RPS to use? Master shuts it down. Makes sure it doesn't shut it down before other users are done with it?", "author": "saintstack", "createdAt": "2020-05-22T04:34:26Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionProcedureStore.java", "diffHunk": "@@ -183,51 +106,14 @@ public void start(int numThreads) throws IOException {\n     this.numThreads = numThreads;\n   }\n \n-  private void shutdownWAL() {\n-    if (walFactory != null) {\n-      try {\n-        walFactory.shutdown();\n-      } catch (IOException e) {\n-        LOG.warn(\"Failed to shutdown WAL\", e);\n-      }\n-    }\n-  }\n-\n-  private void closeRegion(boolean abort) {\n-    if (region != null) {\n-      try {\n-        region.close(abort);\n-      } catch (IOException e) {\n-        LOG.warn(\"Failed to close region\", e);\n-      }\n-    }\n-\n-  }\n-\n   @Override\n   public void stop(boolean abort) {\n     if (!setRunning(false)) {\n       return;\n     }\n     LOG.info(\"Stopping the Region Procedure Store, isAbort={}\", abort);\n-    if (cleaner != null) {\n-      cleaner.cancel(abort);\n-    }\n-    if (flusherAndCompactor != null) {\n-      flusherAndCompactor.close();\n-    }\n-    // if abort, we shutdown wal first to fail the ongoing updates to the region, and then close the\n-    // region, otherwise there will be dead lock.\n-    if (abort) {\n-      shutdownWAL();\n-      closeRegion(true);\n-    } else {\n-      closeRegion(false);\n-      shutdownWAL();\n-    }\n-\n-    if (walRoller != null) {\n-      walRoller.close();\n+    if (localStore != null) {", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA5MTAwMg==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429091002", "bodyText": "The ideal answer is, no. It should be initialized by master and also stop by master. You can see the draft PR here\n#1746\nWhere I moved the initialization and stop out from the RegionProcedureStore.\nAnd here, since RegionProcedureStore is the only place where we use the LocalStore, there will be no technical problem to initialize and stop it inside RegionProcedureStore. Moving it out will have big impact on tests, as in most tests we will stop the ProcedureStore and reinitialize it again to test fail recovery. If we move the initialization and stop out, all these tests have to be rewritten as we need to recreate the LocalStore by our own.\nSo I prefer we do this in another issue, where we do need to store data other than procedure to the LocalStore. For example, in HBASE-24388 I have to do this.", "author": "Apache9", "createdAt": "2020-05-22T07:39:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTEyMDQwMA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429120400", "bodyText": "Oh, maybe we do not need to restart the local region when testing procedure store restart. Just add some tests to make sure that the local store recovery can work is enough?\nLet me have a try.", "author": "Apache9", "createdAt": "2020-05-22T08:43:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzNzc1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzODM1Ng==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429038356", "bodyText": "oh, the second family will come in here if we decide to store root table in here?  Not till then. Ok. I think that makes sense. If table already exists, will have to alter it when we add the root table CF?", "author": "saintstack", "createdAt": "2020-05-22T04:37:23Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalStore.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Used for storing data at master side. The data will be stored in a {@link LocalRegion}.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalStore {\n+\n+  // Use the character $ to let the log cleaner know that this is not the normal wal file.\n+  public static final String ARCHIVED_WAL_SUFFIX = \"$masterlocalwal$\";\n+\n+  public static final String ARCHIVED_HFILE_SUFFIX = \"$masterlocalhfile$\";\n+\n+  private static final String MAX_WALS_KEY = \"hbase.master.store.region.maxwals\";\n+\n+  private static final int DEFAULT_MAX_WALS = 10;\n+\n+  public static final String USE_HSYNC_KEY = \"hbase.master.store.region.wal.hsync\";\n+\n+  public static final String MASTER_STORE_DIR = \"MasterData\";\n+\n+  private static final String FLUSH_SIZE_KEY = \"hbase.master.store.region.flush.size\";\n+\n+  private static final long DEFAULT_FLUSH_SIZE = TableDescriptorBuilder.DEFAULT_MEMSTORE_FLUSH_SIZE;\n+\n+  private static final String FLUSH_PER_CHANGES_KEY = \"hbase.master.store.region.flush.per.changes\";\n+\n+  private static final long DEFAULT_FLUSH_PER_CHANGES = 1_000_000;\n+\n+  private static final String FLUSH_INTERVAL_MS_KEY = \"hbase.master.store.region.flush.interval.ms\";\n+\n+  // default to flush every 15 minutes, for safety\n+  private static final long DEFAULT_FLUSH_INTERVAL_MS = TimeUnit.MINUTES.toMillis(15);\n+\n+  private static final String COMPACT_MIN_KEY = \"hbase.master.store.region.compact.min\";\n+\n+  private static final int DEFAULT_COMPACT_MIN = 4;\n+\n+  private static final String ROLL_PERIOD_MS_KEY = \"hbase.master.store.region.walroll.period.ms\";\n+\n+  private static final long DEFAULT_ROLL_PERIOD_MS = TimeUnit.MINUTES.toMillis(15);\n+\n+  private static final String RING_BUFFER_SLOT_COUNT = \"hbase.master.store.ringbuffer.slot.count\";\n+\n+  private static final int DEFAULT_RING_BUFFER_SLOT_COUNT = 128;\n+\n+  public static final TableName TABLE_NAME = TableName.valueOf(\"master:store\");\n+\n+  public static final byte[] PROC_FAMILY = Bytes.toBytes(\"proc\");\n+\n+  private static final TableDescriptor TABLE_DESC = TableDescriptorBuilder.newBuilder(TABLE_NAME)\n+    .setColumnFamily(ColumnFamilyDescriptorBuilder.of(PROC_FAMILY)).build();", "originalCommit": "b5ecafb52606eee213d26073237598a04d7736f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA5MTQ2OQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429091469", "bodyText": "I think just changing the TABLE_DESC here and then restarting is enough. It just works like the old time, where the meta descriptor is hard coded in code.", "author": "Apache9", "createdAt": "2020-05-22T07:40:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzODM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM2OTY0OA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r431369648", "bodyText": "So the plan would be to store multiple responsibilities (proc store, root store, other projects?) in the same LocalRegion instance? Each of these responsibilities would get it's own LocalStore/column family? Why do this vs. having a dedicated LocalRegion instance for each responsibility?", "author": "ndimiduk", "createdAt": "2020-05-27T18:54:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzODM1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIxNTExOA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r432215118", "bodyText": "Use their own column family. The problems of introduing more local regions are:\n\nEach region would have its own fail recovery logic, which means we need to do lease recovery multiple times when starting master.\nMaybe we need to duplicate all the configuations here multiple times for supporting different type of local regions, which is a pain for operators.\nMaybe we need to introduce more types of HFileCleaner and WALCleaner, which is also a pain.", "author": "Apache9", "createdAt": "2020-05-29T01:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTAzODM1Ng=="}], "type": "inlineReview"}, {"oid": "b065f2702476271dfcb32d53ece11a54a1ac1cf5", "url": "https://github.com/apache/hbase/commit/b065f2702476271dfcb32d53ece11a54a1ac1cf5", "message": "HBAE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-22T08:08:38Z", "type": "forcePushed"}, {"oid": "15f5fc9ee48b5557c2e8029725210207abb1cc2f", "url": "https://github.com/apache/hbase/commit/15f5fc9ee48b5557c2e8029725210207abb1cc2f", "message": "HBASE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-22T15:22:25Z", "type": "forcePushed"}, {"oid": "0f5d045d417d239556cfcb79b6e028bf25501342", "url": "https://github.com/apache/hbase/commit/0f5d045d417d239556cfcb79b6e028bf25501342", "message": "HBASE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-22T15:23:58Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NTk5NA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429345994", "bodyText": "nice", "author": "saintstack", "createdAt": "2020-05-22T16:37:18Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/HMaster.java", "diffHunk": "@@ -1550,10 +1563,8 @@ protected void stopServiceThreads() {\n \n   private void createProcedureExecutor() throws IOException {\n     MasterProcedureEnv procEnv = new MasterProcedureEnv(this);\n-    // Create cleaner thread pool\n-    cleanerPool = new DirScanPool(conf);\n-    procedureStore = new RegionProcedureStore(this, cleanerPool,\n-      new MasterProcedureEnv.FsUtilsLeaseRecovery(this));\n+    procedureStore =\n+      new RegionProcedureStore(this, localStore, new MasterProcedureEnv.FsUtilsLeaseRecovery(this));", "originalCommit": "0f5d045d417d239556cfcb79b6e028bf25501342", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NjEzOQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429346139", "bodyText": "The passing of an already initialized localregion is what is nice.", "author": "saintstack", "createdAt": "2020-05-22T16:37:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0NTk5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM0OTEzNA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r429349134", "bodyText": "Nice. This is cleaner w/ the passing in of the local region.", "author": "saintstack", "createdAt": "2020-05-22T16:43:59Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/procedure2/store/region/RegionProcedureStore.java", "diffHunk": "@@ -688,11 +444,12 @@ public void cleanup() {\n         Cell cell = cells.get(0);\n         cells.clear();\n         if (cell.getValueLength() == 0) {\n-          region.delete(new Delete(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength()));\n+          localStore.update(r -> r\n+            .delete(new Delete(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength())));\n         }\n       }\n     } catch (IOException e) {\n       LOG.warn(\"Failed to clean up delete procedures\", e);\n     }\n   }\n-}\n+}", "originalCommit": "0f5d045d417d239556cfcb79b6e028bf25501342", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "162da681072c87678a4dc9a81b1d868308ffc871", "url": "https://github.com/apache/hbase/commit/162da681072c87678a4dc9a81b1d868308ffc871", "message": "HBASE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-22T23:47:21Z", "type": "commit"}, {"oid": "162da681072c87678a4dc9a81b1d868308ffc871", "url": "https://github.com/apache/hbase/commit/162da681072c87678a4dc9a81b1d868308ffc871", "message": "HBASE-24408 Introduce a general 'local region' to store data on master", "committedDate": "2020-05-22T23:47:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzExNQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r432783115", "bodyText": "This class name confuses me. I see now that it uses \"store\" as a legacy of what was earlier called the \"ProcedureStore\". The confusion is this: our Regions also have an internal structure called a \"Store\".\nMaybe o.a.h.h.master.store should now be called o.a.h.h.master.region. This class is apparently just a delegate to the region instance. Maybe we can rename LocalRegion to MasterRegion, do away with this LocalStore, replace it with a MasterRegionFactory, and let the caller invoke methods directly on the MasterRegion.", "author": "ndimiduk", "createdAt": "2020-05-29T23:38:34Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/store/LocalStore.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.store;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hbase.Server;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.Get;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.Scan;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.regionserver.HRegion.FlushResult;\n+import org.apache.hadoop.hbase.regionserver.RegionScanner;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.yetus.audience.InterfaceAudience;\n+\n+import org.apache.hbase.thirdparty.com.google.common.annotations.VisibleForTesting;\n+\n+/**\n+ * Used for storing data at master side. The data will be stored in a {@link LocalRegion}.\n+ */\n+@InterfaceAudience.Private\n+public final class LocalStore {", "originalCommit": "162da681072c87678a4dc9a81b1d868308ffc871", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4NjE0NQ==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r432786145", "bodyText": "Sounds fine.\nLet me open a new issue for this.", "author": "Apache9", "createdAt": "2020-05-29T23:54:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzExNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4NjU1OA==", "url": "https://github.com/apache/hbase/pull/1753#discussion_r432786558", "bodyText": "https://issues.apache.org/jira/browse/HBASE-24474", "author": "Apache9", "createdAt": "2020-05-29T23:57:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc4MzExNQ=="}], "type": "inlineReview"}]}