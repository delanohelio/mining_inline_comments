{"pr_number": 1446, "pr_title": "HBASE-23723 Ensure MOB compaction works in optimized mode after snapshot clone", "pr_createdAt": "2020-04-07T07:07:41Z", "pr_url": "https://github.com/apache/hbase/pull/1446", "timeline": [{"oid": "1de5967d934083d2c7e1aee862ef77cc1ce69975", "url": "https://github.com/apache/hbase/commit/1de5967d934083d2c7e1aee862ef77cc1ce69975", "message": "HBASE-23723 Reorganize MOB compaction tests for more reuse.", "committedDate": "2020-04-07T07:03:48Z", "type": "commit"}, {"oid": "4ba9e30e217d6c482e06c86fe156fb32c746e5e9", "url": "https://github.com/apache/hbase/commit/4ba9e30e217d6c482e06c86fe156fb32c746e5e9", "message": "HBASE-23723 Add a test for mob compaction after a snapshot clone.", "committedDate": "2020-04-07T07:03:49Z", "type": "commit"}, {"oid": "22508db856511a08d278591ff647f91e88e5b5a7", "url": "https://github.com/apache/hbase/commit/22508db856511a08d278591ff647f91e88e5b5a7", "message": "HBASE-23723 note the original table used to write a given mob hfile and use that to find it later.", "committedDate": "2020-04-07T07:03:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NDIyNA==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r404584224", "bodyText": "This file is a rename of TestMobCompactionBase that's then combined with TestMobCompactionRegularMode.java. I'm not sure why the github UI doesn't show it as that. my local git client can see it.", "author": "busbey", "createdAt": "2020-04-07T07:11:41Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobCompactionWithDefaults.java", "diffHunk": "@@ -0,0 +1,335 @@\n+/*\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.mob;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.stream.Collectors;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.HBaseTestingUtility;\n+import org.apache.hadoop.hbase.TableName;\n+import org.apache.hadoop.hbase.client.Admin;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\n+import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\n+import org.apache.hadoop.hbase.client.CompactionState;\n+import org.apache.hadoop.hbase.client.Put;\n+import org.apache.hadoop.hbase.client.Result;\n+import org.apache.hadoop.hbase.client.ResultScanner;\n+import org.apache.hadoop.hbase.client.Table;\n+import org.apache.hadoop.hbase.client.TableDescriptor;\n+import org.apache.hadoop.hbase.client.TableDescriptorBuilder;\n+import org.apache.hadoop.hbase.testclassification.LargeTests;\n+import org.apache.hadoop.hbase.util.Bytes;\n+import org.apache.hadoop.hbase.util.RegionSplitter;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TestName;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+  * Mob file compaction base test.\n+  * 1. Enables batch mode for regular MOB compaction,\n+  *    Sets batch size to 7 regions. (Optional)\n+  * 2. Disables periodic MOB compactions, sets minimum age to archive to 10 sec\n+  * 3. Creates MOB table with 20 regions\n+  * 4. Loads MOB data (randomized keys, 1000 rows), flushes data.\n+  * 5. Repeats 4. two more times\n+  * 6. Verifies that we have 20 *3 = 60 mob files (equals to number of regions x 3)\n+  * 7. Runs major MOB compaction.\n+  * 8. Verifies that number of MOB files in a mob directory is 20 x4 = 80\n+  * 9. Waits for a period of time larger than minimum age to archive\n+  * 10. Runs Mob cleaner chore\n+  * 11 Verifies that number of MOB files in a mob directory is 20.\n+  * 12 Runs scanner and checks all 3 * 1000 rows.\n+ */\n+@SuppressWarnings(\"deprecation\")\n+@Category(LargeTests.class)\n+public class TestMobCompactionWithDefaults {", "originalCommit": "22508db856511a08d278591ff647f91e88e5b5a7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTUzOTcxNA==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405539714", "bodyText": "my bad leaving this cruft in. I'll add another commit that cleans this out.", "author": "busbey", "createdAt": "2020-04-08T13:49:50Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java", "diffHunk": "@@ -280,7 +283,11 @@ protected void finalizeWriter(StoreFileWriter writer, long cacheFlushSeqNum,\n     // The hfile is current up to and including cacheFlushSeqNum.\n     status.setStatus(\"Flushing \" + store + \": appending metadata\");\n     writer.appendMetadata(cacheFlushSeqNum, false);\n-    writer.appendMobMetadata(mobRefSet.get());\n+    //writer.appendMobMetadata(ImmutableSetMultimap.builder<TableName, String>().putAll(store.getTableName(),", "originalCommit": "22508db856511a08d278591ff647f91e88e5b5a7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3baa8e9441cb49ff59a4e33b8d9eb38996a45f1b", "url": "https://github.com/apache/hbase/commit/3baa8e9441cb49ff59a4e33b8d9eb38996a45f1b", "message": "HBASE-23723 checkstyle / javadoc cleanup courtesy qabot feedback.", "committedDate": "2020-04-08T14:06:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NTQ4Ng==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405695486", "bodyText": "This is potentially a flakey test under load. Probably do an assert of the number of MOB files/flushes before running the MOB compaction. We could retry in a loop until we reach the required number of files by waiting until the flushes are done?", "author": "esteban", "createdAt": "2020-04-08T17:33:05Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobCompactionWithDefaults.java", "diffHunk": "@@ -152,49 +167,102 @@ private void loadData(int num) {\n   public void tearDown() throws Exception {\n     admin.disableTable(tableDescriptor.getTableName());\n     admin.deleteTable(tableDescriptor.getTableName());\n-    HTU.shutdownMiniCluster();\n   }\n \n-\n+  @Test\n   public void baseTestMobFileCompaction() throws InterruptedException, IOException {\n+    LOG.info(\"MOB compaction \" + description() + \" started\");\n+    loadAndFlushThreeTimes(rows, table, famStr);", "originalCommit": "1de5967d934083d2c7e1aee862ef77cc1ce69975", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcxMjUxMw==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405712513", "bodyText": "The implementation of loadAndFlushThreeTimes includes an assertion on the number of generated files already.", "author": "busbey", "createdAt": "2020-04-08T18:02:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NTQ4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcxMzYxNA==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405713614", "bodyText": "and it looks like the implementation also waits for the flushes to be done before doing that check. (The call to Admin.flush is synchronous.)", "author": "busbey", "createdAt": "2020-04-08T18:04:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NTQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NjQ4MA==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405696480", "bodyText": "Do we rely on the test duration limit or can we add a time limit for the compaction to finish?", "author": "esteban", "createdAt": "2020-04-08T17:34:46Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobCompactionWithDefaults.java", "diffHunk": "@@ -152,49 +167,102 @@ private void loadData(int num) {\n   public void tearDown() throws Exception {\n     admin.disableTable(tableDescriptor.getTableName());\n     admin.deleteTable(tableDescriptor.getTableName());\n-    HTU.shutdownMiniCluster();\n   }\n \n-\n+  @Test\n   public void baseTestMobFileCompaction() throws InterruptedException, IOException {\n+    LOG.info(\"MOB compaction \" + description() + \" started\");\n+    loadAndFlushThreeTimes(rows, table, famStr);\n+    mobCompact(tableDescriptor, familyDescriptor);\n+    assertEquals(\"Should have 4 MOB files per region due to 3xflush + compaction.\", numRegions * 4,\n+        getNumberOfMobFiles(table, famStr));\n+    cleanupAndVerifyCounts(table, famStr, 3*rows);\n+    LOG.info(\"MOB compaction \" + description() + \" finished OK\");\n+  }\n \n+  protected void loadAndFlushThreeTimes(int rows, TableName table, String family)\n+      throws IOException {\n+    final long start = getNumberOfMobFiles(table, family);\n     // Load and flush data 3 times\n-    loadData(rows);\n-    loadData(rows);\n-    loadData(rows);\n-    long num = getNumberOfMobFiles(conf, table.getName(), new String(fam));\n-    assertEquals(numRegions * 3, num);\n-    // Major MOB compact\n-    mobCompact(admin, tableDescriptor, familyDescriptor);\n-    // wait until compaction is complete\n-    while (admin.getCompactionState(tableDescriptor.getTableName()) != CompactionState.NONE) {\n+    loadData(table, rows);\n+    loadData(table, rows);\n+    loadData(table, rows);\n+    assertEquals(\"Should have 3 more mob files per region from flushing.\", start +  numRegions * 3,\n+        getNumberOfMobFiles(table, family));\n+  }\n+\n+  protected String description() {\n+    return \"regular mode\";\n+  }\n+\n+  protected void enableCompactions() throws IOException {\n+    final List<String> serverList = admin.getRegionServers().stream().map(sn -> sn.getServerName())\n+          .collect(Collectors.toList());\n+    admin.compactionSwitch(true, serverList);\n+  }\n+\n+  protected void disableCompactions() throws IOException {\n+    final List<String> serverList = admin.getRegionServers().stream().map(sn -> sn.getServerName())\n+          .collect(Collectors.toList());\n+    admin.compactionSwitch(false, serverList);\n+  }\n+\n+  /**\n+   * compact the given table and return once it is done.\n+   * should presume compactions are disabled when called.\n+   * should ensure compactions are disabled before returning.\n+   */\n+  protected void mobCompact(TableDescriptor tableDescriptor,\n+      ColumnFamilyDescriptor familyDescriptor) throws IOException, InterruptedException {\n+    LOG.debug(\"Major compact MOB table \" + tableDescriptor.getTableName());\n+    enableCompactions();\n+    mobCompactImpl(tableDescriptor, familyDescriptor);\n+    waitUntilCompactionIsComplete(tableDescriptor.getTableName());\n+    disableCompactions();\n+  }\n+\n+  /**\n+   * Call the API for compaction specific to the test set.\n+   * should not wait for compactions to finish.\n+   * may assume compactions are enabled when called.\n+   */\n+  protected void mobCompactImpl(TableDescriptor tableDescriptor,\n+      ColumnFamilyDescriptor familyDescriptor) throws IOException, InterruptedException {\n+    admin.majorCompact(tableDescriptor.getTableName(), familyDescriptor.getName());\n+  }\n+\n+  protected void waitUntilCompactionIsComplete(TableName table)", "originalCommit": "1de5967d934083d2c7e1aee862ef77cc1ce69975", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcxMTEyNw==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405711127", "bodyText": "We have a test duration limit, so it didn't seem worth adding the complexity of another timeout within the test.", "author": "busbey", "createdAt": "2020-04-08T17:59:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NjQ4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc0NTI1Nw==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405745257", "bodyText": "Sounds good, we can rely on the test timeout for now.", "author": "esteban", "createdAt": "2020-04-08T18:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NjQ4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5OTEyNw==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405699127", "bodyText": "Does it matter if we don't do this in a finally block if we get the RTE from above?", "author": "esteban", "createdAt": "2020-04-08T17:39:25Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreCompactor.java", "diffHunk": "@@ -190,34 +192,71 @@ public DefaultMobStoreCompactor(Configuration conf, HStore store) {\n     // Check if I/O optimized MOB compaction\n     if (ioOptimizedMode) {\n       if (request.isMajor() && request.getPriority() == HStore.PRIORITY_USER) {\n-        Path mobDir =\n-            MobUtils.getMobFamilyPath(conf, store.getTableName(), store.getColumnFamilyName());\n-        List<Path> mobFiles = MobUtils.getReferencedMobFiles(request.getFiles(), mobDir);\n-        //reset disableIO\n-        disableIO.set(Boolean.FALSE);\n-        if (mobFiles.size() > 0) {\n-          calculateMobLengthMap(mobFiles);\n+        try {\n+          final SetMultimap<TableName, String> mobRefs = request.getFiles().stream()\n+              .map(file -> {\n+                byte[] value = file.getMetadataValue(HStoreFile.MOB_FILE_REFS);\n+                ImmutableSetMultimap.Builder<TableName, String> builder;\n+                if (value == null) {\n+                  builder = ImmutableSetMultimap.builder();\n+                } else {\n+                  try {\n+                    builder = MobUtils.deserializeMobFileRefs(value);\n+                  } catch (RuntimeException exception) {\n+                     throw new RuntimeException(\"failure getting mob references for hfile \" + file,\n+                         exception);\n+                  }\n+                }\n+                return builder;\n+              }).reduce((a, b) -> a.putAll(b.build())).orElseGet(ImmutableSetMultimap::builder)\n+              .build();\n+          //reset disableIO\n+          disableIO.set(Boolean.FALSE);", "originalCommit": "22508db856511a08d278591ff647f91e88e5b5a7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcyMTQ0Ng==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405721446", "bodyText": "as far as I can tell, yes this is fine. we're setting it to false in prep for the call right after to calculateMobLengthMap where we check each of the file names to see if we need to switch the flag.\nIf instead we hit the RuntimeException from deserializing then we shouldn't make that call to calculateMobLengthMap and so we don't need to mess with the disableIO flag at all.", "author": "busbey", "createdAt": "2020-04-08T18:17:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5OTEyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwMDQ2Mw==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405700463", "bodyText": "same as above?", "author": "esteban", "createdAt": "2020-04-08T17:41:39Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/mob/DefaultMobStoreFlusher.java", "diffHunk": "@@ -280,7 +283,11 @@ protected void finalizeWriter(StoreFileWriter writer, long cacheFlushSeqNum,\n     // The hfile is current up to and including cacheFlushSeqNum.\n     status.setStatus(\"Flushing \" + store + \": appending metadata\");\n     writer.appendMetadata(cacheFlushSeqNum, false);\n-    writer.appendMobMetadata(mobRefSet.get());\n+    //writer.appendMobMetadata(ImmutableSetMultimap.builder<TableName, String>().putAll(store.getTableName(),\n+    //    mobRefSet.get()).build());", "originalCommit": "22508db856511a08d278591ff647f91e88e5b5a7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcyNDA2Mg==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405724062", "bodyText": "sorry,  I can't seem to retrace the context for this comment. could you take a look at the most recent change set and see if you have a concern still?", "author": "busbey", "createdAt": "2020-04-08T18:21:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwMDQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc0NTk1MQ==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405745951", "bodyText": "It was just about the 2 commented lines, unless there is something else to do, those shouldn't be there.", "author": "esteban", "createdAt": "2020-04-08T18:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwMDQ2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc0OTczNQ==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405749735", "bodyText": "ah. yep I took care of making sure no commented out lines in the checkstyle/javadoc commit.", "author": "busbey", "createdAt": "2020-04-08T19:05:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwMDQ2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwNDY2Mg==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405704662", "bodyText": "Wait and check if snapshot is done?", "author": "esteban", "createdAt": "2020-04-08T17:48:56Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/mob/TestMobCompactionWithDefaults.java", "diffHunk": "@@ -180,6 +180,42 @@ public void baseTestMobFileCompaction() throws InterruptedException, IOException\n     LOG.info(\"MOB compaction \" + description() + \" finished OK\");\n   }\n \n+  @Test\n+  public void testMobFileCompactionAfterSnapshotClone() throws InterruptedException, IOException {\n+    final TableName clone = TableName.valueOf(test.getMethodName() + \"-clone\");\n+    LOG.info(\"MOB compaction of cloned snapshot, \" + description() + \" started\");\n+    loadAndFlushThreeTimes(rows, table, famStr);\n+    LOG.debug(\"Taking snapshot and cloning table {}\", table);\n+    admin.snapshot(test.getMethodName(), table);\n+    admin.cloneSnapshot(test.getMethodName(), clone);", "originalCommit": "4ba9e30e217d6c482e06c86fe156fb32c746e5e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcxODEyMQ==", "url": "https://github.com/apache/hbase/pull/1446#discussion_r405718121", "bodyText": "The Admin.snpashot and Admin.cloneSnasphot calls are both synchronous. they're only supposed to return if their operations are successful. The should throw an exception if something goes wrong.", "author": "busbey", "createdAt": "2020-04-08T18:11:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTcwNDY2Mg=="}], "type": "inlineReview"}]}