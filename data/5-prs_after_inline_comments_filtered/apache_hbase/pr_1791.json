{"pr_number": 1791, "pr_title": "HBASE-23202 ExportSnapshot (import) will fail if copying files to roo\u2026", "pr_createdAt": "2020-05-27T17:35:02Z", "pr_url": "https://github.com/apache/hbase/pull/1791", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r431403678", "bodyText": "Could this be handled better? It seems that in the event of an exception, the entirety of the in-progress snapshot would excluded.\nLogging the exception doesn't tell us anything useful because the SnapshotDescription isn't party to the message. Maybe we should log the snapshot name and table name. At WARN level?", "author": "ndimiduk", "createdAt": "2020-05-27T19:50:19Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java", "diffHunk": "@@ -251,6 +260,25 @@ private void refreshCache() throws IOException {\n     this.snapshots.putAll(newSnapshots);\n   }\n \n+  @VisibleForTesting\n+  List<String> getSnapshotsInProgress() throws IOException {\n+    List<String> snapshotInProgress = Lists.newArrayList();\n+    // only add those files to the cache, but not to the known snapshots\n+    FileStatus[] snapshotsInProgress = CommonFSUtils.listStatus(fs,\n+      new Path(snapshotDir, SnapshotDescriptionUtils.SNAPSHOT_TMP_DIR_NAME));\n+\n+    if (!ArrayUtils.isEmpty(snapshotsInProgress)) {\n+      for (FileStatus snapshot : snapshotsInProgress) {\n+        try {\n+          snapshotInProgress.addAll(fileInspector.filesUnderSnapshot(snapshot.getPath()));\n+        } catch (CorruptedSnapshotException cse) {\n+          LOG.debug(\"Corrupted in-progress snapshot file exception, ignored.\", cse);", "originalCommit": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ2NDQzMg==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r431464432", "bodyText": "It is hard to say. The CorruptedSnapshotException will only be thrown out when it reads a corrupted .snapshotinfo file. There are two cases, one is normal, which .snapshotinfo is being written and it reads incomplete one; the other is that it is a real corrupted .snapshotinfo. The original code assumes the first case (maybe in reality, there are more first cases than the second one). Change it to info level? The exception has the following info\nthrow new CorruptedSnapshotException(\"Couldn't read snapshot info from:\" + snapshotInfo, e);\n\nIt is the path of .snapshotinfo, it has snapshot name embedded in the path (does not have table name). Let me see if table name can be added.", "author": "huaxiangsun", "createdAt": "2020-05-27T21:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ2OTk2NA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r431469964", "bodyText": "It will be hard to put table name here. For an example, in the context of ExportSnapshot job, at the destination cluster, the .snapshotinfo is written to tmp directory first. There is no table existing yet, table may be cloned from snapshot after ExportSnapshot job is done.", "author": "huaxiangsun", "createdAt": "2020-05-27T22:06:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4NjY5MQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r431486691", "bodyText": "CorruptedSnapshotException contains a copy of SnapshotDescription. Where this is logged, instead of logging the exception, it can grab the snaps tho info out of the description field to build a more meaningful log message.\nI don't know about the log level. I guess it depends on if you think this is a really severe problem or not. If not, debug is fine. If it's the only sign an operator has of a bad problem, or it should be info or warn.", "author": "ndimiduk", "createdAt": "2020-05-27T22:51:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIyMzQ5Nw==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434223497", "bodyText": "yeah, it has multiple constructors, in this specific case, there is no SnapshotDescription provided (reading SnapshotDescription results into IOException due to corrupted/missing files). I changed log level from debug to info", "author": "huaxiangsun", "createdAt": "2020-06-02T23:10:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQwMzY3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1MjU0Ng==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432052546", "bodyText": "Please use https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java#L198 to get the temporary directory. Currently, this will break https://issues.apache.org/jira/browse/HBASE-21098.\nIt's probably worth adding a similar test with the config value for working snapshot dir set to avoid any regressions.", "author": "z-york", "createdAt": "2020-05-28T18:56:40Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotFileCache.java", "diffHunk": "@@ -251,6 +260,25 @@ private void refreshCache() throws IOException {\n     this.snapshots.putAll(newSnapshots);\n   }\n \n+  @VisibleForTesting\n+  List<String> getSnapshotsInProgress() throws IOException {\n+    List<String> snapshotInProgress = Lists.newArrayList();\n+    // only add those files to the cache, but not to the known snapshots\n+    FileStatus[] snapshotsInProgress = CommonFSUtils.listStatus(fs,\n+      new Path(snapshotDir, SnapshotDescriptionUtils.SNAPSHOT_TMP_DIR_NAME));", "originalCommit": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA5NDE1MA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432094150", "bodyText": "Thanks! Let me check it out.", "author": "huaxiangsun", "createdAt": "2020-05-28T20:07:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1MjU0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE2OTY3NA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434169674", "bodyText": "This is a very good catch, I updated the code and added a new set of tests to cover snapshot_working_dir to be on a different filesystem than rootdir.", "author": "huaxiangsun", "createdAt": "2020-06-02T20:54:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1MjU0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NDQ0MQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432054441", "bodyText": "What is this testing?", "author": "z-york", "createdAt": "2020-05-28T19:00:02Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -156,7 +164,29 @@ public void testCorruptedDataManifest() throws IOException {\n     builder.consolidate();\n     builder.corruptDataManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {\n+      cache.getSnapshotsInProgress();\n+    } finally {\n+      fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n           TEST_UTIL.getConfiguration()), true);\n+    }\n+  }\n+\n+  @Test\n+  public void testMissedTmpSnapshot() throws IOException {\n+    SnapshotTestingUtils.SnapshotMock snapshotMock =\n+        new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);\n+    SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2(\n+        SNAPSHOT_NAME_STR, TABLE_NAME_STR);\n+    builder.addRegionV2();\n+    builder.missOneRegionSnapshotFile();\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    cache.getSnapshotsInProgress();\n+    assertTrue(fs.exists(builder.getSnapshotsDir()));", "originalCommit": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxODA2MQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434218061", "bodyText": "It tests missing snapshot manifests will throw out CorruptedSnapshotException and it is handled in getSnapshotsInProgress().", "author": "huaxiangsun", "createdAt": "2020-06-02T22:53:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NDQ0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxODE5Ng==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434218196", "bodyText": "A separate case for corrupted manifest files.", "author": "huaxiangsun", "createdAt": "2020-06-02T22:53:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NDQ0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432055822", "bodyText": "Is this testing that we don't throw an exception when the snapshot is corrupted?", "author": "z-york", "createdAt": "2020-05-28T19:02:31Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -137,8 +138,15 @@ public void testCorruptedRegionManifest() throws IOException {\n     builder.addRegionV2();\n     builder.corruptOneRegionManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir, TEST_UTIL.getConfiguration()),\n-      true);\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {\n+      cache.getSnapshotsInProgress();", "originalCommit": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMzgzNQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434213835", "bodyText": "Going through the context, it tests in case of corrupted snapshot manifest file, it throws out CorruptedSnapshotException and it is handled in getSnapshotsInProgress().", "author": "huaxiangsun", "createdAt": "2020-06-02T22:40:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1ODYyMQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434258621", "bodyText": "In this case, shouldn't the try{} be removed (since it might mask a true failure)?", "author": "z-york", "createdAt": "2020-06-03T01:21:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0NDUyMQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434744521", "bodyText": "This try{} finally {} does not catch any exception, it is just used for deleting directory created by the test. If getSnapshotsInProgress() throws out any exception, it will fail the test.", "author": "huaxiangsun", "createdAt": "2020-06-03T17:43:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1NTgyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1OTkwNA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r432059904", "bodyText": "This tests the case where getSnapshotsInProgress is and isn't called, but we should also directly test the getSnapshotsInProgress method to test the case where a file is correctly included if the file is in progress (and the negative case).", "author": "z-york", "createdAt": "2020-05-28T19:10:07Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java", "diffHunk": "@@ -133,6 +145,71 @@ public void testCacheUpdatedWhenLastModifiedOfSnapDirNotUpdated() throws IOExcep\n     createAndTestSnapshotV2(cache, \"snapshot2v2\", true, false, true);\n   }\n \n+  @Test\n+  public void testWeNeverCacheTmpDirAndLoadIt() throws Exception {\n+\n+    final AtomicInteger count = new AtomicInteger(0);\n+    // don't refresh the cache unless we tell it to\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles()) {\n+      @Override\n+      List<String> getSnapshotsInProgress()\n+              throws IOException {\n+        List<String> result = super.getSnapshotsInProgress();\n+        count.incrementAndGet();\n+        return result;\n+      }\n+\n+      @Override public void triggerCacheRefreshForTesting() {\n+        super.triggerCacheRefreshForTesting();\n+      }\n+    };\n+\n+    SnapshotMock.SnapshotBuilder complete =\n+        createAndTestSnapshotV1(cache, \"snapshot\", false, false, false);\n+\n+    int countBeforeCheck = count.get();\n+\n+    CommonFSUtils.logFileSystemState(fs, rootDir, LOG);\n+\n+    List<FileStatus> allStoreFiles = getStoreFilesForSnapshot(complete);\n+    Iterable<FileStatus> deletableFiles = cache.getUnreferencedFiles(allStoreFiles, null);\n+    assertTrue(Iterables.isEmpty(deletableFiles));\n+    // no need for tmp dir check as all files are accounted for.\n+    assertEquals(0, count.get() - countBeforeCheck);\n+\n+    // add a random file to make sure we refresh\n+    FileStatus randomFile = mockStoreFile(UTIL.getRandomUUID().toString());\n+    allStoreFiles.add(randomFile);\n+    deletableFiles = cache.getUnreferencedFiles(allStoreFiles, null);\n+    assertEquals(randomFile, Iterables.getOnlyElement(deletableFiles));\n+    assertEquals(1, count.get() - countBeforeCheck); // we check the tmp directory", "originalCommit": "059cdb1edfc7631067c820cfaa41ba8c2c7c3176", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMDI0NQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434210245", "bodyText": "The newly added cases in testLoadAndDelete()\n\ncreateAndTestSnapshotV1(cache, \"snapshot1b\", true, true, false);\ncreateAndTestSnapshotV2(cache, \"snapshot1a\", true, true, false);\ntest the case that files are correctly included for snapshot in progress.\nIs that not enough?", "author": "huaxiangsun", "createdAt": "2020-06-02T22:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA1OTkwNA=="}], "type": "inlineReview"}, {"oid": "6f1a191d329207916a3bdda10a99cf10681e4f23", "url": "https://github.com/apache/hbase/commit/6f1a191d329207916a3bdda10a99cf10681e4f23", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL", "committedDate": "2020-06-02T23:19:08Z", "type": "forcePushed"}, {"oid": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "url": "https://github.com/apache/hbase/commit/d42f46227f0d8f309e6db7534eed249dcc1407c5", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL", "committedDate": "2020-06-02T23:38:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NjczMA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434256730", "bodyText": "This should just be be fs because workingFs or fs could be passed in", "author": "z-york", "createdAt": "2020-06-03T01:13:40Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotHFileCleaner.java", "diffHunk": "@@ -93,12 +94,17 @@ public void setConf(final Configuration conf) {\n         DEFAULT_HFILE_CACHE_REFRESH_PERIOD);\n       final FileSystem fs = CommonFSUtils.getCurrentFileSystem(conf);\n       Path rootDir = CommonFSUtils.getRootDir(conf);\n-      cache = new SnapshotFileCache(fs, rootDir, cacheRefreshPeriod, cacheRefreshPeriod,\n-          \"snapshot-hfile-cleaner-cache-refresher\", new SnapshotFileCache.SnapshotFileInspector() {\n+      Path workingDir = SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir, conf);\n+      FileSystem workingFs = workingDir.getFileSystem(conf);\n+\n+      cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, cacheRefreshPeriod,\n+        cacheRefreshPeriod, \"snapshot-hfile-cleaner-cache-refresher\",\n+        new SnapshotFileCache.SnapshotFileInspector() {\n             @Override\n-            public Collection<String> filesUnderSnapshot(final Path snapshotDir)\n+            public Collection<String> filesUnderSnapshot(final FileSystem workingFs,", "originalCommit": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjIzOQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434772239", "bodyText": "Yeah, let me change it back to fs, workingFs is misleading.", "author": "huaxiangsun", "createdAt": "2020-06-03T18:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NjczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NzcyMw==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434257723", "bodyText": "Hmm, weird that this is duplicated. +1 on merging/removing one. Does it make more sense to be part of TakeSnapshotHandler? Why does it need to be in SnapshotDescriptionUtils?", "author": "z-york", "createdAt": "2020-06-03T01:17:55Z", "path": "hbase-server/src/main/java/org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.java", "diffHunk": "@@ -383,25 +385,38 @@ public static SnapshotDescription readSnapshotInfo(FileSystem fs, Path snapshotD\n   }\n \n   /**\n-   * Move the finished snapshot to its final, publicly visible directory - this marks the snapshot\n-   * as 'complete'.\n-   * @param snapshot description of the snapshot being tabken\n-   * @param rootdir root directory of the hbase installation\n-   * @param workingDir directory where the in progress snapshot was built\n-   * @param fs {@link FileSystem} where the snapshot was built\n-   * @throws org.apache.hadoop.hbase.snapshot.SnapshotCreationException if the\n-   * snapshot could not be moved\n+   * Commits the snapshot process by moving the working snapshot\n+   * to the finalized filepath\n+   *\n+   * @param snapshotDir The file path of the completed snapshots\n+   * @param workingDir  The file path of the in progress snapshots\n+   * @param fs The file system of the completed snapshots\n+   * @param workingDirFs The file system of the in progress snapshots\n+   * @param conf Configuration\n+   *\n+   * @throws SnapshotCreationException if the snapshot could not be moved\n    * @throws IOException the filesystem could not be reached\n    */\n-  public static void completeSnapshot(SnapshotDescription snapshot, Path rootdir, Path workingDir,\n-      FileSystem fs) throws SnapshotCreationException, IOException {\n-    Path finishedDir = getCompletedSnapshotDir(snapshot, rootdir);\n-    LOG.debug(\"Snapshot is done, just moving the snapshot from \" + workingDir + \" to \"\n-        + finishedDir);\n-    if (!fs.rename(workingDir, finishedDir)) {\n-      throw new SnapshotCreationException(\n-          \"Failed to move working directory(\" + workingDir + \") to completed directory(\"\n-              + finishedDir + \").\", ProtobufUtil.createSnapshotDesc(snapshot));\n+  public static void completeSnapshot(Path snapshotDir, Path workingDir, FileSystem fs,", "originalCommit": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2OTg2NQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434769865", "bodyText": "completeSnapshot() is being used by some other test classes besides TakeSnapshotHandler. What it does is doing a few checks and do a rename/copy ( a static utility method). SnapshotDescriptionUtils is a class which aggregates set of utility methods, though the name is kind of misleading, it already has a set of utility methods beyond  SnapshotDescription. Putting a static utility method in TakeSnapshotHandler does not seem a good fit to me, what do you think?", "author": "huaxiangsun", "createdAt": "2020-06-03T18:27:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NzcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDkxMjE3OA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434912178", "bodyText": "I think this is okay for now... maybe in the future we can pull these non-snapshotDescription utility methods to a new file.", "author": "z-york", "createdAt": "2020-06-03T23:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1NzcyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1ODg4OQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434258889", "bodyText": "Same here", "author": "z-york", "createdAt": "2020-06-03T01:22:59Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotHFileCleaner.java", "diffHunk": "@@ -148,15 +156,37 @@ public void testCorruptedRegionManifest() throws IOException {\n   @Test\n   public void testCorruptedDataManifest() throws IOException {\n     SnapshotTestingUtils.SnapshotMock\n-        snapshotMock = new SnapshotTestingUtils.SnapshotMock(TEST_UTIL.getConfiguration(), fs, rootDir);\n+        snapshotMock = new SnapshotTestingUtils.SnapshotMock(conf, fs, rootDir);\n     SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder = snapshotMock.createSnapshotV2(\n         SNAPSHOT_NAME_STR, TABLE_NAME_STR);\n     builder.addRegionV2();\n     // consolidate to generate a data.manifest file\n     builder.consolidate();\n     builder.corruptDataManifest();\n \n-    fs.delete(SnapshotDescriptionUtils.getWorkingSnapshotDir(rootDir,\n+    long period = Long.MAX_VALUE;\n+    SnapshotFileCache cache = new SnapshotFileCache(conf, period, 10000000,\n+        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    try {", "originalCommit": "d42f46227f0d8f309e6db7534eed249dcc1407c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0NDcwMQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r434744701", "bodyText": "This try{} finally {} does not catch any exception, it is just used for deleting directory created by the test. If getSnapshotsInProgress() throws out any exception, it will fail the test.", "author": "huaxiangsun", "createdAt": "2020-06-03T17:44:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDI1ODg4OQ=="}], "type": "inlineReview"}, {"oid": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "url": "https://github.com/apache/hbase/commit/4375fec4ee34507d64b622a3985b7e19f9a9727e", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL", "committedDate": "2020-06-03T18:39:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU3NzMyMw==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435577323", "bodyText": "I missed the reason for changing this test parameter. By the comment there between method invocations, it seems repetition of the name, a.k.a, the directory, \"snapshot1\" was intentional. Why have two different parameters? Doesn't that negate the purpose of this test?", "author": "ndimiduk", "createdAt": "2020-06-04T22:02:11Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCache.java", "diffHunk": "@@ -85,32 +106,34 @@ public void cleanupFiles() throws Exception {\n \n   @Test\n   public void testLoadAndDelete() throws IOException {\n-    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, PERIOD, 10000000,\n-        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, PERIOD,\n+      10000000, \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n \n     createAndTestSnapshotV1(cache, \"snapshot1a\", false, true, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1b\", true, true, false);\n \n     createAndTestSnapshotV2(cache, \"snapshot2a\", false, true, false);\n+    createAndTestSnapshotV2(cache, \"snapshot2b\", true, true, false);\n   }\n \n   @Test\n   public void testReloadModifiedDirectory() throws IOException {\n-    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, PERIOD, 10000000,\n-        \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n+    SnapshotFileCache cache = new SnapshotFileCache(fs, rootDir, workingFs, workingDir, PERIOD,\n+      10000000, \"test-snapshot-file-cache-refresh\", new SnapshotFiles());\n \n-    createAndTestSnapshotV1(cache, \"snapshot1\", false, true, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1v1\", false, true, false);\n     // now delete the snapshot and add a file with a different name\n-    createAndTestSnapshotV1(cache, \"snapshot1\", false, false, false);\n+    createAndTestSnapshotV1(cache, \"snapshot1v2\", false, false, false);", "originalCommit": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwNjk3NA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435606974", "bodyText": "Oh, probably an over-engineering change I made, will read the comments and revert.", "author": "huaxiangsun", "createdAt": "2020-06-04T23:30:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU3NzMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMDExOA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435630118", "bodyText": "reverted it back.", "author": "huaxiangsun", "createdAt": "2020-06-05T00:37:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU3NzMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MDI4MA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435580280", "bodyText": "nit: you're mixing java.nio and Hadoop APIs for building this path. I'm not quite sure, but maybe you want something like Paths.get(\".\", UUID.randomUUID().toString()).toAbsolutePath().toString()? I'm not sure where Paths.get(\"\") would drop you, but I assume it's the same as pwd.", "author": "ndimiduk", "createdAt": "2020-06-04T22:09:46Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCacheWithDifferentWorkingDir.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.snapshot;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.UUID;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;\n+import org.apache.hadoop.hbase.testclassification.LargeTests;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Test that we correctly reload the cache, filter directories, etc.\n+ * while the temporary directory is on a different file system than the root directory\n+ */\n+@Category({MasterTests.class, LargeTests.class})\n+public class TestSnapshotFileCacheWithDifferentWorkingDir extends TestSnapshotFileCache {\n+\n+  @ClassRule\n+  public static final HBaseClassTestRule CLASS_RULE =\n+    HBaseClassTestRule.forClass(TestSnapshotFileCacheWithDifferentWorkingDir.class);\n+\n+  protected static String TEMP_DIR =\n+    Paths.get(\"\").toAbsolutePath().toString() + Path.SEPARATOR + UUID.randomUUID().toString();", "originalCommit": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwNzQ5MA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435607490", "bodyText": "Hmm, I copied from an existing test case and did not look at it very closely, take a close look.", "author": "huaxiangsun", "createdAt": "2020-06-04T23:32:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MDI4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMjMwOQ==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435632309", "bodyText": "The purpose to use java.nio is get a different fileystem (local) than hdfs in this case to test out the snapshot working_dir.", "author": "huaxiangsun", "createdAt": "2020-06-05T00:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MDI4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTAyMw==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435581023", "bodyText": "nit: it would require a good bit of refactor, but I find that test case inheritance is really unreliable to maintain. Maybe better to make TestSnapshotFileCache a parameterized test.", "author": "ndimiduk", "createdAt": "2020-06-04T22:11:35Z", "path": "hbase-server/src/test/java/org/apache/hadoop/hbase/master/snapshot/TestSnapshotFileCacheWithDifferentWorkingDir.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.hbase.master.snapshot;\n+\n+import java.io.File;\n+import java.nio.file.Paths;\n+import java.util.UUID;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.hbase.HBaseClassTestRule;\n+import org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;\n+import org.apache.hadoop.hbase.testclassification.LargeTests;\n+import org.apache.hadoop.hbase.testclassification.MasterTests;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.experimental.categories.Category;\n+\n+/**\n+ * Test that we correctly reload the cache, filter directories, etc.\n+ * while the temporary directory is on a different file system than the root directory\n+ */\n+@Category({MasterTests.class, LargeTests.class})\n+public class TestSnapshotFileCacheWithDifferentWorkingDir extends TestSnapshotFileCache {", "originalCommit": "4375fec4ee34507d64b622a3985b7e19f9a9727e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYwODAyMA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r435608020", "bodyText": "Let me try to change it to a parameterized test.", "author": "huaxiangsun", "createdAt": "2020-06-04T23:32:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTAyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjg4ODIxMA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r436888210", "bodyText": "I created HBASE-24522 to address this comment. Busy at this moment for other priorities, will go back to this later.\nHope it is ok with you, @ndimiduk. I addressed your other two comments, and going to push the patch after it passes the tests.", "author": "huaxiangsun", "createdAt": "2020-06-08T17:52:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTAyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcxNzAyNA==", "url": "https://github.com/apache/hbase/pull/1791#discussion_r437717024", "bodyText": "Yep, no problem. Thanks for addressing my other concerns :)", "author": "ndimiduk", "createdAt": "2020-06-09T20:57:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTU4MTAyMw=="}], "type": "inlineReview"}, {"oid": "ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "url": "https://github.com/apache/hbase/commit/ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL", "committedDate": "2020-06-08T17:44:46Z", "type": "commit"}, {"oid": "ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "url": "https://github.com/apache/hbase/commit/ede033b26c172a6ea6b07e6e0d4e2a8e37eb765b", "message": "HBASE-23202 ExportSnapshot (import) will fail if copying files to root directory takes longer than cleaner TTL", "committedDate": "2020-06-08T17:44:46Z", "type": "forcePushed"}]}