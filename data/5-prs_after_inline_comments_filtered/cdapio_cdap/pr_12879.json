{"pr_number": 12879, "pr_title": "(CDAP-17439) Added runtime support for Hadoop + Spark 3", "pr_createdAt": "2020-12-04T00:48:06Z", "pr_url": "https://github.com/cdapio/cdap/pull/12879", "timeline": [{"oid": "0d48e0dcd22024d68a7f29993f8d3be85e270213", "url": "https://github.com/cdapio/cdap/commit/0d48e0dcd22024d68a7f29993f8d3be85e270213", "message": "(CDAP-17439) Added runtime support for Hadoop + Spark 3\n\nThis change added support for Hadoop 3 and Spark 3, yet maintaining compatibility with\nHadoop 2 and Spark 1 and Spark 2.\n\nHadoop YARN\n* Don\u2019t use YARN localization to expand program jar file due to YARN bug YARN-9591\n** In twill containers, expand the jar locally\n** In Spark, renames the jar to .zip before localization\n\nGuava depdendency\n* Add missing methods to the Guava library\n** Various missing Preconditions.checkArgument() methods\n** Various missing Preconditions.checkState() methods\n** MoreExecutors.directExecutor() method\n\nHadoop 3\n* Upgrade to Avro 1.8.2\n** SpecificData constructor becomes public\n* Remove usage of ConcurrentHashSet from the jetty library as Hadoop 3 uses an incompatible version, and CDAP shouldn\u2019t be using that library outside of the cdap-security module\n\nSpark 3\n* Use Reflection to alter SparkListenerApplicationStart event\n** Spark 2 and 3 are binary incompatible for that class\n\nAlso, there is some small refactoring to modernize the code to use the standard Java library instead of Guava", "committedDate": "2020-12-04T00:49:07Z", "type": "forcePushed"}, {"oid": "5b206a280a63a90086d2d9dbd7ba23c27768d2e3", "url": "https://github.com/cdapio/cdap/commit/5b206a280a63a90086d2d9dbd7ba23c27768d2e3", "message": "(CDAP-17439) Added runtime support for Hadoop + Spark 3\n\nThis change added support for Hadoop 3 and Spark 3, yet maintaining compatibility with\nHadoop 2 and Spark 1 and Spark 2.\n\nHadoop YARN\n* Don\u2019t use YARN localization to expand program jar file due to YARN bug YARN-9591\n** In twill containers, expand the jar locally\n** In Spark, renames the jar to .zip before localization\n\nGuava depdendency\n* Add missing methods to the Guava library\n** Various missing Preconditions.checkArgument() methods\n** Various missing Preconditions.checkState() methods\n** MoreExecutors.directExecutor() method\n\nHadoop 3\n* Upgrade to Avro 1.8.2\n** SpecificData constructor becomes public\n* Remove usage of ConcurrentHashSet from the jetty library as Hadoop 3 uses an incompatible version, and CDAP shouldn\u2019t be using that library outside of the cdap-security module\n\nSpark 3\n* Use Reflection to alter SparkListenerApplicationStart event\n** Spark 2 and 3 are binary incompatible for that class\n\nAlso, there is some small refactoring to modernize the code to use the standard Java library instead of Guava", "committedDate": "2020-12-04T06:13:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg2NzgyNA==", "url": "https://github.com/cdapio/cdap/pull/12879#discussion_r535867824", "bodyText": "Would be good to add more information here about why this is needed.", "author": "albertshau", "createdAt": "2020-12-04T06:32:36Z", "path": "cdap-common/src/main/java/io/cdap/cdap/common/lang/GuavaClassRewriter.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Copyright \u00a9 2020 Cask Data, Inc.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n+ * use this file except in compliance with the License. You may obtain a copy of\n+ * the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations under\n+ * the License.\n+ */\n+\n+package io.cdap.cdap.common.lang;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.util.concurrent.MoreExecutors;\n+import io.cdap.cdap.internal.asm.Methods;\n+import org.objectweb.asm.ClassReader;\n+import org.objectweb.asm.ClassVisitor;\n+import org.objectweb.asm.ClassWriter;\n+import org.objectweb.asm.Handle;\n+import org.objectweb.asm.MethodVisitor;\n+import org.objectweb.asm.Opcodes;\n+import org.objectweb.asm.Type;\n+import org.objectweb.asm.commons.GeneratorAdapter;\n+import org.objectweb.asm.commons.Method;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.lang.invoke.LambdaMetafactory;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.Executor;\n+import javax.annotation.Nullable;\n+\n+/**\n+ * A {@link ClassRewriter} for rewriting Guava library classes to add missing functions that are available in\n+ * later Guava library.", "originalCommit": "5b206a280a63a90086d2d9dbd7ba23c27768d2e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg3NzE1NA==", "url": "https://github.com/cdapio/cdap/pull/12879#discussion_r535877154", "bodyText": "Added more comments", "author": "chtyim", "createdAt": "2020-12-04T06:57:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTg2NzgyNA=="}], "type": "inlineReview"}, {"oid": "4570295c99bce9aab75fb2d1929193c7f777140c", "url": "https://github.com/cdapio/cdap/commit/4570295c99bce9aab75fb2d1929193c7f777140c", "message": "(CDAP-17439) Added runtime support for Hadoop + Spark 3\n\nThis change added support for Hadoop 3 and Spark 3, yet maintaining compatibility with\nHadoop 2 and Spark 1 and Spark 2.\n\nHadoop YARN\n* Don\u2019t use YARN localization to expand program jar file due to YARN bug YARN-9591\n** In twill containers, expand the jar locally\n** In Spark, renames the jar to .zip before localization\n\nGuava depdendency\n* Add missing methods to the Guava library\n** Various missing Preconditions.checkArgument() methods\n** Various missing Preconditions.checkState() methods\n** MoreExecutors.directExecutor() method\n\nHadoop 3\n* Upgrade to Avro 1.8.2\n** SpecificData constructor becomes public\n* Remove usage of ConcurrentHashSet from the jetty library as Hadoop 3 uses an incompatible version, and CDAP shouldn\u2019t be using that library outside of the cdap-security module\n\nSpark 3\n* Use Reflection to alter SparkListenerApplicationStart event\n** Spark 2 and 3 are binary incompatible for that class\n\nAlso, there is some small refactoring to modernize the code to use the standard Java library instead of Guava", "committedDate": "2020-12-04T06:57:06Z", "type": "commit"}, {"oid": "4570295c99bce9aab75fb2d1929193c7f777140c", "url": "https://github.com/cdapio/cdap/commit/4570295c99bce9aab75fb2d1929193c7f777140c", "message": "(CDAP-17439) Added runtime support for Hadoop + Spark 3\n\nThis change added support for Hadoop 3 and Spark 3, yet maintaining compatibility with\nHadoop 2 and Spark 1 and Spark 2.\n\nHadoop YARN\n* Don\u2019t use YARN localization to expand program jar file due to YARN bug YARN-9591\n** In twill containers, expand the jar locally\n** In Spark, renames the jar to .zip before localization\n\nGuava depdendency\n* Add missing methods to the Guava library\n** Various missing Preconditions.checkArgument() methods\n** Various missing Preconditions.checkState() methods\n** MoreExecutors.directExecutor() method\n\nHadoop 3\n* Upgrade to Avro 1.8.2\n** SpecificData constructor becomes public\n* Remove usage of ConcurrentHashSet from the jetty library as Hadoop 3 uses an incompatible version, and CDAP shouldn\u2019t be using that library outside of the cdap-security module\n\nSpark 3\n* Use Reflection to alter SparkListenerApplicationStart event\n** Spark 2 and 3 are binary incompatible for that class\n\nAlso, there is some small refactoring to modernize the code to use the standard Java library instead of Guava", "committedDate": "2020-12-04T06:57:06Z", "type": "forcePushed"}]}