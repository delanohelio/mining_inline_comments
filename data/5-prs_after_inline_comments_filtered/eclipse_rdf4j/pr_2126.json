{"pr_number": 2126, "pr_title": "GH-2121 group adds/removes together in sparql update sequence", "pr_createdAt": "2020-04-24T00:24:48Z", "pr_url": "https://github.com/eclipse/rdf4j/pull/2126", "timeline": [{"oid": "2ccb1ad12764bdd8a968a5975b563d9fcd12a2ae", "url": "https://github.com/eclipse/rdf4j/commit/2ccb1ad12764bdd8a968a5975b563d9fcd12a2ae", "message": "GH-2121 single INSERT/DELETE DATA per add/remove block", "committedDate": "2020-04-24T00:15:11Z", "type": "commit"}, {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490", "url": "https://github.com/eclipse/rdf4j/commit/3001f68987c2610d3cab6063818cd0c3e6c63490", "message": "GH-2121 create single INSERT/DELETE DATA per batch of triples\n\n- avoid having a INSERT/DELETE operation for each individual triple", "committedDate": "2020-04-24T00:26:45Z", "type": "commit"}, {"oid": "3001f68987c2610d3cab6063818cd0c3e6c63490", "url": "https://github.com/eclipse/rdf4j/commit/3001f68987c2610d3cab6063818cd0c3e6c63490", "message": "GH-2121 create single INSERT/DELETE DATA per batch of triples\n\n- avoid having a INSERT/DELETE operation for each individual triple", "committedDate": "2020-04-24T00:26:45Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzMjU2Ng==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414332566", "bodyText": "I think .contexts() upgrades the DynamicModel to a HashModel. This is probably not going to be what is performance critical in this situation though. I'm also unsure if .clear() downgrades the model again.", "author": "hmottestad", "createdAt": "2020-04-24T06:41:17Z", "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -827,39 +819,71 @@ public boolean isActive() throws UnknownTransactionStateException, RepositoryExc\n \t\t}\n \t}\n \n+\t@Override\n+\tprotected void addWithoutCommit(Statement st, Resource... contexts)\n+\t\t\tthrows RepositoryException {\n+\t\tflushPendingRemoves();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingAdds.add(st);\n+\t\t} else {\n+\t\t\tpendingAdds.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n+\t}\n+\n \t@Override\n \tprotected void addWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tValueFactory f = getValueFactory();\n+\t\tflushPendingRemoves();\n+\t\tpendingAdds.add(subject, predicate, object, contexts);\n+\t}\n \n-\t\tStatement st = f.createStatement(subject, predicate, object);\n+\tprivate void flushPendingRemoves() {\n+\t\tif (!pendingRemoves.isEmpty()) {\n+\t\t\tfor (Resource context : pendingRemoves.contexts()) {\n+\t\t\t\tString sparqlCommand = createDeleteDataCommand(pendingRemoves.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingRemoves.clear();\n+\t\t}\n+\t}\n \n-\t\tList<Statement> list = new ArrayList<>(1);\n-\t\tlist.add(st);\n-\t\tString sparqlCommand = createInsertDataCommand(list, contexts);\n+\tprivate void flushPendingAdds() {\n+\t\tif (!pendingAdds.isEmpty()) {\n+\t\t\tfor (Resource context : pendingAdds.contexts()) {\n+\t\t\t\tString sparqlCommand = createInsertDataCommand(pendingAdds.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingAdds.clear();", "originalCommit": "3001f68987c2610d3cab6063818cd0c3e6c63490", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNzU1Ng==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414337556", "bodyText": "I'm also unsure if .clear() downgrades the model again.\n\nThat might be an interesting improvement to DynamicModel. I mostly just used a model here because it's a simple way to keep track of statements per context. I could perhaps also use a Multimap of some sort if this turns out to be heavy.", "author": "jeenbroekstra", "createdAt": "2020-04-24T06:51:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzMjU2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDk1MTEyNA==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414951124", "bodyText": "For now I've changed it slightly to just drop the model and create a new empty one when flushing.", "author": "jeenbroekstra", "createdAt": "2020-04-25T01:57:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzMjU2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTEwNw==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414335107", "bodyText": "Bit hazy in the morning but I wonder how you handle removing from all contexts (implicitly).", "author": "hmottestad", "createdAt": "2020-04-24T06:46:30Z", "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -827,39 +819,71 @@ public boolean isActive() throws UnknownTransactionStateException, RepositoryExc\n \t\t}\n \t}\n \n+\t@Override\n+\tprotected void addWithoutCommit(Statement st, Resource... contexts)\n+\t\t\tthrows RepositoryException {\n+\t\tflushPendingRemoves();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingAdds.add(st);\n+\t\t} else {\n+\t\t\tpendingAdds.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n+\t}\n+\n \t@Override\n \tprotected void addWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tValueFactory f = getValueFactory();\n+\t\tflushPendingRemoves();\n+\t\tpendingAdds.add(subject, predicate, object, contexts);\n+\t}\n \n-\t\tStatement st = f.createStatement(subject, predicate, object);\n+\tprivate void flushPendingRemoves() {\n+\t\tif (!pendingRemoves.isEmpty()) {\n+\t\t\tfor (Resource context : pendingRemoves.contexts()) {\n+\t\t\t\tString sparqlCommand = createDeleteDataCommand(pendingRemoves.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingRemoves.clear();\n+\t\t}\n+\t}\n \n-\t\tList<Statement> list = new ArrayList<>(1);\n-\t\tlist.add(st);\n-\t\tString sparqlCommand = createInsertDataCommand(list, contexts);\n+\tprivate void flushPendingAdds() {\n+\t\tif (!pendingAdds.isEmpty()) {\n+\t\t\tfor (Resource context : pendingAdds.contexts()) {\n+\t\t\t\tString sparqlCommand = createInsertDataCommand(pendingAdds.getStatements(null, null, null, context),\n+\t\t\t\t\t\tcontext);\n+\t\t\t\tsparqlTransaction.append(sparqlCommand);\n+\t\t\t\tsparqlTransaction.append(\"; \");\n+\t\t\t}\n+\t\t\tpendingAdds.clear();\n+\t\t}\n+\t}\n \n-\t\tsparqlTransaction.append(sparqlCommand);\n-\t\tsparqlTransaction.append(\"; \");\n+\t@Override\n+\tprotected void removeWithoutCommit(Statement st, Resource... contexts) throws RepositoryException {\n+\t\tflushPendingAdds();\n+\t\tif (contexts.length == 0) {\n+\t\t\tpendingRemoves.add(st);\n+\t\t} else {\n+\t\t\tpendingRemoves.add(st.getSubject(), st.getPredicate(), st.getObject(), contexts);\n+\t\t}\n \t}\n \n \t@Override\n \tprotected void removeWithoutCommit(Resource subject, IRI predicate, Value object, Resource... contexts)\n \t\t\tthrows RepositoryException {\n-\t\tString sparqlCommand = \"\";\n-\t\tif (subject != null && predicate != null && object != null) {\n-\t\t\tValueFactory f = getValueFactory();\n-\n-\t\t\tStatement st = f.createStatement(subject, predicate, object);\n+\t\tflushPendingAdds();\n \n-\t\t\tList<Statement> list = new ArrayList<>(1);\n-\t\t\tlist.add(st);\n-\t\t\tsparqlCommand = createDeleteDataCommand(list, contexts);\n+\t\tif (subject != null && predicate != null && object != null) {\n+\t\t\tpendingRemoves.add(subject, predicate, object, contexts);", "originalCommit": "3001f68987c2610d3cab6063818cd0c3e6c63490", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNzg0OA==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414337848", "bodyText": "Ah - good call. I'll write a test case for that.", "author": "jeenbroekstra", "createdAt": "2020-04-24T06:52:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTEwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDk1MDQ0OQ==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414950449", "bodyText": "Just to be clear: this is in fact handled by just mapping to a DELETE DATA operation without a GRAPH clause. Funnily enough the integration tests didn't cover this specific case, so I've added a few unit tests as well as a new integration test.", "author": "jeenbroekstra", "createdAt": "2020-04-25T01:53:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTEwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTM4OA==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414335388", "bodyText": "Do we need a private getter?", "author": "hmottestad", "createdAt": "2020-04-24T06:47:06Z", "path": "core/repository/sparql/src/main/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnection.java", "diffHunk": "@@ -972,4 +996,8 @@ protected Statement convert(BindingSet b) throws QueryEvaluationException {\n \t\t};\n \t}\n \n+\tprivate ModelFactory getModelFactory() {\n+\t\treturn modelFactory;\n+\t}", "originalCommit": "3001f68987c2610d3cab6063818cd0c3e6c63490", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNjU2Ng==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414336566", "bodyText": "Not necesarily, I think I originally made it public and then changed my mind :)", "author": "jeenbroekstra", "createdAt": "2020-04-24T06:49:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNTM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNjgwMA==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414336800", "bodyText": "Good we have some tests. Do we have any integration tests that would cover this too? Benchmarks would also be great, so we don't have a regression of this some time in the future.", "author": "hmottestad", "createdAt": "2020-04-24T06:50:13Z", "path": "core/repository/sparql/src/test/java/org/eclipse/rdf4j/repository/sparql/SPARQLConnectionTest.java", "diffHunk": "@@ -48,4 +53,52 @@ public void commitOnEmptyTxnDoesNothing() throws Exception {\n \t\tverify(client, never()).sendUpdate(any(), any(), any(), any(), anyBoolean(), anyInt(), any());\n \t\tverify(client, never()).sendUpdate(any(), any(), any(), any(), anyBoolean(), any());\n \t}\n+\n+\t@Test\n+\tpublic void testGroupingAddsInInsert() throws Exception {\n+\t\tArgumentCaptor<String> sparqlUpdateCaptor = ArgumentCaptor.forClass(String.class);\n+\n+\t\tsubject.begin();\n+\t\tsubject.add(FOAF.PERSON, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.add(FOAF.AGENT, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.commit();\n+\n+\t\tverify(client).sendUpdate(any(), sparqlUpdateCaptor.capture(), any(), any(), anyBoolean(), anyInt(), any());\n+\n+\t\tString sparqlUpdate = sparqlUpdateCaptor.getValue();\n+\t\tString expectedTriple1 = \"<\" + FOAF.PERSON + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \">\";\n+\t\tString expectedTriple2 = \"<\" + FOAF.AGENT + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \">\";\n+\n+\t\tassertThat(sparqlUpdate).containsOnlyOnce(\"INSERT DATA\").contains(expectedTriple1).contains(expectedTriple2);\n+\t}\n+\n+\t@Test\n+\tpublic void testHandlingAddsRemoves() throws Exception {\n+\t\tArgumentCaptor<String> sparqlUpdateCaptor = ArgumentCaptor.forClass(String.class);\n+\n+\t\tsubject.begin();\n+\t\tsubject.add(FOAF.PERSON, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.add(FOAF.AGENT, RDF.TYPE, RDFS.CLASS);\n+\t\tsubject.remove(FOAF.BIRTHDAY, RDF.TYPE, RDF.PROPERTY);\n+\t\tsubject.add(FOAF.AGE, RDF.TYPE, RDF.PROPERTY);\n+\t\tsubject.commit();\n+\n+\t\tverify(client).sendUpdate(any(), sparqlUpdateCaptor.capture(), any(), any(), anyBoolean(), anyInt(), any());\n+\n+\t\tString sparqlUpdate = sparqlUpdateCaptor.getValue();\n+\n+\t\tString expectedAddedTriple1 = \"<\" + FOAF.PERSON + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \"> .\";\n+\t\tString expectedAddedTriple2 = \"<\" + FOAF.AGENT + \"> <\" + RDF.TYPE + \"> <\" + RDFS.CLASS + \"> .\";\n+\t\tString expectedAddedTriple3 = \"<\" + FOAF.AGE + \"> <\" + RDF.TYPE + \"> <\" + RDF.PROPERTY + \"> \";\n+\t\tString expectedRemovedTriple1 = \"<\" + FOAF.BIRTHDAY + \"> <\" + RDF.TYPE + \"> <\" + RDF.PROPERTY + \"> .\";\n+\n+\t\tString expectedSequence = \"INSERT DATA[^{]*\\\\{[^}]*\\\\}[^D]+DELETE DATA[^{]*\\\\{[^}]*\\\\}[^I]+INSERT DATA.*\";\n+\n+\t\tassertThat(sparqlUpdate).containsPattern(expectedSequence);\n+\t\tassertThat(sparqlUpdate).contains(expectedAddedTriple1)\n+\t\t\t\t.contains(expectedAddedTriple2)\n+\t\t\t\t.contains(expectedAddedTriple3)\n+\t\t\t\t.contains(expectedRemovedTriple1);\n+\n+\t}", "originalCommit": "3001f68987c2610d3cab6063818cd0c3e6c63490", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM1MTU4OA==", "url": "https://github.com/eclipse/rdf4j/pull/2126#discussion_r414351588", "bodyText": "Yes we have quite extensive integration tests for this, see rdf4j-repository-compliance.\nI don't think we have benchmarks though. I'll see what I can do this weekend. But I must admit I suck at benchmarks.", "author": "jeenbroekstra", "createdAt": "2020-04-24T07:19:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDMzNjgwMA=="}], "type": "inlineReview"}, {"oid": "c9cfe1870743694186018cbfcc1e4e9e92eb8233", "url": "https://github.com/eclipse/rdf4j/commit/c9cfe1870743694186018cbfcc1e4e9e92eb8233", "message": "GH-2121 test cases for handling of adding/removal with context", "committedDate": "2020-04-25T01:30:09Z", "type": "commit"}, {"oid": "c2e1ff46cc88c29dd146504d9cfa98ebc5cc67ba", "url": "https://github.com/eclipse/rdf4j/commit/c2e1ff46cc88c29dd146504d9cfa98ebc5cc67ba", "message": "GH-2121 force flush if pending stmt size reaches 1M\n\n- cleaned up integration test for SPARQLRepository by re-enabling\n  certain test cases we now support", "committedDate": "2020-04-25T01:54:12Z", "type": "commit"}]}