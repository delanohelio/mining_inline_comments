{"pr_number": 2112, "pr_title": "GH-2111 cache IDFile", "pr_createdAt": "2020-04-20T11:27:16Z", "pr_url": "https://github.com/eclipse/rdf4j/pull/2112", "timeline": [{"oid": "8dce0457a6e964ff5e5ae78405e6762e20618621", "url": "https://github.com/eclipse/rdf4j/commit/8dce0457a6e964ff5e5ae78405e6762e20618621", "message": "GH-2111 adjusted read size and also added synchronization\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-21T09:11:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwODc4OA==", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412708788", "bodyText": "Should probably synchronise this too.", "author": "hmottestad", "createdAt": "2020-04-22T06:37:14Z", "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost\n+\t\t// never be cached. This simplifies the code since we don't have to deal with partial lines.\n+\t\tif (getMaxID() > cacheLineSize && id < getMaxID() - cacheLineSize) {\n+\n+\t\t\t// doing one big read is considerably faster than doing a single read per id\n+\t\t\tbyte[] bytes = nioFile.readBytes(ITEM_SIZE * (cacheLookupIndex << cacheLineShift),\n+\t\t\t\t\t(int) (ITEM_SIZE * cacheLineSize));\n+\n+\t\t\tcacheLine = convertBytesToLongs(bytes);\n+\n+\t\t\tsynchronized (this) {\n+\t\t\t\t// we try not to overwrite an existing cache line\n+\t\t\t\tif (!cache.containsKey(cacheLineLookupIndex)) {\n+\t\t\t\t\tcache.put(cacheLookupIndex, cacheLine);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tgcReducingCache = cacheLine;\n+\t\t\tgcReducingCacheIndex = cacheLookupIndex;", "originalCommit": "8dce0457a6e964ff5e5ae78405e6762e20618621", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwOTA2NA==", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412709064", "bodyText": "Typo og=of", "author": "hmottestad", "createdAt": "2020-04-22T06:37:46Z", "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost", "originalCommit": "8dce0457a6e964ff5e5ae78405e6762e20618621", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjcwOTU0MA==", "url": "https://github.com/eclipse/rdf4j/pull/2112#discussion_r412709540", "bodyText": "Clear Cache!", "author": "hmottestad", "createdAt": "2020-04-22T06:38:42Z", "path": "core/sail/nativerdf/src/main/java/org/eclipse/rdf4j/sail/nativerdf/datastore/IDFile.java", "diffHunk": "@@ -105,52 +132,111 @@ public final File getFile() {\n \n \t/**\n \t * Gets the largest ID that is stored in this ID file.\n-\t * \n+\t *\n \t * @return The largest ID, or <tt>0</tt> if the file does not contain any data.\n \t * @throws IOException If an I/O error occurs.\n \t */\n \tpublic int getMaxID() throws IOException {\n-\t\treturn (int) (nioFile.size() / ITEM_SIZE) - 1;\n+\t\treturn (int) (nioFileSize / ITEM_SIZE) - 1;\n \t}\n \n \t/**\n \t * Stores the offset of a new data entry, returning the ID under which is stored.\n \t */\n \tpublic int storeOffset(long offset) throws IOException {\n-\t\tlong fileSize = nioFile.size();\n+\t\tlong fileSize = nioFileSize;\n \t\tnioFile.writeLong(offset, fileSize);\n+\t\tnioFileSize += ITEM_SIZE;\n \t\treturn (int) (fileSize / ITEM_SIZE);\n \t}\n \n \t/**\n \t * Sets or updates the stored offset for the specified ID.\n-\t * \n+\t *\n \t * @param id     The ID to set the offset for, must be larger than 0.\n \t * @param offset The (new) offset for the specified ID.\n \t */\n \tpublic void setOffset(int id, long offset) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n \t\tnioFile.writeLong(offset, ITEM_SIZE * id);\n+\n+\t\t// We need to update the cache after writing to file (not before) so that if anyone refreshes the cache it will\n+\t\t// include the write above.\n+\t\t// The scenario is as follows:\n+\t\t// 1. there is nothing in the cache, everything is fine\n+\t\t// 2. the relevant cache line is from before the writeLong operation above, in which case we update it\n+\t\t// 3. the relevant cache line is from right after the write in which case updating it doesnt matter\n+\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\tcacheLine[cacheLineLookupIndex] = offset;\n+\t\t}\n+\n \t}\n \n \t/**\n \t * Gets the offset of the data entry with the specified ID.\n-\t * \n+\t *\n \t * @param id The ID to get the offset for, must be larger than 0.\n \t * @return The offset for the ID.\n \t */\n \tpublic long getOffset(int id) throws IOException {\n \t\tassert id > 0 : \"id must be larger than 0, is: \" + id;\n+\n+\t\t// the index used to lookup the cache line\n+\t\tint cacheLookupIndex = id >> cacheLineShift;\n+\n+\t\t// the index used to lookup the actual value inside the cache line\n+\t\tint cacheLineLookupIndex = id % cacheLineSize;\n+\n+\t\t// the cache line which is of size cacheLineSize\n+\t\tLong[] cacheLine = getCacheLine(cacheLookupIndex);\n+\n+\t\tif (cacheLine != null) {\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\t\t}\n+\n+\t\t// We only cache complete lines og size cacheLineSize. This means that the last line in the file will almost\n+\t\t// never be cached. This simplifies the code since we don't have to deal with partial lines.\n+\t\tif (getMaxID() > cacheLineSize && id < getMaxID() - cacheLineSize) {\n+\n+\t\t\t// doing one big read is considerably faster than doing a single read per id\n+\t\t\tbyte[] bytes = nioFile.readBytes(ITEM_SIZE * (cacheLookupIndex << cacheLineShift),\n+\t\t\t\t\t(int) (ITEM_SIZE * cacheLineSize));\n+\n+\t\t\tcacheLine = convertBytesToLongs(bytes);\n+\n+\t\t\tsynchronized (this) {\n+\t\t\t\t// we try not to overwrite an existing cache line\n+\t\t\t\tif (!cache.containsKey(cacheLineLookupIndex)) {\n+\t\t\t\t\tcache.put(cacheLookupIndex, cacheLine);\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\tgcReducingCache = cacheLine;\n+\t\t\tgcReducingCacheIndex = cacheLookupIndex;\n+\n+\t\t\treturn cacheLine[cacheLineLookupIndex];\n+\n+\t\t}\n+\n+\t\t// we did not find a cached value and we did not create a new cache line\n \t\treturn nioFile.readLong(ITEM_SIZE * id);\n \t}\n \n \t/**\n \t * Discards all stored data.\n-\t * \n+\t *\n \t * @throws IOException If an I/O error occurred.\n \t */\n \tpublic void clear() throws IOException {\n \t\tnioFile.truncate(HEADER_LENGTH);\n+\t\tnioFileSize = nioFile.size();", "originalCommit": "8dce0457a6e964ff5e5ae78405e6762e20618621", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b42e7f32a2cc8eb25010996699d4782eb0e56b51", "url": "https://github.com/eclipse/rdf4j/commit/b42e7f32a2cc8eb25010996699d4782eb0e56b51", "message": "GH-2111 Use a ReferenceMap to create a memory aware cache in IDFile\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "commit"}, {"oid": "bccf5949afcc18640e0554415570b827a150cb47", "url": "https://github.com/eclipse/rdf4j/commit/bccf5949afcc18640e0554415570b827a150cb47", "message": "Shared and synchronized java object is more costly than just creating a new one every time, especially due to escape analysis\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "commit"}, {"oid": "5ab97c2d3958a98dff039b15c772b8ffad0d0889", "url": "https://github.com/eclipse/rdf4j/commit/5ab97c2d3958a98dff039b15c772b8ffad0d0889", "message": "GH-2111 minor code cleanup\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "commit"}, {"oid": "f628aca5d4385d70682dd657fce5190291f6371e", "url": "https://github.com/eclipse/rdf4j/commit/f628aca5d4385d70682dd657fce5190291f6371e", "message": "GH-2111 adjusted read size and also added synchronization\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "commit"}, {"oid": "e2b0e72c9682ec793c57069aa523d37c301cc4a7", "url": "https://github.com/eclipse/rdf4j/commit/e2b0e72c9682ec793c57069aa523d37c301cc4a7", "message": "review fixes\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "commit"}, {"oid": "e2b0e72c9682ec793c57069aa523d37c301cc4a7", "url": "https://github.com/eclipse/rdf4j/commit/e2b0e72c9682ec793c57069aa523d37c301cc4a7", "message": "review fixes\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:32:24Z", "type": "forcePushed"}, {"oid": "e4928956da8c8b891c9807e200b099b8c0ece517", "url": "https://github.com/eclipse/rdf4j/commit/e4928956da8c8b891c9807e200b099b8c0ece517", "message": "sort imports\n\nSigned-off-by: Ha\u030avard Ottestad <hmottestad@gmail.com>", "committedDate": "2020-04-22T08:33:30Z", "type": "commit"}]}