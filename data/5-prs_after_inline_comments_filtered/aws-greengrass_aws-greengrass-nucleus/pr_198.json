{"pr_number": 198, "pr_title": "Add support for retrying jobs on retryable exceptions", "pr_createdAt": "2020-04-21T16:25:05Z", "pr_url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198", "timeline": [{"oid": "85205dd0d1dceca4226de605bdbcdd624dff1453", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/85205dd0d1dceca4226de605bdbcdd624dff1453", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-21T16:09:51Z", "type": "forcePushed"}, {"oid": "e19f6142218d313731436a7c0a03bd9addde42ee", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e19f6142218d313731436a7c0a03bd9addde42ee", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-21T16:22:12Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMzNzM3MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412337371", "bodyText": "Get rid of this. This is a unit test which should not need any sleeping.", "author": "MikeDombo", "createdAt": "2020-04-21T17:10:12Z", "path": "src/test/java/com/aws/iot/evergreen/deployment/DeploymentServiceTest.java", "diffHunk": "@@ -182,6 +183,32 @@ public void GIVEN_deployment_job_WHEN_deployment_process_fails_THEN_report_faile\n             deploymentService.shutdown();\n         }\n \n+        @Test\n+        public void GIVEN_deployment_job_WHEN_deployment_process_fails_with_retry_THEN_retry_job(ExtensionContext context)\n+                throws Exception {\n+            CompletableFuture<Void> mockFutureWithException = new CompletableFuture<>();\n+            ignoreExceptionUltimateCauseOfType(context, RetryableDeploymentTaskFailureException.class);\n+            Throwable t = new RetryableDeploymentTaskFailureException(null);\n+            mockFutureWithException.completeExceptionally(t);\n+            when(mockExecutorService.submit(any(DeploymentTask.class))).thenReturn(mockFutureWithException, mockFuture);\n+            startDeploymentServiceInAnotherThread();\n+\n+            //Wait for the enough time after which deployment service would have processed the job from the queue\n+            Thread.sleep(Duration.ofSeconds(2).toMillis());", "originalCommit": "e19f6142218d313731436a7c0a03bd9addde42ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUzMDQzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412530430", "bodyText": "We need to wait for the deployment service to start in another thread and reach a point where it processed the job.  There is no latches in the code to indicate that it reached certain execution point.", "author": "abanthiy", "createdAt": "2020-04-21T22:18:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMzNzM3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMzNzUzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412337530", "bodyText": "Why atMost and not times?", "author": "MikeDombo", "createdAt": "2020-04-21T17:10:26Z", "path": "src/test/java/com/aws/iot/evergreen/deployment/DeploymentServiceTest.java", "diffHunk": "@@ -182,6 +183,32 @@ public void GIVEN_deployment_job_WHEN_deployment_process_fails_THEN_report_faile\n             deploymentService.shutdown();\n         }\n \n+        @Test\n+        public void GIVEN_deployment_job_WHEN_deployment_process_fails_with_retry_THEN_retry_job(ExtensionContext context)\n+                throws Exception {\n+            CompletableFuture<Void> mockFutureWithException = new CompletableFuture<>();\n+            ignoreExceptionUltimateCauseOfType(context, RetryableDeploymentTaskFailureException.class);\n+            Throwable t = new RetryableDeploymentTaskFailureException(null);\n+            mockFutureWithException.completeExceptionally(t);\n+            when(mockExecutorService.submit(any(DeploymentTask.class))).thenReturn(mockFutureWithException, mockFuture);\n+            startDeploymentServiceInAnotherThread();\n+\n+            //Wait for the enough time after which deployment service would have processed the job from the queue\n+            Thread.sleep(Duration.ofSeconds(2).toMillis());\n+            // Expecting two invocations\n+            verify(mockExecutorService, atMost(2)).submit(any(DeploymentTask.class));", "originalCommit": "e19f6142218d313731436a7c0a03bd9addde42ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyODI4MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413128280", "bodyText": "Changed to times, copy pasta", "author": "chaurah", "createdAt": "2020-04-22T16:25:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjMzNzUzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUyNTcyMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412525721", "bodyText": "Need to have a max times till when we will keep adding this to the queue. Also I don't think we need to add the QUEUED status to the config. The documentation at https://docs.aws.amazon.com/iot/latest/developerguide/jobs-api.html#mqtt-updatejobexecution mentions the update statuses from among (IN_PROGRESS, FAILED, SUCCEEDED, or REJECTED). I think keeping it IN_PROGRESS should be fine since thats the next thing we are going to process.", "author": "abanthiy", "createdAt": "2020-04-21T22:09:01Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentService.java", "diffHunk": "@@ -228,12 +230,14 @@ private void finishCurrentDeployment() throws InterruptedException {\n             logger.atError().kv(JOB_ID_LOG_KEY_NAME, currentJobId).setCause(e)\n                     .log(\"Caught exception while getting the status of the Job\");\n             Throwable t = e.getCause();\n+            HashMap<String, String> statusDetails = new HashMap<>();\n+            statusDetails.put(\"error\", t.getMessage());\n             if (t instanceof NonRetryableDeploymentTaskFailureException) {\n-                HashMap<String, String> statusDetails = new HashMap<>();\n-                statusDetails.put(\"error\", t.getMessage());\n                 storeDeploymentStatusInConfig(currentJobId, JobStatus.FAILED, statusDetails);\n+            } else if (t instanceof RetryableDeploymentTaskFailureException) {\n+                storeDeploymentStatusInConfig(currentJobId, JobStatus.QUEUED, statusDetails);", "originalCommit": "e19f6142218d313731436a7c0a03bd9addde42ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyNzA3NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413127075", "bodyText": "Makes sense. adding an explicit call to make sure it stays in IN_PROGRESS. Create a hard coded constant for now for max retries with a value of say 3?", "author": "chaurah", "createdAt": "2020-04-22T16:23:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUyNTcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUyODMwMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412528301", "bodyText": "I think this is a big try block. Consider putting try-catch blocks around the specific calls. For example PackageVersionConflictException can be caught around the resolveDependencies call. SImilarly for other calls?", "author": "abanthiy", "createdAt": "2020-04-21T22:14:27Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentTask.java", "diffHunk": "@@ -59,9 +60,16 @@ public Void call() throws NonRetryableDeploymentTaskFailureException, RetryableD\n                     newConfig).get();\n             logger.atInfo().setEventType(DEPLOYMENT_TASK_EVENT_TYPE)\n                     .addKeyValue(\"deploymentId\", deploymentDocument.getDeploymentId()).log(\"Finish deployment task\");\n-        // TODO: unwrap ExcutionException to see which one is retryable.\n-        } catch (PackageVersionConflictException | UnexpectedPackagingException | ExecutionException e) {\n+        } catch (PackageVersionConflictException | UnexpectedPackagingException e) {\n             throw new NonRetryableDeploymentTaskFailureException(e);\n+        } catch (ExecutionException e) {\n+            Throwable t = e.getCause();\n+            if (t instanceof PackagingException\n+                    || t instanceof InterruptedException\n+                    || t instanceof IOException) {\n+                throw new RetryableDeploymentTaskFailureException(t);\n+            }\n+            throw new NonRetryableDeploymentTaskFailureException(t);\n         } catch (InterruptedException | IOException | PackagingException e) {", "originalCommit": "e19f6142218d313731436a7c0a03bd9addde42ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyNzc0MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413127741", "bodyText": "I did think of that, but it was even longer code. This seemed to be a bit better overall", "author": "chaurah", "createdAt": "2020-04-22T16:24:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjUyODMwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjU0MjQ3OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r412542478", "bodyText": "Can you rewind an \"INPROGRESS\" job to \"QUEUED\" ?", "author": "ShirleyZheng92", "createdAt": "2020-04-21T22:45:38Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentService.java", "diffHunk": "@@ -228,12 +230,14 @@ private void finishCurrentDeployment() throws InterruptedException {\n             logger.atError().kv(JOB_ID_LOG_KEY_NAME, currentJobId).setCause(e)\n                     .log(\"Caught exception while getting the status of the Job\");\n             Throwable t = e.getCause();\n+            HashMap<String, String> statusDetails = new HashMap<>();\n+            statusDetails.put(\"error\", t.getMessage());\n             if (t instanceof NonRetryableDeploymentTaskFailureException) {\n-                HashMap<String, String> statusDetails = new HashMap<>();\n-                statusDetails.put(\"error\", t.getMessage());\n                 storeDeploymentStatusInConfig(currentJobId, JobStatus.FAILED, statusDetails);\n+            } else if (t instanceof RetryableDeploymentTaskFailureException) {\n+                storeDeploymentStatusInConfig(currentJobId, JobStatus.QUEUED, statusDetails);", "originalCommit": "e19f6142218d313731436a7c0a03bd9addde42ee", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzEyODA2MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413128061", "bodyText": "Keeping it in IN_PROGRESS based on Amit's comment above.", "author": "chaurah", "createdAt": "2020-04-22T16:24:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjU0MjQ3OA=="}], "type": "inlineReview"}, {"oid": "5b9d79a5ec054874036dcf36228e5211547bded9", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5b9d79a5ec054874036dcf36228e5211547bded9", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-22T16:14:50Z", "type": "forcePushed"}, {"oid": "f643b2e43617272f06608e61f99955e2c0c72c9c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f643b2e43617272f06608e61f99955e2c0c72c9c", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-22T17:19:19Z", "type": "forcePushed"}, {"oid": "33f1c8c8dc3e90ff3f3703a98aff78163779d77c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/33f1c8c8dc3e90ff3f3703a98aff78163779d77c", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-22T17:23:21Z", "type": "forcePushed"}, {"oid": "03605c0fb2b9e0aabb3db5a8c533372b918df64c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/03605c0fb2b9e0aabb3db5a8c533372b918df64c", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-22T17:33:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5MjU0OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413192548", "bodyText": "4 seconds is way too long for a unit test. All this stuff should be happening within milliseconds.", "author": "MikeDombo", "createdAt": "2020-04-22T17:51:10Z", "path": "src/test/java/com/aws/iot/evergreen/deployment/DeploymentServiceTest.java", "diffHunk": "@@ -63,6 +65,7 @@\n     private static final String TEST_JOB_ID_1 = \"TEST_JOB_1\";\n     private static final String TEST_JOB_ID_2 = \"TEST_JOB_2\";\n     private static final String CONNECTION_ERROR = \"Connection error\";\n+    private static final VerificationWithTimeout WAIT_FOUR_SECONDS = timeout(Duration.ofSeconds(4).toMillis());", "originalCommit": "03605c0fb2b9e0aabb3db5a8c533372b918df64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5Mjk2Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413192967", "bodyText": "Actually, nevermind since it will be at most 4 s.", "author": "MikeDombo", "createdAt": "2020-04-22T17:51:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5MjU0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5Nzk1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413197952", "bodyText": "Out of the 7-8 times I ran the test with a 2 second timeout, at least once it failed. In the worst case, am using this to monitor 5 invocations of a single function. Keeping it high to avoid flakiness. I agree it's long but at the moment, there's no way to block on some value in the deployment service and completely avoid timers.", "author": "chaurah", "createdAt": "2020-04-22T17:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzE5MjU0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NTk5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413355993", "bodyText": "Nothing else should be pushed between the new timestamp and the old timestamp since we are executing everything in single thread and also pushing deployment to the head of the deque. Timestamps are used for ordering the updates and in this case the order will not be affected.\nI see that we are updating the status details with the error information. Afaik right now there is no requirement to update the status of deployment every retry, and we do not mention in status details that we are retrying. It is also going to get overridden (in cloud) by the IN_PROGRESS update made on the new retry. I think we can skip this update and only update the status of the deployment when its final. What do you think?", "author": "abanthiy", "createdAt": "2020-04-22T21:47:34Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentService.java", "diffHunk": "@@ -219,21 +230,27 @@ private void connectToAWSIot() throws InterruptedException {\n     private void finishCurrentDeployment() throws InterruptedException {\n         logger.atInfo().kv(JOB_ID_LOG_KEY_NAME, currentJobId).log(\"Current deployment finished\");\n         try {\n-            //No timeout is set here. Detection of error is delegated to downstream components like\n+            // No timeout is set here. Detection of error is delegated to downstream components like\n             // dependency resolver, package downloader, kernel which will have more visibility\n             // if something is going wrong\n             currentProcessStatus.get();\n             storeDeploymentStatusInConfig(currentJobId, JobStatus.SUCCEEDED, new HashMap<>());\n+            currentJobAttemptCount.set(0);\n         } catch (ExecutionException e) {\n             logger.atError().kv(JOB_ID_LOG_KEY_NAME, currentJobId).setCause(e)\n                     .log(\"Caught exception while getting the status of the Job\");\n             Throwable t = e.getCause();\n-            if (t instanceof NonRetryableDeploymentTaskFailureException) {\n-                HashMap<String, String> statusDetails = new HashMap<>();\n-                statusDetails.put(\"error\", t.getMessage());\n+            HashMap<String, String> statusDetails = new HashMap<>();\n+            statusDetails.put(\"error\", t.getMessage());\n+            if (t instanceof NonRetryableDeploymentTaskFailureException\n+                    || currentJobAttemptCount.get() >= DEPLOYMENT_MAX_ATTEMPTS) {\n                 storeDeploymentStatusInConfig(currentJobId, JobStatus.FAILED, statusDetails);\n+                currentJobAttemptCount.set(0);\n+            } else if (t instanceof RetryableDeploymentTaskFailureException) {\n+                // Required to update timestamps", "originalCommit": "03605c0fb2b9e0aabb3db5a8c533372b918df64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzgwMTk5Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413801997", "bodyText": "I was erring on the side of more information over less. But if there's an override happening then it doesn't make sense to do this at the moment. Removing", "author": "chaurah", "createdAt": "2020-04-23T13:10:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NTk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM3MzY3Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413373672", "bodyText": "Have you considered storing DeploymentTask into a class variable and then submitting that to the executor service as oppose to resubmitting the Deployment.\n\nIt saves the processing that needs to be done again when submitting the same Deployment\nIt will allow us to keep it as a Queue, as opposed to Deque. This is to preserve that deployments run in the order in which they are submitted.", "author": "abanthiy", "createdAt": "2020-04-22T22:23:54Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentService.java", "diffHunk": "@@ -219,21 +230,27 @@ private void connectToAWSIot() throws InterruptedException {\n     private void finishCurrentDeployment() throws InterruptedException {\n         logger.atInfo().kv(JOB_ID_LOG_KEY_NAME, currentJobId).log(\"Current deployment finished\");\n         try {\n-            //No timeout is set here. Detection of error is delegated to downstream components like\n+            // No timeout is set here. Detection of error is delegated to downstream components like\n             // dependency resolver, package downloader, kernel which will have more visibility\n             // if something is going wrong\n             currentProcessStatus.get();\n             storeDeploymentStatusInConfig(currentJobId, JobStatus.SUCCEEDED, new HashMap<>());\n+            currentJobAttemptCount.set(0);\n         } catch (ExecutionException e) {\n             logger.atError().kv(JOB_ID_LOG_KEY_NAME, currentJobId).setCause(e)\n                     .log(\"Caught exception while getting the status of the Job\");\n             Throwable t = e.getCause();\n-            if (t instanceof NonRetryableDeploymentTaskFailureException) {\n-                HashMap<String, String> statusDetails = new HashMap<>();\n-                statusDetails.put(\"error\", t.getMessage());\n+            HashMap<String, String> statusDetails = new HashMap<>();\n+            statusDetails.put(\"error\", t.getMessage());\n+            if (t instanceof NonRetryableDeploymentTaskFailureException\n+                    || currentJobAttemptCount.get() >= DEPLOYMENT_MAX_ATTEMPTS) {\n                 storeDeploymentStatusInConfig(currentJobId, JobStatus.FAILED, statusDetails);\n+                currentJobAttemptCount.set(0);\n+            } else if (t instanceof RetryableDeploymentTaskFailureException) {\n+                // Required to update timestamps\n+                storeDeploymentStatusInConfig(currentJobId, JobStatus.IN_PROGRESS, statusDetails);\n+                deploymentsQueue.addFirst(currentDeployment);", "originalCommit": "03605c0fb2b9e0aabb3db5a8c533372b918df64c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzkxODE0OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r413918149", "bodyText": "I did consider that. However, there's a lot of stuff happening in the createNewDeployment function like updating persisted deployments etc. As of now, it seems to be fairly straightforward? I just didn't see the point of adding a workaround that may have other implications when an iterative solution was easily available.\nI can update if you feel it's necessary, but as of now this seems the better approach until the rest of your thoughts in comments around refactoring get addressed. It should be possible to just move to queuing deployment tasks and avoiding the entire loop but that would require a lot more work than a one day task would allow I think.", "author": "chaurah", "createdAt": "2020-04-23T15:55:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM3MzY3Mg=="}], "type": "inlineReview"}, {"oid": "71a4c8970ada06f304a0bef487517000bd07477d", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/71a4c8970ada06f304a0bef487517000bd07477d", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-23T23:20:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE4OTY5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r414189693", "bodyText": "Change it back to Queue?", "author": "abanthiy", "createdAt": "2020-04-23T23:26:59Z", "path": "src/main/java/com/aws/iot/evergreen/deployment/DeploymentService.java", "diffHunk": "@@ -88,7 +99,7 @@\n     private final AtomicBoolean retryConnectingToAWSIot = new AtomicBoolean(false);\n     @Setter\n     private long pollingFrequency = DEPLOYMENT_POLLING_FREQUENCY;\n-    private LinkedBlockingQueue<Deployment> deploymentsQueue = new LinkedBlockingQueue<>();\n+    private LinkedBlockingDeque<Deployment> deploymentsQueue = new LinkedBlockingDeque<>();", "originalCommit": "71a4c8970ada06f304a0bef487517000bd07477d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE5MTU1OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/198#discussion_r414191558", "bodyText": "Refresh :)", "author": "chaurah", "createdAt": "2020-04-23T23:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDE4OTY5Mw=="}], "type": "inlineReview"}, {"oid": "b13e526751b0b1937f5fc491ef9adf968867611e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/b13e526751b0b1937f5fc491ef9adf968867611e", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-23T23:27:43Z", "type": "commit"}, {"oid": "b13e526751b0b1937f5fc491ef9adf968867611e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/b13e526751b0b1937f5fc491ef9adf968867611e", "message": "Add support for retrying jobs on retryable exceptions", "committedDate": "2020-04-23T23:27:43Z", "type": "forcePushed"}]}