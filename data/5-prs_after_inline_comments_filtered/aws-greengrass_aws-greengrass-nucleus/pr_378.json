{"pr_number": 378, "pr_title": "Telemetry service to log kernel component state metrics", "pr_createdAt": "2020-08-21T21:55:02Z", "pr_url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378", "timeline": [{"oid": "16b2d04e236534a8b690f055b838f374fcb00b02", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/16b2d04e236534a8b690f055b838f374fcb00b02", "message": "update tests + test utils", "committedDate": "2020-09-22T02:07:16Z", "type": "commit"}, {"oid": "7f377ece01d65c38afeba3647580d88ecd9b750a", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7f377ece01d65c38afeba3647580d88ecd9b750a", "message": "close context afterEach", "committedDate": "2020-09-22T05:36:30Z", "type": "commit"}, {"oid": "ad7266b7ccd2dd40abdf3bf031c9c5e6e93168e3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/ad7266b7ccd2dd40abdf3bf031c9c5e6e93168e3", "message": "close context afterEach", "committedDate": "2020-09-22T07:00:08Z", "type": "commit"}, {"oid": "663a72a747d0e3296eaef1b02e4bd1a1dd9aee42", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/663a72a747d0e3296eaef1b02e4bd1a1dd9aee42", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-22T07:01:47Z", "type": "commit"}, {"oid": "5fbfd960435c0016a8b9d0f17f14a2211b9ef933", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5fbfd960435c0016a8b9d0f17f14a2211b9ef933", "message": "update kernelComponents to GreengrassComponents", "committedDate": "2020-09-22T19:04:04Z", "type": "commit"}, {"oid": "e22abcb43550efb8e08c9b2e837eebd997a98f4a", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e22abcb43550efb8e08c9b2e837eebd997a98f4a", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-22T19:04:34Z", "type": "commit"}, {"oid": "a8dd452d086596145dbc618b6108a9adddb6c463", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a8dd452d086596145dbc618b6108a9adddb6c463", "message": "update publish topic", "committedDate": "2020-09-22T20:45:18Z", "type": "commit"}, {"oid": "73660164430ebf1cd0f54b13c61cc0e9a75a08ec", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/73660164430ebf1cd0f54b13c61cc0e9a75a08ec", "message": "update publish topic", "committedDate": "2020-09-22T20:58:22Z", "type": "commit"}, {"oid": "46f3f153c4aae98e0f30103ed5a1e97c785b9cb5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/46f3f153c4aae98e0f30103ed5a1e97c785b9cb5", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-22T20:59:13Z", "type": "commit"}, {"oid": "f76a4fb43a83d166a6362bdf7d197ab8d3de5436", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f76a4fb43a83d166a6362bdf7d197ab8d3de5436", "message": "Use single metric factory for all the tests", "committedDate": "2020-09-23T00:49:21Z", "type": "commit"}, {"oid": "593c73f5f9ccfbaec204eda8bcece7582d6a2871", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/593c73f5f9ccfbaec204eda8bcece7582d6a2871", "message": "integ tests", "committedDate": "2020-09-23T03:24:33Z", "type": "commit"}, {"oid": "c194bdf0c6f5b4bc75e57efb91fe8a3d31044c0b", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c194bdf0c6f5b4bc75e57efb91fe8a3d31044c0b", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-23T03:24:51Z", "type": "commit"}, {"oid": "d977bc1a3ef114e4227fd40a741007294c886b19", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d977bc1a3ef114e4227fd40a741007294c886b19", "message": "integ tests", "committedDate": "2020-09-23T10:13:03Z", "type": "commit"}, {"oid": "1f5ec3bc87d3be6d9bf072fffd46bd39219aedd5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1f5ec3bc87d3be6d9bf072fffd46bd39219aedd5", "message": "update tests", "committedDate": "2020-09-23T17:56:32Z", "type": "commit"}, {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-23T17:57:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDM5Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830392", "bodyText": "new AtomicReference(new ArrayList<>)", "author": "MikeDombo", "createdAt": "2020-09-23T19:05:11Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.integrationtests.e2e.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.SubscribeRequest;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(GGExtension.class)\n+@Tag(\"E2E\")\n+public class TelemetryAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    protected TelemetryAgentTest() throws Exception {\n+        super();\n+    }\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_WHEN_telemetry_agent_starts_THEN_metrics_are_published_to_Cloud() throws\n+            InterruptedException, ExecutionException, TimeoutException, ServiceLoadException {\n+        /*\n+         Metrics agent is an auto-start service. It publishes data to the cloud irrespective of the deployments.\n+         In this test, we just start the kernel and expect MA to publish time-based metrics such as system metrics and\n+         kernel component state metrics in the given interval.\n+        */\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+        CountDownLatch cdl = new CountDownLatch(1);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDcyMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830722", "bodyText": "the client is mocked, so you don't really need to close it", "author": "MikeDombo", "createdAt": "2020-09-23T19:05:49Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493831617", "bodyText": "instead of this, can you just check the topic that it is writing to? if it fails to deserialize, that ought to be a problem and fail the test.", "author": "MikeDombo", "createdAt": "2020-09-23T19:07:32Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);\n+        assertTrue(Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)) > lastAgg);\n+\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay < periodicInterval);\n+        // telemetry logs are always written to ~root/telemetry\n+        assertEquals(kernel.getRootPath().resolve(\"telemetry\"), TelemetryConfig.getTelemetryDirectory());\n+        // THEN\n+        verify(mqttClient, timeout(1000).atLeastOnce()).publish(captor.capture());\n+        List<PublishRequest> prs = captor.getAllValues();\n+        for (PublishRequest pr : prs) {\n+            try {\n+                MetricsPayload mp = new ObjectMapper().readValue(pr.getPayload(), MetricsPayload.class);\n+                //There will be nothing to aggregate as publish happens at 1st second and aggregation at 2nd second.\n+                // So, there will only one accumulated data point for each namespace during the first publish\n+                assertEquals(kernel.getContext().get(MetricsAggregator.class)\n+                        .getNamespaceSet().getNamespaces().size(), mp.getAggregatedMetricList().size());\n+                assertEquals(QualityOfService.AT_LEAST_ONCE, pr.getQos());\n+                assertEquals(DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", \"\"), pr.getTopic());\n+                assertEquals(\"2020-07-30\", mp.getSchema());\n+                // enough to verify the first message of type MetricsPayload\n+                break;\n+            } catch (IOException e) {\n+                System.out.println(\"Ignore if the publish message is not of MetricsPayload type\");", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg0NTAyOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493845028", "bodyText": "FSS and TelemetryAgent write to the same topic. MetricsPayload is only for Telemetry. FSS has other type. The reason for adding the try catch was for that purpose.\nI can check in the exception if it is of type FSS and fail if not?", "author": "saranyailla", "createdAt": "2020-09-23T19:32:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg0NTc1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493845752", "bodyText": "Cloud is setup to deserialize 2 different types on the same topic?", "author": "MikeDombo", "createdAt": "2020-09-23T19:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMTIzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494601230", "bodyText": "FSS and telemetry log to different topics. If you are unable to deserialize the payload, then fail.", "author": "nikkhilmuthye", "createdAt": "2020-09-24T20:47:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMjQzMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493832433", "bodyText": "do this after everything has shutdown since otherwise you may be losing telemetry.\nMaybe put it right before the context close", "author": "MikeDombo", "createdAt": "2020-09-23T19:09:04Z", "path": "src/main/java/com/aws/greengrass/lifecyclemanager/KernelLifecycle.java", "diffHunk": "@@ -255,6 +256,8 @@ public void shutdown(int timeoutSeconds) {\n             return;\n         }\n         close(tlog);\n+        //close the telemetry logger context\n+        TelemetryConfig.getInstance().closeContext();", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMzI3OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493833278", "bodyText": "if connection flips on and off very quickly, will this be doing the right thing?\nWhy do you re-schedule when the connection is resumed? Isn't the old schedule still going fine?", "author": "MikeDombo", "createdAt": "2020-09-23T19:10:38Z", "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    public static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator;\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzkxNzIwNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493917206", "bodyText": "The idea was to publish once as soon as the connection resumes irrespective of the ongoing schedule. But you are right, there is no reason to reschedule again with the same interval.", "author": "saranyailla", "createdAt": "2020-09-23T21:54:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMzI3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDY1Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493834653", "bodyText": "must we sleep? We highly advise against randomly sleeping.", "author": "MikeDombo", "createdAt": "2020-09-23T19:13:12Z", "path": "src/test/java/com/aws/greengrass/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.aws.greengrass.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.greengrass.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.greengrass.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final String sm = \"SystemMetrics\";\n+    private final NamespaceSet namespaceSet = new NamespaceSet();\n+    private final MetricFactory mf = new MetricFactory(sm);\n+    @TempDir\n+    protected Path tempRootDir;\n+    private MetricsAggregator ma;\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    @BeforeEach\n+    void setup() {\n+        namespaceSet.addNamespace(sm);\n+        ma = new MetricsAggregator(namespaceSet);\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+    }\n+\n+    @AfterEach\n+    void cleanup() {\n+        TelemetryConfig.getInstance().closeContext();\n+    }\n+\n+    @Test\n+    void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        Metric m3 = new Metric(sm, \"TotalNumberOfFDs\", TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1, 10);\n+        mf.putMetricData(m2, 2000);\n+        mf.putMetricData(m3, 4000);\n+        mf.putMetricData(m1, 20);\n+        mf.putMetricData(m2, 3000);\n+        mf.putMetricData(m3, 5000);\n+        mf.putMetricData(m1, 30);\n+        mf.putMetricData(m2, 4000);\n+        mf.putMetricData(m3, 6000);\n+        Thread.sleep(100);\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\n+                \"AggregateMetrics.log\");\n+        List<String> list = Files.readAllLines(path);\n+        assertEquals(ma.getNamespaceSet().getNamespaces().size(), list.size()); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    AggregatedMetric.class);\n+            if (am.getNamespace().equals(sm)) {\n+                assertEquals(3, am.getMetrics().size()); // Three system metrics\n+                for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getName().equals(\"CpuUsage\")) {\n+                        assertEquals((double) 60, metrics.getValue().get(\"Sum\"));\n+                    } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                        assertEquals((double) 3000, metrics.getValue().get(\"Average\"));\n+                    } else if (metrics.getName().equals(\"TotalNumberOfFDs\")) {\n+                        assertEquals((double) 6000, metrics.getValue().get(\"Maximum\"));\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        currTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        list = Files.readAllLines(path);\n+        assertEquals(2, list.size()); // AggregateMetrics.log is appended with the latest aggregations.\n+        for (String s : list) {\n+            GreengrassLogMessage egLog = mapper.readValue(s, GreengrassLogMessage.class);\n+            AggregatedMetric am = mapper.readValue(egLog.getMessage(),\n+                    AggregatedMetric.class);\n+            if (am.getTimestamp() == currTimestamp && am.getNamespace().equals(\"SystemMetrics\")) {\n+                assertEquals(0, am.getMetrics().size()); // There is no aggregation as there are no latest values\n+            }\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_invalid_metrics_WHEN_aggregate_THEN_parse_them_properly(ExtensionContext exContext) throws IOException,\n+            InterruptedException {\n+        //Create a sample file with aggregated metrics so we can test the freshness of the file and logs\n+        // with respect to the current timestamp\n+        ignoreExceptionOfType(exContext, MismatchedInputException.class);\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        // Put null data\n+        mf.putMetricData(m1, null);\n+\n+        // Put invalid data for average aggregation\n+        mf.putMetricData(m2, \"banana\");\n+        mf.putMetricData(m2, 2000);\n+        //put invalid metric\n+        mf.logMetrics(new TelemetryLoggerMessage(\"alfredo\"));\n+        Thread.sleep(100);\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, Instant.now().toEpochMilli());\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\"AggregateMetrics.log\");\n+        List<String> list = Files.readAllLines(path);\n+        assertEquals(ma.getNamespaceSet().getNamespaces().size(), list.size()); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    AggregatedMetric.class);\n+            if (am.getNamespace().equals(sm)) {\n+                assertEquals(2, am.getMetrics().size()); // Two system metrics, one of them is null\n+                for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getName().equals(\"CpuUsage\")) {\n+                        assertEquals((double) 0, metrics.getValue().get(\"Sum\")); //No valid data point to aggregate\n+                    } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                        assertEquals((double) 1000, metrics.getValue().get(\"Average\")); // ignore the invalid value\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_aggregated_metrics_WHEN_publish_THEN_collect_only_the_latest_values() throws InterruptedException {\n+        //Create a sample file with aggregated metrics so we can test the freshness of the file and logs\n+        // with respect to the current timestamp\n+        long lastPublish = Instant.now().toEpochMilli();\n+//        MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        List<AggregatedMetric.Metric> metricList = new ArrayList<>();\n+        Map<String, Object> map = new HashMap<>();\n+        map.put(\"Average\", 4000);\n+        metricList.add(new AggregatedMetric.Metric(\"TotalNumberOfFDs\", map, TelemetryUnit.Count));\n+        map.put(\"Average\", 15);\n+        metricList.add(new AggregatedMetric.Metric(\"CpuUsage\", map, TelemetryUnit.Percent));\n+        map.put(\"Average\", 9000);\n+        metricList.add(new AggregatedMetric.Metric(\"SystemMemUsage\", map, TelemetryUnit.Megabytes));\n+        AggregatedMetric aggregatedMetric = new AggregatedMetric(currentTimestamp, sm, metricList);\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        Thread.sleep(100);\n+        // Create an instance of the metrics uploader to get the aggregated metrics\n+        Map<Long, List<AggregatedMetric>> list = ma.getMetricsToPublish(lastPublish, currentTimestamp);\n+\n+        //We perform aggregation on the aggregated data points at the time of publish and get n additional metrics with\n+        // the current timestamp where n = no of namespaces. In this test, we have only 1 namespace i.e SystemMetrics\n+        assertEquals(1, list.get(currentTimestamp).size());\n+        currentTimestamp = Instant.now().toEpochMilli();\n+        list = ma.getMetricsToPublish(lastPublish, currentTimestamp);\n+        lastPublish = currentTimestamp;\n+        // we only have one list of the metrics collected\n+        assertEquals(1, list.size());\n+\n+        //we have 3 entries of the aggregated metrics before this latest TS + 1 entry which is the aggregation of those\n+        // 3 entries\n+        assertEquals(4, list.get(currentTimestamp).size());\n+\n+        Thread.sleep(1000);", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDg5OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493834898", "bodyText": "this shouldn't be needed. It is highly suspect.", "author": "MikeDombo", "createdAt": "2020-09-23T19:13:41Z", "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);\n+        Topic periodicAggregateMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC, \"1\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC))\n+                .thenReturn(periodicAggregateMetricsIntervalSec);\n+        Topic periodicPublishMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC, \"3\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC))\n+                .thenReturn(periodicPublishMetricsIntervalSec);\n+        Topic lastPeriodicAggregateTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC))\n+                .thenReturn(lastPeriodicAggregateTime);\n+        Topic lastPeriodicPublishTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC))\n+                .thenReturn(lastPeriodicPublishTime);\n+        Topic thingNameTopic = Topic.of(context, DEVICE_PARAM_THING_NAME, \"testThing\");\n+        when(config.lookup(DEVICE_PARAM_THING_NAME)).thenReturn(thingNameTopic);\n+        when(mockDeviceConfiguration.getThingName()).thenReturn(thingNameTopic);\n+        Topic telemetryMetricsPublishTopic = Topic.of(context, TELEMETRY_METRICS_PUBLISH_TOPICS,\n+                DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC);\n+        when(config.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS))\n+                .thenReturn(telemetryMetricsPublishTopic);\n+        telemetryAgent = spy(new TelemetryAgent(config, mockMqttClient, mockDeviceConfiguration, ma, sme, kme, ses));\n+    }\n+\n+    @AfterEach\n+    public void cleanUp() throws IOException, InterruptedException {\n+        TelemetryConfig.getInstance().closeContext();\n+        telemetryAgent.shutdown();\n+        ses.shutdown();\n+        Thread.sleep(500);", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg0Njg2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493846865", "bodyText": "Threads are still running even after shutdown causing DirectoryNotEmptyException on windows. I have not seen that error since I have added this.", "author": "saranyailla", "createdAt": "2020-09-23T19:35:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDg5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1MDQ1OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493850458", "bodyText": "use shutdownnow, that interrupts the threads", "author": "MikeDombo", "createdAt": "2020-09-23T19:42:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNzczMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493837733", "bodyText": "use shutdownNow", "author": "MikeDombo", "createdAt": "2020-09-23T19:19:06Z", "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);\n+        Topic periodicAggregateMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC, \"1\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC))\n+                .thenReturn(periodicAggregateMetricsIntervalSec);\n+        Topic periodicPublishMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC, \"3\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC))\n+                .thenReturn(periodicPublishMetricsIntervalSec);\n+        Topic lastPeriodicAggregateTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC))\n+                .thenReturn(lastPeriodicAggregateTime);\n+        Topic lastPeriodicPublishTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC))\n+                .thenReturn(lastPeriodicPublishTime);\n+        Topic thingNameTopic = Topic.of(context, DEVICE_PARAM_THING_NAME, \"testThing\");\n+        when(config.lookup(DEVICE_PARAM_THING_NAME)).thenReturn(thingNameTopic);\n+        when(mockDeviceConfiguration.getThingName()).thenReturn(thingNameTopic);\n+        Topic telemetryMetricsPublishTopic = Topic.of(context, TELEMETRY_METRICS_PUBLISH_TOPICS,\n+                DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC);\n+        when(config.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS))\n+                .thenReturn(telemetryMetricsPublishTopic);\n+        telemetryAgent = spy(new TelemetryAgent(config, mockMqttClient, mockDeviceConfiguration, ma, sme, kme, ses));\n+    }\n+\n+    @AfterEach\n+    public void cleanUp() throws IOException, InterruptedException {\n+        TelemetryConfig.getInstance().closeContext();\n+        telemetryAgent.shutdown();\n+        ses.shutdown();", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ5NDYzOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494494639", "bodyText": "^", "author": "MikeDombo", "createdAt": "2020-09-24T17:36:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNzczMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzODA0Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493838047", "bodyText": "remove this now that you close it in the kernel shutdown", "author": "MikeDombo", "createdAt": "2020-09-23T19:19:39Z", "path": "src/test/java/com/aws/greengrass/testcommons/testutilities/ExceptionLogProtector.java", "diffHunk": "@@ -148,7 +149,9 @@ public void beforeEach(ExtensionContext context) throws Exception {\n     @SneakyThrows\n     public void afterEach(ExtensionContext context) throws Exception {\n         Slf4jLogAdapter.removeGlobalListener(getListener(context));\n-\n+        //Stop the telemetry logger context after each test so we can delete the telemetry log files that are created\n+        // during the test.\n+        TelemetryConfig.getInstance().closeContext();", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyNjk1NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493826955", "bodyText": "You can remove this e2e test.", "author": "nikkhilmuthye", "createdAt": "2020-09-23T18:59:54Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyNzY1Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493827657", "bodyText": "Should wait for MetricAgent to start right?", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:00:35Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyODMxMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493828313", "bodyText": "use TimeUnit.SECONDS.sleep(4)", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:01:31Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyOTIxMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493829212", "bodyText": "You need to await this CDLatch to make sure that the service is actually running. Also, make that new CountDownLatch(1); since there is only one name you are waiting to be started.", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:03:06Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDE5MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830191", "bodyText": "You need to verify the number of metrics as well. that should be (aggregation interval/publish interval) + 1", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:04:51Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);\n+        assertTrue(Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)) > lastAgg);\n+\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay < periodicInterval);\n+        // telemetry logs are always written to ~root/telemetry\n+        assertEquals(kernel.getRootPath().resolve(\"telemetry\"), TelemetryConfig.getTelemetryDirectory());\n+        // THEN\n+        verify(mqttClient, timeout(1000).atLeastOnce()).publish(captor.capture());\n+        List<PublishRequest> prs = captor.getAllValues();\n+        for (PublishRequest pr : prs) {\n+            try {\n+                MetricsPayload mp = new ObjectMapper().readValue(pr.getPayload(), MetricsPayload.class);\n+                //There will be nothing to aggregate as publish happens at 1st second and aggregation at 2nd second.\n+                // So, there will only one accumulated data point for each namespace during the first publish\n+                assertEquals(kernel.getContext().get(MetricsAggregator.class)", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTgzMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493831832", "bodyText": "any reason to inject the NamespaceSet and get use a getter on the NAMESPACE field?", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:07:55Z", "path": "src/main/java/com/aws/greengrass/lifecyclemanager/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.lifecyclemanager;\n+\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.NamespaceSet;\n+import com.aws.greengrass.telemetry.PeriodicMetricsEmitter;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String NAMESPACE = \"GreengrassComponents\";\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     * @param namespaceSet {@link NamespaceSet}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel, NamespaceSet namespaceSet) {\n+        super();", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMjg5NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493832895", "bodyText": "Same here, just use a @Getter on the field right? or make it package private?", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:09:59Z", "path": "src/main/java/com/aws/greengrass/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import javax.inject.Inject;\n+\n+public class SystemMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(SystemMetricsEmitter.class);\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String NAMESPACE = \"SystemMetrics\";\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+    private long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+    /**\n+     * Constructor for the class.\n+     * @param namespaceSet {@link NamespaceSet}\n+     */\n+    @Inject\n+    public SystemMetricsEmitter(NamespaceSet namespaceSet) {", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNTc4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493835788", "bodyText": "they should by default be 0 right?", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:15:16Z", "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    public static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg0MzIyNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493843226", "bodyText": "right, will remove it", "author": "saranyailla", "createdAt": "2020-09-23T19:29:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNTc4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzODQxMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493838413", "bodyText": "Change the topic to be $aws/things/{thingName}/greengrass/health/json", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:20:21Z", "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg0MzAyOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493843028", "bodyText": "Oops, I changed it back to this.", "author": "saranyailla", "createdAt": "2020-09-23T19:28:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzODQxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzOTM2Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493839366", "bodyText": "I don't see why this has to be a class.", "author": "nikkhilmuthye", "createdAt": "2020-09-23T19:22:04Z", "path": "src/main/java/com/aws/greengrass/telemetry/NamespaceSet.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.aws.greengrass.telemetry;\n+\n+import lombok.Getter;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class NamespaceSet {", "originalCommit": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg4MDgxOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493880819", "bodyText": "https://github.com/aws/aws-greengrass-kernel/pull/378/files/000381241095f37a8693d0119fecbad90061f855#diff-30b6c1e7f3017c5e6d429968edc754a4R37 for couple other comments.", "author": "saranyailla", "createdAt": "2020-09-23T20:39:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzOTM2Ng=="}], "type": "inlineReview"}, {"oid": "62b187c5feb711507ee6a0ca1af15a2c39b8fb4d", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/62b187c5feb711507ee6a0ca1af15a2c39b8fb4d", "message": "remove namespace set + get namespaces using loggercontext + update integ tests, remove e2e tests + other changes", "committedDate": "2020-09-23T23:13:04Z", "type": "commit"}, {"oid": "363d5211c7b1c00b9398a7770ef1a2647e93621f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/363d5211c7b1c00b9398a7770ef1a2647e93621f", "message": "update tests", "committedDate": "2020-09-24T00:48:56Z", "type": "commit"}, {"oid": "d9d2a79044108efb574ef45555b9d4c4c25a0151", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d9d2a79044108efb574ef45555b9d4c4c25a0151", "message": "use shutdownNow()", "committedDate": "2020-09-24T01:29:12Z", "type": "commit"}, {"oid": "7da553e7b83954dec40d4e4a46956651e61bc6bc", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7da553e7b83954dec40d4e4a46956651e61bc6bc", "message": "use shutdownNow()", "committedDate": "2020-09-24T01:36:07Z", "type": "commit"}, {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c27c902fe03b4e85c20ece0e798143c10e7af88e", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-24T01:36:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDA1MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994050", "bodyText": "assert true whenever you await on a CDL", "author": "MikeDombo", "createdAt": "2020-09-24T01:56:01Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        telemetryRunning.await(10, TimeUnit.SECONDS);", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDE2Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994162", "bodyText": "you never await this? So why have it at all?", "author": "MikeDombo", "createdAt": "2020-09-24T01:56:28Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(1);", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDgyNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994826", "bodyText": "this is a hack. don't do this", "author": "MikeDombo", "createdAt": "2020-09-24T01:59:13Z", "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,368 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Get the set of all the namespaces created using MetricsFactory. This method assumes that MetricFactory will be\n+     * used only to emit and aggregate metrics.\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        for (ch.qos.logback.classic.Logger logger : TelemetryConfig.getInstance().getContext().getLoggerList()) {", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTExNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995116", "bodyText": "there shouldn't even be a getter for the context. that should be removed. It exposes far too much of the implementation details", "author": "MikeDombo", "createdAt": "2020-09-24T02:00:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDgyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTYxMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995610", "bodyText": "don't mock the context if you're just going to use a real context anyway", "author": "MikeDombo", "createdAt": "2020-09-24T02:02:11Z", "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTY0OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995649", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-09-24T02:02:19Z", "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTg2Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995866", "bodyText": "this is going to cause a kernel to be created. This is not a proper unit test", "author": "MikeDombo", "createdAt": "2020-09-24T02:03:13Z", "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);", "originalCommit": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "138aeda5a7370b5922081cfbe5c1849c93b0ef13", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/138aeda5a7370b5922081cfbe5c1849c93b0ef13", "message": "mock the classes properly in tests", "committedDate": "2020-09-24T02:15:01Z", "type": "commit"}, {"oid": "d83ed45c0b896d9ff2f87497030a11bf8911d95c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d83ed45c0b896d9ff2f87497030a11bf8911d95c", "message": "mock the classes properly in tests", "committedDate": "2020-09-24T02:37:29Z", "type": "commit"}, {"oid": "171b5ff54f9622544b78f65617c32ff3197070da", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/171b5ff54f9622544b78f65617c32ff3197070da", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-24T02:41:51Z", "type": "commit"}, {"oid": "275101e8d3963e7f4404a2ad54e48a1323ed9681", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/275101e8d3963e7f4404a2ad54e48a1323ed9681", "message": "close context", "committedDate": "2020-09-24T02:52:34Z", "type": "commit"}, {"oid": "09b401ca39ef258db27a316519ee7ccffc2f747f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/09b401ca39ef258db27a316519ee7ccffc2f747f", "message": "get namespaces from telemetry files directory + tests", "committedDate": "2020-09-24T04:10:04Z", "type": "commit"}, {"oid": "efe8ff15000f359f3911610ea4d7470958f05db6", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/efe8ff15000f359f3911610ea4d7470958f05db6", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-24T04:10:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAzOTg0NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494039845", "bodyText": "static", "author": "MikeDombo", "createdAt": "2020-09-24T05:01:35Z", "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();", "originalCommit": "efe8ff15000f359f3911610ea4d7470958f05db6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "43b1327d170c18c423610454c698484505b791a5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/43b1327d170c18c423610454c698484505b791a5", "message": "await termination", "committedDate": "2020-09-24T07:48:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMDMxNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494600314", "bodyText": "remove", "author": "nikkhilmuthye", "createdAt": "2020-09-24T20:45:46Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());", "originalCommit": "43b1327d170c18c423610454c698484505b791a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMDY0MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494600640", "bodyText": "The message should convey why it failed.", "author": "nikkhilmuthye", "createdAt": "2020-09-24T20:46:28Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is in RUNNING state.\");", "originalCommit": "43b1327d170c18c423610454c698484505b791a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDIzNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610234", "bodyText": "nit: Make this TODO say, Get accumulated data points during aggregation and cache it to the disk.", "author": "nikkhilmuthye", "createdAt": "2020-09-24T21:05:43Z", "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average", "originalCommit": "43b1327d170c18c423610454c698484505b791a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDU5Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610597", "bodyText": "Does this need to be public? If so, put it in its own class.", "author": "nikkhilmuthye", "createdAt": "2020-09-24T21:06:29Z", "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average\n+        aggUploadMetrics.compute(currTimestamp, (k, v) -> {\n+            v.addAll(getAggForThePublishInterval(aggUploadMetrics.get(currTimestamp), currTimestamp));\n+            return v;\n+        });\n+        return aggUploadMetrics;\n+    }\n+\n+    /**\n+     * This function takes a list of aggregated metrics and returns their aggregation in a list(Aggregation of\n+     * aggregated metrics). This is published to the cloud along with the aggregated metric points\n+     * Example:\n+     * Input:\n+     * TS:123456\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 20,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 5,U - Count\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     * Output:\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 15,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 10,U - Count\n+     *\n+     * @param aggList list of {@link AggregatedMetric}\n+     * @return a list of {@link AggregatedMetric}\n+     */\n+    private List<AggregatedMetric> getAggForThePublishInterval(List<AggregatedMetric> aggList, long currTimestamp) {\n+        List<AggregatedMetric> list = new ArrayList<>();\n+        for (String namespace : getNamespaceSet()) {\n+            HashMap<String, List<AggregatedMetric.Metric>> metrics = new HashMap<>();\n+            AggregatedMetric newAgg = new AggregatedMetric();\n+            for (AggregatedMetric am : aggList) {\n+                if (am.getNamespace().equals(namespace)) {\n+                    for (AggregatedMetric.Metric m : am.getMetrics()) {\n+                        metrics.computeIfAbsent(m.getName(), k -> new ArrayList<>()).add(m);\n+                    }\n+                }\n+            }\n+            newAgg.setNamespace(namespace);\n+            newAgg.setTimestamp(currTimestamp);\n+            newAgg.setMetrics(doAggregationForPublish(metrics));\n+            list.add(newAgg);\n+        }\n+        return list;\n+    }\n+\n+    /**\n+     * This function takes in the map of aggregated metrics with metric name as key and returns a list of metrics with\n+     * aggregation.\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___N - NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N - NumOfComponentsInstalled,Average - 15,U - Count\n+     * NumOfComponentsBroken\n+     * |___N - NumOfComponentsBroken,Average - 10,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 20,U - Count\n+     * Output:\n+     * |___N - NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> aggregated metric\n+     * @return list of {@link AggregatedMetric.Metric }\n+     */\n+    private List<AggregatedMetric.Metric> doAggregationForPublish(Map<String, List<AggregatedMetric.Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<AggregatedMetric.Metric>> metric : map.entrySet()) {\n+            List<AggregatedMetric.Metric> metrics = metric.getValue();\n+            List<Double> values = new ArrayList<>();\n+            metrics.get(0).getValue().forEach((aggType, aggValue) -> {\n+                metrics.forEach((v) -> values.add(Coerce.toDouble(v.getValue().get(aggType))));\n+                Map<String, Object> value = new HashMap<>();\n+                value.put(aggType, values.isEmpty() ? 0 : getAggregatedValue(values, aggType));\n+                AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                        .name(metric.getKey())\n+                        .unit(metrics.get(0).getUnit())\n+                        .value(value)\n+                        .build();\n+                aggMetrics.add(m);\n+            });\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the list of values of the metrics.\n+     *\n+     * @param values          list of the values extracted from the metrics\n+     * @param aggregationType string value of {@link com.aws.greengrass.telemetry.models.TelemetryAggregation}\n+     * @return returns an aggregated value for the entire list.\n+     */\n+    private double getAggregatedValue(List<Double> values, String aggregationType) {\n+        double aggregation = 0;\n+        switch (aggregationType) {\n+            case \"Average\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                if (!values.isEmpty()) {\n+                    aggregation = aggregation / values.size();\n+                }\n+                break;\n+            case \"Sum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                break;\n+            case \"Maximum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).max().getAsDouble();\n+                break;\n+            case \"Minimum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).min().getAsDouble();\n+                break;\n+            default:\n+                logger.atError().log(\"Unknown aggregation type: {}\", aggregationType);\n+                break;\n+        }\n+        return aggregation;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {", "originalCommit": "43b1327d170c18c423610454c698484505b791a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxNDE1OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494614159", "bodyText": "It used to be in its own class. You asked me to keep it inside this class. I am using these in tests.", "author": "saranyailla", "createdAt": "2020-09-24T21:13:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDY4Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610683", "bodyText": "same here", "author": "nikkhilmuthye", "createdAt": "2020-09-24T21:06:42Z", "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average\n+        aggUploadMetrics.compute(currTimestamp, (k, v) -> {\n+            v.addAll(getAggForThePublishInterval(aggUploadMetrics.get(currTimestamp), currTimestamp));\n+            return v;\n+        });\n+        return aggUploadMetrics;\n+    }\n+\n+    /**\n+     * This function takes a list of aggregated metrics and returns their aggregation in a list(Aggregation of\n+     * aggregated metrics). This is published to the cloud along with the aggregated metric points\n+     * Example:\n+     * Input:\n+     * TS:123456\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 20,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 5,U - Count\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     * Output:\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 15,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 10,U - Count\n+     *\n+     * @param aggList list of {@link AggregatedMetric}\n+     * @return a list of {@link AggregatedMetric}\n+     */\n+    private List<AggregatedMetric> getAggForThePublishInterval(List<AggregatedMetric> aggList, long currTimestamp) {\n+        List<AggregatedMetric> list = new ArrayList<>();\n+        for (String namespace : getNamespaceSet()) {\n+            HashMap<String, List<AggregatedMetric.Metric>> metrics = new HashMap<>();\n+            AggregatedMetric newAgg = new AggregatedMetric();\n+            for (AggregatedMetric am : aggList) {\n+                if (am.getNamespace().equals(namespace)) {\n+                    for (AggregatedMetric.Metric m : am.getMetrics()) {\n+                        metrics.computeIfAbsent(m.getName(), k -> new ArrayList<>()).add(m);\n+                    }\n+                }\n+            }\n+            newAgg.setNamespace(namespace);\n+            newAgg.setTimestamp(currTimestamp);\n+            newAgg.setMetrics(doAggregationForPublish(metrics));\n+            list.add(newAgg);\n+        }\n+        return list;\n+    }\n+\n+    /**\n+     * This function takes in the map of aggregated metrics with metric name as key and returns a list of metrics with\n+     * aggregation.\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___N - NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N - NumOfComponentsInstalled,Average - 15,U - Count\n+     * NumOfComponentsBroken\n+     * |___N - NumOfComponentsBroken,Average - 10,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 20,U - Count\n+     * Output:\n+     * |___N - NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> aggregated metric\n+     * @return list of {@link AggregatedMetric.Metric }\n+     */\n+    private List<AggregatedMetric.Metric> doAggregationForPublish(Map<String, List<AggregatedMetric.Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<AggregatedMetric.Metric>> metric : map.entrySet()) {\n+            List<AggregatedMetric.Metric> metrics = metric.getValue();\n+            List<Double> values = new ArrayList<>();\n+            metrics.get(0).getValue().forEach((aggType, aggValue) -> {\n+                metrics.forEach((v) -> values.add(Coerce.toDouble(v.getValue().get(aggType))));\n+                Map<String, Object> value = new HashMap<>();\n+                value.put(aggType, values.isEmpty() ? 0 : getAggregatedValue(values, aggType));\n+                AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                        .name(metric.getKey())\n+                        .unit(metrics.get(0).getUnit())\n+                        .value(value)\n+                        .build();\n+                aggMetrics.add(m);\n+            });\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the list of values of the metrics.\n+     *\n+     * @param values          list of the values extracted from the metrics\n+     * @param aggregationType string value of {@link com.aws.greengrass.telemetry.models.TelemetryAggregation}\n+     * @return returns an aggregated value for the entire list.\n+     */\n+    private double getAggregatedValue(List<Double> values, String aggregationType) {\n+        double aggregation = 0;\n+        switch (aggregationType) {\n+            case \"Average\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                if (!values.isEmpty()) {\n+                    aggregation = aggregation / values.size();\n+                }\n+                break;\n+            case \"Sum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                break;\n+            case \"Maximum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).max().getAsDouble();\n+                break;\n+            case \"Minimum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).min().getAsDouble();\n+                break;\n+            default:\n+                logger.atError().log(\"Unknown aggregation type: {}\", aggregationType);\n+                break;\n+        }\n+        return aggregation;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private String namespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+\n+        @Data\n+        @NoArgsConstructor\n+        @AllArgsConstructor\n+        @Builder\n+        public static class Metric {", "originalCommit": "43b1327d170c18c423610454c698484505b791a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bc9918a2588074440917278a5acb0aa112d950d0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bc9918a2588074440917278a5acb0aa112d950d0", "message": "separate classes for aggreagte metrics + update tests", "committedDate": "2020-09-24T22:19:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY2MDQ4Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494660482", "bodyText": "[nit]\nRemove testinfo, unused.", "author": "MikeDombo", "createdAt": "2020-09-24T23:15:04Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {", "originalCommit": "bc9918a2588074440917278a5acb0aa112d950d0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3Nzg4Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494677887", "bodyText": "nit: Add copywrite", "author": "nikkhilmuthye", "createdAt": "2020-09-25T00:14:43Z", "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetric.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.aws.greengrass.telemetry;", "originalCommit": "bc9918a2588074440917278a5acb0aa112d950d0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3NzkwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494677904", "bodyText": "nit: Add copywrite", "author": "nikkhilmuthye", "createdAt": "2020-09-25T00:14:48Z", "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetricList.java", "diffHunk": "@@ -0,0 +1,22 @@\n+package com.aws.greengrass.telemetry;", "originalCommit": "bc9918a2588074440917278a5acb0aa112d950d0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3ODY3Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494678677", "bodyText": "Can you rename this to something not ending in List since it contains more than a list? Maybe just AggregatedNamespaceData since it is for a namespace? unless you can come up with a better name", "author": "nikkhilmuthye", "createdAt": "2020-09-25T00:17:52Z", "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetricList.java", "diffHunk": "@@ -0,0 +1,22 @@\n+package com.aws.greengrass.telemetry;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.util.List;\n+\n+@Data\n+@Builder\n+@NoArgsConstructor\n+@AllArgsConstructor\n+public class AggregatedMetricList {", "originalCommit": "bc9918a2588074440917278a5acb0aa112d950d0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f95bf07008d53fd815b549751d069f46c1f1109e", "message": "Rename to AggregateNamespaceData + copyright", "committedDate": "2020-09-25T01:01:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNjkyOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494736929", "bodyText": "1 minute is way too long. Try more like 10 seconds at most. We'd like tests to fail fast.", "author": "MikeDombo", "createdAt": "2020-09-25T04:13:11Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");", "originalCommit": "f95bf07008d53fd815b549751d069f46c1f1109e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzAwNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737007", "bodyText": "use kernel.findServiceTopics(<servicename>)", "author": "MikeDombo", "createdAt": "2020-09-25T04:13:32Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);", "originalCommit": "f95bf07008d53fd815b549751d069f46c1f1109e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzExOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737118", "bodyText": "use or create a constant for \"TelemetryAgent\" and use it in the @ImplementsService declaration", "author": "MikeDombo", "createdAt": "2020-09-25T04:14:01Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");", "originalCommit": "f95bf07008d53fd815b549751d069f46c1f1109e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzIyMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737222", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-09-25T04:14:20Z", "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay <= periodicInterval);\n+        //telemetry configurations are set correctly\n+        assertEquals(2, aggregateInterval);\n+        assertEquals(4, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);", "originalCommit": "f95bf07008d53fd815b549751d069f46c1f1109e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1e5623f5e409f2efa7d19db09362166efaa4ad05", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1e5623f5e409f2efa7d19db09362166efaa4ad05", "message": "modify tests with timeout and findservicetopics", "committedDate": "2020-09-25T04:43:34Z", "type": "commit"}, {"oid": "684e1829317055c283470b43d54a859668af59e3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/684e1829317055c283470b43d54a859668af59e3", "message": "Merge branch 'master' into telemetry-logs", "committedDate": "2020-09-25T07:06:31Z", "type": "commit"}, {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/3b5fcf28288381e8c3dce1f31f868dc32d02016f", "message": "Telemetry service to log kernel component state metrics", "committedDate": "2020-08-21T21:46:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODQyNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988426", "bodyText": "remove this. You shouldn't have both field and constructor injection", "author": "MikeDombo", "createdAt": "2020-08-21T22:01:23Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODQ5NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988495", "bodyText": "remove this. It isn't helpful at all as we already log lifecycle events.", "author": "MikeDombo", "createdAt": "2020-08-21T22:01:40Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject\n+    private final Kernel kernel;\n+\n+    @Inject\n+    public MetricsAgent(Topics topics, Kernel kernel) {\n+        super(topics);\n+        this.kernel = kernel;\n+    }\n+\n+    @Override\n+    protected void startup() {\n+        logger.atInfo().log(\"Starting MetricsAgent.\");", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODU3OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988579", "bodyText": "remove this if you're not doing anything", "author": "MikeDombo", "createdAt": "2020-08-21T22:02:00Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject\n+    private final Kernel kernel;\n+\n+    @Inject\n+    public MetricsAgent(Topics topics, Kernel kernel) {\n+        super(topics);\n+        this.kernel = kernel;\n+    }\n+\n+    @Override\n+    protected void startup() {\n+        logger.atInfo().log(\"Starting MetricsAgent.\");\n+        reportState(State.RUNNING);\n+        metricsAgentFactory.collectTimeBasedMetrics(this.kernel);\n+    }\n+\n+    @Override\n+    protected void shutdown() {\n+        logger.atInfo().log(\"MetricsAgent is shutting down!\");\n+    }", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODc5Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988796", "bodyText": "pull this out into a method in this class", "author": "MikeDombo", "createdAt": "2020-08-21T22:02:51Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODk1OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988958", "bodyText": "didn't you have a const for that NUM_COMPONENTS?", "author": "MikeDombo", "createdAt": "2020-08-21T22:03:26Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgxODY2Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r475818666", "bodyText": "Yes, but I have to iterate through the EG services, get their state and increment the corresponding enum value.", "author": "saranyailla", "createdAt": "2020-08-24T18:39:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODk1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTA0MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989040", "bodyText": "reformat this file, there should be spaces around the :", "author": "MikeDombo", "createdAt": "2020-08-21T22:03:43Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());\n+                    numComponentState.put(telemetryMetricName, numComponentState.get(telemetryMetricName) + 1);\n+                }\n+\n+                for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> metricMap:metricsMap.entrySet()) {", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTI2Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989266", "bodyText": "Do not create a new threadpool. Use injection to get the threadpool from the context.\nKeep a reference to the output of the schedule so that you can cancel it when requested to stop.", "author": "MikeDombo", "createdAt": "2020-08-21T22:04:27Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());\n+                    numComponentState.put(telemetryMetricName, numComponentState.get(telemetryMetricName) + 1);\n+                }\n+\n+                for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> metricMap:metricsMap.entrySet()) {\n+                    MetricDataBuilder metricDataBuilder = metricMap.getValue();\n+                    metricDataBuilder.putMetricData(numComponentState.get(metricMap.getKey())).emit();\n+                    numComponentState.put(metricMap.getKey(),0);\n+                }\n+            }\n+        };\n+\n+        ScheduledExecutorService executor = Executors.newScheduledThreadPool(metricsMap.size());\n+        executor.scheduleAtFixedRate(emitMetrics, 0, period, TimeUnit.SECONDS);", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTQwMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989401", "bodyText": "normally we don't break these out into separate classes, you can just keep it where it is used.", "author": "MikeDombo", "createdAt": "2020-08-21T22:04:54Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/constants/DefaultMetricPeriod.java", "diffHunk": "@@ -0,0 +1,5 @@\n+package com.aws.iot.evergreen.telemetry.constants;\n+\n+public class DefaultMetricPeriod {", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTQ4Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989487", "bodyText": "Missing tests.", "author": "MikeDombo", "createdAt": "2020-08-21T22:05:02Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTUzNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989537", "bodyText": "remove spaces.", "author": "MikeDombo", "createdAt": "2020-08-21T22:05:13Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+", "originalCommit": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fd1e7ff14d913726778524300382d9419da84485", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/fd1e7ff14d913726778524300382d9419da84485", "message": "Use context for Executor, Move runnable code to another method, update emit metrics to match with sdk changes", "committedDate": "2020-08-24T21:48:37Z", "type": "commit"}, {"oid": "2009213d5abceae5a7670ecc38df60ec82e15f63", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2009213d5abceae5a7670ecc38df60ec82e15f63", "message": "Move component metrics code to kernel from MA Factory", "committedDate": "2020-08-25T21:16:46Z", "type": "commit"}, {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a3070f8e0be114a435e7a8da76eef7efe44a755f", "message": "Add system metrics", "committedDate": "2020-08-25T21:20:26Z", "type": "commit"}, {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a3070f8e0be114a435e7a8da76eef7efe44a755f", "message": "Add system metrics", "committedDate": "2020-08-25T21:20:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2OTc1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476769752", "bodyText": "Move everything you put in kernel into your new service", "author": "MikeDombo", "createdAt": "2020-08-25T21:48:59Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -540,4 +549,46 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    private void collectKernelComponentState() {", "originalCommit": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3MDY1Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476770657", "bodyText": "you need to add this library as a dependency", "author": "MikeDombo", "createdAt": "2020-08-25T21:50:01Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;", "originalCommit": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3MjE5MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476772190", "bodyText": "?", "author": "MikeDombo", "createdAt": "2020-08-25T21:51:50Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public  class MetricsAgentFactory {\n+    private static final int DEFAULT_SYSTEM_METRICS_PERIOD = 300;\n+    private static int MB_CONVERTER = 1024 * 1024;\n+    private static int PERCENTAGE_CONVERTER = 100;\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+\n+    /**\n+     * Kuch bhi.", "originalCommit": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d5e9abb0328e179dc0e161069923e8ed71ed4e66", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d5e9abb0328e179dc0e161069923e8ed71ed4e66", "message": "Add custom file location for metrics", "committedDate": "2020-08-27T18:26:32Z", "type": "commit"}, {"oid": "939dd8a1df5e3abb0439153187f1c9991249ea91", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/939dd8a1df5e3abb0439153187f1c9991249ea91", "message": "Add metrics aggregator and config", "committedDate": "2020-08-29T09:15:57Z", "type": "commit"}, {"oid": "5fcbab00f75e4ef38b421e1cc3fd7b00cb10c7c4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5fcbab00f75e4ef38b421e1cc3fd7b00cb10c7c4", "message": "add oshi dependency", "committedDate": "2020-08-29T21:18:48Z", "type": "commit"}, {"oid": "e7ee3231e416c1f16d7bd01e24a3fbc5b5616501", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e7ee3231e416c1f16d7bd01e24a3fbc5b5616501", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-08-29T21:23:05Z", "type": "commit"}, {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/044114b548f4eb239cb00d856aedbde52f3984bb", "message": "metrics uploader + metrics aggregator", "committedDate": "2020-08-31T19:39:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2ODgwMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480368803", "bodyText": "remove all of this from kernel. This class is huge. Move it to a separate class to handle kernel metrics which you may call from here.", "author": "MikeDombo", "createdAt": "2020-08-31T20:04:16Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -84,6 +93,13 @@\n     public static final String SERVICE_TYPE_TO_CLASS_MAP_KEY = \"componentTypeToClassMap\";\n     private static final String PLUGIN_SERVICE_TYPE_NAME = \"plugin\";\n \n+    // Kernel metrics\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD =\n+            telemetryDataConfigMap.get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2OTc1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480369752", "bodyText": "why are you doing this? Just take the name as-is, or use toUpperCase() or toLowerCase to regularize it.", "author": "MikeDombo", "createdAt": "2020-08-31T20:06:12Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDU3NzM0OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480577348", "bodyText": "I want the metric name to be \"NumOfComponentsRunning\" - v1 compatible naming. But the state enum is \"RUNNING\".", "author": "saranyailla", "createdAt": "2020-09-01T01:51:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2OTc1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MDM5Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480370397", "bodyText": "Catch the exception for if valueOf fails", "author": "MikeDombo", "createdAt": "2020-08-31T20:07:27Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MTQ5MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480371491", "bodyText": "this map doesn't need to be a field of the class", "author": "MikeDombo", "createdAt": "2020-08-31T20:09:37Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MjUxMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480372513", "bodyText": "Never do this.\nKernel manages your lifecycle correctly", "author": "MikeDombo", "createdAt": "2020-08-31T20:11:38Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    public static final Map<String, TelemetryDataConfig> telemetryDataConfigMap = createSampleConfiguration();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        // Is it always going to be true that STARTING precedes RUNNING?\n+        if (this.getState().equals(State.STARTING)) {", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MjU5NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480372594", "bodyText": "never do this", "author": "MikeDombo", "createdAt": "2020-08-31T20:11:47Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    public static final Map<String, TelemetryDataConfig> telemetryDataConfigMap = createSampleConfiguration();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        // Is it always going to be true that STARTING precedes RUNNING?\n+        if (this.getState().equals(State.STARTING)) {\n+            reportState(State.RUNNING);\n+            this.systemMetricsEmitter.collectSystemMetrics(getContext());\n+            this.metricsAggregator.aggregateMetrics(getContext());\n+            this.metricsUploader.uploadMetrics(getContext());\n+        } else {\n+            reportState(this.getState());\n+        }", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzAxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373015", "bodyText": "this is wrong. Get the path properly", "author": "MikeDombo", "createdAt": "2020-08-31T20:12:43Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzcxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373717", "bodyText": "This won't be clear at all .log(\"Failed reading metric logs\", e)", "author": "MikeDombo", "createdAt": "2020-08-31T20:14:10Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NjY5Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046692", "bodyText": "Same issue", "author": "MikeDombo", "createdAt": "2020-09-08T16:24:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzcxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzc2MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373761", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-08-31T20:14:16Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?\n+                 */\n+                logger.atInfo().log(new ObjectMapper().writeValueAsString(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0Njc4Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046783", "bodyText": "Still here", "author": "MikeDombo", "createdAt": "2020-09-08T16:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzg0MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373840", "bodyText": "use a switch", "author": "MikeDombo", "createdAt": "2020-08-31T20:14:26Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?\n+                 */\n+                logger.atInfo().log(new ObjectMapper().writeValueAsString(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        };\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics,\n+                                                        TelemetryAggregation telemetryAggregation) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            Object aggregation = null;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .max();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NDE5OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480374199", "bodyText": "we need a way to cancel this. Also to de-duplicate calls, otherwise we can have multiple aggregations going.", "author": "MikeDombo", "createdAt": "2020-08-31T20:15:07Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),", "originalCommit": "044114b548f4eb239cb00d856aedbde52f3984bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9b38867eeb049739046da321a88644c60faeacd5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9b38867eeb049739046da321a88644c60faeacd5", "message": "Moved kernel metrics to separate class + Update log messages", "committedDate": "2020-09-01T02:53:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyMzUwMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481223502", "bodyText": "does it have to be static?", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:17:23Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -83,7 +83,7 @@\n     public static final String SERVICE_TYPE_TOPIC_KEY = \"componentType\";\n     public static final String SERVICE_TYPE_TO_CLASS_MAP_KEY = \"componentTypeToClassMap\";\n     private static final String PLUGIN_SERVICE_TYPE_NAME = \"plugin\";\n-\n+    private static final KernelMetricsEmitter kernelMetricsEmitter = new KernelMetricsEmitter();", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyMzczNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481223737", "bodyText": "nit: add copywrite in all new files.", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:17:44Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNTgwMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481225802", "bodyText": "Why are you returning a runnable here? You can just save the kernel reference and metrics data map in the class. and just have a normal void function.", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:20:44Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(kernel, kernelMetricsData),\n+                0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics(Kernel kernel, Map<TelemetryMetricName, Integer> kernelMetricsData) {", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNjU3MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481226570", "bodyText": "I am not a big fan of this logic. Can you just subscribe to a topic and then start/stop the scheduled task based on that?", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:21:47Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNzUxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481227515", "bodyText": "nit: rename to startPeriodicTelemetryMetricsUpdate", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:23:06Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNzc5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481227793", "bodyText": "nit: format", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:23:33Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(kernel, kernelMetricsData),\n+                0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics(Kernel kernel, Map<TelemetryMetricName, Integer> kernelMetricsData) {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                try{\n+                    TelemetryMetricName telemetryMetricName =\n+                            TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                    kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+                } catch (IllegalArgumentException e) {\n+                    logger.atError().log(\"Unable to find the metric name.\" + e);\n+                }\n+            }\n+            for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> kernelMetric : kernelMetrics.entrySet()) {\n+                MetricDataBuilder metricDataBuilder = kernelMetric.getValue();\n+                metricDataBuilder.putMetricData(kernelMetricsData.get(kernelMetric.getKey())).emit();\n+                kernelMetricsData.put(kernelMetric.getKey(),0);", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyOTA5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481229093", "bodyText": "Instead of this just call super.startup()", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:25:28Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        reportState(State.RUNNING);", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMDExNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481230116", "bodyText": "Same comment here. Why use Runnable?", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:26:47Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+\n+    /**\n+     * Upload metrics on based on upload frequency.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void uploadMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config : MetricsAgent.createSampleConfiguration().entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndUpload(metricConfig),0, metricConfig.getUploadFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndUpload(TelemetryDataConfig config) {", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMDU3Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481230576", "bodyText": "nit: rename to startSystemTelemetryMetricsPeriodicUpdate", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:27:22Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,88 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static long SYSTEM_METRICS_PERIOD = createSampleConfiguration()\n+            .get(TelemetryNamespace.SystemMetrics.toString()).getEmitFrequency();\n+    private static String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+    private static Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();\n+\n+    /**\n+     * Create system metrics, collect and emit periodically.\n+     *\n+     */\n+    protected void collectSystemMetrics(Context context) {", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMTA2MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481231061", "bodyText": "Put this in its own class", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:28:03Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/aggregation/AggregatedMetric.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package com.aws.iot.evergreen.telemetry.aggregation;\n+\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import lombok.Builder;\n+import lombok.Data;\n+\n+import java.util.List;\n+\n+@Data\n+public class AggregatedMetric {\n+    @JsonProperty(\"TS\")\n+    private Long timestamp;\n+    @JsonProperty(\"NS\")\n+    private TelemetryNamespace metricNamespace;\n+    @JsonProperty(\"M\")\n+    private List<Metric> metric;\n+\n+    @Data\n+    @Builder\n+    public static class Metric {", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMjYxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481232615", "bodyText": "Need to get this from the logger. Look at how I have done it for the logs uploader. https://github.com/aws/aws-greengrass-sdk-java/pull/56/files#diff-bf04d24956d8f5f6cb2dc5a970349455R71\nMight want to do something similar for metrics.", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:30:05Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    public static final String LOG_FILES_PATH = System.getProperty(\"user.dir\") + \"/Telemetry/\";", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMzExOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481233118", "bodyText": "nit: Right. Instead add a TODO:", "author": "nikkhilmuthye", "createdAt": "2020-09-01T15:30:50Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    public static final String LOG_FILES_PATH = System.getProperty(\"user.dir\") + \"/Telemetry/\";\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: createSampleConfiguration().entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(LOG_FILES_PATH))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (fileName.toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Failed to read the telemetry logs for aggregation.\" + e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?", "originalCommit": "9b38867eeb049739046da321a88644c60faeacd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0782fa17b596f951f873e4a402fa0a2bca4e585c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/0782fa17b596f951f873e4a402fa0a2bca4e585c", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-08T07:33:23Z", "type": "commit"}, {"oid": "c1900ef340a313e29eec3027061f349b38bd093a", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c1900ef340a313e29eec3027061f349b38bd093a", "message": "Telemetry metrics + tests", "committedDate": "2020-09-08T07:37:04Z", "type": "commit"}, {"oid": "bf31cb5a50235c3b20a391be6058c839680f9e39", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bf31cb5a50235c3b20a391be6058c839680f9e39", "message": "Telemetry metrics + tests", "committedDate": "2020-09-08T07:41:14Z", "type": "commit"}, {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-08T07:41:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNjY1NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485036654", "bodyText": "Inject in the constructor instead of getting it from context.", "author": "MikeDombo", "createdAt": "2020-09-08T16:08:07Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzODg1MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485038850", "bodyText": "this is not correct. You're accessing \"parameters\" directly under the root, which it won't be. It will most likely be under \"system\", so you can look at the DeviceConfiguration class which is used to read that section", "author": "MikeDombo", "createdAt": "2020-09-08T16:11:36Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        kernel.getConfig().lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwMjc0Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485902742", "bodyText": "I modified. Could you check if that works?", "author": "saranyailla", "createdAt": "2020-09-09T20:28:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzODg1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzOTUxMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485039513", "bodyText": "log the exception not using concatentation. .log(\"...\", e)", "author": "MikeDombo", "createdAt": "2020-09-08T16:12:40Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        kernel.getConfig().lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);\n+    }\n+\n+    private void emitKernelMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name.\" + e);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDA4OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485040089", "bodyText": "cancel(true)? With true it will attempt to cancel the running instance.", "author": "MikeDombo", "createdAt": "2020-09-08T16:13:39Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3NjYyMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485076622", "bodyText": "Nikkhil and I had a discussion and decided that we want to finish off the ongoing tasks and then make changes to be in the upcoming ones with the new configuration.", "author": "saranyailla", "createdAt": "2020-09-08T17:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDA4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MjczMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485042732", "bodyText": "these should all be injected in the constructor so that you can actually test this code.", "author": "MikeDombo", "createdAt": "2020-09-08T16:17:37Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzExMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043112", "bodyText": "Use dependency injection to get this, don't read directly from the context", "author": "MikeDombo", "createdAt": "2020-09-08T16:18:15Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzQ4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043488", "bodyText": "why does this need a getter? At least don't make it public", "author": "MikeDombo", "createdAt": "2020-09-08T16:18:56Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzYyNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043626", "bodyText": "should not be public", "author": "MikeDombo", "createdAt": "2020-09-08T16:19:10Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzkwMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043902", "bodyText": "again, should you cancel(true)?", "author": "MikeDombo", "createdAt": "2020-09-08T16:19:35Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDUxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044515", "bodyText": "should not be public. Make it package-private if you need to call it in tests", "author": "MikeDombo", "createdAt": "2020-09-08T16:20:33Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDU4NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044585", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-09-08T16:20:42Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDk4MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044980", "bodyText": "these configurations will be deleted on the next deployment. Consider using the runtime config space", "author": "MikeDombo", "createdAt": "2020-09-08T16:21:21Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NTQ4Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485045482", "bodyText": "call super later because that will set your state as running. Instead, try to get through all this code before declaring that you're running", "author": "MikeDombo", "createdAt": "2020-09-08T16:22:10Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())\n+                .subscribe((why, newv) -> lastPeriodicAggregationMetricsTime = Coerce.toLong(newv));\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC).dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        super.startup();", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NjE2OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046169", "bodyText": "this is correct. Change the earlier problematic one in the kernel to use kernel.findServiceTopics(MeticsAgent).lookup(parameters, ...)", "author": "MikeDombo", "createdAt": "2020-09-08T16:23:18Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())\n+                .subscribe((why, newv) -> lastPeriodicAggregationMetricsTime = Coerce.toLong(newv));\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC).dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        super.startup();\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }\n+                });\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicPublishMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicPublishMetricsFuture != null) {\n+                        schedulePeriodicPublishMetrics(true);\n+                    }\n+                });\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS)\n+                .dflt(DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC)", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyNzAyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486727025", "bodyText": "I tried that earlier but it still has the same problem. find returns null if it does not exist. By the time kernel metrics emitter starts, it is not guaranteed that the MA starts. I moved the kernel metric code back to MA.", "author": "saranyailla", "createdAt": "2020-09-11T01:52:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NjE2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzU0Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485047543", "bodyText": "why Object? It looks like it always ends up as a double", "author": "MikeDombo", "createdAt": "2020-09-08T16:25:34Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzkzNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485047936", "bodyText": "why are these classes necessary? Why not use the classes in the logger SDK?", "author": "MikeDombo", "createdAt": "2020-09-08T16:26:10Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getMetricUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyMjU1OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486722558", "bodyText": "This is different from what we have in the sdk package.", "author": "saranyailla", "createdAt": "2020-09-11T01:36:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0ODMxMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485048310", "bodyText": "Do not use concatenation. .log(\"...\", e)", "author": "MikeDombo", "createdAt": "2020-09-08T16:26:45Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getMetricUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {\n+        @JsonProperty(\"N\")\n+        private TelemetryMetricName metricName;\n+        @JsonProperty(\"V\")\n+        private Object value;\n+        @JsonProperty(\"U\")\n+        private TelemetryUnit metricUnit;\n+    }\n+\n+    /**\n+     * Helper function to process the value of the metric object during aggregation.\n+     * @param value metric data point value.\n+     * @return converted value of the object to double. Returns 0 if invalid.\n+     */\n+    public double format(Object value) {\n+        double val = 0;\n+        if (value != null) {\n+            try {\n+                 val = NumberFormat.getInstance().parse(value.toString()).doubleValue();\n+                return val;\n+            } catch (ParseException e) {\n+                logger.atError().log(\"Error parsing the metric value: \" + e);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDEzNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754136", "bodyText": "This is not resolved", "author": "MikeDombo", "createdAt": "2020-09-11T03:37:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0ODMxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTM5Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049397", "bodyText": "we should not be handling text-mode logs here at all. Metrics should always be JSON, and I have no problem forcing that.", "author": "MikeDombo", "createdAt": "2020-09-08T16:28:33Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTU5OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049599", "bodyText": "No concatentation. Use the logger properly to log out exceptions", "author": "MikeDombo", "createdAt": "2020-09-08T16:28:55Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()\n+                                    .readValue(log.split(\" \")[7], MetricsAggregator.AggregatedMetric.class);\n+                            if (am != null && currentTimestamp - am.getTimestamp() <= uploadIntervalMilliSec) {\n+                                aggUploadMetrics.computeIfAbsent(currentTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (MismatchedInputException mis) {\n+                            logger.atError().log(\"Unable to parse the aggregated metric log: \" + mis);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTY2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049665", "bodyText": "add context to the message", "author": "MikeDombo", "createdAt": "2020-09-08T16:29:02Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()\n+                                    .readValue(log.split(\" \")[7], MetricsAggregator.AggregatedMetric.class);\n+                            if (am != null && currentTimestamp - am.getTimestamp() <= uploadIntervalMilliSec) {\n+                                aggUploadMetrics.computeIfAbsent(currentTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (MismatchedInputException mis) {\n+                            logger.atError().log(\"Unable to parse the aggregated metric log: \" + mis);\n+                        }\n+                    }\n+                }\n+            }\n+        } catch (IOException e) {\n+            logger.atError().log(e);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485050075", "bodyText": "do you need a new factory for all of these? Couldn't it be saved and reused?", "author": "MikeDombo", "createdAt": "2020-09-08T16:29:44Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+    private static Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();\n+\n+    /**\n+     * Create system metrics.\n+     */\n+    protected void collectSystemMetrics() {\n+        Metric systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.CpuUsage)\n+                .metricUnit(TelemetryUnit.Percent)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        MetricDataBuilder mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.CpuUsage, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.TotalNumberOfFDs)\n+                .metricUnit(TelemetryUnit.Count)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.TotalNumberOfFDs, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.SystemMemUsage)\n+                .metricUnit(TelemetryUnit.Megabytes)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc4NDYyMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485784620", "bodyText": "We need to specify for each metric to where it as to go during the construction. We cannot reuse it as MetricFactory uses ThreadLocal metric object.", "author": "saranyailla", "createdAt": "2020-09-09T17:11:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc4NTk5OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485785999", "bodyText": "You can call addMetric multiple times when the metrics are going to the same place though, right?", "author": "MikeDombo", "createdAt": "2020-09-09T17:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc4NjY0MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485786641", "bodyText": "All of these are going to system, so just calling addMetric should do the right thing. If it doesn't then that seems like a bug", "author": "MikeDombo", "createdAt": "2020-09-09T17:14:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTAwNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755006", "bodyText": "This is not resolved. The previous iteration of our metrics library handled this case.", "author": "MikeDombo", "createdAt": "2020-09-11T03:41:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDc1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485050752", "bodyText": "No concatenation (especially without a space). Use KV to add a key-value pair .kv(\"topic\", updateTopic)", "author": "MikeDombo", "createdAt": "2020-09-08T16:30:46Z", "path": "src/main/java/com/aws/iot/evergreen/util/MqttChunkedPayloadPublisher.java", "diffHunk": "@@ -52,11 +52,11 @@ public void publish(Chunkable<T> chunkablePayload, List<T> variablePayloads) {\n                         start + chunkingInformation.getNumberOfComponentsPerPublish()));\n                 this.mqttClient.publish(PublishRequest.builder()\n                         .qos(QualityOfService.AT_LEAST_ONCE)\n-                        .topic(this.updateFssDataTopic)\n+                        .topic(this.updateTopic)\n                         .payload(SERIALIZER.writeValueAsBytes(chunkablePayload)).build());\n             }\n         } catch (JsonProcessingException e) {\n-            logger.atError().cause(e).log(\"Unable to publish fleet status service.\");\n+            logger.atError().cause(e).log(\"Unable to publish data via topic.\" + updateTopic);", "originalCommit": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "message": "Add telemetry metrics + tests + modify log statements", "committedDate": "2020-09-09T20:27:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwMzY4OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485903689", "bodyText": "use kernel.findServiceTopics", "author": "MikeDombo", "createdAt": "2020-09-09T20:30:31Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwODE0OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485908149", "bodyText": "It was giving null.", "author": "saranyailla", "createdAt": "2020-09-09T20:38:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwMzY4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwOTc2Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485909763", "bodyText": "Then that's correct because you may not have METRICS_AGENT_SERVICE_TOPICS", "author": "MikeDombo", "createdAt": "2020-09-09T20:42:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwMzY4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDI1Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904253", "bodyText": "These calls are a bit redundant because subscribe is immediately called with the initial value.", "author": "MikeDombo", "createdAt": "2020-09-09T20:31:36Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);\n+        metricTopics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjcyOTIxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486729215", "bodyText": "I looked at how other services have done this. FSS and TES did the same thing. Because we are not calling subscribe first and then dflt, I think it is not that redundant if it takes the default value first and then subscribe for changes.", "author": "saranyailla", "createdAt": "2020-09-11T02:00:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDI1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDQyMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904421", "bodyText": "remove the :", "author": "MikeDombo", "createdAt": "2020-09-09T20:31:54Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);\n+        metricTopics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);\n+    }\n+\n+    private void emitKernelMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name:\", e);", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDYzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904630", "bodyText": "synchronize this", "author": "MikeDombo", "createdAt": "2020-09-09T20:32:17Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk1MDQ1Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485950457", "bodyText": "I used synchronized in the line 69.", "author": "saranyailla", "createdAt": "2020-09-09T22:11:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk1MTA3NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485951074", "bodyText": "This method itself is public, so it can be called and cause a data race with setting the future", "author": "MikeDombo", "createdAt": "2020-09-09T22:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDYzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk1MTkxMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485951911", "bodyText": "L65-66 and L77 is the sync problem", "author": "MikeDombo", "createdAt": "2020-09-09T22:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDYzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDc4Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904783", "bodyText": "use dependency injection instead of reading from context", "author": "MikeDombo", "createdAt": "2020-09-09T20:32:33Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNTQ3MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485905470", "bodyText": "why are these package-private and not just private?", "author": "MikeDombo", "createdAt": "2020-09-09T20:33:41Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkzMjY3Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485932672", "bodyText": "I was using them in the tests. I made them private with getters now.", "author": "saranyailla", "createdAt": "2020-09-09T21:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNTQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNTg5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485905893", "bodyText": "remove :", "author": "MikeDombo", "createdAt": "2020-09-09T20:34:24Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,201 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currTimestamp) {\n+        int aggIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currTimestamp - new File(path.toString()).lastModified() <= aggIntervalMilliSec) {\n+                        List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                        for (String log : logs) {\n+                            try {\n+                            /*\n+\n+                            {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                            \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                            \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                             */\n+\n+                            mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                    MetricDataPoint.class);\n+                            if (mdp.getMetric() != null && currTimestamp - mdp.getTimestamp() <= aggIntervalMilliSec) {\n+                                metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                        k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                                logger.atError().log(\"Unable to parse the metric log: \", e);", "originalCommit": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eb8f6729a4c0e179ff3f13f4ce10ce608827b7b0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/eb8f6729a4c0e179ff3f13f4ce10ce608827b7b0", "message": "Add telemetry metrics + tests + modify log statements", "committedDate": "2020-09-09T20:37:04Z", "type": "commit"}, {"oid": "62a10c319a5a406b376edf792aa91618478a74ca", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/62a10c319a5a406b376edf792aa91618478a74ca", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-09T20:37:55Z", "type": "commit"}, {"oid": "abdc9e5e716f92cf14668bf42de356d989c56b5b", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/abdc9e5e716f92cf14668bf42de356d989c56b5b", "message": "Moved kernel metrics to MA + update tests + add initial e2e test + modify aggregation and publish logic", "committedDate": "2020-09-11T01:05:50Z", "type": "commit"}, {"oid": "067e8400fd290b8575977b2bc59f500d4e68dcae", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/067e8400fd290b8575977b2bc59f500d4e68dcae", "message": "Moved kernel metrics to MA + update tests + add initial e2e test + modify aggregation and publish logic", "committedDate": "2020-09-11T01:25:57Z", "type": "commit"}, {"oid": "a79ccf3350bed1c6dbdd04a7fc26f451d184a7bc", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a79ccf3350bed1c6dbdd04a7fc26f451d184a7bc", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-11T01:27:51Z", "type": "commit"}, {"oid": "a4bf94ffcb92a1b498e471c7532d17798c0840d4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a4bf94ffcb92a1b498e471c7532d17798c0840d4", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-11T01:43:06Z", "type": "commit"}, {"oid": "1bcbcff49657ecb14873822edf541b84dace0cc4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1bcbcff49657ecb14873822edf541b84dace0cc4", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-11T01:43:36Z", "type": "commit"}, {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1f6f8fa609fd963745b7444ac83769f270db472d", "message": "Changed parameter to runtime config space.", "committedDate": "2020-09-11T02:11:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTMxNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751315", "bodyText": "don't bother with this", "author": "MikeDombo", "createdAt": "2020-09-11T03:25:37Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),\n+                Duration.ofMinutes(5), s -> s.equals(JobExecutionStatus.SUCCEEDED));\n+\n+\n+        // Ensure that main is finished, which is its terminal state, so this means that all updates ought to be done\n+        assertThat(kernel.getMain()::getState, eventuallyEval(is(State.FINISHED)));", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTQxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751417", "bodyText": "missing any sort of assertions about the data", "author": "MikeDombo", "createdAt": "2020-09-11T03:26:04Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),\n+                Duration.ofMinutes(5), s -> s.equals(JobExecutionStatus.SUCCEEDED));\n+\n+\n+        // Ensure that main is finished, which is its terminal state, so this means that all updates ought to be done\n+        assertThat(kernel.getMain()::getState, eventuallyEval(is(State.FINISHED)));\n+        List<List<MetricsAggregator.AggregatedMetric>> metrics = new ArrayList<>();\n+        for (MqttMessage mt : mqttMessagesList.get()) {\n+            try {\n+                // In this test, we filter only the metrics payload.\n+                MetricsPayload mp = DESERIALIZER.readValue(mt.getPayload(), MetricsPayload.class);\n+                metrics.add(mp.getAggregatedMetricList());\n+            } catch (MismatchedInputException  e) {\n+                // do nothing if the payload is something else", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NzU1OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486757558", "bodyText": "Yeah, I had to complete them.  That's in TODO.", "author": "saranyailla", "createdAt": "2020-09-11T03:50:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTQxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTgxOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751818", "bodyText": "What is in each of these maps? can it be consolidated? Do they need to exist at all?", "author": "MikeDombo", "createdAt": "2020-09-11T03:27:39Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwOTk4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488009988", "bodyText": "+1", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:11:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTgxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM0MjY1Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488342652", "bodyText": "The kernelMetrics(map) is used to store the already created metric with its name. We don't want to create the metric with its namespace, name, count and aggregation again and again while running the scheduled tasks.\nWe can assign a value to these existing metrics and emit them periodically.\nkernelMetricsData(data) is used in counting the number of components in each state .", "author": "saranyailla", "createdAt": "2020-09-15T02:21:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTgxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTk3MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751971", "bodyText": "remove evergreen from the topic. I think Nikkhil just made a change to make it greengrassv2", "author": "MikeDombo", "createdAt": "2020-09-11T03:28:19Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjEwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752104", "bodyText": "all these getters should be package-private so that they're only used in the tests", "author": "MikeDombo", "createdAt": "2020-09-11T03:28:56Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjE4OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752189", "bodyText": "formatting", "author": "MikeDombo", "createdAt": "2020-09-11T03:29:22Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjMzMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752331", "bodyText": "this needs to be synchronized too", "author": "MikeDombo", "createdAt": "2020-09-11T03:29:51Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjU3NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752574", "bodyText": "Throughput isn't really much of a concern, so just add synchronized to all these methods, otherwise you have threading problems with reading and writing these fields with all the futures.", "author": "MikeDombo", "createdAt": "2020-09-11T03:30:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjMzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjYxOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752618", "bodyText": "remove space", "author": "MikeDombo", "createdAt": "2020-09-11T03:31:07Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjY4MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752681", "bodyText": "not info level. drop to debug", "author": "MikeDombo", "createdAt": "2020-09-11T03:31:24Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjgzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752830", "bodyText": "what? Do not log all this data", "author": "MikeDombo", "createdAt": "2020-09-11T03:31:53Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1ODI3Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486758276", "bodyText": "So, it is just one log per day. My idea was that even if this message is dropped due to network issues or something like that, we still have the data as it is logged. It is only in the memory. I can remove if it is not needed.", "author": "saranyailla", "createdAt": "2020-09-11T03:54:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjgzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1ODc5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486758793", "bodyText": "I don't think I'd log it. If you log it, don't put it as the message. Add it as a kv", "author": "MikeDombo", "createdAt": "2020-09-11T03:56:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjgzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjkwMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752901", "bodyText": "timestamp", "author": "MikeDombo", "createdAt": "2020-09-11T03:32:12Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1Mjk4Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752987", "bodyText": "needs synchronization", "author": "MikeDombo", "createdAt": "2020-09-11T03:32:43Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timeStamp).isEmpty()) {\n+            this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicKernelMetrics() {\n+        this.kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        this.systemMetricsEmitter.collectSystemMetrics();\n+        this.kernelMetricsEmitter.collectKernelComponentState();\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTg3MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125871", "bodyText": "unresolved", "author": "MikeDombo", "createdAt": "2020-09-11T15:35:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1Mjk4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzAzNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753035", "bodyText": "sync", "author": "MikeDombo", "createdAt": "2020-09-11T03:32:50Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timeStamp).isEmpty()) {\n+            this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicKernelMetrics() {\n+        this.kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        this.systemMetricsEmitter.collectSystemMetrics();\n+        this.kernelMetricsEmitter.collectKernelComponentState();\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }\n+                });\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicPublishMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicPublishMetricsFuture != null) {\n+                        schedulePeriodicPublishMetrics(true);\n+                    }", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzE0NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753144", "bodyText": "formatting", "author": "MikeDombo", "createdAt": "2020-09-11T03:33:21Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzUxNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753516", "bodyText": "Deserialize into EvergreenStructuredLogMessage then EvergreenMetricsMessage", "author": "MikeDombo", "createdAt": "2020-09-11T03:34:58Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDA5OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754098", "bodyText": "Why not use the classes that already exist in the logger?", "author": "MikeDombo", "createdAt": "2020-09-11T03:37:13Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                MetricDataPoint.class);\n+                        // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                        // aggregation interval\n+                        if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                            metrics.computeIfAbsent(mdp.getMetric().getName(), k -> new ArrayList<>()).add(mdp);\n+                        }\n+                    } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDI3Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754272", "bodyText": "use Coerce.toDouble", "author": "MikeDombo", "createdAt": "2020-09-11T03:37:59Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                MetricDataPoint.class);\n+                        // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                        // aggregation interval\n+                        if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                            metrics.computeIfAbsent(mdp.getMetric().getName(), k -> new ArrayList<>()).add(mdp);\n+                        }\n+                    } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {\n+        @JsonProperty(\"N\")\n+        private TelemetryMetricName metricName;\n+        @JsonProperty(\"V\")\n+        private Object value;\n+        @JsonProperty(\"U\")\n+        private TelemetryUnit metricUnit;\n+    }\n+\n+    /**\n+     * Helper function to process the value of the metric object during aggregation.\n+     * @param value metric data point value.\n+     * @return converted value of the object to double. Returns 0 if invalid.\n+     */\n+    public double format(Object value) {", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDY3MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754671", "bodyText": "Please add a README.md file under telemetry to explain what all this is doing. I'm quite confused why we have 2 classes that are reading files from the FS. The aggregator and uploader. Why can't we keep more of this in memory?", "author": "MikeDombo", "createdAt": "2020-09-11T03:39:47Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njk3MDk3Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486970977", "bodyText": "Added README.md. Removed the MetricsUploader class completely. Readme might also answer other questions like why I could not reuse the metrics from the sdk package and why we are writing to the files.", "author": "saranyailla", "createdAt": "2020-09-11T10:59:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDY3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDc5Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754792", "bodyText": "Why are aggregates written to a file?", "author": "MikeDombo", "createdAt": "2020-09-11T03:40:15Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>> getAggregatedMetrics(long lastPublish,\n+                                                                                   long currTimestamp) {\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDgxOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754819", "bodyText": "formatting", "author": "MikeDombo", "createdAt": "2020-09-11T03:40:19Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>> getAggregatedMetrics(long lastPublish,\n+                                                                                   long currTimestamp) {\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTIzOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755238", "bodyText": "what is the Object which is the value?", "author": "MikeDombo", "createdAt": "2020-09-11T03:42:11Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,79 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzI4NTI2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487285265", "bodyText": "Object is the value that you want to emit for that metric. For the System metrics, I can remove this map structure totally and do it in a simple way as there are only three metrics to emit.", "author": "saranyailla", "createdAt": "2020-09-11T20:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTIzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTg2OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755868", "bodyText": "Neither of these maps needs to exist. You can just do all of this in an easier to read, plainly procedural way.\nmake metric with value\nmake MDB\nadd metric to MDB\nemit metric\n\nThis should be way way easier than what you've implemented", "author": "MikeDombo", "createdAt": "2020-09-11T03:45:00Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,79 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private final Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjE2Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756163", "bodyText": "add EGExtension", "author": "MikeDombo", "createdAt": "2020-09-11T03:46:00Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjIzNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756236", "bodyText": "Don't initialize here. Just do it in the field and make it static and final", "author": "MikeDombo", "createdAt": "2020-09-11T03:46:20Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjQ0OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756449", "bodyText": "all of these are backwards. It is expected, then actual value in assertions", "author": "MikeDombo", "createdAt": "2020-09-11T03:46:55Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjUwMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756501", "bodyText": "backwards", "author": "MikeDombo", "createdAt": "2020-09-11T03:47:08Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.SystemMemUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 3000);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.TotalNumberOfFDs)) {\n+                        assertEquals((double) metrics.getValue(), (double) 6000);\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currentTimestamp);\n+        list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), 8); // AggregateMetrics.log is appended with the latest aggregations.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getTimestamp() == currentTimestamp && am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 0); // There is no aggregation as there are no latest values", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjUyNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756526", "bodyText": "backwards", "author": "MikeDombo", "createdAt": "2020-09-11T03:47:13Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.SystemMemUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 3000);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.TotalNumberOfFDs)) {\n+                        assertEquals((double) metrics.getValue(), (double) 6000);\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currentTimestamp);\n+        list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), 8); // AggregateMetrics.log is appended with the latest aggregations.", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjU5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756593", "bodyText": "add EGExtension", "author": "MikeDombo", "createdAt": "2020-09-11T03:47:29Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsUploaderTest.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith(MockitoExtension.class)", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1ODM1NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486758355", "bodyText": "cloud deployment is very slow. If you don't absolutely need it; don't use it. Just setup the kernel with some config. You may need to stop extending the base class to make this test run faster without stuff that it doesn't need", "author": "MikeDombo", "createdAt": "2020-09-11T03:54:33Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),", "originalCommit": "1f6f8fa609fd963745b7444ac83769f270db472d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM0MzM0NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488343345", "bodyText": "Not doing any cloud deployments and it looks like I had to extend the base class.", "author": "saranyailla", "createdAt": "2020-09-15T02:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1ODM1NQ=="}], "type": "inlineReview"}, {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "message": "Removed MetricsUploader class + add readme + update tests + sync + format code", "committedDate": "2020-09-11T11:10:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNDYwNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487124606", "bodyText": "just keep the lock for L139", "author": "MikeDombo", "createdAt": "2020-09-11T15:32:56Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {", "originalCommit": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNDcyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487124725", "bodyText": "same, just keep the lock you already are holding", "author": "MikeDombo", "createdAt": "2020-09-11T15:33:07Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {", "originalCommit": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTExOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125119", "bodyText": "since this happens a lot, maybe extract it to a method?", "author": "MikeDombo", "createdAt": "2020-09-11T15:33:47Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }", "originalCommit": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzM1MjEyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487352125", "bodyText": "could you check if that's the right way to do?", "author": "saranyailla", "createdAt": "2020-09-12T01:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTU2Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125567", "bodyText": "drop this to debug", "author": "MikeDombo", "createdAt": "2020-09-11T15:34:30Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics. MQTT connection interrupted.\");", "originalCommit": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "723efea7f1ab287252721edd3ecc80504781a724", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/723efea7f1ab287252721edd3ecc80504781a724", "message": "Removed MetricsUploader class + add readme + update tests + sync + format code", "committedDate": "2020-09-11T21:45:19Z", "type": "commit"}, {"oid": "2a905d731be3d86cd2c82373cb78e9953da3a675", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2a905d731be3d86cd2c82373cb78e9953da3a675", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-11T21:45:49Z", "type": "commit"}, {"oid": "77407ad2ac6b0145c882dd6c63db5bc65ba38f96", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/77407ad2ac6b0145c882dd6c63db5bc65ba38f96", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-11T21:46:32Z", "type": "commit"}, {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/0885143b7846ce5bc38053c39dc261ff10a10b70", "message": "Reuse metric factory + clean up extra objects+ add func for sync", "committedDate": "2020-09-12T01:43:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODQ4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488008488", "bodyText": "nit: renanme", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:09:07Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488011995", "bodyText": "I don't believe this will is the correct way since the kernel might be emitting periodic as well as event based metrics.", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:13:58Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Kernel kernel;\n+    private final MetricFactory metricFactory = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    public void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA3ODkxOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488078919", "bodyText": "Are not the event based component state metrics emitted by the components themselves and kernel would only collect all the components state periodically?", "author": "saranyailla", "createdAt": "2020-09-14T16:49:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMzNDgyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488334825", "bodyText": "Right. My point is, TelemetryNamespace.KernelComponents will have both the periodic and event based metrics right in the future? Just for now, it is only periodic based metrics in that namespace.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T01:53:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM0NDYzMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488344631", "bodyText": "I see your point. We will have to filter the metric names we need as we add more. Leaving it like this with a TODO as I am not sure about what type of metrics are going to be added in order to write a better filter method.\nIf we don't want to write any method as such I can elaborate this for loop with those 9 states.", "author": "saranyailla", "createdAt": "2020-09-15T02:28:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM2NDgyNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488364824", "bodyText": "You can just hard code the list for now.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T03:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNTQ5NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488015494", "bodyText": "Create an interface for PeriodicMetricsEmitter and then implement that here and in the system metrics. Then in the Metrics Agent, you can have a list of PeriodicMetricsEmitters instead of having individual objects.", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:18:41Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNjE1OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488016159", "bodyText": "explain why you do this.", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:19:34Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Kernel kernel;\n+    private final MetricFactory metricFactory = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    public void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .namespace(TelemetryNamespace.KernelComponents)\n+                    .name(telemetryMetricName)\n+                    .unit(TelemetryUnit.Count)\n+                    .aggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = metricFactory.addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    public void emitMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNzIyOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488017229", "bodyText": "why do you need this? Can't you use config?", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:20:55Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyODUxNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488328516", "bodyText": "Using config only. These are used in multiple places.", "author": "saranyailla", "createdAt": "2020-09-15T01:31:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNzIyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMzMTkzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488331930", "bodyText": "You can use config.lookup instead of topics.lookup. You don't have to store it in the class. config == topics", "author": "nikkhilmuthye", "createdAt": "2020-09-15T01:43:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNzIyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMzNDkyMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488334921", "bodyText": "I made changes.", "author": "saranyailla", "createdAt": "2020-09-15T01:53:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNzIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxOTA0Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488019042", "bodyText": "Does not have to be separate future objects right since they are all running with the same interval? maybe a list is fine?", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:23:30Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NDAyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488084025", "bodyText": "Without having individual objects for each of them, same thread is being used for emitting all of these within the pool; for eg. if the kernel metrics are being emitted then the system metrics and aggregation are blocked till it is completed. We have no reason for them depend on each other. I can create a list.", "author": "saranyailla", "createdAt": "2020-09-14T16:55:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxOTA0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NzY5NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488087694", "bodyText": "If they all run at the same schedule, why have separate futures at all? Why not just have a single task which does it all?", "author": "MikeDombo", "createdAt": "2020-09-14T17:01:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxOTA0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODIzNDYxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488234617", "bodyText": "They are all independent tasks but aggregation interval is the common value that they depend on.", "author": "saranyailla", "createdAt": "2020-09-14T21:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxOTA0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyMDkxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488020917", "bodyText": "Add jitter", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:26:03Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        cancel(periodicEmitSystemMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicEmitKernelMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NDY4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488084688", "bodyText": "Aggregation is device specific. So, it is ok to aggregate at the same time on all the devices individually.", "author": "saranyailla", "createdAt": "2020-09-14T16:56:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyMDkxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjEwOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488026109", "bodyText": "why are you synchronizing the cancel?", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:30:32Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        cancel(periodicEmitSystemMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicEmitKernelMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancel(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    void emitPeriodicSystemMetrics() {\n+        systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+    void emitPeriodicKernelMetrics() {\n+        kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancel(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        synchronized (lock) {", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NTMwMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488085303", "bodyText": "As per Michael's comments, everything that holds/works with future needs to be synchronized?", "author": "saranyailla", "createdAt": "2020-09-14T16:57:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NjIzNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488086234", "bodyText": "Cancel doesn't need to be", "author": "MikeDombo", "createdAt": "2020-09-14T16:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjEwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA4NjgxNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488086817", "bodyText": "But now that you've extracted it this way, the call to cancel itself should be. The thing that needs to be synchronized is if(future!=null) { <do stuff>} <- That whole block must be synchronized to be correct", "author": "MikeDombo", "createdAt": "2020-09-14T16:59:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjEwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjM4MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488026381", "bodyText": "nit: copywrite", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:30:54Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package com.aws.iot.evergreen.telemetry;", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNzMxMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488027312", "bodyText": "Instead of doing this, use @Builder.Default in the class.", "author": "nikkhilmuthye", "createdAt": "2020-09-14T15:32:09Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();", "originalCommit": "0885143b7846ce5bc38053c39dc261ff10a10b70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7415ab215d360b905f921bf544ab9e0d0ea85173", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7415ab215d360b905f921bf544ab9e0d0ea85173", "message": "Updated code with latest sdk", "committedDate": "2020-09-14T20:11:41Z", "type": "commit"}, {"oid": "03b0b8c9daac2ec2c7160d6ea19867fdfdab4c97", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/03b0b8c9daac2ec2c7160d6ea19867fdfdab4c97", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-14T20:12:00Z", "type": "commit"}, {"oid": "2229b1c0e1626e974c6b3f91fe299b59cc92ca8d", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2229b1c0e1626e974c6b3f91fe299b59cc92ca8d", "message": "add abstraction for metrics emitter + copyrights + update tests", "committedDate": "2020-09-15T00:03:24Z", "type": "commit"}, {"oid": "31fa4eef1e6347406b493f1be90ab0a45a7290fe", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/31fa4eef1e6347406b493f1be90ab0a45a7290fe", "message": "update readme", "committedDate": "2020-09-15T01:26:04Z", "type": "commit"}, {"oid": "7ed5f105eb4f34ee7ea49794cfd9da068a501675", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7ed5f105eb4f34ee7ea49794cfd9da068a501675", "message": "add default schema value + remove topics to use config + update test", "committedDate": "2020-09-15T01:45:47Z", "type": "commit"}, {"oid": "4d731cde8f9438c921195073cde509085bd39cda", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/4d731cde8f9438c921195073cde509085bd39cda", "message": "clean up", "committedDate": "2020-09-15T02:05:12Z", "type": "commit"}, {"oid": "a1b5c55fdac26c9652cbf13f768ac07401cf27f0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a1b5c55fdac26c9652cbf13f768ac07401cf27f0", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-15T02:53:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MjQ5Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488352493", "bodyText": "assert true around this.", "author": "MikeDombo", "createdAt": "2020-09-15T02:56:43Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.kernel.exceptions.ServiceLoadException;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(EGExtension.class)\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Timeout(value = 3, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_WHEN_metrics_agent_starts_THEN_metrics_are_published_to_Cloud() throws\n+            InterruptedException, ExecutionException, TimeoutException, ServiceLoadException {\n+        /*\n+         Metrics agent is an auto-start service. It publishes data to the cloud irrespective of the deployments.\n+         In this test, we just start the kernel and expect MA to publish time-based metrics such as system metrics and\n+         kernel component state metrics in the given interval.\n+        */\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+        CountDownLatch cdl = new CountDownLatch(1);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        long aggInterval = 1;\n+        long pubInterval = 5;\n+        MetricsPayload mp = null;\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(aggInterval);\n+        maTopics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(pubInterval);\n+        String telemetryTopic = MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC\n+                .replace(\"{thingName}\", thingInfo.getThingName());\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(telemetryTopic)\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                })\n+                .build());\n+        cdl.await(30, TimeUnit.SECONDS);", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzEwNg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353106", "bodyText": "don't use RUNTIME_STORE_NAMESPACE_TOPIC. Use getRuntimeConfig(). Here and everywhere", "author": "MikeDombo", "createdAt": "2020-09-15T02:58:59Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancelJob(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        if (future != null) {\n+            synchronized (lock) {\n+                future.cancel(immediately);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            emitter.buildMetrics();\n+        }\n+        config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzM0Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353342", "bodyText": "why Object? This is a string", "author": "MikeDombo", "createdAt": "2020-09-15T02:59:43Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzU2MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353560", "bodyText": "you already have a Path. Why are you converting it to a string and then a Path again?", "author": "MikeDombo", "createdAt": "2020-09-15T03:00:36Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzcxMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353711", "bodyText": "Do not use collect this will cause massive memory usage as you will be reading in the entire file all at once. Do this as a stream.", "author": "MikeDombo", "createdAt": "2020-09-15T03:01:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzU2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzkyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353925", "bodyText": "again. This is a string", "author": "MikeDombo", "createdAt": "2020-09-15T03:02:02Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5NDAyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488394025", "bodyText": "path.getFileName() returns Path. It cannot be a string.\nMy previous pushes had all these checks in one line but that spotbugs was showing errors specially when path.getFileName().toString was used, so I had to write it this way.", "author": "saranyailla", "createdAt": "2020-09-15T05:27:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzkyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5NDM5OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488394398", "bodyText": "It isn't an Object. Use Coerce.toString() if you must", "author": "MikeDombo", "createdAt": "2020-09-15T05:28:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzkyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5NTgzNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488395837", "bodyText": "You can just use the Path variable instead of using an Object here.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T05:33:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1Mzk1Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353953", "bodyText": "Same as above", "author": "MikeDombo", "createdAt": "2020-09-15T03:02:09Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path : paths) {\n+                // Read from the Telemetry/AggregatedMetrics.log file.\n+                // TODO : Read only those files that are modified after the last publish.\n+                List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NDA4Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488354086", "bodyText": "should not be public", "author": "MikeDombo", "createdAt": "2020-09-15T03:02:40Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/PeriodicMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,18 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import java.util.concurrent.ScheduledFuture;\n+\n+public abstract class PeriodicMetricsEmitter {\n+    public ScheduledFuture future;", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NDUzNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488354534", "bodyText": "I highly disagree with saving these prebuilt metrics. This costs us memory and will be moved into the old generation, if not the perm gen. If you just build the metric when needed which is only once an hour or so, then we can save quite a bit or memory and mental complexity.", "author": "MikeDombo", "createdAt": "2020-09-15T03:04:30Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter extends PeriodicMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Metric> map = new HashMap<>();\n+    private final MetricFactory mf = new MetricFactory(SYSTEM_METRICS_STORE);\n+    private long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+    /**\n+     * Build system metrics.\n+     */\n+    @Override\n+    public void buildMetrics() {", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NTAwMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488355000", "bodyText": "just keep this as a Path and use resolve to get the file", "author": "MikeDombo", "createdAt": "2020-09-15T03:06:20Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricFactory mf = new MetricFactory(TelemetryNamespace.SystemMetrics.toString());\n+        Metric m2 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        Metric m3 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1,10);\n+        mf.putMetricData(m2,2000);\n+        mf.putMetricData(m3,4000);\n+        mf.putMetricData(m1,20);\n+        mf.putMetricData(m2,3000);\n+        mf.putMetricData(m3,5000);\n+        mf.putMetricData(m1,30);\n+        mf.putMetricData(m2,4000);\n+        mf.putMetricData(m3,6000);\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDEzMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370131", "bodyText": "update service name to aws.greengrass.telemetry", "author": "nikkhilmuthye", "createdAt": "2020-09-15T04:06:00Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MTQ4OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488391488", "bodyText": "So, service name will be \"aws.greengrass.telemetry\" and topic be \"MetricsAgent\" or \"TelemetryAgent\" ?", "author": "saranyailla", "createdAt": "2020-09-15T05:18:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDEzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5Mjc2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488392765", "bodyText": "So just rename all references of MetricAgent to TelemetryAgent like the class name or field name.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T05:23:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDEzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDMwOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370309", "bodyText": "lets rename this to TelemetryAgent. Change all mentions of Metric Agent -> Telemetry Agent", "author": "nikkhilmuthye", "createdAt": "2020-09-15T04:06:47Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM4OTA3NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488389074", "bodyText": "Change it to TelemetryService or TelemetryAgent?", "author": "saranyailla", "createdAt": "2020-09-15T05:09:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDMwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MDA1MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488390050", "bodyText": "TelemetryAgent", "author": "nikkhilmuthye", "createdAt": "2020-09-15T05:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDMwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370759", "bodyText": "Filter out the active metric file as well. We don't want any partial reads.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T04:08:42Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MTczOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488371738", "bodyText": "Also, is this going to read and aggregate all the metrics every time it runs?", "author": "nikkhilmuthye", "createdAt": "2020-09-15T04:12:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MTIyMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488391220", "bodyText": "There  won't be any partial reads as each metric is atomic. We will only aggregate whatever is emitted till then. If we filter out the active file, there will be nothing to aggregate as the frequency at which the metrics are emitted is same as aggregation.", "author": "saranyailla", "createdAt": "2020-09-15T05:17:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MjM2OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488392369", "bodyText": "Any architecture which writes to a file and then another thread tries to read from the same file has a potential partial read issue. We can discuss this offline.", "author": "nikkhilmuthye", "createdAt": "2020-09-15T05:21:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MTEwOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488371108", "bodyText": "use logger.atError().cause(e).log() here and everywhere", "author": "nikkhilmuthye", "createdAt": "2020-09-15T04:10:11Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);", "originalCommit": "4d731cde8f9438c921195073cde509085bd39cda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MzQzMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488373433", "bodyText": "No. .log(something, e) does the same thing", "author": "MikeDombo", "createdAt": "2020-09-15T04:19:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MTEwOA=="}], "type": "inlineReview"}, {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/68c490deccce8f729fb21d42c95811875a0e5d6f", "message": "rename MA to TelemetryAgent + path related comments addressed + removed buildMetrics()", "committedDate": "2020-09-15T17:13:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMjQ4OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488832489", "bodyText": "[nit]\nReformat", "author": "MikeDombo", "createdAt": "2020-09-15T17:19:53Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    @Override\n+    public void emitMetrics() {\n+        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            /*\n+              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n+              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n+              and concatenate it with \"NumberOfComponents\" to form the metric name;\n+             */\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                data.put(telemetryMetricName, data.getOrDefault(telemetryMetricName,0) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name.\", e);\n+            }\n+        }\n+\n+        Metric metric = Metric.builder()\n+                .namespace(TelemetryNamespace.KernelComponents)\n+                .name(TelemetryMetricName.NumberOfComponentsStarting)\n+                .unit(TelemetryUnit.Count)\n+                .aggregation(TelemetryAggregation.Average)\n+                .build();\n+        mf.putMetricData(metric,data.get(TelemetryMetricName.NumberOfComponentsStarting));", "originalCommit": "68c490deccce8f729fb21d42c95811875a0e5d6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMzQ1NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488833454", "bodyText": "keep the messages that you had, otherwise it is difficult to know from the log, what exactly went wrong and what part of the code caused it.", "author": "MikeDombo", "createdAt": "2020-09-15T17:20:58Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log();\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log();", "originalCommit": "68c490deccce8f729fb21d42c95811875a0e5d6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMzY0Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488833647", "bodyText": "messages, again put them back here any everywhere else.", "author": "MikeDombo", "createdAt": "2020-09-15T17:21:09Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log();\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log();\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))\n+                    .collect(Collectors.toList());\n+            for (Path path : paths) {\n+                // Read from the Telemetry/AggregatedMetrics.log file.\n+                // TODO : Read only those files that are modified after the last publish.\n+                Files.lines(path).forEach((log) -> {\n+                    try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                        \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                        {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                        \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null}\n+\n+                         */\n+                        EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                EvergreenStructuredLogMessage.class);\n+                        MetricsAggregator.AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                MetricsAggregator.AggregatedMetric.class);\n+                        // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                        // upload interval\n+                        if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                            aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                        }\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log();\n+                    }\n+                });\n+            }\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log();", "originalCommit": "68c490deccce8f729fb21d42c95811875a0e5d6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzNDkzMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488834932", "bodyText": "again, don't use RUNTIME_STORE_NAMESPACE_TOPIC. Use getRuntimeConfig", "author": "MikeDombo", "createdAt": "2020-09-15T17:22:20Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)", "originalCommit": "68c490deccce8f729fb21d42c95811875a0e5d6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzNTMzOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488835338", "bodyText": "this is not correct. The lock should be around this whole thing", "author": "MikeDombo", "createdAt": "2020-09-15T17:22:42Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancelJob(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        if (future != null) {\n+            synchronized (lock) {\n+                future.cancel(immediately);\n+            }", "originalCommit": "68c490deccce8f729fb21d42c95811875a0e5d6f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "17648ea0a4aaec4af11791cdbae1629387a34f0a", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/17648ea0a4aaec4af11791cdbae1629387a34f0a", "message": "Use getRuntimeConfig() + update tests", "committedDate": "2020-09-15T18:40:19Z", "type": "commit"}, {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "message": "reformat code + proper sync + default value for component state", "committedDate": "2020-09-15T19:46:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODkzNzYyMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488937623", "bodyText": "with static final, you can just make it public. No getter needed", "author": "MikeDombo", "createdAt": "2020-09-15T19:58:01Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzNzg4Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489137886", "bodyText": "You don't need to do this to keep it in the map. you can just store it as a State object as the key since you have now hard coded the metrics below.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:22:30Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    @Override\n+    public void emitMetrics() {\n+        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            /*\n+              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n+              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n+              and concatenate it with \"NumberOfComponents\" to form the metric name;\n+             */\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzODY1OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489138659", "bodyText": "Use Switch", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:25:35Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzOTg3OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489139878", "bodyText": "Change this to use the v1 topic.  $aws/things/{thingName}/greengrass/health/json", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:30:20Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0MjM2Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489142362", "bodyText": "You need to add accumulated data point for each namespace.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:39:58Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE2NTIzMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489165233", "bodyText": "Will add a TODO in the PR.", "author": "saranyailla", "createdAt": "2020-09-16T05:05:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0MjM2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTExMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145112", "bodyText": "nit: add java doc for param", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:51:09Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTE2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145165", "bodyText": "nit: add java doc for param", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:51:23Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145374", "bodyText": "Shouldn't we wait for periodicAggregateMetricsIntervalSec before starting aggregation? Lets give the components some time to emit the metrics.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T03:52:20Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,", "originalCommit": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE2MDM1Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489160356", "bodyText": "In the service startup, schedulePeriodicAggregateMetrics(..) is called after setting the periodicAggregateMetricsIntervalSec. Do you still want me to add the delay?", "author": "saranyailla", "createdAt": "2020-09-16T04:52:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE2Mzk4Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489163987", "bodyText": "Yes. we should give some time for the metrics to start emitting the metrics before aggregating.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T05:01:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE2NjA2NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489166065", "bodyText": "Yes, that is done. Aggregation will not start immediately. You can find in the lines below that.", "author": "saranyailla", "createdAt": "2020-09-16T05:09:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE2NzI2Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489167266", "bodyText": "My bad. You are right. This is fine.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T05:13:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA=="}], "type": "inlineReview"}, {"oid": "e4bc81d293832036debe4b86d053ebad08b8344c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e4bc81d293832036debe4b86d053ebad08b8344c", "message": "switch case for aggregation + update publish topic + update tests for more coverage + added java doc param + map in kernel metrics", "committedDate": "2020-09-16T05:27:53Z", "type": "commit"}, {"oid": "56b72b68f420806806b2c9447052c6f068109c1c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/56b72b68f420806806b2c9447052c6f068109c1c", "message": "switch case for aggregation + update publish topic + update tests for more coverage + added java doc param + map in kernel metrics", "committedDate": "2020-09-16T05:34:26Z", "type": "commit"}, {"oid": "7a23cbccdac26eb206dd24da8979435966a62b3c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7a23cbccdac26eb206dd24da8979435966a62b3c", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-16T05:35:00Z", "type": "commit"}, {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7d84d640dd1ef07491a1eee14d870d782d367c8e", "message": "format code", "committedDate": "2020-09-16T05:36:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE3NDQ3OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489174479", "bodyText": "remove the space before spdx", "author": "MikeDombo", "createdAt": "2020-09-16T05:38:09Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0", "originalCommit": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0MTcwMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489641703", "bodyText": "nit: rename", "author": "nikkhilmuthye", "createdAt": "2020-09-16T18:30:39Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -40,23 +41,11 @@ public KernelMetricsEmitter(Kernel kernel) {\n      */\n     @Override\n     public void emitMetrics() {\n-        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Map<State, Integer> data = new HashMap<>();", "originalCommit": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTcwNjcwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489706704", "bodyText": "rename what? data?", "author": "saranyailla", "createdAt": "2020-09-16T19:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0MTcwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0MjY1NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489642655", "bodyText": "nit: don't need the extra variable. Can be done in a single line.", "author": "nikkhilmuthye", "createdAt": "2020-09-16T18:31:25Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -40,23 +41,11 @@ public KernelMetricsEmitter(Kernel kernel) {\n      */\n     @Override\n     public void emitMetrics() {\n-        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Map<State, Integer> data = new HashMap<>();\n         Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n         for (EvergreenService evergreenService : evergreenServices) {\n-            /*\n-              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n-              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n-              and concatenate it with \"NumberOfComponents\" to form the metric name;\n-             */\n-            String serviceState = evergreenService.getState().toString();\n-            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n-            try {\n-                TelemetryMetricName telemetryMetricName =\n-                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n-                data.put(telemetryMetricName, data.getOrDefault(telemetryMetricName, 0) + 1);\n-            } catch (IllegalArgumentException e) {\n-                logger.atError().log(\"Unable to find the metric name.\", e);\n-            }\n+            State state = evergreenService.getState();", "originalCommit": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0NjIzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489646230", "bodyText": "nit: remove space", "author": "nikkhilmuthye", "createdAt": "2020-09-16T18:34:26Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsPayload.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0", "originalCommit": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ad90414f8ba518dde69091471e0c47217de999eb", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/ad90414f8ba518dde69091471e0c47217de999eb", "message": "format copyright + update e2e test to use a working topic + fix a potential bug wrt to publish topic", "committedDate": "2020-09-16T19:24:09Z", "type": "commit"}, {"oid": "fe9fe579cd6807fbd46d474d642e7ff041b69d77", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/fe9fe579cd6807fbd46d474d642e7ff041b69d77", "message": "update readme + rename variable in KME", "committedDate": "2020-09-16T19:37:48Z", "type": "commit"}, {"oid": "918beb4eaa1172d9e102607ce3ab12ac92c3df4e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/918beb4eaa1172d9e102607ce3ab12ac92c3df4e", "message": "Merge branch 'master' into telemetry-logs", "committedDate": "2020-09-16T20:35:13Z", "type": "commit"}, {"oid": "32129a4dfc7cb417bf32c271500e9e176f3af163", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/32129a4dfc7cb417bf32c271500e9e176f3af163", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-16T20:36:29Z", "type": "commit"}, {"oid": "618f3f9935d9bf101f7d0c50fd6d7a907f1ad291", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/618f3f9935d9bf101f7d0c50fd6d7a907f1ad291", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-16T20:37:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTc1MTk5MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489751991", "bodyText": "don't bother. The default timeout is 5 minutes already.", "author": "MikeDombo", "createdAt": "2020-09-16T21:01:58Z", "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.kernel.exceptions.ServiceLoadException;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.aws.iot.evergreen.telemetry.TelemetryAgent;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(EGExtension.class)\n+@Tag(\"E2E\")\n+public class TelemetryAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Timeout(value = 3, unit = TimeUnit.MINUTES)", "originalCommit": "618f3f9935d9bf101f7d0c50fd6d7a907f1ad291", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6ca39b79162b19a788ca0710e2f5d7a455c4dfb3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/6ca39b79162b19a788ca0710e2f5d7a455c4dfb3", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-16T22:37:09Z", "type": "commit"}, {"oid": "baa24ad4850896756274ebc396c35c2711abf572", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/baa24ad4850896756274ebc396c35c2711abf572", "message": "may be fix resource close", "committedDate": "2020-09-16T23:38:45Z", "type": "commit"}, {"oid": "f7edc11d1d0639470beb83acbddc0ca4184d3287", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f7edc11d1d0639470beb83acbddc0ca4184d3287", "message": "format code", "committedDate": "2020-09-16T23:45:20Z", "type": "commit"}, {"oid": "9ec9d6474e607a4034bcbb3f6447adb277bc54b6", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9ec9d6474e607a4034bcbb3f6447adb277bc54b6", "message": "try-resource in tests", "committedDate": "2020-09-17T00:38:46Z", "type": "commit"}, {"oid": "bc605049daf2b96b3b1bd1b70325be2cdddd4278", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bc605049daf2b96b3b1bd1b70325be2cdddd4278", "message": "stop log appenders in tests", "committedDate": "2020-09-17T02:47:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkwNjI4Mw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489906283", "bodyText": "I don't see how this can possibly work. You need to close the context which is actually used, not this context that you just created", "author": "MikeDombo", "createdAt": "2020-09-17T02:49:56Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -45,12 +47,18 @@\n     private static final ObjectMapper mapper = new ObjectMapper();\n     @TempDir\n     protected Path tempRootDir;\n+    private final LoggerContext loggerContext = new LoggerContext();\n \n     @BeforeEach\n     public void setup() {\n         System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n     }\n \n+    @AfterEach\n+    public void cleanup() {\n+        loggerContext.getLogger(\"Metrics-AggregateMetrics\").detachAndStopAllAppenders();", "originalCommit": "bc605049daf2b96b3b1bd1b70325be2cdddd4278", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a2c3c3b09979197ac10ac0251aab21b97b2a26d6", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a2c3c3b09979197ac10ac0251aab21b97b2a26d6", "message": "Create ~root/telemetry + Set telemetry directory path + add try catch for invalidMetricException + update tests + add accumulated data point logic + stop log appenders after each test + update read me", "committedDate": "2020-09-18T17:32:18Z", "type": "commit"}, {"oid": "000381241095f37a8693d0119fecbad90061f855", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/000381241095f37a8693d0119fecbad90061f855", "message": "refer telemetry branch of sdk", "committedDate": "2020-09-18T17:37:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzI5NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097294", "bodyText": "shouldn't be static", "author": "MikeDombo", "createdAt": "2020-09-18T17:39:46Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzQ5MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097491", "bodyText": "don't add getters for static fields. Make the field package-private instead.", "author": "MikeDombo", "createdAt": "2020-09-18T17:40:07Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzU2Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097562", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-09-18T17:40:15Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzYyNQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097625", "bodyText": "same", "author": "MikeDombo", "createdAt": "2020-09-18T17:40:21Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzkwMg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097902", "bodyText": "TELEMETRY_NAMESPACES shouldn't be static", "author": "MikeDombo", "createdAt": "2020-09-18T17:40:56Z", "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.TelemetryAgent;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String NAMESPACE = \"KernelComponents\";\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(NAMESPACE);", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwODAyMw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491108023", "bodyText": "I wanted to discuss this too. While performing aggregation and at couple other places, I need a  list of all the metric namespaces available. When I had enum of namespaces I could use values() to get all of them. But now, I have to build the list myself.\nInitially I thought that I would maintain a list of these in the sdk when new MetricFactory(NAMESPACE) is initiated. I was not quite sure about the best way to maintain this list specially in the cases where Telemetry Agent restarts.", "author": "saranyailla", "createdAt": "2020-09-18T18:00:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwOTE2OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491109168", "bodyText": "It doesn't matter if TA restarts. The non-static field will still be there. Use dependency injection to inject the Agent whereever you need this.", "author": "MikeDombo", "createdAt": "2020-09-18T18:03:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwOTUwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491109504", "bodyText": "Actually, you may want to pull it out of TA and into a separate class because dependency injection doesn't always work nicely with EvergreenServices.", "author": "MikeDombo", "createdAt": "2020-09-18T18:04:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzkwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU3Mg==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491100572", "bodyText": "fix formatting", "author": "MikeDombo", "createdAt": "2020-09-18T17:45:48Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(sm);    }", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDkwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491100904", "bodyText": "what's the difference between setting root and setting the telemetry path? That's confusing that there are 2 very similar options.", "author": "MikeDombo", "createdAt": "2020-09-18T17:46:21Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwNDU3NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491104575", "bodyText": "Setting telemetry path is the creation of a directory. Set root using TelemetryConfig is letting the metric loggers know where the telemetry path is. I can remove the telemetry path and just keep the TelemetryConfig to set root with ~root/telemetry.", "author": "saranyailla", "createdAt": "2020-09-18T17:53:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDkwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwNTU0MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491105540", "bodyText": "Are both updatable independently? If I change the root after logging starts will the files all move to the new root?", "author": "MikeDombo", "createdAt": "2020-09-18T17:55:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDkwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMTI1NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491101255", "bodyText": "you can just use Files.readAllLines", "author": "MikeDombo", "createdAt": "2020-09-18T17:47:00Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(sm);    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException, InvalidMetricException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricFactory mf = new MetricFactory(\"SystemMetrics\");\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes,\n+                TelemetryAggregation.Average);\n+        Metric m3 = new Metric(sm, \"TotalNumberOfFDs\", TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1, 10);\n+        mf.putMetricData(m2, 2000);\n+        mf.putMetricData(m3, 4000);\n+        mf.putMetricData(m1, 20);\n+        mf.putMetricData(m2, 3000);\n+        mf.putMetricData(m3, 5000);\n+        mf.putMetricData(m1, 30);\n+        mf.putMetricData(m2, 4000);\n+        mf.putMetricData(m3, 6000);\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\"AggregateMetrics.log\");\n+        List<String> list;\n+        try (Stream<String> listing = Files.lines(path)) {\n+            list = listing.collect(Collectors.toList());\n+            assertEquals(TelemetryAgent.getTELEMETRY_NAMESPACES().size(), list.size()); // Metrics are aggregated based on the namespace.\n+            for (String s : list) {\n+                AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                        AggregatedMetric.class);\n+                if (am.getNamespace().equals(sm)) {\n+                    assertEquals(3, am.getMetrics().size()); // Three system metrics\n+                    for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                        if (metrics.getName().equals(\"CpuUsage\")) {\n+                            assertEquals((double) 60, metrics.getValue().get(\"Sum\"));\n+                        } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                            assertEquals((double) 3000, metrics.getValue().get(\"Average\"));\n+                        } else if (metrics.getName().equals(\"TotalNumberOfFDs\")) {\n+                            assertEquals((double) 6000, metrics.getValue().get(\"Maximum\"));\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        currTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        try (Stream<String> listing = Files.lines(path)) {\n+            list = listing.collect(Collectors.toList());", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMjg5OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491102898", "bodyText": "add a comment here for why you are doing it.", "author": "MikeDombo", "createdAt": "2020-09-18T17:50:21Z", "path": "src/test/java/com/aws/iot/evergreen/testcommons/testutilities/ExceptionLogProtector.java", "diffHunk": "@@ -148,7 +149,7 @@ public void beforeEach(ExtensionContext context) throws Exception {\n     @SneakyThrows\n     public void afterEach(ExtensionContext context) throws Exception {\n         Slf4jLogAdapter.removeGlobalListener(getListener(context));\n-\n+        TelemetryConfig.getInstance().close();", "originalCommit": "000381241095f37a8693d0119fecbad90061f855", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/30d37ae9f2a50bc4721e19fabe0655d8f074e121", "message": "Add separate class for Namespace + update tests + clean up", "committedDate": "2020-09-19T01:28:07Z", "type": "commit"}, {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/30d37ae9f2a50bc4721e19fabe0655d8f074e121", "message": "Add separate class for Namespace + update tests + clean up", "committedDate": "2020-09-19T01:28:07Z", "type": "forcePushed"}, {"oid": "f2e0e4d7e639d0443c9da30ab83a2e50780e0d55", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f2e0e4d7e639d0443c9da30ab83a2e50780e0d55", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-19T03:09:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI2NzUzMA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491267530", "bodyText": "this is not necessary", "author": "MikeDombo", "createdAt": "2020-09-19T04:28:01Z", "path": "src/main/java/com/aws/iot/evergreen/telemetry/NamespaceSet.java", "diffHunk": "@@ -0,0 +1,21 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import lombok.Getter;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.inject.Inject;\n+\n+public class NamespaceSet {\n+    @Getter\n+    private Set<String> namespaces = new HashSet<>();\n+\n+    @Inject\n+    public NamespaceSet() {\n+        super();\n+    }", "originalCommit": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI2NzcwNA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491267704", "bodyText": "be sure to close this in the afterEach", "author": "MikeDombo", "createdAt": "2020-09-19T04:30:11Z", "path": "src/test/java/com/aws/iot/evergreen/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -62,17 +63,22 @@\n     private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n     @Captor\n     private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n-    private TelemetryAgent telemetryAgent;\n     @Mock\n     private ScheduledExecutorService ses;\n-    @Mock\n-    private Kernel kernel;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n \n     @BeforeEach\n     public void setup() {\n         serviceFullName = \"MetricsAgentService\";\n         initializeMockedConfig();\n         ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();", "originalCommit": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9f4f9bd0c40f8e1460d42657186e7987bb4e5941", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9f4f9bd0c40f8e1460d42657186e7987bb4e5941", "message": "close context + remove constructor", "committedDate": "2020-09-21T03:10:56Z", "type": "commit"}, {"oid": "807de4537377a0f7d5c288032240faf97368a29e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/807de4537377a0f7d5c288032240faf97368a29e", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-21T03:11:10Z", "type": "commit"}, {"oid": "245af4dcf92ef9d1e5d310583f2ec5dcc262adc5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/245af4dcf92ef9d1e5d310583f2ec5dcc262adc5", "message": "change tempdir", "committedDate": "2020-09-21T04:14:59Z", "type": "commit"}, {"oid": "6d0cb59cea3ad18d790de9e1b55083120d513609", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/6d0cb59cea3ad18d790de9e1b55083120d513609", "message": "update telemetry root path", "committedDate": "2020-09-21T08:07:21Z", "type": "commit"}, {"oid": "9b675dcad3da5c7984cdfe3cc59969fff24aef95", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9b675dcad3da5c7984cdfe3cc59969fff24aef95", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-21T17:24:43Z", "type": "commit"}, {"oid": "dd49c445ad65e37dc7dad12658d9797fb8a2f8f9", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/dd49c445ad65e37dc7dad12658d9797fb8a2f8f9", "message": "update TA e2e test", "committedDate": "2020-09-21T17:30:04Z", "type": "commit"}, {"oid": "efcbb7c0d667bd49b2aec35f5abe315e8b11df9f", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/efcbb7c0d667bd49b2aec35f5abe315e8b11df9f", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-21T19:04:17Z", "type": "commit"}, {"oid": "4bd6acdf82fa70cd39634b7060d653ef8a8eb6d9", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/4bd6acdf82fa70cd39634b7060d653ef8a8eb6d9", "message": "remove telemetry directory after each test", "committedDate": "2020-09-21T21:31:17Z", "type": "commit"}, {"oid": "bb845796b57c19a0756ef3408b64af22f47c5f28", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bb845796b57c19a0756ef3408b64af22f47c5f28", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs", "committedDate": "2020-09-22T01:37:10Z", "type": "commit"}, {"oid": "8d12f9423168f747630c7135fac94c353233e1b6", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/8d12f9423168f747630c7135fac94c353233e1b6", "message": "change the configurabletopics to paramters", "committedDate": "2020-09-22T01:42:19Z", "type": "commit"}]}