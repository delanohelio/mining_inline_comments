{"pr_number": 6717, "pr_title": "Avoid prefetch too much data when offloading data to HDFS", "pr_createdAt": "2020-04-11T06:28:36Z", "pr_url": "https://github.com/apache/pulsar/pull/6717", "timeline": [{"oid": "def4a94ad3e03cf0d032634fb91004bb8c5a5f38", "url": "https://github.com/apache/pulsar/commit/def4a94ad3e03cf0d032634fb91004bb8c5a5f38", "message": "fix filesystem offload oom based on https://github.com/apache/pulsar/pull/6697", "committedDate": "2020-04-11T06:20:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzAzMDU1MA==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407030550", "bodyText": "chooseTread(leaderId) make sure the second time write will not be executed, so the task meaningless. I don't think it is a good idea to fix the issue.", "author": "congbobo184", "createdAt": "2020-04-11T07:31:33Z", "path": "tiered-storage/file-system/src/main/java/org/apache/bookkeeper/mledger/offload/filesystem/impl/FileSystemManagedLedgerOffloader.java", "diffHunk": "@@ -188,12 +191,15 @@ public void run() {\n                 AtomicLong haveOffloadEntryNumber = new AtomicLong(0);\n                 long needToOffloadFirstEntryNumber = 0;\n                 CountDownLatch countDownLatch;\n+                //avoid prefetch too much data into memory\n+                ArrayBlockingQueue<Boolean> tasks = new ArrayBlockingQueue<>(PREFETCH_ROUNDS);\n                 do {\n                     long end = Math.min(needToOffloadFirstEntryNumber + ENTRIES_PER_READ - 1, readHandle.getLastAddConfirmed());\n                     log.debug(\"read ledger entries. start: {}, end: {}\", needToOffloadFirstEntryNumber, end);\n                     LedgerEntries ledgerEntriesOnce = readHandle.readAsync(needToOffloadFirstEntryNumber, end).get();\n+                    tasks.put(true);\n                     countDownLatch = new CountDownLatch(1);\n-                    assignmentScheduler.chooseThread(ledgerId).submit(new FileSystemWriter(ledgerEntriesOnce, dataWriter,\n+                    assignmentScheduler.chooseThread(ledgerId).submit(FileSystemWriter.create(ledgerEntriesOnce, dataWriter, tasks,", "originalCommit": "def4a94ad3e03cf0d032634fb91004bb8c5a5f38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NzYzMw==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407047633", "bodyText": "I made a comment below @congbobo184", "author": "pheecian", "createdAt": "2020-04-11T10:37:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzAzMDU1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NzU0NQ==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407047545", "bodyText": "the blockingQueue is to block the whole do while loop(to be precisely, the read and submit) Here, not try to limit fileSystemWriter. I understand that the FileSystemWriter will be executed orderly. My intention is to limit the whole do while loop because the do while loop((readAsync().get()) read data from ledger in advance too much too quickly(and lead to consume much memory), more than  FileSystemWriter Threads can handle timely. So read in advance, or put in other words, prefetch, should be controlled to some degree. So I introduce a blocking queue and hence a producer-consumer mock-up. the do while loop(read and submit) acts like a producer, the FileSystemWriter acts as a consumer. @congbobo184", "author": "pheecian", "createdAt": "2020-04-11T10:36:16Z", "path": "tiered-storage/file-system/src/main/java/org/apache/bookkeeper/mledger/offload/filesystem/impl/FileSystemManagedLedgerOffloader.java", "diffHunk": "@@ -188,12 +191,15 @@ public void run() {\n                 AtomicLong haveOffloadEntryNumber = new AtomicLong(0);\n                 long needToOffloadFirstEntryNumber = 0;\n                 CountDownLatch countDownLatch;\n+                //avoid prefetch too much data into memory\n+                ArrayBlockingQueue<Boolean> tasks = new ArrayBlockingQueue<>(PREFETCH_ROUNDS);\n                 do {\n                     long end = Math.min(needToOffloadFirstEntryNumber + ENTRIES_PER_READ - 1, readHandle.getLastAddConfirmed());\n                     log.debug(\"read ledger entries. start: {}, end: {}\", needToOffloadFirstEntryNumber, end);\n                     LedgerEntries ledgerEntriesOnce = readHandle.readAsync(needToOffloadFirstEntryNumber, end).get();", "originalCommit": "def4a94ad3e03cf0d032634fb91004bb8c5a5f38", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1OTE5Nw==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407159197", "bodyText": "I have  understood your min, I look up the code context, I think you can use Semaphore to fix it :)", "author": "congbobo184", "createdAt": "2020-04-12T07:26:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NzU0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE2MTQ3Nw==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407161477", "bodyText": "nice idea! I will change the code to implement the idea @congbobo184", "author": "pheecian", "createdAt": "2020-04-12T07:49:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzA0NzU0NQ=="}], "type": "inlineReview"}, {"oid": "c5295836f8c8914a60a05fa059546021f469d94f", "url": "https://github.com/apache/pulsar/commit/c5295836f8c8914a60a05fa059546021f469d94f", "message": "use semaphore instead of blockqueue", "committedDate": "2020-04-12T07:42:08Z", "type": "commit"}, {"oid": "bc7294cf0b3525090e38d7175d4f03a7f0963026", "url": "https://github.com/apache/pulsar/commit/bc7294cf0b3525090e38d7175d4f03a7f0963026", "message": "fix format", "committedDate": "2020-04-12T07:47:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE5OTk1Ng==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407199956", "bodyText": "One per reading is ok, the PREFETCH_ROUNDS unnecessary to big.", "author": "congbobo184", "createdAt": "2020-04-12T13:41:38Z", "path": "tiered-storage/file-system/src/main/java/org/apache/bookkeeper/mledger/offload/filesystem/impl/FileSystemManagedLedgerOffloader.java", "diffHunk": "@@ -62,12 +65,14 @@\n     private final FileSystem fileSystem;\n     private OrderedScheduler scheduler;\n     private static final long ENTRIES_PER_READ = 100;\n+    private static final int PREFETCH_ROUNDS = 100;", "originalCommit": "bc7294cf0b3525090e38d7175d4f03a7f0963026", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIwODk3NQ==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407208975", "bodyText": "ok", "author": "pheecian", "createdAt": "2020-04-12T14:51:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE5OTk1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIwMDE4Nw==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407200187", "bodyText": "this format should not be modified", "author": "congbobo184", "createdAt": "2020-04-12T13:43:14Z", "path": "tiered-storage/file-system/src/main/java/org/apache/bookkeeper/mledger/offload/filesystem/impl/FileSystemManagedLedgerOffloader.java", "diffHunk": "@@ -132,8 +138,8 @@ public FileSystemManagedLedgerOffloader(OffloadPolicies conf, OrderedScheduler s\n     }\n \n     /*\n-    * ledgerMetadata stored in an index of -1\n-    * */\n+     * ledgerMetadata stored in an index of -1", "originalCommit": "bc7294cf0b3525090e38d7175d4f03a7f0963026", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIwODk5MQ==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407208991", "bodyText": "ok", "author": "pheecian", "createdAt": "2020-04-12T14:51:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIwMDE4Nw=="}], "type": "inlineReview"}, {"oid": "01ae3bca7a1b7fd2629fccb06391822a31cb1e8e", "url": "https://github.com/apache/pulsar/commit/01ae3bca7a1b7fd2629fccb06391822a31cb1e8e", "message": "more conservative prefetch", "committedDate": "2020-04-12T14:45:29Z", "type": "commit"}, {"oid": "4e3a7929de7415d2ac3c1a870087b3440e7156a3", "url": "https://github.com/apache/pulsar/commit/4e3a7929de7415d2ac3c1a870087b3440e7156a3", "message": "fix format", "committedDate": "2020-04-12T14:50:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MDQ1Mw==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r407970453", "bodyText": "Can we make this configurable? I am worried about this will cause performance problems.", "author": "sijie", "createdAt": "2020-04-14T08:49:45Z", "path": "tiered-storage/file-system/src/main/java/org/apache/bookkeeper/mledger/offload/filesystem/impl/FileSystemManagedLedgerOffloader.java", "diffHunk": "@@ -188,13 +192,17 @@ public void run() {\n                 AtomicLong haveOffloadEntryNumber = new AtomicLong(0);\n                 long needToOffloadFirstEntryNumber = 0;\n                 CountDownLatch countDownLatch;\n+                //avoid prefetch too much data into memory\n+                Semaphore semaphore = new Semaphore(1);", "originalCommit": "4e3a7929de7415d2ac3c1a870087b3440e7156a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODExNzM5Ng==", "url": "https://github.com/apache/pulsar/pull/6717#discussion_r408117396", "bodyText": "sure", "author": "pheecian", "createdAt": "2020-04-14T13:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MDQ1Mw=="}], "type": "inlineReview"}, {"oid": "532bf5d5e5cc4c4541dbc474de261e0419954db3", "url": "https://github.com/apache/pulsar/commit/532bf5d5e5cc4c4541dbc474de261e0419954db3", "message": "make prefetch for offload configurable", "committedDate": "2020-04-14T12:33:59Z", "type": "commit"}, {"oid": "2ac1c38909a1c2a598b4518098a05f557c110b31", "url": "https://github.com/apache/pulsar/commit/2ac1c38909a1c2a598b4518098a05f557c110b31", "message": "fix format", "committedDate": "2020-04-14T13:00:20Z", "type": "commit"}]}