{"pr_number": 8996, "pr_title": "Ack response implementation ", "pr_createdAt": "2020-12-18T06:00:04Z", "pr_url": "https://github.com/apache/pulsar/pull/8996", "timeline": [{"oid": "6131478d0e106029d58f002f935b5074238ce4b8", "url": "https://github.com/apache/pulsar/commit/6131478d0e106029d58f002f935b5074238ce4b8", "message": "Ack response", "committedDate": "2020-12-18T05:53:43Z", "type": "commit"}, {"oid": "2c59edae59a1f07314318050a912c697ce1f8896", "url": "https://github.com/apache/pulsar/commit/2c59edae59a1f07314318050a912c697ce1f8896", "message": "Modify the ack request by clientCnx pendingRequest", "committedDate": "2020-12-22T16:36:09Z", "type": "commit"}, {"oid": "c38df666ab88eb6e44ae351aff62d405a7053cf7", "url": "https://github.com/apache/pulsar/commit/c38df666ab88eb6e44ae351aff62d405a7053cf7", "message": "Merge branch 'master' into congbobo184_ack_response_implementation\n\n# Conflicts:\n#\tpulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java", "committedDate": "2020-12-22T16:44:43Z", "type": "commit"}, {"oid": "3c2e41b74c990673ea2c730619ffa1fa195a0c29", "url": "https://github.com/apache/pulsar/commit/3c2e41b74c990673ea2c730619ffa1fa195a0c29", "message": "Fix some logical", "committedDate": "2020-12-23T01:59:27Z", "type": "commit"}, {"oid": "2174426c2fb4aebfce968931e6645f55f3532931", "url": "https://github.com/apache/pulsar/commit/2174426c2fb4aebfce968931e6645f55f3532931", "message": "Merge the ack response into tracker", "committedDate": "2020-12-27T11:56:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE1MjQyNw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549152427", "bodyText": "Move this line out of the try block", "author": "eolivelli", "createdAt": "2020-12-27T19:01:18Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -118,175 +122,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public CompletableFuture<Void> addListAcknowledgment(List<MessageIdImpl> messageIds,\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n                                                          AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return CompletableFuture.completedFuture(null);\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackResponseEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();", "originalCommit": "2174426c2fb4aebfce968931e6645f55f3532931", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI3NTY3Mw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557275673", "bodyText": "+1", "author": "codelipenghui", "createdAt": "2021-01-14T10:00:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE1MjQyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE1MjU4OQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549152589", "bodyText": "What happens if we don't have this class? Should we add an instanceof test?", "author": "eolivelli", "createdAt": "2020-12-27T19:03:18Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -118,175 +122,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public CompletableFuture<Void> addListAcknowledgment(List<MessageIdImpl> messageIds,\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n                                                          AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return CompletableFuture.completedFuture(null);\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackResponseEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    addListAcknowledgment(messageIds);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n+                }\n+            } else {\n+                addListAcknowledgment(messageIds);\n+                if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n+            }\n         }\n-        messageIds.forEach(messageId -> {\n+    }\n+\n+    private void addListAcknowledgment(List<MessageId> messageIds) {\n+        for (MessageId messageId : messageIds) {\n+            consumer.onAcknowledge(messageId, null);\n             if (messageId instanceof BatchMessageIdImpl) {\n                 BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) messageId;\n-                pendingIndividualAcks.add(new MessageIdImpl(batchMessageId.getLedgerId(),\n-                        batchMessageId.getEntryId(), batchMessageId.getPartitionIndex()));\n+                if (!batchMessageId.ackIndividual()) {\n+                    doIndividualBatchAckAsync((BatchMessageIdImpl) messageId);\n+                } else {\n+                    messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    doIndividualAckAsync((MessageIdImpl) messageId);\n+                }\n             } else {\n-                pendingIndividualAcks.add(messageId);\n-            }\n-            pendingIndividualBatchIndexAcks.remove(messageId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+                modifyMessageIdStatusInConsumer((MessageIdImpl) messageId);\n+                doIndividualAckAsync((MessageIdImpl) messageId);\n             }\n-        });\n-        if (acknowledgementGroupTimeMicros == 0) {\n-            flush();\n         }\n-        return CompletableFuture.completedFuture(null);\n     }\n \n     @Override\n-    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                  TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty() ||\n-                (txn != null && ackType == AckType.Cumulative)) {\n-                if (msgId instanceof BatchMessageIdImpl && txn != null) {\n-                    BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n-                    doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n-                            batchMessageId.getBatchIndex(),\n-                            ackType, properties, txn.getTxnIdMostBits(), txn.getTxnIdLeastBits());\n+    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType,\n+                                                     Map<String, Long> properties) {\n+        if (msgId instanceof BatchMessageIdImpl) {\n+            BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                // ack this ack carry bitSet index and judge bit set are all ack\n+                if (batchMessageId.ackIndividual()) {\n+                    MessageIdImpl messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    return doIndividualAck(messageId, properties);\n+                } else if (batchIndexAckEnabled){\n+                    return doIndividualBatchAck(batchMessageId, properties);\n+                } else {\n+                    // if we prevent batchIndexAck, we can't send the ack command to broker when the batch message are\n+                    // all ack complete\n                     return CompletableFuture.completedFuture(null);\n                 }\n-            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n-            // uncommon condition since it's only used for the compaction subscription.\n-            doImmediateAck(msgId, ackType, properties, txn);\n-        } else if (ackType == AckType.Cumulative) {\n-            doCumulativeAck(msgId, null);\n-        } else {\n-            // Individual ack\n-            if (msgId instanceof BatchMessageIdImpl) {\n-                pendingIndividualAcks.add(new MessageIdImpl(msgId.getLedgerId(),\n-                        msgId.getEntryId(), msgId.getPartitionIndex()));\n             } else {\n-                if (txn != null) {\n-                    pendingIndividualTransactionAcks\n-                            .add(Triple.of(txn.getTxnIdMostBits(), txn.getTxnIdLeastBits(), msgId));\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                if (((BatchMessageIdImpl) msgId).ackCumulative()) {", "originalCommit": "2174426c2fb4aebfce968931e6645f55f3532931", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI3NzUwMw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557277503", "bodyText": "line 183 is checked, I think @congbobo184 you can use batchMessageId since you already convert to BatchMessageIdImpl in 184", "author": "codelipenghui", "createdAt": "2021-01-14T10:03:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE1MjU4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTE1MjcyNg==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549152726", "bodyText": "Move this line out of the finally block", "author": "eolivelli", "createdAt": "2020-12-27T19:04:29Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -118,175 +122,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public CompletableFuture<Void> addListAcknowledgment(List<MessageIdImpl> messageIds,\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n                                                          AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return CompletableFuture.completedFuture(null);\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackResponseEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    addListAcknowledgment(messageIds);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n+                }\n+            } else {\n+                addListAcknowledgment(messageIds);\n+                if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n+            }\n         }\n-        messageIds.forEach(messageId -> {\n+    }\n+\n+    private void addListAcknowledgment(List<MessageId> messageIds) {\n+        for (MessageId messageId : messageIds) {\n+            consumer.onAcknowledge(messageId, null);\n             if (messageId instanceof BatchMessageIdImpl) {\n                 BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) messageId;\n-                pendingIndividualAcks.add(new MessageIdImpl(batchMessageId.getLedgerId(),\n-                        batchMessageId.getEntryId(), batchMessageId.getPartitionIndex()));\n+                if (!batchMessageId.ackIndividual()) {\n+                    doIndividualBatchAckAsync((BatchMessageIdImpl) messageId);\n+                } else {\n+                    messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    doIndividualAckAsync((MessageIdImpl) messageId);\n+                }\n             } else {\n-                pendingIndividualAcks.add(messageId);\n-            }\n-            pendingIndividualBatchIndexAcks.remove(messageId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+                modifyMessageIdStatusInConsumer((MessageIdImpl) messageId);\n+                doIndividualAckAsync((MessageIdImpl) messageId);\n             }\n-        });\n-        if (acknowledgementGroupTimeMicros == 0) {\n-            flush();\n         }\n-        return CompletableFuture.completedFuture(null);\n     }\n \n     @Override\n-    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                  TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty() ||\n-                (txn != null && ackType == AckType.Cumulative)) {\n-                if (msgId instanceof BatchMessageIdImpl && txn != null) {\n-                    BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n-                    doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n-                            batchMessageId.getBatchIndex(),\n-                            ackType, properties, txn.getTxnIdMostBits(), txn.getTxnIdLeastBits());\n+    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType,\n+                                                     Map<String, Long> properties) {\n+        if (msgId instanceof BatchMessageIdImpl) {\n+            BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                // ack this ack carry bitSet index and judge bit set are all ack\n+                if (batchMessageId.ackIndividual()) {\n+                    MessageIdImpl messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    return doIndividualAck(messageId, properties);\n+                } else if (batchIndexAckEnabled){\n+                    return doIndividualBatchAck(batchMessageId, properties);\n+                } else {\n+                    // if we prevent batchIndexAck, we can't send the ack command to broker when the batch message are\n+                    // all ack complete\n                     return CompletableFuture.completedFuture(null);\n                 }\n-            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n-            // uncommon condition since it's only used for the compaction subscription.\n-            doImmediateAck(msgId, ackType, properties, txn);\n-        } else if (ackType == AckType.Cumulative) {\n-            doCumulativeAck(msgId, null);\n-        } else {\n-            // Individual ack\n-            if (msgId instanceof BatchMessageIdImpl) {\n-                pendingIndividualAcks.add(new MessageIdImpl(msgId.getLedgerId(),\n-                        msgId.getEntryId(), msgId.getPartitionIndex()));\n             } else {\n-                if (txn != null) {\n-                    pendingIndividualTransactionAcks\n-                            .add(Triple.of(txn.getTxnIdMostBits(), txn.getTxnIdLeastBits(), msgId));\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                if (((BatchMessageIdImpl) msgId).ackCumulative()) {\n+                    return doCumulativeAck(msgId, properties, null);\n                 } else {\n-                    pendingIndividualAcks.add(msgId);\n+                    if (batchIndexAckEnabled) {\n+                        return doCumulativeBatchAck(batchMessageId, properties);\n+                    } else {\n+                        // ack the pre messageId, because we prevent the batchIndexAck, we can ensure pre messageId can\n+                        // ack\n+                        if (AckType.Cumulative == ackType\n+                                && !batchMessageId.getAcker().isPrevBatchCumulativelyAcked()) {\n+                            doCumulativeAck(batchMessageId.prevBatchMessageId(), properties, null);\n+                            batchMessageId.getAcker().setPrevBatchCumulativelyAcked(true);\n+                        }\n+                        return CompletableFuture.completedFuture(null);\n+                    }\n                 }\n             }\n-            pendingIndividualBatchIndexAcks.remove(msgId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+        } else {\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                modifyMessageIdStatusInConsumer(msgId);\n+                return doIndividualAck(msgId, properties);\n+            } else {\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                return doCumulativeAck(msgId, properties, null);\n             }\n         }\n-        return CompletableFuture.completedFuture(null);\n     }\n \n-    @Override\n-    public CompletableFuture<Void> addBatchIndexAcknowledgment(BatchMessageIdImpl msgId, int batchIndex, int batchSize, AckType ackType,\n-                                            Map<String, Long> properties, TransactionImpl txn) {\n-        if (batchIndexAckEnabled) {\n-            if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty()) {\n-                doImmediateBatchIndexAck(msgId, batchIndex, batchSize, ackType, properties,\n-                        txn == null ? -1 : txn.getTxnIdMostBits(),\n-                        txn == null ? -1 : txn.getTxnIdLeastBits());\n-            } else if (ackType == AckType.Cumulative) {\n-                BitSetRecyclable bitSet = BitSetRecyclable.create();\n-                bitSet.set(0, batchSize);\n-                bitSet.clear(0, batchIndex + 1);\n-                doCumulativeAck(msgId, bitSet);\n-            } else if (ackType == AckType.Individual) {\n-                ConcurrentBitSetRecyclable bitSet;\n-                bitSet = pendingIndividualBatchIndexAcks.computeIfAbsent(\n-                        new MessageIdImpl(msgId.getLedgerId(), msgId.getEntryId(),\n-                                msgId.getPartitionIndex()), (v) -> {\n-                            ConcurrentBitSetRecyclable value;\n-                            if (msgId.getAcker() != null &&\n-                                    !(msgId.getAcker() instanceof BatchMessageAckerDisabled)) {\n-                                value = ConcurrentBitSetRecyclable.create(msgId.getAcker().getBitSet());\n-                            } else {\n-                                value = ConcurrentBitSetRecyclable.create();\n-                                value.set(0, batchSize);\n-                            }\n-                            return value;\n-                        });\n-                bitSet.clear(batchIndex);\n-                if (pendingIndividualBatchIndexAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+    private MessageIdImpl modifyBatchMessageIdAndStatusInConsumer(BatchMessageIdImpl batchMessageId) {\n+        MessageIdImpl messageId = new MessageIdImpl(batchMessageId.getLedgerId(),\n+                batchMessageId.getEntryId(), batchMessageId.getPartitionIndex());\n+        consumer.getStats().incrementNumAcksSent(batchMessageId.getBatchSize());\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+        return messageId;\n+    }\n+\n+    private void modifyMessageIdStatusInConsumer(MessageIdImpl messageId) {\n+        consumer.getStats().incrementNumAcksSent(1);\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+    }\n+\n+    private void modifyMessageIdStatusInConsumerCommon(MessageIdImpl messageId) {\n+        consumer.getUnAckedMessageTracker().remove(messageId);\n+        if (consumer.getPossibleSendToDeadLetterTopicMessages() != null) {\n+            consumer.getPossibleSendToDeadLetterTopicMessages().remove(messageId);\n+        }\n+    }\n+\n+    private CompletableFuture<Void> doIndividualAck(MessageIdImpl messageId, Map<String, Long> properties) {\n+        if (acknowledgementGroupTimeMicros == 0 || (properties != null && !properties.isEmpty())) {\n+            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n+            // uncommon condition since it's only used for the compaction subscription.\n+            return doImmediateAck(messageId, AckType.Individual, properties, null);\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();", "originalCommit": "2174426c2fb4aebfce968931e6645f55f3532931", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fe2540029e1628c5a93b158e9c9ef9baedf14b58", "url": "https://github.com/apache/pulsar/commit/fe2540029e1628c5a93b158e9c9ef9baedf14b58", "message": "modify the lock logical", "committedDate": "2020-12-28T01:19:41Z", "type": "commit"}, {"oid": "bde7246b406b8e2649212b90b32c3e2069072f05", "url": "https://github.com/apache/pulsar/commit/bde7246b406b8e2649212b90b32c3e2069072f05", "message": "Merge branch 'master' into congbobo184_ack_response_implementation", "committedDate": "2020-12-30T02:44:54Z", "type": "commit"}, {"oid": "37215368b4bd84bd7c980358d5d5bfa6f253865b", "url": "https://github.com/apache/pulsar/commit/37215368b4bd84bd7c980358d5d5bfa6f253865b", "message": "Merge branch 'master' into congbobo184_ack_response_implementation\n\n# Conflicts:\n#\tpulsar-client/src/main/java/org/apache/pulsar/client/impl/AcknowledgmentsGroupingTracker.java\n#\tpulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java\n#\tpulsar-client/src/test/java/org/apache/pulsar/client/impl/AcknowledgementsGroupingTrackerTest.java\n#\tpulsar-common/src/main/java/org/apache/pulsar/common/protocol/Commands.java", "committedDate": "2021-01-06T15:12:13Z", "type": "commit"}, {"oid": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "url": "https://github.com/apache/pulsar/commit/bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "message": "Merge branch 'master' into congbobo184_ack_response_implementation\n\n# Conflicts:\n#\tpulsar-broker/src/test/java/org/apache/pulsar/client/impl/MessageChunkingTest.java", "committedDate": "2021-01-11T01:01:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI2NTkyOQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557265929", "bodyText": "Is the PulsarClientException.TimeoutException works?", "author": "codelipenghui", "createdAt": "2021-01-14T09:45:49Z", "path": "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/PulsarClientException.java", "diffHunk": "@@ -864,6 +864,32 @@ public TransactionConflictException(String msg) {\n         }\n     }\n \n+    /**\n+     * Consumer ack for response timeout.\n+     */\n+    public static class AckResponseTimeoutException extends PulsarClientException {", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzgyNzE2Nw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557827167", "bodyText": "No, it can be deleted.", "author": "congbobo184", "createdAt": "2021-01-15T02:41:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI2NTkyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI2ODQ1Mw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557268453", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                ConsumerBuilder<T> enableAckResponse(boolean ackResponseEnabled);\n          \n          \n            \n                ConsumerBuilder<T> isAckReceiptEnabled(boolean ackReceiptEnabled);", "author": "codelipenghui", "createdAt": "2021-01-14T09:49:39Z", "path": "pulsar-client-api/src/main/java/org/apache/pulsar/client/api/ConsumerBuilder.java", "diffHunk": "@@ -186,6 +186,14 @@\n      */\n     ConsumerBuilder<T> ackTimeout(long ackTimeout, TimeUnit timeUnit);\n \n+    /**\n+     * Ack will return response but does not mean that the message will not be resent after get response.\n+     *\n+     * @param ackResponseEnabled {@link Boolean} is enable ack for response\n+     * @return the consumer builder instance\n+     */\n+    ConsumerBuilder<T> enableAckResponse(boolean ackResponseEnabled);", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI2OTkwMQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557269901", "bodyText": "I think response here a little bit ambiguous since the client also can get the returned future without this feature.", "author": "codelipenghui", "createdAt": "2021-01-14T09:51:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzI2ODQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMxMTA5NQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557311095", "bodyText": "These methods not clear here. Stats, not status. And should split the update stats method and cleanup consumer method stay independent, this will improve the code readability", "author": "codelipenghui", "createdAt": "2021-01-14T10:58:53Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -115,186 +122,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public void addListAcknowledgment(List<MessageIdImpl> messageIds, AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return;\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n+                                                         AckType ackType, Map<String, Long> properties) {\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackResponseEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    addListAcknowledgment(messageIds);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n+                }\n+            } else {\n+                addListAcknowledgment(messageIds);\n+                if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n+            }\n         }\n-        messageIds.forEach(messageId -> {\n+    }\n+\n+    private void addListAcknowledgment(List<MessageId> messageIds) {\n+        for (MessageId messageId : messageIds) {\n+            consumer.onAcknowledge(messageId, null);\n             if (messageId instanceof BatchMessageIdImpl) {\n                 BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) messageId;\n-                pendingIndividualAcks.add(new MessageIdImpl(batchMessageId.getLedgerId(),\n-                        batchMessageId.getEntryId(), batchMessageId.getPartitionIndex()));\n+                if (!batchMessageId.ackIndividual()) {\n+                    doIndividualBatchAckAsync((BatchMessageIdImpl) messageId);\n+                } else {\n+                    messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    doIndividualAckAsync((MessageIdImpl) messageId);\n+                }\n             } else {\n-                pendingIndividualAcks.add(messageId);\n-            }\n-            pendingIndividualBatchIndexAcks.remove(messageId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+                modifyMessageIdStatusInConsumer((MessageIdImpl) messageId);\n+                doIndividualAckAsync((MessageIdImpl) messageId);\n             }\n-        });\n-        if (acknowledgementGroupTimeMicros == 0) {\n-            flush();\n         }\n     }\n \n     @Override\n-    public void addAcknowledgment(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                  TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty() ||\n-                (txn != null && ackType == AckType.Cumulative)) {\n-                if (msgId instanceof BatchMessageIdImpl && txn != null) {\n-                    BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n-                    doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n-                            batchMessageId.getBatchIndex(),\n-                            ackType, properties, txn.getTxnIdMostBits(), txn.getTxnIdLeastBits());\n-                    return;\n+    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType,\n+                                                     Map<String, Long> properties) {\n+        if (msgId instanceof BatchMessageIdImpl) {\n+            BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                // ack this ack carry bitSet index and judge bit set are all ack\n+                if (batchMessageId.ackIndividual()) {\n+                    MessageIdImpl messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    return doIndividualAck(messageId, properties);\n+                } else if (batchIndexAckEnabled){\n+                    return doIndividualBatchAck(batchMessageId, properties);\n+                } else {\n+                    // if we prevent batchIndexAck, we can't send the ack command to broker when the batch message are\n+                    // all ack complete\n+                    return CompletableFuture.completedFuture(null);\n                 }\n-            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n-            // uncommon condition since it's only used for the compaction subscription.\n-            doImmediateAck(msgId, ackType, properties, txn);\n-        } else if (ackType == AckType.Cumulative) {\n-            doCumulativeAck(msgId, null);\n-        } else {\n-            // Individual ack\n-            if (msgId instanceof BatchMessageIdImpl) {\n-                pendingIndividualAcks.add(new MessageIdImpl(msgId.getLedgerId(),\n-                        msgId.getEntryId(), msgId.getPartitionIndex()));\n             } else {\n-                if (txn != null) {\n-                    pendingIndividualTransactionAcks\n-                            .add(Triple.of(txn.getTxnIdMostBits(), txn.getTxnIdLeastBits(), msgId));\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                if (((BatchMessageIdImpl) msgId).ackCumulative()) {\n+                    return doCumulativeAck(msgId, properties, null);\n                 } else {\n-                    pendingIndividualAcks.add(msgId);\n+                    if (batchIndexAckEnabled) {\n+                        return doCumulativeBatchAck(batchMessageId, properties);\n+                    } else {\n+                        // ack the pre messageId, because we prevent the batchIndexAck, we can ensure pre messageId can\n+                        // ack\n+                        if (AckType.Cumulative == ackType\n+                                && !batchMessageId.getAcker().isPrevBatchCumulativelyAcked()) {\n+                            doCumulativeAck(batchMessageId.prevBatchMessageId(), properties, null);\n+                            batchMessageId.getAcker().setPrevBatchCumulativelyAcked(true);\n+                        }\n+                        return CompletableFuture.completedFuture(null);\n+                    }\n                 }\n             }\n-            pendingIndividualBatchIndexAcks.remove(msgId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+        } else {\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                modifyMessageIdStatusInConsumer(msgId);\n+                return doIndividualAck(msgId, properties);\n+            } else {\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                return doCumulativeAck(msgId, properties, null);\n             }\n         }\n     }\n \n-    public void addBatchIndexAcknowledgment(BatchMessageIdImpl msgId, int batchIndex, int batchSize, AckType ackType,\n-                                            Map<String, Long> properties, TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty()) {\n-            doImmediateBatchIndexAck(msgId, batchIndex, batchSize, ackType, properties,\n-                    txn == null ? -1 : txn.getTxnIdMostBits(),\n-                    txn == null ? -1 : txn.getTxnIdLeastBits());\n-        } else if (ackType == AckType.Cumulative) {\n-            BitSetRecyclable bitSet = BitSetRecyclable.create();\n-            bitSet.set(0, batchSize);\n-            bitSet.clear(0, batchIndex + 1);\n-            doCumulativeAck(msgId, bitSet);\n-        } else if (ackType == AckType.Individual) {\n-            ConcurrentBitSetRecyclable bitSet;\n-            if (txn != null) {\n-                synchronized (txn) {\n-                    ConcurrentHashMap<MessageIdImpl, ConcurrentBitSetRecyclable> transactionIndividualBatchIndexAcks =\n-                            pendingIndividualTransactionBatchIndexAcks\n-                                    .computeIfAbsent(txn, (v) -> new ConcurrentHashMap<>());\n-                    bitSet = transactionIndividualBatchIndexAcks.computeIfAbsent(msgId, (v) -> {\n-                        ConcurrentBitSetRecyclable value;\n-                        value = ConcurrentBitSetRecyclable.create();\n-                        value.set(0, msgId.getAcker().getBatchSize());\n-                        return value;\n-                    });\n-                    bitSet.clear(batchIndex);\n+    private MessageIdImpl modifyBatchMessageIdAndStatusInConsumer(BatchMessageIdImpl batchMessageId) {\n+        MessageIdImpl messageId = new MessageIdImpl(batchMessageId.getLedgerId(),\n+                batchMessageId.getEntryId(), batchMessageId.getPartitionIndex());\n+        consumer.getStats().incrementNumAcksSent(batchMessageId.getBatchSize());\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+        return messageId;\n+    }\n+\n+    private void modifyMessageIdStatusInConsumer(MessageIdImpl messageId) {\n+        consumer.getStats().incrementNumAcksSent(1);\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+    }\n+\n+    private void modifyMessageIdStatusInConsumerCommon(MessageIdImpl messageId) {\n+        consumer.getUnAckedMessageTracker().remove(messageId);\n+        if (consumer.getPossibleSendToDeadLetterTopicMessages() != null) {\n+            consumer.getPossibleSendToDeadLetterTopicMessages().remove(messageId);\n+        }\n+    }", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMxMTczNA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557311734", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private CompletableFuture<Void> doCumulativeBatchAck(BatchMessageIdImpl batchMessageId,\n          \n          \n            \n                private CompletableFuture<Void> doCumulativeBatchIndexAck(BatchMessageIdImpl batchMessageId,", "author": "codelipenghui", "createdAt": "2021-01-14T10:59:54Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -115,186 +122,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public void addListAcknowledgment(List<MessageIdImpl> messageIds, AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return;\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n+                                                         AckType ackType, Map<String, Long> properties) {\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackResponseEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    addListAcknowledgment(messageIds);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n+                }\n+            } else {\n+                addListAcknowledgment(messageIds);\n+                if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n+            }\n         }\n-        messageIds.forEach(messageId -> {\n+    }\n+\n+    private void addListAcknowledgment(List<MessageId> messageIds) {\n+        for (MessageId messageId : messageIds) {\n+            consumer.onAcknowledge(messageId, null);\n             if (messageId instanceof BatchMessageIdImpl) {\n                 BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) messageId;\n-                pendingIndividualAcks.add(new MessageIdImpl(batchMessageId.getLedgerId(),\n-                        batchMessageId.getEntryId(), batchMessageId.getPartitionIndex()));\n+                if (!batchMessageId.ackIndividual()) {\n+                    doIndividualBatchAckAsync((BatchMessageIdImpl) messageId);\n+                } else {\n+                    messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    doIndividualAckAsync((MessageIdImpl) messageId);\n+                }\n             } else {\n-                pendingIndividualAcks.add(messageId);\n-            }\n-            pendingIndividualBatchIndexAcks.remove(messageId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+                modifyMessageIdStatusInConsumer((MessageIdImpl) messageId);\n+                doIndividualAckAsync((MessageIdImpl) messageId);\n             }\n-        });\n-        if (acknowledgementGroupTimeMicros == 0) {\n-            flush();\n         }\n     }\n \n     @Override\n-    public void addAcknowledgment(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                  TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty() ||\n-                (txn != null && ackType == AckType.Cumulative)) {\n-                if (msgId instanceof BatchMessageIdImpl && txn != null) {\n-                    BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n-                    doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n-                            batchMessageId.getBatchIndex(),\n-                            ackType, properties, txn.getTxnIdMostBits(), txn.getTxnIdLeastBits());\n-                    return;\n+    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType,\n+                                                     Map<String, Long> properties) {\n+        if (msgId instanceof BatchMessageIdImpl) {\n+            BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                // ack this ack carry bitSet index and judge bit set are all ack\n+                if (batchMessageId.ackIndividual()) {\n+                    MessageIdImpl messageId = modifyBatchMessageIdAndStatusInConsumer(batchMessageId);\n+                    return doIndividualAck(messageId, properties);\n+                } else if (batchIndexAckEnabled){\n+                    return doIndividualBatchAck(batchMessageId, properties);\n+                } else {\n+                    // if we prevent batchIndexAck, we can't send the ack command to broker when the batch message are\n+                    // all ack complete\n+                    return CompletableFuture.completedFuture(null);\n                 }\n-            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n-            // uncommon condition since it's only used for the compaction subscription.\n-            doImmediateAck(msgId, ackType, properties, txn);\n-        } else if (ackType == AckType.Cumulative) {\n-            doCumulativeAck(msgId, null);\n-        } else {\n-            // Individual ack\n-            if (msgId instanceof BatchMessageIdImpl) {\n-                pendingIndividualAcks.add(new MessageIdImpl(msgId.getLedgerId(),\n-                        msgId.getEntryId(), msgId.getPartitionIndex()));\n             } else {\n-                if (txn != null) {\n-                    pendingIndividualTransactionAcks\n-                            .add(Triple.of(txn.getTxnIdMostBits(), txn.getTxnIdLeastBits(), msgId));\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                if (((BatchMessageIdImpl) msgId).ackCumulative()) {\n+                    return doCumulativeAck(msgId, properties, null);\n                 } else {\n-                    pendingIndividualAcks.add(msgId);\n+                    if (batchIndexAckEnabled) {\n+                        return doCumulativeBatchAck(batchMessageId, properties);\n+                    } else {\n+                        // ack the pre messageId, because we prevent the batchIndexAck, we can ensure pre messageId can\n+                        // ack\n+                        if (AckType.Cumulative == ackType\n+                                && !batchMessageId.getAcker().isPrevBatchCumulativelyAcked()) {\n+                            doCumulativeAck(batchMessageId.prevBatchMessageId(), properties, null);\n+                            batchMessageId.getAcker().setPrevBatchCumulativelyAcked(true);\n+                        }\n+                        return CompletableFuture.completedFuture(null);\n+                    }\n                 }\n             }\n-            pendingIndividualBatchIndexAcks.remove(msgId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+        } else {\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                modifyMessageIdStatusInConsumer(msgId);\n+                return doIndividualAck(msgId, properties);\n+            } else {\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                return doCumulativeAck(msgId, properties, null);\n             }\n         }\n     }\n \n-    public void addBatchIndexAcknowledgment(BatchMessageIdImpl msgId, int batchIndex, int batchSize, AckType ackType,\n-                                            Map<String, Long> properties, TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty()) {\n-            doImmediateBatchIndexAck(msgId, batchIndex, batchSize, ackType, properties,\n-                    txn == null ? -1 : txn.getTxnIdMostBits(),\n-                    txn == null ? -1 : txn.getTxnIdLeastBits());\n-        } else if (ackType == AckType.Cumulative) {\n-            BitSetRecyclable bitSet = BitSetRecyclable.create();\n-            bitSet.set(0, batchSize);\n-            bitSet.clear(0, batchIndex + 1);\n-            doCumulativeAck(msgId, bitSet);\n-        } else if (ackType == AckType.Individual) {\n-            ConcurrentBitSetRecyclable bitSet;\n-            if (txn != null) {\n-                synchronized (txn) {\n-                    ConcurrentHashMap<MessageIdImpl, ConcurrentBitSetRecyclable> transactionIndividualBatchIndexAcks =\n-                            pendingIndividualTransactionBatchIndexAcks\n-                                    .computeIfAbsent(txn, (v) -> new ConcurrentHashMap<>());\n-                    bitSet = transactionIndividualBatchIndexAcks.computeIfAbsent(msgId, (v) -> {\n-                        ConcurrentBitSetRecyclable value;\n-                        value = ConcurrentBitSetRecyclable.create();\n-                        value.set(0, msgId.getAcker().getBatchSize());\n-                        return value;\n-                    });\n-                    bitSet.clear(batchIndex);\n+    private MessageIdImpl modifyBatchMessageIdAndStatusInConsumer(BatchMessageIdImpl batchMessageId) {\n+        MessageIdImpl messageId = new MessageIdImpl(batchMessageId.getLedgerId(),\n+                batchMessageId.getEntryId(), batchMessageId.getPartitionIndex());\n+        consumer.getStats().incrementNumAcksSent(batchMessageId.getBatchSize());\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+        return messageId;\n+    }\n+\n+    private void modifyMessageIdStatusInConsumer(MessageIdImpl messageId) {\n+        consumer.getStats().incrementNumAcksSent(1);\n+        modifyMessageIdStatusInConsumerCommon(messageId);\n+    }\n+\n+    private void modifyMessageIdStatusInConsumerCommon(MessageIdImpl messageId) {\n+        consumer.getUnAckedMessageTracker().remove(messageId);\n+        if (consumer.getPossibleSendToDeadLetterTopicMessages() != null) {\n+            consumer.getPossibleSendToDeadLetterTopicMessages().remove(messageId);\n+        }\n+    }\n+\n+    private CompletableFuture<Void> doIndividualAck(MessageIdImpl messageId, Map<String, Long> properties) {\n+        if (acknowledgementGroupTimeMicros == 0 || (properties != null && !properties.isEmpty())) {\n+            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n+            // uncommon condition since it's only used for the compaction subscription.\n+            return doImmediateAck(messageId, AckType.Individual, properties, null);\n+        } else {\n+            if (ackResponseEnabled) {\n+                // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                // any ack operation is allowed.\n+                this.lock.readLock().lock();\n+                try {\n+                    doIndividualAckAsync(messageId);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n                 }\n             } else {\n-                bitSet = pendingIndividualBatchIndexAcks.computeIfAbsent(\n-                new MessageIdImpl(msgId.getLedgerId(), msgId.getEntryId(), msgId.getPartitionIndex()), (v) -> {\n-                            ConcurrentBitSetRecyclable value;\n-                            if (msgId.getAcker() != null && !(msgId.getAcker() instanceof BatchMessageAckerDisabled)) {\n-                                value = ConcurrentBitSetRecyclable.create(msgId.getAcker().getBitSet());\n-                            } else {\n-                                value = ConcurrentBitSetRecyclable.create();\n-                                value.set(0, batchSize);\n-                            }\n-                            return value;\n-                        });\n-                bitSet.clear(batchIndex);\n+                doIndividualAckAsync(messageId);\n+                if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n             }\n-            if (pendingIndividualBatchIndexAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+        }\n+    }\n+\n+\n+    private void doIndividualAckAsync(MessageIdImpl messageId) {\n+        pendingIndividualAcks.add(messageId);\n+        pendingIndividualBatchIndexAcks.remove(messageId);\n+    }\n+\n+    private CompletableFuture<Void> doIndividualBatchAck(BatchMessageIdImpl batchMessageId,\n+                                                         Map<String, Long> properties) {\n+        if (acknowledgementGroupTimeMicros == 0 || (properties != null && !properties.isEmpty())) {\n+            return doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n+                    batchMessageId.getBatchSize(), AckType.Individual, properties);\n+        } else {\n+            return doIndividualBatchAck(batchMessageId);\n+        }\n+    }\n+\n+    private CompletableFuture<Void> doIndividualBatchAck(BatchMessageIdImpl batchMessageId) {\n+        if (ackResponseEnabled) {\n+            // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+            // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+            // any ack operation is allowed.\n+            this.lock.readLock().lock();\n+            try {\n+                doIndividualBatchAckAsync(batchMessageId);\n+                return this.currentIndividualAckFuture;\n+            } finally {\n+                this.lock.readLock().unlock();\n             }\n+        } else {\n+            doIndividualBatchAckAsync(batchMessageId);\n+            return CompletableFuture.completedFuture(null);\n         }\n     }\n \n-    private void doCumulativeAck(MessageIdImpl msgId, BitSetRecyclable bitSet) {\n-        // Handle concurrent updates from different threads\n-        while (true) {\n-            MessageIdImpl lastCumlativeAck = this.lastCumulativeAck;\n-            BitSetRecyclable lastBitSet = this.lastCumulativeAckSet;\n-            if (msgId.compareTo(lastCumlativeAck) > 0) {\n-                if (LAST_CUMULATIVE_ACK_UPDATER.compareAndSet(this, lastCumlativeAck, msgId) && LAST_CUMULATIVE_ACK_SET_UPDATER.compareAndSet(this, lastBitSet, bitSet)) {\n-                    if (lastBitSet != null) {\n-                        try {\n-                            lastBitSet.recycle();\n-                        } catch (Exception ignore) {\n-                            // no-op\n-                        }\n+    private CompletableFuture<Void> doCumulativeAck(MessageIdImpl messageId, Map<String, Long> properties,\n+                                                    BitSetRecyclable bitSet) {\n+        consumer.getStats().incrementNumAcksSent(consumer.getUnAckedMessageTracker().removeMessagesTill(messageId));\n+        if (acknowledgementGroupTimeMicros == 0 || (properties != null && !properties.isEmpty())) {\n+            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n+            // uncommon condition since it's only used for the compaction subscription.\n+            return doImmediateAck(messageId, AckType.Cumulative, properties, bitSet);\n+        } else {\n+            if (ackResponseEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    doCumulativeAckAsync(messageId, bitSet);\n+                    return this.currentCumulativeAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (pendingIndividualBatchIndexAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n                     }\n-                    // Successfully updated the last cumulative ack. Next flush iteration will send this to broker.\n-                    cumulativeAckFlushRequired = true;\n-                    return;\n                 }\n             } else {\n-                // message id acknowledging an before the current last cumulative ack\n-                return;\n+                doCumulativeAckAsync(messageId, bitSet);\n+                if (pendingIndividualBatchIndexAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n             }\n         }\n     }\n \n-    private void doTransactionCumulativeAck(MessageIdImpl msgId, BitSetRecyclable bitSet) {\n+    private void doIndividualBatchAckAsync(BatchMessageIdImpl batchMessageId) {\n+        ConcurrentBitSetRecyclable bitSet = pendingIndividualBatchIndexAcks.computeIfAbsent(\n+                new MessageIdImpl(batchMessageId.getLedgerId(), batchMessageId.getEntryId(),\n+                        batchMessageId.getPartitionIndex()), (v) -> {\n+                    ConcurrentBitSetRecyclable value;\n+                    if (batchMessageId.getAcker() != null &&\n+                            !(batchMessageId.getAcker() instanceof BatchMessageAckerDisabled)) {\n+                        value = ConcurrentBitSetRecyclable.create(batchMessageId.getAcker().getBitSet());\n+                    } else {\n+                        value = ConcurrentBitSetRecyclable.create();\n+                        value.set(0, batchMessageId.getBatchIndex());\n+                    }\n+                    return value;\n+                });\n+        bitSet.clear(batchMessageId.getBatchIndex());\n+    }\n+\n+    private void doCumulativeAckAsync(MessageIdImpl msgId, BitSetRecyclable bitSet) {\n         // Handle concurrent updates from different threads\n+        LastCumulativeAck currentCumulativeAck = LastCumulativeAck.create(msgId, bitSet);\n         while (true) {\n-            MessageIdImpl lastCumlativeAck = this.lastCumulativeAck;\n-            BitSetRecyclable lastBitSet = this.lastCumulativeAckSet;\n-            if (msgId.compareTo(lastCumlativeAck) > 0) {\n-                if (LAST_CUMULATIVE_ACK_UPDATER.compareAndSet(this, lastCumlativeAck, msgId) && LAST_CUMULATIVE_ACK_SET_UPDATER.compareAndSet(this, lastBitSet, bitSet)) {\n-                    if (lastBitSet != null) {\n+            LastCumulativeAck lastCumulativeAck = this.lastCumulativeAck;\n+            if (msgId.compareTo(lastCumulativeAck.messageId) > 0) {\n+                if (LAST_CUMULATIVE_ACK_UPDATER.compareAndSet(this, this.lastCumulativeAck, currentCumulativeAck)) {\n+                    if (lastCumulativeAck.bitSetRecyclable != null) {\n                         try {\n-                            lastBitSet.recycle();\n+                            lastCumulativeAck.bitSetRecyclable.recycle();\n                         } catch (Exception ignore) {\n                             // no-op\n                         }\n+                        lastCumulativeAck.bitSetRecyclable = null;\n                     }\n+                    lastCumulativeAck.recycle();\n                     // Successfully updated the last cumulative ack. Next flush iteration will send this to broker.\n                     cumulativeAckFlushRequired = true;\n                     return;\n                 }\n             } else {\n+                currentCumulativeAck.recycle();\n                 // message id acknowledging an before the current last cumulative ack\n                 return;\n             }\n         }\n     }\n \n-    private boolean doImmediateAck(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                   TransactionImpl transaction) {\n+    private CompletableFuture<Void> doCumulativeBatchAck(BatchMessageIdImpl batchMessageId,", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMxMjk1Nw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557312957", "bodyText": "Please optimize duplicate code", "author": "codelipenghui", "createdAt": "2021-01-14T11:01:57Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -330,16 +462,41 @@ public void flush() {\n             return;\n         }\n \n+        if (ackResponseEnabled) {\n+            this.lock.writeLock().lock();\n+            try {\n+                flushAsync(cnx);\n+            } finally {\n+                this.lock.writeLock().unlock();\n+            }\n+        } else {\n+            flushAsync(cnx);\n+        }\n+    }\n+\n+    private void flushAsync(ClientCnx cnx) {\n         boolean shouldFlush = false;\n         if (cumulativeAckFlushRequired) {\n-            newAckCommand(consumer.consumerId, lastCumulativeAck, lastCumulativeAckSet, AckType.Cumulative, null, Collections.emptyMap(), cnx, false /* flush */, -1, -1);\n+            if (ackResponseEnabled) {\n+                long requestId = consumer.getClient().newRequestId();\n+                ByteBuf cmd = Commands.newAck(consumer.consumerId, lastCumulativeAck.messageId.ledgerId,\n+                        lastCumulativeAck.messageId.getEntryId(), lastCumulativeAck.bitSetRecyclable,\n+                        AckType.Cumulative, null, Collections.emptyMap(), requestId);\n+                cnx.newAckForResponseWithFuture(cmd, requestId, currentCumulativeAckFuture);\n+                this.currentCumulativeAckFuture = new TimedCompletableFuture<>();\n+            } else {\n+                ByteBuf cmd = Commands.newAck(consumer.consumerId, lastCumulativeAck.messageId.ledgerId,\n+                        lastCumulativeAck.messageId.getEntryId(), lastCumulativeAck.bitSetRecyclable,\n+                        AckType.Cumulative, null, Collections.emptyMap(), -1);\n+                cnx.ctx().write(cmd, cnx.ctx().voidPromise());", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Nzg0NDM2MA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557844360", "bodyText": "if we optimize the code, we will judge the ackResponseEnabled twice, because get requestId then new cmd and then write. get requestId and write are different from normal ack and ack response. the middle operation newAckComand can't be optimized.", "author": "congbobo184", "createdAt": "2021-01-15T03:45:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMxMjk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyNDAwMg==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557324002", "bodyText": "Should write the command to the broker?  And please consider reducing the duplicate code", "author": "codelipenghui", "createdAt": "2021-01-14T11:21:23Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -497,46 +586,84 @@ public void close() {\n         }\n     }\n \n-    private void newAckCommand(long consumerId, MessageIdImpl msgId, BitSetRecyclable lastCumulativeAckSet,\n-            AckType ackType, ValidationError validationError, Map<String, Long> map, ClientCnx cnx,\n-                               boolean flush, long txnidMostBits, long txnidLeastBits) {\n-\n-        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.get(msgId);\n-        if (chunkMsgIds != null && txnidLeastBits < 0 && txnidMostBits < 0) {\n-            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())\n-                    && ackType != AckType.Cumulative) {\n+    private CompletableFuture<Void> newImmediateAckAndFlush(long consumerId, MessageIdImpl msgId,\n+                                                            BitSetRecyclable bitSet, AckType ackType,\n+                                                            Map<String, Long> map, ClientCnx cnx) {\n+        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.remove(msgId);\n+        final CompletableFuture<Void> completableFuture;\n+        // cumulative ack chunk by the last messageId\n+        if (chunkMsgIds != null &&  ackType != AckType.Cumulative) {\n+            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())) {\n                 List<Triple<Long, Long, ConcurrentBitSetRecyclable>> entriesToAck = new ArrayList<>(chunkMsgIds.length);\n                 for (MessageIdImpl cMsgId : chunkMsgIds) {\n                     if (cMsgId != null && chunkMsgIds.length > 1) {\n                         entriesToAck.add(Triple.of(cMsgId.getLedgerId(), cMsgId.getEntryId(), null));\n                     }\n                 }\n-                ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck);\n-                if (flush) {\n-                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                if (ackResponseEnabled) {\n+                    long requestId = consumer.getClient().newRequestId();\n+                    ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck, requestId);\n+                    completableFuture = cnx.newAckForResponse(cmd, requestId);", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Nzg0NDg5OQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557844899", "bodyText": "because newImmediateAckAndFlush so we should write the command to broker immediately.", "author": "congbobo184", "createdAt": "2021-01-15T03:47:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyNDAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyNTE3MA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557325170", "bodyText": "Why only support for muti message ack. Single message acknowledge also can enable ack receipt?", "author": "codelipenghui", "createdAt": "2021-01-14T11:23:46Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -497,46 +586,84 @@ public void close() {\n         }\n     }\n \n-    private void newAckCommand(long consumerId, MessageIdImpl msgId, BitSetRecyclable lastCumulativeAckSet,\n-            AckType ackType, ValidationError validationError, Map<String, Long> map, ClientCnx cnx,\n-                               boolean flush, long txnidMostBits, long txnidLeastBits) {\n-\n-        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.get(msgId);\n-        if (chunkMsgIds != null && txnidLeastBits < 0 && txnidMostBits < 0) {\n-            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())\n-                    && ackType != AckType.Cumulative) {\n+    private CompletableFuture<Void> newImmediateAckAndFlush(long consumerId, MessageIdImpl msgId,\n+                                                            BitSetRecyclable bitSet, AckType ackType,\n+                                                            Map<String, Long> map, ClientCnx cnx) {\n+        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.remove(msgId);\n+        final CompletableFuture<Void> completableFuture;\n+        // cumulative ack chunk by the last messageId\n+        if (chunkMsgIds != null &&  ackType != AckType.Cumulative) {\n+            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())) {\n                 List<Triple<Long, Long, ConcurrentBitSetRecyclable>> entriesToAck = new ArrayList<>(chunkMsgIds.length);\n                 for (MessageIdImpl cMsgId : chunkMsgIds) {\n                     if (cMsgId != null && chunkMsgIds.length > 1) {\n                         entriesToAck.add(Triple.of(cMsgId.getLedgerId(), cMsgId.getEntryId(), null));\n                     }\n                 }\n-                ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck);\n-                if (flush) {\n-                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                if (ackResponseEnabled) {\n+                    long requestId = consumer.getClient().newRequestId();\n+                    ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck, requestId);\n+                    completableFuture = cnx.newAckForResponse(cmd, requestId);\n                 } else {\n-                    cnx.ctx().write(cmd, cnx.ctx().voidPromise());\n+                    ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck, -1);\n+                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                    completableFuture = CompletableFuture.completedFuture(null);\n                 }\n             } else {\n+                // if don't support multi message ack, it also support ack response, so we should not think about the\n+                // ack response in this logic", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzgzOTAzMQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557839031", "bodyText": "this is the chunk message, so if want to use ack response, broker must support multi message ack, we don't need to support broker don't support multi message ack and then we return ack response.", "author": "congbobo184", "createdAt": "2021-01-15T03:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyNTE3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyNjQyMQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557326421", "bodyText": "I think we can use a method getRequestId() and a method getCompletableFuture(). I think this will make the logic simpler", "author": "codelipenghui", "createdAt": "2021-01-14T11:26:06Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -497,46 +586,84 @@ public void close() {\n         }\n     }\n \n-    private void newAckCommand(long consumerId, MessageIdImpl msgId, BitSetRecyclable lastCumulativeAckSet,\n-            AckType ackType, ValidationError validationError, Map<String, Long> map, ClientCnx cnx,\n-                               boolean flush, long txnidMostBits, long txnidLeastBits) {\n-\n-        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.get(msgId);\n-        if (chunkMsgIds != null && txnidLeastBits < 0 && txnidMostBits < 0) {\n-            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())\n-                    && ackType != AckType.Cumulative) {\n+    private CompletableFuture<Void> newImmediateAckAndFlush(long consumerId, MessageIdImpl msgId,\n+                                                            BitSetRecyclable bitSet, AckType ackType,\n+                                                            Map<String, Long> map, ClientCnx cnx) {\n+        MessageIdImpl[] chunkMsgIds = this.consumer.unAckedChunkedMessageIdSequenceMap.remove(msgId);\n+        final CompletableFuture<Void> completableFuture;\n+        // cumulative ack chunk by the last messageId\n+        if (chunkMsgIds != null &&  ackType != AckType.Cumulative) {\n+            if (Commands.peerSupportsMultiMessageAcknowledgment(cnx.getRemoteEndpointProtocolVersion())) {\n                 List<Triple<Long, Long, ConcurrentBitSetRecyclable>> entriesToAck = new ArrayList<>(chunkMsgIds.length);\n                 for (MessageIdImpl cMsgId : chunkMsgIds) {\n                     if (cMsgId != null && chunkMsgIds.length > 1) {\n                         entriesToAck.add(Triple.of(cMsgId.getLedgerId(), cMsgId.getEntryId(), null));\n                     }\n                 }\n-                ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck);\n-                if (flush) {\n-                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                if (ackResponseEnabled) {\n+                    long requestId = consumer.getClient().newRequestId();\n+                    ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck, requestId);\n+                    completableFuture = cnx.newAckForResponse(cmd, requestId);\n                 } else {\n-                    cnx.ctx().write(cmd, cnx.ctx().voidPromise());\n+                    ByteBuf cmd = Commands.newMultiMessageAck(consumer.consumerId, entriesToAck, -1);\n+                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                    completableFuture = CompletableFuture.completedFuture(null);\n                 }\n             } else {\n+                // if don't support multi message ack, it also support ack response, so we should not think about the\n+                // ack response in this logic\n                 for (MessageIdImpl cMsgId : chunkMsgIds) {\n                     ByteBuf cmd = Commands.newAck(consumerId, cMsgId.getLedgerId(), cMsgId.getEntryId(),\n-                            lastCumulativeAckSet, ackType, validationError, map);\n-                    if (flush) {\n-                        cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n-                    } else {\n-                        cnx.ctx().write(cmd, cnx.ctx().voidPromise());\n-                    }\n+                            bitSet, ackType, null, map, -1);\n+                    cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n                 }\n+                completableFuture = CompletableFuture.completedFuture(null);\n             }\n-            this.consumer.unAckedChunkedMessageIdSequenceMap.remove(msgId);\n         } else {\n-            ByteBuf cmd = Commands.newAck(consumerId, msgId.getLedgerId(), msgId.getEntryId(), lastCumulativeAckSet,\n-                    ackType, validationError, map, txnidLeastBits, txnidMostBits, -1);\n-            if (flush) {\n-                cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+            if (ackResponseEnabled) {\n+                long requestId = consumer.getClient().newRequestId();\n+                ByteBuf cmd = Commands.newAck(consumerId, msgId.getLedgerId(), msgId.getEntryId(), bitSet,\n+                        ackType, null, map, requestId);\n+                completableFuture = cnx.newAckForResponse(cmd, requestId);\n             } else {\n-                cnx.ctx().write(cmd, cnx.ctx().voidPromise());\n+                ByteBuf cmd = Commands.newAck(consumerId, msgId.getLedgerId(), msgId.getEntryId(), bitSet,\n+                        ackType, null, map, -1);\n+                cnx.ctx().writeAndFlush(cmd, cnx.ctx().voidPromise());\n+                completableFuture = CompletableFuture.completedFuture(null);\n+            }\n+        }\n+        return completableFuture;", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyOTg0NA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557329844", "bodyText": "Do we need to return the future again?", "author": "codelipenghui", "createdAt": "2021-01-14T11:32:33Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/ClientCnx.java", "diffHunk": "@@ -816,25 +833,35 @@ SocketAddress serverAddrees() {\n     }\n \n     CompletableFuture<ProducerResponse> sendRequestWithId(ByteBuf cmd, long requestId) {\n-        return sendRequestAndHandleTimeout(cmd, requestId, RequestType.Command);\n+        return sendRequestAndHandleTimeout(cmd, requestId, RequestType.Command, true,\n+                new TimedCompletableFuture<>());\n     }\n \n-    private <T> CompletableFuture<T> sendRequestAndHandleTimeout(ByteBuf requestMessage, long requestId, RequestType requestType) {\n-        TimedCompletableFuture<T> future = new TimedCompletableFuture<>();\n+    private <T> CompletableFuture<T> sendRequestAndHandleTimeout(ByteBuf requestMessage, long requestId,\n+                                                                 RequestType requestType, boolean flush,\n+                                                                 TimedCompletableFuture<T> future) {", "originalCommit": "bfe770b51963bf882ef7ed6a11baf2bbbd598de4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMzMTk3NQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r557331975", "bodyText": "I think you can use 2 methods to handle this case\nprivate <T> void sendRequestAndHandleTimeout(ByteBuf requestMessage, long requestId,\n                                                                 RequestType requestType, boolean flush,\n                                                                 TimedCompletableFuture<T> future) {\n\n}\n\nprivate <T> CompletableFuture<T> sendRequestAndHandleTimeout(ByteBuf requestMessage, long requestId, RequestType requestType, boolean flush) {\n       TimedCompletableFuture<T> future = new TimedCompletableFuture<>();\n        sendRequestAndHandleTimeout(... future);\n        return future;\n}", "author": "codelipenghui", "createdAt": "2021-01-14T11:36:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzMyOTg0NA=="}], "type": "inlineReview"}, {"oid": "b2ddce84e1f580d3aa76fb20bf1942b2aa46f615", "url": "https://github.com/apache/pulsar/commit/b2ddce84e1f580d3aa76fb20bf1942b2aa46f615", "message": "Fix some comments", "committedDate": "2021-01-15T06:24:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NTkwNg==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549275906", "bodyText": "do we have to wait for this operation to complete ?", "author": "eolivelli", "createdAt": "2020-12-28T09:21:41Z", "path": "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java", "diffHunk": "@@ -1079,7 +1092,7 @@ public void testDeactivatingBacklogConsumer() throws Exception {\n         // 3. Consume messages: at Faster subscriber\n         for (int i = 0; i < totalMsgs; i++) {\n             msg = subscriber1.receive(100, TimeUnit.MILLISECONDS);\n-            subscriber1.acknowledge(msg);\n+            subscriber1.acknowledgeAsync(msg);", "originalCommit": "fe2540029e1628c5a93b158e9c9ef9baedf14b58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1MDExNw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r558250117", "bodyText": "it won't influence the result, if wait it the test will spend a lot of time when enable the ack response.", "author": "congbobo184", "createdAt": "2021-01-15T11:36:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NTkwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NTk0Mw==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549275943", "bodyText": "do we have to wait for this operation to complete ?", "author": "eolivelli", "createdAt": "2020-12-28T09:21:48Z", "path": "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java", "diffHunk": "@@ -1098,7 +1111,7 @@ public void testDeactivatingBacklogConsumer() throws Exception {\n         // 6. consume messages : at slower subscriber\n         for (int i = 0; i < totalMsgs; i++) {\n             msg = subscriber2.receive(100, TimeUnit.MILLISECONDS);\n-            subscriber2.acknowledge(msg);\n+            subscriber2.acknowledgeAsync(msg);", "originalCommit": "fe2540029e1628c5a93b158e9c9ef9baedf14b58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1MDMyNA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r558250324", "bodyText": "it won't influence the result, if wait it the test will spend a lot of time when enable the ack response.", "author": "congbobo184", "createdAt": "2021-01-15T11:36:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NTk0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NjAwMQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549276001", "bodyText": "do we have to wait for this operation to complete and check the result ?", "author": "eolivelli", "createdAt": "2020-12-28T09:22:03Z", "path": "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java", "diffHunk": "@@ -1397,13 +1412,7 @@ public void testConsumerBlockingWithUnAckedMessages() throws Exception {\n             assertEquals(messages.size(), unAckedMessagesBufferSize);\n \n             // start acknowledging messages\n-            messages.forEach(m -> {\n-                try {\n-                    consumer.acknowledge(m);\n-                } catch (PulsarClientException e) {\n-                    fail(\"ack failed\", e);\n-                }\n-            });\n+            messages.forEach(consumer::acknowledgeAsync);", "originalCommit": "fe2540029e1628c5a93b158e9c9ef9baedf14b58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1MTIzMA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r558251230", "bodyText": "it won't influence the result, if wait it the test will spend a lot of time when enable the ack response.", "author": "congbobo184", "createdAt": "2021-01-15T11:38:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NjAwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NjA2MA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r549276060", "bodyText": "do we have to wait for this operation to complete ?", "author": "eolivelli", "createdAt": "2020-12-28T09:22:13Z", "path": "pulsar-broker/src/test/java/org/apache/pulsar/client/api/SimpleProducerConsumerTest.java", "diffHunk": "@@ -1802,7 +1816,7 @@ public void testUnackedBlockAtBatch(int batchMessageDelayMs) throws Exception {\n                 if (msg != null) {\n                     messages.add(msg);\n                     totalReceiveMessages++;\n-                    consumer1.acknowledge(msg);\n+                    consumer1.acknowledgeAsync(msg);", "originalCommit": "fe2540029e1628c5a93b158e9c9ef9baedf14b58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1MTUwMA==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r558251500", "bodyText": "it won't influence the result, if wait it the test will spend a lot of time when enable the ack response.", "author": "congbobo184", "createdAt": "2021-01-15T11:38:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3NjA2MA=="}], "type": "inlineReview"}, {"oid": "81add2440a4766ac3729adaf4f4019507324313d", "url": "https://github.com/apache/pulsar/commit/81add2440a4766ac3729adaf4f4019507324313d", "message": "Merge branch 'master' into congbobo184_ack_response_implementation", "committedDate": "2021-01-15T10:06:38Z", "type": "commit"}, {"oid": "ce181eba0c3cd9e6dcf221949b2fe81927baabe1", "url": "https://github.com/apache/pulsar/commit/ce181eba0c3cd9e6dcf221949b2fe81927baabe1", "message": "Fix some comment", "committedDate": "2021-01-15T11:57:27Z", "type": "commit"}, {"oid": "a363d271971ff2568d524d7d583e296126eec226", "url": "https://github.com/apache/pulsar/commit/a363d271971ff2568d524d7d583e296126eec226", "message": "Merge branch 'master' into congbobo184_ack_response_implementation", "committedDate": "2021-01-18T03:06:36Z", "type": "commit"}, {"oid": "89d6a06124d66395779e2e2ae6c26f438e0bc373", "url": "https://github.com/apache/pulsar/commit/89d6a06124d66395779e2e2ae6c26f438e0bc373", "message": "merge master", "committedDate": "2021-01-18T03:08:36Z", "type": "commit"}, {"oid": "19cf876e16ae872260d65511db28cc63a101a128", "url": "https://github.com/apache/pulsar/commit/19cf876e16ae872260d65511db28cc63a101a128", "message": "Revert \"merge master\"\n\nThis reverts commit 89d6a06124d66395779e2e2ae6c26f438e0bc373.", "committedDate": "2021-01-18T03:09:11Z", "type": "commit"}, {"oid": "b4931bdc3d0916b82924e94eaed196b20188a2ec", "url": "https://github.com/apache/pulsar/commit/b4931bdc3d0916b82924e94eaed196b20188a2ec", "message": "Merge branch 'master' into congbobo184_ack_response_implementation", "committedDate": "2021-01-18T15:10:24Z", "type": "commit"}, {"oid": "5a259bb39c0e52b1c646d944e7f46ff5b451db86", "url": "https://github.com/apache/pulsar/commit/5a259bb39c0e52b1c646d944e7f46ff5b451db86", "message": "Change the log location and change ack response to ack receipt.", "committedDate": "2021-01-19T10:29:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDI3MTM2OQ==", "url": "https://github.com/apache/pulsar/pull/8996#discussion_r560271369", "bodyText": "It's better to use a method isAckReceiptEnabled() to check if the consumer enabled the ack receipt and the broker support the ack receipt.", "author": "codelipenghui", "createdAt": "2021-01-19T15:39:10Z", "path": "pulsar-client/src/main/java/org/apache/pulsar/client/impl/PersistentAcknowledgmentsGroupingTracker.java", "diffHunk": "@@ -115,186 +123,302 @@ public boolean isDuplicate(MessageId messageId) {\n     }\n \n     @Override\n-    public void addListAcknowledgment(List<MessageIdImpl> messageIds, AckType ackType, Map<String, Long> properties) {\n-        if (ackType == AckType.Cumulative) {\n-            messageIds.forEach(messageId -> doCumulativeAck(messageId, null));\n-            return;\n+    public CompletableFuture<Void> addListAcknowledgment(List<MessageId> messageIds,\n+                                                         AckType ackType, Map<String, Long> properties) {\n+        if (AckType.Cumulative.equals(ackType)) {\n+            if (ackReceiptEnabled) {\n+                Set<CompletableFuture<Void>> completableFutureSet = new HashSet<>();\n+                messageIds.forEach(messageId ->\n+                        completableFutureSet.add(addAcknowledgment((MessageIdImpl) messageId, ackType, properties)));\n+                return FutureUtil.waitForAll(new ArrayList<>(completableFutureSet));\n+            } else {\n+                messageIds.forEach(messageId -> addAcknowledgment((MessageIdImpl) messageId, ackType, properties));\n+                return CompletableFuture.completedFuture(null);\n+            }\n+        } else {\n+            if (ackReceiptEnabled) {\n+                try {\n+                    // when flush the ack, we should bind the this ack in the currentFuture, during this time we can't\n+                    // change currentFuture. but we can lock by the read lock, because the currentFuture is not change\n+                    // any ack operation is allowed.\n+                    this.lock.readLock().lock();\n+                    addListAcknowledgment(messageIds);\n+                    return this.currentIndividualAckFuture;\n+                } finally {\n+                    this.lock.readLock().unlock();\n+                    if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                        flush();\n+                    }\n+                }\n+            } else {\n+                addListAcknowledgment(messageIds);\n+                if (acknowledgementGroupTimeMicros == 0 || pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n+                    flush();\n+                }\n+                return CompletableFuture.completedFuture(null);\n+            }\n         }\n-        messageIds.forEach(messageId -> {\n+    }\n+\n+    private void addListAcknowledgment(List<MessageId> messageIds) {\n+        for (MessageId messageId : messageIds) {\n+            consumer.onAcknowledge(messageId, null);\n             if (messageId instanceof BatchMessageIdImpl) {\n                 BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) messageId;\n-                pendingIndividualAcks.add(new MessageIdImpl(batchMessageId.getLedgerId(),\n-                        batchMessageId.getEntryId(), batchMessageId.getPartitionIndex()));\n+                if (!batchMessageId.ackIndividual()) {\n+                    doIndividualBatchAckAsync((BatchMessageIdImpl) messageId);\n+                } else {\n+                    messageId = modifyBatchMessageIdAndStatesInConsumer(batchMessageId);\n+                    doIndividualAckAsync((MessageIdImpl) messageId);\n+                }\n             } else {\n-                pendingIndividualAcks.add(messageId);\n-            }\n-            pendingIndividualBatchIndexAcks.remove(messageId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+                modifyMessageIdStatesInConsumer((MessageIdImpl) messageId);\n+                doIndividualAckAsync((MessageIdImpl) messageId);\n             }\n-        });\n-        if (acknowledgementGroupTimeMicros == 0) {\n-            flush();\n         }\n     }\n \n     @Override\n-    public void addAcknowledgment(MessageIdImpl msgId, AckType ackType, Map<String, Long> properties,\n-                                  TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty() ||\n-                (txn != null && ackType == AckType.Cumulative)) {\n-                if (msgId instanceof BatchMessageIdImpl && txn != null) {\n-                    BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n-                    doImmediateBatchIndexAck(batchMessageId, batchMessageId.getBatchIndex(),\n-                            batchMessageId.getBatchIndex(),\n-                            ackType, properties, txn.getTxnIdMostBits(), txn.getTxnIdLeastBits());\n-                    return;\n+    public CompletableFuture<Void> addAcknowledgment(MessageIdImpl msgId, AckType ackType,\n+                                                     Map<String, Long> properties) {\n+        if (msgId instanceof BatchMessageIdImpl) {\n+            BatchMessageIdImpl batchMessageId = (BatchMessageIdImpl) msgId;\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                // ack this ack carry bitSet index and judge bit set are all ack\n+                if (batchMessageId.ackIndividual()) {\n+                    MessageIdImpl messageId = modifyBatchMessageIdAndStatesInConsumer(batchMessageId);\n+                    return doIndividualAck(messageId, properties);\n+                } else if (batchIndexAckEnabled){\n+                    return doIndividualBatchAck(batchMessageId, properties);\n+                } else {\n+                    // if we prevent batchIndexAck, we can't send the ack command to broker when the batch message are\n+                    // all ack complete\n+                    return CompletableFuture.completedFuture(null);\n                 }\n-            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n-            // uncommon condition since it's only used for the compaction subscription.\n-            doImmediateAck(msgId, ackType, properties, txn);\n-        } else if (ackType == AckType.Cumulative) {\n-            doCumulativeAck(msgId, null);\n-        } else {\n-            // Individual ack\n-            if (msgId instanceof BatchMessageIdImpl) {\n-                pendingIndividualAcks.add(new MessageIdImpl(msgId.getLedgerId(),\n-                        msgId.getEntryId(), msgId.getPartitionIndex()));\n             } else {\n-                if (txn != null) {\n-                    pendingIndividualTransactionAcks\n-                            .add(Triple.of(txn.getTxnIdMostBits(), txn.getTxnIdLeastBits(), msgId));\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                if (batchMessageId.ackCumulative()) {\n+                    return doCumulativeAck(msgId, properties, null);\n                 } else {\n-                    pendingIndividualAcks.add(msgId);\n+                    if (batchIndexAckEnabled) {\n+                        return doCumulativeBatchIndexAck(batchMessageId, properties);\n+                    } else {\n+                        // ack the pre messageId, because we prevent the batchIndexAck, we can ensure pre messageId can\n+                        // ack\n+                        if (AckType.Cumulative == ackType\n+                                && !batchMessageId.getAcker().isPrevBatchCumulativelyAcked()) {\n+                            doCumulativeAck(batchMessageId.prevBatchMessageId(), properties, null);\n+                            batchMessageId.getAcker().setPrevBatchCumulativelyAcked(true);\n+                        }\n+                        return CompletableFuture.completedFuture(null);\n+                    }\n                 }\n             }\n-            pendingIndividualBatchIndexAcks.remove(msgId);\n-            if (pendingIndividualAcks.size() >= MAX_ACK_GROUP_SIZE) {\n-                flush();\n+        } else {\n+            if (ackType == AckType.Individual) {\n+                consumer.onAcknowledge(msgId, null);\n+                modifyMessageIdStatesInConsumer(msgId);\n+                return doIndividualAck(msgId, properties);\n+            } else {\n+                consumer.onAcknowledgeCumulative(msgId, null);\n+                return doCumulativeAck(msgId, properties, null);\n             }\n         }\n     }\n \n-    public void addBatchIndexAcknowledgment(BatchMessageIdImpl msgId, int batchIndex, int batchSize, AckType ackType,\n-                                            Map<String, Long> properties, TransactionImpl txn) {\n-        if (acknowledgementGroupTimeMicros == 0 || !properties.isEmpty()) {\n-            doImmediateBatchIndexAck(msgId, batchIndex, batchSize, ackType, properties,\n-                    txn == null ? -1 : txn.getTxnIdMostBits(),\n-                    txn == null ? -1 : txn.getTxnIdLeastBits());\n-        } else if (ackType == AckType.Cumulative) {\n-            BitSetRecyclable bitSet = BitSetRecyclable.create();\n-            bitSet.set(0, batchSize);\n-            bitSet.clear(0, batchIndex + 1);\n-            doCumulativeAck(msgId, bitSet);\n-        } else if (ackType == AckType.Individual) {\n-            ConcurrentBitSetRecyclable bitSet;\n-            if (txn != null) {\n-                synchronized (txn) {\n-                    ConcurrentHashMap<MessageIdImpl, ConcurrentBitSetRecyclable> transactionIndividualBatchIndexAcks =\n-                            pendingIndividualTransactionBatchIndexAcks\n-                                    .computeIfAbsent(txn, (v) -> new ConcurrentHashMap<>());\n-                    bitSet = transactionIndividualBatchIndexAcks.computeIfAbsent(msgId, (v) -> {\n-                        ConcurrentBitSetRecyclable value;\n-                        value = ConcurrentBitSetRecyclable.create();\n-                        value.set(0, msgId.getAcker().getBatchSize());\n-                        return value;\n-                    });\n-                    bitSet.clear(batchIndex);\n+    private MessageIdImpl modifyBatchMessageIdAndStatesInConsumer(BatchMessageIdImpl batchMessageId) {\n+        MessageIdImpl messageId = new MessageIdImpl(batchMessageId.getLedgerId(),\n+                batchMessageId.getEntryId(), batchMessageId.getPartitionIndex());\n+        consumer.getStats().incrementNumAcksSent(batchMessageId.getBatchSize());\n+        clearMessageIdFromUnAckTrackerAndDeadLetter(messageId);\n+        return messageId;\n+    }\n+\n+    private void modifyMessageIdStatesInConsumer(MessageIdImpl messageId) {\n+        consumer.getStats().incrementNumAcksSent(1);\n+        clearMessageIdFromUnAckTrackerAndDeadLetter(messageId);\n+    }\n+\n+    private void clearMessageIdFromUnAckTrackerAndDeadLetter(MessageIdImpl messageId) {\n+        consumer.getUnAckedMessageTracker().remove(messageId);\n+        if (consumer.getPossibleSendToDeadLetterTopicMessages() != null) {\n+            consumer.getPossibleSendToDeadLetterTopicMessages().remove(messageId);\n+        }\n+    }\n+\n+    private CompletableFuture<Void> doIndividualAck(MessageIdImpl messageId, Map<String, Long> properties) {\n+        if (acknowledgementGroupTimeMicros == 0 || (properties != null && !properties.isEmpty())) {\n+            // We cannot group acks if the delay is 0 or when there are properties attached to it. Fortunately that's an\n+            // uncommon condition since it's only used for the compaction subscription.\n+            return doImmediateAck(messageId, AckType.Individual, properties, null);\n+        } else {\n+            if (ackReceiptEnabled) {", "originalCommit": "5a259bb39c0e52b1c646d944e7f46ff5b451db86", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "82d5b7989606d38387c201029f7c478ffd6f97b2", "url": "https://github.com/apache/pulsar/commit/82d5b7989606d38387c201029f7c478ffd6f97b2", "message": "Fix some comment", "committedDate": "2021-01-20T03:08:32Z", "type": "commit"}, {"oid": "cc410adeb3c1a588e798ab63ffe0aad5c49e89f7", "url": "https://github.com/apache/pulsar/commit/cc410adeb3c1a588e798ab63ffe0aad5c49e89f7", "message": "Fix the test", "committedDate": "2021-01-20T09:40:38Z", "type": "commit"}]}