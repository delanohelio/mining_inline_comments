{"pr_number": 4830, "pr_title": "DHFPROD-6217:Catch and log error if updating job doc fails", "pr_createdAt": "2020-11-06T02:18:11Z", "pr_url": "https://github.com/marklogic/marklogic-data-hub/pull/4830", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNTQ1Ng==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r518715456", "bodyText": "Is the \"or\" check here only because it will be \"started\" on ML 9? If so, this should first do a check of the ML version to see if it's ML 9, and use that to determine what the expected status should be. Same goes for the other \"or\" checks below.", "author": "rjrudin", "createdAt": "2020-11-06T12:18:10Z", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +32,10 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+        assertTrue(getJobDocumentStatus().equals(\"canceled\") ||", "originalCommit": "226a58faae3b89683686ab692f923c2ef47938e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTU5MjYwNA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r519592604", "bodyText": "The failures are not consistent in 9.0-x. In WriteJobWithCustomEndpointsTest , whenever custom endpoint is used to initialize write , we are able to update the job document (regardless of whether custom endpoint is used to finalize write or not).\nIf default endpoints are used, we can create job doc but are not able to update it.", "author": "srinathgit", "createdAt": "2020-11-09T07:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNTQ1Ng=="}], "type": "inlineReview"}, {"oid": "1db7ce1868d43097fcf1aa744d37e1a34b202001", "url": "https://github.com/marklogic/marklogic-data-hub/commit/1db7ce1868d43097fcf1aa744d37e1a34b202001", "message": "DHFPROD-6217:Catch and log error if updating job doc fails", "committedDate": "2020-11-09T18:14:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzODcyMw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520038723", "bodyText": "Do we know why this is not working on 9.0-x? Is it something about amps and SJS functions? Whatever the reason is, it should be part of the assertion message.", "author": "rjrudin", "createdAt": "2020-11-09T18:49:16Z", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/HandleAbortedWriterTest.java", "diffHunk": "@@ -31,8 +31,14 @@ void dataSourceWriterIsAborted() {\n         assertEquals(2, getFruitCount(), \"Just verifying the two fruits were written\");\n \n         dataSourceWriter.abort(null);\n-        assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n-            \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n-            \"But that is a limitation of the JobStatus class in DHF.\");\n+        if(canUpdateJobDoc()){\n+            assertEquals(\"canceled\", getJobDocumentStatus(), \"If the DataSourceWriter is aborted for any reason, the job \" +\n+                \"document should have a status of 'canceled'. Note that this does not imply whether any writes failed. \" +\n+                \"But that is a limitation of the JobStatus class in DHF.\");\n+        }\n+        else{\n+            assertEquals(\"started\", getJobDocumentStatus(), \"In case of 9.0-x server, status will remain 'started'\");", "originalCommit": "1db7ce1868d43097fcf1aa744d37e1a34b202001", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MzU0MA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520043540", "bodyText": "Actually, this can become a new protected method in AbstractSparkConnectorTest - verifyJobDocumentWasNotUpdated(). Then you can reuse it across tests.", "author": "rjrudin", "createdAt": "2020-11-09T18:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDAzODcyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA0MjkxMg==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4830#discussion_r520042912", "bodyText": "Just to avoid duplication, toss this into a new private method - e.g verifyStatusIsStopOnError.", "author": "rjrudin", "createdAt": "2020-11-09T18:56:03Z", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/writer/WriteJobWithCustomEndpointsTest.java", "diffHunk": "@@ -38,7 +38,10 @@ void bothEndpointsAreCustom() {\n \n         verifyCustomInitializeEndpointIsUsed();\n         dataSourceWriter.commit(null);\n-        verifyCustomFinalizeEndpointIsUsed();\n+        assertEquals(\"stop-on-error\", getJobDocumentStatus(),", "originalCommit": "1db7ce1868d43097fcf1aa744d37e1a34b202001", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5a61d7d4c64b313d2d8a379d1b560d4c8fe0ad79", "url": "https://github.com/marklogic/marklogic-data-hub/commit/5a61d7d4c64b313d2d8a379d1b560d4c8fe0ad79", "message": "DHFPROD-6217:Catch and log error if updating job doc fails", "committedDate": "2020-11-09T20:07:59Z", "type": "commit"}, {"oid": "5a61d7d4c64b313d2d8a379d1b560d4c8fe0ad79", "url": "https://github.com/marklogic/marklogic-data-hub/commit/5a61d7d4c64b313d2d8a379d1b560d4c8fe0ad79", "message": "DHFPROD-6217:Catch and log error if updating job doc fails", "committedDate": "2020-11-09T20:07:59Z", "type": "forcePushed"}]}