{"pr_number": 4590, "pr_title": "DHFPROD-5943: Renaming the connector to Spark Connector", "pr_createdAt": "2020-09-18T03:05:35Z", "pr_url": "https://github.com/marklogic/marklogic-data-hub/pull/4590", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700385", "bodyText": "HubDataSource should be inside the writer folder because it implements WriteSupport. It cannot be used as a generic class. For Reader we will have to create a new class that implements ReadSupport.", "author": "anu3990", "createdAt": "2020-09-18T04:50:32Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+", "originalCommit": "ae3f7455276434566bd5c19730d797a8b2424720", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjI1Nw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896257", "bodyText": "I am thinking that since WriteSupport is in the \"v2\" package and not \"v2.writer\", we'll eventually have this implement ReadSupport as well. Here's an example of that - https://www.bugdbug.com/post/speed-up-apache-spark-operations-using-a-custom-data-source .\nI think that makes sense conceptually - we have a single DataSource which supports Read and Write. That makes life easier for Ernie, who only has to worry about one DataSource class now.", "author": "rjrudin", "createdAt": "2020-09-18T11:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDM4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDcwMDg3MQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490700871", "bodyText": "I am not sure if we can have MarkLogicWriter as an inner class. Is this setup working.?", "author": "anu3990", "createdAt": "2020-09-18T04:52:29Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,17 +13,33 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating MarkLogicWriter\");\n+        return Optional.of(new MarkLogicWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class MarkLogicWriter implements DataSourceWriter {", "originalCommit": "ae3f7455276434566bd5c19730d797a8b2424720", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "86967777922c0430d61346b375632e3cbeda918f", "url": "https://github.com/marklogic/marklogic-data-hub/commit/86967777922c0430d61346b375632e3cbeda918f", "message": "DHFPROD-5943: Renaming the connector to Spark Connector", "committedDate": "2020-09-18T05:28:55Z", "type": "forcePushed"}, {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "url": "https://github.com/marklogic/marklogic-data-hub/commit/4311eacc520a56edf1ca39c778b7e59f309e4cd4", "message": "DHFPROD-5943: Renaming the connector to Spark Connector", "committedDate": "2020-09-18T05:37:42Z", "type": "commit"}, {"oid": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "url": "https://github.com/marklogic/marklogic-data-hub/commit/4311eacc520a56edf1ca39c778b7e59f309e4cd4", "message": "DHFPROD-5943: Renaming the connector to Spark Connector", "committedDate": "2020-09-18T05:37:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NjY5Ng==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490896696", "bodyText": "I believe you can remove the empty braces here.", "author": "rjrudin", "createdAt": "2020-09-18T11:51:32Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){", "originalCommit": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg5NzA5MQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4590#discussion_r490897091", "bodyText": "I like this approach of tossing this class in here as a non-public one. I think we'll want to do that for HubDataSourceReader too in the future.", "author": "rjrudin", "createdAt": "2020-09-18T11:52:24Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/HubDataSource.java", "diffHunk": "@@ -13,26 +13,42 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package com.marklogic.hub.cloud.aws.glue.Writer;\n+package com.marklogic.hub.spark.sql.sources.v2;\n \n+import com.marklogic.client.ext.helper.LoggingObject;\n+import com.marklogic.hub.spark.sql.sources.v2.writer.HubDataWriterFactory;\n+import org.apache.spark.sql.SaveMode;\n import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.sources.v2.DataSourceOptions;\n+import org.apache.spark.sql.sources.v2.WriteSupport;\n import org.apache.spark.sql.sources.v2.writer.DataSourceWriter;\n import org.apache.spark.sql.sources.v2.writer.DataWriterFactory;\n import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;\n import org.apache.spark.sql.types.StructType;\n \n import java.util.Map;\n+import java.util.Optional;\n \n-public class MarkLogicWriter implements DataSourceWriter {\n+public class HubDataSource extends LoggingObject implements WriteSupport {\n+\n+    @Override\n+    public Optional<DataSourceWriter> createWriter(String writeUUID, StructType schema, SaveMode mode, DataSourceOptions options) {\n+        logger.info(\"Creating HubDataSourceWriter\");\n+        return Optional.of(new HubDataSourceWriter(options.asMap(), schema){\n+\n+        });\n+    }\n+}\n+class HubDataSourceWriter implements DataSourceWriter {", "originalCommit": "4311eacc520a56edf1ca39c778b7e59f309e4cd4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}