{"pr_number": 3536, "pr_title": "[CAMEL-14468] Add support for classification in camel-weka", "pr_createdAt": "2020-01-31T13:11:58Z", "pr_url": "https://github.com/apache/camel/pull/3536", "timeline": [{"oid": "1f355bf25b7d9503f97656a452af86a3cd3b3b03", "url": "https://github.com/apache/camel/commit/1f355bf25b7d9503f97656a452af86a3cd3b3b03", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-01-31T13:14:38Z", "type": "forcePushed"}, {"oid": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "url": "https://github.com/apache/camel/commit/d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-01-31T14:07:10Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzgyMg==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763822", "bodyText": "No ?option in syntax. And label should be a single word, datamining or something as a category label.", "author": "davsclaus", "createdAt": "2020-02-01T07:17:43Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -16,22 +16,46 @@\n  */\n package org.apache.camel.component.weka;\n \n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.io.OutputStreamWriter;\n+import java.net.URL;\n+import java.nio.file.Paths;\n+\n import org.apache.camel.Consumer;\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Message;\n import org.apache.camel.Processor;\n import org.apache.camel.Producer;\n+import org.apache.camel.component.file.GenericFile;\n import org.apache.camel.spi.UriEndpoint;\n import org.apache.camel.spi.UriParam;\n import org.apache.camel.support.DefaultEndpoint;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import io.nessus.weka.AssertState;\n+import io.nessus.weka.Dataset;\n+import io.nessus.weka.ModelLoader;\n+import io.nessus.weka.ModelPersister;\n+import io.nessus.weka.UncheckedException;\n+import weka.classifiers.Classifier;\n+import weka.classifiers.Evaluation;\n+import weka.core.Instances;\n import weka.core.Version;\n+import weka.core.converters.ArffLoader;\n+import weka.core.converters.CSVLoader;\n+import weka.core.converters.Loader;\n \n /**\n  * The camel-weka component provides Data Mining functionality through Weka.\n  */\n-@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\",\n-        syntax = \"weka:cmd?options\", producerOnly = true, label = \"data mining\")\n+@UriEndpoint(firstVersion = \"3.1.0\", scheme = \"weka\", title = \"Weka\", syntax = \"weka:cmd?options\", label = \"data mining\")", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDAzMTQwNg==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374031406", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T10:41:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzgyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg1Mg==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763852", "bodyText": "Its preferred to create thread via Camel. See CamelContext ExecutorServiceStrategy which has APIs for creating threads. Also you should stop the thread in doStop.", "author": "davsclaus", "createdAt": "2020-02-01T07:18:43Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.camel.component.weka;\n+\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Processor;\n+import org.apache.camel.component.weka.WekaConfiguration.Command;\n+import org.apache.camel.support.DefaultConsumer;\n+\n+import io.nessus.weka.Dataset;\n+\n+public class WekaConsumer extends DefaultConsumer {\n+\n+    public WekaConsumer(WekaEndpoint endpoint, Processor processor) {\n+        super(endpoint, processor);\n+    }\n+\n+    @Override\n+    public WekaEndpoint getEndpoint() {\n+        return (WekaEndpoint)super.getEndpoint();\n+    }\n+\n+    public WekaConfiguration getConfiguration() {\n+        return getEndpoint().getConfiguration();\n+    }\n+    \n+    @Override\n+    protected void doStart() throws Exception {\n+        super.doStart();\n+        \n+        Thread thread = new Thread(new Runnable() {", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg2Ng==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763866", "bodyText": "Check for invalid command in the component or the createConsumer method. Doing this here is too late.", "author": "davsclaus", "createdAt": "2020-02-01T07:19:16Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaConsumer.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.camel.component.weka;\n+\n+import org.apache.camel.Exchange;\n+import org.apache.camel.Processor;\n+import org.apache.camel.component.weka.WekaConfiguration.Command;\n+import org.apache.camel.support.DefaultConsumer;\n+\n+import io.nessus.weka.Dataset;\n+\n+public class WekaConsumer extends DefaultConsumer {\n+\n+    public WekaConsumer(WekaEndpoint endpoint, Processor processor) {\n+        super(endpoint, processor);\n+    }\n+\n+    @Override\n+    public WekaEndpoint getEndpoint() {\n+        return (WekaEndpoint)super.getEndpoint();\n+    }\n+\n+    public WekaConfiguration getConfiguration() {\n+        return getEndpoint().getConfiguration();\n+    }\n+    \n+    @Override\n+    protected void doStart() throws Exception {\n+        super.doStart();\n+        \n+        Thread thread = new Thread(new Runnable() {\n+            \n+            @Override\n+            public void run() {\n+                \n+                WekaEndpoint endpoint = getEndpoint();\n+                Exchange exchange = endpoint.createExchange();\n+                \n+                Command cmd = getConfiguration().getCommand();\n+                if (Command.read != cmd) {", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MjAzNQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374042035", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T11:04:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg3OQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763879", "bodyText": "You need to call configureConsumer too, see the other components", "author": "davsclaus", "createdAt": "2020-02-01T07:19:59Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -44,14 +68,18 @@ public WekaEndpoint(String uri, WekaComponent component, WekaConfiguration confi\n         this.configuration = config;\n     }\n \n+    public WekaConfiguration getConfiguration() {\n+        return configuration;\n+    }\n+\n     @Override\n     public WekaComponent getComponent() {\n-        return (WekaComponent)super.getComponent();\n+        return (WekaComponent) super.getComponent();\n     }\n \n     @Override\n-    public Consumer createConsumer(Processor processor) throws Exception {\n-        throw new UnsupportedOperationException();\n+    public Consumer createConsumer(Processor processor) {\n+        return new WekaConsumer(this, processor);", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MjgyNw==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374042827", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T11:06:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg5NQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763895", "bodyText": "LOG.debug", "author": "davsclaus", "createdAt": "2020-02-01T07:20:38Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzM4MQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043381", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T11:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzkyNQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763925", "bodyText": "debug logging", "author": "davsclaus", "createdAt": "2020-02-01T07:20:57Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzMyMg==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043322", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T11:07:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2MzkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzk0NQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373763945", "bodyText": "Is this needed to be logged at info level? And is this per exchange which then can get noisy", "author": "davsclaus", "createdAt": "2020-02-01T07:21:40Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0MzUwNw==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374043507", "bodyText": "Done", "author": "tdiesler", "createdAt": "2020-02-03T11:08:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2Mzk0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAwMQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764001", "bodyText": "Can the stream not leak? eg need to close it after use", "author": "davsclaus", "createdAt": "2020-02-01T07:23:09Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0NDQ5MQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374044491", "bodyText": "Well spotted, thanks.", "author": "tdiesler", "createdAt": "2020-02-03T11:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAzMQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764031", "bodyText": "Can the stream not leak? eg need to close it after use", "author": "davsclaus", "createdAt": "2020-02-01T07:23:47Z", "path": "components/camel-weka/src/main/java/org/apache/camel/component/weka/WekaEndpoint.java", "diffHunk": "@@ -64,11 +92,245 @@ public boolean isSingleton() {\n         return false;\n     }\n \n-    public WekaConfiguration getConfiguration() {\n-        return configuration;\n-    }\n-\n     String wekaVersion() {\n         return Version.VERSION;\n     }\n+\n+    Dataset handlePushCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.push(dsname);\n+        } else {\n+            dataset.push();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handlePopCmd(Exchange exchange) throws Exception {\n+        \n+        String dsname = configuration.getDsname();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        if (dsname != null) {\n+            dataset.pop(dsname);\n+        } else {\n+            dataset.pop();\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleReadCmd(Exchange exchange) throws Exception {\n+        \n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            Dataset dataset = Dataset.create(fpath);\n+            return dataset;\n+        }\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        return dataset;\n+    }\n+\n+    Object handleWriteCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        String fpath = configuration.getPath();\n+        \n+        if (fpath != null) {\n+            \n+            dataset.write(Paths.get(fpath));\n+            return dataset;\n+            \n+        } else {\n+            \n+            // The internal implementation of DataSink does this.. \n+            // Instances.toString().getBytes()\n+            //\n+            // Therefore, we avoid creating yet another copy of the\n+            // instance data and call Instances.toString() as well\n+            \n+            Instances instances = dataset.getInstances();\n+            byte[] bytes = instances.toString().getBytes();\n+            return new ByteArrayInputStream(bytes);\n+        }\n+    }\n+\n+    Dataset handleFilterCmd(Exchange exchange) throws Exception {\n+        \n+        String applyValue = configuration.getApply();\n+\n+        Dataset dataset = assertDatasetBody(exchange);\n+        dataset = dataset.apply(applyValue);\n+        \n+        return dataset;\n+    }\n+\n+    Dataset handleModelCmd(Exchange exchange) throws Exception {\n+        \n+        Dataset dataset = assertDatasetBody(exchange);\n+        \n+        String dsname = configuration.getDsname();\n+        boolean crossValidate = configuration.isXval();\n+        String buildSpec = configuration.getBuild();\n+        String loadFrom = configuration.getLoadFrom();\n+        String saveTo = configuration.getSaveTo();\n+        \n+        // Load the Model\n+        \n+        if (loadFrom != null) {\n+            \n+            Classifier cl = dataset\n+                    .loadClassifier(new ModelLoader(loadFrom))\n+                    .getClassifier();\n+            \n+            AssertState.notNull(cl, \"Cannot load the classifier from: \" + loadFrom);\n+            LOG.info(\"{}\", cl);\n+        } \n+        \n+        // Build a classifier\n+        \n+        else if (buildSpec != null) {\n+            \n+            dataset.buildClassifier(buildSpec);\n+            \n+            // Cross Validate the Model\n+            \n+            if (crossValidate) {\n+                int seed = configuration.getSeed();\n+                int folds = configuration.getFolds();\n+                dataset.crossValidateModel(folds, seed);\n+            } \n+            \n+            // Validate the Model using explicit/current instances\n+            \n+            else {\n+                \n+                // Use the named data set training\n+                if (dsname != null) {\n+                    dataset.pop(dsname);\n+                }\n+                \n+                // Train with current instances\n+                dataset.evaluateModel();\n+            }\n+            \n+            Classifier cl = dataset.getClassifier();\n+            AssertState.notNull(cl, \"Model command requires 'load' or 'apply'\");\n+            LOG.info(\"{}\", cl);\n+            \n+            Evaluation ev = dataset.getEvaluation();\n+            LOG.info(\"{}\", ev.toSummaryString());\n+        }\n+        \n+        // Save the Model\n+        \n+        if (saveTo != null) {\n+            dataset.consumeClassifier(new ModelPersister(saveTo));\n+        }\n+        \n+        return dataset;\n+    }\n+\n+    private Dataset assertDatasetBody(Exchange exchange) throws Exception {\n+        \n+        Message msg = exchange.getMessage();\n+        Object body = msg.getBody();\n+        \n+        Dataset dataset = msg.getBody(Dataset.class);\n+        \n+        if (dataset == null) {\n+            \n+            if (body instanceof Instances) {\n+\n+                dataset = Dataset.create((Instances) body);\n+                \n+            } else if (body instanceof GenericFile) {\n+                \n+                GenericFile<?> file = (GenericFile<?>) body;\n+                AssertState.isFalse(file.isDirectory(), \"Directory not supported: \" + file);\n+                String absolutePath = file.getAbsoluteFilePath();\n+                dataset = Dataset.create(absolutePath);\n+                \n+            } else if (body instanceof URL) {\n+                \n+                URL url = (URL) body;\n+                Instances instances = readInternal(url.openStream());\n+                dataset = Dataset.create(instances);\n+                \n+            } else if (body instanceof InputStream) {\n+                \n+                InputStream input = (InputStream) body;\n+                Instances instances = readInternal(input);\n+                dataset = Dataset.create(instances);\n+            }\n+        }\n+        \n+        AssertState.notNull(dataset, \"Cannot obtain dataset from body: \" + body);\n+        return dataset;\n+    }\n+\n+    // https://github.com/tdiesler/nessus-weka/issues/11\n+    private static Instances readInternal(InputStream input) {", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDA0NDcxOQ==", "url": "https://github.com/apache/camel/pull/3536#discussion_r374044719", "bodyText": "Caller resposibility", "author": "tdiesler", "createdAt": "2020-02-03T11:11:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDAzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc2NDA0Ng==", "url": "https://github.com/apache/camel/pull/3536#discussion_r373764046", "bodyText": "Add license headers for missing files.", "author": "davsclaus", "createdAt": "2020-02-01T07:24:08Z", "path": "components/camel-weka/src/test/java/org/apache/camel/component/weka/DecisionTreeTest.java", "diffHunk": "@@ -0,0 +1,124 @@\n+package org.apache.camel.component.weka;", "originalCommit": "d2aca2509cb6fcafcf0dccb627fb79f77912dcc8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "893abc6763ad60abcefe6be0ca15db7632569cb9", "url": "https://github.com/apache/camel/commit/893abc6763ad60abcefe6be0ca15db7632569cb9", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T11:26:59Z", "type": "forcePushed"}, {"oid": "6db2745bc59ee5764d0d6d2407715bc83b12615d", "url": "https://github.com/apache/camel/commit/6db2745bc59ee5764d0d6d2407715bc83b12615d", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T14:33:01Z", "type": "forcePushed"}, {"oid": "08ffe791e8def1b337df8502e921ae2dac6c4c15", "url": "https://github.com/apache/camel/commit/08ffe791e8def1b337df8502e921ae2dac6c4c15", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T14:42:25Z", "type": "forcePushed"}, {"oid": "ea08371a87657f234b9b84d9cad067dbdd3a6eba", "url": "https://github.com/apache/camel/commit/ea08371a87657f234b9b84d9cad067dbdd3a6eba", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T15:25:00Z", "type": "forcePushed"}, {"oid": "55007d4bc6cc5a2c568e0f9eb0b27ea2062460b7", "url": "https://github.com/apache/camel/commit/55007d4bc6cc5a2c568e0f9eb0b27ea2062460b7", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T15:25:51Z", "type": "commit"}, {"oid": "55007d4bc6cc5a2c568e0f9eb0b27ea2062460b7", "url": "https://github.com/apache/camel/commit/55007d4bc6cc5a2c568e0f9eb0b27ea2062460b7", "message": "[CAMEL-14468] Add support for classification in camel-weka", "committedDate": "2020-02-03T15:25:51Z", "type": "forcePushed"}]}