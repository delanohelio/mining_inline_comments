{"pr_number": 6356, "pr_title": "Collect split read and paired end evidence files for GATK-SV pipeline", "pr_createdAt": "2020-01-07T21:09:24Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6356", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1Mjg2Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365352866", "bodyText": "Could phrase it this way too: direction: side of read that is clipped (\"left\" or \"right\"). I initially found the use of left and right confusing. If we end up sticking with this data format it might make more sense to use strand labels (left = -, right = +) which also use fewer characters.", "author": "mwalker174", "createdAt": "2020-01-10T17:45:48Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzAzNzQzMg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367037432", "bodyText": "Done, I agree that it would be better to eventually convert to using +/- or some other one-character indicator in the file format.", "author": "cwhelan", "createdAt": "2020-01-15T18:30:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1Mjg2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356192", "bodyText": "When we migrated GATK4 tools, Geraldine discouraged the use of any \"non-standard\" short arguments (eg -I, -O, -R) because they are hard to interpret at a glance and could end up conflicting across different tools. I tend to agree, although the PE and SR files may become common for us. I'd suggest using -PE and -SR as those shouldn't cause any conflicts and follow the upper-case convention.", "author": "mwalker174", "createdAt": "2020-01-10T17:54:25Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjQ2Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356466", "bodyText": "Also do we have a place for defining SV arguments? I think at the very least you should have them as public constants.", "author": "mwalker174", "createdAt": "2020-01-10T17:55:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzAzOTAyNg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367039026", "bodyText": "Changed to -PE and -SR, and moved argument strings to public static constants.", "author": "cwhelan", "createdAt": "2020-01-15T18:34:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjE5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjcxNg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365356716", "bodyText": "I think this can be final", "author": "mwalker174", "createdAt": "2020-01-10T17:55:45Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MDczOA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367040738", "bodyText": "Done, and made splitPosBuffer and discordantPairs final as well by move initialization from onTraversalStart.", "author": "cwhelan", "createdAt": "2020-01-15T18:37:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODAyMw==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365358023", "bodyText": "Can you do this by overriding getDefaultReadFilters()? That way we have the option of customizing them", "author": "mwalker174", "createdAt": "2020-01-10T17:59:06Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MjI2Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367042262", "bodyText": "Done.", "author": "cwhelan", "createdAt": "2020-01-15T18:41:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODAyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQxNzA5Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365417096", "bodyText": "Adds to split read counts list the new prevClippedReadEndPos... (nothing is actually returned)", "author": "mwalker174", "createdAt": "2020-01-10T20:27:03Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzEzNA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043134", "bodyText": "Done", "author": "cwhelan", "createdAt": "2020-01-15T18:43:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQxNzA5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421833", "bodyText": "Could replace getBestAvailableSequenceDictionary () with sequenceDictionary", "author": "mwalker174", "createdAt": "2020-01-10T20:41:17Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzUzMA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043530", "bodyText": "Done", "author": "cwhelan", "createdAt": "2020-01-15T18:44:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0MzczNA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367043734", "bodyText": "Done", "author": "cwhelan", "createdAt": "2020-01-15T18:44:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTgzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTk5MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365421991", "bodyText": "Could replace samSequenceDictionary with sequenceDictionary?", "author": "mwalker174", "createdAt": "2020-01-10T20:41:47Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDgzMg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367044832", "bodyText": "This is this way for ease of testing so I might leave it as is..", "author": "cwhelan", "createdAt": "2020-01-15T18:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyMTk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyODMwMg==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365428302", "bodyText": "What's this for?", "author": "mwalker174", "createdAt": "2020-01-10T21:00:33Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =\n+                Comparator.comparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getContig()))\n+                        .thenComparing(DiscordantRead::getStart)\n+                        .thenComparing(DiscordantRead::isReadReverseStrand)\n+                        .thenComparing((DiscordantRead r) -> getBestAvailableSequenceDictionary().getSequenceIndex(r.getMateContig()))\n+                        .thenComparing(DiscordantRead::getMateStart)\n+                        .thenComparing(DiscordantRead::isMateReverseStrand);\n+\n+        discordantPairs.sort(discReadComparator);\n+        discordantPairs.forEach(this::writeDiscordantPair);\n+        discordantPairs.clear();\n+    }\n+\n+    private void writeDiscordantPair(final DiscordantRead r) {\n+        final String strandA = r.isReadReverseStrand() ? \"-\" : \"+\";\n+        final String strandB = r.isMateReverseStrand() ? \"-\" : \"+\";\n+\n+        try {\n+            // subtract 1 from positions to match pysam output\n+            peWriter.write(r.getContig() + \"\\t\" + (r.getStart() - 1) + \"\\t\" + strandA + \"\\t\" + r.getMateContig() + \"\\t\" + (r.getMateStart() - 1) + \"\\t\" + strandB + \"\\t\" + sampleName + \"\\n\");\n+        } catch (IOException e) {\n+            throw new GATKException(\"Could not write to PE file\", e);\n+        }\n+    }\n+\n+    /**\n+     * Adds read information to the counts in splitCounts.\n+     * @return the new prevClippedReadEndPos after counting this read, which is the rightmost aligned position of the read\n+     */\n+    @VisibleForTesting\n+    public void countSplitRead(final GATKRead read, final PriorityQueue<SplitPos> splitCounts, final OutputStreamWriter srWriter) {\n+        final SplitPos splitPosition = getSplitPosition(read);\n+        final int readStart = read.getStart();\n+        if (splitPosition.direction == POSITION.MIDDLE) {\n+            return;\n+        }\n+        if (currentChrom == null) {\n+            currentChrom = read.getContig();\n+        } else if (!currentChrom.equals(read.getContig())) {\n+            flushSplitCounts(splitPos -> true, srWriter, splitCounts);\n+            currentChrom = read.getContig();\n+        } else {\n+            flushSplitCounts(sp -> (sp.pos < readStart - 1), srWriter, splitCounts);\n+        }\n+\n+        splitCounts.add(splitPosition);\n+    }\n+\n+    private void flushSplitCounts(final Predicate<SplitPos> flushablePosition, final OutputStreamWriter srWriter, final PriorityQueue<SplitPos> splitCounts) {\n+\n+        while (splitCounts.size() > 0 && flushablePosition.test(splitCounts.peek())) {\n+            SplitPos pos = splitCounts.poll();\n+            int countAtPos = 1;\n+            while (splitCounts.size() > 0 && splitCounts.peek().equals(pos)) {\n+                countAtPos++;\n+                splitCounts.poll();\n+            }\n+            try {\n+                srWriter.write(currentChrom + \"\\t\" + (pos.pos - 1) + \"\\t\" + pos.direction.getDescription() + \"\\t\" + countAtPos + \"\\t\" + sampleName + \"\\n\");\n+            } catch (IOException e) {\n+                throw new GATKException(\"Could not write to sr file\", e);\n+            }\n+        }\n+    }\n+\n+    private SplitPos getSplitPosition(GATKRead read) {\n+        if (read.getCigar().getFirstCigarElement().getOperator() == CigarOperator.M) {\n+            final int matchLength = read.getCigar().getCigarElements().stream().filter(e -> e.getOperator().consumesReferenceBases()).mapToInt(CigarElement::getLength).sum();\n+            return new SplitPos(read.getStart() + matchLength, POSITION.RIGHT);\n+        } else if (read.getCigar().getLastCigarElement().getOperator() == CigarOperator.M) {\n+            return new SplitPos(read.getStart(), POSITION.LEFT);\n+        }\n+\n+        return new SplitPos(-1, POSITION.MIDDLE);\n+    }\n+\n+    private boolean isSoftClipped(final GATKRead read) {\n+        final CigarOperator firstOperator = read.getCigar().getFirstCigarElement().getOperator();\n+        final CigarOperator lastOperator = read.getCigar().getLastCigarElement().getOperator();\n+        return (firstOperator == CigarOperator.SOFT_CLIP && lastOperator != CigarOperator.SOFT_CLIP) ||\n+                (firstOperator != CigarOperator.SOFT_CLIP && lastOperator == CigarOperator.SOFT_CLIP);\n+    }\n+\n+    @Override\n+    public Object onTraversalSuccess() {\n+        flushSplitCounts(splitPos -> true, srWriter, splitPosBuffer);\n+        flushDiscordantReadPairs();\n+        return null;\n+    }\n+\n+    @Override\n+    public void closeTool() {\n+        super.closeTool();\n+        try {\n+            peWriter.close();\n+            srWriter.close();\n+        } catch (IOException e) {\n+            throw new GATKException(\"error closing output file\", e);\n+        }\n+    }\n+\n+    enum POSITION {\n+        LEFT (\"left\"),\n+        MIDDLE (\"middle\"),\n+        RIGHT (\"right\");\n+\n+        private String description;\n+\n+        POSITION(final String description) {\n+            this.description = description;\n+        }\n+\n+        public String getDescription() {\n+            return description;\n+        }", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NTU1MA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367045550", "bodyText": "Just to store the string that will actually make it into the file VS the name of the enum element. In this case it's just \"left\" vs LEFT, etc..", "author": "cwhelan", "createdAt": "2020-01-15T18:48:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQyODMwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMDg4MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365430881", "bodyText": "This is so cool", "author": "mwalker174", "createdAt": "2020-01-10T21:08:30Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollectionUnitTest.java", "diffHunk": "@@ -0,0 +1,128 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import htsjdk.samtools.SAMFileHeader;\n+import org.broadinstitute.hellbender.GATKBaseTest;\n+import org.broadinstitute.hellbender.utils.read.ArtificialReadUtils;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+import org.mockito.Mockito;\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+import java.io.OutputStreamWriter;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.PriorityQueue;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+public class PairedEndAndSplitReadEvidenceCollectionUnitTest extends GATKBaseTest {\n+\n+    @Test\n+    public void testGetReportableDiscordantReadPair() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+\n+        // read pair on different contigs\n+        final GATKRead discRPDiffContigsFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 0, 1000, 150);\n+        discRPDiffContigsFirst.setMatePosition(header.getSequence(1).getSequenceName(), 9000);\n+        final GATKRead discRPDiffContigsSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP1\", 1, 9000, 150);\n+        discRPDiffContigsSecond.setMatePosition(header.getSequence(0).getSequenceName(), 1000);\n+\n+        // read pair on same contig\n+        final GATKRead discRPSameContigFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 500, 150);\n+        discRPSameContigFirst.setMatePosition(header.getSequence(1).getSequenceName(), 5000);\n+        final GATKRead discRPSameContigSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP2\", 1, 5000, 150);\n+        discRPSameContigSecond.setMatePosition(header.getSequence(1).getSequenceName(), 500);\n+\n+        // read pair on same contig, same start position\n+        final GATKRead discRPSameContigSameStartFirst = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartFirst.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+        final GATKRead discRPSameContigSameStartSecond = ArtificialReadUtils.createArtificialRead(header, \"discRP3\", 1, 4000, 150);\n+        discRPSameContigSameStartSecond.setMatePosition(header.getSequence(1).getSequenceName(), 4000);\n+\n+        final HashSet<String> observedDiscordantNamesAtThisLocus = new HashSet<>();\n+\n+        final PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+\n+        PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNotNull(reportableDiscordantReadPair);\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPDiffContigsFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPDiffContigsSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigFirst);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartFirst, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        assertDiscordantReadInfo(reportableDiscordantReadPair, discRPSameContigSameStartFirst);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.contains(discRPSameContigSameStartFirst.getName()));\n+\n+        reportableDiscordantReadPair =\n+                tool.getReportableDiscordantReadPair(discRPSameContigSameStartSecond, observedDiscordantNamesAtThisLocus, header.getSequenceDictionary());\n+        Assert.assertNull(reportableDiscordantReadPair);\n+        Assert.assertTrue(observedDiscordantNamesAtThisLocus.isEmpty());\n+\n+    }\n+\n+    private void assertDiscordantReadInfo(final PairedEndAndSplitReadEvidenceCollection.DiscordantRead reportableDiscordantReadPair, final GATKRead gatkRead) {\n+        Assert.assertEquals(reportableDiscordantReadPair.getName(), gatkRead.getName());\n+        Assert.assertEquals(reportableDiscordantReadPair.getContig(), gatkRead.getContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getStart(), gatkRead.getStart());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateContig(), gatkRead.getMateContig());\n+        Assert.assertEquals(reportableDiscordantReadPair.getMateStart(), gatkRead.getMateStart());\n+    }\n+\n+    @Test\n+    public void testCountSplitRead() throws Exception {\n+        final SAMFileHeader header = ArtificialReadUtils.createArtificialSamHeader(2, 1, 10000);\n+        final GATKRead rightClip = ArtificialReadUtils.createArtificialRead(header, \"rightClip\", 0, 1000, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"100M51S\");\n+\n+        final OutputStreamWriter mockSrWriter = Mockito.mock(OutputStreamWriter.class);\n+\n+        PairedEndAndSplitReadEvidenceCollection tool = new PairedEndAndSplitReadEvidenceCollection();\n+        final PriorityQueue<PairedEndAndSplitReadEvidenceCollection.SplitPos> splitCounts = new PriorityQueue<>(new PairedEndAndSplitReadEvidenceCollection.SplitPosComparator());\n+        tool.sampleName = \"sample\";\n+\n+        tool.countSplitRead(rightClip, splitCounts, mockSrWriter);\n+        Map<PairedEndAndSplitReadEvidenceCollection.SplitPos, Long> counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead rightClip2 = ArtificialReadUtils.createArtificialRead(header, \"rightClip2\", 0, 1050, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"50M101S\");\n+        tool.countSplitRead(rightClip2, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClip = ArtificialReadUtils.createArtificialRead(header, \"leftClip\", 0, 1100, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClip, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)).intValue(), 2);\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verifyZeroInteractions(mockSrWriter);\n+\n+        final GATKRead leftClipDownstream = ArtificialReadUtils.createArtificialRead(header, \"leftClipDownstream\", 0, 1600, ArtificialReadUtils.createRandomReadBases(151, false),\n+                ArtificialReadUtils.createRandomReadQuals(151), \"20S131M\");\n+        tool.countSplitRead(leftClipDownstream, splitCounts, mockSrWriter);\n+        counts = splitCounts.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.RIGHT)));\n+        Assert.assertFalse(counts.containsKey(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1100, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)));\n+        Assert.assertEquals(counts.get(new PairedEndAndSplitReadEvidenceCollection.SplitPos(1600, PairedEndAndSplitReadEvidenceCollection.POSITION.LEFT)).intValue(), 1);\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"left\" + \"\\t\" + 1 + \"\\t\" + \"sample\" + \"\\n\");\n+        Mockito.verify(mockSrWriter).write(\"1\" + \"\\t\" + 1099 + \"\\t\" + \"right\" + \"\\t\" + 2 + \"\\t\" + \"sample\" + \"\\n\");", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NTcwMw==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367045703", "bodyText": "I love Mockito", "author": "cwhelan", "createdAt": "2020-01-15T18:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMDg4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMTQzNA==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r365431434", "bodyText": "Can you make a class out of this? Could be useful in the future", "author": "mwalker174", "createdAt": "2020-01-10T21:10:24Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/sv/PairedEndAndSplitReadEvidenceCollection.java", "diffHunk": "@@ -0,0 +1,434 @@\n+package org.broadinstitute.hellbender.tools.walkers.sv;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import htsjdk.samtools.CigarElement;\n+import htsjdk.samtools.CigarOperator;\n+import htsjdk.samtools.SAMSequenceDictionary;\n+import htsjdk.samtools.util.BlockCompressedOutputStream;\n+import org.broadinstitute.barclay.argparser.Argument;\n+import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;\n+import org.broadinstitute.hellbender.cmdline.programgroups.StructuralVariantDiscoveryProgramGroup;\n+import org.broadinstitute.hellbender.engine.FeatureContext;\n+import org.broadinstitute.hellbender.engine.ReadWalker;\n+import org.broadinstitute.hellbender.engine.ReferenceContext;\n+import org.broadinstitute.hellbender.exceptions.GATKException;\n+import org.broadinstitute.hellbender.exceptions.UserException;\n+import org.broadinstitute.hellbender.utils.read.GATKRead;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.function.Predicate;\n+\n+/**\n+ * Creates discordant read pair and split read evidence files for use in the GATK-SV pipeline.\n+ *\n+ * This tool emulates the functionality of the \"svtk collect-pesr\" used in v1 of the GATK-SV pipeline.\n+ * The first output file is a tab-delimited file containing information on discordant read pairs in the\n+ * input cram, with the following columns:\n+ *\n+ * <ul>\n+ *     <li>read contig</li>\n+ *     <li>read start</li>\n+ *     <li>read strand</li>\n+ *     <li>mate contig</li>\n+ *     <li>mate start</li>\n+ *     <li>mate strand</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ *\n+ * Only one record is emitted for each discordant read pair, at the read in the pair with the \"upstream\" start\n+ * position according to the sequence dictionary contig ordering and coordinate.\n+ *\n+ * The second file contains the locations of all split read clippings in the input bam or cram, with the\n+ * following columns:\n+ *\n+ * <ul>\n+ *     <li>contig</li>\n+ *     <li>clipping position</li>\n+ *     <li>direction: either LEFT or RIGHT depending on whether the reads were clipped on the left or right side</li>\n+ *     <li>count: the number of reads clipped at this location in this direction</li>\n+ *     <li>sample name</li>\n+ * </ul>\n+ */\n+@CommandLineProgramProperties(\n+        summary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline. Output files \" +\n+                \"are a file containing the location of and orientation of read pairs marked as discordant, and a \" +\n+                \"file containing the clipping location of all soft clipped reads and the orientation of the clipping.\",\n+        oneLineSummary = \"Gathers paired-end and split read evidence files for use in the GATK-SV pipeline.\",\n+        programGroup = StructuralVariantDiscoveryProgramGroup.class\n+)\n+public class PairedEndAndSplitReadEvidenceCollection extends ReadWalker {\n+\n+    @Argument(shortName = \"p\", fullName = \"pe-file\", doc = \"Output file for paired end evidence\", optional=false)\n+    public String peFile;\n+\n+    @Argument(shortName = \"s\", fullName = \"sr-file\", doc = \"Output file for split read evidence\", optional=false)\n+    public String srFile;\n+\n+    @Argument(fullName = \"sample-name\", doc = \"Sample name\")\n+    String sampleName = null;\n+\n+    Set<String> observedDiscordantNames = new HashSet<>();\n+    int currentDiscordantPosition = -1;\n+    String currentChrom = null;\n+    private OutputStreamWriter peWriter;\n+    private OutputStreamWriter srWriter;\n+\n+    PriorityQueue<SplitPos> splitPosBuffer;\n+    List<DiscordantRead> discordantPairs;\n+    private SAMSequenceDictionary sequenceDictionary;\n+\n+    @Override\n+    public boolean requiresReads() {\n+        return true;\n+    }\n+\n+\n+    @Override\n+    public void onTraversalStart() {\n+        super.onTraversalStart();\n+\n+        try {\n+            if (peFile.endsWith(\".gz\")) {\n+                peWriter = new OutputStreamWriter(new BlockCompressedOutputStream(peFile, 6));\n+            } else {\n+                peWriter = new OutputStreamWriter(new FileOutputStream(new File(peFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + peFile);\n+        }\n+\n+        try {\n+            if (srFile.endsWith(\".gz\")) {\n+                srWriter = new OutputStreamWriter(new BlockCompressedOutputStream(srFile, 6));\n+            } else {\n+                srWriter = new OutputStreamWriter(new FileOutputStream(new File(srFile)));\n+            }\n+        } catch (FileNotFoundException e) {\n+            throw new UserException(\"Could not open \" + srFile);\n+        }\n+\n+        splitPosBuffer = new PriorityQueue<>(new SplitPosComparator());\n+\n+        discordantPairs = new ArrayList<>();\n+\n+        sequenceDictionary = getBestAvailableSequenceDictionary();\n+    }\n+\n+    public boolean isExcluded(final GATKRead read) {\n+        return read.isUnmapped() || read.mateIsUnmapped() || read.isSecondaryAlignment() || read.isDuplicate() || read.isSupplementaryAlignment();\n+    }\n+\n+\n+    @Override\n+    public void apply(final GATKRead read, final ReferenceContext referenceContext, final FeatureContext featureContext) {\n+        if (isExcluded(read)) {\n+            return;\n+        }\n+\n+        if (isSoftClipped(read)) {\n+            countSplitRead(read, splitPosBuffer, srWriter);\n+        }\n+\n+        if (! read.isProperlyPaired()) {\n+            reportDiscordantReadPair(read);\n+        }\n+    }\n+\n+    private void reportDiscordantReadPair(final GATKRead read) {\n+        if (read.getStart() != currentDiscordantPosition) {\n+            flushDiscordantReadPairs();\n+            currentDiscordantPosition = read.getStart();\n+            observedDiscordantNames.clear();\n+        }\n+\n+        final DiscordantRead reportableDiscordantReadPair = getReportableDiscordantReadPair(read, observedDiscordantNames,\n+                sequenceDictionary);\n+        if (reportableDiscordantReadPair != null) {\n+            discordantPairs.add(reportableDiscordantReadPair);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    public DiscordantRead getReportableDiscordantReadPair(final GATKRead read, final Set<String> observedDiscordantNamesAtThisLocus,\n+                                                          final SAMSequenceDictionary samSequenceDictionary) {\n+        final int readSeqId = samSequenceDictionary.getSequenceIndex(read.getContig());\n+        final int mateSeqId = samSequenceDictionary.getSequenceIndex(read.getMateContig());\n+        if (readSeqId < mateSeqId) {\n+            return new DiscordantRead(read);\n+        } else if (readSeqId == mateSeqId) {\n+            if (read.getStart() < read.getMateStart()) {\n+                return new DiscordantRead(read);\n+            } else if (read.getStart() == read.getMateStart()) {\n+                final boolean seenBefore = observedDiscordantNamesAtThisLocus.remove(read.getName());\n+                if (! seenBefore) {\n+                    final DiscordantRead discordantRead = new DiscordantRead(read);\n+                    observedDiscordantNamesAtThisLocus.add(read.getName());\n+                    return discordantRead;\n+                }\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private void flushDiscordantReadPairs() {\n+        final Comparator<DiscordantRead> discReadComparator =", "originalCommit": "c6e2ea58f7dd4e48087a15c3dede288bcb28a851", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0ODUzOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6356#discussion_r367048539", "bodyText": "Wrapped this up in a static inner class for now.", "author": "cwhelan", "createdAt": "2020-01-15T18:55:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQzMTQzNA=="}], "type": "inlineReview"}, {"oid": "0b36d11974f13aab0af41feae91ebc45860f4a3f", "url": "https://github.com/broadinstitute/gatk/commit/0b36d11974f13aab0af41feae91ebc45860f4a3f", "message": "address PR comments", "committedDate": "2020-01-15T18:57:47Z", "type": "forcePushed"}, {"oid": "bd3b3966b6457558abf1365b9b709a1fe6c3ee03", "url": "https://github.com/broadinstitute/gatk/commit/bd3b3966b6457558abf1365b9b709a1fe6c3ee03", "message": "prototype port of PESR collection", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "7ee8ef3d4fb7b60dd90cc885f0343bced36163da", "url": "https://github.com/broadinstitute/gatk/commit/7ee8ef3d4fb7b60dd90cc885f0343bced36163da", "message": "fix discordant read comparator", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "401a5fbadc8b3383d07f61e788b5eee37b76254a", "url": "https://github.com/broadinstitute/gatk/commit/401a5fbadc8b3383d07f61e788b5eee37b76254a", "message": "minor bug fix to pesr collection", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "27c02b50cba8a105db9b8359dd34902dfba52965", "url": "https://github.com/broadinstitute/gatk/commit/27c02b50cba8a105db9b8359dd34902dfba52965", "message": "use an intermediate discordant read object to save memory", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "4ef7a582e044c50fe4a490305e02f4f329bf92f2", "url": "https://github.com/broadinstitute/gatk/commit/4ef7a582e044c50fe4a490305e02f4f329bf92f2", "message": "fix sorting and flushing bugs", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "8e38b8c946f0001e5e9d3ccc26cb024f9603700e", "url": "https://github.com/broadinstitute/gatk/commit/8e38b8c946f0001e5e9d3ccc26cb024f9603700e", "message": "memory improvements", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "8783becd6eba7b27e7db57a6ff9c0aa3c72e5761", "url": "https://github.com/broadinstitute/gatk/commit/8783becd6eba7b27e7db57a6ff9c0aa3c72e5761", "message": "switch to list + sort", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "6d91bb1b5e8c86a5c174555ba183c0905346a713", "url": "https://github.com/broadinstitute/gatk/commit/6d91bb1b5e8c86a5c174555ba183c0905346a713", "message": "fix some bugs", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "215e14b0b75e615a0ac3aaac61ca57ede6f41185", "url": "https://github.com/broadinstitute/gatk/commit/215e14b0b75e615a0ac3aaac61ca57ede6f41185", "message": "make some instance variables private", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "c3eb8956a30034ff0396842246e4c65327c34e54", "url": "https://github.com/broadinstitute/gatk/commit/c3eb8956a30034ff0396842246e4c65327c34e54", "message": "fix bad bai index", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "e076c0532848a08cf5d66f59a4c61a851797f8a8", "url": "https://github.com/broadinstitute/gatk/commit/e076c0532848a08cf5d66f59a4c61a851797f8a8", "message": "stubs for tests", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "39f513382e64107300d3640c0e3d4a3289873dc2", "url": "https://github.com/broadinstitute/gatk/commit/39f513382e64107300d3640c0e3d4a3289873dc2", "message": "fix test stub", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "31f708084b9d5e45bd79236ea7ff11441090bfb9", "url": "https://github.com/broadinstitute/gatk/commit/31f708084b9d5e45bd79236ea7ff11441090bfb9", "message": "start adding unit tests", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "b22cc719d25bfdef4c762fd61dbeebbd38e35076", "url": "https://github.com/broadinstitute/gatk/commit/b22cc719d25bfdef4c762fd61dbeebbd38e35076", "message": "add unit test and integration test", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "886e28edef29769839009e620176779f4c84a64e", "url": "https://github.com/broadinstitute/gatk/commit/886e28edef29769839009e620176779f4c84a64e", "message": "refactor and add test cases", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "5c8f7de2755b993e16400279ba42d7f4558e5e05", "url": "https://github.com/broadinstitute/gatk/commit/5c8f7de2755b993e16400279ba42d7f4558e5e05", "message": "clean up and add some documentation", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "0b36d11974f13aab0af41feae91ebc45860f4a3f", "url": "https://github.com/broadinstitute/gatk/commit/0b36d11974f13aab0af41feae91ebc45860f4a3f", "message": "address PR comments", "committedDate": "2020-01-15T18:57:47Z", "type": "commit"}, {"oid": "333081daac2ed2dff4de64dabe4454abd31225a8", "url": "https://github.com/broadinstitute/gatk/commit/333081daac2ed2dff4de64dabe4454abd31225a8", "message": "add the beta tool marker", "committedDate": "2020-01-15T21:20:29Z", "type": "commit"}]}