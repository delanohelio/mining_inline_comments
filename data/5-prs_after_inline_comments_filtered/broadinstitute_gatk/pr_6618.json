{"pr_number": 6618, "pr_title": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS.", "pr_createdAt": "2020-05-27T15:48:22Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6618", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NzM4MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431397381", "bodyText": "I sort of which java had lightweight type aliases so we could rename this locally to HdfsPath and avoid these nasty fully specified names...", "author": "lbergelson", "createdAt": "2020-05-27T19:38:06Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");", "originalCommit": "1b01459a630e7658559c9356c3c83d25bfb1a3b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNjc0Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431416746", "bodyText": "Yeah, I frequently wish Java had type aliases.", "author": "cmnbroad", "createdAt": "2020-05-27T20:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5NzM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA2NA==", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431398064", "bodyText": "nitpick, i'm a booster for argBuilder.addInput and .addOutput, but it doesn't matter at all", "author": "lbergelson", "createdAt": "2020-05-27T19:39:29Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSparkIntegrationTest.java", "diffHunk": "@@ -67,6 +74,44 @@ public void testGCSInputsAndOutputsWithSparkNio(final String gcsInput, final Str\n         SamAssertionUtils.assertSamsEqual(IOUtils.getPath(outputPath), IOUtils.getPath(gcsInputPath), null);\n     }\n \n+    @Test(groups = \"spark\")\n+    public void testReadAndWriteCRAMAndReferenceOnHDFS() throws Exception {\n+        final GATKPathSpecifier testCram = new GATKPathSpecifier(getTestFile(\"count_reads.cram\").getAbsolutePath());\n+        final GATKPathSpecifier testRef = new GATKPathSpecifier(getTestFile(\"count_reads.fasta\").getAbsolutePath());\n+        final GATKPathSpecifier testRefDict = new GATKPathSpecifier(getTestFile(\"count_reads.dict\").getAbsolutePath());\n+        final GATKPathSpecifier testRefIndex = new GATKPathSpecifier(getTestFile(\"count_reads.fasta.fai\").getAbsolutePath());\n+\n+        MiniClusterUtils.runOnIsolatedMiniCluster(cluster -> {\n+            final org.apache.hadoop.fs.Path workingDirectory = MiniClusterUtils.getWorkingDir(cluster);\n+\n+            // copy all the test files to HDFS\n+            final org.apache.hadoop.fs.Path cramHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.cram\");\n+            final org.apache.hadoop.fs.Path refHDFSPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta\");\n+            final org.apache.hadoop.fs.Path refHDFSDictPath = new org.apache.hadoop.fs.Path(workingDirectory,\"count_reads.dict\");\n+            final org.apache.hadoop.fs.Path refHDFSIndexPath = new org.apache.hadoop.fs.Path(workingDirectory, \"count_reads.fasta.fai\");\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testCram.getURI()), cramHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRef.getURI()), refHDFSPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefDict.getURI()), refHDFSDictPath);\n+            cluster.getFileSystem().copyFromLocalFile(new org.apache.hadoop.fs.Path(testRefIndex.getURI()), refHDFSIndexPath);\n+\n+            // run PrintReadsSpark and print the contents of the HDFS cram test file to an output HDFS cram\n+            final GATKPathSpecifier outputHDFSPath = new GATKPathSpecifier(workingDirectory + \"testCramOnHDFSOut.cram\");\n+            final ArgumentsBuilder argBuilder = new ArgumentsBuilder();\n+            argBuilder.add(\"input\", cramHDFSPath.toUri().toString())", "originalCommit": "1b01459a630e7658559c9356c3c83d25bfb1a3b9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQxNjk5NA==", "url": "https://github.com/broadinstitute/gatk/pull/6618#discussion_r431416994", "bodyText": "I keep forgetting about those. Easy enough to change though.", "author": "cmnbroad", "createdAt": "2020-05-27T20:17:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM5ODA2NA=="}], "type": "inlineReview"}, {"oid": "c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "url": "https://github.com/broadinstitute/gatk/commit/c2902b03f1a82e64785a1deaae03edcbdee0ae2a", "message": "Code review comments.", "committedDate": "2020-06-08T12:27:36Z", "type": "forcePushed"}, {"oid": "30b426b062cb759c0e231cc89e1f613b4866bbf4", "url": "https://github.com/broadinstitute/gatk/commit/30b426b062cb759c0e231cc89e1f613b4866bbf4", "message": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS.", "committedDate": "2020-06-08T12:47:42Z", "type": "commit"}, {"oid": "30b426b062cb759c0e231cc89e1f613b4866bbf4", "url": "https://github.com/broadinstitute/gatk/commit/30b426b062cb759c0e231cc89e1f613b4866bbf4", "message": "Add a read/write roundtrip Spark integration test for a CRAM and reference on HDFS.", "committedDate": "2020-06-08T12:47:42Z", "type": "forcePushed"}]}