{"pr_number": 6394, "pr_title": "Consolidated branch with JunctionTreeImprovements.", "pr_createdAt": "2020-01-20T00:33:48Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6394", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNzc0Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369917746", "bodyText": "haplotypeList might not be the best name for a Set<Haplotype>", "author": "davidbenjamin", "createdAt": "2020-01-23T03:28:55Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java", "diffHunk": "@@ -11,6 +15,8 @@\n     private final Status status;\n     private final AbstractReadThreadingGraph threadingGraph;\n     private final SeqGraph graph;\n+    private Set<Haplotype> haplotypeList;", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxNzg4Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369917882", "bodyText": "I would let good grammar override the desire to start boolean getters with is.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:29:50Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyResult.java", "diffHunk": "@@ -42,6 +48,22 @@ public int getKmerSize() {\n         return graph == null? threadingGraph.getKmerSize() : graph.getKmerSize();\n     }\n \n+    public Set<Haplotype> getHaplotypeList() {\n+        return haplotypeList;\n+    }\n+\n+    public void setHaplotypeList(Set<Haplotype> haplotypeList) {\n+        this.haplotypeList = haplotypeList;\n+    }\n+\n+    public boolean isContainsSuspectHaplotypes() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODIxNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918214", "bodyText": "omit the space before 10", "author": "davidbenjamin", "createdAt": "2020-01-23T03:32:10Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -61,7 +61,7 @@\n      */\n     @Advanced\n     @Argument(fullName= KMER_SIZE_LONG_NAME, doc=\"Kmer size to use in the read threading assembler\", optional = true)\n-    public List<Integer> kmerSizes = Lists.newArrayList(10,25);\n+    public List<Integer> kmerSizes = Lists.newArrayList( 10, 25);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODMyNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918324", "bodyText": "Rewrite the doc string to avoid the double negative", "author": "davidbenjamin", "createdAt": "2020-01-23T03:32:54Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -161,6 +161,13 @@\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n+    /**\n+     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder\n+     */\n+    @Hidden\n+    @Argument(fullName=\"disable-artificial-haplotype-recovery\", doc = \"If disabled, linked de bruijn graph will not attempt to recover variant haplotypes that are not supported by junction trees\", optional = true)", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODM1OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918358", "bodyText": "This javadoc was copied and not modified", "author": "davidbenjamin", "createdAt": "2020-01-23T03:33:07Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -161,6 +161,13 @@\n     @Argument(fullName=\"linked-de-bruijn-graph\", doc = \"If enabled, the Assembly Engine will construct a Linked De Brujin graph to recover better haplotypes\", optional = true)\n     public boolean useLinkedDeBrujinGraph = false;\n \n+    /**\n+     * Disables graph simplification into a seq graph. This is experimental and may cause performance issues for the GraphBasedKBestHaplotypeFinder", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODYzNQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369918635", "bodyText": "setWasPoorlyRecovered", "author": "davidbenjamin", "createdAt": "2020-01-23T03:35:15Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JTBestHaplotype.java", "diffHunk": "@@ -167,6 +184,14 @@ public void addJunctionTree(final JunctionTreeLinkedDeBruinGraph.ThreadingTree j\n         }\n     }\n \n+    /**\n+     * Add a flag of graph that based on this haplotype we think we should expand the kmer size\n+     * @param b\n+     */\n+    public void setIsWonky(final boolean b) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI1NzY1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374257659", "bodyText": "What, you think the isWonky() is not a reasonable method in the gatk?", "author": "jamesemery", "createdAt": "2020-02-03T18:12:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkxODYzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTY0OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921648", "bodyText": "There's a runMutect2 method at the bottom of this class that you should use.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:55:08Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test\n+    public void testWhySiteFails() {\n+        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTkxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921918", "bodyText": "And does the test still work without all the non-default arguments?", "author": "davidbenjamin", "createdAt": "2020-01-23T03:56:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTcxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921718", "bodyText": "What is this testing?", "author": "davidbenjamin", "createdAt": "2020-01-23T03:55:31Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0ODYwNw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374348607", "bodyText": "same as the other error. I apologize i thought I had deleted all of these debugger test sites from development.", "author": "jamesemery", "createdAt": "2020-02-03T21:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMTgzNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369921834", "bodyText": "Same as above -- what is it testing and use the runMutect2 method.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:56:14Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2IntegrationTest.java", "diffHunk": "@@ -197,6 +197,23 @@ public void testNA12878NormalNormalFiltering() {\n         };\n     }\n \n+    @Test\n+    public void testWhySiteFails() {\n+        String[] args = (\"-I gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.tumor.bam -I\" +\n+                \" gs://broad-public-datasets/TCGA_DREAM/synthetic.challenge.set1.normal.bam -R /Users/emeryj/hellbender/references/Homo_sapiens_assembly19.fasta\" +\n+                \" -normal synthetic.challenge.set1.normal -bamout bamout.bam -O calls.vcf -L 15:33482411-33484411 --debug-graph-transformations\").split(\" \");\n+        runCommandLine(args);\n+    }\n+\n+    @Test\n+    public void testInfiniteLoop() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjA1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369922059", "bodyText": "Use an ArgumentsBuilder and explain what this is testing.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:57:44Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java", "diffHunk": "@@ -126,6 +129,12 @@ public void testVCFModeWithExperimentalAssemblyEngineCode(final String inputFile\n         }\n     }\n \n+    @Test\n+    public void testThisSiteThatEludesMe() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0NzgwMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374347801", "bodyText": "whoops, this was leftover from trying to debug some issue or other in the code during development. I'll just remove this test so as not to cause problems.", "author": "jamesemery", "createdAt": "2020-02-03T21:22:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMjE3Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369922176", "bodyText": "Use the variable, not the string literal.", "author": "davidbenjamin", "createdAt": "2020-01-23T03:58:16Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerIntegrationTest.java", "diffHunk": "@@ -114,7 +117,7 @@ public void testVCFModeWithExperimentalAssemblyEngineCode(final String inputFile\n                 \"-L\", \"20:10000000-10100000\",\n                 \"-O\", outputPath,\n                 \"-pairHMM\", \"AVX_LOGLESS_CACHING\",\n-                \"--disable-sequence-graph-simplification\",\n+                \"--linked-de-bruijn-graph\",", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzgzOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369923838", "bodyText": "Is the idea that this has to be a List and not, say, an OptionalInt, because of cycles in the reference?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:09:12Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/MultiSampleEdge.java", "diffHunk": "@@ -30,6 +32,8 @@\n     private final int singleSampleCapacity;\n     private final PriorityQueue<Integer> singleSampleMultiplicities;\n \n+    private final List<Integer> referencePathIndexes = new ArrayList<>(2);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMzNjUxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374336513", "bodyText": "Correct", "author": "jamesemery", "createdAt": "2020-02-03T20:56:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyMzk2NA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369923964", "bodyText": "While you're at it, the line above can use Utils.validate()", "author": "davidbenjamin", "createdAt": "2020-01-23T04:10:00Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/Path.java", "diffHunk": "@@ -93,7 +93,8 @@ public Path(final Path<V,E> p, final List<E> edges) {\n         for (int i = 0; i < edges.size(); i++) {\n             if ( ! p.graph.getEdgeSource(edges.get(i)).equals(tmpVertex) ) {\n                 throw new IllegalStateException(\"Edges added to path must be contiguous.\");\n-            } tmpVertex = p.graph.getEdgeTarget(edges.get(i));\n+            }", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDE0Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924143", "bodyText": "typo: should be Indices (or Indexes -- both are correct)", "author": "davidbenjamin", "createdAt": "2020-01-23T04:11:14Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -404,6 +405,20 @@ public void postProcessForHaplotypeFinding(final File debugGraphOutputPath, fina\n         }\n     }\n \n+    //TODO this should really be easy enough to write a test for\n+    @VisibleForTesting\n+    private void annotateEdgesWithReferenceIndecies() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDE5MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924191", "bodyText": "This method is both private and VisibleForTesting?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:11:33Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -404,6 +405,20 @@ public void postProcessForHaplotypeFinding(final File debugGraphOutputPath, fina\n         }\n     }\n \n+    //TODO this should really be easy enough to write a test for\n+    @VisibleForTesting\n+    private void annotateEdgesWithReferenceIndecies() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNDYzOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369924639", "bodyText": "final", "author": "davidbenjamin", "createdAt": "2020-01-23T04:14:33Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -452,25 +467,43 @@ private void threadSequenceForJuncitonTree(final SequenceForKmers seqForKmers) {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        int kmersPastSinceLast = 0;\n+        boolean hasToRediscoverKmer = false;\n+        int kmersPastSinceLastNullVertex = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            final MultiDeBruijnVertex vertex;\n-            if (kmersPastSinceLast == 0) {\n+            MultiDeBruijnVertex vertex;\n+            if (!hasToRediscoverKmer) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-                // TODO this might cause problems\n-                if (vertex != null) {\n-                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n+            }\n+            // we found a null path in the grpah\n+            if (vertex == null) {\n+                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n+                if (kmersPastSinceLastNullVertex == 0) {\n+                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369925448", "bodyText": "Could you explain what this does?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:19:50Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraph.java", "diffHunk": "@@ -452,25 +467,43 @@ private void threadSequenceForJuncitonTree(final SequenceForKmers seqForKmers) {\n \n         // loop over all of the bases in sequence, extending the graph by one base at each point, as appropriate\n         MultiDeBruijnVertex lastVertex = startingVertex;\n-        int kmersPastSinceLast = 0;\n+        boolean hasToRediscoverKmer = false;\n+        int kmersPastSinceLastNullVertex = 0;\n         for ( int i = startPos + 1; i <= seqForKmers.stop - kmerSize; i++ ) {\n-            final MultiDeBruijnVertex vertex;\n-            if (kmersPastSinceLast == 0) {\n+            MultiDeBruijnVertex vertex;\n+            if (!hasToRediscoverKmer) {\n                 vertex = extendJunctionThreadingByOne(lastVertex, seqForKmers.sequence, i, nodeHelper);\n             } else {\n                 Kmer kmer = new Kmer(seqForKmers.sequence, i, kmerSize);\n                 vertex = kmerToVertexMap.get(kmer);\n-                // TODO this might cause problems\n-                if (vertex != null) {\n-                   attemptToResolveThreadingBetweenVertexes(lastVertex, nodeHelper, vertex);\n+            }\n+            // we found a null path in the grpah\n+            if (vertex == null) {\n+                // if we are not in an error kmer try to extend the path anyway assuming its a one base mismatch\n+                if (kmersPastSinceLastNullVertex == 0) {\n+                    Set<MultiSampleEdge> outgoingEdges = outgoingEdgesOf(lastVertex);\n+                    if (outgoingEdges.size()==1) {\n+                        vertex = getEdgeTarget(outgoingEdges.stream().findFirst().get());\n+                        kmersPastSinceLastNullVertex = 1;\n+                    }\n+                // if we dropped multiple bases from the read following an already missing path from the reference then we throw it away and try to catch the trail from kmers again\n+                } else {\n+                    hasToRediscoverKmer = true;\n+                    nodeHelper.clear();\n                 }\n             }\n+\n             // If for whatever reason vertex = null, then we have fallen off the corrected graph so we don't update anything\n             if (vertex != null) {\n                 lastVertex = vertex;\n-                kmersPastSinceLast = 0;\n-            } else {\n-                kmersPastSinceLast++;\n+\n+                // If we aren't in an error state do nothing, otherwise we increment the count of bases, if we are over kmersize then revert to a safety state\n+                if (kmersPastSinceLastNullVertex > 0) {\n+                    kmersPastSinceLastNullVertex++;\n+                    if (kmersPastSinceLastNullVertex > kmerSize) {\n+                        kmersPastSinceLastNullVertex = 0;", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0NzA5Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374347097", "bodyText": "Yes. I will try to clean up the comments to this effect:\nWe want to \"skip\" over single base incongruities if we can since they mean some path was pruned from the graph. In order to do that we have a \"unsafe state\" mode and the normal mode. If we are missing our next edge then we attempt to skip one edge past in both and flip into the unsafe state. The idea is that if there was a pruned SNP error we want to try to walk over the next kmer size bases and if we find k. If we find k exact matching bases between the read and the graph then we have walked over an entire kmer. There is a potential issue with this code that we discussed. I will refactor this to check ahead of time for validity without touching the trees at all.", "author": "jamesemery", "createdAt": "2020-02-03T21:20:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4ODY1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374388655", "bodyText": "I have refactored it to do this step \"tentatively\" ahead of time. I will ask you to take a look afterwards.", "author": "jamesemery", "createdAt": "2020-02-03T22:55:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTQ0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNTgxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369925813", "bodyText": "SNP", "author": "davidbenjamin", "createdAt": "2020-01-23T04:21:44Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjUxOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369926518", "bodyText": "Is there an overloaded version of addSequence with a multiplicity argument so you don't have to repeat lines?", "author": "davidbenjamin", "createdAt": "2020-01-23T04:26:17Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het\n+        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n+        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n+\n+        assembler.addSequence(\"reference\", getBytes(ref), true);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4MTYxMA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374381610", "bodyText": "There is one but it has the feature of adding multiplicty to the graph which doesn't get accounted for in the junction trees. Maybe it should be refactored to work that way?", "author": "jamesemery", "createdAt": "2020-02-03T22:37:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjUxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNjYwNw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369926607", "bodyText": "Typo: dorpped", "author": "davidbenjamin", "createdAt": "2020-01-23T04:26:56Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -96,6 +96,105 @@ public void testDegenerateLoopingCase() {\n \n     }\n \n+    @Test\n+    public void testRecoveryOfAPathDroppedByJunctionTrees() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(5);\n+        String ref = \"AAAACAC\"+\"C\"+\"ATGTGCGG\"+\"T\"+\"GGGTT\"; // the first site has an interesting graph structure and the second site is used to ensure the graph isinterestingg\n+\n+        // A simple snip het\n+        String read1 = \"AAAACAC\"+\"T\"+\"CTGTGCGG\"+\"C\"+\"GGGTT\"; // CGAC merges with the below read\n+        String read2 =                \"TGTGCGG\"+\"A\"+\"GGGTT\"; // doesn't show up in the first graph\n+\n+        assembler.addSequence(\"reference\", getBytes(ref), true);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+        assembler.addSequence(\"anonymous\", getBytes(read1), false);\n+\n+        assembler.addSequence(\"anonymous\", getBytes(read2), false);\n+\n+        assembler.buildGraphIfNecessary();\n+        assembler.generateJunctionTrees();\n+\n+        final List<String> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1)\n+                .findBestHaplotypes(5).stream().map(haplotype -> new String(haplotype.getBases())).collect(Collectors.toList());\n+\n+        Assert.assertEquals(bestPaths.size(), 2);\n+        Assert.assertEquals(bestPaths.get(0), read1);\n+        Assert.assertEquals(bestPaths.get(1), \"AAAACAC\"+\"T\"+\"C\" + read2); //asserting that the front of read 1 was appended to read 2 for haplotype construction\n+    }\n+\n+    @Test\n+    // This test documents one of the known edge cases in the pivotal edge recovery code where sometimes an edge might be\n+    // dropped if there doesn't happen to be any result path that connects to the root vertex of this dorpped path", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTkyNzEzMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r369927133", "bodyText": "This is a very nice test.", "author": "davidbenjamin", "createdAt": "2020-01-23T04:30:26Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinderUnitTest.java", "diffHunk": "@@ -1099,4 +1198,80 @@ public void testKmerGraphSimpleReferenceRecoveryWithSNP() {\n         }\n         return path;\n     }\n+\n+\n+    @Test\n+    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderBasicExample() {\n+        int readlength = 20;\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(7);\n+        String ref = \"TAAACAAG\"+\"G\"+\"TTGGGTTCG\"+\"A\"+\"GCGGGGTTC\"+\"T\"+\"CTCGAAGT\"+\"T\"+\"CTTGGTAATAT\"+\"A\"+\"GGGGGCCCC\"; // Reference with 5 sites all separated by at least kmer size\n+        String alt1 = \"TAAACAAG\"+\"T\"+\"TTGGGTTCG\"+\"G\"+\"GCGGGGTTC\"+\"A\"+\"CTCGAAGT\"+\"C\"+\"CTTGGTAATAT\"+\"G\"+\"GGGGGCCCC\"; // Alt with different values for all sites\n+\n+        // Generate some reads that do not span the entire active region\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        for (int i = 0; i + readlength < ref.length(); i++) {\n+            assembler.addSequence(\"anonymous\", getBytes(alt1.substring(i, i + readlength)), false);\n+        }\n+\n+        assembler.buildGraphIfNecessary();\n+        assembler.generateJunctionTrees();\n+\n+        final JunctionTreeKBestHaplotypeFinder<MultiDeBruijnVertex, MultiSampleEdge> bestPaths = new JunctionTreeKBestHaplotypeFinder<>(assembler).setWeightThreshold(1);\n+\n+        LinkedHashSet<MultiSampleEdge> pivotalEdges = bestPaths.createMapOfPivotalEdgesInTopologicalOrder();\n+        Iterator<MultiSampleEdge> edgesInOrder = pivotalEdges.iterator();\n+        ListIterator<String> expectedEdgeKmerTargetsFOrPivotalEdges = Arrays.asList(new String[]{\"AACAAGT\",\"GGTTCGG\",\"GGGTTCA\",\"CGAAGTC\",\"TAATATG\"}).listIterator();\n+\n+        // Asserting that the order of edges is as expected\n+        Assert.assertEquals(pivotalEdges.size(), 5);\n+        while (edgesInOrder.hasNext()) {\n+            MultiSampleEdge nextEdge = edgesInOrder.next();\n+            String expectedKmerEdge = expectedEdgeKmerTargetsFOrPivotalEdges.next();\n+            String nextTarget = assembler.getEdgeTarget(nextEdge).getSequenceString();\n+            Assert.assertEquals(nextTarget, expectedKmerEdge);\n+        }\n+\n+    }\n+\n+    @Test\n+    // this test asserts that included in pivotal edges are edges that are only reachable by following uncovered reference path\n+    public void testCreateMapOfPivotalEdgesInTopoglogicalOrderHiddenReferenceSequence() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxMzkyMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370313922", "bodyText": "Having a ternary where all operands are boolean is just too boolean.  How about:\nif (queue.size() > (result.isEmpty() ? DEFAULT_MAX_PATHS_TO_CONSIDER_WITHOUT_RESULT : DEFAULT_MAX_PATHS_TO_EVER_CONSIDER)", "author": "davidbenjamin", "createdAt": "2020-01-23T19:34:03Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -86,33 +97,49 @@ public boolean keepCycles() {\n     @Override\n     @SuppressWarnings({\"unchecked\"})\n     public List<KBestHaplotype<V, E>> findBestHaplotypes(final int maxNumberOfHaplotypes) {\n+        //pre-process step: find pivotal edges so they can be marked off as visited (if we want to recover edges uncovered in the graph).\n+        final LinkedHashSet<E> unvisitedPivotalEdges = experimentalEndRecoveryMode ? createMapOfPivotalEdgesInTopologicalOrder() : new LinkedHashSet<>();\n+\n         final List<JTBestHaplotype<V, E>> result = new ArrayList<>();\n         final PriorityQueue<JTBestHaplotype<V, E>> queue = new PriorityQueue<>(Comparator.comparingDouble(KBestHaplotype<V, E>::score).reversed());\n         sources.forEach(source -> queue.add(new JTBestHaplotype<>(source, graph)));\n \n         // Iterate over paths in the queue, unless we are out of paths of maxHaplotypes to find\n-        while (!queue.isEmpty() && result.size() < maxNumberOfHaplotypes) {\n+        while (result.size() < maxNumberOfHaplotypes && (!queue.isEmpty() || !unvisitedPivotalEdges.isEmpty())) {\n+            // check that we aren't caught in a hopelessly complicated graph for which we can't hope to recover\n+            if (result.isEmpty() ?", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNDgxMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370314811", "bodyText": "Do you have a plan for this TODO?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:36:05Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzA4MTY5Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r373081693", "bodyText": "This was intended as a question for you the reviewer. Specifically I mean the path annotation based on the graph which is used to mark haplotypes that are \"bad\" so we may filter or kmer expand them. Its disabled now because as it was implemented it didn't change the results on that CHM dataset I was looking at.", "author": "jamesemery", "createdAt": "2020-01-30T17:15:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNDgxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTQ4MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315481", "bodyText": "Write this as something like \"Filter out paths that involve the same kmer too many times without permission from a junction tree\"", "author": "davidbenjamin", "createdAt": "2020-01-23T19:37:25Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTY2OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315669", "bodyText": "typo: laset", "author": "davidbenjamin", "createdAt": "2020-01-23T19:37:47Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)\n+                List<JTBestHaplotype<V, E>> filteredPaths = jTPaths.stream()\n+                        .filter(path -> path.hasJunctionTreeEvidence() || path.wasLastEdgeFollowedBasedOnJTEvidence() ||\n+                                // Count the number of occurances of the laset vertex, if there are more than DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH throw away the path", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTk2NA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370315964", "bodyText": "I liked the previous indentation better.   What does IntelliJ say?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:38:22Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -144,24 +171,37 @@ public boolean keepCycles() {\n             if (sinks.contains(vertexToExtend) && pathToExtend.hasStoppingEvidence(weightThreshold)) {\n                 //TODO this will probably be resolved using a junction tree on that node and treating it as an edge to extend\n                 //todo the proposal here would be to check if there is an active tree left for us at this point and if so keep going\n-                if (chain.isEmpty()) {\n-                    result.add(pathToExtend);\n-                } else {\n-                    result.add(new JTBestHaplotype<>(pathToExtend, chain, 0));\n+                JTBestHaplotype<V, E> newPath = reconcilePathMissingReferenceStartPositions(chain.isEmpty() ?\n+                        pathToExtend :  new JTBestHaplotype<>(pathToExtend, chain, 0), result, graph);\n+                // check that we were able to recover the missing path\n+                if (newPath != null) {\n+                    //TODO this might be removed, this is where we evaluate\n+                    //annotatePathBasedOnGraph(newPath, junctionTreeLinkedDeBruinGraph);\n+                    result.add(newPath);\n                 }\n+                pathToExtend.getEdges().forEach(unvisitedPivotalEdges::remove);\n             }\n             // NOTE: even if we are at the reference stop and there is evidence in the junction trees of a stop we still want to explore other edges potentially\n \n             // We must be at a point where the path diverges, use junction trees to resolve if possible\n             if (outgoingEdges.size() > 1) {\n                 List<JTBestHaplotype<V, E>> jTPaths = pathToExtend.getApplicableNextEdgesBasedOnJunctionTrees(chain, outgoingEdges, weightThreshold);\n                 if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n-//                    throw new GATKException(\"Found no path based on the junction trees or exisiting paths, this should not have happened\");\n-                    System.out.println(\"Found nothing Queue has this many: \"+queue.size()+\"\\nPath that failed to extend was junction tree: \"+pathToExtend.getVertices());\n+                    logger.debug(\"Found nothing Queue has this many: \" + queue.size() + \"\\nPath that failed to extend was junction tree: \" + pathToExtend.getVertices());\n                 }\n-                queue.addAll(jTPaths);\n+                // Filter out paths that involve the same kmer too many times (if we were directed by a junction tree or have trees to follow then don't worry about repeated kmers)\n+                List<JTBestHaplotype<V, E>> filteredPaths = jTPaths.stream()\n+                        .filter(path -> path.hasJunctionTreeEvidence() || path.wasLastEdgeFollowedBasedOnJTEvidence() ||\n+                                // Count the number of occurances of the laset vertex, if there are more than DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH throw away the path\n+                                path.getVertices().stream().filter(v -> v.equals(path.getLastVertex())).count() <= DEFAULT_MAX_ACCEPTABLE_REPETITIONS_OF_A_KMER_IN_A_PATH)\n+                        .collect(Collectors.toList());\n+                if (jTPaths.isEmpty() && !sinks.contains(vertexToExtend)) {\n+                    logger.debug(\"A path was filtered because it was looping without junction tree support\");\n+                }\n+\n+                queue.addAll(filteredPaths);\n \n-            // Otherwise just take the next node forward\n+                // Otherwise just take the next node forward", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDUwNA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374314504", "bodyText": "whoops, some of these are casualties to the intellij automatic formatting.", "author": "jamesemery", "createdAt": "2020-02-03T20:08:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNTk2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjI1MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370316250", "bodyText": "This would be a good place to remind people of the definition of a pivotal edge.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:39:00Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjkyMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370316922", "bodyText": "Status of this TODO?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:40:22Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM5MTYwMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374391601", "bodyText": "It did show up as a non-zero fraction on the profiler. It should be optimized. That and \"is this vertex a junction tree vertex\" (which is not cached and thus gets called by every read at every vertex which should be fixed) are both newly taking up runtime and could save a few percent in runtime. I would opt to push optimization into another PR the fix for this so as not to get bogged down in this review.", "author": "jamesemery", "createdAt": "2020-02-03T23:03:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNjkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNzM2Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370317367", "bodyText": "typo: piviotal", "author": "davidbenjamin", "createdAt": "2020-01-23T19:41:21Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxNzc3MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370317771", "bodyText": "typo: occurrences", "author": "davidbenjamin", "createdAt": "2020-01-23T19:42:14Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODI1MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318250", "bodyText": "This exception is not very informative", "author": "davidbenjamin", "createdAt": "2020-01-23T19:43:16Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318372", "bodyText": "Status of this commented-out code?", "author": "davidbenjamin", "createdAt": "2020-01-23T19:43:32Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMyMDUyOA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r374320528", "bodyText": "This was the old attempt to reconcile path heads after the fact. Something akin to this will be necessary in the future if we want to base head pasting on the similarity between ptaths. For now i think its okay to just remove it.", "author": "jamesemery", "createdAt": "2020-02-03T20:21:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMyOTY4Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375329686", "bodyText": "Remove is good for now.", "author": "davidbenjamin", "createdAt": "2020-02-05T15:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODM3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxODcxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370318713", "bodyText": "capitalize tiny", "author": "davidbenjamin", "createdAt": "2020-01-23T19:44:19Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n+     *\n+     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n+     * or might not be considered by the KBestHaplotypeFinder.\n+     *\n+     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n+     *       a breadth first search.\n+     *\n+     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n+     */\n+    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n+    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n+    @VisibleForTesting\n+    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n+        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n+        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n+        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n+\n+        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n+        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?\n+\n+        // Initialize the graph with the start\n+        edgesToVisit.addAll(sources.stream()\n+                .flatMap(s -> graph.outgoingEdgesOf(s).stream())\n+                .map(e -> new tinyEdgeHelper(e, 0))\n+                .collect(Collectors.toList()));\n+\n+        while (!edgesToVisit.isEmpty()) {\n+            tinyEdgeHelper nextEdge = edgesToVisit.poll();\n+            List<E> outgoingEdges = new ArrayList<>(graph.outgoingEdgesOf(graph.getEdgeTarget(nextEdge.edge)));\n+\n+            // If there are multiple interesting outgoing edges mark them as pivotal (this is currently non-deterministic and maybe could be improved?)\n+            if (outgoingEdges.size() > 1) {\n+                // not that uncovered reference edges do not get added to the output (because they were discounted from the graph for a reason)\n+                outputEdgesInOrder.addAll(outgoingEdges.stream().filter(e -> !(e.isRef() && e.getMultiplicity() == 1) && !visitedEdges.contains(e)).collect(Collectors.toList()));\n+            }\n+\n+            // visit the unvisited edges and add any edges not already found to the output linked hash map\n+            outgoingEdges.stream()\n+                    .filter(e -> !visitedEdges.contains(e))\n+                    .forEach(e -> {\n+                        edgesToVisit.add(new tinyEdgeHelper(e, nextEdge.score + 1));\n+                        visitedEdges.add(e);\n+                    });\n+        }\n+\n+        return outputEdgesInOrder;\n+    }\n+\n+\n+    // TODO also this could be greatly optimized if we just remember where the suspect edges are during the first pass...\n+    private class tinyEdgeHelper {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxOTUxMw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370319513", "bodyText": "topography. . . topographical", "author": "davidbenjamin", "createdAt": "2020-01-23T19:45:57Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.\n+     *\n+     * In order to accomplish this, the entire graph is traversed starting at the reference inputs and edges that might\n+     * or might not be considered by the KBestHaplotypeFinder.\n+     *\n+     * Note: Currently \"Topological order is defined as the number of edges taken from the start, which is accomplished with\n+     *       a breadth first search.\n+     *\n+     * @return returns a LinkedHashSet object where all of the pivotal edges in the graph will be iterated in\n+     */\n+    //TODO for this first implementation I have chosen (for simplicity sake) to base the event on the\n+    //TODO this can be optimized, don't go down this rabbit hole too eagerly\n+    @VisibleForTesting\n+    LinkedHashSet<E> createMapOfPivotalEdgesInTopologicalOrder() {\n+        final Set<E> visitedEdges = new HashSet<>(); // used to save ourselves the trouble of excessive graph traversal (and repetative)\n+        final PriorityQueue<tinyEdgeHelper> edgesToVisit = new PriorityQueue<>(Comparator.comparingDouble(tinyEdgeHelper::score));\n+        final LinkedHashSet<E> outputEdgesInOrder = new LinkedHashSet<>();\n+\n+        // zips through the entire graph, searching for pivotal edges and adding them based on the number of edges since the referecne\n+        // TODO decide on true topography or distance from reference. To add confusion, how do you guarantee the topographical order is visited correctly?", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMxOTc5Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370319796", "bodyText": "Remind the reader about the definition of pivotal edge here", "author": "davidbenjamin", "createdAt": "2020-01-23T19:46:31Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/graphs/JunctionTreeKBestHaplotypeFinder.java", "diffHunk": "@@ -188,4 +228,201 @@ public boolean keepCycles() {\n         return result.stream().map(n -> (KBestHaplotype<V, E>) n).collect(Collectors.toList());\n     }\n \n+    /**\n+     * Helper method that controls the logic for pivotal edges.\n+     *\n+     * The logic for pivotal edges currently is this:\n+     *  1: pop the next pivotal edge in our tree\n+     *  2: search our results set for any paths that cross the uncovered vertex, choose the one with the highest score\n+     *  3: if one is found, search for the last occurrence of the vertex for the pivotal edge in the path.\n+     *  4: construct an \"artificial\" haplotype that consists of all the edges of the chosen path up to the pivotal vertex\n+     *     with the chosen pivotal edge appended to the end. Add this to the provided queue.\n+     *\n+     *\n+     * NOTE: there is a limitation to this approach, while appending the paths at the front is faster and simpler as it allows\n+     *       the new \"artificial\" haplotype to remember what edges it has visited, it does not necessarily mean that the chosen\n+     *       path is the closest match to the resulting haplotype... See {@link JunctiontreeKbesthaplotypeFinderUnitTest.testRecoveryOfDroppedPathChoosingMostLikePathDespiteThatPathHavingAWorseScore()}\n+     *       for an illustration of this problem.\n+     *\n+     * @param unvisitedPivotalEdges ordered list of edges to try connecting\n+     * @param result                completed paths in the graph to use for construction\n+     * @param queue                 path priority queue to deposit new edges into\n+     */\n+    private void enqueueNextPivotalEdge(LinkedHashSet<E> unvisitedPivotalEdges, List<JTBestHaplotype<V, E>> result, PriorityQueue<JTBestHaplotype<V, E>> queue) {\n+        final E firstEdge = unvisitedPivotalEdges.stream().findFirst().get();\n+        final V pivotalVerex = graph.getEdgeSource(firstEdge);\n+        unvisitedPivotalEdges.remove(firstEdge);\n+\n+        // Check at this stage that are not starting a path that can never succeed //TODO this might cost a lot of runtime, check in profiler\n+        Optional<JTBestHaplotype<V, E>> bestMatchingHaplotype = result.stream().filter(path -> path.containsVertex(pivotalVerex)).max(Comparator.comparingDouble(JTBestHaplotype::score));\n+        if (bestMatchingHaplotype.isPresent()) {\n+            // Now we try to construct a reference covering haplotype from the one we just discovered\n+            final List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.get().getEdges();\n+            final List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+            //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+            if (edgesIncomingToSplitPoint.isEmpty()) {\n+                return;\n+            }\n+\n+            // From that best haplotype we choose the last occurrence of the piviotal branch vertex as representative\n+            // TODO maybe this will matter some day, simply select the last edge\n+            List<E> edgesBeforeSplit = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+            edgesBeforeSplit.add(firstEdge);\n+\n+            // create a new path with the beginging of the best edge stapled to the front\n+            JTBestHaplotype<V, E> pathToAdd = new JTBestHaplotype<>(new JTBestHaplotype<>(bestMatchingHaplotype.get().getFirstVertex(), graph), edgesBeforeSplit, bestMatchingHaplotype.get().score());\n+            List<JunctionTreeLinkedDeBruinGraph.ThreadingTree> treesPassed = pathToAdd.getVertices().stream()\n+                    .map(v -> junctionTreeLinkedDeBruinGraph.getJunctionTreeForNode((MultiDeBruijnVertex) v))\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .collect(Collectors.toList());\n+            pathToAdd.markTreesAsVisited(treesPassed);\n+            queue.add(pathToAdd);\n+        }\n+    }\n+\n+    //TODO this probably needs to be more testing...\n+    //TODO thiss might be best computed in the paths as they are being expanded\n+    private void annotatePathBasedOnGraph(final JTBestHaplotype<V, E> newPath, final JunctionTreeLinkedDeBruinGraph graph) {\n+        int farthestReferenceEdgeReached = 0;\n+        int numUpstreamRefEdgesEncountered = 0;\n+        int lastReferenceEdgeVisited = 0;\n+        for (E edge : newPath.getEdges()) {\n+            List<Integer> refOccurances = ((MultiSampleEdge)edge).getReferencePathIndexes();\n+\n+            // if we are not on a reference edge don't worry\n+            if (!refOccurances.isEmpty()) {\n+                // find the next lowest ref occurance that is incrementally higher than our current one (assumes sorted ref occurrences list)\n+                int refIndex = 0;\n+                for (Integer index : refOccurances) {\n+                    refIndex = index;\n+                    if (refIndex > lastReferenceEdgeVisited) {\n+                        break;\n+                    }\n+                }\n+\n+                // check if we are too far upstream\n+                if (farthestReferenceEdgeReached > refIndex + DEFAULT_MAX_UPSTREAM_REFERENCE_JUMP_TO_ALLOW) {\n+                    numUpstreamRefEdgesEncountered++;\n+                } else if (refIndex > farthestReferenceEdgeReached) {\n+                    farthestReferenceEdgeReached = refIndex;\n+                }\n+                lastReferenceEdgeVisited = refIndex;\n+            }\n+        }\n+\n+        // if we saw too many out of sequence reference edges then we report it as a potentially bad haplotype\n+        if (numUpstreamRefEdgesEncountered > DEFAULT_NUM_UPSTREAM_REFERENCE_EDGES_TO_TOLERATE) {\n+            newPath.setIsWonky(true);\n+        }\n+    }\n+\n+\n+    /**\n+     * Helper method that takes BestHaplotypePaths that may or may not start at a valid reference start position\n+     *\n+     * @return true if a valid reference-starting path was able to be constructed.\n+     */\n+    // TODO maybe if this fails to find we should include the reference path explicitly\n+    private JTBestHaplotype<V, E> reconcilePathMissingReferenceStartPositions(JTBestHaplotype<V, E> pathToReconcile, List<JTBestHaplotype<V, E>> validReturnPaths, BaseGraph<V, E> graph) {\n+        // check that the path is valid, if so don't modify it\n+        if (  sources.contains(pathToReconcile.getVertices().get(0))) {\n+            return pathToReconcile;\n+        }\n+\n+        throw new RuntimeException(\"e\");\n+//\n+//        V pivotalVerex = pathToReconcile.getFirstVertex();\n+//        //TODO this can be MUCH faster than a simple contains search here\n+//        List<JTBestHaplotype<V, E>> candidatePaths = validReturnPaths.stream().filter(path -> path.containsVertex(pivotalVerex)).collect(Collectors.toList());\n+//\n+//        // todo, perhaps something more drastic can be done here, this arises from either uncovered reference path or from branches that lead to loops that are unresolvable... perhaps try to capture the first one\n+//        if (candidatePaths.isEmpty()) {\n+//            // this is a failure state for now\n+//            return null;\n+//        }\n+//\n+//        //TODO this is totally simple for right now, will choose a better approach soon.\n+//        JTBestHaplotype<V, E> bestMatchingHaplotype = candidatePaths.stream().max(Comparator.comparingDouble(JTBestHaplotype::score)).get();\n+//\n+//        // Now we try to construct a reference covering haplotype from the one we just discovered\n+//        List<E> bestMatchingHaplotypeEdges = bestMatchingHaplotype.getEdges();\n+//        List<E> edgesIncomingToSplitPoint = bestMatchingHaplotypeEdges.stream().filter(edge -> graph.getEdgeTarget(edge).equals(pivotalVerex)).collect(Collectors.toList());\n+//        //todo it is either an error state to find nothing or could mean we accidentally did the search over the source vertex, either way shoudl be a bug\n+//        if (edgesIncomingToSplitPoint.isEmpty()) {\n+//            return null;\n+//        }\n+//\n+//        // TODO maybe this will matter some day, simply select the last edge\n+//        List<E> outputEdges = new ArrayList<>(bestMatchingHaplotypeEdges.subList(0, bestMatchingHaplotypeEdges.lastIndexOf(edgesIncomingToSplitPoint.get(edgesIncomingToSplitPoint.size() - 1)) + 1));\n+//        outputEdges.addAll(pathToReconcile.getEdges());\n+//\n+//        return new JTBestHaplotype<V,E>(new JTBestHaplotype<V,E>(bestMatchingHaplotype.getFirstVertex(), graph), outputEdges, bestMatchingHaplotype.score() + pathToReconcile.score());\n+    }\n+\n+    /**\n+     * This method is used as a pre-processing step in order to find all of the pivotal edges in the graph in a sorted fashion.", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMDI3Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370320273", "bodyText": "typo: Correciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:47:35Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMTI0Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370321242", "bodyText": "typo: Correciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:49:43Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMTg1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370321855", "bodyText": "These are great tests but you need to extract the shared code.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:51:12Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjQ3Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322476", "bodyText": "typo: Junciton", "author": "davidbenjamin", "createdAt": "2020-01-23T19:52:22Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        // We only see the supported alt path because the unsupported alt path is never recovered\n+        Assert.assertEquals(bestPaths.size(),1);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has two unsupported edges which should be pruned, however they are more than kmer size apart so the junction tree code should still work to recover the connectivity\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"G\"+\"TTTTTGGGGGGG\"+\"T\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCCTTTTTT\"+\"A\"+\"TTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistencySake() {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjY2NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322665", "bodyText": "If possible, it would be nice for this test too to fall within the extracted method of the above two tests.", "author": "davidbenjamin", "createdAt": "2020-01-23T19:52:50Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -485,6 +485,106 @@ public void testSimpleHaplotypeRethreading() {\n         Assert.assertNotNull(startAlt);\n     }\n \n+    @Test\n+    public void testJunctionTreeErrorCorreciton() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"C\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        Assert.assertEquals(bestPaths.size(),2);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+        Assert.assertEquals(new String(bestPaths.get(1).getBases()), \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\");\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonUnrecoverableWithInsertion() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);\n+        final String ref            = \"AAAAAAAAAAACCCCCC\"+\"G\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        final String supportedAlt   = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"A\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"A\"+\"ATATATATAATAT\";\n+        // This path has an undersupported edge that gets pruned, we want to assert that we can recover the proper junction tree weights regardless\n+        final String unSupportedAlt = \"AAAAAAAAAAACCCCCC\"+\"T\"+\"CCCCCTTTTTTTTTTTGGGGGGG\"+\"CAAT\"+\"GGGGTGTGTGTGTGCCCGTGTGT\"+\"C\"+\"ATATATATAATAT\";\n+        assembler.addSequence(\"anonymous\", getBytes(ref), true);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        assembler.addSequence(\"anonymous\", getBytes(supportedAlt), false);\n+        // Only provide a single instance of the path so that its middle C variant gets pruned\n+        assembler.addSequence(\"anonymous\", getBytes(unSupportedAlt), false);\n+        assembler.buildGraphIfNecessary();\n+        new LowWeightChainPruner<MultiDeBruijnVertex, MultiSampleEdge>(2).pruneLowWeightChains(assembler);\n+        assembler.generateJunctionTrees();\n+\n+        final List<KBestHaplotype<MultiDeBruijnVertex, MultiSampleEdge>> bestPaths =\n+                new JunctionTreeKBestHaplotypeFinder<>(assembler,assembler.getReferenceSourceVertex(),assembler.getReferenceSinkVertex(), 0, false).findBestHaplotypes(10);\n+\n+        // We only see the supported alt path because the unsupported alt path is never recovered\n+        Assert.assertEquals(bestPaths.size(),1);\n+        Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n+    }\n+\n+    @Test\n+    public void testJunctionTreeErrorCorrecitonKmerSizeDistanceAllowance() {\n+        final JunctionTreeLinkedDeBruinGraph assembler = new JunctionTreeLinkedDeBruinGraph(11);", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMjg5OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370322899", "bodyText": "Comment not needed", "author": "davidbenjamin", "createdAt": "2020-01-23T19:53:18Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -74,12 +75,17 @@ public ReadThreadingAssembler(final int maxAllowedPathsForReadThreadingAssembler\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = kmerSizes;\n+        this.kmerSizes = new ArrayList<>(kmerSizes);\n+        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMzE2MA==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370323160", "bodyText": "typo: exeperimental", "author": "davidbenjamin", "createdAt": "2020-01-23T19:53:53Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -74,12 +75,17 @@ public ReadThreadingAssembler(final int maxAllowedPathsForReadThreadingAssembler\n                                   final double initialErrorRateForPruning, final double pruningLogOddsThreshold,\n                                   final int maxUnprunedVariants, final boolean useLinkedDebrujinGraphs) {\n         Utils.validateArg( maxAllowedPathsForReadThreadingAssembler >= 1, \"numBestHaplotypesPerGraph should be >= 1 but got \" + maxAllowedPathsForReadThreadingAssembler);\n-        this.kmerSizes = kmerSizes;\n+        this.kmerSizes = new ArrayList<>(kmerSizes);\n+        kmerSizes.sort(Integer::compareTo); //sort the kmer sizes\n         this.dontIncreaseKmerSizesForCycles = dontIncreaseKmerSizesForCycles;\n         this.allowNonUniqueKmersInRef = allowNonUniqueKmersInRef;\n         this.numPruningSamples = numPruningSamples;\n         this.pruneFactor = pruneFactor;\n         this.generateSeqGraph = !useLinkedDebrujinGraphs;\n+        if (!generateSeqGraph) {\n+            logger.error(\"JunctionTreeLinkedDeBruinGraph is enabled.\\n This is an exeperimental assembly graph mode that has not been fully validated\\n\\n\");", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMyMzU1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370323559", "bodyText": "put stuff on separate lines", "author": "davidbenjamin", "createdAt": "2020-01-23T19:54:45Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -142,24 +148,44 @@ public AssemblyResultSet runLocalAssembly(final AssemblyRegion assemblyRegion,\n         final SimpleInterval activeRegionExtendedLocation = assemblyRegion.getExtendedSpan();\n         refHaplotype.setGenomeLocation(activeRegionExtendedLocation);\n         resultSet.add(refHaplotype);\n-        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n+        // either follow the old method for building graphs and then assembling or assemble and haplotype call before expanding kmers\n+        if (generateSeqGraph) {\n+            assembleKmerGraphsAndHaplotypeCall(refHaplotype, refLoc, header, aligner,\n+                    correctedReads, nonRefSeqGraphs, resultSet, activeRegionExtendedLocation);\n+        } else {\n+            assembleGraphsAndExpandKmersGivenHaplotypes(refHaplotype, refLoc, header, aligner,\n+                    correctedReads, nonRefRTGraphs, resultSet, activeRegionExtendedLocation);\n+        }\n+\n+        // If we get to this point then no graph worked... thats bad and indicates something horrible happened, in this case we just return a reference haplotype\n+        if (resultSet.getHaplotypeList().isEmpty()) {\n+            logger.debug(\"Graph at position \"+resultSet.getPaddedReferenceLoc()+\" failed to assemble anything informative; emitting just the reference here\" );\n+        }\n+\n+        // print the graphs if the appropriate debug option has been turned on\n+        if ( graphOutputPath != null ) { if (generateSeqGraph) { printGraphs(nonRefSeqGraphs); } else { printGraphs(nonRefRTGraphs); } }", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDM1MDQwMg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r370350402", "bodyText": "How about for savedAssemblyResult : Lists.reverse(savedAssemblyResults), which iterates over a reversing wrapper of the list?", "author": "davidbenjamin", "createdAt": "2020-01-23T20:57:48Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java", "diffHunk": "@@ -168,56 +194,147 @@ public AssemblyResultSet runLocalAssembly(final AssemblyRegion assemblyRegion,\n         }\n \n         // add assembled alt haplotypes to the {@code resultSet}\n-        if (generateSeqGraph) {\n-            findBestPaths(nonRefSeqGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultBySeqGraph, resultSet, aligner);\n-        } else {\n-            findBestPaths(nonRefRTGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByRTGraph, resultSet, aligner);\n+        findBestPaths(nonRefSeqGraphs, assemblyResultBySeqGraph, refHaplotype, refLoc, activeRegionExtendedLocation, resultSet, aligner);\n+    }\n+\n+    /**\n+     * Follow the kmer expansion heurisics as {@link #assemble(List, Haplotype, SAMFileHeader, SmithWatermanAligner)}, but in this case\n+     * attempt to recover haplotypes from the kmer graph and use them to assess whether to expand the kmer size.\n+     */\n+    private void assembleGraphsAndExpandKmersGivenHaplotypes(final Haplotype refHaplotype, final SimpleInterval refLoc, final SAMFileHeader header,\n+                                                             final SmithWatermanAligner aligner, final List<GATKRead> correctedReads,\n+                                                             final List<AbstractReadThreadingGraph> nonRefRTGraphs, final AssemblyResultSet resultSet,\n+                                                             final SimpleInterval activeRegionExtendedLocation) {\n+        final Map<AbstractReadThreadingGraph,AssemblyResult> assemblyResultByRTGraph = new HashMap<>();\n+        // create the graphs by calling our subclass assemble method\n+\n+        final List<AssemblyResult> savedAssemblyResults = new ArrayList<>();\n+\n+        boolean hasAdequatelyAssembledGraph = false;\n+        List<Integer> kmersToTry = getExpandedKmerList();\n+        // first, try using the requested kmer sizes\n+        for ( int i = 0; i < kmersToTry.size(); i++ ) {\n+            final int kmerSize = kmersToTry.get(i);\n+            final boolean isLastCycle = i == kmersToTry.size() - 1;\n+            if (!hasAdequatelyAssembledGraph) {\n+                AssemblyResult assembledResult = createGraph(correctedReads, refHaplotype, kmerSize, isLastCycle || dontIncreaseKmerSizesForCycles, isLastCycle || allowNonUniqueKmersInRef, header, aligner);\n+                if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION) {\n+                    // do some QC on the graph\n+                    sanityCheckGraph(assembledResult.getThreadingGraph(), refHaplotype);\n+                    assembledResult.getThreadingGraph().postProcessForHaplotypeFinding(debugGraphOutputPath, refHaplotype.getLocation());\n+                    // add it to graphs with meaningful non-reference features\n+                    assemblyResultByRTGraph.put(assembledResult.getThreadingGraph(), assembledResult);\n+                    nonRefRTGraphs.add(assembledResult.getThreadingGraph());\n+\n+                    if (graphHaplotypeHistogramPath != null) {\n+                        kmersUsedHistogram.add((double) assembledResult.getKmerSize());\n+                    }\n+\n+                    AbstractReadThreadingGraph graph = assembledResult.getThreadingGraph();\n+                    findBestPaths(Collections.singletonList(graph), Collections.singletonMap(graph, assembledResult),\n+                            refHaplotype, refLoc, activeRegionExtendedLocation, null, aligner);\n+\n+                    savedAssemblyResults.add(assembledResult);\n+\n+                    //TODO LOGIC PLAN HERE - we want to check if we have a trustworthy graph (i.e. no badly assembled haplotypes) if we do, emit it.\n+                    //TODO                 - but if we failed to assemble due to excessive looping or did have badly assembled haplotypes then we expand kmer size.\n+                    //TODO                 - If we get no variation\n+\n+                    // if asssembly didn't fail ( which is a degenerate case that occurs for some subset of graphs with difficult loops)\n+                    if (! savedAssemblyResults.get(savedAssemblyResults.size() - 1).getHaplotypeList().isEmpty()) {\n+                        // we have found our workable kmer size so lets add the results and finish\n+                        if (!assembledResult.isContainsSuspectHaplotypes()) {\n+                            for (Haplotype h : assembledResult.getHaplotypeList()) {\n+                                resultSet.add(h, assembledResult);\n+                            }\n+                            hasAdequatelyAssembledGraph = true;\n+                        }\n+                    }\n+\n+                // if no variation is discoverd in the graph don't bother expanding the kmer size.\n+                } else if (assembledResult != null && assembledResult.getStatus() == AssemblyResult.Status.JUST_ASSEMBLED_REFERENCE) {\n+                    hasAdequatelyAssembledGraph = true;\n+                }\n+            }\n         }\n \n-        // print the graphs if the appropriate debug option has been turned on\n-        if ( graphOutputPath != null ) { printGraphs(nonRefSeqGraphs); }\n-        if ( graphHaplotypeHistogramPath != null ) { haplotypeHistogram.add((double)resultSet.getHaplotypeCount()); }\n \n-        return resultSet;\n+        // This indicates that we have thrown everything away... we should go back and check that we weren't too conservative about assembly results that might otherwise be good\n+        if (!hasAdequatelyAssembledGraph) {\n+            // search for the last haplotype set that had any results, if none are found just return me\n+            // In this case we prefer the last meaningful kmer size if possible\n+            for (int i = savedAssemblyResults.size() - 1; i > 0; i --) {", "originalCommit": "16db1a126fa5fa8108364bc4bd35517520321fef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMzMDk2Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375330967", "bodyText": "For consistency this should be LINKED_DE_BRUJN_GRAPH_LONG_NAME", "author": "davidbenjamin", "createdAt": "2020-02-05T15:36:48Z", "path": "src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReadThreadingAssemblerArgumentCollection.java", "diffHunk": "@@ -23,6 +23,7 @@\n     public static final String CAPTURE_ASSEMBLY_FAILURE_BAM_LONG_NAME = \"capture-assembly-failure-bam\";\n     public static final String KMER_SIZE_LONG_NAME = \"kmer-size\";\n     public static final String DONT_INCREASE_KMER_SIZE_LONG_NAME = \"dont-increase-kmer-sizes-for-cycles\";\n+    public static final String LINKED_DE_BRUIJN_GRAPH_ARGUMENT = \"linked-de-bruijn-graph\";", "originalCommit": "9d2497935fc8251c8ba864dbd64ec010d77ce6fe", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTMzNDQ1Mg==", "url": "https://github.com/broadinstitute/gatk/pull/6394#discussion_r375334452", "bodyText": "typo: Junciton", "author": "davidbenjamin", "createdAt": "2020-02-05T15:42:08Z", "path": "src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/JunctionTreeLinkedDeBruinGraphUnitTest.java", "diffHunk": "@@ -585,6 +584,35 @@ public void testJuncitonTreeErrorCorrectionFailingIfWithinKmerSizeForConsistency\n         Assert.assertEquals(new String(bestPaths.get(0).getBases()), supportedAlt);\n     }\n \n+    @Test\n+    // test asserting that we don't make spurious edges when we are trying to recover error bases\n+    public void testJuncitonTreeErrorCorrectionNotAddingTreesWhenOverTentativeBases() {", "originalCommit": "9d2497935fc8251c8ba864dbd64ec010d77ce6fe", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dac52340c334a2feab53a1ab7d13148aea88fb05", "url": "https://github.com/broadinstitute/gatk/commit/dac52340c334a2feab53a1ab7d13148aea88fb05", "message": "resolved conflicts between old and new branches", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "814d7da49dfa0d7dfb2b90e62d91477ae1b47402", "url": "https://github.com/broadinstitute/gatk/commit/814d7da49dfa0d7dfb2b90e62d91477ae1b47402", "message": "First attempt at recovering paths that have been dropped by the graphing code based on painting covered edges and recovering them later", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "4908314e8b24b8d9c3deda2ce3b7313c8536306c", "url": "https://github.com/broadinstitute/gatk/commit/4908314e8b24b8d9c3deda2ce3b7313c8536306c", "message": "removed pruning and removed 10mer for arguments sake", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "923366894ed052eaa5513c97cc2a0a75523579d2", "url": "https://github.com/broadinstitute/gatk/commit/923366894ed052eaa5513c97cc2a0a75523579d2", "message": "tmp", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "cc04b5f0f80f66ec2079a254c79dabf43a59008c", "url": "https://github.com/broadinstitute/gatk/commit/cc04b5f0f80f66ec2079a254c79dabf43a59008c", "message": "still an inadequate ammount of stuff done, how to filter out sites?", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "1f0ae1125c905ed45f37cf71350b298774c4807a", "url": "https://github.com/broadinstitute/gatk/commit/1f0ae1125c905ed45f37cf71350b298774c4807a", "message": "working on implementaiotn", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "23fe827463ae863e282e59440a0c54180a8948fd", "url": "https://github.com/broadinstitute/gatk/commit/23fe827463ae863e282e59440a0c54180a8948fd", "message": "lets see where this wild ride takes us, now the graphs are expanded based on the haplotype recovered result", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "aeb4bd23e10e2fcdb47e030b9a146a66739976bb", "url": "https://github.com/broadinstitute/gatk/commit/aeb4bd23e10e2fcdb47e030b9a146a66739976bb", "message": "merged the two branches so hopefully both the expansion heuristics and the front pasting are accounted for", "committedDate": "2020-02-05T18:48:41Z", "type": "commit"}, {"oid": "196e531bf4eec58e38d9cdf725f8c833a631041b", "url": "https://github.com/broadinstitute/gatk/commit/196e531bf4eec58e38d9cdf725f8c833a631041b", "message": "attempt at synthesis where the old restriction rules have been done away with", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "3ab244c4d5480d0a2ed973f03ce0c64675faa7a6", "url": "https://github.com/broadinstitute/gatk/commit/3ab244c4d5480d0a2ed973f03ce0c64675faa7a6", "message": "fixed a horrible issue that would cause null pointers on real data", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "7b02e46c936882c7a1ce5bd9e95269fd86506912", "url": "https://github.com/broadinstitute/gatk/commit/7b02e46c936882c7a1ce5bd9e95269fd86506912", "message": "some cleanup and the first steps towrads disqualifying potentially badly looping paths", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "360157f56f99217296be1d3c9739ddb9a59619cd", "url": "https://github.com/broadinstitute/gatk/commit/360157f56f99217296be1d3c9739ddb9a59619cd", "message": "apparently working but possibly not who knows", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "655227c372a743f3bb6fe9a5ffd5f81fe287fd1f", "url": "https://github.com/broadinstitute/gatk/commit/655227c372a743f3bb6fe9a5ffd5f81fe287fd1f", "message": "added ErrorAcceptingTHreadingWork", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "1103ff101120b859891b6f214066796e57c42ceb", "url": "https://github.com/broadinstitute/gatk/commit/1103ff101120b859891b6f214066796e57c42ceb", "message": "removing 10mers", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "05266ec2cf882bb1388da6081a081626dd91e7a0", "url": "https://github.com/broadinstitute/gatk/commit/05266ec2cf882bb1388da6081a081626dd91e7a0", "message": "fixed the jt error correciton code and added tests", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "bf3cfaf5a13ec4de814c30524e3394b1e61d610d", "url": "https://github.com/broadinstitute/gatk/commit/bf3cfaf5a13ec4de814c30524e3394b1e61d610d", "message": "Fixxed the issue with 85mers not being properly treated if there was reference variance out to that size", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "02e6aa7fa981c88746a50685fd01fa00720f6455", "url": "https://github.com/broadinstitute/gatk/commit/02e6aa7fa981c88746a50685fd01fa00720f6455", "message": "Refactored ReadThreadingAssembler to handle both JunctionTrees and SeqGraphs without reusing too much code", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "b9a323e6c1577347092bcdc43fb8096ddc97292f", "url": "https://github.com/broadinstitute/gatk/commit/b9a323e6c1577347092bcdc43fb8096ddc97292f", "message": "turning back off the regeneration code", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "b8f2941668b8d1105c95518c185573f93d1284cf", "url": "https://github.com/broadinstitute/gatk/commit/b8f2941668b8d1105c95518c185573f93d1284cf", "message": "refactored and cleaned up the threading code. There could probably be a few more tests of the haplotype recovery but lets kick this to the reviewer", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "756522bea219e2d79cd25e9d6e18db47c3e7dc9b", "url": "https://github.com/broadinstitute/gatk/commit/756522bea219e2d79cd25e9d6e18db47c3e7dc9b", "message": "responded to the first round of comments", "committedDate": "2020-02-05T18:48:42Z", "type": "commit"}, {"oid": "6999063a12a07648b971fe3d49ffdc6c28805e0d", "url": "https://github.com/broadinstitute/gatk/commit/6999063a12a07648b971fe3d49ffdc6c28805e0d", "message": "defensive OBOB", "committedDate": "2020-02-05T18:48:43Z", "type": "commit"}, {"oid": "f266f2e23e6091fec684af75ed9985002afde3da", "url": "https://github.com/broadinstitute/gatk/commit/f266f2e23e6091fec684af75ed9985002afde3da", "message": "responding to revdiew comments again", "committedDate": "2020-02-05T18:48:43Z", "type": "commit"}, {"oid": "55ca10377437cc488465c88481edad8c7191b6fc", "url": "https://github.com/broadinstitute/gatk/commit/55ca10377437cc488465c88481edad8c7191b6fc", "message": "updating the expected output to reflect the changes from the rebase", "committedDate": "2020-02-05T19:04:44Z", "type": "commit"}, {"oid": "55ca10377437cc488465c88481edad8c7191b6fc", "url": "https://github.com/broadinstitute/gatk/commit/55ca10377437cc488465c88481edad8c7191b6fc", "message": "updating the expected output to reflect the changes from the rebase", "committedDate": "2020-02-05T19:04:44Z", "type": "forcePushed"}]}