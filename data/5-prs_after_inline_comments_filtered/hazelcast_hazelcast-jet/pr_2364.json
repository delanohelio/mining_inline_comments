{"pr_number": 2364, "pr_title": "Add test for CDC join scenario", "pr_createdAt": "2020-06-25T10:12:21Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2364", "timeline": [{"oid": "4fc316115b9c80810d55632d9de60d1c2e4b8ec8", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4fc316115b9c80810d55632d9de60d1c2e4b8ec8", "message": "Add test for CDC join scenario", "committedDate": "2020-06-25T10:06:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxMjUxMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446812510", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return jet.<Integer, OrdersOfCustomer>getMap(name).entrySet().stream()\n          \n          \n            \n                            .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n          \n          \n            \n                    return new HashMap<>(jet.getMap(name));", "author": "frant-hartm", "createdAt": "2020-06-29T07:02:33Z", "path": "extensions/cdc-postgres/src/test/java/com/hazelcast/jet/cdc/postgres/MultiTableCacheIntegrationTest.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc.postgres;\n+\n+import com.hazelcast.jet.JetInstance;\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.jet.cdc.RecordPart;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.function.TriFunction;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+import com.hazelcast.map.EntryProcessor;\n+import org.jetbrains.annotations.NotNull;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class MultiTableCacheIntegrationTest extends AbstractPostgresCdcIntegrationTest {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+    private static final String CACHE = \"cache\";\n+    private static final int REPEATS = 1000;\n+\n+    @Test\n+    public void ordersOfCustomers() throws Exception {\n+        StreamSource<ChangeRecord> source = sourceBuilder(\"source\")\n+                .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+                .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));\n+\n+        // when\n+        JetInstance jet = createJetMembers(1)[0];\n+        Job job = jet.newJob(pipeline);\n+        //then\n+        Map<Integer, OrdersOfCustomer> expected = toMap(\n+        new OrdersOfCustomer(\n+                new Customer(1001, \"Sally\", \"Thomas\", \"sally.thomas@acme.com\"),\n+                new Order(10001, new Date(1452902400000L), 1001, 1, 102)),\n+        new OrdersOfCustomer(\n+                new Customer(1002, \"George\", \"Bailey\", \"gbailey@foobar.com\"),\n+                new Order(10002, new Date(1452988800000L) , 1002, 2, 105),\n+                new Order(10003, new Date(1455840000000L), 1002, 2, 106)),\n+        new OrdersOfCustomer(\n+                new Customer(1003, \"Edward\", \"Walker\", \"ed@walker.com\"),\n+                new Order(10004, new Date(1456012800000L), 1003, 1, 107)),\n+        new OrdersOfCustomer(\n+                new Customer(1004, \"Anne\", \"Kretchmar\", \"annek@noanswer.org\")));\n+        assertEqualsEventually(() -> getIMapContent(jet, CACHE), expected);\n+\n+        //when\n+        try (Connection connection = DriverManager.getConnection(postgres.getJdbcUrl(), postgres.getUsername(),\n+                postgres.getPassword())) {\n+            connection.setSchema(\"inventory\");\n+            Statement statement = connection.createStatement();\n+            for (int i = 1; i <= REPEATS; i++) {\n+                statement.addBatch(\"UPDATE customers SET first_name='Anne\" + i + \"' WHERE id=1004\");\n+\n+                statement.addBatch(\"INSERT INTO customers VALUES (1005, 'Jason', 'Bourne', 'jason@bourne.org')\");\n+                statement.addBatch(\"DELETE FROM customers WHERE id=1005\");\n+\n+                statement.addBatch(\"UPDATE orders SET quantity='\" + i + \"' WHERE id=10004\");\n+\n+                statement.addBatch(\"DELETE FROM orders WHERE id=10003\");\n+                statement.addBatch(\"INSERT INTO orders VALUES (10003, '2016-02-19', 1002, 2, 106)\");\n+            }\n+            statement.executeBatch();\n+        }\n+        //then\n+        expected = toMap(\n+                new OrdersOfCustomer(\n+                        new Customer(1001, \"Sally\", \"Thomas\", \"sally.thomas@acme.com\"),\n+                        new Order(10001, new Date(1452902400000L), 1001, 1, 102)),\n+                new OrdersOfCustomer(\n+                        new Customer(1002, \"George\", \"Bailey\", \"gbailey@foobar.com\"),\n+                        new Order(10002, new Date(1452988800000L) , 1002, 2, 105),\n+                        new Order(10003, new Date(1455840000000L), 1002, 2, 106)),\n+                new OrdersOfCustomer(\n+                        new Customer(1003, \"Edward\", \"Walker\", \"ed@walker.com\"),\n+                        new Order(10004, new Date(1456012800000L), 1003, REPEATS, 107)),\n+                new OrdersOfCustomer(\n+                        new Customer(1004, \"Anne\" + REPEATS, \"Kretchmar\", \"annek@noanswer.org\")));\n+        expected.put(1005, new OrdersOfCustomer());\n+        assertEqualsEventually(() -> getIMapContent(jet, CACHE), expected);\n+    }\n+\n+    private StreamStage<ChangeRecord> fixOrdering(StreamStage<ChangeRecord> input) {\n+        return input\n+                .groupingKey(ChangeRecord::key)\n+                .mapStateful(\n+                        TimeUnit.SECONDS.toMillis(10),\n+                        () -> new Sequence(0, 0),\n+                        (lastSequence, key, record) -> {\n+                            ChangeRecordImpl recordImpl = (ChangeRecordImpl) record;\n+                            long source = recordImpl.getSequenceSource();\n+                            long sequence = recordImpl.getSequenceValue();\n+                            if (lastSequence.update(source, sequence)) {\n+                                return record;\n+                            }\n+                            return null;\n+                        },\n+                        (TriFunction<Sequence, RecordPart, Long, ChangeRecord>) (sequence, recordPart, aLong) -> null);\n+    }\n+\n+    @NotNull\n+    private static Map<Integer, OrdersOfCustomer> getIMapContent(JetInstance jet, String name) {\n+        return jet.<Integer, OrdersOfCustomer>getMap(name).entrySet().stream()\n+                .collect(Collectors.toMap(Entry::getKey, Entry::getValue));", "originalCommit": "4fc316115b9c80810d55632d9de60d1c2e4b8ec8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwMjEzMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446902132", "bodyText": "Ok.", "author": "jbartok", "createdAt": "2020-06-29T11:36:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxMjUxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxNTA3Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446815073", "bodyText": "Will this work when loading larger amount of data from scratch?", "author": "frant-hartm", "createdAt": "2020-06-29T07:08:24Z", "path": "extensions/cdc-postgres/src/test/java/com/hazelcast/jet/cdc/postgres/MultiTableCacheIntegrationTest.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc.postgres;\n+\n+import com.hazelcast.jet.JetInstance;\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.jet.cdc.RecordPart;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.function.TriFunction;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+import com.hazelcast.map.EntryProcessor;\n+import org.jetbrains.annotations.NotNull;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class MultiTableCacheIntegrationTest extends AbstractPostgresCdcIntegrationTest {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+    private static final String CACHE = \"cache\";\n+    private static final int REPEATS = 1000;\n+\n+    @Test\n+    public void ordersOfCustomers() throws Exception {\n+        StreamSource<ChangeRecord> source = sourceBuilder(\"source\")\n+                .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+                .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));", "originalCommit": "4fc316115b9c80810d55632d9de60d1c2e4b8ec8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwNTc0MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446905740", "bodyText": "You mean if the state used in the mapStateful from fixOrdering expires or not before a large initial snapshot is over. It should not, since all the events have the same event time in the snapshot and there is no watermark beyond that.", "author": "jbartok", "createdAt": "2020-06-29T11:42:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxNTA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxNzI2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446817265", "bodyText": "I hoped to have\nclass Customer {\n  Set<Order> orders;\n}\n\nis there anything blocking us from having this? The OrdersOfCustomer is kind of equivalent, but not as nice.", "author": "frant-hartm", "createdAt": "2020-06-29T07:13:17Z", "path": "extensions/cdc-postgres/src/test/java/com/hazelcast/jet/cdc/postgres/MultiTableCacheIntegrationTest.java", "diffHunk": "@@ -0,0 +1,314 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.cdc.postgres;\n+\n+import com.hazelcast.jet.JetInstance;\n+import com.hazelcast.jet.Job;\n+import com.hazelcast.jet.cdc.ChangeRecord;\n+import com.hazelcast.jet.cdc.Operation;\n+import com.hazelcast.jet.cdc.ParsingException;\n+import com.hazelcast.jet.cdc.RecordPart;\n+import com.hazelcast.jet.cdc.impl.ChangeRecordImpl;\n+import com.hazelcast.jet.function.TriFunction;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.Sinks;\n+import com.hazelcast.jet.pipeline.StreamSource;\n+import com.hazelcast.jet.pipeline.StreamStage;\n+import com.hazelcast.map.EntryProcessor;\n+import org.jetbrains.annotations.NotNull;\n+import org.junit.Test;\n+\n+import java.io.Serializable;\n+import java.sql.Connection;\n+import java.sql.DriverManager;\n+import java.sql.Statement;\n+import java.util.Arrays;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class MultiTableCacheIntegrationTest extends AbstractPostgresCdcIntegrationTest {\n+\n+    private static final int MAX_CONCURRENT_OPERATIONS = 1;\n+    private static final String CACHE = \"cache\";\n+    private static final int REPEATS = 1000;\n+\n+    @Test\n+    public void ordersOfCustomers() throws Exception {\n+        StreamSource<ChangeRecord> source = sourceBuilder(\"source\")\n+                .setTableWhitelist(\"inventory.customers\", \"inventory.orders\")\n+                .build();\n+\n+        Pipeline pipeline = Pipeline.create();\n+        StreamStage<ChangeRecord> allRecords = pipeline.readFrom(source)\n+                .withNativeTimestamps(0);\n+\n+        allRecords.filter(r -> r.table().equals(\"customers\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.key().toMap().get(\"id\"),\n+                        CustomerEntryProcessor::new\n+                ));\n+\n+        allRecords.filter(r -> r.table().equals(\"orders\"))\n+                .apply(this::fixOrdering)\n+                .writeTo(Sinks.mapWithEntryProcessor(MAX_CONCURRENT_OPERATIONS, CACHE,\n+                        record -> (Integer) record.value().toMap().get(\"purchaser\"),\n+                        OrderEntryProcessor::new\n+                ));\n+\n+        // when\n+        JetInstance jet = createJetMembers(1)[0];\n+        Job job = jet.newJob(pipeline);\n+        //then\n+        Map<Integer, OrdersOfCustomer> expected = toMap(\n+        new OrdersOfCustomer(\n+                new Customer(1001, \"Sally\", \"Thomas\", \"sally.thomas@acme.com\"),\n+                new Order(10001, new Date(1452902400000L), 1001, 1, 102)),\n+        new OrdersOfCustomer(\n+                new Customer(1002, \"George\", \"Bailey\", \"gbailey@foobar.com\"),\n+                new Order(10002, new Date(1452988800000L) , 1002, 2, 105),\n+                new Order(10003, new Date(1455840000000L), 1002, 2, 106)),\n+        new OrdersOfCustomer(\n+                new Customer(1003, \"Edward\", \"Walker\", \"ed@walker.com\"),\n+                new Order(10004, new Date(1456012800000L), 1003, 1, 107)),\n+        new OrdersOfCustomer(\n+                new Customer(1004, \"Anne\", \"Kretchmar\", \"annek@noanswer.org\")));\n+        assertEqualsEventually(() -> getIMapContent(jet, CACHE), expected);\n+\n+        //when\n+        try (Connection connection = DriverManager.getConnection(postgres.getJdbcUrl(), postgres.getUsername(),\n+                postgres.getPassword())) {\n+            connection.setSchema(\"inventory\");\n+            Statement statement = connection.createStatement();\n+            for (int i = 1; i <= REPEATS; i++) {\n+                statement.addBatch(\"UPDATE customers SET first_name='Anne\" + i + \"' WHERE id=1004\");\n+\n+                statement.addBatch(\"INSERT INTO customers VALUES (1005, 'Jason', 'Bourne', 'jason@bourne.org')\");\n+                statement.addBatch(\"DELETE FROM customers WHERE id=1005\");\n+\n+                statement.addBatch(\"UPDATE orders SET quantity='\" + i + \"' WHERE id=10004\");\n+\n+                statement.addBatch(\"DELETE FROM orders WHERE id=10003\");\n+                statement.addBatch(\"INSERT INTO orders VALUES (10003, '2016-02-19', 1002, 2, 106)\");\n+            }\n+            statement.executeBatch();\n+        }\n+        //then\n+        expected = toMap(\n+                new OrdersOfCustomer(\n+                        new Customer(1001, \"Sally\", \"Thomas\", \"sally.thomas@acme.com\"),\n+                        new Order(10001, new Date(1452902400000L), 1001, 1, 102)),\n+                new OrdersOfCustomer(\n+                        new Customer(1002, \"George\", \"Bailey\", \"gbailey@foobar.com\"),\n+                        new Order(10002, new Date(1452988800000L) , 1002, 2, 105),\n+                        new Order(10003, new Date(1455840000000L), 1002, 2, 106)),\n+                new OrdersOfCustomer(\n+                        new Customer(1003, \"Edward\", \"Walker\", \"ed@walker.com\"),\n+                        new Order(10004, new Date(1456012800000L), 1003, REPEATS, 107)),\n+                new OrdersOfCustomer(\n+                        new Customer(1004, \"Anne\" + REPEATS, \"Kretchmar\", \"annek@noanswer.org\")));\n+        expected.put(1005, new OrdersOfCustomer());\n+        assertEqualsEventually(() -> getIMapContent(jet, CACHE), expected);\n+    }\n+\n+    private StreamStage<ChangeRecord> fixOrdering(StreamStage<ChangeRecord> input) {\n+        return input\n+                .groupingKey(ChangeRecord::key)\n+                .mapStateful(\n+                        TimeUnit.SECONDS.toMillis(10),\n+                        () -> new Sequence(0, 0),\n+                        (lastSequence, key, record) -> {\n+                            ChangeRecordImpl recordImpl = (ChangeRecordImpl) record;\n+                            long source = recordImpl.getSequenceSource();\n+                            long sequence = recordImpl.getSequenceValue();\n+                            if (lastSequence.update(source, sequence)) {\n+                                return record;\n+                            }\n+                            return null;\n+                        },\n+                        (TriFunction<Sequence, RecordPart, Long, ChangeRecord>) (sequence, recordPart, aLong) -> null);\n+    }\n+\n+    @NotNull\n+    private static Map<Integer, OrdersOfCustomer> getIMapContent(JetInstance jet, String name) {\n+        return jet.<Integer, OrdersOfCustomer>getMap(name).entrySet().stream()\n+                .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+    }\n+\n+    @NotNull\n+    private static Map<Integer, OrdersOfCustomer> toMap(OrdersOfCustomer... ordersOfCustomers) {\n+        return Arrays.stream(ordersOfCustomers).collect(Collectors.toMap(\n+                orders -> orders.getCustomer().getId(), Function.identity()));\n+    }\n+\n+    private static class Sequence {\n+\n+        private long source;\n+        private long sequence;\n+\n+        Sequence(long source, long sequence) {\n+            this.source = source;\n+            this.sequence = sequence;\n+        }\n+\n+        boolean update(long source, long sequence) {\n+            if (this.source != source) { //sequence source changed for key\n+                this.source = source;\n+                this.sequence = sequence;\n+                return true;\n+            }\n+\n+            if (this.sequence < sequence) { //sequence is newer than previous for key\n+                this.sequence = sequence;\n+                return true;\n+            }\n+\n+            return false;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"source=\" + source + \", sequence=\" + sequence;\n+        }\n+    }\n+\n+    private static class OrdersOfCustomer implements Serializable {", "originalCommit": "4fc316115b9c80810d55632d9de60d1c2e4b8ec8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjkwNTUyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2364#discussion_r446905528", "bodyText": "We can change it. The thing is though, that: 1) neither the current nor the suggested solution will actually work in a real cluster, due to IMDG not knowing how to deserialize these classes 2) the purpose of this test is to prove that we have SOME way of doing this join correctly and getting the data into IMDG. So... beautifying it should happen probably some place else.", "author": "jbartok", "createdAt": "2020-06-29T11:42:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjgxNzI2NQ=="}], "type": "inlineReview"}, {"oid": "495b233763a6107297e8519ede679d1dc5cdad2f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/495b233763a6107297e8519ede679d1dc5cdad2f", "message": "Simplify code", "committedDate": "2020-06-29T11:55:21Z", "type": "commit"}]}