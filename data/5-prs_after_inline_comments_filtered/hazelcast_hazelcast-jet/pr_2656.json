{"pr_number": 2656, "pr_title": "Amazon Kinesis source & sink", "pr_createdAt": "2020-11-13T06:27:25Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2656", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2Mzk2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556463965", "bodyText": "can we rename this to something ending with Future. I think we can also drop the describeStream prefix for this and other fields. The only thing we are really interested is the shard-count I guess", "author": "gurbuzali", "createdAt": "2021-01-13T11:50:37Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/ShardCountMonitor.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.DescribeStreamSummaryResult;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class ShardCountMonitor extends AbstractShardWorker {\n+\n+    /**\n+     * DescribeStreamSummary operations are limited to 20 per second, per account.\n+     */\n+    private static final int DESCRIBE_STREAM_OPERATIONS_ALLOWED_PER_SECOND = 20;\n+\n+    /**\n+     * We don't want to issue describe stream operations at the peak allowed rate.\n+     */\n+    private static final double RATIO_OF_DESCRIBE_STREAM_RATE_UTILIZED = 0.1;\n+\n+    private final AtomicInteger shardCount;\n+    private final RandomizedRateTracker descriteStreamRateTracker;\n+    private final RetryTracker describeStreamRetryTracker;\n+\n+    private Future<DescribeStreamSummaryResult> describeStreamResult;", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA4MjUyOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557082529", "bodyText": "Do you have arguments beyond personal preference? If not, I prefer them as they are.", "author": "jbartok", "createdAt": "2021-01-14T07:05:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2Mzk2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzIwMTE0MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557201141", "bodyText": "\ud83d\udc4d", "author": "gurbuzali", "createdAt": "2021-01-14T08:36:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2Mzk2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MDU1Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556470552", "bodyText": "can be used context.totalParallelism()", "author": "gurbuzali", "createdAt": "2021-01-13T12:03:22Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,502 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.internal.metrics.Probe;\n+import com.hazelcast.internal.metrics.ProbeUnit;\n+import com.hazelcast.internal.util.counters.Counter;\n+import com.hazelcast.internal.util.counters.SwCounter;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.jet.kinesis.KinesisSinks;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.lang.System.nanoTime;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    /**\n+     * Each shard can ingest a maximum of a 1000 records per second.\n+     */\n+    private static final int MAX_RECORD_PER_SHARD_PER_SECOND = 1000;\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    /**\n+     * Since we are using PutRecords for its batching effect, we don't want\n+     * the batch size to be so small as to negate all benefits.\n+     */\n+    private static final int MIN_RECORDS_IN_REQUEST = 10;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * Kinesis always uses UTF-8 to encode strings.\n+     */\n+    private static final Charset KINESIS_STRING_ENCODING = StandardCharsets.UTF_8;\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nullable\n+    private final ShardCountMonitor monitor;\n+    @Nonnull\n+    private final AtomicInteger shardCountProvider;\n+    @Nonnull\n+    private final Buffer<T> buffer;\n+\n+    @Probe(name = KinesisSinks.BATCH_SIZE_METRIC, unit = ProbeUnit.COUNT)\n+    private final Counter batchSizeMetric;\n+    @Probe(name = KinesisSinks.THROTTLING_SLEEP_METRIC, unit = ProbeUnit.MS)\n+    private final Counter sleepMetric = SwCounter.newSwCounter();\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+    private int shardCount;\n+    private int sinkCount;\n+\n+    private Future<PutRecordsResult> sendResult;\n+    private long nextSendTime = nanoTime();\n+    private final RetryTracker sendRetryTracker;\n+\n+    private final ThroughputController throughputController = new ThroughputController();\n+\n+    public KinesisSinkP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn,\n+            @Nullable ShardCountMonitor monitor,\n+            @Nonnull AtomicInteger shardCountProvider,\n+            @Nonnull RetryStrategy retryStrategy\n+            ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.monitor = monitor;\n+        this.shardCountProvider = shardCountProvider;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+        this.batchSizeMetric = SwCounter.newSwCounter(buffer.getCapacity());\n+        this.sendRetryTracker = new RetryTracker(retryStrategy);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        sinkCount = context.memberCount() * context.localParallelism();", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA4Mzg0MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557083840", "bodyText": "Ok, I will update it, but I feel like this is a redundancy in the API we should not have.", "author": "jbartok", "createdAt": "2021-01-14T07:07:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MDU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNzE1Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556537153", "bodyText": "we could use Arrays.setAll to initialize the arry instead of creating a stream for it\n            this.entries = new BufferEntry[MAX_RECORDS_IN_REQUEST];\n            Arrays.setAll(entries, value -> new BufferEntry());", "author": "gurbuzali", "createdAt": "2021-01-13T13:57:04Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,502 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.internal.metrics.Probe;\n+import com.hazelcast.internal.metrics.ProbeUnit;\n+import com.hazelcast.internal.util.counters.Counter;\n+import com.hazelcast.internal.util.counters.SwCounter;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.jet.kinesis.KinesisSinks;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.lang.System.nanoTime;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    /**\n+     * Each shard can ingest a maximum of a 1000 records per second.\n+     */\n+    private static final int MAX_RECORD_PER_SHARD_PER_SECOND = 1000;\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    /**\n+     * Since we are using PutRecords for its batching effect, we don't want\n+     * the batch size to be so small as to negate all benefits.\n+     */\n+    private static final int MIN_RECORDS_IN_REQUEST = 10;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * Kinesis always uses UTF-8 to encode strings.\n+     */\n+    private static final Charset KINESIS_STRING_ENCODING = StandardCharsets.UTF_8;\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nullable\n+    private final ShardCountMonitor monitor;\n+    @Nonnull\n+    private final AtomicInteger shardCountProvider;\n+    @Nonnull\n+    private final Buffer<T> buffer;\n+\n+    @Probe(name = KinesisSinks.BATCH_SIZE_METRIC, unit = ProbeUnit.COUNT)\n+    private final Counter batchSizeMetric;\n+    @Probe(name = KinesisSinks.THROTTLING_SLEEP_METRIC, unit = ProbeUnit.MS)\n+    private final Counter sleepMetric = SwCounter.newSwCounter();\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+    private int shardCount;\n+    private int sinkCount;\n+\n+    private Future<PutRecordsResult> sendResult;\n+    private long nextSendTime = nanoTime();\n+    private final RetryTracker sendRetryTracker;\n+\n+    private final ThroughputController throughputController = new ThroughputController();\n+\n+    public KinesisSinkP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn,\n+            @Nullable ShardCountMonitor monitor,\n+            @Nonnull AtomicInteger shardCountProvider,\n+            @Nonnull RetryStrategy retryStrategy\n+            ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.monitor = monitor;\n+        this.shardCountProvider = shardCountProvider;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+        this.batchSizeMetric = SwCounter.newSwCounter(buffer.getCapacity());\n+        this.sendRetryTracker = new RetryTracker(retryStrategy);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        sinkCount = context.memberCount() * context.localParallelism();\n+        helper = new KinesisHelper(kinesis, stream);\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        if (monitor != null) {\n+            monitor.run();\n+        }\n+\n+        updateThroughputLimitations();\n+\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            initSending(inbox);\n+        }\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            if (buffer.isEmpty()) {\n+                return true;\n+            }\n+            initSending(null);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean saveToSnapshot() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        return sendResult == null;\n+    }\n+\n+    private void updateThroughputLimitations() {\n+        int newShardCount = shardCountProvider.get();\n+        if (newShardCount > 0 && shardCount != newShardCount) {\n+            buffer.setCapacity(throughputController.computeBatchSize(newShardCount, sinkCount));\n+            batchSizeMetric.set(buffer.getCapacity());\n+\n+            shardCount = newShardCount;\n+        }\n+    }\n+\n+    private void initSending(@Nullable Inbox inbox) {\n+        if (inbox != null) {\n+            bufferFromInbox(inbox);\n+        }\n+        attemptToDispatchBufferContent();\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty()) {\n+            return;\n+        }\n+\n+        long currentTime = nanoTime();\n+        if (currentTime < nextSendTime) {\n+            return;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+        nextSendTime = currentTime;\n+    }\n+\n+    private void checkIfSendingFinished() {\n+        if (sendResult.isDone()) {\n+            PutRecordsResult result;\n+            try {\n+                result = helper.readResult(this.sendResult);\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                dealWithThroughputExceeded(\"Data throughput rate exceeded. Backing off and retrying in %d ms\");\n+                return;\n+            } catch (SdkClientException sce) {\n+                dealWithSendFailure(sce);\n+                return;\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            } finally {\n+                sendResult = null;\n+            }\n+\n+            pruneSentFromBuffer(result);\n+            if (result.getFailedRecordCount() > 0) {\n+                dealWithThroughputExceeded(\"Failed to send \" + result.getFailedRecordCount() + \" (out of \" +\n+                        result.getRecords().size() + \") record(s) to stream '\" + stream +\n+                        \"'. Sending will be retried in %d ms, message reordering is likely.\");\n+            } else {\n+                long sleepTimeNanos = throughputController.markSuccess();\n+                this.nextSendTime += sleepTimeNanos;\n+                this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+                sendRetryTracker.reset();\n+            }\n+        }\n+    }\n+\n+    private void dealWithSendFailure(@Nonnull Exception failure) {\n+        sendRetryTracker.attemptFailed();\n+        if (sendRetryTracker.shouldTryAgain()) {\n+            long timeoutMillis = sendRetryTracker.getNextWaitTimeMillis();\n+            logger.warning(String.format(\"Failed to send records, will retry in %d ms. Cause: %s\",\n+                    timeoutMillis, failure.getMessage()));\n+            nextSendTime = System.nanoTime() + MILLISECONDS.toNanos(timeoutMillis);\n+        } else {\n+            throw rethrow(failure);\n+        }\n+\n+    }\n+\n+    private void dealWithThroughputExceeded(@Nonnull String message) {\n+        long sleepTimeNanos = throughputController.markFailure();\n+        this.nextSendTime += sleepTimeNanos;\n+        this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+        logger.warning(String.format(message, NANOSECONDS.toMillis(sleepTimeNanos)));\n+    }\n+\n+    private void pruneSentFromBuffer(@Nullable PutRecordsResult result) {\n+        if (result == null) {\n+            return;\n+        }\n+\n+        List<PutRecordsResultEntry> resultEntries = result.getRecords();\n+        if (result.getFailedRecordCount() > 0) {\n+            for (int i = resultEntries.size() - 1; i >= 0; i--) {\n+                PutRecordsResultEntry resultEntry = resultEntries.get(i);\n+                if (resultEntry.getErrorCode() == null) {\n+                    buffer.remove(i);\n+                }\n+            }\n+        } else {\n+            buffer.remove(0, resultEntries.size());\n+        }\n+    }\n+\n+    private static class Buffer<T> {\n+\n+        private final FunctionEx<T, String> keyFn;\n+        private final FunctionEx<T, byte[]> valueFn;\n+\n+        private final BufferEntry[] entries;\n+        private int entryCount;\n+        private int totalEntrySize;\n+        private int capacity;\n+\n+        Buffer(FunctionEx<T, String> keyFn, FunctionEx<T, byte[]> valueFn) {\n+            this.keyFn = keyFn;\n+            this.valueFn = valueFn;\n+            this.entries = initEntries();", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA4NTE1OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557085159", "bodyText": "Why not create a stream for it? It's safer, more readable code and performance is not a concern, since it's a non-frequent operation.", "author": "jbartok", "createdAt": "2021-01-14T07:08:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNzE1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjYwNzQxOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556607418", "bodyText": "buffer.remove(index) moves the entry at the given index to the end and shifts all the entries after the index. And we do it for each successful entry one by one. I suggest to add a retainFailedEntries method to Buffer, something like this:\n        public void retainFailedEntries(List<PutRecordsResultEntry> records) {\n            int startIndex = 0;\n            for (int index = 0; index < records.size(); index++) {\n                if (records.get(index).getErrorCode() != null) {\n                    swap(startIndex++, index);\n                } else {\n                    totalEntrySize -= entries[index].encodedSize;\n                    entryCount--;\n                }\n            }\n        }\n\n        private void swap(int a, int b) {\n            BufferEntry temp = entries[a];\n            entries[a] = entries[b];\n            entries[b] = temp;\n        }\n\nThe method iterates over the records and if failed moves it to the beginning of the array by swapping entries.\nAlso the below remove(index, count) can be replaced with just clear I guess. It is called when there is no failed record which means the record count should be equal to the entryCount of the buffer. In this case current implementation already delegates to clear.", "author": "gurbuzali", "createdAt": "2021-01-13T15:30:29Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,502 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.internal.metrics.Probe;\n+import com.hazelcast.internal.metrics.ProbeUnit;\n+import com.hazelcast.internal.util.counters.Counter;\n+import com.hazelcast.internal.util.counters.SwCounter;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.jet.kinesis.KinesisSinks;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.lang.System.nanoTime;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    /**\n+     * Each shard can ingest a maximum of a 1000 records per second.\n+     */\n+    private static final int MAX_RECORD_PER_SHARD_PER_SECOND = 1000;\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    /**\n+     * Since we are using PutRecords for its batching effect, we don't want\n+     * the batch size to be so small as to negate all benefits.\n+     */\n+    private static final int MIN_RECORDS_IN_REQUEST = 10;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * Kinesis always uses UTF-8 to encode strings.\n+     */\n+    private static final Charset KINESIS_STRING_ENCODING = StandardCharsets.UTF_8;\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nullable\n+    private final ShardCountMonitor monitor;\n+    @Nonnull\n+    private final AtomicInteger shardCountProvider;\n+    @Nonnull\n+    private final Buffer<T> buffer;\n+\n+    @Probe(name = KinesisSinks.BATCH_SIZE_METRIC, unit = ProbeUnit.COUNT)\n+    private final Counter batchSizeMetric;\n+    @Probe(name = KinesisSinks.THROTTLING_SLEEP_METRIC, unit = ProbeUnit.MS)\n+    private final Counter sleepMetric = SwCounter.newSwCounter();\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+    private int shardCount;\n+    private int sinkCount;\n+\n+    private Future<PutRecordsResult> sendResult;\n+    private long nextSendTime = nanoTime();\n+    private final RetryTracker sendRetryTracker;\n+\n+    private final ThroughputController throughputController = new ThroughputController();\n+\n+    public KinesisSinkP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn,\n+            @Nullable ShardCountMonitor monitor,\n+            @Nonnull AtomicInteger shardCountProvider,\n+            @Nonnull RetryStrategy retryStrategy\n+            ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.monitor = monitor;\n+        this.shardCountProvider = shardCountProvider;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+        this.batchSizeMetric = SwCounter.newSwCounter(buffer.getCapacity());\n+        this.sendRetryTracker = new RetryTracker(retryStrategy);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        sinkCount = context.memberCount() * context.localParallelism();\n+        helper = new KinesisHelper(kinesis, stream);\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        if (monitor != null) {\n+            monitor.run();\n+        }\n+\n+        updateThroughputLimitations();\n+\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            initSending(inbox);\n+        }\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            if (buffer.isEmpty()) {\n+                return true;\n+            }\n+            initSending(null);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean saveToSnapshot() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        return sendResult == null;\n+    }\n+\n+    private void updateThroughputLimitations() {\n+        int newShardCount = shardCountProvider.get();\n+        if (newShardCount > 0 && shardCount != newShardCount) {\n+            buffer.setCapacity(throughputController.computeBatchSize(newShardCount, sinkCount));\n+            batchSizeMetric.set(buffer.getCapacity());\n+\n+            shardCount = newShardCount;\n+        }\n+    }\n+\n+    private void initSending(@Nullable Inbox inbox) {\n+        if (inbox != null) {\n+            bufferFromInbox(inbox);\n+        }\n+        attemptToDispatchBufferContent();\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty()) {\n+            return;\n+        }\n+\n+        long currentTime = nanoTime();\n+        if (currentTime < nextSendTime) {\n+            return;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+        nextSendTime = currentTime;\n+    }\n+\n+    private void checkIfSendingFinished() {\n+        if (sendResult.isDone()) {\n+            PutRecordsResult result;\n+            try {\n+                result = helper.readResult(this.sendResult);\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                dealWithThroughputExceeded(\"Data throughput rate exceeded. Backing off and retrying in %d ms\");\n+                return;\n+            } catch (SdkClientException sce) {\n+                dealWithSendFailure(sce);\n+                return;\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            } finally {\n+                sendResult = null;\n+            }\n+\n+            pruneSentFromBuffer(result);\n+            if (result.getFailedRecordCount() > 0) {\n+                dealWithThroughputExceeded(\"Failed to send \" + result.getFailedRecordCount() + \" (out of \" +\n+                        result.getRecords().size() + \") record(s) to stream '\" + stream +\n+                        \"'. Sending will be retried in %d ms, message reordering is likely.\");\n+            } else {\n+                long sleepTimeNanos = throughputController.markSuccess();\n+                this.nextSendTime += sleepTimeNanos;\n+                this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+                sendRetryTracker.reset();\n+            }\n+        }\n+    }\n+\n+    private void dealWithSendFailure(@Nonnull Exception failure) {\n+        sendRetryTracker.attemptFailed();\n+        if (sendRetryTracker.shouldTryAgain()) {\n+            long timeoutMillis = sendRetryTracker.getNextWaitTimeMillis();\n+            logger.warning(String.format(\"Failed to send records, will retry in %d ms. Cause: %s\",\n+                    timeoutMillis, failure.getMessage()));\n+            nextSendTime = System.nanoTime() + MILLISECONDS.toNanos(timeoutMillis);\n+        } else {\n+            throw rethrow(failure);\n+        }\n+\n+    }\n+\n+    private void dealWithThroughputExceeded(@Nonnull String message) {\n+        long sleepTimeNanos = throughputController.markFailure();\n+        this.nextSendTime += sleepTimeNanos;\n+        this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+        logger.warning(String.format(message, NANOSECONDS.toMillis(sleepTimeNanos)));\n+    }\n+\n+    private void pruneSentFromBuffer(@Nullable PutRecordsResult result) {\n+        if (result == null) {\n+            return;\n+        }\n+\n+        List<PutRecordsResultEntry> resultEntries = result.getRecords();\n+        if (result.getFailedRecordCount() > 0) {\n+            for (int i = resultEntries.size() - 1; i >= 0; i--) {\n+                PutRecordsResultEntry resultEntry = resultEntries.get(i);\n+                if (resultEntry.getErrorCode() == null) {\n+                    buffer.remove(i);", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc2MjIwOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556762208", "bodyText": "we need to change the content method too, in order to apply above logic.\n.limit(Math.min(entryCount, capacity)) -> .limit(entryCount)\nthis means if capacity changes just before we send a batch, we'll not take it into effect for this batch but it'll be used when filling the buffer for the next batch.", "author": "gurbuzali", "createdAt": "2021-01-13T19:05:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjYwNzQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA5MzU3MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557093571", "bodyText": "Yeah, good points. Had a version similar to this, but have removed it after some comments from Viliam. But will take another look, this looks correct to me now.", "author": "jbartok", "createdAt": "2021-01-14T07:19:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjYwNzQxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzEyMjEyOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557122129", "bodyText": "After looking through it I've realized that this current, convoluted solution came to be because, after making the send window of variable size, it was possible to have send results of a size different than how many items were actually in the buffer, so the logic needed to be more complicated. However it's not the case now, in the final version, so yes, we can make the changes you've suggested and they are much more efficient.", "author": "jbartok", "createdAt": "2021-01-14T07:45:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjYwNzQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjYyMTUwNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556621505", "bodyText": "again having a Future at the end of the field name can help the code reader", "author": "gurbuzali", "createdAt": "2021-01-13T15:47:28Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,502 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.internal.metrics.Probe;\n+import com.hazelcast.internal.metrics.ProbeUnit;\n+import com.hazelcast.internal.util.counters.Counter;\n+import com.hazelcast.internal.util.counters.SwCounter;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.jet.kinesis.KinesisSinks;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.lang.System.nanoTime;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    /**\n+     * Each shard can ingest a maximum of a 1000 records per second.\n+     */\n+    private static final int MAX_RECORD_PER_SHARD_PER_SECOND = 1000;\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    /**\n+     * Since we are using PutRecords for its batching effect, we don't want\n+     * the batch size to be so small as to negate all benefits.\n+     */\n+    private static final int MIN_RECORDS_IN_REQUEST = 10;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * Kinesis always uses UTF-8 to encode strings.\n+     */\n+    private static final Charset KINESIS_STRING_ENCODING = StandardCharsets.UTF_8;\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nullable\n+    private final ShardCountMonitor monitor;\n+    @Nonnull\n+    private final AtomicInteger shardCountProvider;\n+    @Nonnull\n+    private final Buffer<T> buffer;\n+\n+    @Probe(name = KinesisSinks.BATCH_SIZE_METRIC, unit = ProbeUnit.COUNT)\n+    private final Counter batchSizeMetric;\n+    @Probe(name = KinesisSinks.THROTTLING_SLEEP_METRIC, unit = ProbeUnit.MS)\n+    private final Counter sleepMetric = SwCounter.newSwCounter();\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+    private int shardCount;\n+    private int sinkCount;\n+\n+    private Future<PutRecordsResult> sendResult;", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3MjQ4OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556772488", "bodyText": "we encode the key to UTF8 just to get the byte length of key, can't we use the unicodeCharsInKey*3. the actual byte length will be less than that amount most of the time. we don't need to be that accurate I think and this is on the hot path of the sink, it encodes each and every one of the passed key.", "author": "gurbuzali", "createdAt": "2021-01-13T19:23:14Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,502 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.internal.metrics.Probe;\n+import com.hazelcast.internal.metrics.ProbeUnit;\n+import com.hazelcast.internal.util.counters.Counter;\n+import com.hazelcast.internal.util.counters.SwCounter;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.jet.kinesis.KinesisSinks;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.Charset;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.lang.System.nanoTime;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.NANOSECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    /**\n+     * Each shard can ingest a maximum of a 1000 records per second.\n+     */\n+    private static final int MAX_RECORD_PER_SHARD_PER_SECOND = 1000;\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    /**\n+     * Since we are using PutRecords for its batching effect, we don't want\n+     * the batch size to be so small as to negate all benefits.\n+     */\n+    private static final int MIN_RECORDS_IN_REQUEST = 10;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * Kinesis always uses UTF-8 to encode strings.\n+     */\n+    private static final Charset KINESIS_STRING_ENCODING = StandardCharsets.UTF_8;\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nullable\n+    private final ShardCountMonitor monitor;\n+    @Nonnull\n+    private final AtomicInteger shardCountProvider;\n+    @Nonnull\n+    private final Buffer<T> buffer;\n+\n+    @Probe(name = KinesisSinks.BATCH_SIZE_METRIC, unit = ProbeUnit.COUNT)\n+    private final Counter batchSizeMetric;\n+    @Probe(name = KinesisSinks.THROTTLING_SLEEP_METRIC, unit = ProbeUnit.MS)\n+    private final Counter sleepMetric = SwCounter.newSwCounter();\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+    private int shardCount;\n+    private int sinkCount;\n+\n+    private Future<PutRecordsResult> sendResult;\n+    private long nextSendTime = nanoTime();\n+    private final RetryTracker sendRetryTracker;\n+\n+    private final ThroughputController throughputController = new ThroughputController();\n+\n+    public KinesisSinkP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn,\n+            @Nullable ShardCountMonitor monitor,\n+            @Nonnull AtomicInteger shardCountProvider,\n+            @Nonnull RetryStrategy retryStrategy\n+            ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.monitor = monitor;\n+        this.shardCountProvider = shardCountProvider;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+        this.batchSizeMetric = SwCounter.newSwCounter(buffer.getCapacity());\n+        this.sendRetryTracker = new RetryTracker(retryStrategy);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        sinkCount = context.memberCount() * context.localParallelism();\n+        helper = new KinesisHelper(kinesis, stream);\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        if (monitor != null) {\n+            monitor.run();\n+        }\n+\n+        updateThroughputLimitations();\n+\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            initSending(inbox);\n+        }\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        if (sendResult == null) {\n+            if (buffer.isEmpty()) {\n+                return true;\n+            }\n+            initSending(null);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean saveToSnapshot() {\n+        if (sendResult != null) {\n+            checkIfSendingFinished();\n+        }\n+        return sendResult == null;\n+    }\n+\n+    private void updateThroughputLimitations() {\n+        int newShardCount = shardCountProvider.get();\n+        if (newShardCount > 0 && shardCount != newShardCount) {\n+            buffer.setCapacity(throughputController.computeBatchSize(newShardCount, sinkCount));\n+            batchSizeMetric.set(buffer.getCapacity());\n+\n+            shardCount = newShardCount;\n+        }\n+    }\n+\n+    private void initSending(@Nullable Inbox inbox) {\n+        if (inbox != null) {\n+            bufferFromInbox(inbox);\n+        }\n+        attemptToDispatchBufferContent();\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty()) {\n+            return;\n+        }\n+\n+        long currentTime = nanoTime();\n+        if (currentTime < nextSendTime) {\n+            return;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+        nextSendTime = currentTime;\n+    }\n+\n+    private void checkIfSendingFinished() {\n+        if (sendResult.isDone()) {\n+            PutRecordsResult result;\n+            try {\n+                result = helper.readResult(this.sendResult);\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                dealWithThroughputExceeded(\"Data throughput rate exceeded. Backing off and retrying in %d ms\");\n+                return;\n+            } catch (SdkClientException sce) {\n+                dealWithSendFailure(sce);\n+                return;\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            } finally {\n+                sendResult = null;\n+            }\n+\n+            pruneSentFromBuffer(result);\n+            if (result.getFailedRecordCount() > 0) {\n+                dealWithThroughputExceeded(\"Failed to send \" + result.getFailedRecordCount() + \" (out of \" +\n+                        result.getRecords().size() + \") record(s) to stream '\" + stream +\n+                        \"'. Sending will be retried in %d ms, message reordering is likely.\");\n+            } else {\n+                long sleepTimeNanos = throughputController.markSuccess();\n+                this.nextSendTime += sleepTimeNanos;\n+                this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+                sendRetryTracker.reset();\n+            }\n+        }\n+    }\n+\n+    private void dealWithSendFailure(@Nonnull Exception failure) {\n+        sendRetryTracker.attemptFailed();\n+        if (sendRetryTracker.shouldTryAgain()) {\n+            long timeoutMillis = sendRetryTracker.getNextWaitTimeMillis();\n+            logger.warning(String.format(\"Failed to send records, will retry in %d ms. Cause: %s\",\n+                    timeoutMillis, failure.getMessage()));\n+            nextSendTime = System.nanoTime() + MILLISECONDS.toNanos(timeoutMillis);\n+        } else {\n+            throw rethrow(failure);\n+        }\n+\n+    }\n+\n+    private void dealWithThroughputExceeded(@Nonnull String message) {\n+        long sleepTimeNanos = throughputController.markFailure();\n+        this.nextSendTime += sleepTimeNanos;\n+        this.sleepMetric.set(NANOSECONDS.toMillis(sleepTimeNanos));\n+        logger.warning(String.format(message, NANOSECONDS.toMillis(sleepTimeNanos)));\n+    }\n+\n+    private void pruneSentFromBuffer(@Nullable PutRecordsResult result) {\n+        if (result == null) {\n+            return;\n+        }\n+\n+        List<PutRecordsResultEntry> resultEntries = result.getRecords();\n+        if (result.getFailedRecordCount() > 0) {\n+            for (int i = resultEntries.size() - 1; i >= 0; i--) {\n+                PutRecordsResultEntry resultEntry = resultEntries.get(i);\n+                if (resultEntry.getErrorCode() == null) {\n+                    buffer.remove(i);\n+                }\n+            }\n+        } else {\n+            buffer.remove(0, resultEntries.size());\n+        }\n+    }\n+\n+    private static class Buffer<T> {\n+\n+        private final FunctionEx<T, String> keyFn;\n+        private final FunctionEx<T, byte[]> valueFn;\n+\n+        private final BufferEntry[] entries;\n+        private int entryCount;\n+        private int totalEntrySize;\n+        private int capacity;\n+\n+        Buffer(FunctionEx<T, String> keyFn, FunctionEx<T, byte[]> valueFn) {\n+            this.keyFn = keyFn;\n+            this.valueFn = valueFn;\n+            this.entries = initEntries();\n+            this.capacity = entries.length;\n+        }\n+\n+        public int getCapacity() {\n+            return capacity;\n+        }\n+\n+        void setCapacity(int capacity) {\n+            if (capacity < 0 || capacity > entries.length) {\n+                throw new IllegalArgumentException(\"Capacity limited to [0, \" + entries.length + \")\");\n+            }\n+            this.capacity = capacity;\n+        }\n+\n+        boolean add(T item) {\n+            if (isFull()) {\n+                return false;\n+            }\n+\n+            String key = keyFn.apply(item);\n+            if (key.isEmpty()) {\n+                throw new JetException(\"Key empty\");\n+            }\n+            int unicodeCharsInKey = key.length();\n+            if (unicodeCharsInKey > KinesisSinks.MAXIMUM_KEY_LENGTH) {\n+                throw new JetException(\"Key too long\");\n+            }\n+            int keyLength = getKeyLength(key);", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3MzYwNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556773604", "bodyText": "or we can just use unicodeCharsInKey as byte length without multiplying it with 3. If the encoded length is greater then it'll fail when we actually send the entry to kinesis anyway.", "author": "gurbuzali", "createdAt": "2021-01-13T19:25:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3MjQ4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA5MjQ5Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557092496", "bodyText": "Good point, will make the change.", "author": "jbartok", "createdAt": "2021-01-14T07:17:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3MjQ4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3OTc0MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556779740", "bodyText": "we can create a noop ShardCountMonitor and pass it for the other processors instead of a null value to eliminate the null check for each run. We can also move the AtomicInteger shardCount = new AtomicInteger(); into ShardCountMonitor and access the shardCount through it.", "author": "gurbuzali", "createdAt": "2021-01-13T19:36:13Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkPSupplier.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.Collection;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.stream.IntStream;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class KinesisSinkPSupplier<T> implements ProcessorSupplier {\n+\n+    private static final long serialVersionUID = 1L;\n+\n+    @Nonnull\n+    private final AwsConfig awsConfig;\n+    @Nonnull\n+    private final String stream;\n+    @Nonnull\n+    private final FunctionEx<T, String> keyFn;\n+    @Nonnull\n+    private final FunctionEx<T, byte[]> valueFn;\n+    @Nonnull\n+    private final RetryStrategy retryStrategy;\n+\n+    private transient AmazonKinesisAsync client;\n+    private transient int memberCount;\n+    private transient ILogger logger;\n+\n+    public KinesisSinkPSupplier(\n+            @Nonnull AwsConfig awsConfig,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn,\n+            @Nonnull RetryStrategy retryStrategy\n+    ) {\n+        this.awsConfig = awsConfig;\n+        this.stream = stream;\n+        this.keyFn = keyFn;\n+        this.valueFn = valueFn;\n+        this.retryStrategy = retryStrategy;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Context context) {\n+        this.memberCount = context.memberCount();\n+        this.logger = context.logger();\n+        this.client = awsConfig.buildClient();\n+    }\n+\n+    @Nonnull\n+    @Override\n+    public Collection<? extends Processor> get(int count) {\n+        AtomicInteger shardCount = new AtomicInteger();\n+\n+        ShardCountMonitor shardCountMonitor = new ShardCountMonitor(\n+                shardCount,\n+                memberCount,\n+                client,\n+                stream,\n+                retryStrategy,\n+                logger\n+        );\n+\n+        return IntStream.range(0, count)\n+                .mapToObj(i -> new KinesisSinkP<>(\n+                        client,\n+                        stream,\n+                        keyFn,\n+                        valueFn,\n+                        i == 0 ? shardCountMonitor : null,", "originalCommit": "812bec6d345b083efca7ade5606565263803a944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc4NTU5NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r556785594", "bodyText": "I've just implemented this, so leaving the comment as an explanation", "author": "gurbuzali", "createdAt": "2021-01-13T19:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3OTc0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA5Mjg4OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557092888", "bodyText": "Looks good.", "author": "jbartok", "createdAt": "2021-01-14T07:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njc3OTc0MA=="}], "type": "inlineReview"}, {"oid": "16ec9635baf33d43de2211d28c66694d0f9d0a5d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/16ec9635baf33d43de2211d28c66694d0f9d0a5d", "message": "Address review concerns", "committedDate": "2021-01-14T07:54:56Z", "type": "commit"}, {"oid": "a90f59803307037f4106ca02a0c4e1aba21ab552", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a90f59803307037f4106ca02a0c4e1aba21ab552", "message": "Fix bug, improve tests", "committedDate": "2021-01-14T09:32:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDA5MDM3Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r544090376", "bodyText": "This class might be easier with IdentifiedDataSerializable", "author": "viliam-durina", "createdAt": "2020-12-16T08:07:03Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSourceP.java", "diffHunk": "@@ -0,0 +1,323 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.Traverser;\n+import com.hazelcast.jet.Traversers;\n+import com.hazelcast.jet.core.AbstractProcessor;\n+import com.hazelcast.jet.core.BroadcastKey;\n+import com.hazelcast.jet.core.EventTimeMapper;\n+import com.hazelcast.jet.core.EventTimePolicy;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.hazelcast.jet.Traversers.traverseStream;\n+import static com.hazelcast.jet.Util.entry;\n+import static com.hazelcast.jet.core.BroadcastKey.broadcastKey;\n+import static com.hazelcast.jet.impl.util.Util.toLocalTime;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+\n+public class KinesisSourceP extends AbstractProcessor {\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nonnull\n+    private final EventTimeMapper<? super Entry<String, byte[]>> eventTimeMapper;\n+    @Nonnull\n+    private final HashRange hashRange;\n+    @Nonnull\n+    private final ShardStates shardStates = new ShardStates();\n+    @Nonnull\n+    private final Queue<Shard> shardQueue;\n+    @Nullable\n+    private final RangeMonitor monitor;\n+    @Nonnull\n+    private final List<ShardReader> shardReaders = new ArrayList<>();\n+    @Nonnull\n+    private final RetryStrategy retryStrategy;\n+\n+    private int id;\n+    private ILogger logger;\n+\n+    private Traverser<Object> traverser = Traversers.empty();\n+    private Traverser<Entry<BroadcastKey<String>, Object[]>> snapshotTraverser;\n+\n+    private int nextReader;\n+\n+    public KinesisSourceP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull EventTimePolicy<? super Entry<String, byte[]>> eventTimePolicy,\n+            @Nonnull HashRange hashRange,\n+            @Nonnull Queue<Shard> shardQueue,\n+            @Nullable RangeMonitor monitor,\n+            @Nonnull RetryStrategy retryStrategy\n+            ) {\n+        this.kinesis = Objects.requireNonNull(kinesis, \"kinesis\");\n+        this.stream = Objects.requireNonNull(stream, \"stream\");\n+        this.eventTimeMapper = new EventTimeMapper<>(eventTimePolicy);\n+        this.hashRange = Objects.requireNonNull(hashRange, \"hashRange\");\n+        this.shardQueue = shardQueue;\n+        this.monitor = monitor;\n+        this.retryStrategy = retryStrategy;\n+    }\n+\n+    @Override\n+    protected void init(@Nonnull Context context) throws Exception {\n+        super.init(context);\n+\n+        logger = context.logger();\n+        id = context.globalProcessorIndex();\n+\n+        logger.info(\"Processor \" + id + \" handles \" + hashRange);\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (!emitFromTraverser(traverser)) {\n+            return false;\n+        }\n+\n+        runMonitor();\n+        checkForNewShards();\n+        runReaders();\n+\n+        return false;\n+    }\n+\n+    private void runMonitor() {\n+        if (monitor != null) {\n+            monitor.run();\n+        }\n+    }\n+\n+    private void checkForNewShards() {\n+        Shard shard = shardQueue.poll();\n+        if (shard != null) {\n+            addShardReader(shard);\n+        }\n+    }\n+\n+    private void runReaders() {\n+        if (!shardReaders.isEmpty()) {\n+            long currentTime = System.nanoTime();\n+            for (int i = 0; i < shardReaders.size(); i++) {\n+                int currentReader = nextReader;\n+                ShardReader reader = shardReaders.get(currentReader);\n+                nextReader = incrCircular(currentReader, shardReaders.size());\n+\n+                ShardReader.Result result = reader.probe(currentTime);\n+                if (ShardReader.Result.HAS_DATA.equals(result)) {\n+                    traverser = reader.clearData()\n+                            .flatMap(record -> eventTimeMapper.flatMapEvent(\n+                                    entry(record.getPartitionKey(), record.getData().array()), //todo: shady?\n+                                    currentReader,\n+                                    record.getApproximateArrivalTimestamp().getTime()\n+                            ));\n+                    Long watermark = eventTimeMapper.getWatermark(currentReader);\n+                    watermark = watermark < 0 ? null : watermark;\n+                    shardStates.update(reader.getShard(), reader.getLastSeenSeqNo(), watermark);\n+                    emitFromTraverser(traverser);\n+                    return;\n+                } else if (ShardReader.Result.CLOSED.equals(result)) {\n+                    Shard shard = reader.getShard();\n+                    logger.info(\"Shard \" + shard.getShardId() + \" of stream \" + stream + \" closed\");\n+                    shardStates.close(shard);\n+                    removeShardReader(currentReader);\n+                    nextReader = 0;\n+                    return;\n+                }\n+            }\n+        }\n+\n+        traverser = eventTimeMapper.flatMapIdle();\n+        emitFromTraverser(traverser);\n+    }\n+\n+    @Override\n+    public boolean saveToSnapshot() {\n+        if (!emitFromTraverser(traverser)) {\n+            return false;\n+        }\n+\n+        if (snapshotTraverser == null) {\n+            snapshotTraverser = traverseStream(shardStates.snapshotEntries())\n+                    .onFirstNull(() -> {\n+                        snapshotTraverser = null;\n+                        if (getLogger().isFinestEnabled()) {\n+                            getLogger().finest(\"Finished saving snapshot. Saved shard states: \" + shardStates);\n+                        }\n+                    });\n+        }\n+        return emitFromTraverserToSnapshot(snapshotTraverser);\n+    }\n+\n+    @Override\n+    protected void restoreFromSnapshot(@Nonnull Object key, @Nonnull Object value) {\n+        String shardId = ((BroadcastKey<String>) key).key();\n+\n+        Object[] shardState = (Object[]) value;\n+        String startingHashKey = ShardStates.startingHashKey(shardState);\n+        shardBelongsToRange(startingHashKey, hashRange);\n+        if (shardBelongsToRange(startingHashKey, hashRange)) {\n+            boolean closed = ShardStates.closed(shardState);\n+            String seqNo = ShardStates.lastSeenSeqNo(shardState);\n+            Long watermark = ShardStates.watermark(shardState);\n+            shardStates.update(shardId, startingHashKey, closed, seqNo, watermark);\n+        }\n+    }\n+\n+    private void addShardReader(Shard shard) {\n+        String shardId = shard.getShardId();\n+        Object[] shardState = shardStates.get(shardId);\n+        if (!ShardStates.closed(shardState)) {\n+            int readerIndex = shardReaders.size();\n+\n+            String lastSeenSeqNo = ShardStates.lastSeenSeqNo(shardState);\n+            shardReaders.add(initShardReader(shard, lastSeenSeqNo));\n+\n+            eventTimeMapper.addPartitions(1);\n+\n+            Long watermark = ShardStates.watermark(shardState);\n+            if (watermark != null) {\n+                eventTimeMapper.restoreWatermark(readerIndex, watermark);\n+            }\n+        }\n+    }\n+\n+    private void removeShardReader(int index) {\n+        shardReaders.remove(index);\n+        eventTimeMapper.removePartition(index);\n+    }\n+\n+    @Nonnull\n+    private ShardReader initShardReader(Shard shard, String lastSeenSeqNo) {\n+        logger.info(\"Shard \" + shard.getShardId() + \" of stream \" + stream + \" assigned to processor instance \" + id);\n+        return new ShardReader(kinesis, stream, shard, lastSeenSeqNo, retryStrategy, logger);\n+    }\n+\n+    private static int incrCircular(int v, int limit) {\n+        v++;\n+        if (v == limit) {\n+            v = 0;\n+        }\n+        return v;\n+    }\n+\n+    private static class ShardStates {", "originalCommit": "17d6e220ad5dc7870e7199811ac6ae0441719d32", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDA5MDg1MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r544090850", "bodyText": "We should also check for expired shards and add them to the queue so that processors can remove the entry for them for the snapshot.", "author": "viliam-durina", "createdAt": "2020-12-16T08:07:51Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/RangeMonitor.java", "diffHunk": "@@ -0,0 +1,175 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.Set;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static java.util.stream.Collectors.joining;\n+import static java.util.stream.Collectors.toCollection;\n+import static java.util.stream.Collectors.toList;\n+\n+public class RangeMonitor extends AbstractShardWorker {\n+\n+    /**\n+     * ListStreams operations are limited to 100 per second, per data stream\n+     */\n+    private static final int SHARD_LISTINGS_ALLOWED_PER_SECOND = 100;\n+\n+    /**\n+     * We don't want to issue shard listing requests at the peak allowed rate.\n+     */\n+    private static final double RATIO_OF_SHARD_LISTING_RATE_UTILIZED = 0.1;\n+\n+    private final Set<String> knownShards = new HashSet<>();\n+    private final HashRange coveredRange;\n+    private final HashRange[] rangePartitions;\n+    private final Queue<Shard>[] shardQueues;\n+    private final RandomizedRateTracker listShardsRateTracker;\n+    private final RetryTracker listShardRetryTracker;\n+\n+    private String nextToken;\n+    private Future<ListShardsResult> listShardResult;\n+    private long nextListShardsTime;\n+\n+    public RangeMonitor(\n+            int totalInstances,\n+            AmazonKinesisAsync kinesis,\n+            String stream,\n+            HashRange coveredRange,\n+            HashRange[] rangePartitions,\n+            Queue<Shard>[] shardQueues,\n+            RetryStrategy retryStrategy,\n+            ILogger logger\n+    ) {\n+        super(kinesis, stream, logger);\n+        this.coveredRange = coveredRange;\n+        this.rangePartitions = rangePartitions;\n+        this.shardQueues = shardQueues;\n+        this.listShardRetryTracker = new RetryTracker(retryStrategy);\n+        this.listShardsRateTracker = initRandomizedTracker(totalInstances);\n+        this.nextListShardsTime = System.nanoTime() + listShardsRateTracker.next();\n+    }\n+\n+    public void run() {\n+        if (listShardResult == null) {\n+            initShardListing();\n+        } else {\n+            checkForNewShards();\n+        }\n+    }\n+\n+    private void initShardListing() {\n+        long currentTime = System.nanoTime();\n+        if (currentTime < nextListShardsTime) {\n+            return;\n+        }\n+        listShardResult = helper.listShardsAsync(nextToken);\n+        nextListShardsTime = currentTime + listShardsRateTracker.next();\n+    }\n+\n+    private void checkForNewShards() {", "originalCommit": "17d6e220ad5dc7870e7199811ac6ae0441719d32", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "54df21cb47313a9a6b0be3a9e2f641f8be906745", "url": "https://github.com/hazelcast/hazelcast-jet/commit/54df21cb47313a9a6b0be3a9e2f641f8be906745", "message": "Swith from kinesis to bundle SDK jar", "committedDate": "2021-01-14T10:41:22Z", "type": "commit"}, {"oid": "50bf585df328f5c2cafc536e83961f8a498642eb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/50bf585df328f5c2cafc536e83961f8a498642eb", "message": "Remove explicit CBOR dependency", "committedDate": "2021-01-14T10:47:04Z", "type": "commit"}, {"oid": "418d181fa9757a68b7c67d4d1fa24f1b167836e8", "url": "https://github.com/hazelcast/hazelcast-jet/commit/418d181fa9757a68b7c67d4d1fa24f1b167836e8", "message": "Address review concerns", "committedDate": "2021-01-14T11:08:03Z", "type": "commit"}, {"oid": "44e8cddd58c9107738f5e4cd1ee9c86fd540025f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/44e8cddd58c9107738f5e4cd1ee9c86fd540025f", "message": "Fix some typos, grammar", "committedDate": "2021-01-14T11:42:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM0Mjg0OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557342848", "bodyText": "Isn't it always the case that if firstDetection == true, then trackingInfo was null above? If yes, you can apply this suggestion:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        if (trackingInfo == null) {\n          \n          \n            \n                            int owner = findOwner(new BigInteger(shard.getHashKeyRange().getStartingHashKey()));\n          \n          \n            \n                            trackingInfo = new TrackingInfo(owner, currentTimeMs);\n          \n          \n            \n                            info.put(shardId, trackingInfo);\n          \n          \n            \n                        }\n          \n          \n            \n                        boolean firstDetection = trackingInfo.markDetection(currentTimeMs);\n          \n          \n            \n                        if (firstDetection) {\n          \n          \n            \n                            if (newShards.isEmpty()) {\n          \n          \n            \n                                newShards = new HashMap<>();\n          \n          \n            \n                            }\n          \n          \n            \n                            newShards.put(shard, trackingInfo.getOwner());\n          \n          \n            \n                        }\n          \n          \n            \n                        if (trackingInfo == null) {\n          \n          \n            \n                            int owner = findOwner(new BigInteger(shard.getHashKeyRange().getStartingHashKey()));\n          \n          \n            \n                            trackingInfo = new TrackingInfo(owner, currentTimeMs);\n          \n          \n            \n                            info.put(shardId, trackingInfo);\n          \n          \n            \n                            if (newShards.isEmpty()) {\n          \n          \n            \n                                newShards = new HashMap<>();\n          \n          \n            \n                            }\n          \n          \n            \n                            newShards.put(shard, trackingInfo.getOwner());\n          \n          \n            \n                        }\n          \n          \n            \n                        trackingInfo.markDetection(currentTimeMs);\n          \n      \n    \n    \n  \n\nFrom TrackingInfo you can then remove the boolean detected field.", "author": "viliam-durina", "createdAt": "2021-01-14T11:57:19Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/ShardTracker.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.JetException;\n+\n+import java.math.BigInteger;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import static java.util.concurrent.TimeUnit.MINUTES;\n+\n+public class ShardTracker {\n+\n+    /**\n+     * We consider shards to be expired if they haven't been detected at all\n+     * (neither as OPEN, nor as CLOSED) since at least this amount of time.\n+     */\n+    static final long EXPIRATION_MS = MINUTES.toMillis(10);\n+\n+    private final Map<String, TrackingInfo> info = new HashMap<>();\n+    private final HashRange[] rangePartitions;\n+\n+    public ShardTracker(HashRange[] rangePartitions) {\n+        this.rangePartitions = rangePartitions;\n+    }\n+\n+    public void addUndetected(String shardId, BigInteger startingHashKey, long currentTimeMs) {\n+        assert !info.containsKey(shardId);\n+        info.put(shardId, new TrackingInfo(findOwner(startingHashKey), currentTimeMs));\n+    }\n+\n+    public Map<Shard, Integer> markDetections(Set<Shard> shards, long currentTimeMs) {\n+        Map<Shard, Integer> newShards = Collections.emptyMap();\n+        for (Shard shard : shards) {\n+            String shardId = shard.getShardId();\n+            TrackingInfo trackingInfo = info.get(shardId);\n+            if (trackingInfo == null) {\n+                int owner = findOwner(new BigInteger(shard.getHashKeyRange().getStartingHashKey()));\n+                trackingInfo = new TrackingInfo(owner, currentTimeMs);\n+                info.put(shardId, trackingInfo);\n+            }\n+            boolean firstDetection = trackingInfo.markDetection(currentTimeMs);\n+            if (firstDetection) {\n+                if (newShards.isEmpty()) {\n+                    newShards = new HashMap<>();\n+                }\n+                newShards.put(shard, trackingInfo.getOwner());\n+            }", "originalCommit": "418d181fa9757a68b7c67d4d1fa24f1b167836e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM0NTM2OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r557345369", "bodyText": "I was wrong, ignore this.", "author": "viliam-durina", "createdAt": "2021-01-14T12:01:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM0Mjg0OA=="}], "type": "inlineReview"}, {"oid": "065d68e4b0f9fb19d2e751c5d2cec9e1d13c5bf1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/065d68e4b0f9fb19d2e751c5d2cec9e1d13c5bf1", "message": "Simplify ShardQueue's API", "committedDate": "2021-01-14T12:20:06Z", "type": "commit"}, {"oid": "9de35804c8ea5a01e224c5d88a45fad0d6b7a8b2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/9de35804c8ea5a01e224c5d88a45fad0d6b7a8b2", "message": "Fix style", "committedDate": "2021-01-14T12:20:27Z", "type": "commit"}, {"oid": "8fc46f1fcf11fff5eb3bf0d31f9527cdef7596ab", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8fc46f1fcf11fff5eb3bf0d31f9527cdef7596ab", "message": "add jobsStartedBeforeStreamExists test", "committedDate": "2021-01-14T14:59:00Z", "type": "commit"}, {"oid": "fade2cd4ba3a9e9e6e28922769e52a220548ad98", "url": "https://github.com/hazelcast/hazelcast-jet/commit/fade2cd4ba3a9e9e6e28922769e52a220548ad98", "message": "Fix license text", "committedDate": "2021-01-14T17:44:25Z", "type": "commit"}, {"oid": "3f394e373a6d852f34173ddf4c86c6a57a7bfb4b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3f394e373a6d852f34173ddf4c86c6a57a7bfb4b", "message": "Update NOTICE file", "committedDate": "2021-01-14T18:53:32Z", "type": "commit"}, {"oid": "217afb255a6ad42ae31b8cadb5600b5003044de3", "url": "https://github.com/hazelcast/hazelcast-jet/commit/217afb255a6ad42ae31b8cadb5600b5003044de3", "message": "Update site/docs/design-docs/018-kinesis-connectors.md\n\nCo-authored-by: Viliam Durina <viliam-durina@users.noreply.github.com>", "committedDate": "2021-01-15T06:47:54Z", "type": "commit"}, {"oid": "65faee6fe918dd39b6c6c08fac3d91f613f6d786", "url": "https://github.com/hazelcast/hazelcast-jet/commit/65faee6fe918dd39b6c6c08fac3d91f613f6d786", "message": "Improve documentation, fix a bug", "committedDate": "2021-01-15T07:46:42Z", "type": "commit"}, {"oid": "d6b9f99ddca5844fa9e35b25006d744fcdc0d20b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d6b9f99ddca5844fa9e35b25006d744fcdc0d20b", "message": "Update extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java\n\nCo-authored-by: Viliam Durina <viliam-durina@users.noreply.github.com>", "committedDate": "2021-01-15T08:49:09Z", "type": "commit"}, {"oid": "cc8584e312a4af135c8b48c0c7439d4ed1053482", "url": "https://github.com/hazelcast/hazelcast-jet/commit/cc8584e312a4af135c8b48c0c7439d4ed1053482", "message": "Improve documentation", "committedDate": "2021-01-15T09:37:52Z", "type": "commit"}, {"oid": "2ee0191823a64cad40ce9b9be4eebcf45b731969", "url": "https://github.com/hazelcast/hazelcast-jet/commit/2ee0191823a64cad40ce9b9be4eebcf45b731969", "message": "Add possibility to run KinesisIntegrationTest with real backend", "committedDate": "2021-01-15T09:48:17Z", "type": "commit"}, {"oid": "53f046fd5b38720995a080824d6071b6d9b13ddb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/53f046fd5b38720995a080824d6071b6d9b13ddb", "message": "Change from assembly to shade plugin, relocate com.amazonaws", "committedDate": "2021-01-15T10:29:24Z", "type": "commit"}, {"oid": "1205c555116b00a19767ee911c1fb1bde1b94e89", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1205c555116b00a19767ee911c1fb1bde1b94e89", "message": "Add missing dependency", "committedDate": "2021-01-15T11:26:33Z", "type": "commit"}, {"oid": "87dfce7fe7206ceadbd75a7e349b8c9b7a29eda7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/87dfce7fe7206ceadbd75a7e349b8c9b7a29eda7", "message": "Update NOTICE file", "committedDate": "2021-01-15T12:02:18Z", "type": "commit"}, {"oid": "46f9aeb60c565be5110f544c43ae6d306a9d46a1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/46f9aeb60c565be5110f544c43ae6d306a9d46a1", "message": "Define Kinesis module and integration test framework", "committedDate": "2020-11-19T11:33:28Z", "type": "commit"}, {"oid": "09be7f6c83942108c4b47f29764d552bfd8dd2e5", "url": "https://github.com/hazelcast/hazelcast-jet/commit/09be7f6c83942108c4b47f29764d552bfd8dd2e5", "message": "Basic source and test", "committedDate": "2020-11-19T11:33:29Z", "type": "commit"}, {"oid": "f4086c697eeb1381470d435616a731e27097b375", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f4086c697eeb1381470d435616a731e27097b375", "message": "Make checkstyle happy", "committedDate": "2020-11-19T11:33:29Z", "type": "commit"}, {"oid": "5533f122e6a8d5ee5d40789cc65b491ccc91f825", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5533f122e6a8d5ee5d40789cc65b491ccc91f825", "message": "Rename jackson.jr.version because it's used for more than Jackson jr", "committedDate": "2020-11-19T11:33:29Z", "type": "commit"}, {"oid": "8588a02a57359e1e9a8b3acb9404ffd62e7bf5b2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8588a02a57359e1e9a8b3acb9404ffd62e7bf5b2", "message": "Improve the source", "committedDate": "2020-11-19T11:33:29Z", "type": "commit"}, {"oid": "73e4f9b56ae1ed082db707115214de2e5d7fe618", "url": "https://github.com/hazelcast/hazelcast-jet/commit/73e4f9b56ae1ed082db707115214de2e5d7fe618", "message": "Improve GetRecords limit/quota handling", "committedDate": "2020-11-19T11:33:30Z", "type": "commit"}, {"oid": "7e0e3369eb96e1c8a79d83297217be27b0e42a24", "url": "https://github.com/hazelcast/hazelcast-jet/commit/7e0e3369eb96e1c8a79d83297217be27b0e42a24", "message": "First working version of the sink", "committedDate": "2020-11-19T11:33:30Z", "type": "commit"}, {"oid": "e43b86e769fdb8c22ed808950622131b86be2cd4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e43b86e769fdb8c22ed808950622131b86be2cd4", "message": "Recycle data objects in the sink", "committedDate": "2020-11-19T11:33:30Z", "type": "commit"}, {"oid": "f495d9652d5320651463eb5274f15af44106e3fe", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f495d9652d5320651463eb5274f15af44106e3fe", "message": "Make checkstyle happy", "committedDate": "2020-11-19T11:33:30Z", "type": "commit"}, {"oid": "aa5f33ae7ca980c3a0511e211c4f813c3932e0e1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/aa5f33ae7ca980c3a0511e211c4f813c3932e0e1", "message": "First working version of merge handling", "committedDate": "2020-11-19T11:33:31Z", "type": "commit"}, {"oid": "b750e9a2e61075020c42c0fa430c0dc4b656e336", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b750e9a2e61075020c42c0fa430c0dc4b656e336", "message": "Finish merge handling", "committedDate": "2020-11-19T11:33:31Z", "type": "commit"}, {"oid": "db1c69552a8e9fc6d63e97566a8821100cda4230", "url": "https://github.com/hazelcast/hazelcast-jet/commit/db1c69552a8e9fc6d63e97566a8821100cda4230", "message": "Handle splits, improve source", "committedDate": "2020-11-19T11:33:31Z", "type": "commit"}, {"oid": "04fec118830987a0924fa564f83d55dc5955151f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/04fec118830987a0924fa564f83d55dc5955151f", "message": "Improve exception handling", "committedDate": "2020-11-19T11:33:31Z", "type": "commit"}, {"oid": "71d3c18448b8369c9ace1a67d50931de4457f12b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/71d3c18448b8369c9ace1a67d50931de4457f12b", "message": "Improve various aspects", "committedDate": "2020-11-19T11:33:32Z", "type": "commit"}, {"oid": "4d488eec9666cb52c0e49625166d9d525a80cfb4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4d488eec9666cb52c0e49625166d9d525a80cfb4", "message": "Improve test cleanup", "committedDate": "2020-11-19T11:33:32Z", "type": "commit"}, {"oid": "4de2d506e7f27ca4866b42892ed9c983995c9d2d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4de2d506e7f27ca4866b42892ed9c983995c9d2d", "message": "Improve tests", "committedDate": "2020-11-19T11:33:32Z", "type": "commit"}, {"oid": "0343ef6cea59c2faef852008eb4f73d594bb1e66", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0343ef6cea59c2faef852008eb4f73d594bb1e66", "message": "Fix version name", "committedDate": "2020-11-19T11:33:32Z", "type": "commit"}, {"oid": "1a877e0314e92fe545e5cd50f65b494690e1e81c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1a877e0314e92fe545e5cd50f65b494690e1e81c", "message": "Fix hostname used in tests", "committedDate": "2020-11-19T11:33:33Z", "type": "commit"}, {"oid": "c6cbf0b627a1bb84577b7ca404486d66e7296fe6", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c6cbf0b627a1bb84577b7ca404486d66e7296fe6", "message": "Add timestamp handling", "committedDate": "2020-11-19T11:33:33Z", "type": "commit"}, {"oid": "c6cbf0b627a1bb84577b7ca404486d66e7296fe6", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c6cbf0b627a1bb84577b7ca404486d66e7296fe6", "message": "Add timestamp handling", "committedDate": "2020-11-19T11:33:33Z", "type": "forcePushed"}, {"oid": "5123b8bce803483a7df547a975a131cd1962e7cc", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5123b8bce803483a7df547a975a131cd1962e7cc", "message": "Add exception handling", "committedDate": "2020-11-19T11:54:24Z", "type": "commit"}, {"oid": "60210677a91b60121237606301d59bb9988dfc9e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/60210677a91b60121237606301d59bb9988dfc9e", "message": "Improve failure handling", "committedDate": "2020-11-20T08:49:05Z", "type": "commit"}, {"oid": "424328c77710e5f9841ebd5a432e05a0800e6797", "url": "https://github.com/hazelcast/hazelcast-jet/commit/424328c77710e5f9841ebd5a432e05a0800e6797", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-11-20T09:09:01Z", "type": "commit"}, {"oid": "a94b91e2e9984853cc768963a8147f3c150a4b97", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a94b91e2e9984853cc768963a8147f3c150a4b97", "message": "Make sink cooperative", "committedDate": "2020-11-23T13:41:06Z", "type": "commit"}, {"oid": "3b641d8a258793aa7f6ea64ed211d34f1eb6af9d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3b641d8a258793aa7f6ea64ed211d34f1eb6af9d", "message": "Fix shard monitoring issue", "committedDate": "2020-11-25T11:33:57Z", "type": "commit"}, {"oid": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "url": "https://github.com/hazelcast/hazelcast-jet/commit/2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-11-25T11:34:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzODkzNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530438934", "bodyText": "Shouldn't we shutdown the clients in the close method here?", "author": "viliam-durina", "createdAt": "2020-11-25T15:02:22Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkPSupplier.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+\n+import javax.annotation.Nonnull;\n+import java.util.Collection;\n+import java.util.stream.IntStream;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class KinesisSinkPSupplier<T> implements ProcessorSupplier {\n+\n+    private static final long serialVersionUID = 1L;\n+\n+    /**\n+     * We don't want to create an AWS client for each processor instance,\n+     * because they aren't light. We also can't do the other extreme, have a\n+     * single AWS client shared by all processors, because there would be a lot\n+     * of contention, causing problems. So we use shared clients but use them\n+     * for a limited number of processor instances, specified by this constant.\n+     */\n+    private static final int PROCESSORS_PER_CLIENT = 12; //todo: find optimal value on real backend\n+\n+    @Nonnull\n+    private final AwsConfig awsConfig;\n+    @Nonnull\n+    private final String stream;\n+    @Nonnull\n+    private final FunctionEx<T, String> keyFn;\n+    @Nonnull\n+    private final FunctionEx<T, byte[]> valueFn;\n+\n+    private transient AmazonKinesisAsync[] clients;\n+\n+    public KinesisSinkPSupplier(\n+            @Nonnull AwsConfig awsConfig,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.awsConfig = awsConfig;\n+        this.stream = stream;\n+        this.keyFn = keyFn;\n+        this.valueFn = valueFn;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Context context) {\n+        int localParallelism = context.localParallelism();\n+        this.clients = IntStream.range(0, (int) Math.ceil((double) localParallelism / PROCESSORS_PER_CLIENT))", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDgwODQ2MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530808461", "bodyText": "Allegedly is optional, but can't hurt. Will add.", "author": "jbartok", "createdAt": "2020-11-26T06:59:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzODkzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0MzI1Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530843253", "bodyText": "Weird statement, indeed:\n\nThis is an optional method, and callers are not expected to call it, but can if they want to explicitly release any open resources.\n\nOf course we want to \"explicitly release any open resources\"!", "author": "viliam-durina", "createdAt": "2020-11-26T08:17:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzODkzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0NDcyMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530844723", "bodyText": "Checked the code, there are some channels and executors and background monitors that are closed/stopped.", "author": "viliam-durina", "createdAt": "2020-11-26T08:20:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQzODkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ0NDA4NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530444085", "bodyText": "This will cause double logging. When we re-throw the exception, there's no need to log it.\nSame below.", "author": "viliam-durina", "createdAt": "2020-11-25T15:09:33Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisHelper.java", "diffHunk": "@@ -0,0 +1,239 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.AmazonKinesisException;\n+import com.amazonaws.services.kinesis.model.DescribeStreamSummaryRequest;\n+import com.amazonaws.services.kinesis.model.ExpiredNextTokenException;\n+import com.amazonaws.services.kinesis.model.GetRecordsRequest;\n+import com.amazonaws.services.kinesis.model.GetRecordsResult;\n+import com.amazonaws.services.kinesis.model.GetShardIteratorResult;\n+import com.amazonaws.services.kinesis.model.InvalidArgumentException;\n+import com.amazonaws.services.kinesis.model.LimitExceededException;\n+import com.amazonaws.services.kinesis.model.ListShardsRequest;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequest;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.ResourceInUseException;\n+import com.amazonaws.services.kinesis.model.ResourceNotFoundException;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.amazonaws.services.kinesis.model.ShardFilter;\n+import com.amazonaws.services.kinesis.model.ShardFilterType;\n+import com.amazonaws.services.kinesis.model.StreamDescriptionSummary;\n+import com.amazonaws.services.kinesis.model.StreamStatus;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.math.BigInteger;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisHelper {\n+\n+    private static final int SLEEP_DURATION = 250;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final ILogger logger;\n+\n+    public KinesisHelper(AmazonKinesisAsync kinesis, String stream, ILogger logger) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.logger = logger;\n+    }\n+\n+    public static boolean shardActive(@Nonnull Shard shard) {\n+        String endingSequenceNumber = shard.getSequenceNumberRange().getEndingSequenceNumber();\n+        return endingSequenceNumber == null;\n+        //need to rely on this hack, because shard filters don't seem to work, on the mock at least ...\n+    }\n+\n+    public static boolean shardBelongsToRange(@Nonnull Shard shard, @Nonnull HashRange range) {\n+        String startingHashKey = shard.getHashKeyRange().getStartingHashKey();\n+        return range.contains(new BigInteger(startingHashKey));\n+    }\n+\n+    public void waitForStreamToActivate() {\n+        while (true) {\n+            StreamStatus status = callSafely(this::getStreamStatus);\n+            switch (status) {\n+                case ACTIVE:\n+                    return;\n+                case CREATING:\n+                case UPDATING:\n+                    logger.info(\"Waiting for stream \" + stream + \" to become active...\");\n+                    waitABit();\n+                    break;\n+                case DELETING:\n+                    throw new JetException(\"Stream is being deleted\");\n+                default:\n+                    throw new JetException(\"Programming error, unhandled stream status: \" + status);\n+            }\n+        }\n+    }\n+\n+    public void waitForStreamToDisappear() {\n+        while (true) {\n+            List<String> streams = callSafely(this::listStreams);\n+            if (streams.isEmpty()) {\n+                return;\n+            } else {\n+                logger.info(\"Waiting for stream \" + stream + \" to disappear...\");\n+                waitABit();\n+            }\n+        }\n+    }\n+\n+    private List<String> listStreams() {\n+        return kinesis.listStreams().getStreamNames();\n+    }\n+\n+    private StreamStatus getStreamStatus() {\n+        DescribeStreamSummaryRequest request = new DescribeStreamSummaryRequest();\n+        request.setStreamName(stream);\n+\n+        StreamDescriptionSummary description = kinesis.describeStreamSummary(request).getStreamDescriptionSummary();\n+        String statusString = description.getStreamStatus();\n+\n+        return StreamStatus.valueOf(statusString);\n+    }\n+\n+    public List<Shard> listShards(Predicate<? super Shard> filter) {\n+        return callSafely(this::listShards).stream()\n+                .filter(filter)\n+                .collect(Collectors.toList());\n+    }\n+\n+    private List<Shard> listShards() throws AmazonKinesisException {\n+        List<Shard> shards = new ArrayList<>();\n+        String nextToken = null;\n+        do {\n+            ListShardsRequest request = listShardsRequest(nextToken);\n+            ListShardsResult response = kinesis.listShards(request);\n+            shards.addAll(response.getShards());\n+            nextToken = response.getNextToken();\n+        } while (nextToken != null);\n+        return shards;\n+    }\n+\n+    private ListShardsRequest listShardsRequest(@Nullable String nextToken) {\n+        ListShardsRequest request = new ListShardsRequest();\n+        if (nextToken == null) {\n+            request.setStreamName(stream);\n+        } else {\n+            request.setNextToken(nextToken);\n+        }\n+        request.setShardFilter(new ShardFilter().withType(ShardFilterType.AT_LATEST));\n+        return request;\n+    }\n+\n+    public Future<ListShardsResult> listShardsAsync(String nextToken) {\n+        ListShardsRequest request = listShardsRequest(nextToken);\n+        return kinesis.listShardsAsync(request);\n+    }\n+\n+    public Future<GetShardIteratorResult> getShardIteratorAsync(Shard shard) {\n+        return kinesis.getShardIteratorAsync(\n+                stream,\n+                shard.getShardId(),\n+                \"AT_SEQUENCE_NUMBER\",\n+                shard.getSequenceNumberRange().getStartingSequenceNumber()\n+        ); //todo: proper starting sequence number will be provided from offsets restored from Jet snapshots\n+    }\n+\n+    public Future<GetRecordsResult> getRecordsAsync(String shardIterator) {\n+        GetRecordsRequest request = new GetRecordsRequest();\n+        request.setShardIterator(shardIterator);\n+        return kinesis.getRecordsAsync(request);\n+    }\n+\n+    public Future<PutRecordsResult> putRecordsAsync(Collection<PutRecordsRequestEntry> entries) {\n+        PutRecordsRequest request = new PutRecordsRequest();\n+        request.setRecords(entries);\n+        request.setStreamName(stream);\n+        return kinesis.putRecordsAsync(request);\n+    }\n+\n+    private <T> T callSafely(Callable<T> callable) {\n+        while (true) {\n+            try {\n+                return callable.call();\n+            } catch (LimitExceededException lee) {\n+                String message = \"The requested resource exceeds the maximum number allowed, or the number of \" +\n+                        \"concurrent stream requests exceeds the maximum number allowed. Will retry.\";\n+                logger.warning(message, lee);\n+            } catch (ExpiredNextTokenException ente) {\n+                String message = \"The pagination token passed to the operation is expired. Will retry.\";\n+                logger.warning(message, ente);\n+            } catch (ResourceInUseException riue) {\n+                String message = \"The resource is not available for this operation. For successful operation, the \" +\n+                        \"resource must be in the <code>ACTIVE</code> state. Will retry.\";\n+                logger.warning(message, riue);\n+            } catch (ResourceNotFoundException rnfe) {\n+                String message = \"The requested resource could not be found. The stream might not be specified correctly.\";\n+                logger.severe(message, rnfe);\n+                throw new JetException(message, rnfe);", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ0NDYwNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530444607", "bodyText": "HTML in error messages?", "author": "viliam-durina", "createdAt": "2020-11-25T15:10:13Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisHelper.java", "diffHunk": "@@ -0,0 +1,239 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.AmazonKinesisException;\n+import com.amazonaws.services.kinesis.model.DescribeStreamSummaryRequest;\n+import com.amazonaws.services.kinesis.model.ExpiredNextTokenException;\n+import com.amazonaws.services.kinesis.model.GetRecordsRequest;\n+import com.amazonaws.services.kinesis.model.GetRecordsResult;\n+import com.amazonaws.services.kinesis.model.GetShardIteratorResult;\n+import com.amazonaws.services.kinesis.model.InvalidArgumentException;\n+import com.amazonaws.services.kinesis.model.LimitExceededException;\n+import com.amazonaws.services.kinesis.model.ListShardsRequest;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequest;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.ResourceInUseException;\n+import com.amazonaws.services.kinesis.model.ResourceNotFoundException;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.amazonaws.services.kinesis.model.ShardFilter;\n+import com.amazonaws.services.kinesis.model.ShardFilterType;\n+import com.amazonaws.services.kinesis.model.StreamDescriptionSummary;\n+import com.amazonaws.services.kinesis.model.StreamStatus;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.math.BigInteger;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisHelper {\n+\n+    private static final int SLEEP_DURATION = 250;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final ILogger logger;\n+\n+    public KinesisHelper(AmazonKinesisAsync kinesis, String stream, ILogger logger) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.logger = logger;\n+    }\n+\n+    public static boolean shardActive(@Nonnull Shard shard) {\n+        String endingSequenceNumber = shard.getSequenceNumberRange().getEndingSequenceNumber();\n+        return endingSequenceNumber == null;\n+        //need to rely on this hack, because shard filters don't seem to work, on the mock at least ...\n+    }\n+\n+    public static boolean shardBelongsToRange(@Nonnull Shard shard, @Nonnull HashRange range) {\n+        String startingHashKey = shard.getHashKeyRange().getStartingHashKey();\n+        return range.contains(new BigInteger(startingHashKey));\n+    }\n+\n+    public void waitForStreamToActivate() {\n+        while (true) {\n+            StreamStatus status = callSafely(this::getStreamStatus);\n+            switch (status) {\n+                case ACTIVE:\n+                    return;\n+                case CREATING:\n+                case UPDATING:\n+                    logger.info(\"Waiting for stream \" + stream + \" to become active...\");\n+                    waitABit();\n+                    break;\n+                case DELETING:\n+                    throw new JetException(\"Stream is being deleted\");\n+                default:\n+                    throw new JetException(\"Programming error, unhandled stream status: \" + status);\n+            }\n+        }\n+    }\n+\n+    public void waitForStreamToDisappear() {\n+        while (true) {\n+            List<String> streams = callSafely(this::listStreams);\n+            if (streams.isEmpty()) {\n+                return;\n+            } else {\n+                logger.info(\"Waiting for stream \" + stream + \" to disappear...\");\n+                waitABit();\n+            }\n+        }\n+    }\n+\n+    private List<String> listStreams() {\n+        return kinesis.listStreams().getStreamNames();\n+    }\n+\n+    private StreamStatus getStreamStatus() {\n+        DescribeStreamSummaryRequest request = new DescribeStreamSummaryRequest();\n+        request.setStreamName(stream);\n+\n+        StreamDescriptionSummary description = kinesis.describeStreamSummary(request).getStreamDescriptionSummary();\n+        String statusString = description.getStreamStatus();\n+\n+        return StreamStatus.valueOf(statusString);\n+    }\n+\n+    public List<Shard> listShards(Predicate<? super Shard> filter) {\n+        return callSafely(this::listShards).stream()\n+                .filter(filter)\n+                .collect(Collectors.toList());\n+    }\n+\n+    private List<Shard> listShards() throws AmazonKinesisException {\n+        List<Shard> shards = new ArrayList<>();\n+        String nextToken = null;\n+        do {\n+            ListShardsRequest request = listShardsRequest(nextToken);\n+            ListShardsResult response = kinesis.listShards(request);\n+            shards.addAll(response.getShards());\n+            nextToken = response.getNextToken();\n+        } while (nextToken != null);\n+        return shards;\n+    }\n+\n+    private ListShardsRequest listShardsRequest(@Nullable String nextToken) {\n+        ListShardsRequest request = new ListShardsRequest();\n+        if (nextToken == null) {\n+            request.setStreamName(stream);\n+        } else {\n+            request.setNextToken(nextToken);\n+        }\n+        request.setShardFilter(new ShardFilter().withType(ShardFilterType.AT_LATEST));\n+        return request;\n+    }\n+\n+    public Future<ListShardsResult> listShardsAsync(String nextToken) {\n+        ListShardsRequest request = listShardsRequest(nextToken);\n+        return kinesis.listShardsAsync(request);\n+    }\n+\n+    public Future<GetShardIteratorResult> getShardIteratorAsync(Shard shard) {\n+        return kinesis.getShardIteratorAsync(\n+                stream,\n+                shard.getShardId(),\n+                \"AT_SEQUENCE_NUMBER\",\n+                shard.getSequenceNumberRange().getStartingSequenceNumber()\n+        ); //todo: proper starting sequence number will be provided from offsets restored from Jet snapshots\n+    }\n+\n+    public Future<GetRecordsResult> getRecordsAsync(String shardIterator) {\n+        GetRecordsRequest request = new GetRecordsRequest();\n+        request.setShardIterator(shardIterator);\n+        return kinesis.getRecordsAsync(request);\n+    }\n+\n+    public Future<PutRecordsResult> putRecordsAsync(Collection<PutRecordsRequestEntry> entries) {\n+        PutRecordsRequest request = new PutRecordsRequest();\n+        request.setRecords(entries);\n+        request.setStreamName(stream);\n+        return kinesis.putRecordsAsync(request);\n+    }\n+\n+    private <T> T callSafely(Callable<T> callable) {\n+        while (true) {\n+            try {\n+                return callable.call();\n+            } catch (LimitExceededException lee) {\n+                String message = \"The requested resource exceeds the maximum number allowed, or the number of \" +\n+                        \"concurrent stream requests exceeds the maximum number allowed. Will retry.\";\n+                logger.warning(message, lee);\n+            } catch (ExpiredNextTokenException ente) {\n+                String message = \"The pagination token passed to the operation is expired. Will retry.\";\n+                logger.warning(message, ente);\n+            } catch (ResourceInUseException riue) {\n+                String message = \"The resource is not available for this operation. For successful operation, the \" +\n+                        \"resource must be in the <code>ACTIVE</code> state. Will retry.\";", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ0NjYwNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530446607", "bodyText": "If we throw the cause, we won't see where the exception was caught. The cause has a stack trace from another thread.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        throw e.getCause();\n          \n          \n            \n                        throw e;", "author": "viliam-durina", "createdAt": "2020-11-25T15:12:56Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisHelper.java", "diffHunk": "@@ -0,0 +1,239 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.AmazonKinesisException;\n+import com.amazonaws.services.kinesis.model.DescribeStreamSummaryRequest;\n+import com.amazonaws.services.kinesis.model.ExpiredNextTokenException;\n+import com.amazonaws.services.kinesis.model.GetRecordsRequest;\n+import com.amazonaws.services.kinesis.model.GetRecordsResult;\n+import com.amazonaws.services.kinesis.model.GetShardIteratorResult;\n+import com.amazonaws.services.kinesis.model.InvalidArgumentException;\n+import com.amazonaws.services.kinesis.model.LimitExceededException;\n+import com.amazonaws.services.kinesis.model.ListShardsRequest;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequest;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.ResourceInUseException;\n+import com.amazonaws.services.kinesis.model.ResourceNotFoundException;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.amazonaws.services.kinesis.model.ShardFilter;\n+import com.amazonaws.services.kinesis.model.ShardFilterType;\n+import com.amazonaws.services.kinesis.model.StreamDescriptionSummary;\n+import com.amazonaws.services.kinesis.model.StreamStatus;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.math.BigInteger;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisHelper {\n+\n+    private static final int SLEEP_DURATION = 250;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final ILogger logger;\n+\n+    public KinesisHelper(AmazonKinesisAsync kinesis, String stream, ILogger logger) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.logger = logger;\n+    }\n+\n+    public static boolean shardActive(@Nonnull Shard shard) {\n+        String endingSequenceNumber = shard.getSequenceNumberRange().getEndingSequenceNumber();\n+        return endingSequenceNumber == null;\n+        //need to rely on this hack, because shard filters don't seem to work, on the mock at least ...\n+    }\n+\n+    public static boolean shardBelongsToRange(@Nonnull Shard shard, @Nonnull HashRange range) {\n+        String startingHashKey = shard.getHashKeyRange().getStartingHashKey();\n+        return range.contains(new BigInteger(startingHashKey));\n+    }\n+\n+    public void waitForStreamToActivate() {\n+        while (true) {\n+            StreamStatus status = callSafely(this::getStreamStatus);\n+            switch (status) {\n+                case ACTIVE:\n+                    return;\n+                case CREATING:\n+                case UPDATING:\n+                    logger.info(\"Waiting for stream \" + stream + \" to become active...\");\n+                    waitABit();\n+                    break;\n+                case DELETING:\n+                    throw new JetException(\"Stream is being deleted\");\n+                default:\n+                    throw new JetException(\"Programming error, unhandled stream status: \" + status);\n+            }\n+        }\n+    }\n+\n+    public void waitForStreamToDisappear() {\n+        while (true) {\n+            List<String> streams = callSafely(this::listStreams);\n+            if (streams.isEmpty()) {\n+                return;\n+            } else {\n+                logger.info(\"Waiting for stream \" + stream + \" to disappear...\");\n+                waitABit();\n+            }\n+        }\n+    }\n+\n+    private List<String> listStreams() {\n+        return kinesis.listStreams().getStreamNames();\n+    }\n+\n+    private StreamStatus getStreamStatus() {\n+        DescribeStreamSummaryRequest request = new DescribeStreamSummaryRequest();\n+        request.setStreamName(stream);\n+\n+        StreamDescriptionSummary description = kinesis.describeStreamSummary(request).getStreamDescriptionSummary();\n+        String statusString = description.getStreamStatus();\n+\n+        return StreamStatus.valueOf(statusString);\n+    }\n+\n+    public List<Shard> listShards(Predicate<? super Shard> filter) {\n+        return callSafely(this::listShards).stream()\n+                .filter(filter)\n+                .collect(Collectors.toList());\n+    }\n+\n+    private List<Shard> listShards() throws AmazonKinesisException {\n+        List<Shard> shards = new ArrayList<>();\n+        String nextToken = null;\n+        do {\n+            ListShardsRequest request = listShardsRequest(nextToken);\n+            ListShardsResult response = kinesis.listShards(request);\n+            shards.addAll(response.getShards());\n+            nextToken = response.getNextToken();\n+        } while (nextToken != null);\n+        return shards;\n+    }\n+\n+    private ListShardsRequest listShardsRequest(@Nullable String nextToken) {\n+        ListShardsRequest request = new ListShardsRequest();\n+        if (nextToken == null) {\n+            request.setStreamName(stream);\n+        } else {\n+            request.setNextToken(nextToken);\n+        }\n+        request.setShardFilter(new ShardFilter().withType(ShardFilterType.AT_LATEST));\n+        return request;\n+    }\n+\n+    public Future<ListShardsResult> listShardsAsync(String nextToken) {\n+        ListShardsRequest request = listShardsRequest(nextToken);\n+        return kinesis.listShardsAsync(request);\n+    }\n+\n+    public Future<GetShardIteratorResult> getShardIteratorAsync(Shard shard) {\n+        return kinesis.getShardIteratorAsync(\n+                stream,\n+                shard.getShardId(),\n+                \"AT_SEQUENCE_NUMBER\",\n+                shard.getSequenceNumberRange().getStartingSequenceNumber()\n+        ); //todo: proper starting sequence number will be provided from offsets restored from Jet snapshots\n+    }\n+\n+    public Future<GetRecordsResult> getRecordsAsync(String shardIterator) {\n+        GetRecordsRequest request = new GetRecordsRequest();\n+        request.setShardIterator(shardIterator);\n+        return kinesis.getRecordsAsync(request);\n+    }\n+\n+    public Future<PutRecordsResult> putRecordsAsync(Collection<PutRecordsRequestEntry> entries) {\n+        PutRecordsRequest request = new PutRecordsRequest();\n+        request.setRecords(entries);\n+        request.setStreamName(stream);\n+        return kinesis.putRecordsAsync(request);\n+    }\n+\n+    private <T> T callSafely(Callable<T> callable) {\n+        while (true) {\n+            try {\n+                return callable.call();\n+            } catch (LimitExceededException lee) {\n+                String message = \"The requested resource exceeds the maximum number allowed, or the number of \" +\n+                        \"concurrent stream requests exceeds the maximum number allowed. Will retry.\";\n+                logger.warning(message, lee);\n+            } catch (ExpiredNextTokenException ente) {\n+                String message = \"The pagination token passed to the operation is expired. Will retry.\";\n+                logger.warning(message, ente);\n+            } catch (ResourceInUseException riue) {\n+                String message = \"The resource is not available for this operation. For successful operation, the \" +\n+                        \"resource must be in the <code>ACTIVE</code> state. Will retry.\";\n+                logger.warning(message, riue);\n+            } catch (ResourceNotFoundException rnfe) {\n+                String message = \"The requested resource could not be found. The stream might not be specified correctly.\";\n+                logger.severe(message, rnfe);\n+                throw new JetException(message, rnfe);\n+            } catch (InvalidArgumentException iae) {\n+                String message = \"A specified parameter exceeds its restrictions, is not supported, or can't be used.\";\n+                logger.severe(message, iae);\n+                throw new JetException(message, iae);\n+            } catch (SdkClientException sce) {\n+                String message = \"Amazon SDK failure, ignoring and retrying.\";\n+                logger.warning(message, sce);\n+            } catch (Exception e) {\n+                throw rethrow(e);\n+            }\n+\n+            waitABit();\n+        }\n+    }\n+\n+    public <T> T readResult(Future<T> future) throws Throwable {\n+        try {\n+            return future.get();\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            throw new JetException(\"Interrupted while waiting for results\");\n+        } catch (ExecutionException e) {\n+            throw e.getCause();", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0NzUwMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530847500", "bodyText": "That's what we want in this case. We want to see the underlying background service failure, the cause.", "author": "jbartok", "createdAt": "2020-11-26T08:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ0NjYwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg0OTAyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530849028", "bodyText": "We will see it. We will see both: the cause and the place where the exception was thrown.", "author": "viliam-durina", "createdAt": "2020-11-26T08:28:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ0NjYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ4NzEyNg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530487126", "bodyText": "If not deleting from the end, the old code doesn't move entries, but just swaps the removed and last entry, which is wrong. It also doesn't decrement entryCount\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        if (index < 0 || index >= entryCount) {\n          \n          \n            \n                            throw new IllegalArgumentException(\"Index needs to be between 0 and \" + entryCount);\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        totalEntrySize -= entries[index].encodedSize;\n          \n          \n            \n            \n          \n          \n            \n                        int lastIndex = entryCount - 1;\n          \n          \n            \n                        if (index < lastIndex) {\n          \n          \n            \n                            BufferEntry tmp = entries[index];\n          \n          \n            \n                            entries[index] = entries[lastIndex];\n          \n          \n            \n                            entries[lastIndex] = tmp;\n          \n          \n            \n                        } else {\n          \n          \n            \n                            entryCount--;\n          \n          \n            \n                        }\n          \n          \n            \n                        if (index < 0 || index >= entryCount) {\n          \n          \n            \n                            throw new IndexOutOfBoundsException(\"index=\" + index + \", size=\" + entryCount);\n          \n          \n            \n                        }\n          \n          \n            \n                        totalEntrySize -= entries[index].encodedSize;\n          \n          \n            \n                        entryCount--;\n          \n          \n            \n                        if (index < entryCount) {\n          \n          \n            \n                            BufferEntry tmp = entries[index];\n          \n          \n            \n                            System.arraycopy(entries, index + 1, entries, index, entryCount - index);\n          \n          \n            \n                            entries[entryCount] = tmp;\n          \n          \n            \n                        }", "author": "viliam-durina", "createdAt": "2020-11-25T16:08:27Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        switch (state) {\n+            case READY_TO_SEND:\n+                handleReadyToSend(inbox);\n+                return;\n+            case SENDING_IN_PROGRESS:\n+                handleSendingInProgress();\n+                return;\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void handleReadyToSend(@Nonnull Inbox inbox) {\n+        bufferFromInbox(inbox);\n+        if (attemptToDispatchBufferContent()) {\n+            state = State.SENDING_IN_PROGRESS;\n+        }\n+    }\n+\n+    private boolean attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty() || System.currentTimeMillis() < nextSendTime) {\n+            return false;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+\n+        nextSendTime = System.currentTimeMillis(); //todo: add some wait here?\n+        return true;\n+    }\n+\n+    private void handleSendingInProgress() {\n+        if (sendResult.isDone()) {\n+            try {\n+                PutRecordsResult result = helper.readResult(this.sendResult);\n+                pruneSentFromBuffer(result);\n+                if (result.getFailedRecordCount() > 0) {\n+                    dealWithSendFailure(\"Sending only partially successful. Retry sending failed items (ordering\" +\n+                            \" will be affected). \");\n+                } else {\n+                    dealWithSendSuccessful();\n+                }\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                dealWithSendFailure(\"Data throughput rate exceeded. Backing off and retrying.\");\n+            } catch (SdkClientException sce) {\n+                dealWithSendFailure(\"Failed reading records, retrying. Cause: \" + sce.getMessage());\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            }\n+        }\n+    }\n+\n+    private void dealWithSendSuccessful() {\n+        state = State.READY_TO_SEND;\n+    }\n+\n+    private void dealWithSendFailure(@Nonnull String message) {\n+        logger.warning(message);\n+        nextSendTime = System.currentTimeMillis() + PAUSE_AFTER_FAILURE;\n+        state = State.READY_TO_SEND;\n+    }\n+\n+    private void pruneSentFromBuffer(@Nullable PutRecordsResult result) {\n+        if (result == null) {\n+            return;\n+        }\n+\n+        int failCount = result.getFailedRecordCount();\n+        if (failCount > 0) {\n+            logger.warning(\"Failed sending \" + failCount + \" records to stream \" + stream + \". \" +\n+                    \"Sending them will be retried, but reordering might be unavoidable.\");\n+            List<PutRecordsResultEntry> resultEntries = result.getRecords();\n+            for (int i = resultEntries.size() - 1; i >= 0; i--) {\n+                PutRecordsResultEntry resultEntry = resultEntries.get(i);\n+                if (resultEntry.getErrorCode() == null) {\n+                    buffer.remove(i);\n+                }\n+            }\n+        } else {\n+            buffer.clear();\n+        }\n+    }\n+\n+    private enum State {\n+        /**\n+         * Ready to send data to Kinesis, if available.\n+         */\n+        READY_TO_SEND,\n+\n+        /**\n+         * Data has been sent to Kinesis, waiting for a reply.\n+         */\n+        SENDING_IN_PROGRESS,\n+    }\n+\n+    private static class Buffer<T> {\n+\n+        private final FunctionEx<T, String> keyFn;\n+        private final FunctionEx<T, byte[]> valueFn;\n+\n+        private final BufferEntry[] entries;\n+        private int entryCount;\n+        private int totalEntrySize;\n+\n+        Buffer(FunctionEx<T, String> keyFn, FunctionEx<T, byte[]> valueFn) {\n+            this.keyFn = keyFn;\n+            this.valueFn = valueFn;\n+            this.entries = initEntries();\n+        }\n+\n+        boolean add(T item) {\n+            if (entryCount == entries.length) {\n+                return false;\n+            }\n+\n+            String key = keyFn.apply(item);\n+            int unicodeCharsInKey = key.length();\n+            if (unicodeCharsInKey > MAX_UNICODE_CHARS_IN_KEY) {\n+                throw new IllegalArgumentException(\"Key of \" + item + \" too long\");\n+            }\n+            int keyLength = getKeyLength(key);\n+\n+            byte[] value = valueFn.apply(item);\n+            int itemLength = value.length + keyLength;\n+            if (itemLength > MAX_RECORD_SIZE_IN_BYTES) {\n+                throw new IllegalArgumentException(\"Item \" + item + \" encoded length (key + payload) is too big\");\n+            }\n+\n+            if (totalEntrySize + itemLength > MAX_REQUEST_SIZE_IN_BYTES) {\n+                return false;\n+            } else {\n+                totalEntrySize += itemLength;\n+\n+                BufferEntry entry = entries[entryCount++];\n+                entry.set(key, value, itemLength);\n+\n+                return true;\n+            }\n+        }\n+\n+        public void remove(int index) { //todo: test it, at least manually\n+            if (index < 0 || index >= entryCount) {\n+                throw new IllegalArgumentException(\"Index needs to be between 0 and \" + entryCount);\n+            }\n+\n+            totalEntrySize -= entries[index].encodedSize;\n+\n+            int lastIndex = entryCount - 1;\n+            if (index < lastIndex) {\n+                BufferEntry tmp = entries[index];\n+                entries[index] = entries[lastIndex];\n+                entries[lastIndex] = tmp;\n+            } else {\n+                entryCount--;\n+            }", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ4OTQ4Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530489487", "bodyText": "In general we should use nanoTime to measure elapsed time.", "author": "viliam-durina", "createdAt": "2020-11-25T16:11:55Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        switch (state) {\n+            case READY_TO_SEND:\n+                handleReadyToSend(inbox);\n+                return;\n+            case SENDING_IN_PROGRESS:\n+                handleSendingInProgress();\n+                return;\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void handleReadyToSend(@Nonnull Inbox inbox) {\n+        bufferFromInbox(inbox);\n+        if (attemptToDispatchBufferContent()) {\n+            state = State.SENDING_IN_PROGRESS;\n+        }\n+    }\n+\n+    private boolean attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty() || System.currentTimeMillis() < nextSendTime) {\n+            return false;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+\n+        nextSendTime = System.currentTimeMillis(); //todo: add some wait here?\n+        return true;\n+    }\n+\n+    private void handleSendingInProgress() {\n+        if (sendResult.isDone()) {\n+            try {\n+                PutRecordsResult result = helper.readResult(this.sendResult);\n+                pruneSentFromBuffer(result);\n+                if (result.getFailedRecordCount() > 0) {\n+                    dealWithSendFailure(\"Sending only partially successful. Retry sending failed items (ordering\" +\n+                            \" will be affected). \");\n+                } else {\n+                    dealWithSendSuccessful();\n+                }\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                dealWithSendFailure(\"Data throughput rate exceeded. Backing off and retrying.\");\n+            } catch (SdkClientException sce) {\n+                dealWithSendFailure(\"Failed reading records, retrying. Cause: \" + sce.getMessage());\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            }\n+        }\n+    }\n+\n+    private void dealWithSendSuccessful() {\n+        state = State.READY_TO_SEND;\n+    }\n+\n+    private void dealWithSendFailure(@Nonnull String message) {\n+        logger.warning(message);\n+        nextSendTime = System.currentTimeMillis() + PAUSE_AFTER_FAILURE;", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5Mjg2Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530492862", "bodyText": "Code was correct, but it's a long reading ;)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (buffer.isFull()) {\n          \n          \n            \n                        return;\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    while (true) {\n          \n          \n            \n                        T t = (T) inbox.peek();\n          \n          \n            \n                        if (t == null) {\n          \n          \n            \n                            //no more items in inbox\n          \n          \n            \n                            return;\n          \n          \n            \n                        }\n          \n          \n            \n            \n          \n          \n            \n                        boolean canBeBuffered = buffer.add(t);\n          \n          \n            \n                        if (canBeBuffered) {\n          \n          \n            \n                            inbox.remove();\n          \n          \n            \n                        } else {\n          \n          \n            \n                            //no more room in buffer\n          \n          \n            \n                            return;\n          \n          \n            \n                        }\n          \n          \n            \n                    }\n          \n          \n            \n                    for (T t; (t = (T) inbox.peek()) != null && buffer.add(t); ) {\n          \n          \n            \n                        inbox.remove();\n          \n          \n            \n                    }", "author": "viliam-durina", "createdAt": "2020-11-25T16:16:52Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        switch (state) {\n+            case READY_TO_SEND:\n+                handleReadyToSend(inbox);\n+                return;\n+            case SENDING_IN_PROGRESS:\n+                handleSendingInProgress();\n+                return;\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NDc4MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530494780", "bodyText": "Should initialize to MIN_VALUE, it won't start sending until 1.1.1970 otherwise :-)\nEspecially if we switch to nanoTime.", "author": "viliam-durina", "createdAt": "2020-11-25T16:19:35Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NjM3Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530496376", "bodyText": "This is unnecessary now. It can stay in the past unless we see a reason to postpone next sending.", "author": "viliam-durina", "createdAt": "2020-11-25T16:21:55Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        switch (state) {\n+            case READY_TO_SEND:\n+                handleReadyToSend(inbox);\n+                return;\n+            case SENDING_IN_PROGRESS:\n+                handleSendingInProgress();\n+                return;\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+\n+    }\n+\n+    private void bufferFromInbox(@Nonnull Inbox inbox) {\n+        if (buffer.isFull()) {\n+            return;\n+        }\n+\n+        while (true) {\n+            T t = (T) inbox.peek();\n+            if (t == null) {\n+                //no more items in inbox\n+                return;\n+            }\n+\n+            boolean canBeBuffered = buffer.add(t);\n+            if (canBeBuffered) {\n+                inbox.remove();\n+            } else {\n+                //no more room in buffer\n+                return;\n+            }\n+        }\n+    }\n+\n+    private void handleReadyToSend(@Nonnull Inbox inbox) {\n+        bufferFromInbox(inbox);\n+        if (attemptToDispatchBufferContent()) {\n+            state = State.SENDING_IN_PROGRESS;\n+        }\n+    }\n+\n+    private boolean attemptToDispatchBufferContent() {\n+        if (buffer.isEmpty() || System.currentTimeMillis() < nextSendTime) {\n+            return false;\n+        }\n+\n+        List<PutRecordsRequestEntry> entries = buffer.content();\n+        sendResult = helper.putRecordsAsync(entries);\n+\n+        nextSendTime = System.currentTimeMillis(); //todo: add some wait here?", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg1NDYwMA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530854600", "bodyText": "I'll take care of this when I add reconnect strategy configuration/exponential backoff.", "author": "jbartok", "createdAt": "2020-11-26T08:36:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NjM3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5OTUyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530499528", "bodyText": "In the current code, if sending in progress was just done, we won't send another batch immediately. We'll wait for a next call. The ProcessorTasklet will think no progress was made, so it will back off a little, unnecessarily.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    switch (state) {\n          \n          \n            \n                        case READY_TO_SEND:\n          \n          \n            \n                            handleReadyToSend(inbox);\n          \n          \n            \n                            return;\n          \n          \n            \n                        case SENDING_IN_PROGRESS:\n          \n          \n            \n                            handleSendingInProgress();\n          \n          \n            \n                            return;\n          \n          \n            \n                        default:\n          \n          \n            \n                            throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n          \n          \n            \n                    }\n          \n          \n            \n                    if (state == State.SENDING_IN_PROGRESS) {\n          \n          \n            \n                        handleSendingInProgress();\n          \n          \n            \n                    }\n          \n          \n            \n                    if (state == State.READY_TO_SEND) {\n          \n          \n            \n                        handleReadyToSend(inbox);\n          \n          \n            \n                    }\n          \n      \n    \n    \n  \n\nNote there's no else before the second if - the state might change after the first call.", "author": "viliam-durina", "createdAt": "2020-11-25T16:26:29Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {\n+        switch (state) {\n+            case READY_TO_SEND:\n+                handleReadyToSend(inbox);\n+                return;\n+            case SENDING_IN_PROGRESS:\n+                handleSendingInProgress();\n+                return;\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg2NDg4NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530864884", "bodyText": "Makes sense, will apply.", "author": "jbartok", "createdAt": "2020-11-26T08:53:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5OTUyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMzA4MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530503081", "bodyText": "We must override the complete() method and ensure that the in-progress items are finished. Currently, the job will be terminated before the last request completes. And if it doesn't complete successfully, the items will be lost.", "author": "viliam-durina", "createdAt": "2020-11-25T16:31:46Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDg3MDkwOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530870908", "bodyText": "Good catch, thank you!", "author": "jbartok", "createdAt": "2020-11-26T09:02:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMzA4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwNDM3MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r530504371", "bodyText": "For example, if the inbox has 501 items in it, we'll send it in at least 2 batches: 500 items in the first and 1 in the second. The reason is that no more items are added to the inbox until it's made empty by the process method.\nThe solution would be to fill up the buffer while waiting for the response. But I think we won't be able to reuse the ByteBuffers the way we do now. Also retries would need to be handled in another way.", "author": "viliam-durina", "createdAt": "2020-11-25T16:33:53Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSinkP.java", "diffHunk": "@@ -0,0 +1,354 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.PutRecordsRequestEntry;\n+import com.amazonaws.services.kinesis.model.PutRecordsResult;\n+import com.amazonaws.services.kinesis.model.PutRecordsResultEntry;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.core.Inbox;\n+import com.hazelcast.jet.core.Outbox;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.Watermark;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+\n+public class KinesisSinkP<T> implements Processor {\n+\n+    //todo; Each shard can support writes up to 1,000 records per second, up to a\n+    // maximum data write total of 1 MiB per second. Right now we don't pre-check\n+    // this, because we don't check which item goes to what shard, we just rely\n+    // failure handling with exponential backoff. Would be complicated to improve\n+    // on, but can we affort not to?\n+\n+    /**\n+     * PutRecords requests are limited to 500 records.\n+     */\n+    private static final int MAX_RECORDS_IN_REQUEST = 500;\n+\n+    private static final long PAUSE_AFTER_FAILURE = 1000L; //todo: exponential backoff\n+\n+    /**\n+     * Each record, when encoded as a byte array, is limited to 1M,\n+     * including the partition key (Unicode String).\n+     */\n+    private static final int MAX_RECORD_SIZE_IN_BYTES = 1024 * 1024;\n+\n+    /**\n+     * The maximum allowed size of all the records in a PutRecords request,\n+     * including partition keys is 5M.\n+     */\n+    private static final int MAX_REQUEST_SIZE_IN_BYTES = 5 * 1024 * 1024;\n+\n+    /**\n+     * The number of Unicode characters making up keys is limited to a maximum\n+     * of 256.\n+     */\n+    private static final int MAX_UNICODE_CHARS_IN_KEY = 256;\n+\n+    private final AmazonKinesisAsync kinesis;\n+    private final String stream;\n+\n+    private final Buffer<T> buffer;\n+\n+    private ILogger logger;\n+    private KinesisHelper helper;\n+\n+    private State state = State.READY_TO_SEND;\n+    private long nextSendTime;\n+    private Future<PutRecordsResult> sendResult;\n+\n+    public KinesisSinkP(\n+            AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull FunctionEx<T, String> keyFn,\n+            @Nonnull FunctionEx<T, byte[]> valueFn\n+    ) {\n+        this.kinesis = kinesis;\n+        this.stream = stream;\n+        this.buffer = new Buffer<>(keyFn, valueFn);\n+    }\n+\n+    @Override\n+    public boolean isCooperative() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void init(@Nonnull Outbox outbox, @Nonnull Context context) {\n+        logger = context.logger();\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+        helper.waitForStreamToActivate();\n+    }\n+\n+    @Override\n+    public boolean tryProcessWatermark(@Nonnull Watermark watermark) {\n+        return true; //watermark ignored\n+    }\n+\n+    @Override\n+    public void process(int ordinal, @Nonnull Inbox inbox) {", "originalCommit": "2d266c70b69fb4d4a8d61c6d33348b1399e9dca0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6463e2631d1a155984e553b8c221f080135b9394", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6463e2631d1a155984e553b8c221f080135b9394", "message": "Grammar, remove double logging", "committedDate": "2020-11-25T16:50:21Z", "type": "commit"}, {"oid": "fb266950d88d91d177b3ab05de7ec25e4c181a8b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/fb266950d88d91d177b3ab05de7ec25e4c181a8b", "message": "Address review concerns", "committedDate": "2020-11-26T09:36:31Z", "type": "commit"}, {"oid": "49ebee2691e0221bcb044ab990192a3bffd6d7e6", "url": "https://github.com/hazelcast/hazelcast-jet/commit/49ebee2691e0221bcb044ab990192a3bffd6d7e6", "message": "Merge remote-tracking branch 'origin/kinesis' into kinesis", "committedDate": "2020-11-26T09:36:46Z", "type": "commit"}, {"oid": "5c321cd75e22181553597815b51eccd3efd71544", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5c321cd75e22181553597815b51eccd3efd71544", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-11-26T09:57:39Z", "type": "commit"}, {"oid": "4173407054222ba04b96b03e797caf73650579db", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4173407054222ba04b96b03e797caf73650579db", "message": "Fix jackson version", "committedDate": "2020-11-26T09:58:26Z", "type": "commit"}, {"oid": "d6eb91bab7a1bf86f775e78041b9bd883190de57", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d6eb91bab7a1bf86f775e78041b9bd883190de57", "message": "Minor changes", "committedDate": "2020-11-30T14:25:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjU5NjU3NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532596575", "bodyText": "Javadoc of Collectors.toSet() says:\n\nThere are no guarantees on the type, mutability, serializability, or thread-safety of the Set returned; if more control over the returned Set is required, use toCollection(Supplier).", "author": "viliam-durina", "createdAt": "2020-11-30T13:29:38Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/RangeMonitor.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static java.util.stream.Collectors.joining;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+\n+public class RangeMonitor extends AbstractShardWorker {\n+\n+    /**\n+     * ListStreams operations are limited to 100 per second, per data stream\n+     */\n+    private static final int SHARD_LISTINGS_ALLOWED_PER_SECOND = 100;\n+\n+    /**\n+     * We don't want to issue shard listing requests at the peak allowed rate.\n+     */\n+    private static final double PERCENTAGE_OF_SHARD_LISTING_RATE_UTILIZED = 0.1;\n+\n+    /**\n+     * Failure usually happens due to the over-utilization of resources and/or\n+     * crossing of various limits. Even if we retry the operation it is a good\n+     * idea to add some waits (decrease the rate) in order to alleviate the\n+     * problem.\n+     */\n+    private static final long PAUSE_AFTER_FAILURE = SECONDS.toNanos(1); //todo: exponential backoff\n+\n+    //todo: never removing from the set of known shards, because I have to read from all shards, not\n+    // just the active ones and I have to not read from shards that are closed and I have read from them already...\n+\n+    private final HashRange hashRange;\n+    private final Set<String> knownShards;\n+    private final RandomizedRateTracker listShardsRateTracker;\n+    private final ILogger logger;\n+    private final List<Shard> newShards = new ArrayList<>();\n+\n+    private State state = State.READY_TO_LIST_SHARDS;\n+    private String nextToken;\n+    private Future<ListShardsResult> listShardResult;\n+    private long nextListShardsTime;\n+\n+    public RangeMonitor(\n+            int totalInstances,\n+            AmazonKinesisAsync kinesis,\n+            String stream,\n+            HashRange hashRange,\n+            Collection<Shard> knownShards,\n+            ILogger logger\n+    ) {\n+        super(kinesis, stream, logger);\n+        this.logger = logger;\n+        this.hashRange = hashRange;\n+        this.knownShards = knownShards.stream().map(Shard::getShardId).collect(toSet());", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk1NTE3Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r533955177", "bodyText": "Ok, I wasn't aware of it, thanks, will change it.", "author": "jbartok", "createdAt": "2020-12-02T07:43:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjU5NjU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMTc4OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532601789", "bodyText": "This class seems a bit complex to me, unnecessarily.\nInstead of the Result enum we could return a collection that would be empty or not. Currently we expect that after returning a NEW_SHARDS, the caller is expected to call getNewShards(), and then the next call to run() switches the state to next state.\nWe can also get rid of the state: if listShardResult is not null, wait until it's done. If it's null, wait until it's time and issue a new request.\nThe run method would be better named probe: it will not block, but return the list of new shards, if it has some.\nThis is a suggestion, it's a matter of style, the current code is correct as far as I can tell. IMO it will be easier to read.", "author": "viliam-durina", "createdAt": "2020-11-30T13:37:52Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/RangeMonitor.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static java.util.stream.Collectors.joining;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+\n+public class RangeMonitor extends AbstractShardWorker {", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk2ODA4OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r533968089", "bodyText": "You are absolutely right. I copied the design of ShardReader without thinking. Will change it.", "author": "jbartok", "createdAt": "2020-12-02T08:10:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMTc4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMjM1Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532602353", "bodyText": "We could move the catch clause just after helper.readResult. It will be clearer where the error occurs.", "author": "viliam-durina", "createdAt": "2020-11-30T13:38:48Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/RangeMonitor.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ListShardsResult;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static java.util.stream.Collectors.joining;\n+import static java.util.stream.Collectors.toList;\n+import static java.util.stream.Collectors.toSet;\n+\n+public class RangeMonitor extends AbstractShardWorker {\n+\n+    /**\n+     * ListStreams operations are limited to 100 per second, per data stream\n+     */\n+    private static final int SHARD_LISTINGS_ALLOWED_PER_SECOND = 100;\n+\n+    /**\n+     * We don't want to issue shard listing requests at the peak allowed rate.\n+     */\n+    private static final double PERCENTAGE_OF_SHARD_LISTING_RATE_UTILIZED = 0.1;\n+\n+    /**\n+     * Failure usually happens due to the over-utilization of resources and/or\n+     * crossing of various limits. Even if we retry the operation it is a good\n+     * idea to add some waits (decrease the rate) in order to alleviate the\n+     * problem.\n+     */\n+    private static final long PAUSE_AFTER_FAILURE = SECONDS.toNanos(1); //todo: exponential backoff\n+\n+    //todo: never removing from the set of known shards, because I have to read from all shards, not\n+    // just the active ones and I have to not read from shards that are closed and I have read from them already...\n+\n+    private final HashRange hashRange;\n+    private final Set<String> knownShards;\n+    private final RandomizedRateTracker listShardsRateTracker;\n+    private final ILogger logger;\n+    private final List<Shard> newShards = new ArrayList<>();\n+\n+    private State state = State.READY_TO_LIST_SHARDS;\n+    private String nextToken;\n+    private Future<ListShardsResult> listShardResult;\n+    private long nextListShardsTime;\n+\n+    public RangeMonitor(\n+            int totalInstances,\n+            AmazonKinesisAsync kinesis,\n+            String stream,\n+            HashRange hashRange,\n+            Collection<Shard> knownShards,\n+            ILogger logger\n+    ) {\n+        super(kinesis, stream, logger);\n+        this.logger = logger;\n+        this.hashRange = hashRange;\n+        this.knownShards = knownShards.stream().map(Shard::getShardId).collect(toSet());\n+        this.listShardsRateTracker = initRandomizedTracker(totalInstances);\n+        this.nextListShardsTime = System.nanoTime() + listShardsRateTracker.next();\n+    }\n+\n+    public Result run() {\n+        switch (state) {\n+            case READY_TO_LIST_SHARDS:\n+                return handleReadyToListShards();\n+            case WAITING_FOR_SHARD_LIST:\n+                return handleWaitingForShardList();\n+            case NEW_SHARDS_FOUND:\n+                return handleNewShardsFound();\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+    }\n+\n+    private Result handleReadyToListShards() {\n+        if (System.nanoTime() < nextListShardsTime) {\n+            return Result.NOTHING;\n+        }\n+\n+        listShardResult = helper.listShardsAsync(nextToken);\n+        state = State.WAITING_FOR_SHARD_LIST;\n+\n+        nextListShardsTime = System.nanoTime() + listShardsRateTracker.next();\n+\n+        return Result.NOTHING;\n+    }\n+\n+    private Result handleWaitingForShardList() {\n+        if (listShardResult.isDone()) {\n+            try {\n+                ListShardsResult result = helper.readResult(listShardResult);\n+                nextToken = result.getNextToken();\n+\n+                List<Shard> shards = result.getShards();\n+\n+                List<Shard> unknownShards = shards.stream()\n+                        .filter(shard -> shardBelongsToRange(shard, hashRange))\n+                        .filter(shard -> !knownShards.contains(shard.getShardId())).collect(toList());\n+\n+                if (unknownShards.isEmpty()) {\n+                    state = State.READY_TO_LIST_SHARDS;\n+                    return Result.NOTHING;\n+                } else {\n+                    knownShards.addAll(unknownShards.stream().map(Shard::getShardId).collect(toList()));\n+                    newShards.addAll(unknownShards);\n+                    logger.info(\"New shards detected: \" +\n+                            unknownShards.stream().map(Shard::getShardId).collect(joining(\", \")));\n+                    state = State.NEW_SHARDS_FOUND;\n+                    return Result.NEW_SHARDS;\n+                }\n+            } catch (SdkClientException e) {", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNDM3MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532614370", "bodyText": "Both rangeMonitor and readers check System.nanoTime. It's quite expensive operation if run on the hot path. It might be better to read it once in complete and pass the current value to these methods.", "author": "viliam-durina", "createdAt": "2020-11-30T13:56:58Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSourceP.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.Record;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.Traverser;\n+import com.hazelcast.jet.Traversers;\n+import com.hazelcast.jet.core.AbstractProcessor;\n+import com.hazelcast.jet.core.EventTimeMapper;\n+import com.hazelcast.jet.core.EventTimePolicy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.Util.entry;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+\n+public class KinesisSourceP extends AbstractProcessor {\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nonnull\n+    private final EventTimeMapper<? super Map.Entry<String, byte[]>> eventTimeMapper;\n+    @Nonnull\n+    private final HashRange hashRange;\n+\n+    private int id;\n+    private ILogger logger;\n+\n+    private Traverser<Object> traverser = Traversers.empty();\n+\n+    private KinesisHelper helper;\n+    private RangeMonitor rangeMonitor;\n+    private List<ShardReader> shardReaders = new ArrayList<>();\n+    private int nextReader;\n+\n+    public KinesisSourceP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull EventTimePolicy<? super Map.Entry<String, byte[]>> eventTimePolicy,\n+            @Nonnull HashRange hashRange\n+    ) {\n+        this.kinesis = Objects.requireNonNull(kinesis, \"kinesis\");\n+        this.stream = Objects.requireNonNull(stream, \"stream\");\n+        this.eventTimeMapper = new EventTimeMapper<>(eventTimePolicy);\n+        this.hashRange = Objects.requireNonNull(hashRange, \"hashRange\");\n+    }\n+\n+    @Override\n+    protected void init(@Nonnull Context context) throws Exception {\n+        super.init(context);\n+\n+        logger = context.logger();\n+        id = context.globalProcessorIndex();\n+\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+\n+        logger.info(\"Processor \" + id + \" handles \" + hashRange);\n+\n+        helper.waitForStreamToActivate();\n+        List<Shard> shardsInRange = helper.listShards(\n+                (Predicate<? super Shard>) shard -> shardBelongsToRange(shard, hashRange));\n+        rangeMonitor = new RangeMonitor(context.totalParallelism(), kinesis, stream, hashRange, shardsInRange, logger);\n+        addShardReaders(shardsInRange);\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (!emitFromTraverser(traverser)) {\n+            return false;\n+        }\n+\n+        runMonitor();\n+        runReaders();", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMTEyNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532621124", "bodyText": "What about using ArrayDeque? The linked list uses more memory and has more dereferencing. It allows for random removals, but we don't need that, we only remove from one and and add to the other.", "author": "viliam-durina", "createdAt": "2020-11-30T14:06:45Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/ShardReader.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ExpiredIteratorException;\n+import com.amazonaws.services.kinesis.model.GetRecordsResult;\n+import com.amazonaws.services.kinesis.model.GetShardIteratorResult;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.Record;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.logging.ILogger;\n+\n+import java.util.LinkedList;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+class ShardReader extends AbstractShardWorker {\n+\n+    /* Kinesis allows for a maximum of 5 GetRecords operations per second. */\n+    private static final int GET_RECORD_OPS_PER_SECOND = 5;\n+\n+    /* Even though GetRecords operations are limited to 5 per second, if one\n+     * such operation happens to return too much data, following operations will\n+     * throw ProvisionedThroughputExceededException. In such cases we need to\n+     * wait a bit longer than for regular rate limiting.\n+     *\n+     * Relevant section from AWS documentation:\n+     *\n+     * \"The size of the data returned by GetRecords varies depending on the\n+     * utilization of the shard. The maximum size of data that GetRecords can\n+     * return is 10 MiB. If a call returns this amount of data, subsequent calls\n+     * made within the next 5 seconds throw\n+     * ProvisionedThroughputExceededException. If there is insufficient\n+     * provisioned throughput on the stream, subsequent calls made within the\n+     * next 1 second throw ProvisionedThroughputExceededException. GetRecords\n+     * doesn't return any data when it throws an exception. For this reason, we\n+     * recommend that you wait 1 second between calls to GetRecords. However,\n+     * it's possible that the application will get exceptions for longer than\n+     * 1 second.\"\n+     *\n+     * We also need to add this extra wait whenever we encounter other unexpected\n+     * failures.\n+     * */\n+    private static final long PAUSE_AFTER_FAILURE = SECONDS.toNanos(1); //todo: exponential backoff\n+\n+    /**\n+     * Maximum number of records returned by this reader in a single batch. Is\n+     * limited due to being used from a cooperative processor. Should not pose\n+     * a performance bottleneck, because while available data is being processed\n+     * the asynchronous request for more will already be issued in the background.\n+     */\n+    private static final int DATA_BATCH_SIZE = 100;\n+\n+    private final Shard shard;\n+    private final RandomizedRateTracker getRecordsRateTracker =\n+            new RandomizedRateTracker(1000, GET_RECORD_OPS_PER_SECOND);\n+\n+    private State state = State.NO_SHARD_ITERATOR;\n+    private String shardIterator;\n+    private Future<GetShardIteratorResult> shardIteratorResult;\n+    private Future<GetRecordsResult> recordsResult;\n+    private long nextGetRecordsTime = System.nanoTime();\n+\n+    private final LinkedList<Record> data = new LinkedList<>();", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyNDU5Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532624592", "bodyText": "There's a bit too much copying: we copy the results from GetRecordsResult to LinkedList<Record> in handleWaitingForRecords. Then from the linked list to an array in getData(). I think neither of this is necessary - can't we directly return the List<Record> from the GetRecordsResult in getData? Why do we need the batching here?", "author": "viliam-durina", "createdAt": "2020-11-30T14:11:45Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/ShardReader.java", "diffHunk": "@@ -0,0 +1,278 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.SdkClientException;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.ExpiredIteratorException;\n+import com.amazonaws.services.kinesis.model.GetRecordsResult;\n+import com.amazonaws.services.kinesis.model.GetShardIteratorResult;\n+import com.amazonaws.services.kinesis.model.ProvisionedThroughputExceededException;\n+import com.amazonaws.services.kinesis.model.Record;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.logging.ILogger;\n+\n+import java.util.LinkedList;\n+import java.util.concurrent.Future;\n+\n+import static com.hazelcast.jet.impl.util.ExceptionUtil.rethrow;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+class ShardReader extends AbstractShardWorker {\n+\n+    /* Kinesis allows for a maximum of 5 GetRecords operations per second. */\n+    private static final int GET_RECORD_OPS_PER_SECOND = 5;\n+\n+    /* Even though GetRecords operations are limited to 5 per second, if one\n+     * such operation happens to return too much data, following operations will\n+     * throw ProvisionedThroughputExceededException. In such cases we need to\n+     * wait a bit longer than for regular rate limiting.\n+     *\n+     * Relevant section from AWS documentation:\n+     *\n+     * \"The size of the data returned by GetRecords varies depending on the\n+     * utilization of the shard. The maximum size of data that GetRecords can\n+     * return is 10 MiB. If a call returns this amount of data, subsequent calls\n+     * made within the next 5 seconds throw\n+     * ProvisionedThroughputExceededException. If there is insufficient\n+     * provisioned throughput on the stream, subsequent calls made within the\n+     * next 1 second throw ProvisionedThroughputExceededException. GetRecords\n+     * doesn't return any data when it throws an exception. For this reason, we\n+     * recommend that you wait 1 second between calls to GetRecords. However,\n+     * it's possible that the application will get exceptions for longer than\n+     * 1 second.\"\n+     *\n+     * We also need to add this extra wait whenever we encounter other unexpected\n+     * failures.\n+     * */\n+    private static final long PAUSE_AFTER_FAILURE = SECONDS.toNanos(1); //todo: exponential backoff\n+\n+    /**\n+     * Maximum number of records returned by this reader in a single batch. Is\n+     * limited due to being used from a cooperative processor. Should not pose\n+     * a performance bottleneck, because while available data is being processed\n+     * the asynchronous request for more will already be issued in the background.\n+     */\n+    private static final int DATA_BATCH_SIZE = 100;\n+\n+    private final Shard shard;\n+    private final RandomizedRateTracker getRecordsRateTracker =\n+            new RandomizedRateTracker(1000, GET_RECORD_OPS_PER_SECOND);\n+\n+    private State state = State.NO_SHARD_ITERATOR;\n+    private String shardIterator;\n+    private Future<GetShardIteratorResult> shardIteratorResult;\n+    private Future<GetRecordsResult> recordsResult;\n+    private long nextGetRecordsTime = System.nanoTime();\n+\n+    private final LinkedList<Record> data = new LinkedList<>();\n+\n+    ShardReader(AmazonKinesisAsync kinesis, String stream, Shard shard, ILogger logger) {\n+        super(kinesis, stream, logger);\n+        this.shard = shard;\n+    }\n+\n+    public Result run() {\n+        switch (state) {\n+            case NO_SHARD_ITERATOR:\n+                return handleNoShardIterator();\n+            case WAITING_FOR_SHARD_ITERATOR:\n+                return handleWaitingForShardIterator();\n+            case NEED_TO_REQUEST_RECORDS:\n+                return handleNeedToRequestRecords();\n+            case WAITING_FOR_RECORDS:\n+                return handleWaitingForRecords();\n+            case HAS_DATA_NEED_TO_REQUEST_RECORDS:\n+                return handleHasDataNeedToRequestRecords();\n+            case HAS_DATA:\n+                return handleHasData();\n+            case SHARD_CLOSED:\n+                return handleShardClosed();\n+            default:\n+                throw new RuntimeException(\"Programming error, unhandled state: \" + state);\n+        }\n+    }\n+\n+    private Result handleNoShardIterator() {\n+        shardIteratorResult = helper.getShardIteratorAsync(shard);\n+        state = State.WAITING_FOR_SHARD_ITERATOR;\n+        return Result.NOTHING;\n+    }\n+\n+    private Result handleWaitingForShardIterator() {\n+        if (shardIteratorResult.isDone()) {\n+            try {\n+                shardIterator = helper.readResult(shardIteratorResult).getShardIterator();\n+                state = State.NEED_TO_REQUEST_RECORDS;\n+            } catch (SdkClientException sce) {\n+                logger.warning(\"Failed retrieving shard iterator, retrying. Cause: \" + sce.getMessage());\n+                state = State.NO_SHARD_ITERATOR;\n+                return Result.NOTHING;\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            }\n+        }\n+        return Result.NOTHING;\n+    }\n+\n+    private Result handleNeedToRequestRecords() {\n+        if (attemptToSendGetRecordsRequest()) {\n+            state = State.WAITING_FOR_RECORDS;\n+        }\n+\n+        return Result.NOTHING;\n+    }\n+\n+    private Result handleWaitingForRecords() {\n+        if (recordsResult.isDone()) {\n+            try {\n+                GetRecordsResult result = helper.readResult(recordsResult);\n+                shardIterator = result.getNextShardIterator();\n+                data.addAll(result.getRecords());\n+                if (shardIterator == null) {\n+                    state = State.SHARD_CLOSED;\n+                    return data.size() > 0 ? Result.HAS_DATA : Result.CLOSED;\n+                } else if (data.size() > 0) {\n+                    state = State.HAS_DATA_NEED_TO_REQUEST_RECORDS;\n+                    return Result.HAS_DATA;\n+                } else {\n+                    state = State.NEED_TO_REQUEST_RECORDS;\n+                    return Result.NOTHING;\n+                }\n+            } catch (ProvisionedThroughputExceededException pte) {\n+                return dealWithReadRecordFailure(\"Data throughput rate exceeded. Backing off and retrying.\");\n+            } catch (ExpiredIteratorException eie) {\n+                return dealWithReadRecordFailure(\"Record iterator expired. Retrying.\");\n+            } catch (SdkClientException sce) {\n+                return dealWithReadRecordFailure(\"Failed reading records, retrying. Cause: \" + sce.getMessage());\n+            } catch (Throwable t) {\n+                throw rethrow(t);\n+            }\n+        } else {\n+            return Result.NOTHING;\n+        }\n+    }\n+\n+    private Result dealWithReadRecordFailure(String message) {\n+        logger.warning(message);\n+        nextGetRecordsTime = System.nanoTime() + PAUSE_AFTER_FAILURE;\n+        state = State.NEED_TO_REQUEST_RECORDS;\n+        return Result.NOTHING;\n+    }\n+\n+    private Result handleHasDataNeedToRequestRecords() {\n+        if (attemptToSendGetRecordsRequest()) {\n+            state = data.size() > 0 ? State.HAS_DATA : State.WAITING_FOR_RECORDS;\n+        }\n+\n+        return data.size() > 0 ? Result.HAS_DATA : Result.NOTHING;\n+    }\n+\n+    private Result handleHasData() {\n+        state = data.size() > 0 ? State.HAS_DATA : State.WAITING_FOR_RECORDS;\n+        return data.size() > 0 ? Result.HAS_DATA : Result.NOTHING;\n+    }\n+\n+    private Result handleShardClosed() {\n+        return data.size() > 0 ? Result.HAS_DATA : Result.CLOSED;\n+    }\n+\n+    private boolean attemptToSendGetRecordsRequest() {\n+        if (System.nanoTime() < nextGetRecordsTime) {\n+            return false;\n+        }\n+\n+        recordsResult = helper.getRecordsAsync(shardIterator);\n+\n+        nextGetRecordsTime = System.nanoTime() + getRecordsRateTracker.next();\n+        return true;\n+    }\n+\n+    public Shard getShard() {\n+        return shard;\n+    }\n+\n+    public Record[] getData() {\n+        if (data.isEmpty()) {\n+            throw new IllegalStateException(\"Can't ask for data when none is available\");\n+        }\n+\n+        Record[] records = new Record[Math.min(data.size(), DATA_BATCH_SIZE)];", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDAzNjQ3Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r534036472", "bodyText": "I've added the batching because GetRecordsResult can contain up to 10,000 records and since the source is supposed to be cooperative, that's a bit much to return in one go, or is it not?", "author": "jbartok", "createdAt": "2020-12-02T09:56:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyNDU5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDA0NzY1MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r534047651", "bodyText": "We should add to the outbox as much as the outbox accepts. We should limit the time spent in the call, but we're just copying items so we're not doing much work. This is what we do elsewhere: the outbox free capacity is the limit for the batch size.", "author": "viliam-durina", "createdAt": "2020-12-02T10:12:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyNDU5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyNzg2NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r532627864", "bodyText": "I think we should also save the list of closed shards until we're sure they will be no longer returned from ListShards.", "author": "viliam-durina", "createdAt": "2020-11-30T14:16:23Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSourceP.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.Record;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.Traverser;\n+import com.hazelcast.jet.Traversers;\n+import com.hazelcast.jet.core.AbstractProcessor;\n+import com.hazelcast.jet.core.EventTimeMapper;\n+import com.hazelcast.jet.core.EventTimePolicy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+\n+import static com.hazelcast.jet.Util.entry;\n+import static com.hazelcast.jet.kinesis.impl.KinesisHelper.shardBelongsToRange;\n+\n+public class KinesisSourceP extends AbstractProcessor {\n+\n+    @Nonnull\n+    private final AmazonKinesisAsync kinesis;\n+    @Nonnull\n+    private final String stream;\n+    @Nonnull\n+    private final EventTimeMapper<? super Map.Entry<String, byte[]>> eventTimeMapper;\n+    @Nonnull\n+    private final HashRange hashRange;\n+\n+    private int id;\n+    private ILogger logger;\n+\n+    private Traverser<Object> traverser = Traversers.empty();\n+\n+    private KinesisHelper helper;\n+    private RangeMonitor rangeMonitor;\n+    private List<ShardReader> shardReaders = new ArrayList<>();\n+    private int nextReader;\n+\n+    public KinesisSourceP(\n+            @Nonnull AmazonKinesisAsync kinesis,\n+            @Nonnull String stream,\n+            @Nonnull EventTimePolicy<? super Map.Entry<String, byte[]>> eventTimePolicy,\n+            @Nonnull HashRange hashRange\n+    ) {\n+        this.kinesis = Objects.requireNonNull(kinesis, \"kinesis\");\n+        this.stream = Objects.requireNonNull(stream, \"stream\");\n+        this.eventTimeMapper = new EventTimeMapper<>(eventTimePolicy);\n+        this.hashRange = Objects.requireNonNull(hashRange, \"hashRange\");\n+    }\n+\n+    @Override\n+    protected void init(@Nonnull Context context) throws Exception {\n+        super.init(context);\n+\n+        logger = context.logger();\n+        id = context.globalProcessorIndex();\n+\n+        helper = new KinesisHelper(kinesis, stream, logger);\n+\n+        logger.info(\"Processor \" + id + \" handles \" + hashRange);\n+\n+        helper.waitForStreamToActivate();\n+        List<Shard> shardsInRange = helper.listShards(\n+                (Predicate<? super Shard>) shard -> shardBelongsToRange(shard, hashRange));\n+        rangeMonitor = new RangeMonitor(context.totalParallelism(), kinesis, stream, hashRange, shardsInRange, logger);\n+        addShardReaders(shardsInRange);\n+    }\n+\n+    @Override\n+    public boolean complete() {\n+        if (!emitFromTraverser(traverser)) {\n+            return false;\n+        }\n+\n+        runMonitor();\n+        runReaders();\n+        return false;\n+    }\n+\n+    private void runMonitor() {\n+        RangeMonitor.Result result = rangeMonitor.run();\n+        if (RangeMonitor.Result.NEW_SHARDS.equals(result)) {\n+            Collection<Shard> shards = rangeMonitor.getNewShards();\n+            addShardReaders(shards);\n+        }\n+    }\n+\n+    private void runReaders() {\n+        for (int i = 0; i < shardReaders.size(); i++) {\n+            int currentReader = nextReader;\n+            ShardReader reader = shardReaders.get(currentReader);\n+            nextReader = incrCircular(currentReader, shardReaders.size());\n+\n+            ShardReader.Result result = reader.run();\n+            if (ShardReader.Result.HAS_DATA.equals(result)) {\n+                Record[] records = reader.getData();\n+                traverser = Traversers.traverseArray(records)\n+                        .flatMap(record -> eventTimeMapper.flatMapEvent(\n+                                entry(record.getPartitionKey(), record.getData().array()), //todo: shady?\n+                                currentReader,\n+                                record.getApproximateArrivalTimestamp().getTime()\n+                        ));\n+                emitFromTraverser(traverser);\n+                return;\n+            } else if (ShardReader.Result.CLOSED.equals(result)) {\n+                Shard shard = reader.getShard();\n+                logger.info(\"Shard \" + shard.getShardId() + \" of stream \" + stream + \" closed\");\n+                removeShardReader(currentReader);\n+                nextReader = 0;\n+                return;\n+            }\n+        }\n+\n+        traverser = eventTimeMapper.flatMapIdle();\n+        emitFromTraverser(traverser);\n+    }\n+\n+    @Override\n+    public boolean saveToSnapshot() {\n+        if (!emitFromTraverser(traverser)) {\n+            return false;\n+        }\n+\n+        //todo: actual snapshot saving; we will be saving the sequence numbers of last seen messages, per shard", "originalCommit": "4173407054222ba04b96b03e797caf73650579db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDAzNzUzMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r534037531", "bodyText": "Ok, will keep in mind, have set a todo.", "author": "jbartok", "createdAt": "2020-12-02T09:57:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyNzg2NA=="}], "type": "inlineReview"}, {"oid": "d9bdc0bfb4c64f3bbb705e4482a25852a3537603", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d9bdc0bfb4c64f3bbb705e4482a25852a3537603", "message": "Addressing review concerns", "committedDate": "2020-12-02T08:04:49Z", "type": "commit"}, {"oid": "5b80af7073a6df7b2092d516f53977491f4592af", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5b80af7073a6df7b2092d516f53977491f4592af", "message": "Addressing review concerns", "committedDate": "2020-12-02T08:17:14Z", "type": "commit"}, {"oid": "d14a50669e46ee2e2d4ff17ad4548c602b60a623", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d14a50669e46ee2e2d4ff17ad4548c602b60a623", "message": "Addressing review concerns", "committedDate": "2020-12-02T09:11:39Z", "type": "commit"}, {"oid": "68a2ec1c6102a7c00b2fbb68f734b74f23b22f66", "url": "https://github.com/hazelcast/hazelcast-jet/commit/68a2ec1c6102a7c00b2fbb68f734b74f23b22f66", "message": "Addressing review concerns", "committedDate": "2020-12-02T10:22:20Z", "type": "commit"}, {"oid": "b82c039e261697a2d4dd648d26038d4f7df8f74d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b82c039e261697a2d4dd648d26038d4f7df8f74d", "message": "Make source fault tolerant, works for static streams", "committedDate": "2020-12-03T11:38:42Z", "type": "commit"}, {"oid": "f3d194ea99f91de326de1fc6e7da0716d9f7e854", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f3d194ea99f91de326de1fc6e7da0716d9f7e854", "message": "Attempt to fix test failure", "committedDate": "2020-12-03T17:00:24Z", "type": "commit"}, {"oid": "f88b08c5be1c416c8927635dfa4c24e0cbdd5618", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f88b08c5be1c416c8927635dfa4c24e0cbdd5618", "message": "Poll shard metadata only once per member", "committedDate": "2020-12-06T08:47:59Z", "type": "commit"}, {"oid": "84c9f6a97aef379f85e71f296a352ee8e4cd096a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/84c9f6a97aef379f85e71f296a352ee8e4cd096a", "message": "Make sure source fault tolerance works", "committedDate": "2020-12-07T08:08:21Z", "type": "commit"}, {"oid": "8ed63c124c1db7fb971e588a5f041fab9caeb169", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8ed63c124c1db7fb971e588a5f041fab9caeb169", "message": "Add small fix, until it shows up on master", "committedDate": "2020-12-07T10:04:30Z", "type": "commit"}, {"oid": "e69c4caf4101f0c02d8347070f61eff0215ff308", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e69c4caf4101f0c02d8347070f61eff0215ff308", "message": "Add small fix, until it shows up on master", "committedDate": "2020-12-07T10:08:03Z", "type": "commit"}, {"oid": "717ab4c22cb2fde38cb421afbb772f8fcc537c4a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/717ab4c22cb2fde38cb421afbb772f8fcc537c4a", "message": "Make sink fault tolerant (at-least once), do various changes", "committedDate": "2020-12-07T11:14:37Z", "type": "commit"}, {"oid": "a008524e9c769d4599c3e51d31df33c1116a2957", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a008524e9c769d4599c3e51d31df33c1116a2957", "message": "Simplify builders", "committedDate": "2020-12-07T11:43:07Z", "type": "commit"}, {"oid": "81e717c74ead5caaae12902a238d5b978cb40920", "url": "https://github.com/hazelcast/hazelcast-jet/commit/81e717c74ead5caaae12902a238d5b978cb40920", "message": "Add exponential backoff to retries", "committedDate": "2020-12-08T10:14:25Z", "type": "commit"}, {"oid": "3e054c8074d7fdad7501d7749b344ace3b66f07a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3e054c8074d7fdad7501d7749b344ace3b66f07a", "message": "Modify retry strategy configuration", "committedDate": "2020-12-08T12:38:16Z", "type": "commit"}, {"oid": "8513d3e0be701205b0360e2cacfef61d86a1e9b6", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8513d3e0be701205b0360e2cacfef61d86a1e9b6", "message": "Make checkstyle happy", "committedDate": "2020-12-08T12:45:06Z", "type": "commit"}, {"oid": "719836d2ef067e94827627abd4d0bf6de7b87425", "url": "https://github.com/hazelcast/hazelcast-jet/commit/719836d2ef067e94827627abd4d0bf6de7b87425", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-12-09T08:58:01Z", "type": "commit"}, {"oid": "6126832abda4dbc0ba2081b386fb8e30110206e1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6126832abda4dbc0ba2081b386fb8e30110206e1", "message": "Control throughput in the sink", "committedDate": "2020-12-14T13:19:04Z", "type": "commit"}, {"oid": "efac18ab93dd99266d84c00159ffdd3cba7746e7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/efac18ab93dd99266d84c00159ffdd3cba7746e7", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-12-15T07:38:43Z", "type": "commit"}, {"oid": "77f0995d8cfd04973956aa9761bd1593f53499bd", "url": "https://github.com/hazelcast/hazelcast-jet/commit/77f0995d8cfd04973956aa9761bd1593f53499bd", "message": "Add some more tests", "committedDate": "2020-12-15T11:16:00Z", "type": "commit"}, {"oid": "dcb527e2ac4d88dee8471bed5fb339d18fd8224f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/dcb527e2ac4d88dee8471bed5fb339d18fd8224f", "message": "Add some more tests", "committedDate": "2020-12-15T14:13:14Z", "type": "commit"}, {"oid": "17d6e220ad5dc7870e7199811ac6ae0441719d32", "url": "https://github.com/hazelcast/hazelcast-jet/commit/17d6e220ad5dc7870e7199811ac6ae0441719d32", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-12-15T21:00:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY5MzAyMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r543693021", "bodyText": "Is this based on some testing or is it a recommendation by Amazon? It should be mentioned here.", "author": "viliam-durina", "createdAt": "2020-12-15T21:18:27Z", "path": "extensions/kinesis/src/main/java/com/hazelcast/jet/kinesis/impl/KinesisSourcePSupplier.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.hazelcast.jet.kinesis.impl;\n+\n+import com.amazonaws.services.kinesis.AmazonKinesis;\n+import com.amazonaws.services.kinesis.AmazonKinesisAsync;\n+import com.amazonaws.services.kinesis.model.Shard;\n+import com.hazelcast.jet.core.EventTimePolicy;\n+import com.hazelcast.jet.core.Processor;\n+import com.hazelcast.jet.core.ProcessorSupplier;\n+import com.hazelcast.jet.retry.RetryStrategy;\n+import com.hazelcast.logging.ILogger;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.stream.IntStream;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class KinesisSourcePSupplier implements ProcessorSupplier {\n+\n+    private static final long serialVersionUID = 1L;\n+\n+    /**\n+     * We don't want to create an AWS client for each processor instance,\n+     * because they aren't light. We also can't do the other extreme, have a\n+     * single AWS client shared by all processors, because there would be a lot\n+     * of contention, causing problems. So we use shared clients but use them\n+     * for a limited number of processor instances, specified by this constant.\n+     */\n+    private static final int PROCESSORS_PER_CLIENT = 12;", "originalCommit": "17d6e220ad5dc7870e7199811ac6ae0441719d32", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzgzNDk5Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2656#discussion_r547834996", "bodyText": "I've re-examined and re-tested this, it's not actually necessary, so I've removed it. Some wrong conclusions/reasonings have lead me to add it before.", "author": "jbartok", "createdAt": "2020-12-23T09:07:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY5MzAyMQ=="}], "type": "inlineReview"}, {"oid": "2fbdddf90dc98808c27727c52a2fe1f8cf2d72bc", "url": "https://github.com/hazelcast/hazelcast-jet/commit/2fbdddf90dc98808c27727c52a2fe1f8cf2d72bc", "message": "Remove duplicate line", "committedDate": "2020-12-16T09:13:57Z", "type": "commit"}, {"oid": "20728c2996537f1dd9e33bfa490d44190de7b0da", "url": "https://github.com/hazelcast/hazelcast-jet/commit/20728c2996537f1dd9e33bfa490d44190de7b0da", "message": "Add eviction of expired shards", "committedDate": "2020-12-16T10:51:57Z", "type": "commit"}, {"oid": "50c4bea194ce4b246769479fa0d8873aff83679f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/50c4bea194ce4b246769479fa0d8873aff83679f", "message": "Add some TODOs", "committedDate": "2020-12-16T11:03:05Z", "type": "commit"}, {"oid": "82c9c6bbc0f0f626d333b24d3575dd905920467e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/82c9c6bbc0f0f626d333b24d3575dd905920467e", "message": "Write the first version of the TDD", "committedDate": "2020-12-21T10:01:26Z", "type": "commit"}, {"oid": "92c41d2d329b4c912024828b41a9676216106193", "url": "https://github.com/hazelcast/hazelcast-jet/commit/92c41d2d329b4c912024828b41a9676216106193", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-12-21T10:03:56Z", "type": "commit"}, {"oid": "92c41d2d329b4c912024828b41a9676216106193", "url": "https://github.com/hazelcast/hazelcast-jet/commit/92c41d2d329b4c912024828b41a9676216106193", "message": "Merge branch 'master' into kinesis", "committedDate": "2020-12-21T10:03:56Z", "type": "forcePushed"}, {"oid": "a44d4f00721c06579a2a38aa38ca4de82039cc27", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a44d4f00721c06579a2a38aa38ca4de82039cc27", "message": "Fix EventTimeMapper related bug", "committedDate": "2020-12-22T08:12:26Z", "type": "commit"}, {"oid": "03f59952e010cc05e7da566bfce9387e0b184966", "url": "https://github.com/hazelcast/hazelcast-jet/commit/03f59952e010cc05e7da566bfce9387e0b184966", "message": "Add Kinesis to the distribution", "committedDate": "2020-12-22T08:12:45Z", "type": "commit"}, {"oid": "ecc730e39c211d217e4fa83faf0df5d9ff042f07", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ecc730e39c211d217e4fa83faf0df5d9ff042f07", "message": "Fix bugs", "committedDate": "2020-12-22T10:52:09Z", "type": "commit"}, {"oid": "e90966bca3c5cee2752b7f7c02b2d988965d3604", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e90966bca3c5cee2752b7f7c02b2d988965d3604", "message": "Add javadoc", "committedDate": "2020-12-22T10:52:37Z", "type": "commit"}, {"oid": "a5baf1abf2f74b9833685767bde9201f69c47830", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a5baf1abf2f74b9833685767bde9201f69c47830", "message": "Fix bug, improve tests", "committedDate": "2020-12-22T13:33:53Z", "type": "commit"}, {"oid": "372f3e8ab648f821536cea718e4642f04074aa7d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/372f3e8ab648f821536cea718e4642f04074aa7d", "message": "Improve tests", "committedDate": "2020-12-23T08:29:15Z", "type": "commit"}, {"oid": "8609e7b6f687a9982d8347cd6def0ef468083dbe", "url": "https://github.com/hazelcast/hazelcast-jet/commit/8609e7b6f687a9982d8347cd6def0ef468083dbe", "message": "Change expiration related implementation", "committedDate": "2020-12-23T08:29:24Z", "type": "commit"}, {"oid": "edbb8bb0904a41d091b0a85b9226a60fd9406b12", "url": "https://github.com/hazelcast/hazelcast-jet/commit/edbb8bb0904a41d091b0a85b9226a60fd9406b12", "message": "Remove unnecessary complications", "committedDate": "2020-12-23T09:05:17Z", "type": "commit"}, {"oid": "1d67987aafdd684d3f0ed25330ccee89a0d172ad", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1d67987aafdd684d3f0ed25330ccee89a0d172ad", "message": "Address review concerns", "committedDate": "2020-12-23T10:37:37Z", "type": "commit"}, {"oid": "cb736640d67378785d6e72e9797a4d7f553196a9", "url": "https://github.com/hazelcast/hazelcast-jet/commit/cb736640d67378785d6e72e9797a4d7f553196a9", "message": "Remove local parallelism hardcoding", "committedDate": "2020-12-23T11:08:37Z", "type": "commit"}, {"oid": "321f3a57fccc7a0b745f5c1fe50c49cee9a52390", "url": "https://github.com/hazelcast/hazelcast-jet/commit/321f3a57fccc7a0b745f5c1fe50c49cee9a52390", "message": "Address review concerns", "committedDate": "2020-12-24T06:01:39Z", "type": "commit"}, {"oid": "0df5525326fd92f192c121023d603512e23a663f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0df5525326fd92f192c121023d603512e23a663f", "message": "Implement metrics, improve tests", "committedDate": "2020-12-24T10:12:37Z", "type": "commit"}, {"oid": "bc138f18bef001b3ed039365d0561fd747a4ebcf", "url": "https://github.com/hazelcast/hazelcast-jet/commit/bc138f18bef001b3ed039365d0561fd747a4ebcf", "message": "Add Kinesis tutorial, make sure it works", "committedDate": "2020-12-28T12:57:50Z", "type": "commit"}, {"oid": "1b7f8560a717a8c169ead6af86fa04230b2b756c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1b7f8560a717a8c169ead6af86fa04230b2b756c", "message": "Handle producer retries in test", "committedDate": "2020-12-29T09:45:38Z", "type": "commit"}, {"oid": "898987a209e10b136a811550d0a7bda95b05a4d4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/898987a209e10b136a811550d0a7bda95b05a4d4", "message": "Address ClientConfiguration", "committedDate": "2020-12-29T10:06:51Z", "type": "commit"}, {"oid": "4c842ba12ea554c1ea944e24c8cc74b95f059f90", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4c842ba12ea554c1ea944e24c8cc74b95f059f90", "message": "Remove ClientConfiguration", "committedDate": "2020-12-29T11:29:40Z", "type": "commit"}, {"oid": "a3e66eed11f3f9aa761660da8b4aec8f7e4ebb8d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a3e66eed11f3f9aa761660da8b4aec8f7e4ebb8d", "message": "Finished sources & sinks documentation update", "committedDate": "2020-12-30T08:24:53Z", "type": "commit"}, {"oid": "958abb850a7c507db8ee09e4a3345fc98048354f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/958abb850a7c507db8ee09e4a3345fc98048354f", "message": "Write all javadoc (NEEDS CHECKING)", "committedDate": "2020-12-30T12:41:40Z", "type": "commit"}, {"oid": "f97b566c186da9decfc80f4dc803af1e8f489692", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f97b566c186da9decfc80f4dc803af1e8f489692", "message": "Spell-check recent javadocs", "committedDate": "2020-12-31T08:32:06Z", "type": "commit"}, {"oid": "6433029c85d2d18542d640df370fad9b61889d51", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6433029c85d2d18542d640df370fad9b61889d51", "message": "Merge branch 'master' into kinesis", "committedDate": "2021-01-04T08:35:12Z", "type": "commit"}, {"oid": "942fae336e600bddd83a0d8d29fb46878b5f195f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/942fae336e600bddd83a0d8d29fb46878b5f195f", "message": "Change shard state serialization", "committedDate": "2021-01-04T10:29:33Z", "type": "commit"}, {"oid": "f8a4c0da340a2d9dfd26633f46c0a4dc407c06d4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f8a4c0da340a2d9dfd26633f46c0a4dc407c06d4", "message": "Add clean-up section to tutorial", "committedDate": "2021-01-04T11:27:49Z", "type": "commit"}, {"oid": "7756af1bbd27c061ddd74d8f998326abdd171e15", "url": "https://github.com/hazelcast/hazelcast-jet/commit/7756af1bbd27c061ddd74d8f998326abdd171e15", "message": "Rename and document the asymmetrical tracker for sleep times", "committedDate": "2021-01-04T11:33:18Z", "type": "commit"}, {"oid": "b7fe0907044a3e74cb7f4cd5ccb03a7ab9909e47", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b7fe0907044a3e74cb7f4cd5ccb03a7ab9909e47", "message": "Solve and remove minor TODOs", "committedDate": "2021-01-04T12:16:46Z", "type": "commit"}, {"oid": "c2a9d3ec0acceb541585651d5fe349d44b56cac1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c2a9d3ec0acceb541585651d5fe349d44b56cac1", "message": "Solve final TODOs", "committedDate": "2021-01-05T08:19:42Z", "type": "commit"}, {"oid": "25afc92be6b738b3100650a2311e717658131453", "url": "https://github.com/hazelcast/hazelcast-jet/commit/25afc92be6b738b3100650a2311e717658131453", "message": "Merge branch 'master' into kinesis", "committedDate": "2021-01-05T11:33:31Z", "type": "commit"}, {"oid": "c0dfa6b217360339a2c18c688f8f9cca061ff5ef", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c0dfa6b217360339a2c18c688f8f9cca061ff5ef", "message": "Make checkstyle happy", "committedDate": "2021-01-05T12:04:30Z", "type": "commit"}, {"oid": "03129217fa36d69ce61d8ee61ccb48cb6ea2695e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/03129217fa36d69ce61d8ee61ccb48cb6ea2695e", "message": "Merge branch 'master' into kinesis", "committedDate": "2021-01-07T07:37:03Z", "type": "commit"}, {"oid": "42c5ceeb17cd1a95869ed14ddfcddf96d58394c3", "url": "https://github.com/hazelcast/hazelcast-jet/commit/42c5ceeb17cd1a95869ed14ddfcddf96d58394c3", "message": "Address review concerns", "committedDate": "2021-01-07T08:08:08Z", "type": "commit"}, {"oid": "9dd61b0a43787374ffe95128cc815822403798cb", "url": "https://github.com/hazelcast/hazelcast-jet/commit/9dd61b0a43787374ffe95128cc815822403798cb", "message": "Address review concerns", "committedDate": "2021-01-07T08:27:35Z", "type": "commit"}, {"oid": "0ef28c3f311c74ca702cb77f69af345c1ffd8b2b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0ef28c3f311c74ca702cb77f69af345c1ffd8b2b", "message": "Improve tests a bit", "committedDate": "2021-01-08T12:27:44Z", "type": "commit"}, {"oid": "6528e1fbd8f42471cd7fd92549e8ac521b08041e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6528e1fbd8f42471cd7fd92549e8ac521b08041e", "message": "Make initial shard iterators configurable", "committedDate": "2021-01-11T13:00:14Z", "type": "commit"}, {"oid": "3210b8420ed35ceb9bacd82995560f3bf97f76e5", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3210b8420ed35ceb9bacd82995560f3bf97f76e5", "message": "Test initial shard iterator mechanism", "committedDate": "2021-01-12T11:19:00Z", "type": "commit"}, {"oid": "71e88f662a3d4c2021925b9b8cea8c23271e1bcd", "url": "https://github.com/hazelcast/hazelcast-jet/commit/71e88f662a3d4c2021925b9b8cea8c23271e1bcd", "message": "Merge branch 'master' into kinesis", "committedDate": "2021-01-12T14:04:41Z", "type": "commit"}, {"oid": "812bec6d345b083efca7ade5606565263803a944", "url": "https://github.com/hazelcast/hazelcast-jet/commit/812bec6d345b083efca7ade5606565263803a944", "message": "Fix version constants", "committedDate": "2021-01-13T09:27:29Z", "type": "commit"}, {"oid": "79a7d0afa0901d33af02a2215570835661ff177e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/79a7d0afa0901d33af02a2215570835661ff177e", "message": "use noop shard monitor for non leader kinesis sinks, also put shardCount into the monitor", "committedDate": "2021-01-13T21:58:19Z", "type": "commit"}, {"oid": "79a7d0afa0901d33af02a2215570835661ff177e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/79a7d0afa0901d33af02a2215570835661ff177e", "message": "use noop shard monitor for non leader kinesis sinks, also put shardCount into the monitor", "committedDate": "2021-01-13T21:58:19Z", "type": "forcePushed"}]}