{"pr_number": 2518, "pr_title": "File data ingestion", "pr_createdAt": "2020-09-15T10:32:09Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2518", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTAyMjExNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r489022114", "bodyText": "we shouldn't use any class(NullWritable) from hadoop, it adds a dependency to hadoop even if user wants to read files without hadoop module.", "author": "gurbuzali", "createdAt": "2020-09-15T22:17:47Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/AvroFileFormat.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file;\n+\n+import com.hazelcast.function.BiFunctionEx;\n+import com.hazelcast.function.FunctionEx;\n+import org.apache.avro.Schema;\n+import org.apache.avro.file.DataFileReader;\n+import org.apache.avro.io.DatumReader;\n+import org.apache.avro.mapred.AvroKey;\n+import org.apache.avro.mapreduce.AvroKeyInputFormat;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.avro.reflect.ReflectDatumReader;\n+import org.apache.avro.specific.SpecificDatumReader;\n+import org.apache.hadoop.io.NullWritable;\n+\n+import java.nio.file.Path;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+\n+/**\n+ * FileFormat for avro files\n+ *\n+ *\n+ * @param <T>\n+ */\n+public class AvroFileFormat<T> extends AbstractFileFormat<AvroKey<T>, NullWritable, T>", "originalCommit": "250662eb1edc7691ce12577016b295234a976157", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE3NjU5OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r489176599", "bodyText": "we use jackson-dataformat here which adds a dependency to the core", "author": "gurbuzali", "createdAt": "2020-09-16T05:44:41Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file;\n+\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import com.fasterxml.jackson.dataformat.csv.CsvMapper;\n+import com.fasterxml.jackson.dataformat.csv.CsvSchema;\n+import com.hazelcast.function.BiFunctionEx;\n+import com.hazelcast.function.FunctionEx;\n+import org.apache.hadoop.io.NullWritable;\n+\n+import java.io.InputStream;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class CsvFileFormat<T> extends AbstractFileFormat<NullWritable, T, T> implements FileFormat<NullWritable, T, T> {\n+\n+    public static final String CSV_INPUT_FORMAT_BEAN_CLASS = \"csv.bean.class\";\n+\n+    private final Class<T> clazz;\n+\n+    public CsvFileFormat(Class<T> clazz) {\n+        this.clazz = clazz;\n+\n+        withOption(INPUT_FORMAT_CLASS, \"com.hazelcast.jet.hadoop.impl.CsvInputFormat\");\n+        withOption(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getCanonicalName());\n+    }\n+\n+    @Override\n+    public FunctionEx<InputStream, Stream<T>> mapInputStreamFn() {\n+        CsvSchema schema = CsvSchema.emptySchema().withHeader();", "originalCommit": "250662eb1edc7691ce12577016b295234a976157", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU0NTE3Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r493545176", "bodyText": "Couple the returned format to the format of handled FileFormat? Otherwise it can easily get out of sync.", "author": "gierlachg", "createdAt": "2020-09-23T12:44:35Z", "path": "extensions/avro/src/main/java/com/hazelcast/jet/avro/AvroMapFnProvider.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.avro;\n+\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.pipeline.file.AvroFileFormat;\n+import com.hazelcast.jet.pipeline.file.impl.MapFnProvider;\n+import org.apache.avro.file.DataFileReader;\n+import org.apache.avro.io.DatumReader;\n+import org.apache.avro.reflect.ReflectDatumReader;\n+import org.apache.avro.specific.SpecificDatumReader;\n+\n+import java.nio.file.Path;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+\n+/**\n+ * MapFnProvider for Avro files, reading given path and deserializing using\n+ * avro DatumReader\n+ *\n+ * @param <T> type of the item emitted from the source\n+ */\n+public class AvroMapFnProvider<T> implements MapFnProvider<AvroFileFormat<T>, T> {\n+\n+    @Override\n+    public FunctionEx<Path, Stream<T>> create(AvroFileFormat<T> format) {\n+        Class<T> reflectClass = format.reflectClass();\n+        return (path) -> {\n+            DatumReader<T> datumReader = datumReader(reflectClass);\n+            DataFileReader<T> reader = new DataFileReader<>(path.toFile(), datumReader);\n+            return StreamSupport.stream(reader.spliterator(), false)\n+                                .onClose(() -> uncheckRun(reader::close));\n+        };\n+    }\n+\n+    private static <T> DatumReader<T> datumReader(Class<T> reflectClass) {\n+        return reflectClass == null ? new SpecificDatumReader<>() : new ReflectDatumReader<>(reflectClass);\n+    }\n+\n+    @Override\n+    public String format() {\n+        return \"avro\";", "originalCommit": "5da2197c944aae3b23bde72c463d1ec289bf6fe8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDExNzk3MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494117970", "bodyText": "Done.", "author": "frant-hartm", "createdAt": "2020-09-24T08:04:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU0NTE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU3MjA3Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r493572077", "bodyText": "Get the key from the provider? To keep them in sync?", "author": "gierlachg", "createdAt": "2020-09-23T13:12:36Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/LocalFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import com.fasterxml.jackson.dataformat.csv.CsvMapper;\n+import com.fasterxml.jackson.dataformat.csv.CsvSchema;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.impl.util.IOUtil;\n+import com.hazelcast.jet.json.JsonUtil;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.Sources;\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSourceFactory;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.Charset;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.impl.util.Util.uncheckCall;\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+/**\n+ * Implementation of FileSourceFactory for local filesystem\n+ *\n+ * @param <T> type of the item emitted from the source\n+ */\n+public class LocalFileSourceFactory<T> implements FileSourceFactory<T> {\n+\n+    private Map<String, MapFnProvider<? extends FileFormat<?>, ?>> mapFns;\n+\n+    /**\n+     * Default constructor\n+     */\n+    public LocalFileSourceFactory() {\n+        mapFns = new HashMap<>();\n+\n+        mapFns.put(\"csv\", new CsvMapFnProvider());", "originalCommit": "5da2197c944aae3b23bde72c463d1ec289bf6fe8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDExODE2NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494118164", "bodyText": "Done.", "author": "frant-hartm", "createdAt": "2020-09-24T08:05:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU3MjA3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU3NTg3Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r493575872", "bodyText": "Why the '1' suffix?", "author": "gierlachg", "createdAt": "2020-09-23T13:16:40Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/LocalFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import com.fasterxml.jackson.dataformat.csv.CsvMapper;\n+import com.fasterxml.jackson.dataformat.csv.CsvSchema;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.impl.util.IOUtil;\n+import com.hazelcast.jet.json.JsonUtil;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.Sources;\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSourceFactory;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.Charset;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.impl.util.Util.uncheckCall;\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+/**\n+ * Implementation of FileSourceFactory for local filesystem\n+ *\n+ * @param <T> type of the item emitted from the source\n+ */\n+public class LocalFileSourceFactory<T> implements FileSourceFactory<T> {\n+\n+    private Map<String, MapFnProvider<? extends FileFormat<?>, ?>> mapFns;\n+\n+    /**\n+     * Default constructor\n+     */\n+    public LocalFileSourceFactory() {\n+        mapFns = new HashMap<>();\n+\n+        mapFns.put(\"csv\", new CsvMapFnProvider());\n+        mapFns.put(\"jsonl\", new JsonMapFnProvider<>());", "originalCommit": "5da2197c944aae3b23bde72c463d1ec289bf6fe8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc4NjQ0MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r493786440", "bodyText": "That's lowercase L. See https://jsonlines.org/, which is the actual supported format, not regular json.", "author": "frant-hartm", "createdAt": "2020-09-23T18:02:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU3NTg3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzU3NjIxNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r493576214", "bodyText": "Just 'lines' instead of 'txt1'?", "author": "gierlachg", "createdAt": "2020-09-23T13:17:06Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/LocalFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import com.fasterxml.jackson.dataformat.csv.CsvMapper;\n+import com.fasterxml.jackson.dataformat.csv.CsvSchema;\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.impl.util.IOUtil;\n+import com.hazelcast.jet.json.JsonUtil;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.Sources;\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSourceFactory;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.Charset;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.impl.util.Util.uncheckCall;\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+/**\n+ * Implementation of FileSourceFactory for local filesystem\n+ *\n+ * @param <T> type of the item emitted from the source\n+ */\n+public class LocalFileSourceFactory<T> implements FileSourceFactory<T> {\n+\n+    private Map<String, MapFnProvider<? extends FileFormat<?>, ?>> mapFns;\n+\n+    /**\n+     * Default constructor\n+     */\n+    public LocalFileSourceFactory() {\n+        mapFns = new HashMap<>();\n+\n+        mapFns.put(\"csv\", new CsvMapFnProvider());\n+        mapFns.put(\"jsonl\", new JsonMapFnProvider<>());\n+        mapFns.put(\"txtl\", new LinesMapFnProvider());", "originalCommit": "5da2197c944aae3b23bde72c463d1ec289bf6fe8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDg2MjM2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494862365", "bodyText": "This class is public API, shouldn't be in impl.", "author": "mtopolnik", "createdAt": "2020-09-25T09:24:26Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/MapFnProvider.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+\n+import java.nio.file.Path;\n+import java.util.stream.Stream;\n+\n+/**\n+ * Provides a mapping function from a Path to a Stream of items emitted from local filesystem source\n+ *\n+ * @param <F> FileFormat type\n+ * @param <T> type of the items emitted from the file source\n+ */\n+public interface MapFnProvider<F extends FileFormat<?>, T> {", "originalCommit": "ad181730f72e87b1054c64207f6432048d0be93a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDg3Njc3Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494876772", "bodyText": "A factory method would be a nicer choice, I think. It removes the diamond operator and new, looks cleaner.", "author": "mtopolnik", "createdAt": "2020-09-25T09:49:10Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -0,0 +1,193 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file;\n+\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.file.impl.LocalFileSourceFactory;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Builder for file sources\n+ * <p>\n+ * The builder works with local filesystem and with hadoop supported\n+ * filesystems.\n+ * <p>\n+ * The builder requires 'path' and 'format' parameters and creates a\n+ * {@link BatchSource}. The path specifies the location of the file(s)\n+ * and possibly the data source - s3a://, hdfs://, etc..\n+ * <p>\n+ * The format determines how the contents of the file is parsed and\n+ * also determines the type of the source items. E.g. the\n+ * {@link LinesTextFileFormat} returns each line as a String,\n+ * {@link JsonFileFormat} returns each line of a JSON Lines file\n+ * deserialized into an instance of a specified class.\n+ * <p>\n+ * You may also use Hadoop to read local files by specifying the\n+ * {@link #useHadoopForLocalFiles()} flag.\n+ * <p>\n+ * Usage:\n+ * <pre>{@code\n+ * BatchSource<User> source = new FileSourceBuilder(\"data/users.jsonl\")\n+ *   .withFormat(new JsonFileFormat<>(User.class))", "originalCommit": "ad181730f72e87b1054c64207f6432048d0be93a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDYwNTc1MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r504605751", "bodyText": "Added factory methods for all formats.", "author": "frant-hartm", "createdAt": "2020-10-14T11:35:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDg3Njc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDQ4NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494954485", "bodyText": "We have fileSourceBuilder.build() and then we have HadoopSourceFactory.create(fileSourceBuilder). This is inconsistent API. It also creates the problem of nullability, you can pass in a builder in any state.", "author": "mtopolnik", "createdAt": "2020-09-25T12:30:50Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopSourceFactory.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import com.hazelcast.function.BiFunctionEx;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.hadoop.HadoopSources;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.file.AvroFileFormat;\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSourceFactory;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import org.apache.avro.Schema;\n+import org.apache.avro.mapred.AvroKey;\n+import org.apache.avro.mapreduce.AvroJob;\n+import org.apache.avro.mapreduce.AvroKeyInputFormat;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;\n+import org.apache.parquet.avro.AvroParquetInputFormat;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static com.hazelcast.jet.hadoop.impl.CsvInputFormat.CSV_INPUT_FORMAT_BEAN_CLASS;\n+import static com.hazelcast.jet.hadoop.impl.JsonInputFormat.JSON_INPUT_FORMAT_BEAN_CLASS;\n+\n+/**\n+ * Hadoop based implementation for FileSourceFactory\n+ *\n+ * @param <T> type of the items emitted from the source\n+ */\n+public class HadoopSourceFactory<T> implements FileSourceFactory<T> {\n+\n+    private final Map<Class<? extends FileFormat>, JobConfigurer<?, ?>> configs;\n+\n+    /**\n+     * Creates HadoopSourceFactory\n+     */\n+    public HadoopSourceFactory() {\n+        configs = new HashMap<>();\n+\n+        configs.put(AvroFileFormat.class, new AvroFormatJobConfigurer());\n+        configs.put(CsvFileFormat.class, new CsvFormatJobConfigurer());\n+        configs.put(JsonFileFormat.class, new JsonFormatJobConfigurer());\n+        configs.put(LinesTextFileFormat.class, new LineTextJobConfigurer());\n+        configs.put(ParquetFileFormat.class, new ParquetFormatJobConfigurer());\n+        configs.put(RawBytesFileFormat.class, new RawBytesFormatJobConfigurer());\n+        configs.put(TextFileFormat.class, new TextJobConfigurer());\n+    }\n+\n+    @Override\n+    public BatchSource<T> create(FileSourceBuilder<T> builder) {", "originalCommit": "aea745df108100358b6d094c25f6576d807a0820", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk3MjA0Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r494972046", "bodyText": "HadoopSourceFactory is internal class (hence in impl package).", "author": "frant-hartm", "createdAt": "2020-09-25T13:03:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDk1NDQ4NQ=="}], "type": "inlineReview"}, {"oid": "ed6e8e3462cadc066e386d3bdb1ae57777cd3a99", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ed6e8e3462cadc066e386d3bdb1ae57777cd3a99", "message": "More Javadoc", "committedDate": "2020-11-04T14:06:37Z", "type": "forcePushed"}, {"oid": "d59d83d81f8079302fab7a7b2641166f8df692f8", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d59d83d81f8079302fab7a7b2641166f8df692f8", "message": "Do not list licenses without a dependency\n\nSome dependencies are present only either in main distribution or in\nseparate download. This way we don't list a license without at least one\ndependency present.", "committedDate": "2020-11-11T13:34:28Z", "type": "commit"}, {"oid": "1611c55fd7a4283fff1a2eab2fcaf720543f0803", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1611c55fd7a4283fff1a2eab2fcaf720543f0803", "message": "Add unified file connector\n\nThis commit adds unified file connector API and its implementation for\nlocal filesystem.", "committedDate": "2020-11-11T13:34:28Z", "type": "commit"}, {"oid": "c19183e7dadb1973643cd6bbda5c485b8552be33", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c19183e7dadb1973643cd6bbda5c485b8552be33", "message": "Implement unified file connector for hadoop", "committedDate": "2020-11-11T13:34:28Z", "type": "commit"}, {"oid": "1900a3e96f27177c93213abdd51197b5498eddc4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1900a3e96f27177c93213abdd51197b5498eddc4", "message": "Add modules for s3, gcs, azure and hadoop-all", "committedDate": "2020-11-11T13:34:28Z", "type": "commit"}, {"oid": "3f3f0d44de035aaf8a17f2cccf36bc5c269b05bc", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3f3f0d44de035aaf8a17f2cccf36bc5c269b05bc", "message": "Add TDD for File Data Ingestion", "committedDate": "2020-11-11T13:34:28Z", "type": "commit"}, {"oid": "db3f8bb00606ca9ae5825f51a5e4e56f1967adc7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/db3f8bb00606ca9ae5825f51a5e4e56f1967adc7", "message": "Add documentation for Unified File Connector", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "5800b6cf0c95bcebc40afe5a4e2a829f8aa49c94", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5800b6cf0c95bcebc40afe5a4e2a829f8aa49c94", "message": "Override guava version in transitive dependencies", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "57c4f7c0bcf2251b6ca6042c7856e8b93cf5b923", "url": "https://github.com/hazelcast/hazelcast-jet/commit/57c4f7c0bcf2251b6ca6042c7856e8b93cf5b923", "message": "Improve Javadoc", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "aa0c1adab037aeebf77b72b6bb653d288f0ae9d8", "url": "https://github.com/hazelcast/hazelcast-jet/commit/aa0c1adab037aeebf77b72b6bb653d288f0ae9d8", "message": "Nullability, Javadoc", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "a878d25dcbdae932513f91031d6ea430fb449ed9", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a878d25dcbdae932513f91031d6ea430fb449ed9", "message": "More Javadoc", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "c7a5c7da7971eaf8827f09ea85702bb514162a5c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/c7a5c7da7971eaf8827f09ea85702bb514162a5c", "message": "Add support for sharedFileSystem flag", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "6216722ab769777773720f1f00178cde84224269", "url": "https://github.com/hazelcast/hazelcast-jet/commit/6216722ab769777773720f1f00178cde84224269", "message": "Add test with glob in the middle of filename", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "92fb5360c7e80808d589c9c21bae0f4d872d449a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/92fb5360c7e80808d589c9c21bae0f4d872d449a", "message": "Add test for glob in path (supported by hadoop, not by local file\nconnector)", "committedDate": "2020-11-12T08:17:52Z", "type": "commit"}, {"oid": "5fd6815598dc26d79a8b6836dce6d5f4c48678b7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5fd6815598dc26d79a8b6836dce6d5f4c48678b7", "message": "Make FileFormat constructors package private", "committedDate": "2020-11-12T08:28:47Z", "type": "commit"}, {"oid": "e082892d8063ca9f4683156d4af5333286b28daf", "url": "https://github.com/hazelcast/hazelcast-jet/commit/e082892d8063ca9f4683156d4af5333286b28daf", "message": "Add support for Azure Data Lake Gen 2", "committedDate": "2020-10-30T12:40:08Z", "type": "forcePushed"}, {"oid": "5fd6815598dc26d79a8b6836dce6d5f4c48678b7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5fd6815598dc26d79a8b6836dce6d5f4c48678b7", "message": "Make FileFormat constructors package private", "committedDate": "2020-11-12T08:28:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk2ODQ3Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r521968472", "bodyText": "Boolean getters tend to be confusing:\nFileSourceBuilder<String> source = FileSources.files(\"src/test/resources/directory/\")\n                                              .withFormat(FileFormat.lines());\nsource.sharedFileSystem();\nUnless there's a smart IDE warning that warns you're ignoring the boolean return value (you're ignoring it all the time anyway, with return this methods), this will be a very surprising thing.\nA better name isisSharedFileSystem.", "author": "mtopolnik", "createdAt": "2020-11-12T09:41:11Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -163,6 +189,13 @@ public String path() {\n         return format;\n     }\n \n+    /**\n+     * Returns if the filesystem is shared. Only valid for local filesystem, distributed filesystems are always shared.\n+     */\n+    public boolean sharedFileSystem() {", "originalCommit": "c7a5c7da7971eaf8827f09ea85702bb514162a5c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fee408de9eac16c424fd2e95bf70ebf87f0d5aa2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/fee408de9eac16c424fd2e95bf70ebf87f0d5aa2", "message": "Address Marko's comments on naming of builder methods", "committedDate": "2020-11-12T11:35:30Z", "type": "commit"}, {"oid": "0734140c5b02fe396708c38509aa306e02fabb85", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0734140c5b02fe396708c38509aa306e02fabb85", "message": "Move CSV to separate module", "committedDate": "2020-11-12T14:34:58Z", "type": "commit"}, {"oid": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "message": "Add @since to javadoc", "committedDate": "2020-11-12T14:34:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwNDE1MQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r522704151", "bodyText": "why don't we use Nonnull and force user to use the no-argument variant. We use this convention for LinesTextFileFormat and TextFileFormat for example.", "author": "gurbuzali", "createdAt": "2020-11-13T07:02:20Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileFormat.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+import java.nio.charset.Charset;\n+\n+/**\n+ * Identifies the data format of a file to be used as a Jet data source.\n+ * This is a data object that holds the configuration; actual implementation\n+ * code is looked up elsewhere, by using this object as a key.\n+ *\n+ * @param <T> type of items a source using this file format will emit\n+ * @since 4.4\n+ */\n+public interface FileFormat<T> {\n+\n+    /**\n+     * Returns the unique identifier of the file format. The convention is to\n+     * use the well-known filename suffix or, if there is none, a short-form\n+     * name of the format.\n+     */\n+    @Nonnull\n+    String format();\n+\n+\n+    // Factory methods for supported file formats are here for easy discoverability.\n+\n+    /**\n+     * Returns a file format for Avro files.\n+     */\n+    @Nonnull\n+    static <T> AvroFileFormat<T> avro() {\n+        return avro(null);\n+    }\n+\n+    /**\n+     * Returns a file format for Avro files that specifies to use reflection\n+     * to deserialize the data into instances of the provided Java class.\n+     * Jet will use the {@code ReflectDatumReader} to read Avro data. The\n+     * parameter may be {@code null}, disabling the option to deserialize\n+     * using reflection, but for that case you should prefer the no-argument\n+     * {@link #avro()} call.\n+     */\n+    @Nonnull\n+    static <T> AvroFileFormat<T> avro(@Nullable Class<T> clazz) {", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk4MTI3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528981278", "bodyText": "See comment on the related method.", "author": "frant-hartm", "createdAt": "2020-11-23T20:38:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwNDE1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwODAxNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r522708015", "bodyText": "I would make this Nonnull too. By default it is null, if user explicitly calls it then the user wants to configure the class.", "author": "gurbuzali", "createdAt": "2020-11-13T07:07:00Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/AvroFileFormat.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file;\n+\n+import javax.annotation.Nonnull;\n+import javax.annotation.Nullable;\n+\n+/**\n+ * {@link FileFormat} for avro files. See {@link FileFormat#avro} for more\n+ * details.\n+ *\n+ * @param <T> type of items a source using this file format will emit\n+ * @since 4.4\n+ */\n+public class AvroFileFormat<T> implements FileFormat<T> {\n+\n+    /**\n+     * Format id for Avro.\n+     */\n+    public static final String FORMAT_AVRO = \"avro\";\n+\n+    private Class<T> reflectClass;\n+\n+    /**\n+     * Creates {@link AvroFileFormat}. See {@link FileFormat#avro} for more\n+     * details.\n+     */\n+    AvroFileFormat() {\n+    }\n+\n+    /**\n+     * Specifies to use reflection to deserialize data into the given class.\n+     * Jet will use the {@code ReflectDatumReader} to read Avro data. The\n+     * parameter may be {@code null}, this disables the option to deserialize\n+     * using reflection.\n+     *\n+     * @param reflectClass class to deserialize data into\n+     */\n+    @Nonnull\n+    public AvroFileFormat<T> withReflect(@Nullable Class<T> reflectClass) {", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjkwODc3NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r522908774", "bodyText": "The counterargument is that the user may have some general code that has a nullable class. With our @Nullable, it can just pass it in, otherwise it must do a boilerplate null-check to decide which method to call.", "author": "mtopolnik", "createdAt": "2020-11-13T12:04:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwODAxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzEyNjQ2MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523126460", "bodyText": "well, we keep the Nonnull convention for other file-formats already, this one is the exception", "author": "gurbuzali", "createdAt": "2020-11-13T17:55:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwODAxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk4Mjk3NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528982975", "bodyText": "It's an exception, because this is optional. All the Nonnull parameters elsewhere are compulsory or have a reasonable default value.", "author": "frant-hartm", "createdAt": "2020-11-23T20:41:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwODAxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjc0NTM5NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r522745395", "bodyText": "I think the logic to find if the path is a directory or a file is wrong.  the comment says:\n        // We can't ask the filesystem because this code runs on the client, which\n        // is likely a different machine than the cluster members. So this is a\n        // best guess, we assume that directories end with '/'.\n\nLet's say I want to read the files in the directory /user/home/tmp and I didn't put a / to the end.\nThe source tries to read the file tmp in the parent directory /usr/home. Since there is no such file in the directory (uses file-name as glob), the source just completes.", "author": "gurbuzali", "createdAt": "2020-11-13T07:47:44Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/LocalFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.impl.util.IOUtil;\n+import com.hazelcast.jet.json.JsonUtil;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.Sources;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import javax.annotation.Nonnull;\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.Charset;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+import java.util.stream.Stream;\n+\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.impl.util.Util.uncheckCall;\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Implementation of FileSourceFactory for the local filesystem.\n+ */\n+public class LocalFileSourceFactory implements FileSourceFactory {\n+\n+    private static Map<String, ReadFileFnProvider> readFileFnProviders;\n+\n+    static {\n+        Map<String, ReadFileFnProvider> mapFns = new HashMap<>();\n+\n+        addMapFnProvider(mapFns, new JsonReadFileFnProvider());\n+        addMapFnProvider(mapFns, new LinesReadFileFnProvider());\n+        addMapFnProvider(mapFns, new ParquetReadFileFnProvider());\n+        addMapFnProvider(mapFns, new RawBytesReadFileFnProvider());\n+        addMapFnProvider(mapFns, new TextReadFileFnProvider());\n+\n+        ServiceLoader<ReadFileFnProvider> loader = ServiceLoader.load(ReadFileFnProvider.class);\n+        for (ReadFileFnProvider readFileFnProvider : loader) {\n+            addMapFnProvider(mapFns, readFileFnProvider);\n+        }\n+\n+        LocalFileSourceFactory.readFileFnProviders = Collections.unmodifiableMap(mapFns);\n+    }\n+\n+    private static void addMapFnProvider(Map<String, ReadFileFnProvider> mapFns, ReadFileFnProvider provider) {\n+        mapFns.put(provider.format(), provider);\n+    }\n+\n+    @Nonnull @Override\n+    public <T> BatchSource<T> create(@Nonnull FileSourceBuilder<T> builder) {\n+        Tuple2<String, String> dirAndGlob = deriveDirectoryAndGlobFromPath(builder.path());\n+        assert dirAndGlob.f0() != null && dirAndGlob.f1() != null;\n+\n+        FileFormat<T> format = requireNonNull(builder.format());\n+        ReadFileFnProvider readFileFnProvider = readFileFnProviders.get(format.format());\n+        FunctionEx<Path, Stream<T>> mapFn = readFileFnProvider.createReadFileFn(format);\n+        return Sources.filesBuilder(dirAndGlob.f0())\n+                      .glob(dirAndGlob.f1())\n+                      .sharedFileSystem(builder.isSharedFileSystem())\n+                      .build(mapFn);\n+    }\n+\n+    private Tuple2<String, String> deriveDirectoryAndGlobFromPath(String path) {\n+        Path p = Paths.get(path);\n+\n+        String directory;\n+        String glob = \"*\";\n+        if (isDirectory(path)) {", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAzNDUwOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r529034508", "bodyText": "I see 2 options:\n\nwe either keep the directory and glob parameters instead of single path parameters, for hadoop we would just concatenate these\nwe move this piece of code to processor supplier, I have tried to have a go at it, see the latest commit.", "author": "frant-hartm", "createdAt": "2020-11-23T22:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjc0NTM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjc0NzQzOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r522747438", "bodyText": "readFileFnProvider can be null if user provides a custom file format ?", "author": "gurbuzali", "createdAt": "2020-11-13T07:49:52Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/impl/LocalFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.pipeline.file.impl;\n+\n+import com.hazelcast.function.FunctionEx;\n+import com.hazelcast.jet.datamodel.Tuple2;\n+import com.hazelcast.jet.impl.util.IOUtil;\n+import com.hazelcast.jet.json.JsonUtil;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.Sources;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+\n+import javax.annotation.Nonnull;\n+import java.io.BufferedReader;\n+import java.io.FileInputStream;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.Charset;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.ServiceLoader;\n+import java.util.stream.Stream;\n+\n+import static com.hazelcast.jet.datamodel.Tuple2.tuple2;\n+import static com.hazelcast.jet.impl.util.Util.uncheckCall;\n+import static com.hazelcast.jet.impl.util.Util.uncheckRun;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Implementation of FileSourceFactory for the local filesystem.\n+ */\n+public class LocalFileSourceFactory implements FileSourceFactory {\n+\n+    private static Map<String, ReadFileFnProvider> readFileFnProviders;\n+\n+    static {\n+        Map<String, ReadFileFnProvider> mapFns = new HashMap<>();\n+\n+        addMapFnProvider(mapFns, new JsonReadFileFnProvider());\n+        addMapFnProvider(mapFns, new LinesReadFileFnProvider());\n+        addMapFnProvider(mapFns, new ParquetReadFileFnProvider());\n+        addMapFnProvider(mapFns, new RawBytesReadFileFnProvider());\n+        addMapFnProvider(mapFns, new TextReadFileFnProvider());\n+\n+        ServiceLoader<ReadFileFnProvider> loader = ServiceLoader.load(ReadFileFnProvider.class);\n+        for (ReadFileFnProvider readFileFnProvider : loader) {\n+            addMapFnProvider(mapFns, readFileFnProvider);\n+        }\n+\n+        LocalFileSourceFactory.readFileFnProviders = Collections.unmodifiableMap(mapFns);\n+    }\n+\n+    private static void addMapFnProvider(Map<String, ReadFileFnProvider> mapFns, ReadFileFnProvider provider) {\n+        mapFns.put(provider.format(), provider);\n+    }\n+\n+    @Nonnull @Override\n+    public <T> BatchSource<T> create(@Nonnull FileSourceBuilder<T> builder) {\n+        Tuple2<String, String> dirAndGlob = deriveDirectoryAndGlobFromPath(builder.path());\n+        assert dirAndGlob.f0() != null && dirAndGlob.f1() != null;\n+\n+        FileFormat<T> format = requireNonNull(builder.format());\n+        ReadFileFnProvider readFileFnProvider = readFileFnProviders.get(format.format());\n+        FunctionEx<Path, Stream<T>> mapFn = readFileFnProvider.createReadFileFn(format);", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MTMyOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523761328", "bodyText": "why do we call initialize here explicitly while for other FileInputFormats we don't?", "author": "gurbuzali", "createdAt": "2020-11-15T13:49:13Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/WholeFileInputFormat.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+\n+\n+/**\n+ * Adapted from code example from book\n+ * Hadoop: The Definitive Guide, Fourth Edition by Tom White (O'Reilly, 2014)\n+ * https://github.com/tomwhite/hadoop-book/blob/master/ch08-mr-types/src/main/java/WholeFileInputFormat.java\n+ */\n+public class WholeFileInputFormat extends FileInputFormat<NullWritable, BytesWritable> {\n+\n+    @Override\n+    protected boolean isSplitable(JobContext context, Path file) {\n+        return false;\n+    }\n+\n+    @Override\n+    public RecordReader<NullWritable, BytesWritable> createRecordReader(InputSplit split, TaskAttemptContext context) {\n+        WholeFileRecordReader reader = new WholeFileRecordReader();\n+        reader.initialize(split, context);", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk4Nzg1OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528987858", "bodyText": "It was part of the source I took from the Hadoop book Seems it is not needed in the new API, the javadoc says the hadoop framework will call initialize and it the tests pass if I remove it.", "author": "frant-hartm", "createdAt": "2020-11-23T20:50:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MTMyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MTgxOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523761818", "bodyText": "we can use ReflectionUtils.loadClass() here. it removes the necessity of catching ClassNotFoundException", "author": "gurbuzali", "createdAt": "2020-11-15T13:52:42Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/CsvInputFormat.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import com.fasterxml.jackson.databind.MappingIterator;\n+import com.fasterxml.jackson.databind.ObjectReader;\n+import com.fasterxml.jackson.dataformat.csv.CsvMapper;\n+import com.fasterxml.jackson.dataformat.csv.CsvSchema;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+\n+public class CsvInputFormat extends FileInputFormat<NullWritable, Object> {\n+\n+    public static final String CSV_INPUT_FORMAT_BEAN_CLASS = \"csv.bean.class\";\n+\n+    @Override\n+    public RecordReader<NullWritable, Object> createRecordReader(InputSplit split, TaskAttemptContext context) {\n+\n+        return new RecordReader<NullWritable, Object>() {\n+\n+            private Object current;\n+            private MappingIterator<Object> iterator;\n+\n+            @Override\n+            public void initialize(InputSplit split, TaskAttemptContext context) throws IOException {\n+\n+                FileSplit fileSplit = (FileSplit) split;\n+                Configuration conf = context.getConfiguration();\n+\n+                try {\n+\n+                    Configuration configuration = context.getConfiguration();\n+                    String className = configuration.get(CSV_INPUT_FORMAT_BEAN_CLASS);\n+                    Class<?> clazz = Thread.currentThread().getContextClassLoader().loadClass(className);", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk4ODE1NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528988155", "bodyText": "Done.", "author": "frant-hartm", "createdAt": "2020-11-23T20:51:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MTgxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MjYzMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523762633", "bodyText": "we can use ReflectionUtils.loadClass() here", "author": "gurbuzali", "createdAt": "2020-11-15T13:59:28Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/JsonInputFormat.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import com.hazelcast.jet.json.JsonUtil;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.compress.CompressionCodec;\n+import org.apache.hadoop.io.compress.CompressionCodecFactory;\n+import org.apache.hadoop.io.compress.SplittableCompressionCodec;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.LineRecordReader;\n+\n+import java.io.IOException;\n+\n+public class JsonInputFormat extends FileInputFormat<LongWritable, Object> {\n+\n+    public static final String JSON_INPUT_FORMAT_BEAN_CLASS = \"json.bean.class\";\n+\n+    @Override\n+    public RecordReader<LongWritable, Object> createRecordReader(InputSplit split, TaskAttemptContext context) {\n+\n+        try {\n+            Configuration configuration = context.getConfiguration();\n+            String className = configuration.get(JSON_INPUT_FORMAT_BEAN_CLASS);\n+            Class<?> clazz = Thread.currentThread().getContextClassLoader().loadClass(className);", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MzAwNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523763004", "bodyText": "can be simplified as\nreturn codec == null || codec instanceof SplittableCompressionCodec;", "author": "gurbuzali", "createdAt": "2020-11-15T14:02:21Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/JsonInputFormat.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import com.hazelcast.jet.json.JsonUtil;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.compress.CompressionCodec;\n+import org.apache.hadoop.io.compress.CompressionCodecFactory;\n+import org.apache.hadoop.io.compress.SplittableCompressionCodec;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.LineRecordReader;\n+\n+import java.io.IOException;\n+\n+public class JsonInputFormat extends FileInputFormat<LongWritable, Object> {\n+\n+    public static final String JSON_INPUT_FORMAT_BEAN_CLASS = \"json.bean.class\";\n+\n+    @Override\n+    public RecordReader<LongWritable, Object> createRecordReader(InputSplit split, TaskAttemptContext context) {\n+\n+        try {\n+            Configuration configuration = context.getConfiguration();\n+            String className = configuration.get(JSON_INPUT_FORMAT_BEAN_CLASS);\n+            Class<?> clazz = Thread.currentThread().getContextClassLoader().loadClass(className);\n+\n+            return new RecordReader<LongWritable, Object>() {\n+\n+                final LineRecordReader reader = new LineRecordReader();\n+\n+                @Override\n+                public void initialize(InputSplit split, TaskAttemptContext context) throws IOException {\n+                    reader.initialize(split, context);\n+                }\n+\n+                @Override\n+                public boolean nextKeyValue() throws IOException {\n+                    return reader.nextKeyValue();\n+                }\n+\n+                @Override\n+                public LongWritable getCurrentKey() {\n+                    return reader.getCurrentKey();\n+                }\n+\n+                @Override\n+                public Object getCurrentValue() throws IOException {\n+                    return JsonUtil.beanFrom(reader.getCurrentValue().toString(), clazz);\n+                }\n+\n+                @Override\n+                public float getProgress() throws IOException {\n+                    return reader.getProgress();\n+                }\n+\n+                @Override\n+                public void close() throws IOException {\n+                    reader.close();\n+                }\n+            };\n+\n+        } catch (ClassNotFoundException e) {\n+            throw new RuntimeException(e);\n+        }\n+\n+    }\n+\n+    @Override\n+    protected boolean isSplitable(JobContext context, Path file) {\n+        final CompressionCodec codec = new CompressionCodecFactory(context.getConfiguration()).getCodec(file);\n+        if (null == codec) {\n+            return true;\n+        }\n+        return codec instanceof SplittableCompressionCodec;", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk4ODI1MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528988250", "bodyText": "Done.", "author": "frant-hartm", "createdAt": "2020-11-23T20:51:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MzAwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2MzU5Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523763592", "bodyText": "like WholeFileInputFormat why do we call initialize explicitly?", "author": "gurbuzali", "createdAt": "2020-11-15T14:07:19Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/WholeTextInputFormat.java", "diffHunk": "@@ -0,0 +1,47 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.JobContext;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+\n+\n+/**\n+ * Adapted from code example from book\n+ * Hadoop: The Definitive Guide, Fourth Edition by Tom White (O'Reilly, 2014)\n+ * https://github.com/tomwhite/hadoop-book/blob/master/ch08-mr-types/src/main/java/WholeFileInputFormat.java\n+ */\n+public class WholeTextInputFormat extends FileInputFormat<NullWritable, Text> {\n+\n+    @Override\n+    protected boolean isSplitable(JobContext context, Path file) {\n+        return false;\n+    }\n+\n+    @Override\n+    public RecordReader<NullWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context) {\n+        WholeTextRecordReader reader = new WholeTextRecordReader();\n+        reader.initialize(split, context);", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2Mzk3NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523763975", "bodyText": "WholeTextRecordReader and WholeFileRecordReader looks exactly the same except the generic type of the value. can we merge them somehow?", "author": "gurbuzali", "createdAt": "2020-11-15T14:10:28Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/WholeTextRecordReader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.InputSplit;\n+import org.apache.hadoop.mapreduce.RecordReader;\n+import org.apache.hadoop.mapreduce.TaskAttemptContext;\n+import org.apache.hadoop.mapreduce.lib.input.FileSplit;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Adapted from code example from book\n+ * Hadoop: The Definitive Guide, Fourth Edition by Tom White (O'Reilly, 2014)\n+ * https://github.com/tomwhite/hadoop-book/blob/master/ch08-mr-types/src/main/java/WholeFileRecordReader.java\n+ */\n+class WholeTextRecordReader extends RecordReader<NullWritable, Text> {", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk5MzE3OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528993178", "bodyText": "See the update if you like it. If not I will revert it.", "author": "frant-hartm", "createdAt": "2020-11-23T21:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2Mzk3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NDI0MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523764240", "bodyText": "we should do a null check here for custom file format", "author": "gurbuzali", "createdAt": "2020-11-15T14:12:41Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.impl;\n+\n+import com.hazelcast.function.BiFunctionEx;\n+import com.hazelcast.jet.JetException;\n+import com.hazelcast.jet.hadoop.HadoopSources;\n+import com.hazelcast.jet.pipeline.BatchSource;\n+import com.hazelcast.jet.pipeline.file.AvroFileFormat;\n+import com.hazelcast.jet.pipeline.file.CsvFileFormat;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.JsonFileFormat;\n+import com.hazelcast.jet.pipeline.file.LinesTextFileFormat;\n+import com.hazelcast.jet.pipeline.file.ParquetFileFormat;\n+import com.hazelcast.jet.pipeline.file.RawBytesFileFormat;\n+import com.hazelcast.jet.pipeline.file.TextFileFormat;\n+import com.hazelcast.jet.pipeline.file.impl.FileSourceFactory;\n+import org.apache.avro.Schema;\n+import org.apache.avro.mapred.AvroKey;\n+import org.apache.avro.mapreduce.AvroJob;\n+import org.apache.avro.mapreduce.AvroKeyInputFormat;\n+import org.apache.avro.reflect.ReflectData;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.mapreduce.Job;\n+import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n+import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;\n+import org.apache.parquet.avro.AvroParquetInputFormat;\n+\n+import javax.annotation.Nonnull;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+\n+import static com.hazelcast.jet.hadoop.impl.CsvInputFormat.CSV_INPUT_FORMAT_BEAN_CLASS;\n+import static com.hazelcast.jet.hadoop.impl.JsonInputFormat.JSON_INPUT_FORMAT_BEAN_CLASS;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Hadoop-based implementation of {@link FileSourceFactory}.\n+ */\n+public class HadoopFileSourceFactory implements FileSourceFactory {\n+\n+    private final Map<String, JobConfigurer> configs;\n+\n+    /**\n+     * Creates the HadoopSourceFactory.\n+     */\n+    public HadoopFileSourceFactory() {\n+        configs = new HashMap<>();\n+\n+        configs.put(AvroFileFormat.FORMAT_AVRO, new AvroFormatJobConfigurer());\n+        configs.put(CsvFileFormat.FORMAT_CSV, new CsvFormatJobConfigurer());\n+        configs.put(JsonFileFormat.FORMAT_JSONL, new JsonFormatJobConfigurer());\n+        configs.put(LinesTextFileFormat.FORMAT_LINES, new LineTextJobConfigurer());\n+        configs.put(ParquetFileFormat.FORMAT_PARQUET, new ParquetFormatJobConfigurer());\n+        configs.put(RawBytesFileFormat.FORMAT_BIN, new RawBytesFormatJobConfigurer());\n+        configs.put(TextFileFormat.FORMAT_TXT, new TextJobConfigurer());\n+    }\n+\n+    @Nonnull @Override\n+    @SuppressWarnings(\"unchecked\")\n+    public <T> BatchSource<T> create(@Nonnull FileSourceBuilder<T> builder) {\n+\n+        try {\n+            Job job = Job.getInstance();\n+\n+            Configuration configuration = job.getConfiguration();\n+            for (Entry<String, String> option : builder.options().entrySet()) {\n+                configuration.set(option.getKey(), option.getValue());\n+            }\n+\n+            FileInputFormat.addInputPath(job, new Path(builder.path()));\n+\n+            FileFormat<T> fileFormat = requireNonNull(builder.format());\n+            JobConfigurer configurer = configs.get(fileFormat.format());", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODgwMjYzOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528802639", "bodyText": "Added.", "author": "frant-hartm", "createdAt": "2020-11-23T15:49:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NDI0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NTQxNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523765415", "bodyText": "this is not necessary, the instances are terminated at the end of the test already.\nwe should also move the instance creation to a setup method so that new instances are not created for each call of this method.", "author": "gurbuzali", "createdAt": "2020-11-15T14:22:36Z", "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/BaseFileFormatTest.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.file;\n+\n+import com.hazelcast.function.ConsumerEx;\n+import com.hazelcast.jet.JetInstance;\n+import com.hazelcast.jet.core.JetTestSupport;\n+import com.hazelcast.jet.pipeline.Pipeline;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.test.Assertions;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+import org.junit.runners.Parameterized.Parameter;\n+import org.junit.runners.Parameterized.Parameters;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+\n+@RunWith(Parameterized.class)\n+public abstract class BaseFileFormatTest extends JetTestSupport {\n+\n+    @Parameter\n+    public boolean useHadoop;\n+\n+    @Parameters(name = \"{index}: useHadoop={0}\")\n+    public static Iterable<?> parameters() {\n+        return Arrays.asList(true, false);\n+    }\n+\n+    @SafeVarargs\n+    protected final <T> void assertItemsInSource(FileSourceBuilder<T> source, T... items) {\n+        assertItemsInSource(source, collected -> assertThat(collected).containsOnly(items));\n+    }\n+\n+    protected <T> void assertItemsInSource(\n+            FileSourceBuilder<T> source, ConsumerEx<List<T>> assertion\n+    ) {\n+        assertItemsInSource(1, source, assertion);\n+    }\n+\n+    protected <T> void assertItemsInSource(\n+            int memberCount, FileSourceBuilder<T> source, ConsumerEx<List<T>> assertion\n+    ) {\n+        if (useHadoop) {\n+            source.useHadoopForLocalFiles(true);\n+        }\n+\n+        Pipeline p = Pipeline.create();\n+\n+        p.readFrom(source.build())\n+         .apply(Assertions.assertCollected(assertion));\n+\n+        JetInstance[] jets = createJetMembers(memberCount);\n+        jets[0].newJob(p).join();\n+\n+        for (JetInstance jet : jets) {", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc0OTU1OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528749558", "bodyText": "The com.hazelcast.jet.pipeline.test.Assertions#assertCollected checks against all collected items, so you actually need a new instance everytime. Then if the instances are not shut down they connect with instances from previous calls.", "author": "frant-hartm", "createdAt": "2020-11-23T14:39:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NTQxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NTc2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523765765", "bodyText": "why don't we pre-create this file in resources like other file types?", "author": "gurbuzali", "createdAt": "2020-11-15T14:25:26Z", "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/AvroFileFormatTest.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.file;\n+\n+import com.hazelcast.jet.hadoop.file.generated.SpecificUser;\n+import com.hazelcast.jet.hadoop.file.model.User;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSources;\n+import org.apache.avro.file.DataFileWriter;\n+import org.apache.avro.specific.SpecificDatumWriter;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+public class AvroFileFormatTest extends BaseFileFormatTest {\n+\n+    @Test\n+    public void shouldReadAvroWithSchema() throws Exception {\n+        createAvroFile();\n+\n+        FileSourceBuilder<SpecificUser> source = FileSources.files(\"target/avro/file.avro\")\n+                                                            .format(FileFormat.avro());\n+        assertItemsInSource(source,\n+                new SpecificUser(\"Frantisek\", 7),\n+                new SpecificUser(\"Ali\", 42)\n+        );\n+\n+    }\n+\n+    @Test\n+    public void shouldReadAvroWithReflection() throws Exception {\n+        createAvroFile();\n+\n+        FileSourceBuilder<User> source = FileSources.files(\"target/avro/file.avro\")\n+                                                    .format(FileFormat.avro(User.class));\n+\n+        assertItemsInSource(source,\n+                new User(\"Frantisek\", 7),\n+                new User(\"Ali\", 42)\n+        );\n+    }\n+\n+    private static void createAvroFile() throws IOException {\n+        Path inputPath = new Path(\"target/avro\");", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODcyNzQ2NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r528727465", "bodyText": "I think creating it on the fly is easier to maintain. It is a binary file so imbossible to edit in case we need to modify it for a test case or similar.", "author": "frant-hartm", "createdAt": "2020-11-23T14:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NTc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzc2NjAwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2518#discussion_r523766002", "bodyText": "like avro file, can't we keep this created file in resources rather than creating it on the fly?", "author": "gurbuzali", "createdAt": "2020-11-15T14:27:13Z", "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/ParquetFileFormatTest.java", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Hazelcast Inc.\n+ *\n+ * Licensed under the Hazelcast Community License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://hazelcast.com/hazelcast-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.jet.hadoop.file;\n+\n+import com.hazelcast.jet.hadoop.file.generated.SpecificUser;\n+import com.hazelcast.jet.pipeline.file.FileFormat;\n+import com.hazelcast.jet.pipeline.file.FileSourceBuilder;\n+import com.hazelcast.jet.pipeline.file.FileSources;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.parquet.avro.AvroParquetWriter;\n+import org.apache.parquet.hadoop.ParquetWriter;\n+import org.apache.parquet.hadoop.metadata.CompressionCodecName;\n+import org.junit.Test;\n+import org.junit.runners.Parameterized.Parameters;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+\n+public class ParquetFileFormatTest extends BaseFileFormatTest {\n+\n+    // Parquet has a dependency on Hadoop so it does not make sense to run it without it\n+    @Parameters(name = \"{index}: useHadoop={0}\")\n+    public static Iterable<?> parameters() {\n+        return Arrays.asList(true);\n+    }\n+\n+    @Test\n+    public void shouldReadParquetFile() throws Exception {\n+        createParquetFile();\n+\n+        FileSourceBuilder<SpecificUser> source = FileSources.files(\"target/parquet/file.parquet\")\n+                                                            .format(FileFormat.parquet());\n+        assertItemsInSource(source,\n+                new SpecificUser(\"Frantisek\", 7),\n+                new SpecificUser(\"Ali\", 42)\n+        );\n+    }\n+\n+    private void createParquetFile() throws IOException {\n+        Path inputPath = new Path(\"target/parquet\");", "originalCommit": "dcef04e03e01bb7f2a3ee111156d663fdbe7662f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ea26ce7d61b75e437cf4f245bcbbad99ccfd6aa2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ea26ce7d61b75e437cf4f245bcbbad99ccfd6aa2", "message": "Ignore unknown columns in CSV files", "committedDate": "2020-11-23T07:39:36Z", "type": "commit"}, {"oid": "7c9b383b51377c3614b90613f8c906ff93a38514", "url": "https://github.com/hazelcast/hazelcast-jet/commit/7c9b383b51377c3614b90613f8c906ff93a38514", "message": "Add examples for new unified file API", "committedDate": "2020-11-23T07:56:50Z", "type": "commit"}, {"oid": "752f01f8ed399099e0f15cd7799a81fd43b5eb99", "url": "https://github.com/hazelcast/hazelcast-jet/commit/752f01f8ed399099e0f15cd7799a81fd43b5eb99", "message": "Add examples for cloud", "committedDate": "2020-11-23T12:22:24Z", "type": "commit"}, {"oid": "2882d426aa5e77b7a52df6eff408dc4575b06710", "url": "https://github.com/hazelcast/hazelcast-jet/commit/2882d426aa5e77b7a52df6eff408dc4575b06710", "message": "Merge branch 'master' into file-data-ingestion-api", "committedDate": "2020-11-23T12:22:58Z", "type": "commit"}, {"oid": "1594f2636b4c931f5528ebe856214a9f8a9dcb1d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1594f2636b4c931f5528ebe856214a9f8a9dcb1d", "message": "Add tests for custom format, check ReadFileFnProvider/JobConfigurer for null", "committedDate": "2020-11-23T15:49:21Z", "type": "commit"}, {"oid": "74762648f6997ffd19a2904f4e774beb79b2a955", "url": "https://github.com/hazelcast/hazelcast-jet/commit/74762648f6997ffd19a2904f4e774beb79b2a955", "message": "Address review comments", "committedDate": "2020-11-23T20:55:48Z", "type": "commit"}, {"oid": "228786ac89441b81e426b1a1fdf523407a83f8e4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/228786ac89441b81e426b1a1fdf523407a83f8e4", "message": "Avoid code duplication in WholeFileRecordReader and WholeTextRecordReader", "committedDate": "2020-11-23T21:15:15Z", "type": "commit"}, {"oid": "ffd0f83b9e22558bcb3c0f4de88a24fb76bb7f65", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ffd0f83b9e22558bcb3c0f4de88a24fb76bb7f65", "message": "Move deriveDirectoryAndGlobFromPath from client to processor supplier running on Jet nodes", "committedDate": "2020-11-23T21:50:16Z", "type": "commit"}, {"oid": "43c5e55c50df0e58e8043a5e3fc0ff9100d2fe76", "url": "https://github.com/hazelcast/hazelcast-jet/commit/43c5e55c50df0e58e8043a5e3fc0ff9100d2fe76", "message": "Fix some glob corner cases", "committedDate": "2020-11-24T22:23:30Z", "type": "commit"}, {"oid": "1455c4ef7e83d815e5ee38a67db7358c4402366b", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1455c4ef7e83d815e5ee38a67db7358c4402366b", "message": "Fix issues with windows\n\nIgnore hadoop and fix some path issues.", "committedDate": "2020-11-24T22:57:43Z", "type": "commit"}, {"oid": "1035ecff69b1c1698ec13310a30fd554098b9a10", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1035ecff69b1c1698ec13310a30fd554098b9a10", "message": "Add test for file with * in name (non-windows only)", "committedDate": "2020-11-25T07:48:30Z", "type": "commit"}, {"oid": "46663f49d7a4e0eb8db6bae56bfe0f0aa1ccd385", "url": "https://github.com/hazelcast/hazelcast-jet/commit/46663f49d7a4e0eb8db6bae56bfe0f0aa1ccd385", "message": "Clarify where to obtain the artifacts", "committedDate": "2020-11-25T09:04:29Z", "type": "commit"}, {"oid": "7efed9f765a6aa6ba8049bb3002659c711cfede5", "url": "https://github.com/hazelcast/hazelcast-jet/commit/7efed9f765a6aa6ba8049bb3002659c711cfede5", "message": "Change path parameter to path to directory and a glob", "committedDate": "2020-11-25T13:02:35Z", "type": "commit"}, {"oid": "b46df75977345e9bbef489536b1cd7b7f7d858f1", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b46df75977345e9bbef489536b1cd7b7f7d858f1", "message": "Remove getters from the FileSourceBuilder", "committedDate": "2020-11-25T13:28:43Z", "type": "commit"}, {"oid": "4e07620930fb408a77f33cacf39e51dd441807a2", "url": "https://github.com/hazelcast/hazelcast-jet/commit/4e07620930fb408a77f33cacf39e51dd441807a2", "message": "Handle non existing directory and non matching glob", "committedDate": "2020-11-25T13:50:24Z", "type": "commit"}, {"oid": "3c2f04851b35a3b9cf285f7c248bfa11987f361a", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3c2f04851b35a3b9cf285f7c248bfa11987f361a", "message": "Fix check for absolute path for hadoop paths", "committedDate": "2020-11-25T15:13:36Z", "type": "commit"}, {"oid": "306159b5f1c7244c57349cd2209541c105cdd12f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/306159b5f1c7244c57349cd2209541c105cdd12f", "message": "Add logs for nonmatching paths", "committedDate": "2020-11-25T18:39:33Z", "type": "commit"}, {"oid": "aa8d8569faf66ec163f431a8111b210a454650c4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/aa8d8569faf66ec163f431a8111b210a454650c4", "message": "Update documentation and example after glob API change", "committedDate": "2020-11-26T08:58:00Z", "type": "commit"}]}