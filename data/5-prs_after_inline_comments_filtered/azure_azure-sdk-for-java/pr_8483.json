{"pr_number": 8483, "pr_title": "Computer vision api 2.1", "pr_createdAt": "2020-02-26T00:46:47Z", "pr_url": "https://github.com/Azure/azure-sdk-for-java/pull/8483", "timeline": [{"oid": "17dc95c7989a08a387bb0b10e42ee4f3a69110fc", "url": "https://github.com/Azure/azure-sdk-for-java/commit/17dc95c7989a08a387bb0b10e42ee4f3a69110fc", "message": "Generate Computer Vision 2.1", "committedDate": "2020-02-19T01:51:50Z", "type": "commit"}, {"oid": "24c3e9e13061f43eab366ff275cc83809883bdc7", "url": "https://github.com/Azure/azure-sdk-for-java/commit/24c3e9e13061f43eab366ff275cc83809883bdc7", "message": "Add back manager", "committedDate": "2020-02-20T06:19:10Z", "type": "commit"}, {"oid": "508e3933c91f9ad5765f182f8357b21276c55a89", "url": "https://github.com/Azure/azure-sdk-for-java/commit/508e3933c91f9ad5765f182f8357b21276c55a89", "message": "Fix base url to be v2.1", "committedDate": "2020-02-26T00:46:14Z", "type": "commit"}, {"oid": "10473951a4f54b97a2abd484f82c7b38fae67d9d", "url": "https://github.com/Azure/azure-sdk-for-java/commit/10473951a4f54b97a2abd484f82c7b38fae67d9d", "message": "Merge branch 'master' of github.com:Azure/azure-sdk-for-java into computervision2.1", "committedDate": "2020-02-26T20:14:12Z", "type": "commit"}, {"oid": "355814b63f234e164ef54e58155e48fd9c5c82d4", "url": "https://github.com/Azure/azure-sdk-for-java/commit/355814b63f234e164ef54e58155e48fd9c5c82d4", "message": "Fix cosmos reference in pom.data.xml", "committedDate": "2020-02-26T20:26:07Z", "type": "commit"}, {"oid": "c7d7af19ec36492014ed9119d4fc9b7f1b30b92f", "url": "https://github.com/Azure/azure-sdk-for-java/commit/c7d7af19ec36492014ed9119d4fc9b7f1b30b92f", "message": "Remove cosmos from pom.data.xml", "committedDate": "2020-02-26T20:44:27Z", "type": "commit"}, {"oid": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "url": "https://github.com/Azure/azure-sdk-for-java/commit/6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "message": "Use version 1.0.3-beta for computer vision", "committedDate": "2020-02-26T21:20:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NzY4NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384787685", "bodyText": "This was previously marked as @Deprecated. Is this release changing it to a non-deprecated method now? There are other methods in this interface that have similar changes.", "author": "srnagar", "createdAt": "2020-02-26T21:49:37Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -433,108 +282,65 @@\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @return the observable to the OcrResult object\n      */\n-    @Deprecated\n     Observable<OcrResult> recognizePrintedTextInStreamAsync(boolean detectOrientation, byte[] image, RecognizePrintedTextInStreamOptionalParameter recognizePrintedTextInStreamOptionalParameter);\n \n+\n     /**\n-     * Optical Character Recognition (OCR) detects printed text in an image and extracts the recognized characters\n-     *   into a machine-usable character stream.   Upon success, the OCR results will be returned. Upon failure, the\n-     *   error code together with an error message will be returned. The error code can be one of InvalidImageUrl,\n-     *   InvalidImageFormat, InvalidImageSize, NotSupportedImage,  NotSupportedLanguage, or InternalServerError.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n      *\n-     * @return the first stage of the recognizePrintedTextInStream call\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n+     * @return the DomainModelResults object if successful.\n      */\n-    ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithDetectOrientation recognizePrintedTextInStream();\n+    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n \n     /**\n-     * Grouping of recognizePrintedTextInStream definition stages.\n+     * This operation recognizes content within an image by applying a domain-specific model. The list of\n+     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n+     *   request. Currently, the API provides following domain-specific models: celebrities, landmarks.\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON.\n+     *   If the request failed, the response will contain an error code and a message to help understand what went\n+     *   wrong.\n+     *\n+     * @param model The domain-specific content to recognize.\n+     * @param image An image stream.\n+     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return the observable to the DomainModelResults object\n      */\n-    interface ComputerVisionRecognizePrintedTextInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify detectOrientation.\n-         */\n-        interface WithDetectOrientation {\n-            /**\n-             * Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to\n-             *   detect the image orientation and correct it before further processing (e.g. if it's upside-down).\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withDetectOrientation(boolean detectOrientation);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The BCP-47 language code of the text to be detected in the image. The default value is 'unk'. Possible\n-             *   values include: 'unk', 'zh-Hans', 'zh-Hant', 'cs', 'da', 'nl', 'en', 'fi', 'fr', 'de', 'el', 'hu', 'it',\n-             *   'ja', 'ko', 'nb', 'pl', 'pt', 'ru', 'es', 'sv', 'tr', 'ar', 'ro', 'sr-Cyrl', 'sr-Latn', 'sk'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithExecute withLanguage(OcrLanguages language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionRecognizePrintedTextInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the OcrResult object if successful.\n-             */\n-            OcrResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the OcrResult object\n-             */\n-            Observable<OcrResult> executeAsync();\n-        }\n-    }\n+    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTUxOA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841518", "bodyText": "Added back", "author": "jianghaolu", "createdAt": "2020-02-27T00:05:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4NzY4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4Nzk0Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384787942", "bodyText": "Deprecated?", "author": "srnagar", "createdAt": "2020-02-26T21:50:04Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVision.java", "diffHunk": "@@ -69,344 +107,154 @@\n     Observable<Void> recognizeTextInStreamAsync(byte[] image, TextRecognitionMode mode);\n \n \n+\n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the DomainModelResults object if successful.\n+     * @return the ReadOperationResult object if successful.\n      */\n-    @Deprecated\n-    DomainModelResults analyzeImageByDomainInStream(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    ReadOperationResult getReadOperationResult(String operationId);\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * This interface is used for getting OCR results of Read operation. The URL to this interface should\n+      *  be retrieved from 'Operation-Location' field returned from Batch Read File interface.\n      *\n-     * @param model The domain-specific content to recognize.\n-     * @param image An image stream.\n-     * @param analyzeImageByDomainInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of read operation returned in the response of the 'Batch Read File' interface.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the DomainModelResults object\n+     * @return the observable to the ReadOperationResult object\n      */\n-    @Deprecated\n-    Observable<DomainModelResults> analyzeImageByDomainInStreamAsync(String model, byte[] image, AnalyzeImageByDomainInStreamOptionalParameter analyzeImageByDomainInStreamOptionalParameter);\n+    Observable<ReadOperationResult> getReadOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation recognizes content within an image by applying a domain-specific model.  The list of\n-     *   domain-specific models that are supported by the Computer Vision API can be retrieved using the /models GET\n-     *   request.  Currently, the API only provides a single domain-specific model: celebrities. Two input methods\n-     *   are supported -- (1) Uploading an image or (2) specifying an image URL. A successful response will be\n-     *   returned in JSON.  If the request failed, the response will contain an error code and a message to help\n-     *   understand what went wrong.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n      *\n-     * @return the first stage of the analyzeImageByDomainInStream call\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel analyzeImageByDomainInStream();\n+    void batchReadFile(String url);\n \n     /**\n-     * Grouping of analyzeImageByDomainInStream definition stages.\n+     * Use this interface to get the result of a Read operation, employing the state-of-the-art Optical\n+      *  Character Recognition (OCR) algorithms optimized for text-heavy documents. When you use the Read\n+      *  File interface, the response contains a field called 'Operation-Location'. The\n+      *  'Operation-Location' field contains the URL that you must use for your 'GetReadOperationResult'\n+      *  operation to access OCR results.\u200b.\n+     *\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify model.\n-         */\n-        interface WithModel {\n-            /**\n-             * The domain-specific content to recognize.\n-             *\n-             * @return next definition stage\n-             */\n-            WithImage withModel(String model);\n-        }\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the DomainModelResults object if successful.\n-             */\n-            DomainModelResults execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the DomainModelResults object\n-             */\n-            Observable<DomainModelResults> executeAsync();\n-        }\n-    }\n+    Observable<Void> batchReadFileAsync(String url);\n+\n \n-    /**\n-     * The entirety of analyzeImageByDomainInStream definition.\n-     */\n-    interface ComputerVisionAnalyzeImageByDomainInStreamDefinition extends\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithModel,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithImage,\n-        ComputerVisionAnalyzeImageByDomainInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the TagResult object if successful.\n+     * @return the TextOperationResult object if successful.\n      */\n-    @Deprecated\n-    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    TextOperationResult getTextOperationResult(String operationId);\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * This interface is used for getting text operation result. The URL to this interface should be\n+      *  retrieved from 'Operation-Location' field returned from Recognize Text interface.\n      *\n-     * @param image An image stream.\n-     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param operationId Id of the text operation returned in the response of the 'Recognize Text'.\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n-     * @return the observable to the TagResult object\n+     * @return the observable to the TextOperationResult object\n      */\n-    @Deprecated\n-    Observable<TagResult> tagImageInStreamAsync(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);\n+    Observable<TextOperationResult> getTextOperationResultAsync(String operationId);\n+\n+\n \n     /**\n-     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n-     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n-     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n-     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag 'cello'\n-     *   may be accompanied by the hint 'musical instrument'. All tags are in English.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n      *\n-     * @return the first stage of the tagImageInStream call\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @throws ComputerVisionErrorException thrown if the request is rejected by server\n+     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n      */\n-    ComputerVisionTagImageInStreamDefinitionStages.WithImage tagImageInStream();\n+    void recognizeText(String url, TextRecognitionMode mode);\n \n     /**\n-     * Grouping of tagImageInStream definition stages.\n+     * Recognize Text operation. When you use the Recognize Text interface, the response contains a field\n+      *  called 'Operation-Location'. The 'Operation-Location' field contains the URL that you must use for\n+      *  your Get Recognize Text Operation Result operation.\n+     *\n+     * @param mode Type of text to recognize. Possible values include: 'Handwritten', 'Printed'.\n+     * @param url Publicly reachable URL of an image.\n+     * @throws IllegalArgumentException thrown if parameters fail the validation\n+     * @return a representation of the deferred computation of this call if successful.\n      */\n-    interface ComputerVisionTagImageInStreamDefinitionStages {\n-        /**\n-         * The stage of the definition to be specify image.\n-         */\n-        interface WithImage {\n-            /**\n-             * An image stream.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withImage(byte[] image);\n-        }\n-\n-        /**\n-         * The stage of the definition which allows for any other optional settings to be specified.\n-         */\n-        interface WithAllOptions {\n-            /**\n-             * The desired language for output generation. If this parameter is not specified, the default value is\n-             *   &amp;quot;en&amp;quot;.Supported languages:en - English, Default. es - Spanish, ja - Japanese, pt -\n-             *   Portuguese, zh - Simplified Chinese. Possible values include: 'en', 'es', 'ja', 'pt', 'zh'.\n-             *\n-             * @return next definition stage\n-             */\n-            ComputerVisionTagImageInStreamDefinitionStages.WithExecute withLanguage(String language);\n-\n-        }\n-\n-        /**\n-         * The last stage of the definition which will make the operation call.\n-        */\n-        interface WithExecute extends ComputerVisionTagImageInStreamDefinitionStages.WithAllOptions {\n-            /**\n-             * Execute the request.\n-             *\n-             * @return the TagResult object if successful.\n-             */\n-            TagResult execute();\n-\n-            /**\n-             * Execute the request asynchronously.\n-             *\n-             * @return the observable to the TagResult object\n-             */\n-            Observable<TagResult> executeAsync();\n-        }\n-    }\n+    Observable<Void> recognizeTextAsync(String url, TextRecognitionMode mode);\n \n-    /**\n-     * The entirety of tagImageInStream definition.\n-     */\n-    interface ComputerVisionTagImageInStreamDefinition extends\n-        ComputerVisionTagImageInStreamDefinitionStages.WithImage,\n-        ComputerVisionTagImageInStreamDefinitionStages.WithExecute {\n-    }\n \n     /**\n-     * This operation generates a description of an image in human readable language with complete sentences.  The\n-     *   description is based on a collection of content tags, which are also returned by the operation. More than\n-     *   one description can be generated for each image.  Descriptions are ordered by their confidence score. All\n-     *   descriptions are in English. Two input methods are supported -- (1) Uploading an image or (2) specifying an\n-     *   image URL.A successful response will be returned in JSON.  If the request failed, the response will contain\n-     *   an error code and a message to help understand what went wrong.\n+     * This operation generates a list of words, or tags, that are relevant to the content of the supplied image.\n+     *   The Computer Vision API can return tags based on objects, living beings, scenery or actions found in images.\n+     *   Unlike categories, tags are not organized according to a hierarchical classification system, but correspond\n+     *   to image content. Tags may contain hints to avoid ambiguity or provide context, for example the tag\n+     *   \"ascomycete\" may be accompanied by the hint \"fungus\".\n+     *   Two input methods are supported -- (1) Uploading an image or (2) specifying an image URL.\n+     *   A successful response will be returned in JSON. If the request failed, the response will contain an error\n+     *   code and a message to help understand what went wrong.\n      *\n      * @param image An image stream.\n-     * @param describeImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n+     * @param tagImageInStreamOptionalParameter the object representing the optional parameters to be set before calling this API\n      * @throws IllegalArgumentException thrown if parameters fail the validation\n      * @throws ComputerVisionErrorException thrown if the request is rejected by server\n      * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent\n-     * @return the ImageDescription object if successful.\n+     * @return the TagResult object if successful.\n      */\n-    @Deprecated\n-    ImageDescription describeImageInStream(byte[] image, DescribeImageInStreamOptionalParameter describeImageInStreamOptionalParameter);\n+    TagResult tagImageInStream(byte[] image, TagImageInStreamOptionalParameter tagImageInStreamOptionalParameter);", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTExNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841114", "bodyText": "Added back", "author": "jianghaolu", "createdAt": "2020-02-27T00:04:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4Nzk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4OTE4OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384789189", "bodyText": "nit: Don't need extra . here.", "author": "srnagar", "createdAt": "2020-02-26T21:52:31Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -36,14 +36,14 @@\n     String userAgent();\n \n     /**\n-     * Gets Supported Cognitive Services endpoints.\n+     * Gets Supported Cognitive Services endpoints..", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc4OTI3Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384789273", "bodyText": "same as above.", "author": "srnagar", "createdAt": "2020-02-26T21:52:40Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -36,14 +36,14 @@\n     String userAgent();\n \n     /**\n-     * Gets Supported Cognitive Services endpoints.\n+     * Gets Supported Cognitive Services endpoints..\n      *\n      * @return the endpoint value.\n      */\n     String endpoint();\n \n     /**\n-     * Sets Supported Cognitive Services endpoints.\n+     * Sets Supported Cognitive Services endpoints..", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MTQ1Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384791453", "bodyText": "Is this a regression? The previous version had a specific error code type returned instead of Object.", "author": "srnagar", "createdAt": "2020-02-26T21:56:42Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionError.java", "diffHunk": "@@ -11,18 +11,14 @@\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n /**\n- * The ComputerVisionError model.\n+ * Details about the API request error.\n  */\n public class ComputerVisionError {\n     /**\n-     * The error code. Possible values include: 'InvalidImageUrl',\n-     * 'InvalidImageFormat', 'InvalidImageSize', 'NotSupportedVisualFeature',\n-     * 'NotSupportedImage', 'InvalidDetails', 'NotSupportedLanguage',\n-     * 'BadArgument', 'FailedToProcess', 'Timeout', 'InternalServerError',\n-     * 'Unspecified', 'StorageException'.\n+     * The error code.\n      */\n     @JsonProperty(value = \"code\", required = true)\n-    private ComputerVisionErrorCodes code;\n+    private Object code;", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MjU1MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384792551", "bodyText": "This type is deleted but ComputerVisionError has methods that return code - maybe this type should be used there? I know it's generated code but not sure if this is a swagger issue that needs to be looked into.", "author": "srnagar", "createdAt": "2020-02-26T21:58:46Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/models/ComputerVisionErrorCodes.java", "diffHunk": "@@ -1,86 +0,0 @@\n-/**\n- * Copyright (c) Microsoft Corporation. All rights reserved.\n- * Licensed under the MIT License. See License.txt in the project root for\n- * license information.\n- *\n- * Code generated by Microsoft (R) AutoRest Code Generator.\n- */\n-\n-package com.microsoft.azure.cognitiveservices.vision.computervision.models;\n-\n-import com.fasterxml.jackson.annotation.JsonCreator;\n-import com.fasterxml.jackson.annotation.JsonValue;\n-\n-/**\n- * Defines values for ComputerVisionErrorCodes.\n- */\n-public enum ComputerVisionErrorCodes {", "originalCommit": "6fe8be9a0aa6ab97b08c3b848c9411121dabc0b8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg0MTY0MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384841641", "bodyText": "Added \"type\": \"string\" and regenerated this.", "author": "jianghaolu", "createdAt": "2020-02-27T00:05:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDc5MjU1MQ=="}], "type": "inlineReview"}, {"oid": "495a3253cb4332a9b231f8165000317fabdb04c7", "url": "https://github.com/Azure/azure-sdk-for-java/commit/495a3253cb4332a9b231f8165000317fabdb04c7", "message": "Manual fixes after generation", "committedDate": "2020-02-27T00:03:16Z", "type": "commit"}, {"oid": "9e47982313006a1409ded6f2fbcf237625f4878f", "url": "https://github.com/Azure/azure-sdk-for-java/commit/9e47982313006a1409ded6f2fbcf237625f4878f", "message": "double dots", "committedDate": "2020-02-27T00:05:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg2MTI5Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/8483#discussion_r384861297", "bodyText": "Do we care that these Javadocs aren't grammatically correct?", "author": "alzimmermsft", "createdAt": "2020-02-27T01:11:26Z", "path": "sdk/cognitiveservices/ms-azure-cs-computervision/src/main/java/com/microsoft/azure/cognitiveservices/vision/computervision/ComputerVisionClient.java", "diffHunk": "@@ -51,44 +51,44 @@\n     ComputerVisionClient withEndpoint(String endpoint);\n \n     /**\n-     * Gets Gets or sets the preferred language for the response..\n+     * Gets Gets or sets the preferred language for the response.\n      *\n      * @return the acceptLanguage value.\n      */\n     String acceptLanguage();\n \n     /**\n-     * Sets Gets or sets the preferred language for the response..\n+     * Sets Gets or sets the preferred language for the response.", "originalCommit": "9e47982313006a1409ded6f2fbcf237625f4878f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "79f329bba6644e77c5c8cdf9b3feda9e3fe979d5", "url": "https://github.com/Azure/azure-sdk-for-java/commit/79f329bba6644e77c5c8cdf9b3feda9e3fe979d5", "message": "Regenerate with --with-expanded-parameters=true", "committedDate": "2020-02-28T19:38:33Z", "type": "commit"}, {"oid": "fb603566addf391f1ccaaf2e9f17d46ca8a317a3", "url": "https://github.com/Azure/azure-sdk-for-java/commit/fb603566addf391f1ccaaf2e9f17d46ca8a317a3", "message": "Add @Deprecated", "committedDate": "2020-02-28T19:50:34Z", "type": "commit"}]}