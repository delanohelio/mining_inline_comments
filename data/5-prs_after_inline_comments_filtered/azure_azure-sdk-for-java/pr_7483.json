{"pr_number": 7483, "pr_title": "Nio initialization", "pr_createdAt": "2020-01-15T21:15:49Z", "pr_url": "https://github.com/Azure/azure-sdk-for-java/pull/7483", "timeline": [{"oid": "4aa4ec0d24361eb04c2b89b8b90204e2e0bcf8ff", "url": "https://github.com/Azure/azure-sdk-for-java/commit/4aa4ec0d24361eb04c2b89b8b90204e2e0bcf8ff", "message": "Added types for initialization", "committedDate": "2020-01-09T00:59:07Z", "type": "commit"}, {"oid": "8af54ea94bfbefb52b62e283c517a3659471b90a", "url": "https://github.com/Azure/azure-sdk-for-java/commit/8af54ea94bfbefb52b62e283c517a3659471b90a", "message": "Initial test for FileSystem initialization", "committedDate": "2020-01-10T01:42:22Z", "type": "commit"}, {"oid": "15225b56a47f3eb46b2a0db67cf0d1d0c131bf5c", "url": "https://github.com/Azure/azure-sdk-for-java/commit/15225b56a47f3eb46b2a0db67cf0d1d0c131bf5c", "message": "file system initialization", "committedDate": "2020-01-15T18:49:29Z", "type": "commit"}, {"oid": "677a6809a9a0278486525f30ded2a00b75094d9b", "url": "https://github.com/Azure/azure-sdk-for-java/commit/677a6809a9a0278486525f30ded2a00b75094d9b", "message": "Java docs", "committedDate": "2020-01-15T21:14:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExODI4NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367118284", "bodyText": "What is a \"type\" supposed to be?", "author": "jaschrep-msft", "createdAt": "2020-01-15T21:32:55Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileStore.java", "diffHunk": "@@ -0,0 +1,120 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.attribute.FileStoreAttributeView;\n+import java.util.Objects;\n+\n+/**\n+ * An {@code AzureFileStore} is backed by an Azure Blob Storage container.\n+ * \n+ * {@inheritDoc}\n+ */\n+public final class AzureFileStore extends FileStore {\n+    private final AzureFileSystem parentFileSystem;\n+    private final BlobContainerClient containerClient;\n+\n+    AzureFileStore(AzureFileSystem parentFileSystem, String containerName) throws IOException {\n+        // A FileStore should only ever be created by a FileSystem.\n+        if (Objects.isNull(parentFileSystem)) {\n+            throw new IllegalStateException(\"AzureFileStore cannot be instantiated without a parent FileSystem\");\n+        }\n+        this.parentFileSystem = parentFileSystem;\n+        this.containerClient = this.parentFileSystem.getBlobServiceClient().getBlobContainerClient(containerName);\n+\n+        try {\n+            // This also serves as our connection check.\n+            if (!this.containerClient.exists()) {\n+                this.containerClient.create();\n+            }\n+        } catch (Exception e) {\n+            throw new IOException(\"There was an error in establishing the existence of container: \" + containerName, e);\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String name() {\n+        return this.containerClient.getBlobContainerName();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String type() {\n+        return null;", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1NjUxMQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367156511", "bodyText": "Updated PR description to note this API is not implemented yet and does not need to be reviewed.", "author": "rickle-msft", "createdAt": "2020-01-15T23:13:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExODI4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExOTE0Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367119147", "bodyText": "Is it better to return -1 to be extremely obvious that we don't care about these numbers instead of accidentally implying there's no space or something like that?", "author": "jaschrep-msft", "createdAt": "2020-01-15T21:35:01Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileStore.java", "diffHunk": "@@ -0,0 +1,120 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.attribute.FileStoreAttributeView;\n+import java.util.Objects;\n+\n+/**\n+ * An {@code AzureFileStore} is backed by an Azure Blob Storage container.\n+ * \n+ * {@inheritDoc}\n+ */\n+public final class AzureFileStore extends FileStore {\n+    private final AzureFileSystem parentFileSystem;\n+    private final BlobContainerClient containerClient;\n+\n+    AzureFileStore(AzureFileSystem parentFileSystem, String containerName) throws IOException {\n+        // A FileStore should only ever be created by a FileSystem.\n+        if (Objects.isNull(parentFileSystem)) {\n+            throw new IllegalStateException(\"AzureFileStore cannot be instantiated without a parent FileSystem\");\n+        }\n+        this.parentFileSystem = parentFileSystem;\n+        this.containerClient = this.parentFileSystem.getBlobServiceClient().getBlobContainerClient(containerName);\n+\n+        try {\n+            // This also serves as our connection check.\n+            if (!this.containerClient.exists()) {\n+                this.containerClient.create();\n+            }\n+        } catch (Exception e) {\n+            throw new IOException(\"There was an error in establishing the existence of container: \" + containerName, e);\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String name() {\n+        return this.containerClient.getBlobContainerName();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String type() {\n+        return null;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean isReadOnly() {\n+        return false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public long getTotalSpace() throws IOException {\n+        return 0;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public long getUsableSpace() throws IOException {\n+        return 0;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public long getUnallocatedSpace() throws IOException {\n+        return 0;\n+    }", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1NjYzMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367156633", "bodyText": "Updated PR description to note this API is not implemented yet and does not need to be reviewed.", "author": "rickle-msft", "createdAt": "2020-01-15T23:13:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExOTE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE2MDk0OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367160949", "bodyText": "@alzimmermsft Do you think we should use the same system for logging exceptions as in the SDKs. In particular, I think some of the logging methods return RuntimeExceptions, but the spec dictates that specific types of exceptions need to be thrown here. But we probably still should capture a lot of these errors in logs.", "author": "rickle-msft", "createdAt": "2020-01-15T23:28:26Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -3,9 +3,299 @@\n \n package com.azure.storage.blob.nio;\n \n+import com.azure.core.util.CoreUtils;\n+import reactor.core.publisher.Flux;\n+import reactor.core.publisher.Mono;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.nio.channels.SeekableByteChannel;\n+import java.nio.file.AccessMode;\n+import java.nio.file.CopyOption;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystemAlreadyExistsException;\n+import java.nio.file.FileSystemNotFoundException;\n+import java.nio.file.LinkOption;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n /**\n- * Empty class.\n+ * The {@code AzureFileSystemProvider} is Azure Storage's implementation of the nio interface on top of Azure Blob\n+ * Storage.\n+ * <p>\n+ * Particular care should be taken when working with a remote storage service. This implementation makes no guarantees\n+ * on behavior or state should other processes operate on the same data concurrently; file systems from this provider\n+ * will assume they have exclusive access to their data and will behave without regard for potential of interfering\n+ * applications. Moreover, remote file stores introduce higher latencies. Therefore, particular care must be taken when\n+ * managing concurrency: race conditions are more likely to manifest and network failures occur more frequently than\n+ * disk failures. These and other such distributed application scenarios must be considered when working with this file\n+ * system. While the {@code AzureFileSystem} will ensure it takes appropriate steps towards robustness and reliability,\n+ * the application developer must design around these failure scenarios and have fallback and retry options available.\n+ * <p>\n+ * The Azure Blob Storage service backing these APIs is not a true FileSystem, nor is it the goal of this implementation\n+ * to force Azure Blob Storage to act like a full-fledged file system. Some APIs and scenarios will remain unsupported\n+ * indefinitely until they may be sensibly implemented. Other APIs may experience lower performance than is expected\n+ * because of the number of network requests needed to ensure correctness.\n+ * <p>\n+ * The scheme for this provider is {@code \"azb\"}, and the format of the URI to identify an {@code AzureFileSystem} is\n+ * {@code \"azb://?account=&lt;accountName&gt;\"}. The name of the Storage account is used to uniquely identify the file\n+ * system.\n+ * <p>\n+ * An {@link AzureFileSystem} is backed by an account. An {@link AzureFileStore} is backed by a container. Any number of\n+ * containers may be specified as file stores upon creation of the file system. When a file system is created,\n+ * it will try to retrieve the properties of each container to ensure connection to the account. If any of the\n+ * containers does not exist, it will be created. Failure to access or create containers as necessary will result in\n+ * an exception and failure to create the file system. Any data existing in the containers will be preserved and\n+ * accessible via the file system, though customers should be aware that it must be in a format understandable by\n+ * the types in this package or behavior will be undefined.\n+ * <p>\n+ * {@link #newFileSystem(URI, Map)} will check for the following keys in the configuration map and expect the named\n+ * types. Any entries not listed here will be ignored. Note that {@link AzureFileSystem} has public constants defined\n+ * for each of the keys for convenience.\n+ * <ul>\n+ *     <li>{@code AzureStorageAccountKey:}{@link String}</li>\n+ *     <li>{@code AzureStorageSasToken:}{@link String}</li>\n+ *     <li>{@code AzureStorageHttpLogDetailLevel:}{@link com.azure.core.http.policy.HttpLogDetailLevel}</li>\n+ *     <li>{@code AzureStorageMaxTries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageTryTimeout:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageMaxRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageRetryPolicyType:}{@link com.azure.storage.common.policy.RetryPolicyType}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link String}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageBlockSize:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageDownloadResumeRetries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageUseHttps:}{@link Boolean}</li>\n+ *     <li>{@code AzureStorageFileStores:}{@link Iterable<String>}</li>\n+ * </ul>\n+ * <p>\n+ * Either an account key or a sas token must be specified. If both are provided, the account key will be preferred. If\n+ * a sas token is specified, the customer must take care that it has appropriate permissions to perform the actions\n+ * demanded of the file system in a given workflow, including the initial connection check specified above. Furthermore,\n+ * it must have an expiry time that lasts at least until the file system is closed as there is no token refresh offered\n+ * at this time. The same token will be applied to all containers.\n+ * <p>\n+ * An iterable of file stores must also be provided; each entry should simply be the name of a container. All other\n+ * values listed are used to configure the underlying {@link com.azure.storage.blob.BlobServiceClient}. Please refer to\n+ * that type for more information on these values.\n+ *\n+ * @see FileSystemProvider\n  */\n-public class AzureFileSystemProvider  {\n+public final class AzureFileSystemProvider extends FileSystemProvider {\n+    // TODO: Add logger", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2OTA0Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367569047", "bodyText": "Should log these exceptions but don't need to throw them using ClientLogger.logExceptionAs{Warning/Error}, instead could call ClientLogger.warning(Message, Exception) and ClientLogger.error(Message, Exception) and throw the non-runtime exception afterwards. This technique is used in a few places where non-runtime exceptions are being thrown.", "author": "alzimmermsft", "createdAt": "2020-01-16T18:05:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE2MDk0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxMTM4Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367611387", "bodyText": "Will do. Thanks", "author": "rickle-msft", "createdAt": "2020-01-16T19:38:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE2MDk0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3Mzk1Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367173953", "bodyText": "Do we want to make this a constant somewhere?", "author": "gapra-msft", "createdAt": "2020-01-16T00:17:37Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -3,9 +3,299 @@\n \n package com.azure.storage.blob.nio;\n \n+import com.azure.core.util.CoreUtils;\n+import reactor.core.publisher.Flux;\n+import reactor.core.publisher.Mono;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.nio.channels.SeekableByteChannel;\n+import java.nio.file.AccessMode;\n+import java.nio.file.CopyOption;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystemAlreadyExistsException;\n+import java.nio.file.FileSystemNotFoundException;\n+import java.nio.file.LinkOption;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n /**\n- * Empty class.\n+ * The {@code AzureFileSystemProvider} is Azure Storage's implementation of the nio interface on top of Azure Blob\n+ * Storage.\n+ * <p>\n+ * Particular care should be taken when working with a remote storage service. This implementation makes no guarantees\n+ * on behavior or state should other processes operate on the same data concurrently; file systems from this provider\n+ * will assume they have exclusive access to their data and will behave without regard for potential of interfering\n+ * applications. Moreover, remote file stores introduce higher latencies. Therefore, particular care must be taken when\n+ * managing concurrency: race conditions are more likely to manifest and network failures occur more frequently than\n+ * disk failures. These and other such distributed application scenarios must be considered when working with this file\n+ * system. While the {@code AzureFileSystem} will ensure it takes appropriate steps towards robustness and reliability,\n+ * the application developer must design around these failure scenarios and have fallback and retry options available.\n+ * <p>\n+ * The Azure Blob Storage service backing these APIs is not a true FileSystem, nor is it the goal of this implementation\n+ * to force Azure Blob Storage to act like a full-fledged file system. Some APIs and scenarios will remain unsupported\n+ * indefinitely until they may be sensibly implemented. Other APIs may experience lower performance than is expected\n+ * because of the number of network requests needed to ensure correctness.\n+ * <p>\n+ * The scheme for this provider is {@code \"azb\"}, and the format of the URI to identify an {@code AzureFileSystem} is\n+ * {@code \"azb://?account=&lt;accountName&gt;\"}. The name of the Storage account is used to uniquely identify the file\n+ * system.\n+ * <p>\n+ * An {@link AzureFileSystem} is backed by an account. An {@link AzureFileStore} is backed by a container. Any number of\n+ * containers may be specified as file stores upon creation of the file system. When a file system is created,\n+ * it will try to retrieve the properties of each container to ensure connection to the account. If any of the\n+ * containers does not exist, it will be created. Failure to access or create containers as necessary will result in\n+ * an exception and failure to create the file system. Any data existing in the containers will be preserved and\n+ * accessible via the file system, though customers should be aware that it must be in a format understandable by\n+ * the types in this package or behavior will be undefined.\n+ * <p>\n+ * {@link #newFileSystem(URI, Map)} will check for the following keys in the configuration map and expect the named\n+ * types. Any entries not listed here will be ignored. Note that {@link AzureFileSystem} has public constants defined\n+ * for each of the keys for convenience.\n+ * <ul>\n+ *     <li>{@code AzureStorageAccountKey:}{@link String}</li>\n+ *     <li>{@code AzureStorageSasToken:}{@link String}</li>\n+ *     <li>{@code AzureStorageHttpLogDetailLevel:}{@link com.azure.core.http.policy.HttpLogDetailLevel}</li>\n+ *     <li>{@code AzureStorageMaxTries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageTryTimeout:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageMaxRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageRetryPolicyType:}{@link com.azure.storage.common.policy.RetryPolicyType}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link String}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageBlockSize:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageDownloadResumeRetries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageUseHttps:}{@link Boolean}</li>\n+ *     <li>{@code AzureStorageFileStores:}{@link Iterable<String>}</li>\n+ * </ul>\n+ * <p>\n+ * Either an account key or a sas token must be specified. If both are provided, the account key will be preferred. If\n+ * a sas token is specified, the customer must take care that it has appropriate permissions to perform the actions\n+ * demanded of the file system in a given workflow, including the initial connection check specified above. Furthermore,\n+ * it must have an expiry time that lasts at least until the file system is closed as there is no token refresh offered\n+ * at this time. The same token will be applied to all containers.\n+ * <p>\n+ * An iterable of file stores must also be provided; each entry should simply be the name of a container. All other\n+ * values listed are used to configure the underlying {@link com.azure.storage.blob.BlobServiceClient}. Please refer to\n+ * that type for more information on these values.\n+ *\n+ * @see FileSystemProvider\n  */\n-public class AzureFileSystemProvider  {\n+public final class AzureFileSystemProvider extends FileSystemProvider {\n+    // TODO: Add logger\n+    private static final String ACCOUNT_QUERY_KEY = \"account\";\n+\n+    private ConcurrentMap<String, FileSystem> openFileSystems;\n+\n+    // Specs require a public zero argument constructor.\n+\n+    /**\n+     * Creates an AzureFileSystemProvider.\n+     */\n+    public AzureFileSystemProvider() {\n+        this.openFileSystems = new ConcurrentHashMap<>();\n+    }\n+\n+    /**\n+     * Returns {@code \"azb\".}\n+     */\n+    @Override\n+    public String getScheme() {\n+        return \"azb\";", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxMTk5Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367611992", "bodyText": "I can make it a constant if you would prefer, but it feels a little redundant. I only anticipate other code calling into the provider to get the scheme when necessary, so all code would go through this method and the constant would only be returned from this method.", "author": "rickle-msft", "createdAt": "2020-01-16T19:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3Mzk1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzY2OTM4MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367669380", "bodyText": "It's possible a user may want the constant when building their URI right?", "author": "gapra-msft", "createdAt": "2020-01-16T21:52:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3Mzk1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3NzA1OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367177059", "bodyText": "Is there a reason you chose to put the constants in FileSystem and not FileSystemProvider?", "author": "gapra-msft", "createdAt": "2020-01-16T00:29:32Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxMzkzMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367613932", "bodyText": "I put them here because they're used to configure the FileSystem, but since you use them to pass a map into a method on FileSystemProvider, I can see an argument for putting them on the provider.", "author": "rickle-msft", "createdAt": "2020-01-16T19:43:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3NzA1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3ODM5NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367178395", "bodyText": "extra new line", "author": "gapra-msft", "createdAt": "2020-01-16T00:34:59Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.\n+\n+    public static final String AZURE_STORAGE_FILE_STORES = \"AzureStorageFileStores\";\n+\n+    private static final String AZURE_STORAGE_ENDPOINT_TEMPLATE = \"%s://%s.blob.core.windows.net\";\n+\n+    private final AzureFileSystemProvider parentFileSystemProvider;\n+    private final BlobServiceClient blobServiceClient;\n+    private final Integer blockSize;\n+    private final Integer downloadResumeRetries;\n+    private final Map<String, FileStore> fileStores;\n+    private boolean closed;\n+\n+    AzureFileSystem(AzureFileSystemProvider parentFileSystemProvider, String accountName, Map<String, ?> config)\n+            throws IOException {\n+        // A FileSystem should only ever be instantiated by a provider.\n+        if (Objects.isNull(parentFileSystemProvider)) {\n+            throw new IllegalArgumentException(\"AzureFileSystem cannot be instantiated without a parent \" +\n+                \"FileSystemProvider\");\n+        }\n+        this.parentFileSystemProvider = parentFileSystemProvider;\n+\n+        // Read configurations and build client.\n+        try {\n+            this.blobServiceClient = this.buildBlobServiceClient(accountName, config);\n+            this.blockSize = (Integer) config.get(AZURE_STORAGE_BLOCK_SIZE);\n+            this.downloadResumeRetries = (Integer) config.get(AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES);\n+        } catch (Exception e) {\n+            throw new IllegalArgumentException(\"There was an error parsing the configurations map. Please ensure all\" +\n+                \"fields are set to a legal value of the correct type.\");\n+        }\n+\n+        // Initialize and ensure access to FileStores.\n+        try {\n+            this.fileStores = this.initializeFileStores(config);\n+        } catch (IOException e) {\n+            throw new IOException(\"Initializing FileStores failed. FileSystem could not be opened.\", e);\n+        }\n+\n+        this.closed = false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public FileSystemProvider provider() {\n+        return this.parentFileSystemProvider;\n+    }\n+\n+    /**\n+     * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+     * terminate naturally after the file system is closed, though no further operations may be started after the\n+     * parent file system is closed.\n+     *\n+     * Once closed, a file system with the same identifier as the one closed may be re-opened.\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void close() throws IOException {\n+        this.closed = true;\n+        this.parentFileSystemProvider.closeFileSystem(this.getFileSystemName());\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean isOpen() {\n+        return !this.closed;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean isReadOnly() {\n+        return false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String getSeparator() {\n+        return \"/\";\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Iterable<Path> getRootDirectories() {\n+        return null;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Iterable<FileStore> getFileStores() {\n+        return\n+            this.fileStores.values();", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3ODcwMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367178700", "bodyText": "Is this block size for upload? Do we want to clarify that in the name?", "author": "gapra-msft", "createdAt": "2020-01-16T00:36:18Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.\n+\n+    public static final String AZURE_STORAGE_FILE_STORES = \"AzureStorageFileStores\";\n+\n+    private static final String AZURE_STORAGE_ENDPOINT_TEMPLATE = \"%s://%s.blob.core.windows.net\";\n+\n+    private final AzureFileSystemProvider parentFileSystemProvider;\n+    private final BlobServiceClient blobServiceClient;\n+    private final Integer blockSize;\n+    private final Integer downloadResumeRetries;\n+    private final Map<String, FileStore> fileStores;\n+    private boolean closed;\n+\n+    AzureFileSystem(AzureFileSystemProvider parentFileSystemProvider, String accountName, Map<String, ?> config)\n+            throws IOException {\n+        // A FileSystem should only ever be instantiated by a provider.\n+        if (Objects.isNull(parentFileSystemProvider)) {\n+            throw new IllegalArgumentException(\"AzureFileSystem cannot be instantiated without a parent \" +\n+                \"FileSystemProvider\");\n+        }\n+        this.parentFileSystemProvider = parentFileSystemProvider;\n+\n+        // Read configurations and build client.\n+        try {\n+            this.blobServiceClient = this.buildBlobServiceClient(accountName, config);\n+            this.blockSize = (Integer) config.get(AZURE_STORAGE_BLOCK_SIZE);", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxNDI2Ng==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367614266", "bodyText": "It's the block size we pass to the ParallelTransferOptions. I guess in this case it would always be upload, so I'll update the name.", "author": "rickle-msft", "createdAt": "2020-01-16T19:44:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3ODcwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3OTE5OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367179199", "bodyText": "Can we include Blob in this name?", "author": "gapra-msft", "createdAt": "2020-01-16T00:38:27Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.\n+\n+    public static final String AZURE_STORAGE_FILE_STORES = \"AzureStorageFileStores\";\n+\n+    private static final String AZURE_STORAGE_ENDPOINT_TEMPLATE = \"%s://%s.blob.core.windows.net\";", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxNDQwNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367614404", "bodyText": "Yes indeed!", "author": "rickle-msft", "createdAt": "2020-01-16T19:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE3OTE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTAyNw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367559027", "bodyText": "The inherited docs are very vague, in the places where you have done implementation should the docs be re-written.", "author": "alzimmermsft", "createdAt": "2020-01-16T17:43:10Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileStore.java", "diffHunk": "@@ -0,0 +1,120 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.attribute.FileStoreAttributeView;\n+import java.util.Objects;\n+\n+/**\n+ * An {@code AzureFileStore} is backed by an Azure Blob Storage container.\n+ * \n+ * {@inheritDoc}\n+ */\n+public final class AzureFileStore extends FileStore {\n+    private final AzureFileSystem parentFileSystem;\n+    private final BlobContainerClient containerClient;\n+\n+    AzureFileStore(AzureFileSystem parentFileSystem, String containerName) throws IOException {\n+        // A FileStore should only ever be created by a FileSystem.\n+        if (Objects.isNull(parentFileSystem)) {\n+            throw new IllegalStateException(\"AzureFileStore cannot be instantiated without a parent FileSystem\");\n+        }\n+        this.parentFileSystem = parentFileSystem;\n+        this.containerClient = this.parentFileSystem.getBlobServiceClient().getBlobContainerClient(containerName);\n+\n+        try {\n+            // This also serves as our connection check.\n+            if (!this.containerClient.exists()) {\n+                this.containerClient.create();\n+            }\n+        } catch (Exception e) {\n+            throw new IOException(\"There was an error in establishing the existence of container: \" + containerName, e);\n+        }\n+    }\n+\n+    /**\n+     * {@inheritDoc}", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxNzUyNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367617526", "bodyText": "I haven't been super sure about the best way to do docs and am open for input. Generally (I may have missed this method), I've been writing any information specific to this implementation and then inheriting the docs below that. I've also considered using the @see annotation to just refer to the original type. The difficulty there is that I suspect I will then have to add javadocs for each of the parameters all over again to satisfy CI, and that feels like a lot of copying/pasting and error prone. Then again, including all the docs by just inheriting is going to include a lot of the docs that are vague, and even if I resolve those questions first, it's sort of weird to include the whole description.", "author": "rickle-msft", "createdAt": "2020-01-16T19:51:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTAyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2MTgyMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r369161820", "bodyText": "That strategy makes sense to me, document when there is implementation that differs from a potential expectation of a file system, but in the cases where the implementation isn't different or doesn't exist use the inherited documentation.\nThis method wasn't missed, just was the first one in the file so I marked the comment on it.", "author": "alzimmermsft", "createdAt": "2020-01-21T18:14:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTAyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTg2Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367559862", "bodyText": "Could kill two birds with one stone here and use create with passing ETag not equals * and catch the exception and ignore it if the returned error is ContainerAlreadyExists. This would result in an existing container making one call as it would now but in the case it doesn't exist we cut the network calls in half from two to one.", "author": "alzimmermsft", "createdAt": "2020-01-16T17:44:57Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileStore.java", "diffHunk": "@@ -0,0 +1,120 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.attribute.FileStoreAttributeView;\n+import java.util.Objects;\n+\n+/**\n+ * An {@code AzureFileStore} is backed by an Azure Blob Storage container.\n+ * \n+ * {@inheritDoc}\n+ */\n+public final class AzureFileStore extends FileStore {\n+    private final AzureFileSystem parentFileSystem;\n+    private final BlobContainerClient containerClient;\n+\n+    AzureFileStore(AzureFileSystem parentFileSystem, String containerName) throws IOException {\n+        // A FileStore should only ever be created by a FileSystem.\n+        if (Objects.isNull(parentFileSystem)) {\n+            throw new IllegalStateException(\"AzureFileStore cannot be instantiated without a parent FileSystem\");\n+        }\n+        this.parentFileSystem = parentFileSystem;\n+        this.containerClient = this.parentFileSystem.getBlobServiceClient().getBlobContainerClient(containerName);\n+\n+        try {\n+            // This also serves as our connection check.\n+            if (!this.containerClient.exists()) {\n+                this.containerClient.create();", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxODE2Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367618167", "bodyText": "That's true. If the response code is a 412, it means the container is there and we authenticated, so the connection should be fine.", "author": "rickle-msft", "createdAt": "2020-01-16T19:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTg2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzY3OTU3OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367679579", "bodyText": "Just kidding. There are no access conditions on create container.", "author": "rickle-msft", "createdAt": "2020-01-16T22:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1OTg2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2MTk3NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367561975", "bodyText": "Should config be Map<String, Object>?", "author": "alzimmermsft", "createdAt": "2020-01-16T17:49:34Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.\n+\n+    public static final String AZURE_STORAGE_FILE_STORES = \"AzureStorageFileStores\";\n+\n+    private static final String AZURE_STORAGE_ENDPOINT_TEMPLATE = \"%s://%s.blob.core.windows.net\";\n+\n+    private final AzureFileSystemProvider parentFileSystemProvider;\n+    private final BlobServiceClient blobServiceClient;\n+    private final Integer blockSize;\n+    private final Integer downloadResumeRetries;\n+    private final Map<String, FileStore> fileStores;\n+    private boolean closed;\n+\n+    AzureFileSystem(AzureFileSystemProvider parentFileSystemProvider, String accountName, Map<String, ?> config)", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYxODczMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367618732", "bodyText": "This is inherited from the abstract type. I think it more or less ends up being the same effect as just ? means pretty much anything inheriting from Object.", "author": "rickle-msft", "createdAt": "2020-01-16T19:54:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2MTk3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2NDgwNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367564806", "bodyText": "Should add Javadocs here explaining the expected type for each configuration value, generally they should be straightforward but it would make it less complicated from a consumers perspective.\nAnother interesting option would be creating a generic key class, such as AZURE_STORAGE_ACCOUNT_KEY = KeyClass<String> where the T for the key class would indicate and bind the expected configuration type.", "author": "alzimmermsft", "createdAt": "2020-01-16T17:55:30Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMDk1MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367620950", "bodyText": "Good point. I forgot these were public and needed docs :)\nThat is an interesting suggestion. I will have to think about it!", "author": "rickle-msft", "createdAt": "2020-01-16T19:59:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2NDgwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2NzQwMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367567403", "bodyText": "This should use BlobServiceClientBuilder.getDefaultHttpLopOptions() as the base before setting the log level, this will continue to maintain proper query string and header logging. Right now this would wipe out all Storage specific headers and query string parameters from being logged.\nFuture enhancement would be adding two additional configurations that would set the loggable query string parameters and header names.", "author": "alzimmermsft", "createdAt": "2020-01-16T18:01:14Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.\n+\n+    public static final String AZURE_STORAGE_FILE_STORES = \"AzureStorageFileStores\";\n+\n+    private static final String AZURE_STORAGE_ENDPOINT_TEMPLATE = \"%s://%s.blob.core.windows.net\";\n+\n+    private final AzureFileSystemProvider parentFileSystemProvider;\n+    private final BlobServiceClient blobServiceClient;\n+    private final Integer blockSize;\n+    private final Integer downloadResumeRetries;\n+    private final Map<String, FileStore> fileStores;\n+    private boolean closed;\n+\n+    AzureFileSystem(AzureFileSystemProvider parentFileSystemProvider, String accountName, Map<String, ?> config)\n+            throws IOException {\n+        // A FileSystem should only ever be instantiated by a provider.\n+        if (Objects.isNull(parentFileSystemProvider)) {\n+            throw new IllegalArgumentException(\"AzureFileSystem cannot be instantiated without a parent \" +\n+                \"FileSystemProvider\");\n+        }\n+        this.parentFileSystemProvider = parentFileSystemProvider;\n+\n+        // Read configurations and build client.\n+        try {\n+            this.blobServiceClient = this.buildBlobServiceClient(accountName, config);\n+            this.blockSize = (Integer) config.get(AZURE_STORAGE_BLOCK_SIZE);\n+            this.downloadResumeRetries = (Integer) config.get(AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES);\n+        } catch (Exception e) {\n+            throw new IllegalArgumentException(\"There was an error parsing the configurations map. Please ensure all\" +\n+                \"fields are set to a legal value of the correct type.\");\n+        }\n+\n+        // Initialize and ensure access to FileStores.\n+        try {\n+            this.fileStores = this.initializeFileStores(config);\n+        } catch (IOException e) {\n+            throw new IOException(\"Initializing FileStores failed. FileSystem could not be opened.\", e);\n+        }\n+\n+        this.closed = false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public FileSystemProvider provider() {\n+        return this.parentFileSystemProvider;\n+    }\n+\n+    /**\n+     * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+     * terminate naturally after the file system is closed, though no further operations may be started after the\n+     * parent file system is closed.\n+     *\n+     * Once closed, a file system with the same identifier as the one closed may be re-opened.\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public void close() throws IOException {\n+        this.closed = true;\n+        this.parentFileSystemProvider.closeFileSystem(this.getFileSystemName());\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean isOpen() {\n+        return !this.closed;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public boolean isReadOnly() {\n+        return false;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public String getSeparator() {\n+        return \"/\";\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Iterable<Path> getRootDirectories() {\n+        return null;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Iterable<FileStore> getFileStores() {\n+        return\n+            this.fileStores.values();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Set<String> supportedFileAttributeViews() {\n+        return null;\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public Path getPath(String s, String... strings) {\n+        return new AzurePath(this, s, strings);\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public PathMatcher getPathMatcher(String s) {\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public UserPrincipalLookupService getUserPrincipalLookupService() {\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    /**\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public WatchService newWatchService() throws IOException {\n+        throw new UnsupportedOperationException();\n+    }\n+\n+    String getFileSystemName() {\n+        return this.blobServiceClient.getAccountName();\n+    }\n+\n+    BlobServiceClient getBlobServiceClient() {\n+        return this.blobServiceClient;\n+    }\n+\n+    private BlobServiceClient buildBlobServiceClient(String accountName, Map<String,?> config) {\n+        // Build the endpoint.\n+        String scheme = !config.containsKey(AZURE_STORAGE_USE_HTTPS)\n+                || (Boolean) config.get(AZURE_STORAGE_USE_HTTPS)\n+                ? \"https\" : \"http\";\n+        BlobServiceClientBuilder builder = new BlobServiceClientBuilder()\n+                .endpoint(String.format(AZURE_STORAGE_ENDPOINT_TEMPLATE, scheme, accountName));\n+\n+        // Set the credentials.\n+        if (config.containsKey(AZURE_STORAGE_ACCOUNT_KEY)) {\n+            builder.credential(new StorageSharedKeyCredential(accountName,\n+                    (String)config.get(AZURE_STORAGE_ACCOUNT_KEY)));\n+        }\n+        else if (config.containsKey(AZURE_STORAGE_SAS_TOKEN)) {\n+            builder.sasToken((String) config.get(AZURE_STORAGE_SAS_TOKEN));\n+        }\n+        else {\n+            throw new IllegalArgumentException(String.format(\"No credentials were provided. Please specify one of the\" +\n+                    \" following when constructing an AzureFileSystem: %s, %s.\", AZURE_STORAGE_ACCOUNT_KEY,\n+                    AZURE_STORAGE_SAS_TOKEN));\n+        }\n+\n+        // Configure options and client.\n+        builder.httpLogOptions(new HttpLogOptions()\n+            .setLogLevel((HttpLogDetailLevel)config.get(AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL)));", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMTI3Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367621273", "bodyText": "Thanks for catching this.\nYea I felt like those parameters were a bit overkill for an initial release and that it would be easy to add them later.", "author": "rickle-msft", "createdAt": "2020-01-16T20:00:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2NzQwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2MzAyMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r369163022", "bodyText": "Agreed on the parameters not being needed during the initial preview.", "author": "alzimmermsft", "createdAt": "2020-01-21T18:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2NzQwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2Nzg5OA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367567898", "bodyText": "Do we want to leave this undocumented? I think allowing a customer to perform as many options as when building a general client is best.", "author": "alzimmermsft", "createdAt": "2020-01-16T18:02:22Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystem.java", "diffHunk": "@@ -0,0 +1,259 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.storage.blob.nio;\n+\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.policy.HttpLogDetailLevel;\n+import com.azure.core.http.policy.HttpLogOptions;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import com.azure.storage.common.policy.RequestRetryOptions;\n+import com.azure.storage.common.policy.RetryPolicyType;\n+\n+import java.io.IOException;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Path;\n+import java.nio.file.PathMatcher;\n+import java.nio.file.WatchService;\n+import java.nio.file.attribute.UserPrincipalLookupService;\n+import java.nio.file.spi.FileSystemProvider;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * In the hierarchy of this file system, an {@code AzureFileSystem} corresponds to an Azure Blob Storage account. A\n+ * file store is represented by a container in the storage account. Each container has one root directory.\n+ *\n+ * Closing the file system will not block on outstanding operations. Any operations in progress will be allowed to\n+ * terminate naturally after the file system is closed, though no further operations may be started after the parent\n+ * file system is closed.\n+ * {@inheritDoc}\n+ */\n+public final class AzureFileSystem extends FileSystem {\n+    // Configuration constants for blob clients.\n+    public static final String AZURE_STORAGE_ACCOUNT_KEY = \"AzureStorageAccountKey\";\n+    public static final String AZURE_STORAGE_SAS_TOKEN = \"AzureStorageSasToken\";\n+    public static final String AZURE_STORAGE_HTTP_LOG_DETAIL_LEVEL = \"AzureStorageHttpLogDetailLevel\";\n+    public static final String AZURE_STORAGE_MAX_TRIES = \"AzureStorageMaxTries\";\n+    public static final String AZURE_STORAGE_TRY_TIMEOUT = \"AzureStorageTryTimeout\";\n+    public static final String AZURE_STORAGE_RETRY_DELAY_IN_MS = \"AzureStorageRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_MAX_RETRY_DELAY_IN_MS = \"AzureStorageMaxRetryDelayInMs\";\n+    public static final String AZURE_STORAGE_RETRY_POLICY_TYPE = \"AzureStorageRetryPolicyType\";\n+    public static final String AZURE_STORAGE_SECONDARY_HOST = \"AzureStorageSecondaryHost\";\n+    public static final String AZURE_STORAGE_BLOCK_SIZE = \"AzureStorageBlockSize\";\n+    public static final String AZURE_STORAGE_DOWNLOAD_RESUME_RETRIES = \"AzureStorageDownloadResumeRetries\";\n+    public static final String AZURE_STORAGE_USE_HTTPS = \"AzureStorageUseHttps\";\n+    public static final String AZURE_STORAGE_HTTP_CLIENT = \"AzureStorageHttpClient\"; // undocumented; for test.", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMjIwNw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367622207", "bodyText": "I don't feel strongly about leaving it undocumented. The reason I didn't add more full support for it was because I wasn't sure how deep to go into configuring the client for them and I just wanted something for testing more immediately. Should we just accept parameters for the proxy configs and the kind of client they want? Or should we just accept a whole preconfigured client? The former requires lots of options. The latter requires more knowledge from the customer on the underlying client which isn't good.", "author": "rickle-msft", "createdAt": "2020-01-16T20:02:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2Nzg5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE2MDk0NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r369160944", "bodyText": "For the initial preview I think leaving this simpler, the option where a pre-configured HttpClient is the only option available, would be the better option. The latter would require a lot of knowledge of the configuration options available and may cover a smaller group than allowing an overarching pre-configured client.", "author": "alzimmermsft", "createdAt": "2020-01-21T18:12:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2Nzg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU2OTQ0Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367569447", "bodyText": "This could be made final, the object reference never changes in this class", "author": "alzimmermsft", "createdAt": "2020-01-16T18:06:04Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -3,9 +3,299 @@\n \n package com.azure.storage.blob.nio;\n \n+import com.azure.core.util.CoreUtils;\n+import reactor.core.publisher.Flux;\n+import reactor.core.publisher.Mono;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.nio.channels.SeekableByteChannel;\n+import java.nio.file.AccessMode;\n+import java.nio.file.CopyOption;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystemAlreadyExistsException;\n+import java.nio.file.FileSystemNotFoundException;\n+import java.nio.file.LinkOption;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n /**\n- * Empty class.\n+ * The {@code AzureFileSystemProvider} is Azure Storage's implementation of the nio interface on top of Azure Blob\n+ * Storage.\n+ * <p>\n+ * Particular care should be taken when working with a remote storage service. This implementation makes no guarantees\n+ * on behavior or state should other processes operate on the same data concurrently; file systems from this provider\n+ * will assume they have exclusive access to their data and will behave without regard for potential of interfering\n+ * applications. Moreover, remote file stores introduce higher latencies. Therefore, particular care must be taken when\n+ * managing concurrency: race conditions are more likely to manifest and network failures occur more frequently than\n+ * disk failures. These and other such distributed application scenarios must be considered when working with this file\n+ * system. While the {@code AzureFileSystem} will ensure it takes appropriate steps towards robustness and reliability,\n+ * the application developer must design around these failure scenarios and have fallback and retry options available.\n+ * <p>\n+ * The Azure Blob Storage service backing these APIs is not a true FileSystem, nor is it the goal of this implementation\n+ * to force Azure Blob Storage to act like a full-fledged file system. Some APIs and scenarios will remain unsupported\n+ * indefinitely until they may be sensibly implemented. Other APIs may experience lower performance than is expected\n+ * because of the number of network requests needed to ensure correctness.\n+ * <p>\n+ * The scheme for this provider is {@code \"azb\"}, and the format of the URI to identify an {@code AzureFileSystem} is\n+ * {@code \"azb://?account=&lt;accountName&gt;\"}. The name of the Storage account is used to uniquely identify the file\n+ * system.\n+ * <p>\n+ * An {@link AzureFileSystem} is backed by an account. An {@link AzureFileStore} is backed by a container. Any number of\n+ * containers may be specified as file stores upon creation of the file system. When a file system is created,\n+ * it will try to retrieve the properties of each container to ensure connection to the account. If any of the\n+ * containers does not exist, it will be created. Failure to access or create containers as necessary will result in\n+ * an exception and failure to create the file system. Any data existing in the containers will be preserved and\n+ * accessible via the file system, though customers should be aware that it must be in a format understandable by\n+ * the types in this package or behavior will be undefined.\n+ * <p>\n+ * {@link #newFileSystem(URI, Map)} will check for the following keys in the configuration map and expect the named\n+ * types. Any entries not listed here will be ignored. Note that {@link AzureFileSystem} has public constants defined\n+ * for each of the keys for convenience.\n+ * <ul>\n+ *     <li>{@code AzureStorageAccountKey:}{@link String}</li>\n+ *     <li>{@code AzureStorageSasToken:}{@link String}</li>\n+ *     <li>{@code AzureStorageHttpLogDetailLevel:}{@link com.azure.core.http.policy.HttpLogDetailLevel}</li>\n+ *     <li>{@code AzureStorageMaxTries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageTryTimeout:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageMaxRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageRetryPolicyType:}{@link com.azure.storage.common.policy.RetryPolicyType}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link String}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageBlockSize:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageDownloadResumeRetries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageUseHttps:}{@link Boolean}</li>\n+ *     <li>{@code AzureStorageFileStores:}{@link Iterable<String>}</li>\n+ * </ul>\n+ * <p>\n+ * Either an account key or a sas token must be specified. If both are provided, the account key will be preferred. If\n+ * a sas token is specified, the customer must take care that it has appropriate permissions to perform the actions\n+ * demanded of the file system in a given workflow, including the initial connection check specified above. Furthermore,\n+ * it must have an expiry time that lasts at least until the file system is closed as there is no token refresh offered\n+ * at this time. The same token will be applied to all containers.\n+ * <p>\n+ * An iterable of file stores must also be provided; each entry should simply be the name of a container. All other\n+ * values listed are used to configure the underlying {@link com.azure.storage.blob.BlobServiceClient}. Please refer to\n+ * that type for more information on these values.\n+ *\n+ * @see FileSystemProvider\n  */\n-public class AzureFileSystemProvider  {\n+public final class AzureFileSystemProvider extends FileSystemProvider {\n+    // TODO: Add logger\n+    private static final String ACCOUNT_QUERY_KEY = \"account\";\n+\n+    private ConcurrentMap<String, FileSystem> openFileSystems;", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3MDA5NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367570094", "bodyText": "Should we add the already existing FileSystem name into the exception?", "author": "alzimmermsft", "createdAt": "2020-01-16T18:07:34Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -3,9 +3,299 @@\n \n package com.azure.storage.blob.nio;\n \n+import com.azure.core.util.CoreUtils;\n+import reactor.core.publisher.Flux;\n+import reactor.core.publisher.Mono;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.nio.channels.SeekableByteChannel;\n+import java.nio.file.AccessMode;\n+import java.nio.file.CopyOption;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystemAlreadyExistsException;\n+import java.nio.file.FileSystemNotFoundException;\n+import java.nio.file.LinkOption;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n /**\n- * Empty class.\n+ * The {@code AzureFileSystemProvider} is Azure Storage's implementation of the nio interface on top of Azure Blob\n+ * Storage.\n+ * <p>\n+ * Particular care should be taken when working with a remote storage service. This implementation makes no guarantees\n+ * on behavior or state should other processes operate on the same data concurrently; file systems from this provider\n+ * will assume they have exclusive access to their data and will behave without regard for potential of interfering\n+ * applications. Moreover, remote file stores introduce higher latencies. Therefore, particular care must be taken when\n+ * managing concurrency: race conditions are more likely to manifest and network failures occur more frequently than\n+ * disk failures. These and other such distributed application scenarios must be considered when working with this file\n+ * system. While the {@code AzureFileSystem} will ensure it takes appropriate steps towards robustness and reliability,\n+ * the application developer must design around these failure scenarios and have fallback and retry options available.\n+ * <p>\n+ * The Azure Blob Storage service backing these APIs is not a true FileSystem, nor is it the goal of this implementation\n+ * to force Azure Blob Storage to act like a full-fledged file system. Some APIs and scenarios will remain unsupported\n+ * indefinitely until they may be sensibly implemented. Other APIs may experience lower performance than is expected\n+ * because of the number of network requests needed to ensure correctness.\n+ * <p>\n+ * The scheme for this provider is {@code \"azb\"}, and the format of the URI to identify an {@code AzureFileSystem} is\n+ * {@code \"azb://?account=&lt;accountName&gt;\"}. The name of the Storage account is used to uniquely identify the file\n+ * system.\n+ * <p>\n+ * An {@link AzureFileSystem} is backed by an account. An {@link AzureFileStore} is backed by a container. Any number of\n+ * containers may be specified as file stores upon creation of the file system. When a file system is created,\n+ * it will try to retrieve the properties of each container to ensure connection to the account. If any of the\n+ * containers does not exist, it will be created. Failure to access or create containers as necessary will result in\n+ * an exception and failure to create the file system. Any data existing in the containers will be preserved and\n+ * accessible via the file system, though customers should be aware that it must be in a format understandable by\n+ * the types in this package or behavior will be undefined.\n+ * <p>\n+ * {@link #newFileSystem(URI, Map)} will check for the following keys in the configuration map and expect the named\n+ * types. Any entries not listed here will be ignored. Note that {@link AzureFileSystem} has public constants defined\n+ * for each of the keys for convenience.\n+ * <ul>\n+ *     <li>{@code AzureStorageAccountKey:}{@link String}</li>\n+ *     <li>{@code AzureStorageSasToken:}{@link String}</li>\n+ *     <li>{@code AzureStorageHttpLogDetailLevel:}{@link com.azure.core.http.policy.HttpLogDetailLevel}</li>\n+ *     <li>{@code AzureStorageMaxTries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageTryTimeout:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageMaxRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageRetryPolicyType:}{@link com.azure.storage.common.policy.RetryPolicyType}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link String}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageBlockSize:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageDownloadResumeRetries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageUseHttps:}{@link Boolean}</li>\n+ *     <li>{@code AzureStorageFileStores:}{@link Iterable<String>}</li>\n+ * </ul>\n+ * <p>\n+ * Either an account key or a sas token must be specified. If both are provided, the account key will be preferred. If\n+ * a sas token is specified, the customer must take care that it has appropriate permissions to perform the actions\n+ * demanded of the file system in a given workflow, including the initial connection check specified above. Furthermore,\n+ * it must have an expiry time that lasts at least until the file system is closed as there is no token refresh offered\n+ * at this time. The same token will be applied to all containers.\n+ * <p>\n+ * An iterable of file stores must also be provided; each entry should simply be the name of a container. All other\n+ * values listed are used to configure the underlying {@link com.azure.storage.blob.BlobServiceClient}. Please refer to\n+ * that type for more information on these values.\n+ *\n+ * @see FileSystemProvider\n  */\n-public class AzureFileSystemProvider  {\n+public final class AzureFileSystemProvider extends FileSystemProvider {\n+    // TODO: Add logger\n+    private static final String ACCOUNT_QUERY_KEY = \"account\";\n+\n+    private ConcurrentMap<String, FileSystem> openFileSystems;\n+\n+    // Specs require a public zero argument constructor.\n+\n+    /**\n+     * Creates an AzureFileSystemProvider.\n+     */\n+    public AzureFileSystemProvider() {\n+        this.openFileSystems = new ConcurrentHashMap<>();\n+    }\n+\n+    /**\n+     * Returns {@code \"azb\".}\n+     */\n+    @Override\n+    public String getScheme() {\n+        return \"azb\";\n+    }\n+\n+    /**\n+     * The format of a {@code URI} identifying a file system is {@code \"azb://?account=&lt;accountName&gt;\"}.\n+     * <p>\n+     * Once closed, a file system with the same identifier may be reopened.\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public FileSystem newFileSystem(URI uri, Map<String, ?> config) throws IOException {\n+        String accountName = extractAccountName(uri);\n+\n+        if (this.openFileSystems.containsKey(accountName)) {\n+            throw new FileSystemAlreadyExistsException();", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMjQzMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367622432", "bodyText": "Probably a good idea. I'll double check the docs, too.", "author": "rickle-msft", "createdAt": "2020-01-16T20:02:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3MDA5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3MDQ2MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367570460", "bodyText": "Should the name of the FileSystem be included in this message? Would help troubleshooting issues.", "author": "alzimmermsft", "createdAt": "2020-01-16T18:08:29Z", "path": "sdk/storage/azure-storage-blob-nio/src/main/java/com/azure/storage/blob/nio/AzureFileSystemProvider.java", "diffHunk": "@@ -3,9 +3,299 @@\n \n package com.azure.storage.blob.nio;\n \n+import com.azure.core.util.CoreUtils;\n+import reactor.core.publisher.Flux;\n+import reactor.core.publisher.Mono;\n+\n+import java.io.IOException;\n+import java.net.URI;\n+import java.nio.channels.SeekableByteChannel;\n+import java.nio.file.AccessMode;\n+import java.nio.file.CopyOption;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.FileSystemAlreadyExistsException;\n+import java.nio.file.FileSystemNotFoundException;\n+import java.nio.file.LinkOption;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.BasicFileAttributes;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.attribute.FileAttributeView;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n /**\n- * Empty class.\n+ * The {@code AzureFileSystemProvider} is Azure Storage's implementation of the nio interface on top of Azure Blob\n+ * Storage.\n+ * <p>\n+ * Particular care should be taken when working with a remote storage service. This implementation makes no guarantees\n+ * on behavior or state should other processes operate on the same data concurrently; file systems from this provider\n+ * will assume they have exclusive access to their data and will behave without regard for potential of interfering\n+ * applications. Moreover, remote file stores introduce higher latencies. Therefore, particular care must be taken when\n+ * managing concurrency: race conditions are more likely to manifest and network failures occur more frequently than\n+ * disk failures. These and other such distributed application scenarios must be considered when working with this file\n+ * system. While the {@code AzureFileSystem} will ensure it takes appropriate steps towards robustness and reliability,\n+ * the application developer must design around these failure scenarios and have fallback and retry options available.\n+ * <p>\n+ * The Azure Blob Storage service backing these APIs is not a true FileSystem, nor is it the goal of this implementation\n+ * to force Azure Blob Storage to act like a full-fledged file system. Some APIs and scenarios will remain unsupported\n+ * indefinitely until they may be sensibly implemented. Other APIs may experience lower performance than is expected\n+ * because of the number of network requests needed to ensure correctness.\n+ * <p>\n+ * The scheme for this provider is {@code \"azb\"}, and the format of the URI to identify an {@code AzureFileSystem} is\n+ * {@code \"azb://?account=&lt;accountName&gt;\"}. The name of the Storage account is used to uniquely identify the file\n+ * system.\n+ * <p>\n+ * An {@link AzureFileSystem} is backed by an account. An {@link AzureFileStore} is backed by a container. Any number of\n+ * containers may be specified as file stores upon creation of the file system. When a file system is created,\n+ * it will try to retrieve the properties of each container to ensure connection to the account. If any of the\n+ * containers does not exist, it will be created. Failure to access or create containers as necessary will result in\n+ * an exception and failure to create the file system. Any data existing in the containers will be preserved and\n+ * accessible via the file system, though customers should be aware that it must be in a format understandable by\n+ * the types in this package or behavior will be undefined.\n+ * <p>\n+ * {@link #newFileSystem(URI, Map)} will check for the following keys in the configuration map and expect the named\n+ * types. Any entries not listed here will be ignored. Note that {@link AzureFileSystem} has public constants defined\n+ * for each of the keys for convenience.\n+ * <ul>\n+ *     <li>{@code AzureStorageAccountKey:}{@link String}</li>\n+ *     <li>{@code AzureStorageSasToken:}{@link String}</li>\n+ *     <li>{@code AzureStorageHttpLogDetailLevel:}{@link com.azure.core.http.policy.HttpLogDetailLevel}</li>\n+ *     <li>{@code AzureStorageMaxTries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageTryTimeout:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageMaxRetryDelayInMs:}{@link Long}</li>\n+ *     <li>{@code AzureStorageRetryPolicyType:}{@link com.azure.storage.common.policy.RetryPolicyType}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link String}</li>\n+ *     <li>{@code AzureStorageSecondaryHost:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageBlockSize:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageDownloadResumeRetries:}{@link Integer}</li>\n+ *     <li>{@code AzureStorageUseHttps:}{@link Boolean}</li>\n+ *     <li>{@code AzureStorageFileStores:}{@link Iterable<String>}</li>\n+ * </ul>\n+ * <p>\n+ * Either an account key or a sas token must be specified. If both are provided, the account key will be preferred. If\n+ * a sas token is specified, the customer must take care that it has appropriate permissions to perform the actions\n+ * demanded of the file system in a given workflow, including the initial connection check specified above. Furthermore,\n+ * it must have an expiry time that lasts at least until the file system is closed as there is no token refresh offered\n+ * at this time. The same token will be applied to all containers.\n+ * <p>\n+ * An iterable of file stores must also be provided; each entry should simply be the name of a container. All other\n+ * values listed are used to configure the underlying {@link com.azure.storage.blob.BlobServiceClient}. Please refer to\n+ * that type for more information on these values.\n+ *\n+ * @see FileSystemProvider\n  */\n-public class AzureFileSystemProvider  {\n+public final class AzureFileSystemProvider extends FileSystemProvider {\n+    // TODO: Add logger\n+    private static final String ACCOUNT_QUERY_KEY = \"account\";\n+\n+    private ConcurrentMap<String, FileSystem> openFileSystems;\n+\n+    // Specs require a public zero argument constructor.\n+\n+    /**\n+     * Creates an AzureFileSystemProvider.\n+     */\n+    public AzureFileSystemProvider() {\n+        this.openFileSystems = new ConcurrentHashMap<>();\n+    }\n+\n+    /**\n+     * Returns {@code \"azb\".}\n+     */\n+    @Override\n+    public String getScheme() {\n+        return \"azb\";\n+    }\n+\n+    /**\n+     * The format of a {@code URI} identifying a file system is {@code \"azb://?account=&lt;accountName&gt;\"}.\n+     * <p>\n+     * Once closed, a file system with the same identifier may be reopened.\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public FileSystem newFileSystem(URI uri, Map<String, ?> config) throws IOException {\n+        String accountName = extractAccountName(uri);\n+\n+        if (this.openFileSystems.containsKey(accountName)) {\n+            throw new FileSystemAlreadyExistsException();\n+        }\n+\n+        AzureFileSystem afs = new AzureFileSystem(this, accountName, config);\n+        this.openFileSystems.put(accountName, afs);\n+\n+        return afs;\n+    }\n+\n+    /**\n+     * The format of a {@code URI} identifying an file system is {@code \"azb://?account=&lt;accountName&gt;\"}.\n+     * <p>\n+     * Trying to retrieve a closed file system will throw a {@link FileSystemNotFoundException}. Once closed, a\n+     * file system with the same identifier may be reopened.\n+     * {@inheritDoc}\n+     */\n+    @Override\n+    public FileSystem getFileSystem(URI uri) {\n+        String accountName = extractAccountName(uri);\n+        if (!this.openFileSystems.containsKey(accountName)) {\n+            throw new FileSystemNotFoundException();", "originalCommit": "677a6809a9a0278486525f30ded2a00b75094d9b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMjUyNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/7483#discussion_r367622526", "bodyText": "Same as above.", "author": "rickle-msft", "createdAt": "2020-01-16T20:02:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU3MDQ2MA=="}], "type": "inlineReview"}, {"oid": "837626ab41fe009a9b53b5783169c03b01312d08", "url": "https://github.com/Azure/azure-sdk-for-java/commit/837626ab41fe009a9b53b5783169c03b01312d08", "message": "Pr feedback", "committedDate": "2020-01-16T22:45:51Z", "type": "commit"}]}