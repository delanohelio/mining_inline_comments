{"pr_number": 11677, "pr_title": "Reset sync stream on retry", "pr_createdAt": "2020-06-02T18:27:25Z", "pr_url": "https://github.com/Azure/azure-sdk-for-java/pull/11677", "timeline": [{"oid": "ab6e4dec556eec73cc7def98dc2283cb57a5661f", "url": "https://github.com/Azure/azure-sdk-for-java/commit/ab6e4dec556eec73cc7def98dc2283cb57a5661f", "message": "Fixes to stream reset on retry. Needs cleanup and test", "committedDate": "2020-06-01T19:33:26Z", "type": "commit"}, {"oid": "b7b90b8c8cd8470a22cf0fadd3ac80147b929d2c", "url": "https://github.com/Azure/azure-sdk-for-java/commit/b7b90b8c8cd8470a22cf0fadd3ac80147b929d2c", "message": "Clean up and docs", "committedDate": "2020-06-01T23:23:31Z", "type": "commit"}, {"oid": "28df97939ea64aa7fdbfed9f8b47179a04ff44f4", "url": "https://github.com/Azure/azure-sdk-for-java/commit/28df97939ea64aa7fdbfed9f8b47179a04ff44f4", "message": "Cleanup and added test", "committedDate": "2020-06-02T18:14:31Z", "type": "commit"}, {"oid": "4f66bb4e972fefde9f5fd860bf63289d87604725", "url": "https://github.com/Azure/azure-sdk-for-java/commit/4f66bb4e972fefde9f5fd860bf63289d87604725", "message": "Merge remote-tracking branch 'upstream/master' into md5empty", "committedDate": "2020-06-02T18:24:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExMTcyOA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434111728", "bodyText": "Alternatively we can wrap the original Flux inside a Flux.defer and have\nfinal long[] currentTotalLength = new long[1];\ninside the defer which is some what more idiomatic I think.", "author": "anuchandy", "createdAt": "2020-06-02T19:03:47Z", "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/Utility.java", "diffHunk": "@@ -243,6 +243,18 @@ public static OffsetDateTime parseDate(String dateString) {\n                     throw LOGGER.logExceptionAsError(new RuntimeException(\"I/O errors occurs. Error details: \"\n                         + e.getMessage()));\n                 }\n+            })", "originalCommit": "4f66bb4e972fefde9f5fd860bf63289d87604725", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExMzgwMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434113802", "bodyText": "It will also match what we do in RestProxy. https://github.com/Azure/azure-sdk-for-java/blob/master/sdk/core/azure-core/src/main/java/com/azure/core/http/rest/RestProxy.java#L146", "author": "alzimmermsft", "createdAt": "2020-06-02T19:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExMTcyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE1MjYzNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434152634", "bodyText": "Good call. I was just working with what was already there, but I can clean that up.", "author": "rickle-msft", "createdAt": "2020-06-02T20:20:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExMTcyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExNjY2NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434116665", "bodyText": "Why do we mark Integer.MAX_VALUE? If we call reset after this the read position of the stream will be Integer.MAX_VALUE.", "author": "alzimmermsft", "createdAt": "2020-06-02T19:12:17Z", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/BlockBlobClient.java", "diffHunk": "@@ -306,6 +313,8 @@ public void stageBlock(String base64BlockId, InputStream data, long length) {\n     public Response<Void> stageBlockWithResponse(String base64BlockId, InputStream data, long length, byte[] contentMd5,\n         String leaseId, Duration timeout, Context context) {\n         Objects.requireNonNull(data);\n+        data.mark(Integer.MAX_VALUE);", "originalCommit": "4f66bb4e972fefde9f5fd860bf63289d87604725", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE1MjIwMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434152203", "bodyText": "The value passed to mark is the expiry limit. It says after reading N bytes invalidate the mark and throw on a call to reset. I don't think think we ever want our mark to expire. The mark is set at the position of the stream when mark is called, so the intention here is that we'll be resetting the same position that the stream was at when it was handed to us.", "author": "rickle-msft", "createdAt": "2020-06-02T20:19:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDExNjY2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEyMTEyNQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434121125", "bodyText": "Not all input streams support reset(). Some may throw IOException as specified in javadoc. Also, if the input stream does support resetting the position, this will reset to the last marked position that may be different from where the user wanted us to read the stream from.", "author": "srnagar", "createdAt": "2020-06-02T19:19:40Z", "path": "sdk/storage/azure-storage-common/src/main/java/com/azure/storage/common/Utility.java", "diffHunk": "@@ -243,6 +243,18 @@ public static OffsetDateTime parseDate(String dateString) {\n                     throw LOGGER.logExceptionAsError(new RuntimeException(\"I/O errors occurs. Error details: \"\n                         + e.getMessage()));\n                 }\n+            })\n+            .doFirst(() -> {\n+                /*\n+                If the request needs to be retried, the flux will be resubscribed to. The stream and counter must be\n+                reset in order to correctly return the same data again.\n+                 */\n+                currentTotalLength[0] = 0;\n+                try {\n+                    data.reset();", "originalCommit": "4f66bb4e972fefde9f5fd860bf63289d87604725", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE0MTc0MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434141740", "bodyText": "Yes.\nThe most common InputStream in the upload case, FileInputStream (FIS), does not support reset. Users might have to wrap FIS in BufferedInputStream (BIS) and give it as input to upload API. But BIS comes with extra allocation cost as worse as the size of the file.\nFew options I could think of are:\n\n\nIf we choose reset path, then make it clear in the java-doc that it is required to have \"reset to the start\" support for retry. Since FileInputStream is the most common and does not support reset out of the box, having a code sample/snippet showing how to create InputStream from FileChannel may help. FileChannel backing File does support setting read position.\n\n\nanother option is to take a Supplier<InputStream> which means, each subscription will invoke Supplier to get a new InputStream (hence read-position 0 for each instance), But this is a API change and needs to discuss and get approved, there are questions like the pattern for disposing of the obtained IS.", "author": "anuchandy", "createdAt": "2020-06-02T19:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEyMTEyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE1NzAyMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434157022", "bodyText": "Yes, I have added docs to all the apis which call this method indicating that the stream must be markable and giving guidance if it is not. I suggested opening a BlobOutputStream in those cases. I can also add a suggestion to consider wrapping it in a BufferedStream. I didn't add those javadocs to this method because it's in implementation, so those don't get generated anyway, but I can add that for our own internal purposes.\nBefore calling this method, the calling method should be calling mark to ensure it always resets to the same place, although I'm thinking I should actually move that call to be within this method.\nI'm not terribly concerned about FIS in this case because I think if customers are uploading file data they are going to be calling uploadFromFile.\nIt's also worth noting that requiring markability is consistent with the expectations we make on the fluxes passed in to the async equivalent--we require that those be replayable", "author": "rickle-msft", "createdAt": "2020-06-02T20:29:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEyMTEyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE2OTU2OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434169569", "bodyText": "Don't the async operations support non-replayable publishers? This javadoc says that the flux doesn't have to be replayable.", "author": "srnagar", "createdAt": "2020-06-02T20:54:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEyMTEyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDE5MDk3MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434190970", "bodyText": "Those are on the BlobClient, which does support non-replayable publishers for both async and sync. The analogues I'm referring to are on BlockBlobAsyncClient. e.g. stage block", "author": "rickle-msft", "createdAt": "2020-06-02T21:39:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDEyMTEyNQ=="}], "type": "inlineReview"}, {"oid": "d933cc11f893e28afd6da8305b29008a28f179a0", "url": "https://github.com/Azure/azure-sdk-for-java/commit/d933cc11f893e28afd6da8305b29008a28f179a0", "message": "Ci fixes", "committedDate": "2020-06-02T23:15:33Z", "type": "commit"}, {"oid": "5d5287dc682597227ad8e0b162e0470e95ca5dd2", "url": "https://github.com/Azure/azure-sdk-for-java/commit/5d5287dc682597227ad8e0b162e0470e95ca5dd2", "message": "Merge branch 'master' into md5empty", "committedDate": "2020-06-03T21:44:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDg5NjI3Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/11677#discussion_r434896273", "bodyText": "Could we enforce the mark supported by calling?\nhttps://docs.oracle.com/javase/7/docs/api/java/io/InputStream.html#markSupported()", "author": "gapra-msft", "createdAt": "2020-06-03T22:39:27Z", "path": "sdk/storage/azure-storage-blob/src/main/java/com/azure/storage/blob/specialized/AppendBlobClient.java", "diffHunk": "@@ -156,7 +156,8 @@ public AppendBlobItem create(boolean overwrite) {\n      *\n      * {@codesnippet com.azure.storage.blob.specialized.AppendBlobClient.appendBlock#InputStream-long}\n      *\n-     * @param data The data to write to the blob.\n+     * @param data The data to write to the blob. The data must be markable. This is in order to support retries. If", "originalCommit": "5d5287dc682597227ad8e0b162e0470e95ca5dd2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d9f2e6666411d986f1769d7a99a2be92b2558f13", "url": "https://github.com/Azure/azure-sdk-for-java/commit/d9f2e6666411d986f1769d7a99a2be92b2558f13", "message": "PR feedback", "committedDate": "2020-06-03T23:02:52Z", "type": "commit"}, {"oid": "6d7606ededa7c6767ff4d138b103f37fde5b03e5", "url": "https://github.com/Azure/azure-sdk-for-java/commit/6d7606ededa7c6767ff4d138b103f37fde5b03e5", "message": "Merge branch 'md5empty' of github.com:rickle-msft/azure-sdk-for-java into md5empty", "committedDate": "2020-06-03T23:03:10Z", "type": "commit"}, {"oid": "4d5e64fdf263ff590f02e23a2003019d0080267b", "url": "https://github.com/Azure/azure-sdk-for-java/commit/4d5e64fdf263ff590f02e23a2003019d0080267b", "message": "Ci", "committedDate": "2020-06-03T23:23:52Z", "type": "commit"}]}