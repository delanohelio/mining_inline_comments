{"pr_number": 1116, "pr_title": "issue #779 #1150 partitionize bulkexport JavaBatch Job & fix CWWKY0041W warnings", "pr_createdAt": "2020-05-18T20:01:00Z", "pr_url": "https://github.com/IBM/FHIR/pull/1116", "timeline": [{"oid": "1164de36597f809db74358970683dab3d1e3afa5", "url": "https://github.com/IBM/FHIR/commit/1164de36597f809db74358970683dab3d1e3afa5", "message": "Merge pull request #1075 from IBM/issue-#953\n\nIssue #953", "committedDate": "2020-05-12T14:46:05Z", "type": "commit"}, {"oid": "e94da7b85f47cbffa0a47e3497e2e876a45c6c71", "url": "https://github.com/IBM/FHIR/commit/e94da7b85f47cbffa0a47e3497e2e876a45c6c71", "message": "Merge pull request #1114 from IBM/issue-779\n\nIssue 779 - sync with master before PR bulkexport partition updates", "committedDate": "2020-05-18T15:55:15Z", "type": "commit"}, {"oid": "0694a550adac3efff2277ddeda6c51bb1c0014fd", "url": "https://github.com/IBM/FHIR/commit/0694a550adac3efff2277ddeda6c51bb1c0014fd", "message": "issue #779 partitionize bulkexport javabatch job\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-18T19:59:40Z", "type": "commit"}, {"oid": "17dab0f293a6af33394834dc60cc5e0e27ecedb2", "url": "https://github.com/IBM/FHIR/commit/17dab0f293a6af33394834dc60cc5e0e27ecedb2", "message": "issue #779 bulkexport results in job exit status and simple metrics\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-21T12:41:01Z", "type": "commit"}, {"oid": "4cfcdfa1cb9508e8df9acecf6085c6cc832fa57d", "url": "https://github.com/IBM/FHIR/commit/4cfcdfa1cb9508e8df9acecf6085c6cc832fa57d", "message": "issue #779 checkpoint algorithm updates\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-21T18:16:19Z", "type": "commit"}, {"oid": "c4a64643681f778b9ae7e49f5fa97a5b99edc598", "url": "https://github.com/IBM/FHIR/commit/c4a64643681f778b9ae7e49f5fa97a5b99edc598", "message": "issue #779 #1150 further refactor and fix CWWKY0041W warnings\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-26T12:57:06Z", "type": "commit"}, {"oid": "066c797643da029380943400aae495f9296c15da", "url": "https://github.com/IBM/FHIR/commit/066c797643da029380943400aae495f9296c15da", "message": "issue #1150 add cdi-api for fixing CWWKY0041\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-26T13:18:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNjg3OQ==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430416879", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @BatchProperty(name = Constants.COS_BUCKET_FILE_MAX_SZIE)\n          \n          \n            \n                @BatchProperty(name = Constants.COS_BUCKET_FILE_MAX_SIZE)", "author": "prb112", "createdAt": "2020-05-26T13:35:57Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/common/CheckPointAlgorithm.java", "diffHunk": "@@ -6,38 +6,45 @@\n \n package com.ibm.fhir.bulkexport.common;\n \n+import java.util.logging.Level;\n import java.util.logging.Logger;\n \n import javax.batch.api.BatchProperty;\n import javax.batch.api.chunk.CheckpointAlgorithm;\n-import javax.batch.runtime.context.JobContext;\n+import javax.batch.runtime.context.StepContext;\n+import javax.enterprise.context.Dependent;\n import javax.inject.Inject;\n \n import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.config.FHIRConfigHelper;\n+import com.ibm.fhir.config.FHIRConfiguration;\n \n /**\n  * Bulk export Chunk implementation - custom checkpoint algorithm.\n  *\n  */\n-\n+@Dependent\n public class CheckPointAlgorithm implements CheckpointAlgorithm {\n     private final static Logger logger = Logger.getLogger(CheckPointAlgorithm.class.getName());\n+    private int cosFileMaxResources = FHIRConfigHelper.getIntProperty(FHIRConfiguration.PROPERTY_BULKDATA_BATCHJOB_COSFILEMAXRESOURCES, Constants.DEFAULT_COSFILE_MAX_RESOURCESNUMBER);\n+    private int cosFileMaxSize = FHIRConfigHelper.getIntProperty(FHIRConfiguration.PROPERTY_BULKDATA_BATCHJOB_COSFILEMAXSIZE  , Constants.DEFAULT_COSFILE_MAX_SIZE);\n+\n     @Inject\n-    JobContext jobContext;\n+    StepContext stepCtx;\n \n     /**\n-     * The cos.pagesperobject.\n+     * The file resources number limit when exporting to multiple COS files.\n      */\n     @Inject\n-    @BatchProperty(name = \"cos.pagesperobject\")\n-    String pagesPerCosObject;\n+    @BatchProperty(name = Constants.COS_BUCKET_FILE_MAX_RESOURCES)\n+    String cosBucketFileMaxResources;\n \n     /**\n      * The file size limit when exporting to multiple COS files.\n      */\n     @Inject\n-    @BatchProperty(name = \"cos.bucket.maxfilesize\")\n-    String cosBucketMaxFileSize;\n+    @BatchProperty(name = Constants.COS_BUCKET_FILE_MAX_SZIE)", "originalCommit": "066c797643da029380943400aae495f9296c15da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQzNjY3NQ==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430436675", "bodyText": "ugly typo error, let me fix. :)", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNjg3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ0NzMzNw==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430447337", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:17:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNjg3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNzA3Ng==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430417076", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static final String COS_BUCKET_FILE_MAX_SZIE = \"cos.bucket.filemaxsize\";\n          \n          \n            \n                public static final String COS_BUCKET_FILE_MAX_SIZE = \"cos.bucket.filemaxsize\";", "author": "prb112", "createdAt": "2020-05-26T13:36:14Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkcommon/Constants.java", "diffHunk": "@@ -40,17 +40,26 @@\n     public static final String COS_LOCATION = \"cos.location\";\n     public static final String COS_BUCKET_NAME = \"cos.bucket.name\";\n     public static final String COS_IS_IBM_CREDENTIAL = \"cos.credential.ibm\";\n+    public static final String COS_BUCKET_FILE_MAX_SZIE = \"cos.bucket.filemaxsize\";", "originalCommit": "066c797643da029380943400aae495f9296c15da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQzNzUzMg==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430437532", "bodyText": "good catch", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:04:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNzA3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQ0NzQyNg==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430447426", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:17:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxNzA3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxODU0MA==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430418540", "bodyText": "protected?\nthis change from List is because each resourceType is split into separate executions?", "author": "prb112", "createdAt": "2020-05-26T13:38:24Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/patient/ChunkReader.java", "diffHunk": "@@ -41,23 +42,22 @@\n import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n-import com.ibm.fhir.search.compartment.CompartmentUtil;\n import com.ibm.fhir.search.context.FHIRSearchContext;\n import com.ibm.fhir.search.util.SearchUtil;\n \n /**\n  * Bulk patient export Chunk implementation - the Reader.\n  *\n  */\n+@Dependent\n public class ChunkReader extends AbstractItemReader {\n     private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n     protected int pageNum = 1;\n-    protected int indexOfCurrentResourceType = 0;\n     // Control the number of records to read in each \"item\".\n     protected int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n \n     protected FHIRPersistence fhirPersistence;\n-    protected List<String> resourceTypes;\n+    Class<? extends Resource> resourceType;", "originalCommit": "066c797643da029380943400aae495f9296c15da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQzODM2OA==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430438368", "bodyText": "yes, now each partition/chuck codes only need to process its own resouretype - one and only one resource type.", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:05:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQxODU0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQyMTUyMQ==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430421521", "bodyText": "this seems like a good thing to have a log.fine", "author": "prb112", "createdAt": "2020-05-26T13:42:44Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/system/ExportJobListener.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.system;\n+\n+import java.text.DecimalFormat;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.logging.Logger;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.listener.JobListener;\n+import javax.batch.operations.JobOperator;\n+import javax.batch.runtime.BatchRuntime;\n+import javax.batch.runtime.JobExecution;\n+import javax.batch.runtime.context.JobContext;\n+import javax.enterprise.context.Dependent;\n+import javax.inject.Inject;\n+\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+\n+@Dependent\n+public class ExportJobListener implements JobListener {\n+    private static final Logger logger = Logger.getLogger(ExportJobListener.class.getName());\n+\n+    long currentExecutionStartTimeInMS;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    @Inject\n+    @BatchProperty(name = Constants.IMPORT_FHIR_DATASOURCES)\n+    String dataSourcesInfo;\n+\n+    public ExportJobListener() {\n+        // do nothing\n+    }\n+\n+\n+    @Override\n+    public void afterJob() {\n+        long currentExecutionEndTimeInMS = TimeUnit.NANOSECONDS.toMillis(System.nanoTime());\n+\n+        // Used for generating response for all the import data resources.\n+        @SuppressWarnings(\"unchecked\")\n+        List<CheckPointUserData> partitionSummaries = (List<CheckPointUserData>)jobContext.getTransientUserData();\n+\n+        JobOperator jobOperator = BatchRuntime.getJobOperator();\n+        long totalJobExecutionMilliSeconds = 0;\n+        // The job can be started, stopped and then started again, so we need to add them all to get the whole job execution duration.\n+        for ( JobExecution jobExecution: jobOperator.getJobExecutions(jobOperator.getJobInstance(jobContext.getExecutionId()))) {\n+            // For current execution, jobExecution.getEndTime() is either null or with wrong value because the current execution is not\n+            // finished yet, so always use system time for both job execution start time and end time.\n+            if (jobExecution.getExecutionId()  == jobContext.getExecutionId()) {\n+                totalJobExecutionMilliSeconds += (currentExecutionEndTimeInMS - currentExecutionStartTimeInMS);\n+            } else {\n+                totalJobExecutionMilliSeconds += (jobExecution.getEndTime().getTime() - jobExecution.getStartTime().getTime());\n+            }\n+        }\n+\n+        // If the job is stopped before any partition is finished, then nothing to show.\n+        if (partitionSummaries == null) {\n+            return;\n+        }\n+\n+        double jobProcessingSeconds = totalJobExecutionMilliSeconds / 1000.0;\n+        jobProcessingSeconds = jobProcessingSeconds < 1 ? 1.0 : jobProcessingSeconds;\n+\n+        // log the simple metrics.\n+        logger.info(\" ---- Fhir resources exported in \" + jobProcessingSeconds + \"seconds ----\");\n+        logger.info(\"ResourceType \\t| Exported\");\n+        int totalExportedFhirResources = 0;\n+        List<String> resourceTypeSummaries = new ArrayList<>();\n+        for (CheckPointUserData partitionSummary : partitionSummaries) {\n+            logger.info(partitionSummary.getResourceTypeSummary() + \"\\t|\"\n+                  + partitionSummary.getTotalResourcesNum());\n+            resourceTypeSummaries.add(partitionSummary.getResourceTypeSummary());\n+            totalExportedFhirResources += partitionSummary.getTotalResourcesNum();\n+        }\n+\n+        logger.info(\" ---- Total: \" + totalExportedFhirResources", "originalCommit": "066c797643da029380943400aae495f9296c15da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQzOTI3Mg==", "url": "https://github.com/IBM/FHIR/pull/1116#discussion_r430439272", "bodyText": "this is the summary of the whole export job, so I used info instead of fine.", "author": "albertwang-ibm", "createdAt": "2020-05-26T14:06:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDQyMTUyMQ=="}], "type": "inlineReview"}, {"oid": "356ab6a372fe748746c03937f97d61a93a9a5bba", "url": "https://github.com/IBM/FHIR/commit/356ab6a372fe748746c03937f97d61a93a9a5bba", "message": "issue #779 adding fhir-server-config.json and updates per review\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-05-26T14:15:56Z", "type": "commit"}]}