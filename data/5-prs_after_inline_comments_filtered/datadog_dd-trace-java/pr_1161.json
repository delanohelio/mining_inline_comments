{"pr_number": 1161, "pr_title": "Split TraceConsumer into two different disruptors", "pr_createdAt": "2020-01-06T21:13:14Z", "pr_url": "https://github.com/DataDog/dd-trace-java/pull/1161", "timeline": [{"oid": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "url": "https://github.com/DataDog/dd-trace-java/commit/e3054cb6cfe645bd189417c5d3be479beec08ea1", "message": "Split TraceConsumer into two different disruptors\n\nFirst disruptor (TraceProcessingDisruptor) does processing, which is currently limited to serialization, but in the future can do other processing such as TraceInterceptor invocation.\nSecond disruptor (BatchWritingDisruptor) takes serialized traces and batches them into groups and flushes them periodically based on size and time.", "committedDate": "2020-01-06T22:32:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODE1OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363778158", "bodyText": "Yes, this is the direction of having per class Config objects.\nI think that's a good idea, but I'm not entirely sold on Lombok for this purpose.", "author": "dougqh", "createdAt": "2020-01-07T14:40:26Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -29,86 +24,65 @@\n  */\n @Slf4j\n public class DDAgentWriter implements Writer {\n-  private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n-  private static final int SENDER_QUEUE_SIZE = 16;\n-  private static final int FLUSH_PAYLOAD_DELAY = 1; // 1/second\n+  @Value\n+  @lombok.Builder\n+  public static class Spec {", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzgyNTk2Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363825962", "bodyText": "I like that Lombok removes a lot of boiler plate code, but I'm not sold on this specific implementation of this pattern.  Alternatively I think we could have the builder annotation on a constructor, but I liked this way of defining the default values.", "author": "tylerbenson", "createdAt": "2020-01-07T16:13:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODE1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDc2NzY3MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r364767670", "bodyText": "Yes, I like the idea of building a Config / Spec / Parameters object.\nAs for Lombok, it comes down to the specifics of what it makes.\nUltimately, I care more that we have a clean API for building things than I do about having to implement a little boilerplate.", "author": "dougqh", "createdAt": "2020-01-09T14:29:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODE1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODM0Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363778343", "bodyText": "Why are these public?", "author": "dougqh", "createdAt": "2020-01-07T14:40:51Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -29,86 +24,65 @@\n  */\n @Slf4j\n public class DDAgentWriter implements Writer {\n-  private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n-  private static final int SENDER_QUEUE_SIZE = 16;\n-  private static final int FLUSH_PAYLOAD_DELAY = 1; // 1/second\n+  @Value\n+  @lombok.Builder\n+  public static class Spec {\n+    @lombok.Builder.Default public String agentHost = DEFAULT_AGENT_HOST;\n+    @lombok.Builder.Default public int traceAgentPort = DEFAULT_TRACE_AGENT_PORT;\n+    @lombok.Builder.Default public String unixDomainSocket = DEFAULT_AGENT_UNIX_DOMAIN_SOCKET;\n+    @lombok.Builder.Default public int traceBufferSize = DISRUPTOR_BUFFER_SIZE;\n+    @lombok.Builder.Default public Monitor monitor = new Monitor.Noop();\n+    @lombok.Builder.Default public int flushFrequencySeconds = 1;\n+  }\n \n-  private static final ThreadFactory SCHEDULED_FLUSH_THREAD_FACTORY =\n-      new DaemonThreadFactory(\"dd-trace-writer\");\n+  private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n \n   private final DDAgentApi api;\n-  public final int flushFrequencySeconds;\n-  public final TraceSerializingDisruptor disruptor;\n+  public final TraceProcessingDisruptor traceProcessingDisruptor;", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODY2MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363778661", "bodyText": "I'd like to add a comment that explains how the publishing pipeline works.", "author": "dougqh", "createdAt": "2020-01-07T14:41:29Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -29,86 +24,65 @@\n  */\n @Slf4j\n public class DDAgentWriter implements Writer {", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjEwMjQyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366102427", "bodyText": "Done.  Let me know if this is clear enough.", "author": "tylerbenson", "createdAt": "2020-01-14T00:39:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3ODY2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3OTEyOA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363779128", "bodyText": "I think it would be fine to pass the Spec object done to the disruptors.", "author": "dougqh", "createdAt": "2020-01-07T14:42:28Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -29,86 +24,65 @@\n  */\n @Slf4j\n public class DDAgentWriter implements Writer {\n-  private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n-  private static final int SENDER_QUEUE_SIZE = 16;\n-  private static final int FLUSH_PAYLOAD_DELAY = 1; // 1/second\n+  @Value\n+  @lombok.Builder\n+  public static class Spec {\n+    @lombok.Builder.Default public String agentHost = DEFAULT_AGENT_HOST;\n+    @lombok.Builder.Default public int traceAgentPort = DEFAULT_TRACE_AGENT_PORT;\n+    @lombok.Builder.Default public String unixDomainSocket = DEFAULT_AGENT_UNIX_DOMAIN_SOCKET;\n+    @lombok.Builder.Default public int traceBufferSize = DISRUPTOR_BUFFER_SIZE;\n+    @lombok.Builder.Default public Monitor monitor = new Monitor.Noop();\n+    @lombok.Builder.Default public int flushFrequencySeconds = 1;\n+  }\n \n-  private static final ThreadFactory SCHEDULED_FLUSH_THREAD_FACTORY =\n-      new DaemonThreadFactory(\"dd-trace-writer\");\n+  private static final int DISRUPTOR_BUFFER_SIZE = 1024;\n \n   private final DDAgentApi api;\n-  public final int flushFrequencySeconds;\n-  public final TraceSerializingDisruptor disruptor;\n+  public final TraceProcessingDisruptor traceProcessingDisruptor;\n+  public final BatchWritingDisruptor batchWritingDisruptor;\n \n-  public final ScheduledExecutorService scheduledWriterExecutor;\n   private final AtomicInteger traceCount = new AtomicInteger(0);\n-  public final Phaser apiPhaser = new Phaser(); // Ensure API calls are completed when flushing;\n \n   public final Monitor monitor;\n \n   public DDAgentWriter() {\n-    this(\n-        new DDAgentApi(\n-            DEFAULT_AGENT_HOST, DEFAULT_TRACE_AGENT_PORT, DEFAULT_AGENT_UNIX_DOMAIN_SOCKET),\n-        new Monitor.Noop());\n+    this(Spec.builder().build());\n   }\n \n-  public DDAgentWriter(final DDAgentApi api, final Monitor monitor) {\n-    this(api, monitor, DISRUPTOR_BUFFER_SIZE, SENDER_QUEUE_SIZE, FLUSH_PAYLOAD_DELAY);\n-  }\n+  public DDAgentWriter(final Spec spec) {\n+    api = new DDAgentApi(spec.agentHost, spec.traceAgentPort, spec.unixDomainSocket);\n+    monitor = spec.monitor;\n \n-  /** Old signature (pre-Monitor) used in tests */\n-  private DDAgentWriter(final DDAgentApi api) {\n-    this(api, new Monitor.Noop());\n+    batchWritingDisruptor =", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAzNjg1Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366036856", "bodyText": "Currently not all of the DDAgentWriter constructors use the Spec.", "author": "tylerbenson", "createdAt": "2020-01-13T21:26:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3OTEyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4MjA0NA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363782044", "bodyText": "I'm not crazy about adding an extra executor for this.\nThe requesting flush on time out seen cleaner and lighter weight to me.", "author": "dougqh", "createdAt": "2020-01-07T14:48:01Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -0,0 +1,162 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventHandler;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+public class BatchWritingDisruptor extends AbstractDisruptor<byte[]> {\n+  private static final int FLUSH_PAYLOAD_BYTES = 5_000_000; // 5 MB\n+\n+  private final ScheduledExecutorService heartbeatExecutor =\n+      Executors.newScheduledThreadPool(1, new DaemonThreadFactory(\"dd-trace-heartbeat\"));\n+\n+  private final DisruptorEvent.HeartbeatTranslator<byte[]> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+\n+  public BatchWritingDisruptor(\n+      final int disruptorSize,\n+      final int flushFrequencySeconds,\n+      final DDAgentApi api,\n+      final Monitor monitor,\n+      final DDAgentWriter writer) {\n+    super(disruptorSize, new BatchWritingHandler(flushFrequencySeconds, api, monitor, writer));\n+\n+    if (0 < flushFrequencySeconds) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      final Runnable heartbeat =", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzgyNjY4OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363826689", "bodyText": "Not sure what you mean \"on time out\"?  if we don't have any events in the queue, the handler will never be called to trigger a flush.", "author": "tylerbenson", "createdAt": "2020-01-07T16:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4MjA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDc3MTgyMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r364771820", "bodyText": "If you look at the approach in the experimental branch that I did, it doesn't have a scheduled timer.\nInstead the sender thread does something akin to this pseudo-code...\nwhile ( !Thread.current().isInterrupted() ) {\ntry {\nDDApi.Request request = queue.poll(flushFrequencySecs, TimeUnit.SECONDS);\nsend(request);\n} catch ( TimeoutException e ) {\n// request flush\nflush();\n}\n}\nI prefer this because it is one fewer threads, but also because it is easier to have the sender back-off its schedule.", "author": "dougqh", "createdAt": "2020-01-09T14:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4MjA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjA1NDk1MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366054950", "bodyText": "To clarify, the heartbeat only ensures a minimum level of events to enable timely reporting in case no traces are sent in a given time window.  The actual sending frequency can be adjusted in scheduleNextFlush().", "author": "tylerbenson", "createdAt": "2020-01-13T22:08:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4MjA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4Mzc4Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363783783", "bodyText": "I think having a latch per batch is a big improvement in the flush semantics.", "author": "dougqh", "createdAt": "2020-01-07T14:51:18Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/DisruptorEvent.java", "diffHunk": "@@ -2,13 +2,19 @@\n \n import com.lmax.disruptor.EventFactory;\n import com.lmax.disruptor.EventTranslator;\n-import com.lmax.disruptor.EventTranslatorOneArg;\n-import datadog.opentracing.DDSpan;\n-import java.util.List;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import java.util.concurrent.CountDownLatch;\n \n class DisruptorEvent<T> {\n-  public volatile boolean shouldFlush = false;\n   public volatile T data = null;\n+  public volatile int representativeCount = 0;\n+  public volatile CountDownLatch flushLatch = null;", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzgyNzEwNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363827107", "bodyText": "Yes, I also like this much better than the previous phaser approach.", "author": "tylerbenson", "createdAt": "2020-01-07T16:15:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4Mzc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDc3MzA5Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r364773096", "bodyText": "A CountDownLatch might be overkill.  We don't really need to wait for all the flushers to arrive before unblocking the others, but I don't think it is a big deal.", "author": "dougqh", "createdAt": "2020-01-09T14:39:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4Mzc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAzODM1Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366038356", "bodyText": "What would you suggest using instead?", "author": "tylerbenson", "createdAt": "2020-01-13T21:29:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4Mzc4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NDE0Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363784146", "bodyText": "It seems to me that is still probably two separate classes -- one per disruptor, but admittedly, I haven't studied the code carefully.", "author": "dougqh", "createdAt": "2020-01-07T14:52:03Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/DisruptorEvent.java", "diffHunk": "@@ -2,13 +2,19 @@\n \n import com.lmax.disruptor.EventFactory;\n import com.lmax.disruptor.EventTranslator;\n-import com.lmax.disruptor.EventTranslatorOneArg;\n-import datadog.opentracing.DDSpan;\n-import java.util.List;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import java.util.concurrent.CountDownLatch;\n \n class DisruptorEvent<T> {", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjAzODg2Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366038862", "bodyText": "I think there's enough common code to warrant sharing this implementation along with the abstract disruptor class.", "author": "tylerbenson", "createdAt": "2020-01-13T21:30:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NDE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NDcxMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363784710", "bodyText": "Can these be package visible instead?", "author": "dougqh", "createdAt": "2020-01-07T14:53:14Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/DisruptorEvent.java", "diffHunk": "@@ -2,13 +2,19 @@\n \n import com.lmax.disruptor.EventFactory;\n import com.lmax.disruptor.EventTranslator;\n-import com.lmax.disruptor.EventTranslatorOneArg;\n-import datadog.opentracing.DDSpan;\n-import java.util.List;\n+import com.lmax.disruptor.EventTranslatorTwoArg;\n+import java.util.concurrent.CountDownLatch;\n \n class DisruptorEvent<T> {\n-  public volatile boolean shouldFlush = false;\n   public volatile T data = null;", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDc3MzkzNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r364773936", "bodyText": "Also, as discussed elsewhere, these don't need to be volatile.\nThe Sequence object of the Disruptor guarantees the necessary memory ordering.", "author": "dougqh", "createdAt": "2020-01-09T14:41:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NDcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NTMyMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363785321", "bodyText": "I think there's a bug here.  We shouldn't be calling onSerialize before we know if the publishing was successful.", "author": "dougqh", "createdAt": "2020-01-07T14:54:25Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -0,0 +1,88 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.lmax.disruptor.EventHandler;\n+import datadog.opentracing.DDSpan;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.List;\n+import java.util.concurrent.ThreadFactory;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+public class TraceProcessingDisruptor extends AbstractDisruptor<List<DDSpan>> {\n+\n+  public TraceProcessingDisruptor(\n+      final int disruptorSize,\n+      final DDAgentApi api,\n+      final BatchWritingDisruptor batchWritingDisruptor,\n+      final Monitor monitor,\n+      final DDAgentWriter writer) {\n+    // TODO: add config to enable control over serialization overhead.\n+    super(disruptorSize, new TraceSerializingHandler(api, batchWritingDisruptor, monitor, writer));\n+  }\n+\n+  @Override\n+  protected ThreadFactory getThreadFactory() {\n+    return new DaemonThreadFactory(\"dd-trace-processor\");\n+  }\n+\n+  @Override\n+  public boolean publish(final List<DDSpan> data, final int representativeCount) {\n+    return disruptor.getRingBuffer().tryPublishEvent(dataTranslator, data, representativeCount);\n+  }\n+\n+  // This class is threadsafe if we want to enable more processors.\n+  public static class TraceSerializingHandler\n+      implements EventHandler<DisruptorEvent<List<DDSpan>>> {\n+    private final DDAgentApi api;\n+    private final BatchWritingDisruptor batchWritingDisruptor;\n+    private final Monitor monitor;\n+    private final DDAgentWriter writer;\n+\n+    public TraceSerializingHandler(\n+        final DDAgentApi api,\n+        final BatchWritingDisruptor batchWritingDisruptor,\n+        final Monitor monitor,\n+        final DDAgentWriter writer) {\n+      this.api = api;\n+      this.batchWritingDisruptor = batchWritingDisruptor;\n+      this.monitor = monitor;\n+      this.writer = writer;\n+    }\n+\n+    @Override\n+    public void onEvent(\n+        final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n+      try {\n+        if (event.data != null) {\n+          try {\n+            final byte[] serializedTrace = api.serializeTrace(event.data);\n+            monitor.onSerialize(writer, event.data, serializedTrace);", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzgyODAyMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363828021", "bodyText": "I admit, I had a hard time understanding how to translate the monitor calls.  That aspect of this change warrants a thorough review.", "author": "tylerbenson", "createdAt": "2020-01-07T16:17:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NTMyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDc3NTY5Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r364775692", "bodyText": "The monitor callbacks are following a couple rules...\n1 - The call back happens after something is complete.\n2 - The success and failure cases are split -- to force thinking carefully about failure.\nSo in general, I'd expect the callback to be at the end of a try block.", "author": "dougqh", "createdAt": "2020-01-09T14:44:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NTMyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjEwMjcyMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366102721", "bodyText": "I changed the order.  Let me know if I'm missing anything else.", "author": "tylerbenson", "createdAt": "2020-01-14T00:40:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NTMyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NjcxNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363786716", "bodyText": "It could track not just traces but also spans.  We wanted to include in health metrics, but that wasn't terribly easy in the prior design.", "author": "dougqh", "createdAt": "2020-01-07T14:57:02Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -0,0 +1,162 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventHandler;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+public class BatchWritingDisruptor extends AbstractDisruptor<byte[]> {\n+  private static final int FLUSH_PAYLOAD_BYTES = 5_000_000; // 5 MB\n+\n+  private final ScheduledExecutorService heartbeatExecutor =\n+      Executors.newScheduledThreadPool(1, new DaemonThreadFactory(\"dd-trace-heartbeat\"));\n+\n+  private final DisruptorEvent.HeartbeatTranslator<byte[]> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+\n+  public BatchWritingDisruptor(\n+      final int disruptorSize,\n+      final int flushFrequencySeconds,\n+      final DDAgentApi api,\n+      final Monitor monitor,\n+      final DDAgentWriter writer) {\n+    super(disruptorSize, new BatchWritingHandler(flushFrequencySeconds, api, monitor, writer));\n+\n+    if (0 < flushFrequencySeconds) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      final Runnable heartbeat =\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              // Only add if the buffer is empty.\n+              if (running && getCurrentCount() == 0) {\n+                disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+              }\n+            }\n+          };\n+      heartbeatExecutor.scheduleAtFixedRate(heartbeat, 100, 100, TimeUnit.MILLISECONDS);\n+    }\n+  }\n+\n+  @Override\n+  protected ThreadFactory getThreadFactory() {\n+    return new DaemonThreadFactory(\"dd-trace-writer\");\n+  }\n+\n+  @Override\n+  public boolean publish(final byte[] data, final int representativeCount) {\n+    disruptor.getRingBuffer().publishEvent(dataTranslator, data, representativeCount);\n+    return true;\n+  }\n+\n+  // Intentionally not thread safe.\n+  private static class BatchWritingHandler implements EventHandler<DisruptorEvent<byte[]>> {\n+\n+    private final long flushFrequencyNanos;\n+    private final DDAgentApi api;\n+    private final Monitor monitor;\n+    private final DDAgentWriter writer;\n+    private final List<byte[]> serializedTraces = new ArrayList<>();\n+    private int representativeCount = 0;", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjA0MTg0NA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366041844", "bodyText": "Do you mean the number of total spans?  What's the benefit there?", "author": "tylerbenson", "createdAt": "2020-01-13T21:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4NjcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4ODM4MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363788381", "bodyText": "I have some concerns with this.  I'd actually like to see us get away from producing many tiny byte[].\nI'd prefer to see us build up one big byte[] instead to reduce the amount of allocation.\nDDApi.Request from the experimental branch was built with that in mind.  I don't quite see how we do that with this design.", "author": "dougqh", "createdAt": "2020-01-07T15:00:11Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -0,0 +1,162 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventHandler;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+public class BatchWritingDisruptor extends AbstractDisruptor<byte[]> {", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjA0NDQxMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r366044411", "bodyText": "We talked and came up with a good solution.  Use a byte[] on the event as a buffer that gets reused and grows to satisfy the needed size and copy the array off to a large buffer when batching.\nThis requires moving off jackson though, so will be done in a separate PR.", "author": "tylerbenson", "createdAt": "2020-01-13T21:43:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc4ODM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc5NzI2Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363797266", "bodyText": "This should probably be in a finally block in the event that prior close fails.", "author": "dougqh", "createdAt": "2020-01-07T15:17:39Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -161,32 +140,16 @@ public DDAgentApi getApi() {\n \n   @Override\n   public void start() {\n-    disruptor.start();\n-\n+    batchWritingDisruptor.start();\n+    traceProcessingDisruptor.start();\n     monitor.onStart(this);\n   }\n \n   @Override\n   public void close() {\n-\n-    boolean flushSuccess = true;\n-\n-    // We have to shutdown scheduled executor first to make sure no flush events issued after\n-    // disruptor has been shutdown.\n-    // Otherwise those events will never be processed and flush call will wait forever.\n-    scheduledWriterExecutor.shutdown();\n-    try {\n-      scheduledWriterExecutor.awaitTermination(flushFrequencySeconds, SECONDS);\n-    } catch (final InterruptedException e) {\n-      log.warn(\"Waiting for flush executor shutdown interrupted.\", e);\n-\n-      flushSuccess = false;\n-    }\n-    flushSuccess |= disruptor.flush();\n-\n-    disruptor.close();\n-\n-    monitor.onShutdown(this, flushSuccess);\n+    monitor.onShutdown(this, traceProcessingDisruptor.flush(traceCount.getAndSet(0)));\n+    traceProcessingDisruptor.close();\n+    batchWritingDisruptor.close();", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc5NzQ0NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363797445", "bodyText": "I think the call should be after the close.", "author": "dougqh", "createdAt": "2020-01-07T15:17:59Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -161,32 +140,16 @@ public DDAgentApi getApi() {\n \n   @Override\n   public void start() {\n-    disruptor.start();\n-\n+    batchWritingDisruptor.start();\n+    traceProcessingDisruptor.start();\n     monitor.onStart(this);\n   }\n \n   @Override\n   public void close() {\n-\n-    boolean flushSuccess = true;\n-\n-    // We have to shutdown scheduled executor first to make sure no flush events issued after\n-    // disruptor has been shutdown.\n-    // Otherwise those events will never be processed and flush call will wait forever.\n-    scheduledWriterExecutor.shutdown();\n-    try {\n-      scheduledWriterExecutor.awaitTermination(flushFrequencySeconds, SECONDS);\n-    } catch (final InterruptedException e) {\n-      log.warn(\"Waiting for flush executor shutdown interrupted.\", e);\n-\n-      flushSuccess = false;\n-    }\n-    flushSuccess |= disruptor.flush();\n-\n-    disruptor.close();\n-\n-    monitor.onShutdown(this, flushSuccess);\n+    monitor.onShutdown(this, traceProcessingDisruptor.flush(traceCount.getAndSet(0)));", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc5ODM5NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363798395", "bodyText": "To have more meaningful back-pressure, we probably also need to able to back-off on the rate that we are sending.  How would that work with the heartbeatExecutor?", "author": "dougqh", "createdAt": "2020-01-07T15:19:43Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -0,0 +1,162 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventHandler;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+\n+@Slf4j\n+public class BatchWritingDisruptor extends AbstractDisruptor<byte[]> {\n+  private static final int FLUSH_PAYLOAD_BYTES = 5_000_000; // 5 MB\n+\n+  private final ScheduledExecutorService heartbeatExecutor =\n+      Executors.newScheduledThreadPool(1, new DaemonThreadFactory(\"dd-trace-heartbeat\"));\n+\n+  private final DisruptorEvent.HeartbeatTranslator<byte[]> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+\n+  public BatchWritingDisruptor(\n+      final int disruptorSize,\n+      final int flushFrequencySeconds,\n+      final DDAgentApi api,\n+      final Monitor monitor,\n+      final DDAgentWriter writer) {\n+    super(disruptorSize, new BatchWritingHandler(flushFrequencySeconds, api, monitor, writer));\n+\n+    if (0 < flushFrequencySeconds) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      final Runnable heartbeat =\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              // Only add if the buffer is empty.\n+              if (running && getCurrentCount() == 0) {\n+                disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+              }\n+            }\n+          };\n+      heartbeatExecutor.scheduleAtFixedRate(heartbeat, 100, 100, TimeUnit.MILLISECONDS);", "originalCommit": "e3054cb6cfe645bd189417c5d3be479beec08ea1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzgzMjMyNQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r363832325", "bodyText": "The heartbeat Executor will only add an event to the queue if the queue is empty and it doesn't influence the frequency of flushing.  What it does influence is the greatest amount of delay (beyond the flush frequency) that a flush will occur when the queue is empty.  (ie, a flush will be at most 100 ms late from the 1/sec rate.)", "author": "tylerbenson", "createdAt": "2020-01-07T16:26:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc5ODM5NQ=="}], "type": "inlineReview"}, {"oid": "a5b7705dd7d9a44f045edbea2d8f2f4a9c35d6c4", "url": "https://github.com/DataDog/dd-trace-java/commit/a5b7705dd7d9a44f045edbea2d8f2f4a9c35d6c4", "message": "Apply `_sample_rate` metric to allow dd-agent to do proper scaling of metrics when traces are sampled.", "committedDate": "2020-01-13T23:44:51Z", "type": "forcePushed"}, {"oid": "451fba256a5068b3b40871dea630b5ede4213823", "url": "https://github.com/DataDog/dd-trace-java/commit/451fba256a5068b3b40871dea630b5ede4213823", "message": "Split TraceConsumer into two different disruptors\n\nFirst disruptor (TraceProcessingDisruptor) does processing, which is currently limited to serialization, but in the future can do other processing such as TraceInterceptor invocation.\nSecond disruptor (BatchWritingDisruptor) takes serialized traces and batches them into groups and flushes them periodically based on size and time.", "committedDate": "2020-01-16T00:13:44Z", "type": "commit"}, {"oid": "5ff855737b4fca280519f5fee0750a075b94f052", "url": "https://github.com/DataDog/dd-trace-java/commit/5ff855737b4fca280519f5fee0750a075b94f052", "message": "Add documentation, remove volatile/public, improve test reliability.", "committedDate": "2020-01-16T00:13:44Z", "type": "commit"}, {"oid": "a4db31cf79a4fc8ec5bf1ad7ba9d44988daf7383", "url": "https://github.com/DataDog/dd-trace-java/commit/a4db31cf79a4fc8ec5bf1ad7ba9d44988daf7383", "message": "Apply `_sample_rate` metric to allow dd-agent to do proper scaling of metrics when traces are sampled.", "committedDate": "2020-01-16T00:13:44Z", "type": "commit"}, {"oid": "3aea763769557b2f75da901cf34af1308927495f", "url": "https://github.com/DataDog/dd-trace-java/commit/3aea763769557b2f75da901cf34af1308927495f", "message": "Remove test race condition", "committedDate": "2020-01-16T00:13:44Z", "type": "commit"}, {"oid": "66928ae28294a95d2ae691ad20995eda2184d25c", "url": "https://github.com/DataDog/dd-trace-java/commit/66928ae28294a95d2ae691ad20995eda2184d25c", "message": "Replace DDAgentWriter.Spec with a proper Builder.\n\nAlso rename the builder class on DDTracer to default name generated by Lombok.", "committedDate": "2020-01-17T00:43:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyMTIyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r367721227", "bodyText": "@gbbr does this look like a legit way of getting our _sample_rate scaling done by the agent to be accurate?", "author": "tylerbenson", "createdAt": "2020-01-17T00:45:02Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/TraceProcessingDisruptor.java", "diffHunk": "@@ -63,6 +63,12 @@ public void onEvent(\n         final DisruptorEvent<List<DDSpan>> event, final long sequence, final boolean endOfBatch) {\n       try {\n         if (event.data != null) {\n+          if (1 < event.representativeCount && !event.data.isEmpty()) {\n+            // attempt to have agent scale the metrics properly\n+            ((DDSpan) event.data.get(0).getLocalRootSpan())\n+                .context()\n+                .setMetric(\"_sample_rate\", 1d / event.representativeCount);", "originalCommit": "a4db31cf79a4fc8ec5bf1ad7ba9d44988daf7383", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzk1MDYzNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r367950634", "bodyText": "The agent doesn't do any scaling, it's the backend, so I wouldn't be able to tell. _sample_rate is expected to hold the rate that a local client sampler (the one that doesn't send stuff to the agent at all) is using IIRC. @furmmon is our expert for answering any questions around sampling, maybe you can confirm.", "author": "gbbr", "createdAt": "2020-01-17T14:05:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyMTIyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzczMzAyNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r367733026", "bodyText": "This might not work if the last span reported isn't the root span.  This might be an issue for async traces and for partial flush traces.  Any better ideas?", "author": "tylerbenson", "createdAt": "2020-01-17T01:35:47Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/DDAgentWriter.java", "diffHunk": "@@ -113,7 +113,13 @@ public final long getDisruptorRemainingCapacity() {\n   public void write(final List<DDSpan> trace) {\n     // We can't add events after shutdown otherwise it will never complete shutting down.\n     if (traceProcessingDisruptor.running) {\n-      final int representativeCount = traceCount.getAndSet(0) + 1;\n+      final int representativeCount;\n+      if (trace.isEmpty() || !(trace.get(0).isRootSpan())) {", "originalCommit": "a4db31cf79a4fc8ec5bf1ad7ba9d44988daf7383", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5cce4cb783edb1b766f6c22be4b1701739dcc9ae", "url": "https://github.com/DataDog/dd-trace-java/commit/5cce4cb783edb1b766f6c22be4b1701739dcc9ae", "message": "Replace DDAgentWriter.Spec with a proper Builder.\n\nAlso rename the builder class on DDTracer to default name generated by Lombok.", "committedDate": "2020-01-17T19:10:11Z", "type": "commit"}, {"oid": "5cce4cb783edb1b766f6c22be4b1701739dcc9ae", "url": "https://github.com/DataDog/dd-trace-java/commit/5cce4cb783edb1b766f6c22be4b1701739dcc9ae", "message": "Replace DDAgentWriter.Spec with a proper Builder.\n\nAlso rename the builder class on DDTracer to default name generated by Lombok.", "committedDate": "2020-01-17T19:10:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEzNzI3OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1161#discussion_r368137278", "bodyText": "So reducing byte[] remains to be done, I think that's fine for now.  We can revisit that after ripping out Jackson.", "author": "dougqh", "createdAt": "2020-01-17T21:09:00Z", "path": "dd-trace-ot/src/main/java/datadog/trace/common/writer/ddagent/BatchWritingDisruptor.java", "diffHunk": "@@ -0,0 +1,171 @@\n+package datadog.trace.common.writer.ddagent;\n+\n+import com.lmax.disruptor.EventHandler;\n+import datadog.trace.common.util.DaemonThreadFactory;\n+import datadog.trace.common.writer.DDAgentWriter;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+\n+/**\n+ * Disruptor that takes serialized traces and batches them into appropriately sized requests.\n+ *\n+ * <p>publishing to the buffer will block if the buffer is full.\n+ */\n+@Slf4j\n+public class BatchWritingDisruptor extends AbstractDisruptor<byte[]> {\n+  private static final int FLUSH_PAYLOAD_BYTES = 5_000_000; // 5 MB\n+\n+  // TODO: move executor to tracer for sharing with other tasks.\n+  private final ScheduledExecutorService heartbeatExecutor =\n+      Executors.newScheduledThreadPool(1, new DaemonThreadFactory(\"dd-trace-heartbeat\"));\n+\n+  private final DisruptorEvent.HeartbeatTranslator<byte[]> heartbeatTranslator =\n+      new DisruptorEvent.HeartbeatTranslator();\n+\n+  public BatchWritingDisruptor(\n+      final int disruptorSize,\n+      final int flushFrequencySeconds,\n+      final DDAgentApi api,\n+      final Monitor monitor,\n+      final DDAgentWriter writer) {\n+    super(disruptorSize, new BatchWritingHandler(flushFrequencySeconds, api, monitor, writer));\n+\n+    if (0 < flushFrequencySeconds) {\n+      // This provides a steady stream of events to enable flushing with a low throughput.\n+      final Runnable heartbeat =\n+          new Runnable() {\n+            @Override\n+            public void run() {\n+              // Only add if the buffer is empty.\n+              if (running && getCurrentCount() == 0) {\n+                disruptor.getRingBuffer().tryPublishEvent(heartbeatTranslator);\n+              }\n+            }\n+          };\n+      heartbeatExecutor.scheduleAtFixedRate(heartbeat, 100, 100, TimeUnit.MILLISECONDS);\n+    }\n+  }\n+\n+  @Override\n+  protected ThreadFactory getThreadFactory() {\n+    return new DaemonThreadFactory(\"dd-trace-writer\");\n+  }\n+\n+  @Override\n+  public boolean publish(final byte[] data, final int representativeCount) {\n+    // blocking call to ensure serialized traces aren't discarded and apply back pressure.\n+    disruptor.getRingBuffer().publishEvent(dataTranslator, data, representativeCount);\n+    return true;\n+  }\n+\n+  // Intentionally not thread safe.\n+  private static class BatchWritingHandler implements EventHandler<DisruptorEvent<byte[]>> {\n+\n+    private final long flushFrequencyNanos;\n+    private final DDAgentApi api;\n+    private final Monitor monitor;\n+    private final DDAgentWriter writer;\n+    private final List<byte[]> serializedTraces = new ArrayList<>();\n+    private int representativeCount = 0;\n+    private int sizeInBytes = 0;\n+    private long nextScheduledFlush;\n+\n+    private BatchWritingHandler(\n+        final int flushFrequencySeconds,\n+        final DDAgentApi api,\n+        final Monitor monitor,\n+        final DDAgentWriter writer) {\n+      flushFrequencyNanos = TimeUnit.SECONDS.toNanos(flushFrequencySeconds);\n+      scheduleNextFlush();\n+      this.api = api;\n+      this.monitor = monitor;\n+      this.writer = writer;\n+    }\n+\n+    // TODO: reduce byte[] garbage by keeping the byte[] on the event and copy before returning.", "originalCommit": "5cce4cb783edb1b766f6c22be4b1701739dcc9ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}