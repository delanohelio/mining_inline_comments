{"pr_number": 2060, "pr_title": "RPS and error metrics", "pr_createdAt": "2020-11-09T13:25:05Z", "pr_url": "https://github.com/DataDog/dd-trace-java/pull/2060", "timeline": [{"oid": "639b20123647cc67537f59298fdc1f213e088969", "url": "https://github.com/DataDog/dd-trace-java/commit/639b20123647cc67537f59298fdc1f213e088969", "message": "wip", "committedDate": "2020-11-09T13:47:27Z", "type": "forcePushed"}, {"oid": "4904749f22b6fb375e16069db39fb5ddda143145", "url": "https://github.com/DataDog/dd-trace-java/commit/4904749f22b6fb375e16069db39fb5ddda143145", "message": "wip", "committedDate": "2020-11-09T13:57:15Z", "type": "forcePushed"}, {"oid": "a35360e27c35dbf9b5cd33b2ba9bc20cba60635a", "url": "https://github.com/DataDog/dd-trace-java/commit/a35360e27c35dbf9b5cd33b2ba9bc20cba60635a", "message": "wip", "committedDate": "2020-11-10T13:08:35Z", "type": "forcePushed"}, {"oid": "99432f115fe0543c8c645c37a9c996341a6d6b6d", "url": "https://github.com/DataDog/dd-trace-java/commit/99432f115fe0543c8c645c37a9c996341a6d6b6d", "message": "wip", "committedDate": "2020-11-10T13:13:45Z", "type": "forcePushed"}, {"oid": "155b427c7369dc94d45fd7d883cf0dc726487b1b", "url": "https://github.com/DataDog/dd-trace-java/commit/155b427c7369dc94d45fd7d883cf0dc726487b1b", "message": "wip", "committedDate": "2020-11-10T14:18:18Z", "type": "forcePushed"}, {"oid": "a0fe956f3e2723b4e9704dfc8bd5dbab3e9bbb45", "url": "https://github.com/DataDog/dd-trace-java/commit/a0fe956f3e2723b4e9704dfc8bd5dbab3e9bbb45", "message": "wip", "committedDate": "2020-11-10T15:49:25Z", "type": "forcePushed"}, {"oid": "a1ff4c84d9155b2d668c75e115b1b13609efc6d7", "url": "https://github.com/DataDog/dd-trace-java/commit/a1ff4c84d9155b2d668c75e115b1b13609efc6d7", "message": "wip", "committedDate": "2020-11-10T17:49:27Z", "type": "forcePushed"}, {"oid": "56dfe00ac316f50bc616c80f2186b16197200e3c", "url": "https://github.com/DataDog/dd-trace-java/commit/56dfe00ac316f50bc616c80f2186b16197200e3c", "message": "wip", "committedDate": "2020-11-10T21:28:39Z", "type": "forcePushed"}, {"oid": "0aecd65405b48f73af23eaeef01ca4302b992107", "url": "https://github.com/DataDog/dd-trace-java/commit/0aecd65405b48f73af23eaeef01ca4302b992107", "message": "wip", "committedDate": "2020-11-11T10:05:36Z", "type": "forcePushed"}, {"oid": "37d4946ad8cee2d73f8503f7c26381fd651ff82d", "url": "https://github.com/DataDog/dd-trace-java/commit/37d4946ad8cee2d73f8503f7c26381fd651ff82d", "message": "wip", "committedDate": "2020-11-11T16:02:55Z", "type": "forcePushed"}, {"oid": "2551b9b7e63ba280ec48996381fcf438918d9ad3", "url": "https://github.com/DataDog/dd-trace-java/commit/2551b9b7e63ba280ec48996381fcf438918d9ad3", "message": "wip", "committedDate": "2020-11-11T16:05:36Z", "type": "forcePushed"}, {"oid": "0c9a8cc705dce97c98d9c64ab41194bc4d514b98", "url": "https://github.com/DataDog/dd-trace-java/commit/0c9a8cc705dce97c98d9c64ab41194bc4d514b98", "message": "wip", "committedDate": "2020-11-11T16:07:22Z", "type": "forcePushed"}, {"oid": "11b6006e8d3352ad54786d5b0206a136800f550c", "url": "https://github.com/DataDog/dd-trace-java/commit/11b6006e8d3352ad54786d5b0206a136800f550c", "message": "track hit and error count metrics", "committedDate": "2020-11-11T19:31:45Z", "type": "forcePushed"}, {"oid": "4cb3b82e51fb158ca62a3545ed370aabfb474a16", "url": "https://github.com/DataDog/dd-trace-java/commit/4cb3b82e51fb158ca62a3545ed370aabfb474a16", "message": "track hit and error count metrics", "committedDate": "2020-11-11T19:52:33Z", "type": "forcePushed"}, {"oid": "5dfc33628f477c412ae373b0cc09323217610133", "url": "https://github.com/DataDog/dd-trace-java/commit/5dfc33628f477c412ae373b0cc09323217610133", "message": "track hit and error count metrics", "committedDate": "2020-11-11T20:07:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxMzc0Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521613746", "bodyText": "This was all extracted from DDAgentApi", "author": "richardstartin", "createdAt": "2020-11-11T20:17:15Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/http/OkHttpUtils.java", "diffHunk": "@@ -0,0 +1,74 @@\n+package datadog.trace.core.http;\n+\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+\n+import datadog.common.container.ContainerInfo;\n+import datadog.trace.common.writer.ddagent.unixdomainsockets.UnixDomainSocketFactory;\n+import datadog.trace.core.DDTraceCoreInfo;\n+import java.io.File;\n+import java.util.Collections;\n+import okhttp3.ConnectionSpec;\n+import okhttp3.Dispatcher;\n+import okhttp3.HttpUrl;\n+import okhttp3.OkHttpClient;\n+import okhttp3.Request;\n+\n+public final class OkHttpUtils {", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk2NDY4Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521964682", "bodyText": "Great. Will come in handy with error logging going to the agent as well.", "author": "bantonsson", "createdAt": "2020-11-12T09:35:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxMzc0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxMzgyOQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521613829", "bodyText": "Moved to OkHttpUtils", "author": "richardstartin", "createdAt": "2020-11-11T20:17:27Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/writer/ddagent/DDAgentApi.java", "diffHunk": "@@ -332,79 +320,6 @@ private static OkHttpClient validateClient(String endpoint, OkHttpClient client,\n     return null;\n   }\n \n-  private static OkHttpClient buildHttpClient(", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTc4OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521615789", "bodyText": "We've basically agreed not to do protobuf now, so this class will probably be deleted soon", "author": "richardstartin", "createdAt": "2020-11-11T20:21:14Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/protobuf/ProtobufWriter.java", "diffHunk": "@@ -11,6 +11,7 @@\n import java.nio.ByteBuffer;", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzA3MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521617071", "bodyText": "Used for metrics where we expect payloads to be small, but to grow to accommodate an entire payload in a single buffer. This will go away entirely if we start streaming.", "author": "richardstartin", "createdAt": "2020-11-11T20:23:53Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/WritableFormatter.java", "diffHunk": "@@ -124,4 +140,11 @@ public void writeObject(Object value, EncodingCache encodingCache) {\n       writer.write(value, this, encodingCache);\n     }\n   }\n+\n+  private static ByteBuffer resize(ByteBuffer oldBuffer) {", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzU2OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521617568", "bodyText": "Just allows the option not to do the trick where we write the array header at the start of the buffer before publishing it, which is only relevant for trace payloads.", "author": "richardstartin", "createdAt": "2020-11-11T20:24:54Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/WritableFormatter.java", "diffHunk": "@@ -88,14 +104,14 @@ protected void mark() {\n   @Override\n   public void flush() {\n     buffer.flip();\n-    writeHeader();\n+    writeHeader(writeArray);\n     sink.accept(messageCount, buffer.slice());\n     if (!manualReset) {\n       reset();\n     }\n   }\n \n-  protected abstract void writeHeader();\n+  protected abstract void writeHeader(boolean array);", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzk4Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521617983", "bodyText": "I thought this was better than having lots of flags, but plan to simplify this as much as possible in another PR.", "author": "richardstartin", "createdAt": "2020-11-11T20:25:39Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/serialization/WritableFormatter.java", "diffHunk": "@@ -3,28 +3,41 @@\n import datadog.trace.bootstrap.instrumentation.api.UTF8BytesString;\n import java.nio.BufferOverflowException;\n import java.nio.ByteBuffer;\n+import java.util.EnumSet;\n import java.util.Map;\n \n public abstract class WritableFormatter implements Writable, MessageFormatter {\n \n+  public enum Feature {", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxODEyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521618127", "bodyText": "Moved out of DDAgentApi so it can be used elsewhere.", "author": "richardstartin", "createdAt": "2020-11-11T20:25:57Z", "path": "dd-trace-core/src/main/java/datadog/trace/core/http/RejectingExecutorService.java", "diffHunk": "@@ -0,0 +1,41 @@\n+package datadog.trace.core.http;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.AbstractExecutorService;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.RejectedExecutionException;\n+import java.util.concurrent.TimeUnit;\n+\n+/** {@link ExecutorService} that always rejects requests. */\n+public final class RejectingExecutorService extends AbstractExecutorService {", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMDQ0OQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521620449", "bodyText": "This is basically a queue conflation mechanism, betting that items added to the queue are usually similar to those recently added to the queue, which should keep queue length short. On the other hand, the processor should be quite fast so conflation may not be appropriate.", "author": "richardstartin", "createdAt": "2020-11-11T20:30:26Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/ConflatingMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package datadog.trace.common.metrics;\n+\n+import static datadog.trace.util.AgentThreadFactory.AgentThread.METRICS_AGGREGATOR;\n+import static datadog.trace.util.AgentThreadFactory.newAgentThread;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+import datadog.trace.api.Config;\n+import datadog.trace.api.WellKnownTags;\n+import datadog.trace.core.DDSpanData;\n+import datadog.trace.core.util.LRUCache;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpscArrayQueue;\n+import org.jctools.queues.MpscBlockingConsumerArrayQueue;\n+\n+@Slf4j\n+public final class ConflatingMetricsAggregator implements MetricsAggregator, EventListener {\n+\n+  private static final Batch POISON_PILL = Batch.NULL;\n+\n+  private final Queue<Batch> batchPool;\n+  private final ConcurrentHashMap<MetricKey, Batch> pending;\n+  private final Thread thread;\n+  private final BlockingQueue<Batch> inbox;\n+  private final Sink sink;\n+  private final Aggregator aggregator;\n+\n+  private volatile boolean enabled = true;\n+\n+  public ConflatingMetricsAggregator(Config config) {\n+    this(\n+        config.getWellKnownTags(),\n+        new OkHttpSink(config.getAgentUrl(), config.getAgentTimeout()),\n+        config.getTracerMetricsMaxAggregates(),\n+        config.getTracerMetricsMaxPending());\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags, Sink sink, int maxAggregates, int queueSize) {\n+    this(wellKnownTags, sink, maxAggregates, queueSize, 10, SECONDS);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags,\n+      Sink sink,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this(\n+        sink,\n+        new SerializingMetricWriter(wellKnownTags, sink),\n+        maxAggregates,\n+        queueSize,\n+        reportingInterval,\n+        timeUnit);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      Sink sink,\n+      MetricWriter metricWriter,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this.inbox = new MpscBlockingConsumerArrayQueue<>(queueSize);\n+    this.batchPool = new MpscArrayQueue<>(maxAggregates);\n+    this.pending = new ConcurrentHashMap<>(maxAggregates * 4 / 3, 0.75f);\n+    this.sink = sink;\n+    this.aggregator =\n+        new Aggregator(\n+            metricWriter, batchPool, inbox, pending, maxAggregates, reportingInterval, timeUnit);\n+    this.thread = newAgentThread(METRICS_AGGREGATOR, aggregator);\n+  }\n+\n+  @Override\n+  public void start() {\n+    sink.register(this);\n+    thread.start();\n+  }\n+\n+  @Override\n+  public void publish(List<? extends DDSpanData> trace) {\n+    if (enabled) {\n+      for (DDSpanData span : trace) {\n+        if (span.isMeasured()) {\n+          publish(span);\n+        }\n+      }\n+    }\n+  }\n+\n+  private void publish(DDSpanData span) {\n+    boolean error = span.getError() > 0;\n+    long durationNanos = span.getDurationNano();\n+    MetricKey key =\n+        new MetricKey(span.getResourceName(), span.getServiceName(), span.getOperationName(), 0);\n+    Batch batch = pending.get(key);", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMTIyMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521621221", "bodyText": "This is a single threaded processor because DDSketch (which will be processed here) doesn't have any concurrency control, and nor does LRUCache", "author": "richardstartin", "createdAt": "2020-11-11T20:32:02Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/ConflatingMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package datadog.trace.common.metrics;\n+\n+import static datadog.trace.util.AgentThreadFactory.AgentThread.METRICS_AGGREGATOR;\n+import static datadog.trace.util.AgentThreadFactory.newAgentThread;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+import datadog.trace.api.Config;\n+import datadog.trace.api.WellKnownTags;\n+import datadog.trace.core.DDSpanData;\n+import datadog.trace.core.util.LRUCache;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpscArrayQueue;\n+import org.jctools.queues.MpscBlockingConsumerArrayQueue;\n+\n+@Slf4j\n+public final class ConflatingMetricsAggregator implements MetricsAggregator, EventListener {\n+\n+  private static final Batch POISON_PILL = Batch.NULL;\n+\n+  private final Queue<Batch> batchPool;\n+  private final ConcurrentHashMap<MetricKey, Batch> pending;\n+  private final Thread thread;\n+  private final BlockingQueue<Batch> inbox;\n+  private final Sink sink;\n+  private final Aggregator aggregator;\n+\n+  private volatile boolean enabled = true;\n+\n+  public ConflatingMetricsAggregator(Config config) {\n+    this(\n+        config.getWellKnownTags(),\n+        new OkHttpSink(config.getAgentUrl(), config.getAgentTimeout()),\n+        config.getTracerMetricsMaxAggregates(),\n+        config.getTracerMetricsMaxPending());\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags, Sink sink, int maxAggregates, int queueSize) {\n+    this(wellKnownTags, sink, maxAggregates, queueSize, 10, SECONDS);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags,\n+      Sink sink,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this(\n+        sink,\n+        new SerializingMetricWriter(wellKnownTags, sink),\n+        maxAggregates,\n+        queueSize,\n+        reportingInterval,\n+        timeUnit);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      Sink sink,\n+      MetricWriter metricWriter,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this.inbox = new MpscBlockingConsumerArrayQueue<>(queueSize);\n+    this.batchPool = new MpscArrayQueue<>(maxAggregates);\n+    this.pending = new ConcurrentHashMap<>(maxAggregates * 4 / 3, 0.75f);\n+    this.sink = sink;\n+    this.aggregator =\n+        new Aggregator(\n+            metricWriter, batchPool, inbox, pending, maxAggregates, reportingInterval, timeUnit);\n+    this.thread = newAgentThread(METRICS_AGGREGATOR, aggregator);\n+  }\n+\n+  @Override\n+  public void start() {\n+    sink.register(this);\n+    thread.start();\n+  }\n+\n+  @Override\n+  public void publish(List<? extends DDSpanData> trace) {\n+    if (enabled) {\n+      for (DDSpanData span : trace) {\n+        if (span.isMeasured()) {\n+          publish(span);\n+        }\n+      }\n+    }\n+  }\n+\n+  private void publish(DDSpanData span) {\n+    boolean error = span.getError() > 0;\n+    long durationNanos = span.getDurationNano();\n+    MetricKey key =\n+        new MetricKey(span.getResourceName(), span.getServiceName(), span.getOperationName(), 0);\n+    Batch batch = pending.get(key);\n+    if (null != batch) {\n+      if (batch.add(error, durationNanos)) {\n+        // added to a pending batch, skip the queue\n+        return;\n+      }\n+    }\n+    batch = newBatch(key);\n+    batch.add(error, durationNanos);\n+    // overwrite the last one if present, it's already full\n+    pending.put(key, batch);\n+    inbox.offer(batch);\n+  }\n+\n+  private Batch newBatch(MetricKey key) {\n+    Batch batch = batchPool.poll();\n+    return (null == batch ? new Batch() : batch).withKey(key);\n+  }\n+\n+  public void stop() {\n+    inbox.offer(POISON_PILL);\n+  }\n+\n+  @Override\n+  public void close() {\n+    stop();\n+  }\n+\n+  @Override\n+  public void onEvent(EventType eventType, String message) {\n+    switch (eventType) {\n+      case DOWNGRADED:\n+        log.debug(\"Disabling metric reporting because an agent downgrade was detected\");\n+        disable();\n+        break;\n+      case BAD_PAYLOAD:\n+        log.debug(\"bad metrics payload sent to trace agent: {}\", message);\n+        break;\n+      case ERROR:\n+        log.debug(\"trace agent errored receiving metrics payload: {}\", message);\n+        break;\n+      default:\n+    }\n+  }\n+\n+  private void disable() {\n+    this.enabled = false;\n+    this.thread.interrupt();\n+    this.pending.clear();\n+    this.batchPool.clear();\n+    this.inbox.clear();\n+    this.aggregator.clearAggregates();\n+  }\n+\n+  private static final class Aggregator implements Runnable {\n+", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMTY5NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521621695", "bodyText": "Batch is quite heavy so they're pooled. When they've been used they get put back on this queue.", "author": "richardstartin", "createdAt": "2020-11-11T20:32:58Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/ConflatingMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package datadog.trace.common.metrics;\n+\n+import static datadog.trace.util.AgentThreadFactory.AgentThread.METRICS_AGGREGATOR;\n+import static datadog.trace.util.AgentThreadFactory.newAgentThread;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+import datadog.trace.api.Config;\n+import datadog.trace.api.WellKnownTags;\n+import datadog.trace.core.DDSpanData;\n+import datadog.trace.core.util.LRUCache;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpscArrayQueue;\n+import org.jctools.queues.MpscBlockingConsumerArrayQueue;\n+\n+@Slf4j\n+public final class ConflatingMetricsAggregator implements MetricsAggregator, EventListener {\n+\n+  private static final Batch POISON_PILL = Batch.NULL;\n+\n+  private final Queue<Batch> batchPool;", "originalCommit": "5dfc33628f477c412ae373b0cc09323217610133", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE1ODU1MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r522158551", "bodyText": "We've talked about doing object pooling on other classes too.  Perhaps we should create a proper abstraction for it?", "author": "tylerbenson", "createdAt": "2020-11-12T14:44:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYyMTY5NQ=="}], "type": "inlineReview"}, {"oid": "7e7e30208960d9941c27871947d3eae40c1c89b1", "url": "https://github.com/DataDog/dd-trace-java/commit/7e7e30208960d9941c27871947d3eae40c1c89b1", "message": "track hit and error count metrics", "committedDate": "2020-11-11T21:13:58Z", "type": "forcePushed"}, {"oid": "9918d9957fbd4eafb974e44e1a5eea621b6bca4d", "url": "https://github.com/DataDog/dd-trace-java/commit/9918d9957fbd4eafb974e44e1a5eea621b6bca4d", "message": "track hit and error count metrics", "committedDate": "2020-11-11T21:16:40Z", "type": "forcePushed"}, {"oid": "5399c65015d57814641be277d60815a16c2c4290", "url": "https://github.com/DataDog/dd-trace-java/commit/5399c65015d57814641be277d60815a16c2c4290", "message": "add a unit test for WellKnownTags", "committedDate": "2020-11-11T23:14:35Z", "type": "forcePushed"}, {"oid": "4d4a4b1de6eb8270d9b0bc7fae71452677fe0b8f", "url": "https://github.com/DataDog/dd-trace-java/commit/4d4a4b1de6eb8270d9b0bc7fae71452677fe0b8f", "message": "add a unit test for WellKnownTags", "committedDate": "2020-11-12T09:06:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk2MTQzNQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521961435", "bodyText": "So I would love if the comments used a few more words, and said something about it being fine to overwrite the entry in the pending map, since it had already been added to the inbox queue, or similar.", "author": "bantonsson", "createdAt": "2020-11-12T09:30:08Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/ConflatingMetricsAggregator.java", "diffHunk": "@@ -0,0 +1,249 @@\n+package datadog.trace.common.metrics;\n+\n+import static datadog.trace.util.AgentThreadFactory.AgentThread.METRICS_AGGREGATOR;\n+import static datadog.trace.util.AgentThreadFactory.newAgentThread;\n+import static java.util.concurrent.TimeUnit.MILLISECONDS;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+\n+import datadog.trace.api.Config;\n+import datadog.trace.api.WellKnownTags;\n+import datadog.trace.core.DDSpanData;\n+import datadog.trace.core.util.LRUCache;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.TimeUnit;\n+import lombok.extern.slf4j.Slf4j;\n+import org.jctools.queues.MpmcArrayQueue;\n+import org.jctools.queues.MpscBlockingConsumerArrayQueue;\n+\n+@Slf4j\n+public final class ConflatingMetricsAggregator implements MetricsAggregator, EventListener {\n+\n+  private static final Batch POISON_PILL = Batch.NULL;\n+\n+  private final Queue<Batch> batchPool;\n+  private final ConcurrentHashMap<MetricKey, Batch> pending;\n+  private final Thread thread;\n+  private final BlockingQueue<Batch> inbox;\n+  private final Sink sink;\n+  private final Aggregator aggregator;\n+\n+  private volatile boolean enabled = true;\n+\n+  public ConflatingMetricsAggregator(Config config) {\n+    this(\n+        config.getWellKnownTags(),\n+        new OkHttpSink(config.getAgentUrl(), config.getAgentTimeout()),\n+        config.getTracerMetricsMaxAggregates(),\n+        config.getTracerMetricsMaxPending());\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags, Sink sink, int maxAggregates, int queueSize) {\n+    this(wellKnownTags, sink, maxAggregates, queueSize, 10, SECONDS);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      WellKnownTags wellKnownTags,\n+      Sink sink,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this(\n+        sink,\n+        new SerializingMetricWriter(wellKnownTags, sink),\n+        maxAggregates,\n+        queueSize,\n+        reportingInterval,\n+        timeUnit);\n+  }\n+\n+  ConflatingMetricsAggregator(\n+      Sink sink,\n+      MetricWriter metricWriter,\n+      int maxAggregates,\n+      int queueSize,\n+      long reportingInterval,\n+      TimeUnit timeUnit) {\n+    this.inbox = new MpscBlockingConsumerArrayQueue<>(queueSize);\n+    this.batchPool = new MpmcArrayQueue<>(maxAggregates);\n+    this.pending = new ConcurrentHashMap<>(maxAggregates * 4 / 3, 0.75f);\n+    this.sink = sink;\n+    this.aggregator =\n+        new Aggregator(\n+            metricWriter, batchPool, inbox, pending, maxAggregates, reportingInterval, timeUnit);\n+    this.thread = newAgentThread(METRICS_AGGREGATOR, aggregator);\n+  }\n+\n+  @Override\n+  public void start() {\n+    sink.register(this);\n+    thread.start();\n+  }\n+\n+  @Override\n+  public void publish(List<? extends DDSpanData> trace) {\n+    if (enabled) {\n+      for (DDSpanData span : trace) {\n+        if (span.isMeasured()) {\n+          publish(span);\n+        }\n+      }\n+    }\n+  }\n+\n+  private void publish(DDSpanData span) {\n+    boolean error = span.getError() > 0;\n+    long durationNanos = span.getDurationNano();\n+    MetricKey key =\n+        new MetricKey(span.getResourceName(), span.getServiceName(), span.getOperationName(), 0);\n+    Batch batch = pending.get(key);\n+    if (null != batch) {\n+      if (batch.add(error, durationNanos)) {\n+        // added to a pending batch, skip the queue\n+        return;\n+      }\n+    }\n+    batch = newBatch(key);\n+    batch.add(error, durationNanos);\n+    // overwrite the last one if present, it's already full", "originalCommit": "4d4a4b1de6eb8270d9b0bc7fae71452677fe0b8f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk2OTcyMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521969720", "bodyText": "So the errorMask is not used, but I guess this is the place where the separation of error and normal durations would happen.", "author": "bantonsson", "createdAt": "2020-11-12T09:43:02Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/AggregateMetric.java", "diffHunk": "@@ -0,0 +1,42 @@\n+package datadog.trace.common.metrics;\n+\n+public final class AggregateMetric {\n+  private int errorCount;\n+  private int hitCount;\n+  private long duration;\n+\n+  public AggregateMetric addHits(int count) {\n+    hitCount += count;\n+    return this;\n+  }\n+\n+  public AggregateMetric addErrors(int count) {\n+    errorCount += count;\n+    return this;\n+  }\n+\n+  public AggregateMetric recordDurations(long errorMask, long... durations) {", "originalCommit": "4d4a4b1de6eb8270d9b0bc7fae71452677fe0b8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk3ODkzOQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r521978939", "bodyText": "yes exactly", "author": "richardstartin", "createdAt": "2020-11-12T09:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk2OTcyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE3NjI4MQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r522176281", "bodyText": "Since this class seems specific to metrics/stats, consider clarifying that in the class name.", "author": "tylerbenson", "createdAt": "2020-11-12T15:06:39Z", "path": "dd-trace-core/src/main/java/datadog/trace/common/metrics/OkHttpSink.java", "diffHunk": "@@ -0,0 +1,76 @@\n+package datadog.trace.common.metrics;\n+\n+import static datadog.trace.common.metrics.EventListener.EventType.BAD_PAYLOAD;\n+import static datadog.trace.common.metrics.EventListener.EventType.DOWNGRADED;\n+import static datadog.trace.common.metrics.EventListener.EventType.ERROR;\n+import static datadog.trace.common.metrics.EventListener.EventType.OK;\n+import static datadog.trace.core.http.OkHttpUtils.buildHttpClient;\n+import static datadog.trace.core.http.OkHttpUtils.msgpackRequestBodyOf;\n+import static datadog.trace.core.http.OkHttpUtils.prepareRequest;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CopyOnWriteArrayList;\n+import okhttp3.HttpUrl;\n+import okhttp3.OkHttpClient;\n+\n+public final class OkHttpSink implements Sink, EventListener {", "originalCommit": "45ab6e3055da3f44487b6ff48f7947212d40cc20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjIxNzk0Nw==", "url": "https://github.com/DataDog/dd-trace-java/pull/2060#discussion_r522217947", "bodyText": "I aim for its responsibilities to grow until it strangles the other one which got a bit bent out of shape at some point", "author": "richardstartin", "createdAt": "2020-11-12T15:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE3NjI4MQ=="}], "type": "inlineReview"}, {"oid": "cc8db33b2a7c27747783f57c6317a9d632723719", "url": "https://github.com/DataDog/dd-trace-java/commit/cc8db33b2a7c27747783f57c6317a9d632723719", "message": "track hit and error count metrics", "committedDate": "2020-11-12T21:03:06Z", "type": "commit"}, {"oid": "a21fe73e0f1e07c0cc49c490418a9659606ec621", "url": "https://github.com/DataDog/dd-trace-java/commit/a21fe73e0f1e07c0cc49c490418a9659606ec621", "message": "factor out messagepack payloads from DDAgentApi", "committedDate": "2020-11-12T21:03:06Z", "type": "commit"}, {"oid": "308042c283cccd1deae77c88d561c0effcce4856", "url": "https://github.com/DataDog/dd-trace-java/commit/308042c283cccd1deae77c88d561c0effcce4856", "message": "add a unit test for WellKnownTags", "committedDate": "2020-11-12T21:03:06Z", "type": "commit"}, {"oid": "39e944786c6e97fd610b8162deed66b3d63d1060", "url": "https://github.com/DataDog/dd-trace-java/commit/39e944786c6e97fd610b8162deed66b3d63d1060", "message": "clarifications", "committedDate": "2020-11-12T21:03:06Z", "type": "commit"}, {"oid": "8172b4bcffb934925a413bfb58c57206e8ded2f9", "url": "https://github.com/DataDog/dd-trace-java/commit/8172b4bcffb934925a413bfb58c57206e8ded2f9", "message": "fix small performance problem with UTF8ByteString as used in MetricKey by returning to lazy evaluation", "committedDate": "2020-11-12T21:10:26Z", "type": "commit"}, {"oid": "8172b4bcffb934925a413bfb58c57206e8ded2f9", "url": "https://github.com/DataDog/dd-trace-java/commit/8172b4bcffb934925a413bfb58c57206e8ded2f9", "message": "fix small performance problem with UTF8ByteString as used in MetricKey by returning to lazy evaluation", "committedDate": "2020-11-12T21:10:26Z", "type": "forcePushed"}]}