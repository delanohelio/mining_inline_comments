{"pr_number": 1660, "pr_title": "GG-31094: cluster wide collection", "pr_createdAt": "2020-12-16T14:10:59Z", "pr_url": "https://github.com/gridgain/gridgain/pull/1660", "timeline": [{"oid": "c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "url": "https://github.com/gridgain/gridgain/commit/c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "message": "GG-31027: Statistics storage implementation", "committedDate": "2020-11-23T13:55:33Z", "type": "commit"}, {"oid": "fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "url": "https://github.com/gridgain/gridgain/commit/fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31027", "committedDate": "2020-11-23T16:17:37Z", "type": "commit"}, {"oid": "652ab10b366070d91d2396b14dfc2cfad786f99f", "url": "https://github.com/gridgain/gridgain/commit/652ab10b366070d91d2396b14dfc2cfad786f99f", "message": "GG-31027: minor autotests fixes", "committedDate": "2020-11-24T10:56:39Z", "type": "commit"}, {"oid": "9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "url": "https://github.com/gridgain/gridgain/commit/9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "message": "GG-31094: add messages to collect and clear statistics cluster wide.", "committedDate": "2020-12-07T13:56:53Z", "type": "commit"}, {"oid": "593ddab1a7c8c9eb84af8c04e252381a5edae79b", "url": "https://github.com/gridgain/gridgain/commit/593ddab1a7c8c9eb84af8c04e252381a5edae79b", "message": "GG-31094: cluster wide statistics collection routine", "committedDate": "2020-12-16T14:05:25Z", "type": "commit"}, {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "url": "https://github.com/gridgain/gridgain/commit/3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "message": "GG-31094: small fixes", "committedDate": "2020-12-16T14:20:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3MTg1Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545371853", "bodyText": "FYI: You can try IntMap instead of HashMap for per-partition stats. It can be a bit more efficient.", "author": "AMashenkov", "createdAt": "2020-12-17T20:08:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteLogger;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsInMemoryStoreImpl implements IgniteStatisticsStore {\n+    /** Table -> Partition -> Partition Statistics map, populated only on server nodes without persistence enabled. */\n+    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n+", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY4NzM3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545687371", "bodyText": "Ok, fixed.", "author": "Berkof", "createdAt": "2020-12-18T09:08:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3MTg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3Nzg5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545377895", "bodyText": "Let's move this method to the listener object, like it is done for nodeLeft event.", "author": "AMashenkov", "createdAt": "2020-12-17T20:19:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY4OTIxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545689217", "bodyText": "Why? It handle a lot of messages not related with topology change: cancel request, collect request, stas propagation and so on.", "author": "Berkof", "createdAt": "2020-12-18T09:10:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3Nzg5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQyNzMzOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545427338", "bodyText": "Why is colNames a part of StatsKeyMessage, but not a part of StatsKey?", "author": "AMashenkov", "createdAt": "2020-12-17T21:53:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5MDQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545690409", "bodyText": "Because we store statistics by object, aquire statistics by whole object, but we can send request to collect statistics by only some of the tables columns.", "author": "Berkof", "createdAt": "2020-12-18T09:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQyNzMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNDcwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545434707", "bodyText": "Statistic is collected by a 'key' not by a 'message', right?", "author": "AMashenkov", "createdAt": "2020-12-17T22:07:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5MjA1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545692052", "bodyText": "No, we just store and aquire statistics by whole object (by StatsKey), but we can collect and clear it with column granularity (by StatsKeyMessage).", "author": "Berkof", "createdAt": "2020-12-18T09:13:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNDcwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545435438", "bodyText": "Why do we need to pass a Cancel supplier as it look like method is executed synchronously?", "author": "AMashenkov", "createdAt": "2020-12-17T22:09:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNjA0OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545436048", "bodyText": "Can statistic be calculated for partitions in parallel?", "author": "AMashenkov", "createdAt": "2020-12-17T22:10:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5NjQ5MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545696491", "bodyText": "We pass cancelled to allow to cancel such collection while it works. It'll happen when CancelStatisticsCollectionRequest received. Here cancelled - is just wrapper around statistics collection status doneFuture. So to cancel collection we'll just get status from current collection map and mark it's future as cancelled (and remove status from current map so worker won't event find it there and stop request processing).", "author": "Berkof", "createdAt": "2020-12-18T09:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5OTM0MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545699340", "bodyText": "For now - no, all collection made by single thread from IgniteStatisticsManagerImpl.statMgmtPool. Only cancel and reschedule operation can be conducted in parallel (but not for single object during synchronization). But in general - it should be possible to collect statistics in parallel.", "author": "Berkof", "createdAt": "2020-12-18T09:20:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzOTM4OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545439388", "bodyText": "Is aggregated statistics can be updated only after all partitions were processed only?\nWhat if we got updates from primary? Will we update aggregates instantly?\nIf so, why we can't update aggregates after every single local partition is processed?", "author": "AMashenkov", "createdAt": "2020-12-17T22:17:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTcwNDU1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545704554", "bodyText": "\"Is aggregated statistics can be updated only after all partitions were processed only?\"\nYes and no. Yes, because aggregated statistics  should only contains specified in collection request partitions (to allow correctly aggregate global statistics). And no, because as local statistics it can became outdated (if some partition left current node during collection). I don't cover such scenario.\n\"What if we got updates from primary?\"\nLocal level statistics contains statistics only from primary partitions. So if node will receive any partition propagation from another nodes - it won't affect local statistics at all.", "author": "Berkof", "createdAt": "2020-12-18T09:26:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzOTM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ0MjgyNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545442825", "bodyText": "Method 'sendPartitionStatisticsToBackupNodes' name would look more expressive.\nI believe method name should has exact meaning, in opposite to variable, that can be short as variable exists in much narrower scope.", "author": "AMashenkov", "createdAt": "2020-12-17T22:24:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTcwNTQ2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545705468", "bodyText": "OK", "author": "Berkof", "createdAt": "2020-12-18T09:27:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ0MjgyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MDk3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545450970", "bodyText": "return Arrays.stream(cols).filter(colNamesSet::contains).toArray()", "author": "AMashenkov", "createdAt": "2020-12-17T22:41:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTczNjY3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545736678", "bodyText": "OK", "author": "Berkof", "createdAt": "2020-12-18T10:20:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MDk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1Mjg2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545452868", "bodyText": "What is 'doneFut' future purpose? Why we pass a future to status object constructor from outside?", "author": "AMashenkov", "createdAt": "2020-12-17T22:45:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTczODM2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545738367", "bodyText": "It need to async collection and to cancel started collection. But yes, no reason to pass it from the outside. Fixed.", "author": "Berkof", "createdAt": "2020-12-18T10:23:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1Mjg2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MzczOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545453739", "bodyText": "Does \"colId\" mean \"collectionId\" or mean \"columnId\", like a \"colNames\" means column names?", "author": "AMashenkov", "createdAt": "2020-12-17T22:47:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAxMDI3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555010271", "bodyText": "each colId was renamed to gatId (gathering id) to prevent such misunderstandings.", "author": "Berkof", "createdAt": "2021-01-11T12:23:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MzczOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NjIxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545456213", "bodyText": "What does 'sendLocalRequests' mean? Why 'local'?", "author": "AMashenkov", "createdAt": "2020-12-17T22:52:55Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0MTQ0NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545741445", "bodyText": "I thought about locallity of requests. All of them should either collect or cancel local operations. But let it be just sendRequests.", "author": "Berkof", "createdAt": "2020-12-18T10:28:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NjIxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545457255", "bodyText": "'status' doesn't reflect it's role here.\nIt is actually a context of current task\\operation.", "author": "AMashenkov", "createdAt": "2020-12-17T22:54:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1ODU5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545458599", "bodyText": "I would think we just created requests to 'reqs' map. but why we looking for local-node-request in status.remaining().\nI can't figure out how we get there.", "author": "AMashenkov", "createdAt": "2020-12-17T22:57:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0NzUxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545747517", "bodyText": "Why 'status' doesn't fit here? Main purpouse of these function is just to send requests by specified status and update status with sended requests. So it's both status (in general it still represent the state of collection operation) and context (collectObjectStatistics update it with sended requests).\nYour comment a little bit outdated in second part, but I'll describe current situation:\n\nreqs  = currCollections.generateCollectionRequests(...   - we generate requests which should be sended ideally.\nfailedMsgs = sendRequests(reqs)    - we try to send as many requests as possible and return failed ones. BUT we didn't even try to send request to the local node. So it's no way to fail it.\nsendedMsgs = reqs minus failed. - If local node should participate in collection - the request will be in sendedMsg\nstatsu.remainingCollectReqs().putAll(sendedMsgs) - will add local collection request with others to status, so we may get it from here.", "author": "Berkof", "createdAt": "2020-12-18T10:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1OTEzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545459136", "bodyText": "localNodeId is available via KernalConext.localNodeId().", "author": "AMashenkov", "createdAt": "2020-12-17T22:59:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0ODIxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545748213", "bodyText": "Cool, I'll use it. Fixed", "author": "Berkof", "createdAt": "2020-12-18T10:41:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1OTEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NDQ3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545464478", "bodyText": "I think MOVING partitions can be safely skipped here.\nThere is no need to wait for preloader synchronously, you can subscribe to the future and reschedule statistic gathering once it's done.", "author": "AMashenkov", "createdAt": "2020-12-17T23:09:16Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n \n-        Column[] selectedColumns;\n-        boolean fullStat;\n-        if (F.isEmpty(colNames)) {\n-            fullStat = true;\n-            selectedColumns = tbl.getColumns();\n+        synchronized (status) {\n+            currCollections.put(colId, status);\n+            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n+                status.doneFut().cancel();\n+                currCollections.remove(colId);\n+                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+            }\n         }\n-        else {\n-            fullStat = false;\n-            selectedColumns = filterColumns(tbl.getColumns(), colNames);\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+\n+        doneFut.get();\n+        */\n+\n+//\n+//        StatsKey key = new StatsKey(schemaName, objName);\n+//\n+//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n+//\n+//        assert grpContexts.size() == 1;\n+//\n+//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n+//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n+//\n+//        synchronized (status) {\n+//            currCollections.put(colId, status);\n+//\n+//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//\n+//            if (failedReqs != null) {\n+//                for (UUID failedReqId : failedReqs.keySet())\n+//                    status.remainingCollectionReqs().remove(failedReqId);\n+//\n+//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n+//\n+//                assert failedPartIds.size() == 1;\n+//\n+//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n+//\n+//                assert newPartIds != null;\n+//\n+//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n+//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n+//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n+//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//                if (newFailedReqs != null) {\n+//                    doneFut.cancel();\n+//\n+//                    // TODO: is it safe?\n+//                    currCollections.remove(colId);\n+//\n+//                    throw new IgniteCheckedException(String.format(\n+//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n+//                            newFailedReqs.size(), colId));\n+//                }\n+//                status.remainingCollectionReqs().putAll(newReqs);\n+//\n+//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n+//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n+//            }\n+//            UUID locNode = ctx.discovery().localNode().id();\n+//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n+//            if (locReq != null)\n+//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+//\n+//        }\n+//\n+//        doneFut.get();\n+    }\n+\n+    /**\n+     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n+     * into currCollections map. REMOVE!!!!\n+     *\n+     * @param status Status to process.\n+     * @param keys Collection of object keys to collect statistics by.\n+     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n+     * status from cullCollections.\n+     */\n+    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n+                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n+\n         }\n+        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n \n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedColumns);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedColumns, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.remainingCollectionReqs().putAll(reqs);\n+\n+        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+        // TODO: cycle replanning and sending\n+        return failedReqs.isEmpty();\n+\n+         */\n+        return false;\n+    }\n+\n+    /**\n+     * Group request by target node id. REMOVE!!!!\n+     *\n+     * @param reqsByGrps Requests to compress, map.\n+     * @return Grouped requests.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> compressRequests(List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps) {\n+        // NodeId to base request map\n+        Map<UUID, StatsCollectionAddrRequest> reqByNode = new HashMap<>();\n+        for (Map<UUID, StatsCollectionAddrRequest> grpReqs : reqsByGrps)\n+            for (StatsCollectionAddrRequest addReq : grpReqs.values())\n+                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n+\n+        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n+            Map.Entry::getValue));\n+    }\n+\n+    /**\n+     * Add keys from add request to the base one and return it.\n+     *\n+     * @param base Base request to add to.\n+     * @param add Add request to add.\n+     * @return Request with all keys from both specified.\n+     */\n+    protected StatsCollectionAddrRequest addKey(StatsCollectionAddrRequest base, StatsCollectionAddrRequest add) {\n+        assert base.nodeId().equals(add.nodeId());\n+\n+        base.req().keys().putAll(add.req().keys());\n+        return base;\n+    }\n+\n+\n+    /**\n+     * Prepare statistics collection request for each nodes. MOVED!!!!\n+     *\n+     * @param colId Collection id.\n+     * @param keyMsg Key to collect statistics by.\n+     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n+     * @return Map: request id to statistics collection addressed request.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> _____prepareRequests(\n+            UUID colId,\n+            StatsKeyMessage keyMsg,\n+            Map<UUID, List<Integer>> reqNodes\n+    ) {\n+        Map<UUID, StatsCollectionAddrRequest> res = new HashMap<>(reqNodes.size());\n+        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n+            UUID reqId = UUID.randomUUID();\n+            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n+                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+            StatsCollectionAddrRequest addrReq = new StatsCollectionAddrRequest(colReq, reqNode.getKey());\n+            res.put(reqId, addrReq);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * TODO\n+     */\n+    public void stop() {\n+        if (statMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n     }\n \n     /**\n      * Collect partition level statistics.\n      *\n      * @param tbl Table to collect statistics by.\n-     * @param selectedColumns Columns to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n      * @return Collection of partition level statistics by local primary partitions.\n      * @throws IgniteCheckedException in case of error.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(GridH2Table tbl, Column[] selectedColumns)\n-            throws IgniteCheckedException {\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n         List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n         GridH2RowDescriptor desc = tbl.rowDescriptor();\n         String tblName = tbl.getName();\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n             final boolean reserved = locPart.reserve();\n \n             try {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA2ODUxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557068510", "bodyText": "skipped", "author": "Berkof", "createdAt": "2021-01-14T06:26:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NDQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NTI4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545465287", "bodyText": "Let's remove redundant method.", "author": "AMashenkov", "createdAt": "2020-12-17T23:11:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -225,51 +679,58 @@ public IgniteStatisticsRepository statisticsRepository() {\n      * @param tblPartStats Collection of all local partition level statistics by specified key.\n      * @return Local level aggregated statistics.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> tblPartStats) {\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatsKey key,\n+            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n+    ) {\n         // For now there can be only tables\n-        GridH2Table table = schemaMgr.dataTable(key.schema(), key.obj());\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n \n-        if (table == null) {\n+        if (tbl == null) {\n             // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n+                        key.schema(), key.obj()));\n+\n             statsRepos.clearLocalPartitionsStatistics(key);\n         }\n-        return aggregateLocalStatistics(table, table.getColumns(), tblPartStats);\n+        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n     }\n \n     /**\n      * Aggregate partition level statistics to local level one.\n      *\n      * @param tbl Table to aggregate statistics by.\n-     * @param selectedColumns Columns to aggregate statistics by.\n+     * @param selectedCols Columns to aggregate statistics by.\n      * @param tblPartStats Collection of partition level statistics.\n      * @return Local level statistics.\n      */\n     private ObjectStatisticsImpl aggregateLocalStatistics(\n             GridH2Table tbl,\n-            Column[] selectedColumns,\n+            Column[] selectedCols,\n             Collection<ObjectPartitionStatisticsImpl> tblPartStats\n     ) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2NjczMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545766730", "bodyText": "Sure, I'll clean the class. But this particular method isn't redundant as fas as I see.", "author": "Berkof", "createdAt": "2020-12-18T11:17:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NTI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MDU1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545470559", "bodyText": "Why a MOVING partition ignores incoming statistics from? It is feasible primary or backup.\nIf first then we will need to recalculate statistics, in other words make the job twice.\nIf second - we'll loose statistics?", "author": "AMashenkov", "createdAt": "2020-12-17T23:24:01Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAxNTI3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555015271", "bodyText": "Please take a look at current solution. I'll try to scan only local primary partitions. If some partitions wasn't collected on some node - they won't be in parts array in response and sender will reschedule they to some other node.", "author": "Berkof", "createdAt": "2021-01-11T12:32:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MDU1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTA5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545471099", "bodyText": "What does mean 'local' in method name?", "author": "AMashenkov", "createdAt": "2020-12-17T23:25:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2ODA5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545768099", "bodyText": "\"Level\" of statistics. There are partition, local and global statistics. Yes, strictly it can be not exactly local statistics, if there are some rescheduling during whole process, but in general receiveLocalStatistics method should receive collected \"local\" statistics and try to finalyze statistics collection process.", "author": "Berkof", "createdAt": "2020-12-18T11:20:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTA5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545475511", "bodyText": "As I understand StatsGetRequest is just return current aggregated statistics and doesn't trigger gathering new stats, right?\nThis is a different floew and may be we need a separate component for this.", "author": "AMashenkov", "createdAt": "2020-12-17T23:36:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NjI2Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545476266", "bodyText": "Moreover Statistics processor can be started on client node, but it could process only StatGet responses while other messages are not relevant for client node, right?", "author": "AMashenkov", "createdAt": "2020-12-17T23:38:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2OTg0MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545769841", "bodyText": "I'm not sure about it, we can run statistics collection from client node and so StatisticsManager will handle most of it's messages even on client. But then we should send aggregated statistics back to some server node.", "author": "Berkof", "createdAt": "2020-12-18T11:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545477739", "bodyText": "You can use @IgniteLogger annotation and call kernalContext.resource().inject() from outside.", "author": "AMashenkov", "createdAt": "2020-12-17T23:42:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3MDY1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545770658", "bodyText": "Will it works for unit tests?", "author": "Berkof", "createdAt": "2020-12-18T11:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NDY0Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549364647", "bodyText": "Sure, see IgniteTestResources and GridAbstractTest.getTestResources()", "author": "AMashenkov", "createdAt": "2020-12-28T14:21:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU5NjU2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559596568", "bodyText": "I'll fix it in next statistics related PR", "author": "Berkof", "createdAt": "2021-01-18T14:17:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545479751", "bodyText": "Is it ever unregistered?", "author": "AMashenkov", "createdAt": "2020-12-17T23:47:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.db = db;\n+        this.repo = repo;\n+        subscriptionProcessor.registerMetastorageListener(this);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDc1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545480758", "bodyText": "This statistic store either should have lifecycle methods or should be subscribed from outside?", "author": "AMashenkov", "createdAt": "2020-12-17T23:50:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3MzA1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545773052", "bodyText": "GridInternalSubscriptionProcessor events looks like one-time events and there are no methods like unregisterMetastorageListener at all. Neither have documentation on most of methods.", "author": "Berkof", "createdAt": "2020-12-18T11:30:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NjUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549366533", "bodyText": "Ok, as IgniteStatisticsPersistenceStoreImpl is a node single instance.", "author": "AMashenkov", "createdAt": "2020-12-28T14:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MzkxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545483911", "bodyText": "What the difference bw local and global stats?\nDoes it mean localStats contains only local per-partition raw statistics? or local aggregates as well?\nDoes it mean globalStats contains only aggregated cluster-wide statistics or raw remote partition stats as well?\nIf both contains raw partition statistics, can these collections has duplicates?\nI thought it make sense to store only raw statistics, and calculate aggregated on deman. Aggregated statistics can cached for performance purposes and thus can be easily invalidated.", "author": "AMashenkov", "createdAt": "2020-12-17T23:58:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -16,27 +16,32 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+import org.apache.ignite.internal.util.typedef.F;\n \n+import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Map;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n \n /**\n  * Statistics repository implementation.\n  */\n public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepository {\n     /** Logger. */\n-    private IgniteLogger log;\n+    private final IgniteLogger log;\n \n-    /** Statistics manager. */\n-    private final IgniteStatisticsManagerImpl statisticsManager;\n+    /** Statistics store. */\n+    private final IgniteStatisticsStore store;\n \n-    /** Table->Partition->Partition Statistics map, populated only on server nodes without persistence enabled. */\n-    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats;\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> localStats;\n+    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n \n     /** Global (for whole cluster) object statistics. */\n     private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3NjYzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545776633", "bodyText": "Partition level statistics contains per-partition statistics, but there are only two difference in statistics objects: partition one have update counter and partId additional fields.\nAnd yes, we store only partition level statistics and aggregate localOne from it and after aggregate global one from each local statistics.\nFor example:\nnode1 partId1 \"partition\" level statistics: min = 1, max = 10, nulls = 1, total=10, cord = 100, rawCord = byte[]...; updCnt=10, partId=1\nnode1 part2 \"partition\" level statistics: min = 11, max = 21, nulls = 1, total=10, cord = 100, rawCord = byte[]...; updCnt=12, partId=2\nnode2 part3 \"partition\" level statistics: min = 1, max = 200, nulls = 3, total=10, cord = 100, rawCord = byte[]...; updCnt=19, partId=3\nSo after aggregation we'll get \"local\" statistics:\nnode1 \"local\" level statistics: min = 1, max = 21, nulls = 2, total=20, cord = 100, rawCord = byte[]...;\nnode2 \"local\" level statistics: min = 1, max = 200, nulls = 3, total=10, cord = 100, rawCord = byte[]...;\nAnd after final aggregation to global one:\n\"global\" level statistics: min = 1, max = 200, nulls = 5, total=30, cord = 98, rawCord = byte[]...;", "author": "Berkof", "createdAt": "2020-12-18T11:38:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MzkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTI3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485276", "bodyText": "Let's pass correct implementation from outside.", "author": "AMashenkov", "createdAt": "2020-12-18T00:02:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3ODIxMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545778212", "bodyText": "But earlier we decided that implementation can be selected by existence of the database. And in which situation we could pass different store here?", "author": "Berkof", "createdAt": "2020-12-18T11:41:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTI3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485875", "bodyText": "Does it make sense to have dummy repository implementation or may be do not create it on client node at all?", "author": "AMashenkov", "createdAt": "2020-12-18T00:03:53Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n+                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n+\n+            locStats = new ConcurrentHashMap<>();\n         }\n         else {\n             // Cache only global statistics, no store\n-            partsStats = null;\n-            localStats = null;\n-        }\n-        this.statisticsManager = statisticsManager;\n-        this.log = log;\n-    }\n-\n-    /**\n-     * Convert collection of partition level statistics into map(partId->partStatistics).\n-     *\n-     * @param key Object key.\n-     * @param statistics Collection of tables partition statistics.\n-     * @return Partition id to statistics map.\n-     */\n-    private Map<Integer, ObjectPartitionStatisticsImpl> buildStatisticsMap(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> statistics\n-    ) {\n-        Map<Integer, ObjectPartitionStatisticsImpl> statisticsMap = new ConcurrentHashMap<>();\n-        for (ObjectPartitionStatisticsImpl s : statistics) {\n-            if (statisticsMap.put(s.partId(), s) != null)\n-                log.warning(String.format(\"Trying to save more than one %s.%s partition statistics for partition %d\",\n-                        key.schema(), key.obj(), s.partId()));\n+            store = null;", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NjA4NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545486084", "bodyText": "\"if (store==null) return\" in every method looks ugly.", "author": "AMashenkov", "createdAt": "2020-12-18T00:04:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MDI4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545780287", "bodyText": "Yes, we can have a dummy implementation for the client nodes. But there are locStats map too, so part of such ugly tests staing even after that.", "author": "Berkof", "createdAt": "2020-12-18T11:46:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NzIzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545487233", "bodyText": "Confusing javadoc.", "author": "AMashenkov", "createdAt": "2020-12-18T00:07:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MTQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545781409", "bodyText": "Tried to improve.", "author": "Berkof", "createdAt": "2020-12-18T11:48:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NzIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODAwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488008", "bodyText": "Method is declared as to add a collection, but got 'status'.", "author": "AMashenkov", "createdAt": "2020-12-18T00:10:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MjM1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545782358", "bodyText": "It was about statistics collection status. I renamed it.", "author": "Berkof", "createdAt": "2020-12-18T11:50:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODAwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODQzNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488434", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Thread safe update of statistics collection.\n          \n          \n            \n                 * Update status of statistic gathering task", "author": "AMashenkov", "createdAt": "2020-12-18T00:11:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MzIxNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545783215", "bodyText": "Fixed", "author": "Berkof", "createdAt": "2020-12-18T11:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODQzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDAxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545490017", "bodyText": "What if one of cache was stopped somewhen in between, but other are operational?\nWill statistics task result be thrown away or task crashed?", "author": "AMashenkov", "createdAt": "2020-12-18T00:16:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4Mzg3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545783872", "bodyText": "For now - whole task should be cancelled. I'll check it...", "author": "Berkof", "createdAt": "2020-12-18T11:53:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDAxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545491409", "bodyText": "Can we be sure both arrays are sorted?\nIf so, intersect will of sorted arrays is trivial.\nOr may be BitSet fits your needs better?", "author": "AMashenkov", "createdAt": "2020-12-18T00:20:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsCollectionAddrRequest> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsCollectionAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array.\n+     * @param b Second array.\n+     * @return Arrays intersection.\n+     */\n+    protected static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwMTczMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557401731", "bodyText": "Code removed.", "author": "Berkof", "createdAt": "2021-01-14T13:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTQwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjQ1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545492451", "bodyText": "Why 'local'?\nDoes it mean we store statistics for local partitions only? primary or backups or both?\nMay it worth to rename the interface itself?", "author": "AMashenkov", "createdAt": "2020-12-18T00:23:17Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import java.util.Collection;\n+\n+/**\n+ * Statistics store interface.\n+ */\n+public interface IgniteStatisticsStore {\n+    /**\n+     * Clear statistics of any type for any objects;\n+     */\n+    public void clearAllStatistics();\n+\n+    /**\n+     * Replace all tables partition statistics with specified ones.\n+     *\n+     * @param key Statistics key to replace statistics by.\n+     * @param statistics Collection of partition level statistics.\n+     */\n+    public void replaceLocalPartitionsStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> statistics);\n+\n+    /**\n+     * Get local partition statistics by specified object.\n+     *\n+     * @param key Key to get statistics by.\n+     * @return Collection of partitions statistics.\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> getLocalPartitionsStatistics(StatsKey key);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4NjMxMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545786312", "bodyText": "Because it should return only statistics for locals (both primary and backups) partitions.\nDidn't get the idea, what name you suppose?", "author": "Berkof", "createdAt": "2020-12-18T11:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjQ1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545496208", "bodyText": "Why it serializable?", "author": "AMashenkov", "createdAt": "2020-12-18T00:34:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java", "diffHunk": "@@ -15,17 +15,21 @@\n  */\n package org.apache.ignite.internal.processors.query.stat;\n \n+import java.io.Serializable;\n import java.util.Objects;\n \n /**\n  * Statistics key.\n  */\n-public class StatsKey {\n+public class StatsKey implements Serializable {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4NzE0NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545787144", "bodyText": "Obsolete implements, removed.", "author": "Berkof", "createdAt": "2020-12-18T12:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjIwOA=="}], "type": "inlineReview"}, {"oid": "ec4a9ef0e7691b605225c12527d496d07d573b42", "url": "https://github.com/gridgain/gridgain/commit/ec4a9ef0e7691b605225c12527d496d07d573b42", "message": "gg-31094: fix main issues with cluster wide collection", "committedDate": "2020-12-18T05:59:41Z", "type": "commit"}, {"oid": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "url": "https://github.com/gridgain/gridgain/commit/b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "message": "gg-31094: fix multiple local requests statistics handling.", "committedDate": "2020-12-18T07:30:11Z", "type": "commit"}, {"oid": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "url": "https://github.com/gridgain/gridgain/commit/d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "message": "gg-31094: minor fixes by review", "committedDate": "2020-12-18T12:23:00Z", "type": "commit"}, {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d", "url": "https://github.com/gridgain/gridgain/commit/671a2471ef7d2a50a01f45f09289202a9528221d", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2020-12-21T08:37:07Z", "type": "commit"}, {"oid": "adb2fc38f05374d597d32f3164fa444dec40cb8f", "url": "https://github.com/gridgain/gridgain/commit/adb2fc38f05374d597d32f3164fa444dec40cb8f", "message": "GG-31094: more tests on collection process", "committedDate": "2020-12-21T11:00:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3MTQ3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546671470", "bodyText": "it looks like statistics collection manager, so let's give it appropriate name", "author": "korlov42", "createdAt": "2020-12-21T12:09:41Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI4OTkxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556289913", "bodyText": "renamed", "author": "Berkof", "createdAt": "2021-01-13T06:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3MTQ3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3NDMyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546674323", "bodyText": "could be final", "author": "korlov42", "createdAt": "2020-12-21T12:16:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNDU4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555024583", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-11T12:50:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3NDMyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3OTYyMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546679622", "bodyText": "both invocations of locStatistics() assumes that locStatistics is always non null value", "author": "korlov42", "createdAt": "2020-12-21T12:29:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MDMyNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556290327", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T06:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3OTYyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY4Mjk2NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546682964", "bodyText": "constructor ConcurrentHashMap requires non null argument", "author": "korlov42", "createdAt": "2020-12-21T12:37:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MDUwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556290508", "bodyText": "removed from CollectionStatus", "author": "Berkof", "createdAt": "2021-01-13T06:32:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY4Mjk2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NTM5Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546695392", "bodyText": "possible NPE here", "author": "korlov42", "createdAt": "2020-12-21T13:07:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNDk3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555024976", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T12:51:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NTM5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjM3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696370", "bodyText": "btw it is not used anywhere, so let's remove it", "author": "korlov42", "createdAt": "2020-12-21T13:09:22Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0Mjk3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560042976", "bodyText": "now its used again", "author": "Berkof", "createdAt": "2021-01-19T09:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjM3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjYwMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696600", "bodyText": "possible NPE here", "author": "korlov42", "createdAt": "2020-12-21T13:09:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MzM5MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560043390", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-19T09:45:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzAzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697033", "bodyText": "this is not used as well", "author": "korlov42", "createdAt": "2020-12-21T13:10:52Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzEyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697129", "bodyText": "misspell in param name", "author": "korlov42", "createdAt": "2020-12-21T13:11:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjcwMzU0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546703549", "bodyText": "not used", "author": "korlov42", "createdAt": "2020-12-21T13:24:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);\n+        remainingColReqs.putAll(newReqs);\n+        remainingColReqs.remove(oldReqId);\n+    }\n+\n+    /**\n+     * Remove all requests to specified node id (due to its failure).\n+     *\n+     * @param nodeId node id to remove requests by.\n+     * @return Collection of removed requests.\n+     */\n+    public Collection<StatsCollectionRequest> removeNodeRequest(UUID nodeId) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546760623", "bodyText": "Is there any reason to have this as a field?", "author": "korlov42", "createdAt": "2020-12-21T15:12:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -18,35 +18,73 @@\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.function.Supplier;\n import java.util.stream.Collectors;\n \n import org.apache.ignite.IgniteCheckedException;\n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.GridCacheUtils;\n import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsPropagationMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsGetRequest;\n+import org.apache.ignite.internal.util.lang.GridTuple3;\n import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n \n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.MOVING;\n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n \n /**\n  * Statistics manager implementation.\n  */\n-public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n+public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Size of statistics collection pool. */\n+    private static final int STATS_POOL_SIZE = 1;\n+\n+    /** Node left listener to complete statistics collection tasks without left nodes. */\n+    private final NodeLeftListener nodeLeftLsnr;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1MDQyMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549350420", "bodyText": "My guess is the manager should be unsubscribed on stop\\deactivation.", "author": "AMashenkov", "createdAt": "2020-12-28T13:36:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjMzMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766331", "bodyText": "this class could be static", "author": "korlov42", "createdAt": "2020-12-21T15:23:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO\n+                    e.printStackTrace();\n+                }\n+\n+            }\n+            return null;\n+        });\n+    }\n+\n+    /**\n+     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n+     */\n+    private class NodeLeftListener implements GridLocalEventListener {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjcwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766709", "bodyText": "this should be part of NodeLeftListener", "author": "korlov42", "createdAt": "2020-12-21T15:23:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTM0NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025345", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Njg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766858", "bodyText": "commented code", "author": "korlov42", "createdAt": "2020-12-21T15:24:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTU4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025585", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Njg1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NzYwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767606", "bodyText": "uncertain TODO", "author": "korlov42", "createdAt": "2020-12-21T15:25:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTY5NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025694", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NzYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Nzg4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767883", "bodyText": "failedCollections is not used", "author": "korlov42", "createdAt": "2020-12-21T15:26:01Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MTg5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556291895", "bodyText": "fixed in StatisticsGatheringRequestCrawlerImpl", "author": "Berkof", "createdAt": "2021-01-13T06:36:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Nzg4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc3MjE1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546772150", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    currColls.keySet().forEach(k -> {\n          \n          \n            \n                        currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n          \n          \n            \n                    });\n          \n          \n            \n                    currColls.values().forEach(transformation::apply);", "author": "korlov42", "createdAt": "2020-12-21T15:33:44Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+*/\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Calculate node id to stats key map.\n+     *\n+     * @param groupKeys Cache group to stats key map.\n+     * @return Node id to stats key map.\n+     */\n+    public static Map<UUID, Set<StatsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> groupsKeys\n+    ) {\n+        Map<UUID, Set<StatsKeyMessage>> res = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> groupKeys : groupsKeys.entrySet()) {\n+            CacheGroupContext grp = groupKeys.getKey();\n+\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            for (List<ClusterNode> partNodes : assignments) {\n+                for (ClusterNode node : partNodes) {\n+                    res.compute(node.id(), (k, v) -> {\n+                        if (v == null)\n+                            v = new HashSet<>();\n+\n+                        v.addAll(groupKeys.getValue());\n+\n+                        return v;\n+                    });\n+                }\n+            }\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsClearRequest>> generateClearRequests(\n+        Collection<StatsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Set<StatsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+        List<StatsAddrRequest<StatsClearRequest>> res = new ArrayList<>(nodeKeys.size());\n+\n+        return nodeKeys.entrySet().stream().map(e -> new StatsAddrRequest<StatsClearRequest>(\n+                new StatsClearRequest(UUID.randomUUID(), new ArrayList<>(e.getValue())), e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest[] reqs) {\n+        Map<StatsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatsCollectionRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.colId());\n+            colId = req.colId();\n+\n+            for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Get failed partitions map from request and its response.\n+     *\n+     * @param req Request to get the original requested partitions from.\n+     * @param resp Response to get actually collected partitions.\n+     * @return Map of not collected partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest req, StatsCollectionResponse resp) {\n+        assert req.colId().equals(resp.colId());\n+\n+        Map<StatsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n+        for (Map.Entry<StatsObjectData, int[]> data : resp.data().entrySet())\n+            collected.put(data.getKey().key(), data.getValue());\n+\n+        Map<StatsKeyMessage, int[]> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n+\n+            if (failed.length > 0)\n+                res.put(keyEntry.getKey(), failed);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Apply specified transformation to each active statistics collection status.\n+     *\n+     * @param transformation Transformation to apply.\n+     */\n+    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.keySet().forEach(k -> {\n+            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n+        });", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4MzU4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546783587", "bodyText": "it's not a DR pool", "author": "korlov42", "createdAt": "2020-12-21T15:53:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +113,32 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        currCollections = new IgniteStatisticsRequestCollection(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n+        ctx.io().addMessageListener(TOPIC, this);\n+\n         boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n+\n         statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n                 ctx::log);\n+\n+        nodeLeftLsnr = new NodeLeftListener();\n+\n+        statMgmtPool = new IgniteThreadPoolExecutor(\"dr-mgmt-pool\",", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNzE4Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555027182", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T12:55:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4MzU4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784229", "bodyText": "commented code", "author": "korlov42", "createdAt": "2020-12-21T15:54:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMTAyMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556301020", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T07:02:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDU3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784572", "bodyText": "doneFut is not used", "author": "korlov42", "createdAt": "2020-12-21T15:55:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMDYwNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555030604", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDU3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NzEwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546787108", "bodyText": "sendRequests returns a list of failed request. Think there should be retries", "author": "korlov42", "createdAt": "2020-12-21T15:59:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMTY2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555031667", "bodyText": "send stand for communication wrapping only. To retry we, probably, need remap requests to new nodes.", "author": "Berkof", "createdAt": "2021-01-11T13:03:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NzEwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEzODcxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547138717", "bodyText": "unnecessary change", "author": "korlov42", "createdAt": "2020-12-22T08:32:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java", "diffHunk": "@@ -20,6 +20,7 @@\n \n import java.util.List;\n \n+", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjEyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032123", "bodyText": "sure, reverted", "author": "Berkof", "createdAt": "2021-01-11T13:04:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEzODcxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MDEyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547140124", "bodyText": "unused imports", "author": "korlov42", "createdAt": "2020-12-22T08:35:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -16,6 +16,19 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.util.collection.IntHashMap;\n+import org.apache.ignite.internal.util.collection.IntMap;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjUzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032536", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:05:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MDEyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547141024", "bodyText": "uncertain TODO", "author": "korlov42", "createdAt": "2020-12-22T08:37:27Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -197,6 +197,7 @@ public IgniteStatisticsRepositoryImpl(\n         store.clearLocalPartitionStatistics(key, partId);\n     }\n \n+    // TODO", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjY5Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032697", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T13:05:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzAzMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143031", "bodyText": "empty line", "author": "korlov42", "createdAt": "2020-12-22T08:41:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzM5Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143393", "bodyText": "closing tag is not needed, I suppose", "author": "korlov42", "createdAt": "2020-12-22T08:42:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2MTQxOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547161419", "bodyText": "comment in Russian", "author": "korlov42", "createdAt": "2020-12-22T09:18:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzODM3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555038377", "bodyText": "fired", "author": "Berkof", "createdAt": "2021-01-11T13:16:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2MTQxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164224", "bodyText": "this could be simplified by generating partition ids from assignments", "author": "korlov42", "createdAt": "2020-12-22T09:24:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMjMzMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556302332", "bodyText": "Sometimes we need primary, sometimes - backups, sometimes - only mapping for some specied partitions... now this code located in IgniteStatisticsHelper.nodePartitions. How I can simplify it?", "author": "Berkof", "createdAt": "2021-01-13T07:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMzc0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556313742", "bodyText": "for example like this:\n`\n    if (partIds == null)\n        partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n\n    for (Integer partId : partIds)\n        fillPartition(res, assignments, partId, isPrimary);`", "author": "korlov42", "createdAt": "2021-01-13T07:33:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwMjY3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557402671", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-14T13:42:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDcwMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164700", "bodyText": "commented code", "author": "korlov42", "createdAt": "2020-12-22T09:25:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b595e90b5b480aaf80a9256558b1841334df97de", "url": "https://github.com/gridgain/gridgain/commit/b595e90b5b480aaf80a9256558b1841334df97de", "message": "GG-31094: fix message processing, some new tests, batch cleaning", "committedDate": "2020-12-22T11:27:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzIyNzE3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547227177", "bodyText": "Actually, function return nothing.", "author": "AMashenkov", "createdAt": "2020-12-22T11:34:08Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini", "originalCommit": "b595e90b5b480aaf80a9256558b1841334df97de", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMzUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556303533", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T07:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzIyNzE3Nw=="}], "type": "inlineReview"}, {"oid": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "url": "https://github.com/gridgain/gridgain/commit/29e078f2df2c845f1d97ba432d2033c88bdf6464", "message": "GG-31094: rename classes, implement dummy statistics storage", "committedDate": "2020-12-23T13:22:00Z", "type": "commit"}, {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "url": "https://github.com/gridgain/gridgain/commit/ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "message": "GG-31094: main refactoring changes", "committedDate": "2020-12-25T14:03:45Z", "type": "commit"}, {"oid": "5ab0edf44f29bc0c45770c111905807af1982eb2", "url": "https://github.com/gridgain/gridgain/commit/5ab0edf44f29bc0c45770c111905807af1982eb2", "message": "GG-31094: refactoring of message processing", "committedDate": "2020-12-28T13:28:33Z", "type": "commit"}, {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727", "url": "https://github.com/gridgain/gridgain/commit/f03f0e0216f93edace9e8347eddc6ee68388c727", "message": "GG-31094: fixes", "committedDate": "2020-12-28T13:31:08Z", "type": "commit"}, {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "url": "https://github.com/gridgain/gridgain/commit/a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "message": "GG-31094: fix handling local statistics results (StatsGatheringResponse)", "committedDate": "2020-12-28T15:24:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNDcyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549314721", "bodyText": "I don't think GridTuple3 is a correct key type for a map.\nActually,  (new String[]{\"1\"}).equals(new String[]{\"1\"})  will always return \"fase\".", "author": "AMashenkov", "createdAt": "2020-12-28T11:30:25Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwNDI0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556304242", "bodyText": "Had to duplicate StatisticsKeyMessage as StatisticsTarget because Message shouldn't be in core interface and messages shouldn't inherit fields. Fixed", "author": "Berkof", "createdAt": "2021-01-13T07:11:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNDcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNjA5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549316096", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /**\n          \n          \n            \n             * Future to track statistics collection task. Allows to get collection id immediately.\n          \n          \n            \n             * @param <T>\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Statistics collection id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID colId();\n          \n          \n            \n            /**\n          \n          \n            \n             * Future to track gathering statistics task.\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatisticsGatheringTaskFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Task id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID taskId();\n          \n      \n    \n    \n  \n\nActually, it is just a task future.\nGeneric type is not specified, I think we can use certain type here instead of generic.", "author": "AMashenkov", "createdAt": "2020-12-28T11:35:32Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Future to track statistics collection task. Allows to get collection id immediately.\n+ * @param <T>\n+ */\n+public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n+    /**\n+     * @return Statistics collection id.\n+     */\n+    public UUID colId();", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMzI0Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556313246", "bodyText": "Committed", "author": "Berkof", "createdAt": "2021-01-13T07:32:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNjA5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDcwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324709", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n          \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> mapToCacheGroup(Collection<StatisticsKeyMessage> keys)", "author": "AMashenkov", "createdAt": "2020-12-28T12:07:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3OTY5Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559579693", "bodyText": "Renamed to mapToCacheGroups", "author": "Berkof", "createdAt": "2021-01-18T13:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDcwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDg1Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324856", "bodyText": "Invalid HTML tags.", "author": "AMashenkov", "createdAt": "2020-12-28T12:08:02Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA0NzA2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555047069", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:30:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDg1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325229", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "author": "AMashenkov", "createdAt": "2020-12-28T12:09:27Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325368", "bodyText": "Braces.", "author": "AMashenkov", "createdAt": "2020-12-28T12:09:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNTk3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556415970", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T10:26:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NDc3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556464775", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T11:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325399", "bodyText": "Braces", "author": "AMashenkov", "createdAt": "2020-12-28T12:10:02Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNjA0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556416043", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T10:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNjg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549326858", "bodyText": "\"requests will be\".. will be what?", "author": "AMashenkov", "createdAt": "2020-12-28T12:15:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNjk4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556416980", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T10:28:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNjg1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyODk3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549328974", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n          \n          \n            \n                                Collection<StatisticsKeyMessage> grpValues= grpEntry.getValue();", "author": "AMashenkov", "createdAt": "2020-12-28T12:23:16Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMzMzIwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549333206", "bodyText": "Using StatisticsKey->partitions leads to collections analyzing\\filtering\\copying that very hard to understand.\nMethod overall complexity is too high.\nCan this relation be turned into partition->StatisticKeys ?\nFor all keys that relates to same cache group you will do same actions that looks trivial with Partition->StatisticKeys.\nI thinks nodePartitions method result is useless, failedPartitions could be transformed to partition->statisticKeys, then the result can be easily mapped to nodes.", "author": "AMashenkov", "createdAt": "2020-12-28T12:38:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxODY4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556418687", "bodyText": "replaced with gathering task per cache group, so now there is only one partitions collection.", "author": "Berkof", "createdAt": "2021-01-13T10:31:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMzMzIwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MTg4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549341885", "bodyText": "Topology version is shared for all cache groups.", "author": "AMashenkov", "createdAt": "2020-12-28T13:07:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjIyOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342228", "bodyText": "Javadoc is not actual.", "author": "AMashenkov", "createdAt": "2020-12-28T13:08:52Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjU0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342543", "bodyText": "empty line", "author": "AMashenkov", "createdAt": "2020-12-28T13:09:53Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjY0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342642", "bodyText": "Javadoc missed.", "author": "AMashenkov", "createdAt": "2020-12-28T13:10:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjkwMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342901", "bodyText": "Arrays.asList() ?", "author": "AMashenkov", "createdAt": "2020-12-28T13:11:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1NzAzNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549357034", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    else if (db == null)\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n          \n          \n            \n                    else if (!GridCacheUtils.isPersistenceEnabled(ctx.config()))\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(),  ctx.cache().context().database(), ctx::log);", "author": "AMashenkov", "createdAt": "2020-12-28T13:57:56Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MTMxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549371310", "bodyText": "Javadoc", "author": "AMashenkov", "createdAt": "2020-12-28T14:41:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA1MTg1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555051859", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-11T13:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MTMxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MzAxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549373017", "bodyText": "Is it expected request will be processed in Query Pool?", "author": "AMashenkov", "createdAt": "2020-12-28T14:46:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n+\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+            }\n+        }\n+        while (failedPartitions != null);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringRequestsAsync(UUID gatId, Collection<StatisticsKeyMessage> keys) {\n+        msgMgmtPool.submit(() -> sendGatheringRequests(gatId, keys, null));\n+    }\n+\n+    /**\n+     * Send response to given request.\n+     *\n+     * @param reqId Request id to response to.\n+     * @param statistics Collected statistics.\n+     */\n+    private void sendGatheringResponse(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        StatisticsAddrRequest<StatisticsGatheringRequest> req =  remainingRequests.remove(reqId);\n+        if (req == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Dropping results to cancelled collection request %s\", reqId));\n+\n+            return;\n+        }\n+        UUID gatId = req.req().gatId();\n+\n+        Map<StatisticsObjectData, int[]> dataParts = new HashMap<>(statistics.size());\n+        statistics.forEach((k,v) -> {\n+            try {\n+                StatisticsObjectData data = StatisticsUtils.toObjectData(k.getKey(), StatisticsType.LOCAL, k.getValue());\n+\n+                dataParts.put(data, v);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to format statistics %s.%s by request=%s gathering=%s\",\n+                            k.getKey().schema(), k.getKey().obj(), reqId, gatId));\n+\n+            }\n+        });\n+\n+\n+        if (locNodeId.equals(req.senderNodeId()))\n+            statMgr.registerLocalResult(gatId, dataParts);\n+        else {\n+            int parts = dataParts.values().stream().mapToInt(l -> l.length).sum();\n+            statMgr.onRemoteGatheringSend(gatid, parts);\n+            StatisticsGatheringResponse resp = new StatisticsGatheringResponse(req.req().gatId(), reqId, dataParts);\n+            safeSend(req.senderNodeId(), resp);\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringResponseAsync(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        msgMgmtPool.submit(() -> sendGatheringResponse(reqId, statistics));\n+    }\n+\n+    /**\n+     * Send requests to target nodes (except of local one).\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatisticsAddrRequest<T>> sendRequests(\n+        Collection<StatisticsAddrRequest<T>> reqs\n+    ) {\n+        Collection<StatisticsAddrRequest<T>> res = null;\n+\n+        for (StatisticsAddrRequest<T> req : reqs) {\n+            if (locNodeId.equals(req.targetNodeId()))\n+                continue;\n+\n+            try {\n+                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwOTEyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557409129", "bodyText": "No, any request will be processed in separate statistics pools (messages or gathering)", "author": "Berkof", "createdAt": "2021-01-14T13:52:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MzAxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTA5OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375098", "bodyText": "Let's move constant to static final field.", "author": "AMashenkov", "createdAt": "2020-12-28T14:53:23Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQxMDY4MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557410681", "bodyText": "modex to MAX_SEND_RETRIES", "author": "Berkof", "createdAt": "2021-01-14T13:54:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTA5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NzY1Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549377657", "bodyText": "I don't like this object with hardcoded set of fields is a part of protocol.\nThis approach is not flexible, we can't change the content of message that may depends on user needs.\nAlso versioning will be a headache in a future if we will need to change format.\nCustom versioned (de)serializer will be better.", "author": "AMashenkov", "createdAt": "2020-12-28T15:00:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsColumnData.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.processors.query.h2.twostep.msg.GridH2ValueMessage;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Statistics by column (or by set of columns, if they collected together)\n+ */\n+public class StatisticsColumnData implements Message {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3ODA1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559578054", "bodyText": "Discussed on the meeting, for now it'll be as is.", "author": "Berkof", "createdAt": "2021-01-18T13:47:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NzY1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NjUzOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549386539", "bodyText": "Test missed.", "author": "AMashenkov", "createdAt": "2020-12-28T15:25:50Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +202,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat2.put(\"col1\", cs3);\n+        colStat2.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+    /**\n+     *\n+     */\n+    @Test\n+    public void subtractTest() {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NzQ0Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559577446", "bodyText": "implemented", "author": "Berkof", "createdAt": "2021-01-18T13:47:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NjUzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2ODQ1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549368451", "bodyText": "there is no need in circular dependency Store <--> Repo. So let's preserve only Repo --> Store", "author": "korlov42", "createdAt": "2020-12-28T14:33:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -56,7 +56,7 @@\n     private final IgniteCacheDatabaseSharedManager db;\n \n     /** Statistics repository. */\n-    private final IgniteStatisticsRepository repo;\n+    private IgniteStatisticsRepository repo;", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NzIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559577208", "bodyText": "Replaced with handler.", "author": "Berkof", "createdAt": "2021-01-18T13:46:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2ODQ1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374533", "bodyText": "return locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));", "author": "korlov42", "createdAt": "2020-12-28T14:51:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -209,37 +173,45 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeLocalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public ObjectStatisticsImpl mergeLocalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         if (locStats == null) {\n             log.warning(\"Unable to merge local statistics for \" + key + \" on non server node.\");\n \n-            return;\n+            return null;\n         }\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        locStats.compute(key, (k, v) -> {\n+            v = (v == null) ? statistics : add(v, statistics);\n+\n+            res[0] = v;\n \n-        locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n+            return v;\n+        });\n+        return res[0];", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDg0OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374848", "bodyText": "please fix also other places with such pattern", "author": "korlov42", "createdAt": "2020-12-28T14:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA1Mjg0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557052843", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-14T05:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTEyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375124", "bodyText": "missed space", "author": "korlov42", "createdAt": "2020-12-28T14:53:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -256,22 +228,30 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void saveGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public void saveGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         globalStats.put(key, statistics);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n-        globalStats.compute(key, (k,v) -> (v == null) ? statistics : add(v, statistics));\n+    @Override public ObjectStatisticsImpl mergeGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        globalStats.compute(key, (k,v) -> {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4MDg4Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549380886", "bodyText": "mgr is not used anymore", "author": "korlov42", "createdAt": "2020-12-28T15:10:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -71,38 +73,29 @@ public IgniteStatisticsRepositoryImpl(\n         }\n         else {\n             // Cache only global statistics, no store\n-            store = null;\n+            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n             locStats = null;\n-        }\n+        }*/\n+        this.store = store;\n+        this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549384029", "bodyText": "store should not know about repo", "author": "korlov42", "createdAt": "2020-12-28T15:18:23Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -56,29 +56,36 @@\n      * @param partId Partition id.\n      * @return Object partition statistics or {@code null} if there are no statistics collected for such partition.\n      */\n-    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatsKey key, int partId);\n+    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partition statistics.\n      *\n      * @param key Object which statistics needs to be cleaned.\n      * @param partId Partition id.\n      */\n-    public void clearLocalPartitionStatistics(StatsKey key, int partId);\n+    public void clearLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partitions statistics.\n      *\n      * @param key Object which statistics need to be cleaned.\n      * @param partIds Collection of partition ids.\n      */\n-    public void clearLocalPartitionsStatistics(StatsKey key, Collection<Integer> partIds);\n+    public void clearLocalPartitionsStatistics(StatisticsKey key, Collection<Integer> partIds);\n \n     /**\n      * Save partition statistics.\n      *\n      * @param key Object which partition statistics belongs to.\n      * @param statistics Statistics to save.\n      */\n-    public void saveLocalPartitionStatistics(StatsKey key, ObjectPartitionStatisticsImpl statistics);\n+    public void saveLocalPartitionStatistics(StatisticsKey key, ObjectPartitionStatisticsImpl statistics);\n+\n+    /**\n+     * Set statistics repository.\n+     *\n+     * @param repository Ignite statistics repository.\n+     */\n+    public void setRepository(IgniteStatisticsRepository repository);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjU0MTU0Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556541547", "bodyText": "Do you prefer passing some handler to process existing statistics while it will be available?", "author": "Berkof", "createdAt": "2021-01-13T14:03:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzUxMTc4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557511780", "bodyText": "yep", "author": "korlov42", "createdAt": "2021-01-14T16:10:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3Njc3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559576778", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-18T13:45:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNjk1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549616952", "bodyText": "I don't think we need a method to collect statistics by several objects at all", "author": "korlov42", "createdAt": "2020-12-29T08:35:12Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjU0MDY5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556540695", "bodyText": "We discussed it - we need to collect statistics by several tables in the same cache group in single query.", "author": "Berkof", "createdAt": "2021-01-13T14:02:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNjk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNzI5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549617296", "bodyText": "the same as for collection by several objects", "author": "korlov42", "createdAt": "2020-12-29T08:36:19Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -46,6 +73,15 @@\n      * @param schemaName Schema name.\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to remove statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public void clearObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+\n+    /**\n+     * Clear object statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    public void clearObjectStatistics(String schemaName, String objName, String... colNames);\n+    public void clearObjectStatistics(GridTuple3<String, String, String[]>... keys) throws IgniteCheckedException;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618274", "bodyText": "please add empty lines", "author": "korlov42", "createdAt": "2020-12-29T08:39:23Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgxNjYzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555816633", "bodyText": "this is not used anymore", "author": "korlov42", "createdAt": "2021-01-12T14:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzOTcxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556539711", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T14:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODM2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618362", "bodyText": "null handling", "author": "korlov42", "createdAt": "2020-12-29T08:39:41Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());\n+        List<Integer> res = new ArrayList<>();\n+        for (int bVal : b)\n+            if (aSet.contains(bVal))\n+                res.add(bVal);\n+        return res.stream().mapToInt(Integer::intValue).toArray();\n+    }\n+\n+    /**\n+     * Subtract b array from a array.\n+     *\n+     * @param a Base array.\n+     * @param b Array to subtract from the base one.\n+     * @return Subtraction result.\n+     */\n+    public static int[] subtract(int[] a, int[] b) {\n+        Set<Integer> bSet = Arrays.stream(b).boxed().collect(Collectors.toSet());", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzOTE2MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556539160", "bodyText": "Why should I handle null arrays here? In javadoc no option with null array.", "author": "Berkof", "createdAt": "2021-01-13T14:00:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODM2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDI3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620278", "bodyText": "dot", "author": "korlov42", "createdAt": "2020-12-29T08:46:09Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxNDU1Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556314556", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T07:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDI3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDYwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620607", "bodyText": "space", "author": "korlov42", "createdAt": "2020-12-29T08:47:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNzMwNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556537305", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:57:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDc5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620795", "bodyText": "we use 'primary' term", "author": "korlov42", "createdAt": "2020-12-29T08:47:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjg0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536849", "bodyText": "renamed", "author": "Berkof", "createdAt": "2021-01-13T13:56:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMTI1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549621258", "bodyText": "todo", "author": "korlov42", "createdAt": "2020-12-29T08:49:29Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjQyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536421", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:56:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMTI1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjExOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622119", "bodyText": "please do it with tradition for-each loop", "author": "korlov42", "createdAt": "2020-12-29T08:52:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjA3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536075", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:55:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjE5OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622198", "bodyText": "indentation", "author": "korlov42", "createdAt": "2020-12-29T08:52:48Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNDI3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556534277", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T13:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjE5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyNDY1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549624651", "bodyText": "for-each loop", "author": "korlov42", "createdAt": "2020-12-29T09:00:55Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), locNodeId, node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, locNodeId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Filter columns from specified statistics.\n+     *\n+     * @param stat Statistics to filter columns from.\n+     * @param cols Column names to return in result object.\n+     * @return Statistics with only specified columns.\n+     */\n+    public static ObjectStatisticsImpl filterColumns(ObjectStatisticsImpl stat, Collection<String> cols) {\n+        ObjectStatisticsImpl res = stat.clone();\n+        res.columnsStatistics().clear();\n+        cols.forEach(col -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzMzYwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556533606", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:51:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyNDY1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY1NjUwMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549656502", "bodyText": "I would prefer to have it final, cause it prevent from having issues in case of multithreaded modification", "author": "korlov42", "createdAt": "2020-12-29T10:40:41Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java", "diffHunk": "@@ -24,7 +24,7 @@\n  */\n public class ObjectStatisticsImpl implements Cloneable, ObjectStatistics {\n     /** Total number of rows in object. */\n-    private final long rowsCnt;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzMzA1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556533050", "bodyText": "It used in the merge process where we can clone an initial object (to save all previously collected statistics) and set newly collected data. I'll think about how to fix it.", "author": "Berkof", "createdAt": "2021-01-13T13:51:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY1NjUwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjI1NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662255", "bodyText": "empty line and commented code", "author": "korlov42", "createdAt": "2020-12-29T10:59:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyODY3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556528678", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:44:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjM2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662368", "bodyText": "empty line", "author": "korlov42", "createdAt": "2020-12-29T11:00:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n+\n+        store.setRepository(statsRepos);\n+", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwODE4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556508185", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:11:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjU2Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662563", "bodyText": "commented code", "author": "korlov42", "createdAt": "2020-12-29T11:01:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwODc4Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556508786", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:12:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjU2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2ODIzMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549668232", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n          \n          \n            \n                    currColls.compute(gatId, (k, v) -> {\n          \n          \n            \n                        if (v == null)\n          \n          \n            \n                            v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n          \n          \n            \n            \n          \n          \n            \n                        ctxs[0] = v;\n          \n          \n            \n            \n          \n          \n            \n                        return v;\n          \n          \n            \n                    });\n          \n          \n            \n                    StatisticsGatheringContext ctxs = currColls.computeIfAbsent(gatId, \n          \n          \n            \n                        k -> new StatisticsGatheringContext(gatId, keys.keySet(), parts));", "author": "korlov42", "createdAt": "2020-12-29T11:21:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA2Nzg2Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557067863", "bodyText": "rewriten", "author": "Berkof", "createdAt": "2021-01-14T06:24:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2ODIzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY4NTEzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549685136", "bodyText": "it's better to check this after every N rows processed", "author": "korlov42", "createdAt": "2020-12-29T12:24:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyMTc3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556521774", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:33:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY4NTEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5MDk4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549690983", "bodyText": "this has to be WARN", "author": "korlov42", "createdAt": "2020-12-29T12:44:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n+\n+            final boolean reserved = locPart.reserve();\n+\n+            try {\n+                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n+                    continue;\n+\n+                long rowsCnt = 0;\n+\n+                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+\n+                for (Column col : selectedCols)\n+                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+\n+                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n+                        null, true)) {\n+                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(tbl.cacheName(),\n+                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n+                    if (!tblName.equals(typeDesc.tableName()))\n+                        continue;\n+\n+                    rowsCnt++;\n+\n+                    H2Row row0 = desc.createRow(row);\n+\n+                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n+                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+\n+                }\n+\n+                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n+                        csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+\n+                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n+                        locPart.updateCounter(), colStats));\n+\n+                if (log.isTraceEnabled())\n+                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n+                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyODIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556528229", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:44:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5MDk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjE3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696171", "bodyText": "computeIfAbsent suits here better", "author": "korlov42", "createdAt": "2020-12-29T13:01:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUxOTY5MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556519690", "bodyText": "implemented in StatGatheringContext", "author": "Berkof", "createdAt": "2021-01-13T13:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjE3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjYxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696611", "bodyText": "is there any reason to convert this insert a compute's closure?", "author": "korlov42", "createdAt": "2020-12-29T13:03:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUxODkwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556518907", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjYxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5ODQ4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549698480", "bodyText": "StatisticsObjectData has default equals and hashcode methods. IS it OK?", "author": "korlov42", "createdAt": "2020-12-29T13:08:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Message to send statistics.\n+ */\n+public class StatisticsGatheringResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 186;\n+\n+    /** Collection id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Map of collected local object statistics with array of included partitions. */\n+    @GridDirectMap(keyType = StatisticsObjectData.class, valueType = int[].class)\n+    private Map<StatisticsObjectData, int[]> data;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNzQyMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556507422", "bodyText": "Map removed with a sinle group per gathering task change", "author": "Berkof", "createdAt": "2021-01-13T13:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5ODQ4MA=="}], "type": "inlineReview"}, {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "url": "https://github.com/gridgain/gridgain/commit/bbc77144eac02f5ee7e71db9e138935ee5c280a3", "message": "GG-31094: statistics clear, cancel and some fixes to collect", "committedDate": "2020-12-29T14:02:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NTk5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549755996", "bodyText": "it's not going to work since it's possible to create column with comma in the name", "author": "korlov42", "createdAt": "2020-12-29T15:56:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,161 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)\n+    private List<String> colNames;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNjQzNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556506435", "bodyText": "Good point. Any suggestions on how we should specify multicolumn statistics target? Just to put it into a protocol.", "author": "Berkof", "createdAt": "2021-01-13T13:07:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NTk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NjUwNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549756505", "bodyText": "Message interface is partly implemented", "author": "korlov42", "createdAt": "2020-12-29T15:57:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNTA5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556505096", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T13:05:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NjUwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549759940", "bodyText": "StatisticsKeyMessage has default equals and hashcode methods. IS it OK?", "author": "korlov42", "createdAt": "2020-12-29T16:07:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;\n+\n+    /** Gathering id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Keys to partitions to gather statistics by. */\n+    @GridDirectMap(keyType = StatisticsKeyMessage.class, valueType = int[].class)\n+    private Map<StatisticsKeyMessage, int[]> keys;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4MDQ3Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549780473", "bodyText": "No, it's not, since it used here: https://github.com/gridgain/gridgain/pull/1660/files#diff-f727e80fc5250f851bb87b1f9cd9b5c159e5ca0cf094623418d515211784c82eR459", "author": "korlov42", "createdAt": "2020-12-29T17:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNDEzNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556504137", "bodyText": "HashCode&Equals implemented", "author": "Berkof", "createdAt": "2021-01-13T13:03:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc2MDg2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549760862", "bodyText": "please leave a comment inside GridIoMessageFactory with used codes", "author": "korlov42", "createdAt": "2020-12-29T16:09:44Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwMzY4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556503683", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:03:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc2MDg2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTIxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771210", "bodyText": "wrong javadoc", "author": "korlov42", "createdAt": "2020-12-29T16:39:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4OTg3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556489878", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T12:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTU1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771559", "bodyText": "computeIfAbsent", "author": "korlov42", "createdAt": "2020-12-29T16:40:56Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4OTIyNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556489227", "bodyText": "replaced", "author": "Berkof", "createdAt": "2021-01-13T12:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTU1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTY2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771667", "bodyText": "comment in Russian", "author": "korlov42", "createdAt": "2020-12-29T16:41:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NzkyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556477924", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T12:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NDQyNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549774426", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        for (int i = 0; i < assignments.size(); i++)\n          \n          \n            \n                            fillPartition(res, assignments, i, isPrimary);\n          \n          \n            \n                    else\n          \n          \n            \n                        for (Integer partId : partIds)\n          \n          \n            \n                            fillPartition(res, assignments, partId, isPrimary);\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n          \n          \n            \n            \n          \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n            \n          \n          \n            \n                    for (Integer partId : partIds)\n          \n          \n            \n                        fillPartition(res, assignments, partId, isPrimary);", "author": "korlov42", "createdAt": "2020-12-29T16:50:09Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwMjEzMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556502130", "bodyText": "implemented", "author": "Berkof", "createdAt": "2021-01-13T13:00:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NDQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549775416", "bodyText": "why we don't count the last node?", "author": "korlov42", "createdAt": "2020-12-29T16:53:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master or backups node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n+     */\n+    protected static  void fillPartition(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId,\n+        boolean isPrimary\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(partId);\n+\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NjU3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549776572", "bodyText": "also braces", "author": "korlov42", "createdAt": "2020-12-29T16:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NTk1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556475954", "bodyText": "we should, removed -1;\nadded", "author": "Berkof", "createdAt": "2021-01-13T12:13:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4Njc3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549786771", "bodyText": "let's use class with meaningful name instead of GridTuple3", "author": "korlov42", "createdAt": "2020-12-29T17:27:22Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NDI1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556474250", "bodyText": "I create StatisticsTarget for it.", "author": "Berkof", "createdAt": "2021-01-13T12:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4Njc3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4NzQ3OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549787479", "bodyText": "this is not used", "author": "korlov42", "createdAt": "2020-12-29T17:29:42Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3Mzk2NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556473965", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T12:09:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4NzQ3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5MzI4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549793285", "bodyText": "looks like debug code", "author": "korlov42", "createdAt": "2020-12-29T17:49:14Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java", "diffHunk": "@@ -81,7 +81,11 @@ public void compareSelectWithIntConditions() throws IgniteCheckedException {\n                 String.format(lo_med_select, 7, 7), noHints);\n \n         statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\");\n-\n+        try {\n+            Thread.sleep(1000);", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc4NjgxNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555786816", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-12T13:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5MzI4NQ=="}], "type": "inlineReview"}, {"oid": "7ef165002105dd10417170217e86d65771c524bb", "url": "https://github.com/gridgain/gridgain/commit/7ef165002105dd10417170217e86d65771c524bb", "message": "GG-31094: collect statistics by only one cache group by request", "committedDate": "2020-12-31T11:58:01Z", "type": "commit"}, {"oid": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "url": "https://github.com/gridgain/gridgain/commit/05b732cd7e8840c429c48f5561e7c98e0289bcf6", "message": "GG-31094: collect stats by only one cache group", "committedDate": "2021-01-11T11:24:57Z", "type": "commit"}, {"oid": "e54c934091d0917505fbe4bd919fd766a492897e", "url": "https://github.com/gridgain/gridgain/commit/e54c934091d0917505fbe4bd919fd766a492897e", "message": "GG-31094: comment, docs and codestyle", "committedDate": "2021-01-11T11:48:18Z", "type": "commit"}, {"oid": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "url": "https://github.com/gridgain/gridgain/commit/604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "message": "GG-31094: checkstyle", "committedDate": "2021-01-11T12:19:11Z", "type": "commit"}, {"oid": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "url": "https://github.com/gridgain/gridgain/commit/fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "message": "GG-31094: PR fixes", "committedDate": "2021-01-11T13:35:43Z", "type": "commit"}, {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976", "url": "https://github.com/gridgain/gridgain/commit/b385286d37cb759a2a308a055b12f32c5c22a976", "message": "GG-31094: fixes in test, backup sending and local saving.", "committedDate": "2021-01-12T13:20:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgyNzA2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555827069", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                        StatisticsKeyMessage key,\n          \n          \n            \n                        long rowsCnt,\n          \n          \n            \n                        StatisticsType type,\n          \n          \n            \n                        int partId,\n          \n          \n            \n                        long updCnt,\n          \n          \n            \n                        Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {\n          \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                    StatisticsKeyMessage key,\n          \n          \n            \n                    long rowsCnt,\n          \n          \n            \n                    StatisticsType type,\n          \n          \n            \n                    int partId,\n          \n          \n            \n                    long updCnt,\n          \n          \n            \n                    Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {", "author": "korlov42", "createdAt": "2021-01-12T14:48:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java", "diffHunk": "@@ -0,0 +1,265 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.processors.query.stat.StatisticsType;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+import java.util.Map;\n+\n+/**\n+ * Statistics for some object (index or table) in database.\n+ */\n+public class StatisticsObjectData implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 184;\n+\n+    /** Statistics key. */\n+    private StatisticsKeyMessage key;\n+\n+    /** Total row count in current object. */\n+    private long rowsCnt;\n+\n+    /** Type of statistics. */\n+    private StatisticsType type;\n+\n+    /** Partition id if statistics was collected by partition. */\n+    private int partId;\n+\n+    /** Update counter if statistics was collected by partition. */\n+    private long updCnt;\n+\n+    /** Columns key to statistic map. */\n+    @GridDirectMap(keyType = String.class, valueType = StatisticsColumnData.class)\n+    private Map<String, StatisticsColumnData> data;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param key Statistics key.\n+     * @param rowsCnt Total row count.\n+     * @param type Statistics type.\n+     * @param partId Partition id.\n+     * @param updCnt Partition update counter.\n+     * @param data Map of statistics column data.\n+     */\n+    public StatisticsObjectData(\n+            StatisticsKeyMessage key,\n+            long rowsCnt,\n+            StatisticsType type,\n+            int partId,\n+            long updCnt,\n+            Map<String, StatisticsColumnData> data\n+    ) {", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MTgxOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556471819", "bodyText": "intersect removed, suggestion commited", "author": "Berkof", "createdAt": "2021-01-13T12:05:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgyNzA2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4MzEwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555883106", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /** Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats. */\n          \n          \n            \n                @GridDirectCollection(String.class)\n          \n          \n            \n                /**\n          \n          \n            \n                 * Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats.\n          \n          \n            \n                 */\n          \n          \n            \n                @GridDirectCollection(String.class)", "author": "korlov42", "createdAt": "2021-01-12T15:57:59Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MzI5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556473299", "bodyText": "commited", "author": "Berkof", "createdAt": "2021-01-13T12:08:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4MzEwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4NTUwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555885506", "bodyText": "should not be 0", "author": "korlov42", "createdAt": "2021-01-12T16:01:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 188;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** List of keys to supply statistics by. */\n+    @GridDirectCollection(StatisticsObjectData.class)\n+    private List<StatisticsObjectData> data;\n+\n+    /**\n+     * Default constructor.\n+     */\n+    public StatisticsGetResponse() {\n+    }\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param reqId Request id.\n+     * @param data Statistics data.\n+     */\n+    public StatisticsGetResponse(UUID reqId, List<StatisticsObjectData> data) {\n+        this.reqId = reqId;\n+        this.data = data;\n+    }\n+\n+    /**\n+     * @return Request id.\n+     */\n+    public UUID reqId() {\n+        return reqId;\n+    }\n+\n+    /**\n+     * @return Statistics.\n+     */\n+    public List<StatisticsObjectData> data() {\n+        return data;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean writeTo(ByteBuffer buf, MessageWriter writer) {\n+        writer.setBuffer(buf);\n+\n+        if (!writer.isHeaderWritten()) {\n+            if (!writer.writeHeader(directType(), fieldsCount()))\n+                return false;\n+\n+            writer.onHeaderWritten();\n+        }\n+\n+        switch (writer.state()) {\n+            case 0:\n+                if (!writer.writeCollection(\"data\", data, MessageCollectionItemType.MSG))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+            case 1:\n+                if (!writer.writeUuid(\"reqId\", reqId))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+        }\n+\n+        return true;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean readFrom(ByteBuffer buf, MessageReader reader) {\n+        reader.setBuffer(buf);\n+\n+        if (!reader.beforeMessageRead())\n+            return false;\n+\n+        switch (reader.state()) {\n+            case 0:\n+                data = reader.readCollection(\"data\", MessageCollectionItemType.MSG);\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+            case 1:\n+                reqId = reader.readUuid(\"reqId\");\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+        }\n+\n+        return reader.afterMessageRead(StatisticsGetResponse.class);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public short directType() {\n+        return 0;", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2ODU1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556468552", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T11:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4NTUwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkwOTEyNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555909126", "bodyText": "stale javadoc", "author": "korlov42", "createdAt": "2021-01-12T16:33:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -41,131 +40,98 @@\n     private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n+\n+    /** Statistics gathering. */\n+    private final StatisticsGathering statisticsGathering;\n \n     /** Global (for whole cluster) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n      *\n-     * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n      * @param db Database to use in storage if persistence enabled.", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MjYzNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556472637", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T12:07:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkwOTEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyODM4MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555928381", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                        UUID reqId,\n          \n          \n            \n                        Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                        int[] parts,\n          \n          \n            \n                        Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                        StatisticsKeyMessage keyMsg,\n          \n          \n            \n                        Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );\n          \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                    UUID reqId,\n          \n          \n            \n                    Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                    int[] parts,\n          \n          \n            \n                    Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                    StatisticsKeyMessage keyMsg,\n          \n          \n            \n                    Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );", "author": "korlov42", "createdAt": "2021-01-12T16:59:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {\n+    /**\n+     * Collect local statistics by specified keys and partitions\n+     * and pass it to router to send in response to specified reqId.\n+     *\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     * @param parts Partitions to collect statistics by.\n+     * @param cancelled Supplier to track cancelled state.\n+     */\n+    public void collectLocalObjectsStatisticsAsync(\n+            UUID reqId,\n+            Set<StatisticsKeyMessage> keys,\n+            int[] parts,\n+            Supplier<Boolean> cancelled\n+    );\n+\n+    /**\n+     * @param statRepo Statistics repository.\n+     */\n+    public void repository(IgniteStatisticsRepository statRepo);\n+\n+    /**\n+     * Aggregate specified partition level statistics to local level statistics.\n+     *\n+     * @param keyMsg Aggregation key.\n+     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n+     * @return Local level aggregated statistics.\n+     */\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            Collection<? extends ObjectStatisticsImpl> stats\n+    );", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NzcxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556467711", "bodyText": "commited", "author": "Berkof", "createdAt": "2021-01-13T11:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyODM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTkzNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555931935", "bodyText": "why it can't be just a class? do you plan to collect statistics in different ways?", "author": "korlov42", "createdAt": "2021-01-12T17:04:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NzIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556467208", "bodyText": "No, just to improve lucidity of whole process. Sometimes there are different implementation, sometimes - only single, but each important part of the system has its own interface.", "author": "Berkof", "createdAt": "2021-01-13T11:56:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTkzNQ=="}], "type": "inlineReview"}, {"oid": "a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "url": "https://github.com/gridgain/gridgain/commit/a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "message": "GG-31094: triple2StatTarget, minor fixes", "committedDate": "2021-01-13T06:26:03Z", "type": "commit"}, {"oid": "ca1e579abf9a1382be63c0d4ba860f969041b986", "url": "https://github.com/gridgain/gridgain/commit/ca1e579abf9a1382be63c0d4ba860f969041b986", "message": "GG-31094: PR fixes", "committedDate": "2021-01-13T13:12:36Z", "type": "commit"}, {"oid": "17a54090bea4d97c122cf06d6be8e60177006519", "url": "https://github.com/gridgain/gridgain/commit/17a54090bea4d97c122cf06d6be8e60177006519", "message": "GG-31094: PR fixes", "committedDate": "2021-01-13T14:06:01Z", "type": "commit"}, {"oid": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "url": "https://github.com/gridgain/gridgain/commit/efd6b5e9f1f91625c2e6106b4c75522dada68b46", "message": "GG-31094: tests, PR fixes", "committedDate": "2021-01-14T10:58:17Z", "type": "commit"}, {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "url": "https://github.com/gridgain/gridgain/commit/6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "message": "GG-31094: test fixes, test for clearance and cancell gathering", "committedDate": "2021-01-14T13:39:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM5MzU0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557393549", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n          \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));", "author": "korlov42", "createdAt": "2021-01-14T13:27:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * Utility methods to statistics messages generation.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param schemaMgr Schema manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n+     */\n+    public IgniteStatisticsHelper(\n+        UUID locNodeId,\n+        SchemaManager schemaMgr,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.locNodeId = locNodeId;\n+        this.schemaMgr = schemaMgr;\n+        this.log = logSupplier.apply(IgniteStatisticsHelper.class);\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Split specified keys to cache groups.\n+     *\n+     * @param keys Keys to split.\n+     * @return Map cache group to collection of keys in group.\n+     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n+     */\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));", "originalCommit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NjE5Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559576192", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:45:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM5MzU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ0MDk4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557440985", "bodyText": "wrong comment", "author": "korlov42", "createdAt": "2021-01-14T14:37:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -59,6 +66,18 @@\n     /** Statistics repository. */\n     private final IgniteStatisticsRepository statsRepos;\n \n+    /** Current statistics collections tasks. */", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NTUwMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559575503", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ0MDk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ2NjA2NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557466064", "bodyText": "commented code", "author": "korlov42", "createdAt": "2021-01-14T15:10:13Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +205,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat3.put(\"col1\", cs3);\n+        colStat3.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat3);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+//    /**", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NDg4OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559574888", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:42:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ2NjA2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NDQzMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557494430", "bodyText": "empty line", "author": "korlov42", "createdAt": "2021-01-14T15:47:39Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NTI5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557495299", "bodyText": "stale param", "author": "korlov42", "createdAt": "2021-01-14T15:48:45Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Ignite statistics repository. */\n+    private IgniteStatisticsRepository statRepo;\n+\n+    /** Statistics crawler. */\n+    private final StatisticsGatheringRequestCrawler statCrawler;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param cacheProcessor Grid cache processor.", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NDQ5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559574495", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-18T13:42:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NTI5OQ=="}], "type": "inlineReview"}, {"oid": "48b736c4cf138d5db12978e2004c446e26e1f097", "url": "https://github.com/gridgain/gridgain/commit/48b736c4cf138d5db12978e2004c446e26e1f097", "message": "GG-31094: minor refactoring, codestyle, statistics version in metastore and collection on caches with lost partitions.", "committedDate": "2021-01-18T13:30:47Z", "type": "commit"}, {"oid": "a23eebc202da08a14cf888988d43eb62231d1189", "url": "https://github.com/gridgain/gridgain/commit/a23eebc202da08a14cf888988d43eb62231d1189", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-18T13:33:19Z", "type": "commit"}, {"oid": "23afcfd0b070646af24a1572418edbec1d4b5605", "url": "https://github.com/gridgain/gridgain/commit/23afcfd0b070646af24a1572418edbec1d4b5605", "message": "GG-31094: PR small fixes", "committedDate": "2021-01-18T13:52:49Z", "type": "commit"}, {"oid": "c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "url": "https://github.com/gridgain/gridgain/commit/c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "message": "GG-31094: tests fixes", "committedDate": "2021-01-19T09:40:33Z", "type": "commit"}, {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d", "url": "https://github.com/gridgain/gridgain/commit/390bfd8e824301929df7b139844e3b40bd216f6d", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-19T09:46:53Z", "type": "commit"}, {"oid": "7f29d66b8a36ce398400e761327f382e93ad2957", "url": "https://github.com/gridgain/gridgain/commit/7f29d66b8a36ce398400e761327f382e93ad2957", "message": "GG-31094: licences", "committedDate": "2021-01-19T11:26:19Z", "type": "commit"}, {"oid": "fe2051cb06a7d4423864c145d20b447da276320e", "url": "https://github.com/gridgain/gridgain/commit/fe2051cb06a7d4423864c145d20b447da276320e", "message": "GG-31094: licences", "committedDate": "2021-01-19T11:30:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2OTcyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560069721", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Return map cache group to corrsponding stats keys.\n          \n          \n            \n                 * Return map cache group to corresponding stats keys.", "author": "korlov42", "createdAt": "2021-01-19T10:24:29Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -88,13 +158,13 @@ public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws Ignite\n     }\n \n     /**\n-     * Extract groups of stats keys.\n+     * Return map cache group to corrsponding stats keys.", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY2MzY0NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561663644", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T07:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2OTcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3Mjc2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560072769", "bodyText": "sout", "author": "korlov42", "createdAt": "2021-01-19T10:29:10Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -85,6 +85,7 @@ public IgniteStatisticsRepositoryImpl(\n             res.add(newStat);\n             store.saveLocalPartitionStatistics(key, newStat);\n         }\n+        System.out.println(statistics.size() + \" partitions saved!\");", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3MzkyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560073921", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Receive gathering response and math it to request, then process these couple.\n          \n          \n            \n                 * Receive gathering response and match it to request, then process these couple.", "author": "korlov42", "createdAt": "2021-01-19T10:31:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -412,7 +421,7 @@ public void sendClearStatistics(Collection<StatisticsKeyMessage> keys) {\n     }\n \n     /**\n-     * Receive and handle statistics gathering response message as response for collection request.\n+     * Receive gathering response and math it to request, then process these couple.", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY2MzkxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561663917", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T07:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3MzkyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDExOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134118", "bodyText": "lockPool", "author": "korlov42", "createdAt": "2021-01-19T12:15:06Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY5OTAxNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561699014", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T08:52:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDExOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDg2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134862", "bodyText": "GridTestUtils#getFieldValue(Object obj, String... fieldNames)", "author": "korlov42", "createdAt": "2021-01-19T12:16:31Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringImpl.gatMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeGathLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringImpl crawler = readField(statMgr, \"statGathering\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"gatMgmtPool\");\n+        return lockPool(pool);\n+    }\n+\n+    /**\n+     * Lock specified pool with task, waiting for lock release.\n+     *\n+     * @param pool Pool to block.\n+     * @return Lock.\n+     */\n+    private Lock lockPool(IgniteThreadPoolExecutor pool) {\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Read object field value by name.\n+     *\n+     * @param obj Object to read value from.\n+     * @param field Field name.\n+     * @return Field value.\n+     * @throws Exception If case if object doesn't contains specified field.\n+     */\n+    protected <T> T readField(Object obj, String field) throws Exception {", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY3NTg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561675858", "bodyText": "Good point. replaced.", "author": "Berkof", "createdAt": "2021-01-21T08:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDg2Mg=="}], "type": "inlineReview"}, {"oid": "d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "url": "https://github.com/gridgain/gridgain/commit/d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "message": "GG-31094: gathering tests, small refactorings", "committedDate": "2021-01-20T08:29:24Z", "type": "commit"}, {"oid": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "url": "https://github.com/gridgain/gridgain/commit/33170812024f6c4d321f85287fea0b6c3abdb9e5", "message": "GG-31094: codestyle refactorings, batch gathering test.", "committedDate": "2021-01-20T11:21:27Z", "type": "commit"}, {"oid": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "url": "https://github.com/gridgain/gridgain/commit/84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "message": "GG-31094: checkstyle", "committedDate": "2021-01-20T11:45:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560911475", "bodyText": "it's better to complete a future with this exception", "author": "korlov42", "createdAt": "2021-01-20T12:08:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -255,13 +261,15 @@ public void gatherLocalObjectStatisticsAsync(\n         StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n             new StatisticsGatheringContext(gatId, keysSet, partsCnt));\n \n-        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFut().isCancelled());\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFuture().isCancelled());\n     }\n \n     /** {@inheritDoc} */\n-    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n     ) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics async\");", "originalCommit": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY3OTIyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561679223", "bodyText": "But sometimes we'll throw exception while sometimes (as you suggest) - put the same error into the array of futures? And we still can produce IgniteChechedException while starting the task if there are no such object in scheme (now).\nFrom this point of view - what if we'll throw IgniteChechedException here if there are some node(s) without such future, but return errors about object lacks in related to such object future?", "author": "Berkof", "createdAt": "2021-01-21T08:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTgwNDI3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561804278", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T11:31:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ=="}], "type": "inlineReview"}, {"oid": "1eb42d79754cf530e8ede9439c69b74635dd022f", "url": "https://github.com/gridgain/gridgain/commit/1eb42d79754cf530e8ede9439c69b74635dd022f", "message": "GG-31094: GridTestUtils.getFieldValue usage", "committedDate": "2021-01-21T08:37:47Z", "type": "commit"}, {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "url": "https://github.com/gridgain/gridgain/commit/f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "message": "GG-31094: remove Exception from Async method, add StatisticsTarget array to the gathering future.", "committedDate": "2021-01-21T11:11:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4Mjk4Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561982982", "bodyText": "it's better to check this with checkStatisticsSupport(), but slightly modify it to take param to decide wether an exception should be thrown or not (true by default)\n void checkStatisticsSupport(String op) {\n     checkStatisticsSupport(op, true)\n }\n\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\n     if (<support>)\n         return true;\n     \n     if (shouldThrow)\n         throw new Ex();\n\n     return false;\n }", "author": "korlov42", "createdAt": "2021-01-21T15:42:48Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -267,14 +266,23 @@ public void gatherLocalObjectStatisticsAsync(\n     /** {@inheritDoc} */\n     @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n-    ) throws IgniteCheckedException {\n-        checkSupport(\"collect statistics async\");\n+    ) {\n+\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n+            .collect(Collectors.toSet());\n \n-        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-            t -> new StatisticsKeyMessage(t.schema(), t.obj(), Arrays.asList(t.columns()))).collect(Collectors.toSet());\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        List<StatisticsGatheringFuture<Void>> res = new ArrayList<>();\n+        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {", "originalCommit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjQ3NzQyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r562477421", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-22T08:52:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4Mjk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4OTk2Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561989966", "bodyText": "BTW id=52 already reserved. Please check https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list for next feature ID. You need to reserve it first.", "author": "korlov42", "createdAt": "2021-01-21T15:51:24Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "diffHunk": "@@ -194,7 +194,10 @@\n     CACHE_GROUP_KEY_CHANGE(50),\n \n     /** Possibility to safe deactivation, take into account pure in memory caches with possible data loss.*/\n-    SAFE_CLUSTER_DEACTIVATION(51);\n+    SAFE_CLUSTER_DEACTIVATION(51),\n+\n+    /** Statistics collection. */\n+    STATISTICS_COLLECTION(52);", "originalCommit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "url": "https://github.com/gridgain/gridgain/commit/65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "message": "GG-31094: change feature number, minor fix by PR", "committedDate": "2021-01-22T08:55:32Z", "type": "commit"}, {"oid": "acbdccc0496377fc2b3b7d52363aea2185d33239", "url": "https://github.com/gridgain/gridgain/commit/acbdccc0496377fc2b3b7d52363aea2185d33239", "message": "GG-31094: Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-26T16:09:51Z", "type": "commit"}]}