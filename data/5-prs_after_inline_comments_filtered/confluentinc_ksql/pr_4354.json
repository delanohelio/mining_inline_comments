{"pr_number": 4354, "pr_title": "feat: Integrate reactive streams TCK and improvements to our reactive streams implementations", "pr_createdAt": "2020-01-20T13:53:40Z", "pr_url": "https://github.com/confluentinc/ksql/pull/4354", "timeline": [{"oid": "2b39b72b71996ab6a780137c2f4f99267f03b340", "url": "https://github.com/confluentinc/ksql/commit/2b39b72b71996ab6a780137c2f4f99267f03b340", "message": "interim", "committedDate": "2020-01-17T12:35:25Z", "type": "commit"}, {"oid": "0671d13b64724b4e35e8851de11442dfd39c0413", "url": "https://github.com/confluentinc/ksql/commit/0671d13b64724b4e35e8851de11442dfd39c0413", "message": "resolved merge", "committedDate": "2020-01-17T12:35:25Z", "type": "commit"}, {"oid": "0164953725100a5753292720dd013f5579e555ff", "url": "https://github.com/confluentinc/ksql/commit/0164953725100a5753292720dd013f5579e555ff", "message": "more work on publishers", "committedDate": "2020-01-17T12:35:25Z", "type": "commit"}, {"oid": "4367440274f10657dec181c040306fd846f8a05c", "url": "https://github.com/confluentinc/ksql/commit/4367440274f10657dec181c040306fd846f8a05c", "message": "More work on reactive stuff", "committedDate": "2020-01-18T11:35:41Z", "type": "commit"}, {"oid": "ef199950a9c8e2e480f1548326705b19e58cbea9", "url": "https://github.com/confluentinc/ksql/commit/ef199950a9c8e2e480f1548326705b19e58cbea9", "message": "Update copyright", "committedDate": "2020-01-18T20:03:59Z", "type": "commit"}, {"oid": "04f84934f8cda8f2a7c3baf12a239d342deef0c0", "url": "https://github.com/confluentinc/ksql/commit/04f84934f8cda8f2a7c3baf12a239d342deef0c0", "message": "Get puboisher passing tck", "committedDate": "2020-01-19T11:42:16Z", "type": "commit"}, {"oid": "41d24c176c7093c2c6e03c2b136976594318e03c", "url": "https://github.com/confluentinc/ksql/commit/41d24c176c7093c2c6e03c2b136976594318e03c", "message": "more tests", "committedDate": "2020-01-19T15:46:21Z", "type": "commit"}, {"oid": "0eab0ab4c49cc4bf71269ca3bc214c1975a63c42", "url": "https://github.com/confluentinc/ksql/commit/0eab0ab4c49cc4bf71269ca3bc214c1975a63c42", "message": "More work on impl and tests", "committedDate": "2020-01-20T13:01:18Z", "type": "commit"}, {"oid": "812a11345b13fe4bce4d475b20872719e2bcd1aa", "url": "https://github.com/confluentinc/ksql/commit/812a11345b13fe4bce4d475b20872719e2bcd1aa", "message": "a few tweaks", "committedDate": "2020-01-20T13:52:15Z", "type": "commit"}, {"oid": "71f0fc10af0c18608faac2f900eea3a53e39ef94", "url": "https://github.com/confluentinc/ksql/commit/71f0fc10af0c18608faac2f900eea3a53e39ef94", "message": "some tests for malformed json etc", "committedDate": "2020-01-20T14:43:05Z", "type": "commit"}, {"oid": "be3cc5863b16722aecd3975d70c75e146e4a0aff", "url": "https://github.com/confluentinc/ksql/commit/be3cc5863b16722aecd3975d70c75e146e4a0aff", "message": "javadoc tweak", "committedDate": "2020-01-20T15:11:44Z", "type": "commit"}, {"oid": "54485c924fdfca37dc2aa75ea1a301e66ed8612c", "url": "https://github.com/confluentinc/ksql/commit/54485c924fdfca37dc2aa75ea1a301e66ed8612c", "message": "removed TODO", "committedDate": "2020-01-20T17:20:57Z", "type": "commit"}, {"oid": "8d5db75f4fd775899bb144ae2237b1a782edcb55", "url": "https://github.com/confluentinc/ksql/commit/8d5db75f4fd775899bb144ae2237b1a782edcb55", "message": "Mainly javddoc", "committedDate": "2020-01-20T17:49:35Z", "type": "commit"}, {"oid": "7e1cf290e7ffcb04d6cadec0051706e18fce4a3b", "url": "https://github.com/confluentinc/ksql/commit/7e1cf290e7ffcb04d6cadec0051706e18fce4a3b", "message": "some more tweaks", "committedDate": "2020-01-20T18:40:24Z", "type": "commit"}, {"oid": "3a18773a4d0249072ff66488df9ce2e115708525", "url": "https://github.com/confluentinc/ksql/commit/3a18773a4d0249072ff66488df9ce2e115708525", "message": "fixed bug in batched delivery", "committedDate": "2020-01-20T21:22:48Z", "type": "commit"}, {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "url": "https://github.com/confluentinc/ksql/commit/3ba0d8a04f8ce7312a273230cc748f14d7def04b", "message": "fixed race", "committedDate": "2020-01-21T15:46:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTEzOQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311139", "bodyText": "it'd be nice to describe what this means and give an error message that's a little more actionable? What can cause this to happen?", "author": "agavra", "createdAt": "2020-01-22T00:10:28Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {\n+    checkContext();\n+    complete = true;\n+    if (subscription != null) {\n+      try {\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+  }\n+\n+  protected void checkContext() {\n+    if (Vertx.currentContext() != context) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQxODg0NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369418844", "bodyText": "I would definitely recommend reading through the Vert.x docs first as several of the questions you have asked here will probably be answered that way https://vertx.io/docs/vertx-core/java/\nTLDR - the Vert.x threading model guarantees that verticles (our ServiceVerticle verticle) are always executed by Vert.x on the same thread (there is an exception to that but it's not relevant right now). That means you can write your code as single threaded and not have to worry about synchronized, race conditions, most deadlocks etc. This is one of the big wins of Vert.x.  These context checks are just sanity checks to make sure the user is not using them in the way not original intended (e.g. with multiple threads concurrently). \"Context\" is a term you'll hear a lot in Vert.x terminology.", "author": "purplefox", "createdAt": "2020-01-22T08:18:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTEzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTU5NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311595", "bodyText": "I'm confused about the concurrency model of Subscribers - earlier there were some synchronized blocks and now I don't see them. Can you document what the concurrency requirements are? This is especially important if people are going to be implementing sub-classes of this.", "author": "agavra", "createdAt": "2020-01-22T00:12:06Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQxOTM4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369419386", "bodyText": "Ack, I'll add some extra javadoc", "author": "purplefox", "createdAt": "2020-01-22T08:19:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTU5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1MTU4OQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369451589", "bodyText": "Fwiw there's already some javadoc on the constructor which explains a bit, but I'll add some more to the header.\nPlease note, the implementation is in an early stage of development and is likely to change before production. Usually, I wouldn't add any JavaDoc until things have stabilised as otherwise you end up rewriting it every 5 minutes (and worse, forgetting to rewrite it resulting in out of date javadoc!), but I've made an exception here as I know most folks aren't too familiar with Vert.x and/or reactive streams so this helps the learning process :)", "author": "purplefox", "createdAt": "2020-01-22T09:33:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTU5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTgyNg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311826", "bodyText": "can we make all of the overridden methods final? that way implementations don't accidentally override", "author": "agavra", "createdAt": "2020-01-22T00:12:57Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQxOTg1OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369419858", "bodyText": "It may be useful for subclasses to override these methods, so I'd rather not.", "author": "purplefox", "createdAt": "2020-01-22T08:20:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTgyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwNjI1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370206257", "bodyText": "Ok. changed my mind, I made them final.", "author": "purplefox", "createdAt": "2020-01-23T16:00:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTgyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMjk0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369312941", "bodyText": "it seems like every method is supposed to check the context first. can we just make that method private and have all of the main action methods (i.e. onError, onComplete) call checkContext inside the runOnContext block?", "author": "agavra", "createdAt": "2020-01-22T00:16:59Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyMDg4NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369420884", "bodyText": "I think it's better to keep the check inside the method as is, in case that method accidentally gets called from elsewhere that's on the wrong context in a future refactoring.", "author": "purplefox", "createdAt": "2020-01-22T08:23:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMjk0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzM1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369313357", "bodyText": "we should make sure that we propagate t into this error message so at least we know what happened", "author": "agavra", "createdAt": "2020-01-22T00:18:17Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {\n+    checkContext();\n+    complete = true;\n+    if (subscription != null) {\n+      try {\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyMTA1NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369421055", "bodyText": "Ack", "author": "purplefox", "createdAt": "2020-01-22T08:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzM1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzY2MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369313660", "bodyText": "I have a preference for protected methods to be either abstract, empty or final - is there a reason any of these methods can't be final?", "author": "agavra", "createdAt": "2020-01-22T00:19:15Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyMTgyNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369421824", "bodyText": "I tend to err on the side of keeping the method non final unless there is a very good reason not to. There can be valid reasons for overriding that we haven't considered and we don't want to reduce the value of this class to subclass implementers", "author": "purplefox", "createdAt": "2020-01-22T08:25:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzY2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTczOTkxNg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369739916", "bodyText": "I think there are some very good reasons \ud83d\ude09 this method, for example, changes private state that this class makes certain assumptions about - if the behavior of complete() was any different than what is written in this class, then other methods would break (e.g. doOnNext would keep handling values). In general I think keeping the surface area of the API as small as possible at the start and expanding it only when necessary is safer.", "author": "agavra", "createdAt": "2020-01-22T18:51:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzY2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwNjQ4OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370206488", "bodyText": "Made them final", "author": "purplefox", "createdAt": "2020-01-23T16:00:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzY2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxNDgwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369314805", "bodyText": "we're cancelling the new subscription, and then setting it to be the current subscription? is this the intended behavior?", "author": "agavra", "createdAt": "2020-01-22T00:23:39Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyMzI1MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369423250", "bodyText": "Not intended. Good catch!", "author": "purplefox", "createdAt": "2020-01-22T08:29:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxNDgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxODEzOA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369318138", "bodyText": "I just realized that we send acks before we handle the inserts - what if we crash between sending the acks and handling the make request?", "author": "agavra", "createdAt": "2020-01-22T00:36:38Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyNDQwNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369424404", "bodyText": "Not sure what you mean by \"we send acks before we handle the inserts\" can you elaborate a bit?", "author": "purplefox", "createdAt": "2020-01-22T08:32:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxODEzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc0MDQ0OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369740448", "bodyText": "nevermind - I think I got confused when reading the code the first time around", "author": "agavra", "createdAt": "2020-01-22T18:52:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxODEzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxOTA2Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369319067", "bodyText": "this seems flipped from usual APIs which return true on the success condition and false when it fails.", "author": "agavra", "createdAt": "2020-01-22T00:40:18Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyNTA0Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369425042", "bodyText": "It's consistent with the Vert.x APIs (it's basically returning whether writeQueueFull) https://vertx.io/docs/apidocs/io/vertx/core/streams/WriteStream.html#writeQueueFull--", "author": "purplefox", "createdAt": "2020-01-22T08:33:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxOTA2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxNDI4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369814286", "bodyText": "ack - makes sense given that we still add it to the buffer in either scenario.", "author": "agavra", "createdAt": "2020-01-22T21:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxOTA2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyMDk0Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369320946", "bodyText": "same comment as above - can these methods be made final?", "author": "agavra", "createdAt": "2020-01-22T00:47:49Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyNTIzMQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369425231", "bodyText": "Reply as above ;)", "author": "purplefox", "createdAt": "2020-01-22T08:34:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyMDk0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNDQzMg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369324432", "bodyText": "I'm confused by this - according to the Subscriber docs (and your assertion above), n is a strictly positive number. Looking at where demand is set, I don't see how this can be less than 1.", "author": "agavra", "createdAt": "2020-01-22T01:02:07Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyNTg5Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369425897", "bodyText": "integer (long) overflow. I will add a comment to clarify.", "author": "purplefox", "createdAt": "2020-01-22T08:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNDQzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTI3MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369325270", "bodyText": "it feels like there should be some synchronization in this class? also do we have any guarantees about when this will be scheduled?", "author": "agavra", "createdAt": "2020-01-22T01:05:38Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyNjI4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369426285", "bodyText": "It doesn't require synchronization due to the Vert.x threading model as per previous comment :)", "author": "purplefox", "createdAt": "2020-01-22T08:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTI3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTY0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369325641", "bodyText": "if it's cancelled, why would I add it to the buffer?", "author": "agavra", "createdAt": "2020-01-22T01:07:05Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQyOTEzNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369429134", "bodyText": "Ack", "author": "purplefox", "createdAt": "2020-01-22T08:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTY0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzA1NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327055", "bodyText": "is it possible that we will never send the complete? it seems like if subscriber that was set never calls request, we won't increase our demand and we will never the buffered elements", "author": "agavra", "createdAt": "2020-01-22T01:12:52Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQzNDE1NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369434155", "bodyText": "This is by design, the complete will only be sent after all buffered messages have been delivered, and they won't be delivered unless they've been requested.", "author": "purplefox", "createdAt": "2020-01-22T08:55:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzA1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzI4OQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327289", "bodyText": "we should explicitly comment that this is a \"one time use\" function - after called once, it won't be called without another call to drainHandler", "author": "agavra", "createdAt": "2020-01-22T01:13:53Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQzNTAyMQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369435021", "bodyText": "Will add clarifying comment.", "author": "purplefox", "createdAt": "2020-01-22T08:57:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzI4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzk5OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327998", "bodyText": "there are still quite a few relevant comments on #4320 that I still see are relevant. Can you please go through them and make sure they are addressed or comment there dismissing them?", "author": "agavra", "createdAt": "2020-01-22T01:17:04Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -79,16 +89,35 @@ public void handleBodyBuffer(final Buffer buff) {\n         return;\n       }\n       final JsonObject properties = args.getJsonObject(\"properties\");\n-      routingContext.request().endHandler(this::handleBodyEnd);\n-      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      acksSubscriber = acks ? new AcksSubscriber(ctx, routingContext.response()) : null;", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2Njg2OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369466868", "bodyText": "I've addressed them now on the other PR", "author": "purplefox", "createdAt": "2020-01-22T10:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzk5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODY3MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369328671", "bodyText": "this isn't a particularly actionable message. can we improve on it by explaining why it's invalid?", "author": "agavra", "createdAt": "2020-01-22T01:19:51Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -32,14 +37,29 @@ private ServerUtils() {\n \n   public static void handleError(final HttpServerResponse response, final int statusCode,\n       final int errorCode, final String errMsg) {\n-    final JsonObject errResponse = new JsonObject().put(\"status\", \"error\")\n+    final JsonObject errResponse = createErrResponse(errorCode, errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static JsonObject createErrResponse(final int errorCode, final String errMsg) {\n+    return new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", errorCode)\n         .put(\"message\", errMsg);\n-    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n   }\n \n   public static void unhandledExceptonHandler(final Throwable t) {\n     log.error(\"Unhandled exception\", t);\n   }\n \n+  public static JsonObject decodeJsonObject(final Buffer buffer,\n+      final RoutingContext routingContext) {\n+    try {\n+      return new JsonObject(buffer);\n+    } catch (DecodeException e) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_INVALID_JSON,\n+          \"Invalid JSON in request args\");", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQzNjQ4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369436486", "bodyText": "I will make sure we log the full information on the server, but I don't think it's a good idea to return the invalid JSON to the client (it could be huge for example)", "author": "purplefox", "createdAt": "2020-01-22T09:01:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODY3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369328941", "bodyText": "can we have this return Optional to indicate that this can return null?", "author": "agavra", "createdAt": "2020-01-22T01:21:06Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -32,14 +37,29 @@ private ServerUtils() {\n \n   public static void handleError(final HttpServerResponse response, final int statusCode,\n       final int errorCode, final String errMsg) {\n-    final JsonObject errResponse = new JsonObject().put(\"status\", \"error\")\n+    final JsonObject errResponse = createErrResponse(errorCode, errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static JsonObject createErrResponse(final int errorCode, final String errMsg) {\n+    return new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", errorCode)\n         .put(\"message\", errMsg);\n-    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n   }\n \n   public static void unhandledExceptonHandler(final Throwable t) {\n     log.error(\"Unhandled exception\", t);\n   }\n \n+  public static JsonObject decodeJsonObject(final Buffer buffer,\n+      final RoutingContext routingContext) {\n+    try {\n+      return new JsonObject(buffer);\n+    } catch (DecodeException e) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_INVALID_JSON,\n+          \"Invalid JSON in request args\");\n+      return null;", "originalCommit": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ0ODI0Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369448242", "bodyText": "This is by design. I prefer it returning null as it makes the code that uses it simpler. If we return Optional then the using code needs to call get() each time to get the actual object which is more verbose. But I appreciate this is a contentious point.", "author": "purplefox", "createdAt": "2020-01-22T09:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc0MTE1MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369741150", "bodyText": "fair enough - I can see both sides", "author": "agavra", "createdAt": "2020-01-22T18:54:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyNjU3NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370126574", "bodyText": "The rest of the code base generally avoids returning nulls from public methods, preferring to encode the optionality of the result into the type system.  It would be nice if you're code followed this convention as well.\nYes, this results in the need to call .get() or .orElse(), but also provides a compile time check that callers handle the null case.   Thus reducing the risk of latent bugs due to calling code not handling null return values.\nSo, for example, you can still use it like this:\nfinal JsonObject requestBody = decodeJsonObject(routingContext.getBody(), routingContext).orElse(null);\n    if (requestBody == null) {\n      return;\n    }", "author": "big-andy-coates", "createdAt": "2020-01-23T13:49:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwODQwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370208405", "bodyText": "I'm not sure I understand why the other is better than:\nfinal JsonObject requestBody = decodeJsonObject(routingContext.getBody(), routingContext);\n    if (requestBody == null) {\n      return;\n    }\n\nIt seems to be doing the exact thing, but with more code?", "author": "purplefox", "createdAt": "2020-01-23T16:04:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTAwMjk4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r371002986", "bodyText": "Changed in later PR", "author": "purplefox", "createdAt": "2020-01-26T14:22:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}], "type": "inlineReview"}, {"oid": "8419a8b321aea510a82d303c655235306393cf08", "url": "https://github.com/confluentinc/ksql/commit/8419a8b321aea510a82d303c655235306393cf08", "message": "Review comments", "committedDate": "2020-01-22T09:38:33Z", "type": "commit"}, {"oid": "1eb4cd594e90f9ce2b4fe1e90f06fec781b8fb0f", "url": "https://github.com/confluentinc/ksql/commit/1eb4cd594e90f9ce2b4fe1e90f06fec781b8fb0f", "message": "More review comments", "committedDate": "2020-01-22T10:06:39Z", "type": "commit"}, {"oid": "bb9ff315edee26c2bc64aef3e6b125a364414f6f", "url": "https://github.com/confluentinc/ksql/commit/bb9ff315edee26c2bc64aef3e6b125a364414f6f", "message": "check on duplicate queryID", "committedDate": "2020-01-22T10:54:31Z", "type": "commit"}, {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "url": "https://github.com/confluentinc/ksql/commit/c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "message": "better check on duplicate queryID", "committedDate": "2020-01-22T10:59:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgwODAwNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369808004", "bodyText": "same comment as the previous PR, I'm not sure this is out of date. tl;dr I think we should rename this requestClose(final long expectedAcks) and to change insertsSent to expectedAcks\n\nIt took me some time to understand what this API does. Does it indicate that we've completed all the inserts we want to send? Do we expect it to be called more than once? Maybe we can name it requestClose(final long expectedAcks). Would also help to have javadoc around here.\nAlso instead of using a single Long to indicate two things: both that we should close and the value of acks expected, I think it would be safer (avoid unboxing a null value) and easier to read if we split it into a flag boolean closeRequested and long expectedAcks.", "author": "agavra", "createdAt": "2020-01-22T21:17:24Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {\n+    checkContext();\n+    cancelled = true;\n+    if (subscription != null) {\n+      subscription.cancel();\n+    }\n+  }\n+\n+  private void checkMakeRequest() {\n+    if (acksSent % REQUEST_BATCH_SIZE == 0) {\n+      makeRequest(REQUEST_BATCH_SIZE);\n+    }\n+  }\n+\n+  private void close() {\n     response.end();\n+    complete();\n+  }\n+\n+  void insertsSent(final long num) {", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxODE2Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369818167", "bodyText": "\ud83d\ude02", "author": "agavra", "createdAt": "2020-01-22T21:39:44Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -93,18 +93,22 @@ public synchronized void stop() {\n     }\n   }\n \n-  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+  ApiQueryID registerQuery(final QuerySubscriber querySubscriber) {\n     Objects.requireNonNull(querySubscriber);\n-    final QueryID queryID = new QueryID();\n-    queries.put(queryID, querySubscriber);\n+    final ApiQueryID queryID = new ApiQueryID();\n+    if (queries.putIfAbsent(queryID, querySubscriber) != null) {\n+      // It should never happen\n+      // https://stackoverflow.com/questions/2513573/how-good-is-javas-uuid-randomuuid", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxOTc5MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369819790", "bodyText": "is this used anywhere?", "author": "agavra", "createdAt": "2020-01-22T21:43:19Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -168,30 +174,39 @@ private void handleCloseQuery(final RoutingContext routingContext) {\n     routingContext.response().end();\n   }\n \n+  private static void connectBodyHandler(final Context ctx, final Endpoints endpoints,", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3MDY3Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369970673", "bodyText": "Nope, good catch", "author": "purplefox", "createdAt": "2020-01-23T07:52:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxOTc5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMjgxMA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369822810", "bodyText": "it seems like most if not all the tests in this class can follow Given/When/Then. For these one's it's trivial:\n// When\nloadPublisher(10);\n\n// Then:\nshouldDeliver(1,1);", "author": "agavra", "createdAt": "2020-01-22T21:49:53Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTk3MjExMQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369972111", "bodyText": "Isn't that kind of obvious without the given/when stuff? ;)", "author": "purplefox", "createdAt": "2020-01-23T07:56:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMjgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyNzA1Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369827052", "bodyText": "\ud83d\ude09 (and the @author below)", "author": "agavra", "createdAt": "2020-01-22T21:59:19Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/tck/ReactiveSubscriberBlackboxVerificationTest.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2014 Red Hat, Inc.", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "url": "https://github.com/confluentinc/ksql/commit/a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "message": "review updates", "committedDate": "2020-01-23T07:58:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1MTI2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370051261", "bodyText": "nit: validate parameters.", "author": "big-andy-coates", "createdAt": "2020-01-23T10:54:23Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwOTgxMA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370209810", "bodyText": "Ack", "author": "purplefox", "createdAt": "2020-01-23T16:06:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1MTI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1NjY3Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370056676", "bodyText": "ReactiveSubscriber already has a subscription field.  Rather than add another here, would it not be cleaner to either:\na. expose the subscription on the base class to derived classes through a protected getter, or\nb. (given this class only tracks the field to call cancel, add a cancel method to the base class\n???", "author": "big-andy-coates", "createdAt": "2020-01-23T11:07:16Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwOTcxMw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370209713", "bodyText": "Ack", "author": "purplefox", "createdAt": "2020-01-23T16:06:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1NjY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1ODA3Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370058072", "bodyText": "Forgive my lack of knowledge of vert.x, just wanted to check that the lambda passed here will always be called back on the same context/thread, i.e. just checking we're not missing a volatile.", "author": "big-andy-coates", "createdAt": "2020-01-23T11:10:43Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxMDkyNw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370210927", "bodyText": "Yep, it will be called on the same thread - this is part of the threading guarantee of Vert.x - handlers set from one context will always be called back on the same context. For standard verticles (like this one), the same context corresponds to the exact same thread (an event loop thread). This means you can code everything in your verticle as single threaded, and not have to worry about synchronized, race conditions, most deadlock etc.", "author": "purplefox", "createdAt": "2020-01-23T16:08:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1ODA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2Mjc1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370062757", "bodyText": "Looking at the logic here it feels like there may be an edge case, or it may be just my lack of experience with vert.x:\nIt looks like the logic is:\nif the write queue is full, then set up a callback, once, to call checkMakeRequest and clear the flag. Sounds good, except that we're requesting batches of 1000, so isn't there a chance that handleValue is going to be called another 999 times and call response.write even though the queue is full?  What will happen in such a situation?", "author": "big-andy-coates", "createdAt": "2020-01-23T11:22:03Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNDMzMg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370214332", "bodyText": "Good observation. Unlike reactive streams, Vert.x-based flow control is not exact, so it's ok to write to a stream after writeQueueFull() returns true. WriteQueueFull() is just indicative, and any writes that can't actually be written will be buffered by HttpServerResponse.\nContrast this with reactive streams where the subscriber requests an exact number of elements and it must not receive any more than that.", "author": "purplefox", "createdAt": "2020-01-23T16:14:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2Mjc1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2NjY4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370066687", "bodyText": "noticed you've dropped the synchronized.  Is this method now always called on the same thread as the main logic? If so, shouldn't we have a checkContext call here?", "author": "big-andy-coates", "createdAt": "2020-01-23T11:32:14Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {\n+    checkContext();\n+    cancelled = true;\n+    if (subscription != null) {\n+      subscription.cancel();\n+    }\n+  }\n+\n+  private void checkMakeRequest() {\n+    if (acksSent % REQUEST_BATCH_SIZE == 0) {\n+      makeRequest(REQUEST_BATCH_SIZE);\n+    }\n+  }\n+\n+  private void close() {\n     response.end();\n+    complete();\n+  }\n+\n+  void insertsSent(final long num) {", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNTEwMg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370215102", "bodyText": "It will be ok as it's on the same context as the caller, but I will add a checkContext() as a sanity check.", "author": "purplefox", "createdAt": "2020-01-23T16:15:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2NjY4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2ODcyNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370068724", "bodyText": "Purely out of interest.... what was involved in picking this number?", "author": "big-andy-coates", "createdAt": "2020-01-23T11:37:24Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNTgxNw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370215817", "bodyText": "They are pretty arbitrary placeholders right now. I have a task to write some perf tests / benchmarks. During this process we can tune these numbers for the best perf and use those (also maybe make them configurable).", "author": "purplefox", "createdAt": "2020-01-23T16:16:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2ODcyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDIxMA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370070210", "bodyText": "nit: validate params, i.e. null check ctx, positive bufferMaxSize", "author": "big-andy-coates", "createdAt": "2020-01-23T11:41:22Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNTk1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370215953", "bodyText": "ack", "author": "purplefox", "createdAt": "2020-01-23T16:17:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDkwNA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370070904", "bodyText": "second check of cancelled is always going to be false. Second if can just be:\nif (demand == 0)", "author": "big-andy-coates", "createdAt": "2020-01-23T11:43:09Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNjU4Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370216583", "bodyText": "oops. ack", "author": "purplefox", "createdAt": "2020-01-23T16:18:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDkwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjA4Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370072083", "bodyText": "There's potential for someone to come along and add another call to this method, unintentionally overwriting a pre-existing handler, right?  Might it be safer to throw something here if the handler is already set? e.g.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                this.drainHandler = handler;\n          \n          \n            \n                if (this.drainHandler != 0) {\n          \n          \n            \n                    throw new IllegalStateException(\"drain handler already set\");\n          \n          \n            \n                }\n          \n          \n            \n                this.drainHandler = Objects.requireNoneNull(handler);", "author": "big-andy-coates", "createdAt": "2020-01-23T11:46:14Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNjk2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370216969", "bodyText": "ack", "author": "purplefox", "createdAt": "2020-01-23T16:18:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjQ4Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370072483", "bodyText": "should this maybe be:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (cancelled || complete) {\n          \n          \n            \n                if (cancelled || completing) {\n          \n      \n    \n    \n  \n\n???", "author": "big-andy-coates", "createdAt": "2020-01-23T11:47:15Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNzQyMg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370217422", "bodyText": "ack", "author": "purplefox", "createdAt": "2020-01-23T16:19:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NTQ5MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370075491", "bodyText": "Is delimiting records by \\n safe?  What if an insert wanted to insert a string that contained a newline character?\nI'm guessing this is OK as the JSON would need the line separator converted to a literal \"\\n\".  But maybe worth adding a test to cover this case.", "author": "big-andy-coates", "createdAt": "2020-01-23T11:54:31Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -34,38 +38,44 @@\n  * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n  * followed by a new-line.\n  */\n-public class InsertsBodyParser {\n+public class InsertsBodyHandler {\n \n+  private final Context ctx;\n   private final Endpoints endpoints;\n   private final RoutingContext routingContext;\n-  private boolean readArguments;\n-  private InsertsPublisher publisher;\n+  private final RecordParser recordParser;\n+  private boolean hasReadArguments;\n+  private BufferedPublisher<JsonObject> publisher;\n   private long rowsReceived;\n   private AcksSubscriber acksSubscriber;\n \n-  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+  public InsertsBodyHandler(final Context ctx, final Endpoints endpoints,\n+      final RoutingContext routingContext) {\n+    this.ctx = ctx;\n     this.endpoints = Objects.requireNonNull(endpoints);\n     this.routingContext = Objects.requireNonNull(routingContext);\n-    routingContext.response().endHandler(v -> {\n-      if (publisher != null) {\n-        publisher.close();\n-      }\n-    });\n+    this.recordParser = RecordParser.newDelimited(\"\\n\", routingContext.request());", "originalCommit": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNzY4Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370217682", "bodyText": "\\n is illegal in JSON strings (they must be escaped as per spec), so this is OK.", "author": "purplefox", "createdAt": "2020-01-23T16:20:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NTQ5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3ODcxMg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370078712", "bodyText": "Consider replacing comment with a constant, e.g.\nprivate static final long INFINITE_DEMAND = Long.MAX;\n\n....\n\nif (demand != INFINITE_DEMAND) {\n   demand--;\n}", "author": "big-andy-coates", "createdAt": "2020-01-23T12:02:40Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxODI2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370218269", "bodyText": "Hmm, ok perhaps", "author": "purplefox", "createdAt": "2020-01-23T16:21:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3ODcxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQ1MDA1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r371450053", "bodyText": "lol.", "author": "big-andy-coates", "createdAt": "2020-01-27T19:54:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3ODcxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3OTMzOA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370079338", "bodyText": "Consider using constant mentioned above:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  demand = Long.MAX_VALUE;\n          \n          \n            \n                  demand = INFINITE_DEMAND;", "author": "big-andy-coates", "createdAt": "2020-01-23T12:04:14Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {\n+      // Catch overflow and set to \"infinite\"\n+      demand = Long.MAX_VALUE;", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxODMyOA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370218328", "bodyText": "as above", "author": "purplefox", "createdAt": "2020-01-23T16:21:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3OTMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MTAxNg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370081016", "bodyText": "Intent might be clearer with something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } else if (demand + n < 1) {\n          \n          \n            \n                } else if (n > Long.MAX_VALUE - demand) {\n          \n      \n    \n    \n  \n\nBut no biggie.", "author": "big-andy-coates", "createdAt": "2020-01-23T12:08:36Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxOTA2Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370219066", "bodyText": "Personally I prefer the existing more intuitive, it's checking for overflow so asking whether demand + n becomes negative seems natural to me.", "author": "purplefox", "createdAt": "2020-01-23T16:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MTAxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQ1MDI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r371450287", "bodyText": "Horses for courses. No biggie.", "author": "big-andy-coates", "createdAt": "2020-01-27T19:55:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MTAxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MzAyNQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370083025", "bodyText": "Can this not make use of decodeJsonObject? e.g. something like:\nfinal JsonObject row = decodeJsonObject(buff, routingContext);\nif (row == null) {\n   acksSubscriber.cancel();\n   return;\n}", "author": "big-andy-coates", "createdAt": "2020-01-23T12:13:27Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -79,16 +89,35 @@ public void handleBodyBuffer(final Buffer buff) {\n         return;\n       }\n       final JsonObject properties = args.getJsonObject(\"properties\");\n-      routingContext.request().endHandler(this::handleBodyEnd);\n-      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      acksSubscriber = acks ? new AcksSubscriber(ctx, routingContext.response()) : null;\n       final InsertsSubscriber insertsSubscriber = endpoints\n           .createInsertsSubscriber(target, properties, acksSubscriber);\n-      publisher = new InsertsPublisher();\n+      publisher = new BufferedPublisher<>(ctx);\n+\n+      // This forces response headers to be written so we know we send a 200 OK\n+      // This is important if we subsequently find an error in the stream\n+      routingContext.response().write(\"\");\n+\n       publisher.subscribe(insertsSubscriber);\n     } else if (publisher != null) {\n-      final JsonObject row = new JsonObject(buff);\n-      publisher.receiveRow(row);\n+      final JsonObject row;\n+      try {\n+        row = new JsonObject(buff);\n+      } catch (DecodeException e) {\n+        final JsonObject errResponse = ServerUtils\n+            .createErrResponse(ErrorCodes.ERROR_CODE_INVALID_JSON,\n+                \"Invalid JSON in inserts stream\");\n+        routingContext.response().write(errResponse.toBuffer().appendString(\"\\n\")).end();\n+        acksSubscriber.cancel();\n+        return;", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxOTQwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370219405", "bodyText": "out of date with other PR", "author": "purplefox", "createdAt": "2020-01-23T16:22:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MzAyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMDE2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370120161", "bodyText": "There's a very simple state machine encoded in this handleBodyBuffermethod. If we were to move the implementation of each step into a separate method II think that state machine would be more obvious, e.g.\npublic void handleBodyBuffer(final Buffer buff) {\n    if (!hasReadArguments) {\n        readArguments(buff);\n    } else if (publisher != null) {\n       publishInsert(buff);\n    } else {\n        // Do nothing as failed to initialize, likely due to invalid request.\n    }\n}", "author": "big-andy-coates", "createdAt": "2020-01-23T13:37:27Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -34,38 +38,44 @@\n  * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n  * followed by a new-line.\n  */\n-public class InsertsBodyParser {\n+public class InsertsBodyHandler {\n \n+  private final Context ctx;\n   private final Endpoints endpoints;\n   private final RoutingContext routingContext;\n-  private boolean readArguments;\n-  private InsertsPublisher publisher;\n+  private final RecordParser recordParser;\n+  private boolean hasReadArguments;\n+  private BufferedPublisher<JsonObject> publisher;\n   private long rowsReceived;\n   private AcksSubscriber acksSubscriber;\n \n-  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+  public InsertsBodyHandler(final Context ctx, final Endpoints endpoints,\n+      final RoutingContext routingContext) {\n+    this.ctx = ctx;\n     this.endpoints = Objects.requireNonNull(endpoints);\n     this.routingContext = Objects.requireNonNull(routingContext);\n-    routingContext.response().endHandler(v -> {\n-      if (publisher != null) {\n-        publisher.close();\n-      }\n-    });\n+    this.recordParser = RecordParser.newDelimited(\"\\n\", routingContext.request());\n   }\n \n   public void handleBodyEnd(final Void v) {\n-    if (acksSubscriber == null) {\n-      routingContext.response().end();\n-    } else {\n-      // We close the response after the stream of acks has been sent\n-      acksSubscriber.insertsSent(rowsReceived);\n+    if (publisher != null) {\n+      publisher.complete();\n+      if (acksSubscriber == null) {\n+        routingContext.response().end();\n+      } else {\n+        // We close the response after the stream of acks has been sent\n+        acksSubscriber.insertsSent(rowsReceived);\n+      }\n     }\n   }\n \n   public void handleBodyBuffer(final Buffer buff) {\n-    if (!readArguments) {\n-      final JsonObject args = new JsonObject(buff);\n-      readArguments = true;\n+    if (!hasReadArguments) {", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxOTg0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370219847", "bodyText": "Ack, but I've already refactored this quite a lot in further work.", "author": "purplefox", "createdAt": "2020-01-23T16:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMDE2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMTA0NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370121044", "bodyText": "nit: validate parameters that will be stored in fields.", "author": "big-andy-coates", "createdAt": "2020-01-23T13:39:18Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation. The state for this subscriber will always be accessed on the\n+ * same Vert.x context so does not require synchronization\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxOTk4OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370219988", "bodyText": "Ack", "author": "purplefox", "createdAt": "2020-01-23T16:23:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMTA0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMjQwOA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370122408", "bodyText": "Might be worth pulling the cancel functionality out into a new base class, e.g. CancelableSubcriber", "author": "big-andy-coates", "createdAt": "2020-01-23T13:41:53Z", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyMDk4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370220987", "bodyText": "Ack, that can go in base class", "author": "purplefox", "createdAt": "2020-01-23T16:25:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMjQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMDg3Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370130876", "bodyText": "do we really need to check both?", "author": "big-andy-coates", "createdAt": "2020-01-23T13:57:37Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -545,6 +548,70 @@ public void shouldHandleErrorInProcessingInserts() throws Exception {\n     assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n   }\n \n+  @Test\n+  public void shouldRejectMalformedJsonInInsertsStreamArgs() throws Exception {\n+    shouldRejectMalformedJsonInArgs(\"/inserts-stream\");\n+  }\n+\n+  @Test\n+  public void shouldHandleMalformedJsonInInsertsStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (int i = 0; i < rows.size() - 1; i++) {\n+      JsonObject row = rows.get(i);\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+    // Malformed row for the last one\n+    requestBody.appendString(\"{ijqwdijqw\");\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyMTI2Ng==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370221266", "bodyText": "The status message can be overridden on the server, so probably worth doing.", "author": "purplefox", "createdAt": "2020-01-23T16:25:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMDg3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQ1MDc2OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r371450768", "bodyText": "Do we override any messages?", "author": "big-andy-coates", "createdAt": "2020-01-27T19:56:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMDg3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMjA2MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370132060", "bodyText": "From a useability point of view, how does the user know which insert statement contained invalid JSON?  Could we include the text maybe?", "author": "big-andy-coates", "createdAt": "2020-01-23T13:59:31Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -545,6 +548,70 @@ public void shouldHandleErrorInProcessingInserts() throws Exception {\n     assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n   }\n \n+  @Test\n+  public void shouldRejectMalformedJsonInInsertsStreamArgs() throws Exception {\n+    shouldRejectMalformedJsonInArgs(\"/inserts-stream\");\n+  }\n+\n+  @Test\n+  public void shouldHandleMalformedJsonInInsertsStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (int i = 0; i < rows.size() - 1; i++) {\n+      JsonObject row = rows.get(i);\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+    // Malformed row for the last one\n+    requestBody.appendString(\"{ijqwdijqw\");\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    validateError(ERROR_CODE_INVALID_JSON, \"Invalid JSON in inserts stream\", insertsResponse.error);", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyMTkwOA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370221908", "bodyText": "I'm usually wary of including actual data in any error messages or exceptions as often these can end up being logged somewhere by someone which can lead to data privacy issues.", "author": "purplefox", "createdAt": "2020-01-23T16:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMjA2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTQ1MTE0NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r371451144", "bodyText": "It's a valid concern. We get around this in other places by allowing the user to control this via a config.  Off by default.", "author": "big-andy-coates", "createdAt": "2020-01-27T19:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMjA2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTc5NA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370135794", "bodyText": "What's the benefit of accepting a supplier, rather than the actual value, given the code immediately calls get() on the supplier, and only calls get() once?  Surely this can be simplified to just take the actual value?", "author": "big-andy-coates", "createdAt": "2020-01-23T14:06:16Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestUtils.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+import org.hamcrest.Matcher;\n+\n+public class TestUtils {\n+\n+  public static void awaitLatch(CountDownLatch latch) throws Exception {\n+    assertThat(latch.await(2000, TimeUnit.MILLISECONDS), is(true));\n+  }\n+\n+  public static class AsyncAssert {\n+\n+    private AssertionError error;\n+\n+    public synchronized <T> void assertAsync(Supplier<? extends T> actualSupplier,\n+        Matcher<? super T> expected) {\n+      try {\n+        assertThat(actualSupplier.get(), expected);\n+      } catch (AssertionError e) {\n+        error = e;\n+      }\n+    }", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyODU2NQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370228565", "bodyText": "ack, copy and paste", "author": "purplefox", "createdAt": "2020-01-23T16:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTc5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDA3Mg==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140072", "bodyText": "Unnecessary override: this can just be deleted, right?", "author": "big-andy-coates", "createdAt": "2020-01-23T14:13:50Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssert.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyOTI1MA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370229250", "bodyText": "sometimes it's nice to be explicit, but yes", "author": "purplefox", "createdAt": "2020-01-23T16:39:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDEyNQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140125", "bodyText": "Unnecessary override: this can just be deleted, right?", "author": "big-andy-coates", "createdAt": "2020-01-23T14:13:56Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssert.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+    assertThat(subscriber.getValues(), hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    asyncAssert.throwAssert();\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecordsNoBuffering() throws Exception {\n+    AsyncAssert asyncAssertOnNext = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssertOnNext.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyOTM2OA==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370229368", "bodyText": "as above", "author": "purplefox", "createdAt": "2020-01-23T16:39:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDEyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDQxMQ==", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140411", "bodyText": "If you had TestSubscriber's constructor take the initial request size you could simplify a lot of these tests.", "author": "big-andy-coates", "createdAt": "2020-01-23T14:14:27Z", "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }", "originalCommit": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}