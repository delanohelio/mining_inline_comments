{"pr_number": 5552, "pr_title": "fix: improve print topic", "pr_createdAt": "2020-06-04T14:56:01Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5552", "timeline": [{"oid": "e323c15c0d7d9b449514abace642f9f10e38f46f", "url": "https://github.com/confluentinc/ksql/commit/e323c15c0d7d9b449514abace642f9f10e38f46f", "message": "fix: improve print topic\n\nPRINT topic tries to determine the format of a topic's key and value.  Sometimes it can mis-detect the key. For example, if the key is a string, and the first value is `Die Hard` (as bytes) then it would interpret this as a `BIGINT` as its eight bytes.  Once it seems more rows it will likely work out the key is a `STRING`, (assuming at least one key is not 8bytes long.\n\nWith this change PRINT will process the whole batch of messages retrieved from the broker to determine the formats and only then output them. This makes it much more likely it will output the first few rows with the right formats, at the cost of formatting all the rows in the batch, even if the user only wanted to see one or two.", "committedDate": "2020-06-04T14:55:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMDM4OA==", "url": "https://github.com/confluentinc/ksql/pull/5552#discussion_r435520388", "bodyText": "Why do call formatRecords here again when you already formatted them at line 110?", "author": "vpapavas", "createdAt": "2020-06-04T20:09:43Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/RecordFormatter.java", "diffHunk": "@@ -103,10 +103,25 @@ public RecordFormatter(\n     this.valueDeserializers = requireNonNull(valueDeserializers, \"valueDeserializers\");\n   }\n \n-  public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n-    return StreamSupport.stream(records.spliterator(), false)\n-        .map(this::delayedFormat)\n-        .collect(Collectors.toList());\n+  public List<String> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n+    final String activeKeyFormat = keyDeserializers.getPossibleFormats().get(0);\n+    final String activeValueFormat = valueDeserializers.getPossibleFormats().get(0);\n+\n+    final List<String> formatted = formatRecords(records);\n+\n+    final boolean sameKeyFormatChanged = activeKeyFormat\n+        .equals(keyDeserializers.getPossibleFormats().get(0));\n+\n+    final boolean sameValueFormatChanged = activeValueFormat\n+        .equals(valueDeserializers.getPossibleFormats().get(0));\n+\n+    if (sameKeyFormatChanged && sameValueFormatChanged) {\n+      return formatted;\n+    }\n+\n+    // The active key/value format has been eliminated as a possibility while processing this batch.\n+    // Reformat with the new active format:\n+    return formatRecords(records);", "originalCommit": "e323c15c0d7d9b449514abace642f9f10e38f46f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTgwNTYwNA==", "url": "https://github.com/confluentinc/ksql/pull/5552#discussion_r435805604", "bodyText": "As the comment says: because the active key or value format has changed during the processing of the batch.\nFor example, if processing the second record in the batch eliminates the KAFKA_BIGINT key format, then the first row, which will have been formatted using KAFKA_BIGINT needs to be processed again, otherwise it will be printed out wrong.\nThis is the whole point of the PR!", "author": "big-andy-coates", "createdAt": "2020-06-05T09:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMDM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMTQzOQ==", "url": "https://github.com/confluentinc/ksql/pull/5552#discussion_r435521439", "bodyText": "This is that sets the batch size? So if it is not set then it is (Integer.MAX_VALUE) - numWritten  where numWritten is what has been processed up to this point?", "author": "vpapavas", "createdAt": "2020-06-04T20:11:41Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PrintPublisher.java", "diffHunk": "@@ -112,8 +110,8 @@ public void subscribe(final Flow.Subscriber<Collection<String>> subscriber) {\n           return null;\n         }\n \n-        final Collection<Supplier<String>> formatted = formatter.format(records);\n-        final Collection<Supplier<String>> limited = new LimitIntervalCollection<>(\n+        final Collection<String> formatted = formatter.format(records);\n+        final Collection<String> limited = new LimitIntervalCollection<>(\n             formatted,\n             printTopic.getLimit().orElse(Integer.MAX_VALUE) - numWritten,", "originalCommit": "e323c15c0d7d9b449514abace642f9f10e38f46f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTgwNjk1MQ==", "url": "https://github.com/confluentinc/ksql/pull/5552#discussion_r435806951", "bodyText": "If by batch size you're talking about the size of the batch of records pull from Kafka, then no.  That's controlled by the consumer config.\nThis code is only handling any LIMIT statement.", "author": "big-andy-coates", "createdAt": "2020-06-05T09:37:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyMTQzOQ=="}], "type": "inlineReview"}]}