{"pr_number": 8829, "pr_title": "KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter", "pr_createdAt": "2020-06-07T22:57:58Z", "pr_url": "https://github.com/apache/kafka/pull/8829", "timeline": [{"oid": "c2867f70bc491f87329736487aaf68663c50f4a5", "url": "https://github.com/apache/kafka/commit/c2867f70bc491f87329736487aaf68663c50f4a5", "message": "KAFKA-10115: Incorporate errors.tolerance with the Errant Record Reporter", "committedDate": "2020-06-08T21:14:11Z", "type": "commit"}, {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "url": "https://github.com/apache/kafka/commit/0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "message": "addressed comments", "committedDate": "2020-06-10T22:21:21Z", "type": "commit"}, {"oid": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "url": "https://github.com/apache/kafka/commit/0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "message": "addressed comments", "committedDate": "2020-06-10T22:21:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1MjE1MQ==", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438452151", "bodyText": "instead, you can just check:\n        if (retryWithToleranceOperator.failed()) {\n            throw retryWithToleranceOperator.error();\n        }\n\nbecause we are already storing the error in the processing context. you can expose that through the operator.", "author": "wicknicks", "createdAt": "2020-06-10T22:58:33Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -556,6 +556,9 @@ private void deliverMessages() {\n             log.trace(\"{} Delivering batch of {} messages to task\", this, messageBatch.size());\n             long start = time.milliseconds();\n             task.put(new ArrayList<>(messageBatch));\n+            if (workerErrantRecordReporter != null && workerErrantRecordReporter.mustThrowException()) {\n+                throw workerErrantRecordReporter.getExceptionToThrow();\n+            }", "originalCommit": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ1MjY5Ng==", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438452696", "bodyText": "we don't need these vars, the errors are already stored in the ProcessingContext. look at comment above.", "author": "wicknicks", "createdAt": "2020-06-10T23:00:11Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/errors/WorkerErrantRecordReporter.java", "diffHunk": "@@ -99,8 +102,15 @@ public WorkerErrantRecordReporter(\n                 valLength, key, value, headers);\n         }\n \n-        Future<Void> future = retryWithToleranceOperator.executeFailed(Stage.TASK_PUT,\n-            SinkTask.class, consumerRecord, error);\n+        Future<Void> future;\n+        try {\n+            future = retryWithToleranceOperator.executeFailed(Stage.TASK_PUT,\n+                SinkTask.class, consumerRecord, error);\n+        } catch (ConnectException e) {\n+            mustThrowException = true;\n+            exceptionToThrow = e;\n+            throw e;\n+        }", "originalCommit": "0ce4daf669d95320c9ab096b7dbc207786aaeeb8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "url": "https://github.com/apache/kafka/commit/603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "message": "addressed comments", "committedDate": "2020-06-10T23:55:34Z", "type": "commit"}, {"oid": "aefe73ffc3e6173a2427bd3dfb957d776d4088fd", "url": "https://github.com/apache/kafka/commit/aefe73ffc3e6173a2427bd3dfb957d776d4088fd", "message": "moved errant record reporter test", "committedDate": "2020-06-11T00:20:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NTM1NQ==", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438475355", "bodyText": "minor: we should move this test to ErrorHandlingIntegrationTest. this class was meant to be an example of how to do integration tests.", "author": "wicknicks", "createdAt": "2020-06-11T00:17:22Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/ExampleConnectIntegrationTest.java", "diffHunk": "@@ -237,6 +239,7 @@ public void testErrantRecordReporter() throws Exception {\n         props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n         props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n         props.put(DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);\n+        props.put(ERRORS_TOLERANCE_CONFIG, ToleranceType.ALL.value());", "originalCommit": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NjcyMg==", "url": "https://github.com/apache/kafka/pull/8829#discussion_r438476722", "bodyText": "let's add a small comment saying why we need to do this: specifically, that if the errors raised from the operator were swallowed by the task implementation, then here we need to kill the task, and if they were not swallowed, we would not get here.", "author": "wicknicks", "createdAt": "2020-06-11T00:22:32Z", "path": "connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSinkTask.java", "diffHunk": "@@ -556,6 +556,10 @@ private void deliverMessages() {\n             log.trace(\"{} Delivering batch of {} messages to task\", this, messageBatch.size());\n             long start = time.milliseconds();\n             task.put(new ArrayList<>(messageBatch));\n+            if (retryWithToleranceOperator.failed() && !retryWithToleranceOperator.withinToleranceLimits()) {", "originalCommit": "603217f1ed0e68295b5a6cfd0bc2fd09ba9f681d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c3324cce90f8379c69c8538b594edd29e83f7fe1", "url": "https://github.com/apache/kafka/commit/c3324cce90f8379c69c8538b594edd29e83f7fe1", "message": "more comments", "committedDate": "2020-06-11T00:44:15Z", "type": "commit"}]}