{"pr_number": 8629, "pr_title": "MINOR: Log4j Improvements on Fetcher", "pr_createdAt": "2020-05-07T05:58:15Z", "pr_url": "https://github.com/apache/kafka/pull/8629", "timeline": [{"oid": "859e03c0db2f9f6f7098e8a1bfca7cc4aadb7fa7", "url": "https://github.com/apache/kafka/commit/859e03c0db2f9f6f7098e8a1bfca7cc4aadb7fa7", "message": "the fix", "committedDate": "2020-05-07T05:50:17Z", "type": "commit"}, {"oid": "662364f34c93783cf9ef99377443c102b30afa7d", "url": "https://github.com/apache/kafka/commit/662364f34c93783cf9ef99377443c102b30afa7d", "message": "revert", "committedDate": "2020-05-07T15:56:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxOTM5Mw==", "url": "https://github.com/apache/kafka/pull/8629#discussion_r421619393", "bodyText": "I assume this was unintentional.", "author": "hachikuji", "createdAt": "2020-05-07T16:03:25Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -260,7 +260,7 @@ public synchronized int sendFetches() {\n             }\n             RequestFuture<ClientResponse> future = client.send(fetchTarget, request);\n             // We add the node to the set of nodes with pending fetch requests before adding the\n-            // listener because the future may have been fulfilled on another thread (e.g. during a\n+            // listenerbecause the future may have been fulfilled on another thread (e.g. during a", "originalCommit": "662364f34c93783cf9ef99377443c102b30afa7d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY0MzUyNg==", "url": "https://github.com/apache/kafka/pull/8629#discussion_r421643526", "bodyText": "I feel logging all of the records even at TRACE level will be too much. For example, our system tests often have TRACE enabled. Huge single-line log messages are difficult to consume both visually and in systems like elastic.", "author": "hachikuji", "createdAt": "2020-05-07T16:41:06Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -676,13 +676,15 @@ private ListOffsetResult fetchOffsetsByTimes(Map<TopicPartition, Long> timestamp\n             if (completedFetch.nextFetchOffset == position.offset) {\n                 List<ConsumerRecord<K, V>> partRecords = completedFetch.fetchRecords(maxRecords);\n \n+                log.trace(\"Returning fetched records {} at offset {} for assigned partition {}\",\n+                        partRecords, position, completedFetch.partition);", "originalCommit": "662364f34c93783cf9ef99377443c102b30afa7d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NDkzMg==", "url": "https://github.com/apache/kafka/pull/8629#discussion_r421654932", "bodyText": "Makes sense, it is primarily for my local debugging of an integration test which only sends a couple records. I will only print the num.records instead.", "author": "guozhangwang", "createdAt": "2020-05-07T16:59:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY0MzUyNg=="}], "type": "inlineReview"}, {"oid": "eab85ef671c48ddd0aa4f2f1e4f5cfb81449b0f2", "url": "https://github.com/apache/kafka/commit/eab85ef671c48ddd0aa4f2f1e4f5cfb81449b0f2", "message": "minor fixes", "committedDate": "2020-05-07T17:00:39Z", "type": "commit"}]}