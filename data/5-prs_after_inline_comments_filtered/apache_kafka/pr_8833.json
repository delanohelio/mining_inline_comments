{"pr_number": 8833, "pr_title": "KAFKA-9441: remove prepareClose() to simplify task management", "pr_createdAt": "2020-06-08T17:12:21Z", "pr_url": "https://github.com/apache/kafka/pull/8833", "timeline": [{"oid": "139bceb054bfdc49309e177cd9265d97716da196", "url": "https://github.com/apache/kafka/commit/139bceb054bfdc49309e177cd9265d97716da196", "message": "KAFKA-9441: remove closePrepare() to simplify task management", "committedDate": "2020-06-09T17:44:32Z", "type": "commit"}, {"oid": "1be5d9216ac5f98d3de87a7f86218dca906455f6", "url": "https://github.com/apache/kafka/commit/1be5d9216ac5f98d3de87a7f86218dca906455f6", "message": "Add missing tests", "committedDate": "2020-06-09T17:48:26Z", "type": "commit"}, {"oid": "54f24e4b8d844d6ee3438648fb9714ecad97e350", "url": "https://github.com/apache/kafka/commit/54f24e4b8d844d6ee3438648fb9714ecad97e350", "message": "Github comments", "committedDate": "2020-06-09T17:48:26Z", "type": "commit"}, {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "url": "https://github.com/apache/kafka/commit/120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "message": "Rebased", "committedDate": "2020-06-09T18:12:29Z", "type": "commit"}, {"oid": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "url": "https://github.com/apache/kafka/commit/120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "message": "Rebased", "committedDate": "2020-06-09T18:12:29Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4ODQwOQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437688409", "bodyText": "Could we merge RESTORING and SUSPENDED?", "author": "abbccdda", "createdAt": "2020-06-09T20:09:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzA1Nw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437767057", "bodyText": "+1, IDEA also suggests it :)", "author": "guozhangwang", "createdAt": "2020-06-09T22:57:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY4ODQwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5MTQyOA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437691428", "bodyText": "add a @return comment for the struct", "author": "abbccdda", "createdAt": "2020-06-09T20:15:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/Task.java", "diffHunk": "@@ -122,44 +123,23 @@ public boolean isValidTransition(final State newState) {\n     /**\n      * @throws StreamsException fatal error, should close the thread\n      */\n-    void prepareCommit();\n+    Map<TopicPartition, OffsetAndMetadata> prepareCommit();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437697665", "bodyText": "I could get a follow-up newbie ticket, but it seems that we have a couple of catch and swallow cases in the task manager with clean flag, does it make sense to extract the executeAndMaybeSwallow to TaskManager class and share between cases?", "author": "abbccdda", "createdAt": "2020-06-09T20:26:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -623,7 +618,11 @@ private long sumOfChangelogOffsets(final TaskId id, final Map<TopicPartition, Lo\n     }\n \n     private void closeTaskDirty(final Task task) {\n-        task.prepareCloseDirty();\n+        try {\n+            task.suspend();\n+        } catch (final RuntimeException swallow) {", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NTMzNA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437775334", "bodyText": "SGTM. Can you create a ticket?", "author": "mjsax", "createdAt": "2020-06-09T23:22:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI1MzU0Ng==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438253546", "bodyText": "Done", "author": "abbccdda", "createdAt": "2020-06-10T16:23:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5NzY2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5ODU1OA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437698558", "bodyText": "What does this lastCall suggest?", "author": "abbccdda", "createdAt": "2020-06-09T20:28:45Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StandbyTaskTest.java", "diffHunk": "@@ -476,6 +445,26 @@ public void shouldDeleteStateDirOnTaskCreatedAndEosBetaUncleanClose() {\n         assertEquals(Task.State.CLOSED, task.state());\n     }\n \n+    @Test\n+    public void shouldRecycleTask() {\n+        EasyMock.expectLastCall();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NTQyMg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437775422", "bodyText": "Ups.", "author": "mjsax", "createdAt": "2020-06-09T23:22:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY5ODU1OA=="}], "type": "inlineReview"}, {"oid": "141c4d018a857b29253c3cc0c114928f5328c558", "url": "https://github.com/apache/kafka/commit/141c4d018a857b29253c3cc0c114928f5328c558", "message": "Github comments", "committedDate": "2020-06-09T23:24:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MTAyMg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437761022", "bodyText": "The comment below is not accurate anymore: we do not write checkpoint during recycle actually.\nEDIT: actually, the updated offsetSnapshotSinceLastCommit seems not used since after this function we would create a new StreamTask and in between we do not check if commitNeeded at all. Could we remove line 175 then?", "author": "guozhangwang", "createdAt": "2020-06-09T22:39:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,69 +151,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();\n \n-        if (state() == State.CREATED || state() == State.RUNNING) {\n+        if (state() == State.CREATED || state() == State.SUSPENDED) {", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2MjQ2OQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437762469", "bodyText": "Ditto for line 195: we do not need to update the snapshot since we are closing the task already.", "author": "guozhangwang", "createdAt": "2020-06-09T22:43:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -232,7 +187,7 @@ public void closeAndRecycleState() {\n     private void close(final boolean clean) {\n         switch (state()) {\n             case CREATED:\n-            case RUNNING:\n+            case SUSPENDED:", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437766716", "bodyText": "Maybe we can skip calling this if we are in RESTORING; I have another comment below.\nAlso could we add javadoc on top explaining what exception can be thrown?", "author": "guozhangwang", "createdAt": "2020-06-09T22:56:14Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -247,82 +246,23 @@ public void completeRestoration() {\n         }\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     *  4. then commit the record collector -- for EOS this is the synchronization barrier\n-     *  5. then checkpoint the state manager -- even if we crash before this step, EOS is still guaranteed\n-     * </pre>\n-     *\n-     * @throws TaskMigratedException if committing offsets failed (non-EOS)\n-     *                               or if the task producer got fenced (EOS)\n-     */\n-    @Override\n-    public void prepareSuspend() {\n-        switch (state()) {\n-            case CREATED:\n-            case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip prepare suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RESTORING:\n-                stateMgr.flush();\n-                log.info(\"Prepare suspending restoring\");\n-\n-                break;\n-\n-            case RUNNING:\n-                closeTopology(true);\n-\n-                stateMgr.flush();\n-                recordCollector.flush();\n-\n-                log.info(\"Prepare suspending running\");\n-\n-                break;\n-\n-            case CLOSED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while suspending active task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while suspending active task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void suspend() {\n         switch (state()) {\n             case CREATED:\n             case SUSPENDED:\n-                // do nothing\n-                log.trace(\"Skip suspending since state is {}\", state());\n-\n-                break;\n-\n-            case RUNNING:\n-                stateMgr.checkpoint(checkpointableOffsets());\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended running\");\n+                log.info(\"Skip suspending since state is {}\", state());\n \n                 break;\n \n             case RESTORING:\n-                // we just checkpoint the position that we've restored up to without\n-                // going through the commit process\n-                stateMgr.checkpoint(emptyMap());\n-\n-                // we should also clear any buffered records of a task when suspending it\n-                partitionGroup.clear();\n-\n-                transitionTo(State.SUSPENDED);\n-                log.info(\"Suspended restoring\");\n+            case RUNNING:\n+                try {\n+                    closeTopology();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgyOTU1NQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437829555", "bodyText": "Is this addressed?", "author": "abbccdda", "createdAt": "2020-06-10T02:46:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MTA4Mw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438361083", "bodyText": "Yes. RESTORING above is it's own \"case\" branch now (before RUNNING and RESTORING was shared the code).", "author": "mjsax", "createdAt": "2020-06-10T19:33:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NjcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437767910", "bodyText": "Maybe we can make an optimization by remembering the committableOffsets, and then if the value (both offset and time) does not change we do not need to give it out to consumer to commit.", "author": "guozhangwang", "createdAt": "2020-06-09T22:59:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5Njg4MA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437796880", "bodyText": "Well, what is the probability that it did not change? Feel free to file a ticket if you think it's worth it, but I would like to not piggy-back other things into the PR>", "author": "mjsax", "createdAt": "2020-06-10T00:38:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI0Mzc5Nw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438243797", "bodyText": "+1, this seems not really necessary atm.", "author": "abbccdda", "createdAt": "2020-06-10T16:10:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI3ODgzNQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438278835", "bodyText": "Sounds fair, we can do that in another PR.", "author": "guozhangwang", "createdAt": "2020-06-10T17:05:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2NzkxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437768897", "bodyText": "Why we need this check?\nAlso nit: how about maybeWriteCheckpoint to align with maybeScheduleCheckpoint.", "author": "guozhangwang", "createdAt": "2020-06-09T23:02:25Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();\n         writeCheckpointIfNeed();\n \n         switch (state()) {\n             case CREATED:\n-            case RESTORING:\n-            case RUNNING:\n             case SUSPENDED:\n                 stateMgr.recycle();\n                 recordCollector.close();\n+\n                 break;\n+\n+            case RESTORING: // we should have transitioned to `SUSPENDED` already\n+            case RUNNING: // we should have transitioned to `SUSPENDED` already\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while recycling active task \" + id);\n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while recycling active task \" + id);\n         }\n \n-        partitionGroup.close();\n+        partitionGroup.clear();\n         closeTaskSensor.record();\n \n         transitionTo(State.CLOSED);\n \n         log.info(\"Closed clean and recycled state\");\n     }\n \n-    /**\n-     * <pre>\n-     * the following order must be followed:\n-     *  1. first close topology to make sure all cached records in the topology are processed\n-     *  2. then flush the state, send any left changelog records\n-     *  3. then flush the record collector\n-     * </pre>\n-     *\n-     * @param clean    shut down cleanly (ie, incl. flush) if {@code true} --\n-     *                 otherwise, just close open resources\n-     * @throws TaskMigratedException if the task producer got fenced (EOS)\n-     */\n-    private void prepareClose(final boolean clean) {\n-        // Reset any previously scheduled checkpoint.\n-        checkpoint = null;\n-\n+    private void maybeScheduleCheckpoint() {\n         switch (state()) {\n-            case CREATED:\n-                // the task is created and not initialized, just re-write the checkpoint file\n-                scheduleCheckpoint(emptyMap());\n+            case RESTORING:\n+                this.checkpoint = checkpointableOffsets();\n+\n                 break;\n \n             case RUNNING:\n-                closeTopology(clean);\n-\n-                if (clean) {\n-                    stateMgr.flush();\n-                    recordCollector.flush();\n-                    scheduleCheckpoint(checkpointableOffsets());\n-                } else {\n-                    executeAndMaybeSwallow(false, stateMgr::flush, \"state manager flush\", log);\n+                if (!eosEnabled) {\n+                    this.checkpoint = checkpointableOffsets();\n                 }\n \n                 break;\n \n-            case RESTORING:\n-                executeAndMaybeSwallow(clean, stateMgr::flush, \"state manager flush\", log);\n-                scheduleCheckpoint(emptyMap());\n+            case SUSPENDED:\n+                this.checkpoint = checkpointableOffsets();\n \n                 break;\n \n-            case SUSPENDED:\n+            case CREATED:\n             case CLOSED:\n-                // not need to checkpoint, since when suspending we've already committed the state\n-                break;\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while scheduling checkpoint for active task \" + id);\n \n             default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while prepare closing active task \" + id);\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while scheduling checkpoint for active task \" + id);\n         }\n     }\n \n-    private void scheduleCheckpoint(final Map<TopicPartition, Long> checkpoint) {\n-        this.checkpoint = checkpoint;\n-    }\n-\n     private void writeCheckpointIfNeed() {\n+        if (commitNeeded) {", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NzQ1Ng==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437797456", "bodyText": "Why do we need any check? To avoid bugs :)\nIf like the different names, because \"maybe\" indicated that the method makes a decision, while \"ifNeeded\" implies that the methods executed a decision that was already made? At least my personal interpretation?", "author": "mjsax", "createdAt": "2020-06-10T00:40:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4MjAwMw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438282003", "bodyText": "okay, fair enough :)\n\n\nactually I think we use maybeXXX and YYYIfNeeded across the repo for both semantics :) my very paranoid nit intention is to just make the private function names more aligned. Your call.", "author": "guozhangwang", "createdAt": "2020-06-10T17:11:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2OTUxNw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438369517", "bodyText": "If we want to align them, I would recommend to go a single PR to align all of them at once :)", "author": "mjsax", "createdAt": "2020-06-10T19:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk1Mzc2Ng==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438953766", "bodyText": "@mjsax  By should only be written if no commit is needed do you mean ...if a commit was just completed?\nDoesn't this break closeAndRecycleState (I thought iI saw in another comment that we don't write checkpoints during recycle anymore?)", "author": "ableegoldman", "createdAt": "2020-06-11T17:33:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODk1NzYyMQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438957621", "bodyText": "Maybe I'm thinking of standby tasks (ie we only skip checkpointing for recycled standbys). For active tasks, we should probably commit them before recycling right? Or is it ok to skip committing altogether \ud83e\udd14", "author": "ableegoldman", "createdAt": "2020-06-11T17:40:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTAwNDk4Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439004982", "bodyText": "@guozhangwang  Just saw this in the SmokeTestDriverIntegrationTest#shouldWorkWithRebalance -- not sure if it merits a separate ticket or can just be fixed together with https://issues.apache.org/jira/browse/KAFKA-10150 ?\nCaused by: java.lang.IllegalStateException: A checkpoint should only be written if no commit is needed.\n\tat org.apache.kafka.streams.processor.internals.StreamTask.writeCheckpointIfNeed(StreamTask.java:534)\n\tat org.apache.kafka.streams.processor.internals.StreamTask.closeAndRecycleState(StreamTask.java:482)\n\tat org.apache.kafka.streams.processor.internals.StandbyTaskCreator.createStandbyTaskFromActive(StandbyTaskCreator.java:115)\n\tat org.apache.kafka.streams.processor.internals.TaskManager.handleAssignment(TaskManager.java:288)", "author": "ableegoldman", "createdAt": "2020-06-11T18:59:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA3NDg2OQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439074869", "bodyText": "Nice catch. Let's just fix it along with 10150?", "author": "guozhangwang", "createdAt": "2020-06-11T21:16:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA3NTc4OQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439075789", "bodyText": "Too late, I already created a ticket for it \ud83d\ude42 But after starting to work on it, I agree, they should be addressed in one PR", "author": "ableegoldman", "createdAt": "2020-06-11T21:18:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2ODg5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc2OTY2NA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437769664", "bodyText": "What about 1) move the line 387/388 out of the switch, also line 400 after the switch block, 2) and then make these three states separate branches, so that we can avoid a mix of switch / if-else.", "author": "guozhangwang", "createdAt": "2020-06-09T23:04:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437771042", "bodyText": "Hmm... this reads a bit weird to me. Can we call this in suspend instead? Also in that case we do not need to call this in close and closeAndRecycle.", "author": "guozhangwang", "createdAt": "2020-06-09T23:08:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -378,42 +320,88 @@ public void prepareCommit() {\n                 break;\n \n             case CREATED:\n-            case SUSPENDED:\n             case CLOSED:\n                 throw new IllegalStateException(\"Illegal state \" + state() + \" while preparing active task \" + id + \" for committing\");\n \n             default:\n                 throw new IllegalStateException(\"Unknown state \" + state() + \" while preparing active task \" + id + \" for committing\");\n         }\n+\n+        return committableOffsetsAndMetadata();\n     }\n \n-    @Override\n-    public void postCommit() {\n+    private Map<TopicPartition, OffsetAndMetadata> committableOffsetsAndMetadata() {\n+        final Map<TopicPartition, OffsetAndMetadata> committableOffsets;\n+\n         switch (state()) {\n-            case RUNNING:\n-                commitNeeded = false;\n-                commitRequested = false;\n+            case CREATED:\n+            case RESTORING:\n+                committableOffsets = Collections.emptyMap();\n \n-                if (!eosEnabled) {\n-                    stateMgr.checkpoint(checkpointableOffsets());\n-                }\n+                break;\n \n-                log.debug(\"Committed\");\n+            case RUNNING:\n+            case SUSPENDED:\n+                final Map<TopicPartition, Long> partitionTimes = extractPartitionTimes();\n+\n+                committableOffsets = new HashMap<>(consumedOffsets.size());\n+                for (final Map.Entry<TopicPartition, Long> entry : consumedOffsets.entrySet()) {\n+                    final TopicPartition partition = entry.getKey();\n+                    Long offset = partitionGroup.headRecordOffset(partition);\n+                    if (offset == null) {\n+                        try {\n+                            offset = mainConsumer.position(partition);\n+                        } catch (final TimeoutException error) {\n+                            // the `consumer.position()` call should never block, because we know that we did process data\n+                            // for the requested partition and thus the consumer should have a valid local position\n+                            // that it can return immediately\n+\n+                            // hence, a `TimeoutException` indicates a bug and thus we rethrow it as fatal `IllegalStateException`\n+                            throw new IllegalStateException(error);\n+                        } catch (final KafkaException fatal) {\n+                            throw new StreamsException(fatal);\n+                        }\n+                    }\n+                    final long partitionTime = partitionTimes.get(partition);\n+                    committableOffsets.put(partition, new OffsetAndMetadata(offset, encodeTimestamp(partitionTime)));\n+                }\n \n                 break;\n \n+            case CLOSED:\n+                throw new IllegalStateException(\"Illegal state \" + state() + \" while getting commitable offsets for active task \" + id);\n+\n+            default:\n+                throw new IllegalStateException(\"Unknown state \" + state() + \" while post committing active task \" + id);\n+        }\n+\n+        return committableOffsets;\n+    }\n+\n+    @Override\n+    public void postCommit() {\n+        switch (state()) {\n             case RESTORING:\n-                commitNeeded = false;\n+            case RUNNING:\n+            case SUSPENDED:\n                 commitRequested = false;\n+                commitNeeded = false;\n+\n+                if (state() == State.RESTORING || state() == State.SUSPENDED) {\n+                    writeCheckpointIfNeed();\n+                } else if (!eosEnabled) { // if RUNNING, checkpoint only for non-eos\n+                    writeCheckpointIfNeed();\n+                }\n \n-                stateMgr.checkpoint(checkpointableOffsets());\n+                if (state() == State.SUSPENDED) {\n+                    partitionGroup.clear();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMDA4Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437800082", "bodyText": "We cannot call it in suspend, because we would loose the partition-time information that we need in prepareCommit() (that is called after suspend()).", "author": "mjsax", "createdAt": "2020-06-10T00:50:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI4Mjc1Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438282752", "bodyText": "Got it, makes sense.\nCould you copy-paste the above as comment to remind other readers?", "author": "guozhangwang", "createdAt": "2020-06-10T17:12:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM3MDA4OQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438370089", "bodyText": "Sure -- but if they change it (I also did the change originally) a unit test fails anyway :)", "author": "mjsax", "createdAt": "2020-06-10T19:50:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MTA0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzE1Mw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437773153", "bodyText": "I think we actually do not need to commit (including write-checkpoint) when closeAndRecycle actually, and only need to suspend the task before recycle it. But this is out of the scope and we can discuss about this in another PR (cc @ableegoldman ).", "author": "guozhangwang", "createdAt": "2020-06-09T23:15:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -504,88 +438,66 @@ public void update(final Set<TopicPartition> topicPartitions, final Map<String,\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n-\n+        suspend();\n+        prepareCommit();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMDU1MQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437800551", "bodyText": "Assuming rebalancing does not happen often (in a stable deployment) it might be re-mature optimization?", "author": "mjsax", "createdAt": "2020-06-10T00:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzE1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437773582", "bodyText": "Should we return emptyMap if we are SUSPENDED as well?", "author": "guozhangwang", "createdAt": "2020-06-09T23:16:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -813,6 +727,10 @@ private void updateProcessorContext(final StampedRecord record, final ProcessorN\n      * Currently only changelog topic offsets need to be checkpointed.\n      */\n     private Map<TopicPartition, Long> checkpointableOffsets() {\n+        if (state() == State.RESTORING) {", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NDYwNg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437774606", "bodyText": "EDIT: actually, I think we need to accumulate the consumed offsets when we just transited to suspend and then called prepareCommit, but if we are already in suspended then it is actually okay to return an emptyMap. However since we do not know if we have just transited to suspended and the below code should not be a big overhead, we can just keep it as-is.\nSo please ignore my previous comment :)", "author": "guozhangwang", "createdAt": "2020-06-09T23:20:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODI1MjA5Nw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438252097", "bodyText": "Is this logic necessary? I don't think we would populate data in record collector or consumed offsets until we start processing?", "author": "abbccdda", "createdAt": "2020-06-10T16:21:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODAyNw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438368027", "bodyText": "Good point!", "author": "mjsax", "createdAt": "2020-06-10T19:46:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3MzU4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437776706", "bodyText": "question: I cannot remember why we need to commit those still owned tasks during handle-assignment, is that necessary? Or is that just an optimization: since we are going to commit anyways, let's just commit everyone.\nIf that's the case, we can refresh the last-commit timestamp as well.", "author": "guozhangwang", "createdAt": "2020-06-09T23:26:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -210,9 +214,8 @@ public void handleAssignment(final Map<TaskId, Set<TopicPartition>> activeTasks,\n                 tasksToRecycle.add(task);\n             } else {\n                 try {\n-                    task.prepareCloseClean();\n-                    final Map<TopicPartition, OffsetAndMetadata> committableOffsets = task\n-                        .committableOffsetsAndMetadata();\n+                    task.suspend();", "originalCommit": "120fb8d8134add8aeb4b402c1e0ecd54a5b673a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NzI0NQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437777245", "bodyText": "Even in that case, in line 205 we could check task.commitNeeded() && task.isActive right?", "author": "guozhangwang", "createdAt": "2020-06-09T23:28:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgwMjMyOQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r437802329", "bodyText": "For eoa-beta, if we commit, we alway need to commit all tasks. And to not distinguish between non-eos/eos-alpha vs eos-beta, be decided to just commit all tasks for all cases.\nAnd we don't own StreamThread#lastCommitMs so we cannot update it.\nFor L205: the outter if checks already if task.isActive", "author": "mjsax", "createdAt": "2020-06-10T00:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA4NjQxNg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439086416", "bodyText": "@mjsax @guozhangwang why do we need to commit at all during handleAssignment? Shouldn't we have already committed all tasks that need to be committed during handleRevocation?\nThat's not exactly a bug, I'm just wondering if it's necessary?", "author": "ableegoldman", "createdAt": "2020-06-11T21:44:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA5MzM3Mg==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r439093372", "bodyText": "We may not call handleRevocation before calling handleAssignment so the task to close may not be in SUSPENDED state yet, and hence do close them we need to commit their states. For other tasks, they are not necessarily committing but I think the point was, that since we are going to send one commit request anyways so just commit for everyone --- note that flushing can indeed be skipped, which is what KAFKA-9450 covers", "author": "guozhangwang", "createdAt": "2020-06-11T21:55:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NjcwNg=="}], "type": "inlineReview"}, {"oid": "c4b266602250f63b6c11b8612997aee2f10db871", "url": "https://github.com/apache/kafka/commit/c4b266602250f63b6c11b8612997aee2f10db871", "message": "Github comments", "committedDate": "2020-06-10T01:27:30Z", "type": "commit"}, {"oid": "9e9859258b2f5bb842262549b362cc6efe85dc5d", "url": "https://github.com/apache/kafka/commit/9e9859258b2f5bb842262549b362cc6efe85dc5d", "message": "Github comments", "committedDate": "2020-06-10T20:53:48Z", "type": "commit"}, {"oid": "329e187a9187c4ea532ce88e0202402cb6f78b86", "url": "https://github.com/apache/kafka/commit/329e187a9187c4ea532ce88e0202402cb6f78b86", "message": "Github comments", "committedDate": "2020-06-10T22:32:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438462721", "bodyText": "Why call prepareCommit (or suspend for that matter)?", "author": "ableegoldman", "createdAt": "2020-06-10T23:33:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StandbyTask.java", "diffHunk": "@@ -151,73 +158,24 @@ public void postCommit() {\n         }\n     }\n \n-    @Override\n-    public void prepareCloseClean() {\n-        prepareClose(true);\n-\n-        log.info(\"Prepared clean close\");\n-    }\n-\n-    @Override\n-    public void prepareCloseDirty() {\n-        prepareClose(false);\n-\n-        log.info(\"Prepared dirty close\");\n-    }\n-\n-    /**\n-     * 1. commit if we are running and clean close;\n-     * 2. close the state manager.\n-     *\n-     * @throws TaskMigratedException all the task has been migrated\n-     * @throws StreamsException fatal error, should close the thread\n-     */\n-    private void prepareClose(final boolean clean) {\n-        switch (state()) {\n-            case CREATED:\n-            case CLOSED:\n-                log.trace(\"Skip prepare closing since state is {}\", state());\n-                return;\n-\n-            case RUNNING:\n-                if (clean) {\n-                    stateMgr.flush();\n-                }\n-\n-                break;\n-\n-            case RESTORING:\n-            case SUSPENDED:\n-                throw new IllegalStateException(\"Illegal state \" + state() + \" while closing standby task \" + id);\n-\n-            default:\n-                throw new IllegalStateException(\"Unknown state \" + state() + \" while closing standby task \" + id);\n-        }\n-    }\n-\n     @Override\n     public void closeClean() {\n         close(true);\n-\n         log.info(\"Closed clean\");\n     }\n \n     @Override\n     public void closeDirty() {\n         close(false);\n-\n         log.info(\"Closed dirty\");\n     }\n \n     @Override\n     public void closeAndRecycleState() {\n-        prepareClose(true);\n+        suspend();\n+        prepareCommit();", "originalCommit": "329e187a9187c4ea532ce88e0202402cb6f78b86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3MTI1OA==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438471258", "bodyText": "Both now do what prepareClose() did before.", "author": "mjsax", "createdAt": "2020-06-11T00:02:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3MjM3Mw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438472373", "bodyText": "I just mean, why not inline that? I'm just imagining coming back to this code in a few months and wondering why we need to suspend a task before recycling, or why we call prepareCommit but don't then actually commit, etc", "author": "ableegoldman", "createdAt": "2020-06-11T00:06:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ3NTg1Mw==", "url": "https://github.com/apache/kafka/pull/8833#discussion_r438475853", "bodyText": "Nevermind, I see that's the pattern we follow everywhere else", "author": "ableegoldman", "createdAt": "2020-06-11T00:19:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODQ2MjcyMQ=="}], "type": "inlineReview"}]}