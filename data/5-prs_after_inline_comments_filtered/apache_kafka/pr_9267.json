{"pr_number": 9267, "pr_title": "MINOR: Add debug logs for StreamThread", "pr_createdAt": "2020-09-08T16:50:08Z", "pr_url": "https://github.com/apache/kafka/pull/9267", "timeline": [{"oid": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "url": "https://github.com/apache/kafka/commit/2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "message": "MINOR: Add debug logs for StreamThread", "committedDate": "2020-09-08T16:48:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2MjI5NQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485062295", "bodyText": "runOnce was too long, according to checkStyle, so I factored out some of the execution phases.", "author": "vvcephei", "createdAt": "2020-09-08T16:50:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -612,63 +612,18 @@ void runOnce() {\n         final long startMs = time.milliseconds();\n         now = startMs;\n \n-        if (state == State.PARTITIONS_ASSIGNED) {\n-            // try to fetch some records with zero poll millis\n-            // to unblock the restoration as soon as possible\n-            records = pollRequests(Duration.ZERO);\n-        } else if (state == State.PARTITIONS_REVOKED) {\n-            // try to fetch som records with zero poll millis to unblock\n-            // other useful work while waiting for the join response\n-            records = pollRequests(Duration.ZERO);\n-        } else if (state == State.RUNNING || state == State.STARTING) {\n-            // try to fetch some records with normal poll time\n-            // in order to get long polling\n-            records = pollRequests(pollTime);\n-        } else if (state == State.PENDING_SHUTDOWN) {\n-            // we are only here because there's rebalance in progress,\n-            // just poll with zero to complete it\n-            records = pollRequests(Duration.ZERO);\n-        } else {\n-            // any other state should not happen\n-            log.error(\"Unexpected state {} during normal iteration\", state);\n-            throw new StreamsException(logPrefix + \"Unexpected state \" + state + \" during normal iteration\");\n-        }\n-\n-        final long pollLatency = advanceNowAndComputeLatency();\n-\n-        pollSensor.record(pollLatency, now);\n-        if (records != null && !records.isEmpty()) {\n-            pollRecordsSensor.record(records.count(), now);\n-            taskManager.addRecordsToTasks(records);\n-        }\n+        final long pollLatency = pollPhase();", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2MjUyNg==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485062526", "bodyText": "Just a slight rewording I thought could be clearer.", "author": "vvcephei", "createdAt": "2020-09-08T16:51:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -612,63 +612,18 @@ void runOnce() {\n         final long startMs = time.milliseconds();\n         now = startMs;\n \n-        if (state == State.PARTITIONS_ASSIGNED) {\n-            // try to fetch some records with zero poll millis\n-            // to unblock the restoration as soon as possible\n-            records = pollRequests(Duration.ZERO);\n-        } else if (state == State.PARTITIONS_REVOKED) {\n-            // try to fetch som records with zero poll millis to unblock\n-            // other useful work while waiting for the join response\n-            records = pollRequests(Duration.ZERO);\n-        } else if (state == State.RUNNING || state == State.STARTING) {\n-            // try to fetch some records with normal poll time\n-            // in order to get long polling\n-            records = pollRequests(pollTime);\n-        } else if (state == State.PENDING_SHUTDOWN) {\n-            // we are only here because there's rebalance in progress,\n-            // just poll with zero to complete it\n-            records = pollRequests(Duration.ZERO);\n-        } else {\n-            // any other state should not happen\n-            log.error(\"Unexpected state {} during normal iteration\", state);\n-            throw new StreamsException(logPrefix + \"Unexpected state \" + state + \" during normal iteration\");\n-        }\n-\n-        final long pollLatency = advanceNowAndComputeLatency();\n-\n-        pollSensor.record(pollLatency, now);\n-        if (records != null && !records.isEmpty()) {\n-            pollRecordsSensor.record(records.count(), now);\n-            taskManager.addRecordsToTasks(records);\n-        }\n+        final long pollLatency = pollPhase();\n \n         // Shutdown hook could potentially be triggered and transit the thread state to PENDING_SHUTDOWN during #pollRequests().\n         // The task manager internal states could be uninitialized if the state transition happens during #onPartitionsAssigned().\n         // Should only proceed when the thread is still running after #pollRequests(), because no external state mutation\n         // could affect the task manager state beyond this point within #runOnce().\n         if (!isRunning()) {\n-            log.debug(\"State already transits to {}, skipping the run once call after poll request\", state);\n+            log.debug(\"Thread state is already {}, skipping the run once call after poll request\", state);", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NDIwMA==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485064200", "bodyText": "I wanted to make all my new debug statements zero-cost if debug isn't enabled. Since state is volatile, resolving the arguments for this call would result in an uncached read of main memory regardless of the log level. Since we don't expect state to actually change in these few lines, I just read it once and saved it in stateSnapshot.", "author": "vvcephei", "createdAt": "2020-09-08T16:54:11Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -752,6 +712,77 @@ void runOnce() {\n         commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n     }\n \n+    private void initializeAndRestorePhase() {\n+        {\n+            // only try to initialize the assigned tasks\n+            // if the state is still in PARTITION_ASSIGNED after the poll call\n+            final State stateSnapshot = state;\n+            if (stateSnapshot == State.PARTITIONS_ASSIGNED\n+                || stateSnapshot == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n+\n+                log.debug(\"State is {}; initializing and restoring\", stateSnapshot);", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NDU4Ng==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485064586", "bodyText": "This time, we really need to read the field, so I'm guarding the method call for the common case in which debug is off.", "author": "vvcephei", "createdAt": "2020-09-08T16:54:54Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -752,6 +712,77 @@ void runOnce() {\n         commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n     }\n \n+    private void initializeAndRestorePhase() {\n+        {\n+            // only try to initialize the assigned tasks\n+            // if the state is still in PARTITION_ASSIGNED after the poll call\n+            final State stateSnapshot = state;\n+            if (stateSnapshot == State.PARTITIONS_ASSIGNED\n+                || stateSnapshot == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n+\n+                log.debug(\"State is {}; initializing and restoring\", stateSnapshot);\n+\n+                // transit to restore active is idempotent so we can call it multiple times\n+                changelogReader.enforceRestoreActive();\n+\n+                if (taskManager.tryToCompleteRestoration()) {\n+                    changelogReader.transitToUpdateStandby();\n+\n+                    setState(State.RUNNING);\n+                }\n+\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"Initialization and restore call done. State is {}\", state);\n+                }", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NTA2MA==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485065060", "bodyText": "Guarded to avoid calling records.count() when debug is off.", "author": "vvcephei", "createdAt": "2020-09-08T16:55:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -752,6 +712,77 @@ void runOnce() {\n         commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n     }\n \n+    private void initializeAndRestorePhase() {\n+        {\n+            // only try to initialize the assigned tasks\n+            // if the state is still in PARTITION_ASSIGNED after the poll call\n+            final State stateSnapshot = state;\n+            if (stateSnapshot == State.PARTITIONS_ASSIGNED\n+                || stateSnapshot == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n+\n+                log.debug(\"State is {}; initializing and restoring\", stateSnapshot);\n+\n+                // transit to restore active is idempotent so we can call it multiple times\n+                changelogReader.enforceRestoreActive();\n+\n+                if (taskManager.tryToCompleteRestoration()) {\n+                    changelogReader.transitToUpdateStandby();\n+\n+                    setState(State.RUNNING);\n+                }\n+\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"Initialization and restore call done. State is {}\", state);\n+                }\n+            }\n+        }\n+\n+        log.debug(\"Invoking ChangeLogReader#restore\");\n+        // we can always let changelog reader try restoring in order to initialize the changelogs;\n+        // if there's no active restoring or standby updating it would not try to fetch any data\n+        changelogReader.restore();\n+    }\n+\n+    private long pollPhase() {\n+        final ConsumerRecords<byte[], byte[]> records;\n+        log.debug(\"Invoking Consumer#poll\");\n+\n+        if (state == State.PARTITIONS_ASSIGNED) {\n+            // try to fetch some records with zero poll millis\n+            // to unblock the restoration as soon as possible\n+            records = pollRequests(Duration.ZERO);\n+        } else if (state == State.PARTITIONS_REVOKED) {\n+            // try to fetch som records with zero poll millis to unblock\n+            // other useful work while waiting for the join response\n+            records = pollRequests(Duration.ZERO);\n+        } else if (state == State.RUNNING || state == State.STARTING) {\n+            // try to fetch some records with normal poll time\n+            // in order to get long polling\n+            records = pollRequests(pollTime);\n+        } else if (state == State.PENDING_SHUTDOWN) {\n+            // we are only here because there's rebalance in progress,\n+            // just poll with zero to complete it\n+            records = pollRequests(Duration.ZERO);\n+        } else {\n+            // any other state should not happen\n+            log.error(\"Unexpected state {} during normal iteration\", state);\n+            throw new StreamsException(logPrefix + \"Unexpected state \" + state + \" during normal iteration\");\n+        }\n+\n+        final long pollLatency = advanceNowAndComputeLatency();\n+\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"Consumer#poll completed in {} ms and fetched {} records\", pollLatency, records.count());\n+        }", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NzA1Mg==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485067052", "bodyText": "Note, this was previously records != null && !records.isEmpty():\nhttps://github.com/apache/kafka/pull/9267/files#diff-045aeaddb4232a85a8560186b4901e69L640\nHowever, records can never be null, except if Consumer#poll returns null, which it does not. It turned out the reason for checking this condition was that there was exactly one test that relied on a nice mock returning null. I fixed the test below.\nNote, the only reason I messed with this was to simplify the debug log message on L775. Otherwise, I'd have needed to think of what to say if records were null.", "author": "vvcephei", "createdAt": "2020-09-08T16:59:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -752,6 +712,77 @@ void runOnce() {\n         commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n     }\n \n+    private void initializeAndRestorePhase() {\n+        {\n+            // only try to initialize the assigned tasks\n+            // if the state is still in PARTITION_ASSIGNED after the poll call\n+            final State stateSnapshot = state;\n+            if (stateSnapshot == State.PARTITIONS_ASSIGNED\n+                || stateSnapshot == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n+\n+                log.debug(\"State is {}; initializing and restoring\", stateSnapshot);\n+\n+                // transit to restore active is idempotent so we can call it multiple times\n+                changelogReader.enforceRestoreActive();\n+\n+                if (taskManager.tryToCompleteRestoration()) {\n+                    changelogReader.transitToUpdateStandby();\n+\n+                    setState(State.RUNNING);\n+                }\n+\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"Initialization and restore call done. State is {}\", state);\n+                }\n+            }\n+        }\n+\n+        log.debug(\"Invoking ChangeLogReader#restore\");\n+        // we can always let changelog reader try restoring in order to initialize the changelogs;\n+        // if there's no active restoring or standby updating it would not try to fetch any data\n+        changelogReader.restore();\n+    }\n+\n+    private long pollPhase() {\n+        final ConsumerRecords<byte[], byte[]> records;\n+        log.debug(\"Invoking Consumer#poll\");\n+\n+        if (state == State.PARTITIONS_ASSIGNED) {\n+            // try to fetch some records with zero poll millis\n+            // to unblock the restoration as soon as possible\n+            records = pollRequests(Duration.ZERO);\n+        } else if (state == State.PARTITIONS_REVOKED) {\n+            // try to fetch som records with zero poll millis to unblock\n+            // other useful work while waiting for the join response\n+            records = pollRequests(Duration.ZERO);\n+        } else if (state == State.RUNNING || state == State.STARTING) {\n+            // try to fetch some records with normal poll time\n+            // in order to get long polling\n+            records = pollRequests(pollTime);\n+        } else if (state == State.PENDING_SHUTDOWN) {\n+            // we are only here because there's rebalance in progress,\n+            // just poll with zero to complete it\n+            records = pollRequests(Duration.ZERO);\n+        } else {\n+            // any other state should not happen\n+            log.error(\"Unexpected state {} during normal iteration\", state);\n+            throw new StreamsException(logPrefix + \"Unexpected state \" + state + \" during normal iteration\");\n+        }\n+\n+        final long pollLatency = advanceNowAndComputeLatency();\n+\n+        if (log.isDebugEnabled()) {\n+            log.debug(\"Consumer#poll completed in {} ms and fetched {} records\", pollLatency, records.count());\n+        }\n+        pollSensor.record(pollLatency, now);\n+\n+        if (!records.isEmpty()) {", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE0MjAxNw==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485142017", "bodyText": "SG.", "author": "guozhangwang", "createdAt": "2020-09-08T19:18:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NzA1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2NzQyOA==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485067428", "bodyText": "Not necessary, but also not harmful, since it's a static final instance anyway. I thought it was nicer for self-documentation this way.", "author": "vvcephei", "createdAt": "2020-09-08T16:59:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -760,7 +791,7 @@ void runOnce() {\n      * @throws TaskMigratedException if the task producer got fenced (EOS only)\n      */\n     private ConsumerRecords<byte[], byte[]> pollRequests(final Duration pollTime) {\n-        ConsumerRecords<byte[], byte[]> records = null;\n+        ConsumerRecords<byte[], byte[]> records = ConsumerRecords.empty();", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA2OTc5OQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485069799", "bodyText": "Switched these to debug now, since they seem to fit with the newly added logs.", "author": "vvcephei", "createdAt": "2020-09-08T17:03:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -845,8 +876,8 @@ private void addToResetList(final TopicPartition partition, final Set<TopicParti\n     int maybeCommit() {\n         final int committed;\n         if (now - lastCommitMs > commitTimeMs) {\n-            if (log.isTraceEnabled()) {\n-                log.trace(\"Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)\",\n+            if (log.isDebugEnabled()) {\n+                log.debug(\"Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)\",", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3MTMzNg==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485071336", "bodyText": "This was a bad input for the test, since poll can never actually return null.", "author": "vvcephei", "createdAt": "2020-09-08T17:06:28Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -496,6 +498,7 @@ public void shouldEnforceRebalanceAfterNextScheduledProbingRebalanceTime() throw\n         );\n         \n         final Consumer<byte[], byte[]> mockConsumer = EasyMock.createNiceMock(Consumer.class);\n+        expect(mockConsumer.poll(anyObject())).andStubReturn(ConsumerRecords.empty());", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQwMw==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485098403", "bodyText": "Is this necessary with the logs inside restore()?\nmaybe can include snapshotState so we can see if it's STARTING or RUNNING? because we don't see the state unless it enters the initialization. Not sure if this would be useful", "author": "wcarlson5", "createdAt": "2020-09-08T17:55:49Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -752,6 +712,77 @@ void runOnce() {\n         commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n     }\n \n+    private void initializeAndRestorePhase() {\n+        {\n+            // only try to initialize the assigned tasks\n+            // if the state is still in PARTITION_ASSIGNED after the poll call\n+            final State stateSnapshot = state;\n+            if (stateSnapshot == State.PARTITIONS_ASSIGNED\n+                || stateSnapshot == State.RUNNING && taskManager.needsInitializationOrRestoration()) {\n+\n+                log.debug(\"State is {}; initializing and restoring\", stateSnapshot);\n+\n+                // transit to restore active is idempotent so we can call it multiple times\n+                changelogReader.enforceRestoreActive();\n+\n+                if (taskManager.tryToCompleteRestoration()) {\n+                    changelogReader.transitToUpdateStandby();\n+\n+                    setState(State.RUNNING);\n+                }\n+\n+                if (log.isDebugEnabled()) {\n+                    log.debug(\"Initialization and restore call done. State is {}\", state);\n+                }\n+            }\n+        }\n+\n+        log.debug(\"Invoking ChangeLogReader#restore\");", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE0MjE3Mw==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485142173", "bodyText": "Not sure what's the purpose of this log entry?", "author": "guozhangwang", "createdAt": "2020-09-08T19:18:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc2NzU5Mg==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485767592", "bodyText": "Thanks, all. The purpose is simply to make the narrative of StreamThread's debug logs unambiguous and complete. The purpose of logging it here instead of relying only on ChangeLogReader's logs is that you can enable just StreamThread's debug logger and get a complete high-level view of what's happening. If you want to then drill down into the restore call itself, you could enable ChangeLogReader's debug log.\nGood point, @wcarlson5 , about logging the state. I'll add it.", "author": "vvcephei", "createdAt": "2020-09-09T16:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQ2NQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485098465", "bodyText": "trace?", "author": "wcarlson5", "createdAt": "2020-09-08T17:55:57Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -706,13 +662,17 @@ void runOnce() {\n                     totalProcessed += processed;\n                 }\n \n+                log.debug(\"TaskManager#process handled {} records; invoking TaskManager#punctuate\", processed);\n+\n                 final int punctuated = taskManager.punctuate();\n                 final long punctuateLatency = advanceNowAndComputeLatency();\n                 totalPunctuateLatency += punctuateLatency;\n                 if (punctuated > 0) {\n                     punctuateSensor.record(punctuateLatency / (double) punctuated, now);\n                 }\n \n+                log.debug(\"TaskManager#punctuate executed: {}\", punctuated);", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc3MTQzNA==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485771434", "bodyText": "Note, this isn't saying that we invoked a single punctuator, but that we invoked all the punctuators that are runnable right now. It's also a top-level phase of executing StreamThread, so I don't think we can leave it out of the debug logs without telling an incomplete story of what's happening. If we log this (or any of the proposed logs) at trace level, the only consequence is that users who want to debug StreamThread would have to use \"trace\" level instead of \"debug\" level. This seems to add unnecessary complexity to the logging.\nIMO, it's better to reserve \"trace\" level for very low-level logs, such as logging the progress of individual documents through the processors, and use \"debug\" level for higher-level summary logs like the ones in this PR.", "author": "vvcephei", "createdAt": "2020-09-09T16:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQ2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEzMjM0OA==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485132348", "bodyText": "Nit: I'd suggest we do not expose internal class names in log entries, e.g. here we can say \"Processed {} records with {} iterations, invoking punctuation now\", ditto below.", "author": "guozhangwang", "createdAt": "2020-09-08T18:59:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -706,13 +662,17 @@ void runOnce() {\n                     totalProcessed += processed;\n                 }\n \n+                log.debug(\"TaskManager#process handled {} records; invoking TaskManager#punctuate\", processed);", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEzMjgxMQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485132811", "bodyText": "What's the rationale of recording both the starting and the ending of a procedure? If it is for trouble shooting purposes only maybe the starting log entry can be trace while ending entry is debug?", "author": "guozhangwang", "createdAt": "2020-09-08T19:00:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -689,6 +644,7 @@ void runOnce() {\n              *  6. Otherwise, increment N.\n              */\n             do {\n+                log.debug(\"Invoking TaskManager#process with {} iterations.\", numIterations);", "originalCommit": "2b9f6122a2b1d3a503f3a8a6104befa15de6efbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc1OTU2NQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485759565", "bodyText": "Yes, it's for debugging purposes, so I'd like to keep them both at debug level. When I was handling the incident that inspired this PR, what I really wanted to see in the logs is both how often we called poll and which operation in the loop was blocking. In theory, I'd only really need the \"before\" or the \"after\" logs for this, but only if I also have the source code pulled up to compare with the log messages. I'm proposing to (redundantly) log both \"before\" and \"after\" messages so that the logs will be context-free and people in the future would be able to tell what is happening just from the narrative of the logs themselves.", "author": "vvcephei", "createdAt": "2020-09-09T16:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEzMjgxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc2Mzg5OQ==", "url": "https://github.com/apache/kafka/pull/9267#discussion_r485763899", "bodyText": "SG", "author": "guozhangwang", "createdAt": "2020-09-09T16:43:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEzMjgxMQ=="}], "type": "inlineReview"}, {"oid": "beb93768cb761367344fb31e40945bdebbba7cb5", "url": "https://github.com/apache/kafka/commit/beb93768cb761367344fb31e40945bdebbba7cb5", "message": "CR feedback", "committedDate": "2020-09-09T17:15:43Z", "type": "commit"}]}