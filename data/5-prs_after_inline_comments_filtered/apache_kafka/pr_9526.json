{"pr_number": 9526, "pr_title": "KAFKA-10525: Emit JSONs with new auto-generated schema", "pr_createdAt": "2020-10-29T03:33:59Z", "pr_url": "https://github.com/apache/kafka/pull/9526", "timeline": [{"oid": "db4cbab3af02e58acf19fe446074857e4eaf44e4", "url": "https://github.com/apache/kafka/commit/db4cbab3af02e58acf19fe446074857e4eaf44e4", "message": "integrate with rebase", "committedDate": "2020-11-20T05:45:12Z", "type": "forcePushed"}, {"oid": "d8a26b6fbaead74096fde0ea41ebe2d337c01bc7", "url": "https://github.com/apache/kafka/commit/d8a26b6fbaead74096fde0ea41ebe2d337c01bc7", "message": "KAFKA-10525: Emit JSONs with new auto-generated schema\n\nKafka\u2019s request and response traces currently output in a format that is JSON-like and are not easily parsable.\n\nThere is a new auto-generated schema for each request type that supports outputting JSON payloads for request and response payloads. These can be adapted to provide structured request tracing.", "committedDate": "2020-12-11T02:53:13Z", "type": "commit"}, {"oid": "c3e1e1f1aa7412b602917b7a8ed00dbb9f8f0cea", "url": "https://github.com/apache/kafka/commit/c3e1e1f1aa7412b602917b7a8ed00dbb9f8f0cea", "message": "add extra lines", "committedDate": "2020-12-11T02:54:08Z", "type": "commit"}, {"oid": "0c7203b6296c0c18b5127726114657c6a3d967ac", "url": "https://github.com/apache/kafka/commit/0c7203b6296c0c18b5127726114657c6a3d967ac", "message": "remove extra spaces", "committedDate": "2020-12-11T02:54:08Z", "type": "commit"}, {"oid": "38747a5782951f6740a1e1cebf007c73a6884b7d", "url": "https://github.com/apache/kafka/commit/38747a5782951f6740a1e1cebf007c73a6884b7d", "message": "add data accessor and creat tests for manually created data", "committedDate": "2020-12-11T02:59:26Z", "type": "commit"}, {"oid": "29392c482c0c0b26b96fa023fec0cd507dcc0bb5", "url": "https://github.com/apache/kafka/commit/29392c482c0c0b26b96fa023fec0cd507dcc0bb5", "message": "access data from accessor", "committedDate": "2020-12-11T02:59:30Z", "type": "commit"}, {"oid": "fb0633cabbd0737ef685726560f05cb7a8711ef7", "url": "https://github.com/apache/kafka/commit/fb0633cabbd0737ef685726560f05cb7a8711ef7", "message": "remove DESCRIBE_QUORUM case and add better error msg", "committedDate": "2020-12-11T02:59:31Z", "type": "commit"}, {"oid": "32f1e9db525d50728f3e36d8c59aaec7d718f90c", "url": "https://github.com/apache/kafka/commit/32f1e9db525d50728f3e36d8c59aaec7d718f90c", "message": "change error messages and asserts", "committedDate": "2020-12-11T02:59:31Z", "type": "commit"}, {"oid": "ab50c8fe258959cd8366ca6dbf56994046ab6f76", "url": "https://github.com/apache/kafka/commit/ab50c8fe258959cd8366ca6dbf56994046ab6f76", "message": "swap expected and actual, change error msg, add accessor to private data field", "committedDate": "2020-12-11T02:59:54Z", "type": "commit"}, {"oid": "97237afbd72335b7617a500afebe5b894aa5bdbc", "url": "https://github.com/apache/kafka/commit/97237afbd72335b7617a500afebe5b894aa5bdbc", "message": "change to data accessor method", "committedDate": "2020-12-11T02:59:57Z", "type": "commit"}, {"oid": "32578e449bb3808f9d19ac8dd7a38e1d91e2fdba", "url": "https://github.com/apache/kafka/commit/32578e449bb3808f9d19ac8dd7a38e1d91e2fdba", "message": "change recordSet field to print sizeInBytes", "committedDate": "2020-12-11T02:59:57Z", "type": "commit"}, {"oid": "ab73c10d4246341a67af90f7bcdd6ab5500da5d5", "url": "https://github.com/apache/kafka/commit/ab73c10d4246341a67af90f7bcdd6ab5500da5d5", "message": "trigger build", "committedDate": "2020-12-11T02:59:57Z", "type": "commit"}, {"oid": "d3b548799abe15655ee1fdafdab5712bc1ea6444", "url": "https://github.com/apache/kafka/commit/d3b548799abe15655ee1fdafdab5712bc1ea6444", "message": "add verbose flag to records in JsonConverter", "committedDate": "2020-12-11T03:01:50Z", "type": "commit"}, {"oid": "bd9a82bd642090a7efbf64ac429a43fa9a040264", "url": "https://github.com/apache/kafka/commit/bd9a82bd642090a7efbf64ac429a43fa9a040264", "message": "add overload method for verbose flag", "committedDate": "2020-12-11T03:03:03Z", "type": "commit"}, {"oid": "0fa879aed005435b8f56534322123f639598296a", "url": "https://github.com/apache/kafka/commit/0fa879aed005435b8f56534322123f639598296a", "message": "add parentheses", "committedDate": "2020-12-11T03:03:07Z", "type": "commit"}, {"oid": "4dd1524301a9dda7dec710d59c9eae204df36a8c", "url": "https://github.com/apache/kafka/commit/4dd1524301a9dda7dec710d59c9eae204df36a8c", "message": "remove verbose tag in unnecessary places", "committedDate": "2020-12-11T03:03:08Z", "type": "commit"}, {"oid": "b102b67fd5c44cd2b01e2e11000176d87b786d8d", "url": "https://github.com/apache/kafka/commit/b102b67fd5c44cd2b01e2e11000176d87b786d8d", "message": "integrate with rebase", "committedDate": "2020-12-11T03:03:09Z", "type": "commit"}, {"oid": "3e439d5d81c9cbede152775385c046b6208a1c04", "url": "https://github.com/apache/kafka/commit/3e439d5d81c9cbede152775385c046b6208a1c04", "message": "handle null ProduceRequest", "committedDate": "2020-12-11T03:03:10Z", "type": "commit"}, {"oid": "4bca18e9b36a8597078f45b4b8eda15e645fecfd", "url": "https://github.com/apache/kafka/commit/4bca18e9b36a8597078f45b4b8eda15e645fecfd", "message": "add specific case for ProduceRequest", "committedDate": "2020-12-11T03:03:10Z", "type": "commit"}, {"oid": "9cc67279ff1b8ea4d0fe014dbaf4787a662b5155", "url": "https://github.com/apache/kafka/commit/9cc67279ff1b8ea4d0fe014dbaf4787a662b5155", "message": "make produce request consistent", "committedDate": "2020-12-11T03:03:11Z", "type": "commit"}, {"oid": "5f91474f006841d679bbe63d64fcdf3cc93282bc", "url": "https://github.com/apache/kafka/commit/5f91474f006841d679bbe63d64fcdf3cc93282bc", "message": "remove special handling for ProduceRequest", "committedDate": "2020-12-11T03:03:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgxOTE2Mw==", "url": "https://github.com/apache/kafka/pull/9526#discussion_r540819163", "bodyText": "I wonder if we should name the field %sSizeInBytes. I just looked at the result and having \"records\":83 in the request log is not super clear to me.", "author": "dajac", "createdAt": "2020-12-11T09:45:15Z", "path": "generator/src/main/java/org/apache/kafka/message/JsonConverterGenerator.java", "diffHunk": "@@ -377,11 +387,24 @@ private void generateVariableLengthTargetToJson(Target target, Versions versions\n                 headerGenerator.addImport(MessageGenerator.ARRAYS_CLASS);\n                 buffer.printf(\"%s;%n\", target.assignmentStatement(\n                     String.format(\"new BinaryNode(Arrays.copyOf(%s, %s.length))\",\n-                        target.sourceVariable(), target.sourceVariable())));\n+                            target.sourceVariable(), target.sourceVariable())));\n             }\n         } else if (target.field().type().isRecords()) {\n             headerGenerator.addImport(MessageGenerator.BINARY_NODE_CLASS);\n+            headerGenerator.addImport(MessageGenerator.INT_NODE_CLASS);\n+            // KIP-673: When logging requests/responses, we do not serialize the record, instead we\n+            // output its sizeInBytes, because outputting the bytes is not very useful and can be\n+            // quite expensive. Otherwise, we will serialize the record.\n+            buffer.printf(\"if (_serializeRecords) {%n\");\n+            buffer.incrementIndent();\n             buffer.printf(\"%s;%n\", target.assignmentStatement(\"new BinaryNode(new byte[]{})\"));\n+            buffer.decrementIndent();\n+            buffer.printf(\"} else {%n\");\n+            buffer.incrementIndent();\n+            buffer.printf(\"%s;%n\", target.assignmentStatement(", "originalCommit": "9f176ffc29ed0da839df70c80e70a8a58cf7c5cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTI0MDU1OA==", "url": "https://github.com/apache/kafka/pull/9526#discussion_r541240558", "bodyText": "I do see the issue of it not being super clear, but I don't think we can change the field name from here. Doing %sSizeInBytes would just add the name at the end of the line which would result in a compilation error. Unless you mean to change the field name in the .json file, but it would change the name for both the serialize and non-serialize case.", "author": "anatasiavela", "createdAt": "2020-12-11T20:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgxOTE2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjMwNTI0OQ==", "url": "https://github.com/apache/kafka/pull/9526#discussion_r542305249", "bodyText": "Would something like the following work?\nbuffer.printf(\"_node.set(\\\"%sSizeInBytes\\\", new IntNode(%s.sizeInBytes()));%n\",\n  target.field().camelCaseName(),\n  target.sourceVariable());", "author": "dajac", "createdAt": "2020-12-14T11:16:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDgxOTE2Mw=="}], "type": "inlineReview"}, {"oid": "97072bbaeba0b5dde308ac5dfb414ef7c2d1ddea", "url": "https://github.com/apache/kafka/commit/97072bbaeba0b5dde308ac5dfb414ef7c2d1ddea", "message": "rebase and address comments", "committedDate": "2020-12-11T20:04:10Z", "type": "commit"}, {"oid": "97072bbaeba0b5dde308ac5dfb414ef7c2d1ddea", "url": "https://github.com/apache/kafka/commit/97072bbaeba0b5dde308ac5dfb414ef7c2d1ddea", "message": "rebase and address comments", "committedDate": "2020-12-11T20:04:10Z", "type": "forcePushed"}, {"oid": "1fc3a11ca54b9958c1ef20fbca9abb4606ecbdd0", "url": "https://github.com/apache/kafka/commit/1fc3a11ca54b9958c1ef20fbca9abb4606ecbdd0", "message": "address minor comments", "committedDate": "2020-12-14T17:59:50Z", "type": "commit"}]}