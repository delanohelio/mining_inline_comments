{"pr_number": 9406, "pr_title": "KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1", "pr_createdAt": "2020-10-09T13:42:23Z", "pr_url": "https://github.com/apache/kafka/pull/9406", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508473537", "bodyText": "Don't we loose the current nextRequestHandler when we end up in this branch?\nFor instance, if nextRequestHandler is a FindCoordinatorHandler and there a no nodes available, targetNode is null and coordinatorType is null as well so we end up here and poll. We don't do anything with nextRequestHandler and return so it is gone. I suppose that it is not an issue for FindCoordinatorHandler as a new one will be enqueued automatically when another TxnRequestHandler handler is processed and the coordinator is unknown.\nWe may want to push back nextRequestHandler to the queue with transactionManager.retry(nextRequestHandler) in oder to handle all the cases.\nI am not sure if that could really happen with any other TxnRequestHandler type though. What do you think?", "author": "dajac", "createdAt": "2020-10-20T12:51:42Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -444,10 +444,20 @@ private boolean maybeSendAndPollTransactionalRequest() {\n         AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n         Node targetNode = null;\n         try {\n-            targetNode = awaitNodeReady(nextRequestHandler.coordinatorType());\n-            if (targetNode == null) {\n+            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n+            targetNode = coordinatorType != null ?\n+                    transactionManager.coordinator(coordinatorType) :\n+                    client.leastLoadedNode(time.milliseconds());\n+            if (targetNode != null) {\n+                awaitNodeReady(targetNode, coordinatorType);\n+            } else if (coordinatorType != null) {\n+                log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n                 maybeFindCoordinatorAndRetry(nextRequestHandler);\n                 return true;\n+            } else {\n+                log.trace(\"No nodes available to send requests, polling until a node is ready.\");\n+                client.poll(retryBackoffMs, time.milliseconds());\n+                return true;", "originalCommit": "42097e99a84ecc4af8652562c521589679640415", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODU4MzUyOA==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508583528", "bodyText": "@dajac Thanks for the review. As far as I can tell, nextRequestHandler returned by transactionManager.nextRequest would have retained the request in this case since it does a peek and removes the element only under certain conditions. I was trying to limit the amount of change to the minimal necessary to handle max.in.flight=1, do you think we should do more to look into the other cases?", "author": "rajinisivaram", "createdAt": "2020-10-20T14:58:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODYyNjk3NQ==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r508626975", "bodyText": "@rajinisivaram It seems that a non-null nextRequestHandler would have been removed from the queue: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L872.\nI've got the impression that InitProducerIdHandler may hit that code path as well as it could have a null coordinatorType when the transaction id is not set (idempotent producer). I think that we could unit test this actually by reusing your testInitProducerIdWithMaxInFlightOne but without setting the transactional id. Should we add this test to be on the safe side?", "author": "dajac", "createdAt": "2020-10-20T15:42:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTA3OTkwNg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509079906", "bodyText": "@dajac Sorry, that was my mistake. Updated code and added test.", "author": "rajinisivaram", "createdAt": "2020-10-21T08:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTIwNzY5Mg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509207692", "bodyText": "Thanks. I will make another pass now.", "author": "dajac", "createdAt": "2020-10-21T11:41:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ3MzUzNw=="}], "type": "inlineReview"}, {"oid": "f68ac1adf1d5bc4b41e7c8fca41a700db9b1acc2", "url": "https://github.com/apache/kafka/commit/f68ac1adf1d5bc4b41e7c8fca41a700db9b1acc2", "message": "KAFKA-10520; Ensure transactional producers poll if leastLoadedNode not available with max.in.flight=1", "committedDate": "2020-10-21T11:07:31Z", "type": "commit"}, {"oid": "e8b3446d1edb2eb4069a1dcf4142168d61b241b6", "url": "https://github.com/apache/kafka/commit/e8b3446d1edb2eb4069a1dcf4142168d61b241b6", "message": "Address review comment", "committedDate": "2020-10-21T11:07:31Z", "type": "commit"}, {"oid": "3e36ffe76440f978f99c2a44dd975f90546879f8", "url": "https://github.com/apache/kafka/commit/3e36ffe76440f978f99c2a44dd975f90546879f8", "message": "Address review comments", "committedDate": "2020-10-21T11:07:32Z", "type": "commit"}, {"oid": "3e36ffe76440f978f99c2a44dd975f90546879f8", "url": "https://github.com/apache/kafka/commit/3e36ffe76440f978f99c2a44dd975f90546879f8", "message": "Address review comments", "committedDate": "2020-10-21T11:07:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509257293", "bodyText": "Looking at this branch again, sorry :). I was comparing it with the previous behavior and I have noticed that we would request a refresh of the metadata when the same conditions were met. That happened here:\n    private void maybeFindCoordinatorAndRetry(TransactionManager.TxnRequestHandler nextRequestHandler) {\n        if (nextRequestHandler.needsCoordinator()) {\n            transactionManager.lookupCoordinator(nextRequestHandler);\n        } else {\n            // For non-coordinator requests, sleep here to prevent a tight loop when no node is available\n            time.sleep(retryBackoffMs);\n            metadata.requestUpdate();\n        }\n\n        transactionManager.retry(nextRequestHandler);\n    }\n\nWhen no node is available and coordinatorType != null, we ended up in the else branch here. I wonder if not doing metadata.requestUpdate() in our new implementation could be problematic and I also wonder if we could just swap that time.sleep(retryBackoffMs) by client.poll(retryBackoffMs, time.milliseconds()) to achieve the same goal. The difference is that another metadata request would be sent in our particular case.\nHave you noticed this small difference?", "author": "dajac", "createdAt": "2020-10-21T13:01:08Z", "path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java", "diffHunk": "@@ -444,10 +444,25 @@ private boolean maybeSendAndPollTransactionalRequest() {\n         AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n         Node targetNode = null;\n         try {\n-            targetNode = awaitNodeReady(nextRequestHandler.coordinatorType());\n-            if (targetNode == null) {\n+            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n+            targetNode = coordinatorType != null ?\n+                    transactionManager.coordinator(coordinatorType) :\n+                    client.leastLoadedNode(time.milliseconds());\n+            if (targetNode != null) {\n+                if (!awaitNodeReady(targetNode, coordinatorType)) {\n+                    log.trace(\"Target node {} not ready within request timeout, will retry when node is ready.\", targetNode);\n+                    maybeFindCoordinatorAndRetry(nextRequestHandler);\n+                    return true;\n+                }\n+            } else if (coordinatorType != null) {\n+                log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n                 maybeFindCoordinatorAndRetry(nextRequestHandler);\n                 return true;\n+            } else {\n+                log.trace(\"No nodes available to send requests, will poll and retry when until a node is ready.\");\n+                transactionManager.retry(nextRequestHandler);\n+                client.poll(retryBackoffMs, time.milliseconds());\n+                return true;", "originalCommit": "3e36ffe76440f978f99c2a44dd975f90546879f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI5MzQ0Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509293443", "bodyText": "@dajac Yes, I was thinking about this earlier when adding the retry. We get to this else path when leastLoadedNode is null. For the other cases, we would have taken one of the other paths, which retain existing behaviour (unless I missed something, again!) When least loaded node is null, the old behaviour didn't quite work because you have to poll to change that state. And you don't have anywhere to send metadata requests to. So just polling seemed to be sufficient for this case. What do you think?", "author": "rajinisivaram", "createdAt": "2020-10-21T13:42:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzcxMg==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509453712", "bodyText": "I agree polling seems sufficient. We will still have an opportunity to refresh metadata if the current connection fails for some reason.", "author": "hachikuji", "createdAt": "2020-10-21T17:03:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ5MjQ5Mw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509492493", "bodyText": "@rajinisivaram Yeah, I do agree. Polling seems sufficient in this case. Thanks for the clarification.", "author": "dajac", "createdAt": "2020-10-21T17:43:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTI1NzI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1NjUxNA==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r509456514", "bodyText": "Wonder if we should consider adding max inflight behavior directly to MockClient. Seems like a notable difference from NetworkClient.", "author": "hachikuji", "createdAt": "2020-10-21T17:08:13Z", "path": "clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java", "diffHunk": "@@ -2667,4 +2760,43 @@ private void assertFutureFailure(Future<?> future, Class<? extends Exception> ex\n         }\n     }\n \n+    private void createMockClientWithMaxFlightOneMetadataPending() {\n+        client = new MockClient(time, metadata) {", "originalCommit": "3e36ffe76440f978f99c2a44dd975f90546879f8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAwOTMzMw==", "url": "https://github.com/apache/kafka/pull/9406#discussion_r510009333", "bodyText": "@hachikuji Thanks for reviewing and merging! I have opened https://issues.apache.org/jira/browse/KAFKA-10626 to add max.in.flight to MockClient.", "author": "rajinisivaram", "createdAt": "2020-10-22T09:19:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1NjUxNA=="}], "type": "inlineReview"}]}