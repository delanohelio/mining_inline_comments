{"pr_number": 7961, "pr_title": "KAFKA-9431: Expose API in KafkaStreams to fetch all local offset lags", "pr_createdAt": "2020-01-14T23:11:26Z", "pr_url": "https://github.com/apache/kafka/pull/7961", "timeline": [{"oid": "e599b4cea1044b90938eb7eec31cad4d230bb7e4", "url": "https://github.com/apache/kafka/commit/e599b4cea1044b90938eb7eec31cad4d230bb7e4", "message": "[KAFKA-9431] Expose API in KafkaStreams to fetch all local offset lags\n\n - Adds KafkaStreams#allLocalOffsetLags(), which returns lag information of all active/standby tasks local to a streams instance\n - LagInfo class encapsulates the current position in the changelog, endoffset in the changelog and their difference as lag\n - Lag information is a mere estimate; it can over-estimate (source topic optimization), or under-estimate.\n - Each call to allLocalOffsetLags() generates a metadata call to Kafka brokers, so caution advised\n - Unit and Integration tests added.", "committedDate": "2020-01-15T21:16:13Z", "type": "commit"}, {"oid": "b30f7b558c3f5e32b4e3941770aae00fe6294f9d", "url": "https://github.com/apache/kafka/commit/b30f7b558c3f5e32b4e3941770aae00fe6294f9d", "message": "Moving the standby checkpoint position fetch to ProcessorStateManager#standbyRestoredOffsets\n\n - This map already contains the source topic optimization fenced last offset seen by an standby task\n - This is updated much more real-time without waiting for checkpointing", "committedDate": "2020-01-15T21:16:13Z", "type": "commit"}, {"oid": "bfc1b36d894b3d87ea1510d712d542c0fe1a9347", "url": "https://github.com/apache/kafka/commit/bfc1b36d894b3d87ea1510d712d542c0fe1a9347", "message": "Enabling topology optimization into lag fetch integration test", "committedDate": "2020-01-15T21:16:13Z", "type": "commit"}, {"oid": "eb33dba59f443d56b860fc3b80dcbafc00c597af", "url": "https://github.com/apache/kafka/commit/eb33dba59f443d56b860fc3b80dcbafc00c597af", "message": "Cleanups after rebasing", "committedDate": "2020-01-15T21:16:14Z", "type": "commit"}, {"oid": "eb33dba59f443d56b860fc3b80dcbafc00c597af", "url": "https://github.com/apache/kafka/commit/eb33dba59f443d56b860fc3b80dcbafc00c597af", "message": "Cleanups after rebasing", "committedDate": "2020-01-15T21:16:14Z", "type": "forcePushed"}, {"oid": "cf7522ecf1a7d5506c771279de064855319f4cde", "url": "https://github.com/apache/kafka/commit/cf7522ecf1a7d5506c771279de064855319f4cde", "message": "Minor cleanups", "committedDate": "2020-01-15T23:15:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxNDE4OQ==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367214189", "bodyText": "What is the purpose of this change? It looks unrelated, but I'm guessing it's related somehow to your tests?", "author": "vvcephei", "createdAt": "2020-01-16T03:22:10Z", "path": "clients/src/test/java/org/apache/kafka/clients/admin/MockAdminClient.java", "diffHunk": "@@ -450,12 +450,17 @@ public ListPartitionReassignmentsResult listPartitionReassignments(Optional<Set<\n \n     @Override\n     public AlterConsumerGroupOffsetsResult alterConsumerGroupOffsets(String groupId, Map<TopicPartition, OffsetAndMetadata> offsets, AlterConsumerGroupOffsetsOptions options) {\n-        throw new UnsupportedOperationException(\"Not implement yet\");\n+        throw new UnsupportedOperationException(\"Not implemented yet\");\n     }\n \n     @Override\n     public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartitionOffsets, ListOffsetsOptions options) {\n-        throw new UnsupportedOperationException(\"Not implement yet\");\n+        throw new UnsupportedOperationException(\"Not implemented yet\");\n+    }\n+\n+    @Override\n+    public ListOffsetsResult listOffsets(Map<TopicPartition, OffsetSpec> topicPartitionOffsets) {\n+        throw new UnsupportedOperationException(\"Not implemented yet\");", "originalCommit": "eb33dba59f443d56b860fc3b80dcbafc00c597af", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ4MTM3NQ==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367481375", "bodyText": "Thats the variant I am using in allLocalOffsetLags.. I swear, at some point I needed it for the KafkaStreamsTest to pass .. I took another look though and test currently with a partial mock on MockAdminClient seems to pass without this change.. So will back this out. Thanks for the call out", "author": "vinothchandar", "createdAt": "2020-01-16T15:26:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxNDE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ5Mzg5Ng==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367493896", "bodyText": "Thanks!", "author": "vvcephei", "createdAt": "2020-01-16T15:47:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIxNDE4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIyMDQ1MQ==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367220451", "bodyText": "This is neat, but we shouldn't use it. There's an IntegrationTestUtil for getting a temporary folder, which is hooked in to support for different testing environments to set their desired temporary file location.", "author": "vvcephei", "createdAt": "2020-01-16T03:56:47Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/LagFetchIntegrationTest.java", "diffHunk": "@@ -0,0 +1,315 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.integration;\n+\n+import static org.apache.kafka.common.utils.Utils.mkSet;\n+import static org.apache.kafka.streams.integration.utils.IntegrationTestUtils.startApplicationAndWaitUntilRunning;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.core.IsEqual.equalTo;\n+import static org.junit.Assert.assertTrue;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.TimeUnit;\n+import kafka.utils.MockTime;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.serialization.LongDeserializer;\n+import org.apache.kafka.common.serialization.LongSerializer;\n+import org.apache.kafka.common.serialization.Serdes;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.KafkaStreamsWrapper;\n+import org.apache.kafka.streams.KeyValue;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.StreamsBuilder;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster;\n+import org.apache.kafka.streams.integration.utils.IntegrationTestUtils;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.processor.StateRestoreListener;\n+import org.apache.kafka.streams.processor.internals.StreamThread;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.apache.kafka.test.TestUtils;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.TestName;\n+\n+@Category({IntegrationTest.class})\n+public class LagFetchIntegrationTest {\n+\n+    @ClassRule\n+    public static final EmbeddedKafkaCluster CLUSTER = new EmbeddedKafkaCluster(1);\n+\n+    private static final long CONSUMER_TIMEOUT_MS = 60000;\n+\n+    @Rule\n+    public TemporaryFolder folder = new TemporaryFolder();", "originalCommit": "cf7522ecf1a7d5506c771279de064855319f4cde", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ4NDAzNA==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367484034", "bodyText": "I see a TestUtils#temporaryFolder which basically uses java Files.createTempDirectory/deleteOnExit route.. This is what you switched to in the QueryableStateIntegrationTest as I see ..\nI ll play by house rules.. but I don't see a IntegrationTestUtil or a related method in IntegrationTestUtils .. I see one where it purges local state dir from streams config.. Is that what you are referring to..\nOnce you respond, I will clean up both tests", "author": "vinothchandar", "createdAt": "2020-01-16T15:30:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIyMDQ1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQ5ODM5Ng==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367498396", "bodyText": "Ah, yes, it's org.apache.kafka.test.TestUtils#tempDirectory(). My mistake. The protocol is for all temporary state in Kafka tests to use that method.\nThe change I made in QueryableStateIntegrationTest is basically what we should do here as well.", "author": "vvcephei", "createdAt": "2020-01-16T15:54:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIyMDQ1MQ=="}], "type": "inlineReview"}, {"oid": "026b9dd5f36a78839a5e628cd51d2e98f91313e9", "url": "https://github.com/apache/kafka/commit/026b9dd5f36a78839a5e628cd51d2e98f91313e9", "message": "Remove changes to MockAdminClient, Clean up LagFetchIntegrationTest", "committedDate": "2020-01-16T18:50:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcwNTY1OA==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367705658", "bodyText": "Since offsetLag is computed from the other two fields, this comparison is not necessary.", "author": "tedyu", "createdAt": "2020-01-16T23:41:25Z", "path": "streams/src/main/java/org/apache/kafka/streams/LagInfo.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams;\n+\n+import java.util.Objects;\n+\n+/**\n+ * Encapsulates information about lag, at a store partition replica (active or standby). This information is constantly changing as the\n+ * tasks process records and thus, they should be treated as simply instantaenous measure of lag.\n+ */\n+public class LagInfo {\n+\n+    private final long currentOffsetPosition;\n+\n+    private final long endOffsetPosition;\n+\n+    private final long offsetLag;\n+\n+    LagInfo(final long currentOffsetPosition, final long endOffsetPosition) {\n+        this.currentOffsetPosition = currentOffsetPosition;\n+        this.endOffsetPosition = endOffsetPosition;\n+        this.offsetLag = Math.max(0, endOffsetPosition - currentOffsetPosition);\n+    }\n+\n+    /**\n+     * Get the current maximum offset on the store partition's changelog topic, that has been successfully written into\n+     * the store partition's state store.\n+     *\n+     * @return current consume offset for standby/restoring store partitions & simply endoffset for active store partition replicas\n+     */\n+    public long currentOffsetPosition() {\n+        return this.currentOffsetPosition;\n+    }\n+\n+    /**\n+     * Get the end offset position for this store partition's changelog topic on the Kafka brokers.\n+     *\n+     * @return last offset written to the changelog topic partition\n+     */\n+    public long endOffsetPosition() {\n+        return this.endOffsetPosition;\n+    }\n+\n+    /**\n+     * Get the measured lag between current and end offset positions, for this store partition replica\n+     *\n+     * @return lag as measured by message offsets\n+     */\n+    public long offsetLag() {\n+        return this.offsetLag;\n+    }\n+\n+    @Override\n+    public boolean equals(final Object obj) {\n+        if (!(obj instanceof LagInfo)) {\n+            return false;\n+        }\n+        final LagInfo other = (LagInfo) obj;\n+        return currentOffsetPosition == other.currentOffsetPosition\n+            && endOffsetPosition == other.endOffsetPosition\n+            && this.offsetLag == other.offsetLag;", "originalCommit": "026b9dd5f36a78839a5e628cd51d2e98f91313e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcwOTUxNg==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r367709516", "bodyText": "I noticed some maps are changed to ConcurrentHashMap.\nMay I ask what was the selection criterion for the change ?\nthanks", "author": "tedyu", "createdAt": "2020-01-16T23:56:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreChangelogReader.java", "diffHunk": "@@ -46,7 +47,7 @@\n     private final StateRestoreListener userStateRestoreListener;\n     private final Map<TopicPartition, Long> restoreToOffsets = new HashMap<>();\n     private final Map<String, List<PartitionInfo>> partitionInfo = new HashMap<>();\n-    private final Map<TopicPartition, StateRestorer> stateRestorers = new HashMap<>();\n+    private final Map<TopicPartition, StateRestorer> stateRestorers = new ConcurrentHashMap<>();", "originalCommit": "026b9dd5f36a78839a5e628cd51d2e98f91313e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE1NzM4OA==", "url": "https://github.com/apache/kafka/pull/7961#discussion_r368157388", "bodyText": "This is for safe iteration from the thread calling the lag fetch API", "author": "vinothchandar", "createdAt": "2020-01-17T22:11:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcwOTUxNg=="}], "type": "inlineReview"}]}