{"pr_number": 8900, "pr_title": "KAFKA-10169: swallow non-fatal KafkaException and don't abort transaction during clean close", "pr_createdAt": "2020-06-18T23:41:12Z", "pr_url": "https://github.com/apache/kafka/pull/8900", "timeline": [{"oid": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "url": "https://github.com/apache/kafka/commit/4185c54b001ac381a8737683e8ae1a4aceb4a875", "message": "swallow this exception, dont abort during a clean close, and tests", "committedDate": "2020-06-23T17:08:01Z", "type": "commit"}, {"oid": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "url": "https://github.com/apache/kafka/commit/4185c54b001ac381a8737683e8ae1a4aceb4a875", "message": "swallow this exception, dont abort during a clean close, and tests", "committedDate": "2020-06-23T17:08:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNjg1OA==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444516858", "bodyText": "Should we fix this in older branches (2.5/2.4), too? (ie follow up PR)", "author": "mjsax", "createdAt": "2020-06-23T21:23:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsMetadataState.java", "diffHunk": "@@ -152,9 +152,9 @@ public StreamsMetadata getLocalMetadata() {\n         }\n \n         if (globalStores.contains(storeName)) {\n-            // global stores are on every node. if we dont' have the host info\n+            // global stores are on every node. if we don't have the host info\n             // for this host then just pick the first metadata\n-            if (thisHost == UNKNOWN_HOST) {\n+            if (thisHost.equals(UNKNOWN_HOST)) {", "originalCommit": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUyMjU0Mw==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444522543", "bodyText": "Will do", "author": "ableegoldman", "createdAt": "2020-06-23T21:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNjg1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUzNzI5Nw==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444537297", "bodyText": "#8919", "author": "ableegoldman", "createdAt": "2020-06-23T22:11:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNjg1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNzc0Ng==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444517746", "bodyText": "If tasksToCloseDirty is not empty, should we close dirty, too, ie pass in clean && tasksToCloseDirty.isEmpty() ?", "author": "mjsax", "createdAt": "2020-06-23T21:25:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -679,92 +675,166 @@ private void cleanupTask(final Task task) {\n     void shutdown(final boolean clean) {\n         final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n \n-        final Set<Task> tasksToClose = new HashSet<>();\n+        final Set<Task> tasksToCloseDirty = new HashSet<>();\n+        tasksToCloseDirty.addAll(tryCloseCleanAllActiveTasks(clean, firstException));\n+        tasksToCloseDirty.addAll(tryCloseCleanAllStandbyTasks(clean, firstException));\n+\n+        for (final Task task : tasksToCloseDirty) {\n+            closeTaskDirty(task);\n+        }\n+\n+        for (final Task task : activeTaskIterable()) {\n+            executeAndMaybeSwallow(\n+                clean,", "originalCommit": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUyNTk5Nw==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444525997", "bodyText": "I think this is more in line with the general code flow elsewhere. Note that if we started out clean but became dirty and had to close some tasks as such, we would have already caught an exception somewhere. So AtomicReference#compareAndSet would be a no-op, and it actually doesn't matter what we pass in here", "author": "ableegoldman", "createdAt": "2020-06-23T21:44:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNzc0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxNzkwNw==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444517907", "bodyText": "As above?", "author": "mjsax", "createdAt": "2020-06-23T21:26:04Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -679,92 +675,166 @@ private void cleanupTask(final Task task) {\n     void shutdown(final boolean clean) {\n         final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n \n-        final Set<Task> tasksToClose = new HashSet<>();\n+        final Set<Task> tasksToCloseDirty = new HashSet<>();\n+        tasksToCloseDirty.addAll(tryCloseCleanAllActiveTasks(clean, firstException));\n+        tasksToCloseDirty.addAll(tryCloseCleanAllStandbyTasks(clean, firstException));\n+\n+        for (final Task task : tasksToCloseDirty) {\n+            closeTaskDirty(task);\n+        }\n+\n+        for (final Task task : activeTaskIterable()) {\n+            executeAndMaybeSwallow(\n+                clean,\n+                () -> activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(task.id()),\n+                e -> firstException.compareAndSet(null, e),\n+                e -> log.warn(\"Ignoring an exception while closing task \" + task.id() + \" producer.\", e)\n+            );\n+        }\n+\n+        executeAndMaybeSwallow(\n+            clean,", "originalCommit": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDUxODMyOQ==", "url": "https://github.com/apache/kafka/pull/8900#discussion_r444518329", "bodyText": "As above.", "author": "mjsax", "createdAt": "2020-06-23T21:26:57Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/TaskManager.java", "diffHunk": "@@ -679,92 +675,166 @@ private void cleanupTask(final Task task) {\n     void shutdown(final boolean clean) {\n         final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n \n-        final Set<Task> tasksToClose = new HashSet<>();\n+        final Set<Task> tasksToCloseDirty = new HashSet<>();\n+        tasksToCloseDirty.addAll(tryCloseCleanAllActiveTasks(clean, firstException));\n+        tasksToCloseDirty.addAll(tryCloseCleanAllStandbyTasks(clean, firstException));\n+\n+        for (final Task task : tasksToCloseDirty) {\n+            closeTaskDirty(task);\n+        }\n+\n+        for (final Task task : activeTaskIterable()) {\n+            executeAndMaybeSwallow(\n+                clean,\n+                () -> activeTaskCreator.closeAndRemoveTaskProducerIfNeeded(task.id()),\n+                e -> firstException.compareAndSet(null, e),\n+                e -> log.warn(\"Ignoring an exception while closing task \" + task.id() + \" producer.\", e)\n+            );\n+        }\n+\n+        executeAndMaybeSwallow(\n+            clean,\n+            activeTaskCreator::closeThreadProducerIfNeeded,\n+            e -> firstException.compareAndSet(null, e),\n+            e -> log.warn(\"Ignoring an exception while closing thread producer.\", e)\n+        );\n+\n+        tasks.clear();\n+\n+\n+        // this should be called after closing all tasks, to make sure we unlock the task dir for tasks that may\n+        // have still been in CREATED at the time of shutdown, since Task#close will not do so\n+        executeAndMaybeSwallow(\n+            clean,", "originalCommit": "4185c54b001ac381a8737683e8ae1a4aceb4a875", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "20321fd1325d402405a4b5899c22c83a51732b1c", "url": "https://github.com/apache/kafka/commit/20321fd1325d402405a4b5899c22c83a51732b1c", "message": "split tests up", "committedDate": "2020-06-23T22:08:59Z", "type": "commit"}]}