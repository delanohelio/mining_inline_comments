{"pr_number": 8699, "pr_title": "KAFKA-9673: Filter and Conditional SMTs", "pr_createdAt": "2020-05-20T18:33:59Z", "pr_url": "https://github.com/apache/kafka/pull/8699", "timeline": [{"oid": "643e74e730ab86f724ac1bead403c22d6fc478a2", "url": "https://github.com/apache/kafka/commit/643e74e730ab86f724ac1bead403c22d6fc478a2", "message": "KIP-585/KAFKA-9673: Filter and Conditional SMTs\n\n* Add Predicate interface\n* Add Filter SMT\n* Add the predicate implementations defined in the KIP.\n* Create abstraction in ConnectorConfig for configuring Transformations and Connectors with the \"alias prefix\" mechanism\n* Add tests and fix existing tests.", "committedDate": "2020-05-27T10:47:01Z", "type": "commit"}, {"oid": "2cfe4e1d3a92afc4c5188b8b5f8ac3732c24b527", "url": "https://github.com/apache/kafka/commit/2cfe4e1d3a92afc4c5188b8b5f8ac3732c24b527", "message": "Use Predicates config group", "committedDate": "2020-05-27T10:48:19Z", "type": "commit"}, {"oid": "0f0e1383f29d293441b70e69a28e077f0c343ce6", "url": "https://github.com/apache/kafka/commit/0f0e1383f29d293441b70e69a28e077f0c343ce6", "message": "Some review comments", "committedDate": "2020-05-27T10:48:20Z", "type": "commit"}, {"oid": "6477fe9cd5b537f515695a0099cd1df49bf711b1", "url": "https://github.com/apache/kafka/commit/6477fe9cd5b537f515695a0099cd1df49bf711b1", "message": "fixup", "committedDate": "2020-05-27T10:48:20Z", "type": "commit"}, {"oid": "460c5f826a8272d6fba06ec1926ef3c8e5fc3e2a", "url": "https://github.com/apache/kafka/commit/460c5f826a8272d6fba06ec1926ef3c8e5fc3e2a", "message": "Comment", "committedDate": "2020-05-27T10:48:20Z", "type": "commit"}, {"oid": "fba43c8fef6a14c7a73639bf3358aa1c52673c8e", "url": "https://github.com/apache/kafka/commit/fba43c8fef6a14c7a73639bf3358aa1c52673c8e", "message": "tidy and fix a couple of tests", "committedDate": "2020-05-27T10:49:13Z", "type": "commit"}, {"oid": "f55e14616ee9698d24d0d1e6534cbe477333d7f0", "url": "https://github.com/apache/kafka/commit/f55e14616ee9698d24d0d1e6534cbe477333d7f0", "message": "Numerous fixes and an integration test.", "committedDate": "2020-05-27T10:49:13Z", "type": "commit"}, {"oid": "49b362cd4144fbe2dc10114d3c1a4095c4c30bdb", "url": "https://github.com/apache/kafka/commit/49b362cd4144fbe2dc10114d3c1a4095c4c30bdb", "message": "Review comments", "committedDate": "2020-05-27T10:49:13Z", "type": "commit"}, {"oid": "e76a0b4d4601310bd080e812668466997ac61268", "url": "https://github.com/apache/kafka/commit/e76a0b4d4601310bd080e812668466997ac61268", "message": "Review comments", "committedDate": "2020-05-27T10:49:13Z", "type": "commit"}, {"oid": "e76a0b4d4601310bd080e812668466997ac61268", "url": "https://github.com/apache/kafka/commit/e76a0b4d4601310bd080e812668466997ac61268", "message": "Review comments", "committedDate": "2020-05-27T10:49:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2MzM1Mg==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431263352", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Configuration specification for this predicate.\n          \n          \n            \n                 */\n          \n          \n            \n                /**\n          \n          \n            \n                 * Configuration specification for this predicate.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @return the configuration definition for this predicate; never null\n          \n          \n            \n                 */", "author": "rhauch", "createdAt": "2020-05-27T16:06:34Z", "path": "connect/api/src/main/java/org/apache/kafka/connect/transforms/predicates/Predicate.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import org.apache.kafka.common.Configurable;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectRecord;\n+\n+/**\n+ * <p>A predicate on records.\n+ * Predicates can be used to conditionally apply a {@link org.apache.kafka.connect.transforms.Transformation}\n+ * by configuring the transformation's {@code predicate} (and {@code negate}) configuration parameters.\n+ * In particular, the {@code Filter} transformation can be conditionally applied in order to filter\n+ * certain records from further processing.\n+ *\n+ * <p>Implementations of this interface must be public and have a public constructor with no parameters.\n+ *\n+ * @param <R> The type of record.\n+ */\n+public interface Predicate<R extends ConnectRecord<R>> extends Configurable, AutoCloseable {\n+\n+    /**\n+     * Configuration specification for this predicate.\n+     */", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI2NTUzMw==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431265533", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /**\n          \n          \n            \n                 * Returns whether the given record satisfies this predicate.\n          \n          \n            \n                 */\n          \n          \n            \n                /**\n          \n          \n            \n                 * Returns whether the given record satisfies this predicate.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param record the record to evaluate; may not be null\n          \n          \n            \n                 * @return true if the predicate matches, or false otherwise\n          \n          \n            \n                 */", "author": "rhauch", "createdAt": "2020-05-27T16:09:41Z", "path": "connect/api/src/main/java/org/apache/kafka/connect/transforms/predicates/Predicate.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import org.apache.kafka.common.Configurable;\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectRecord;\n+\n+/**\n+ * <p>A predicate on records.\n+ * Predicates can be used to conditionally apply a {@link org.apache.kafka.connect.transforms.Transformation}\n+ * by configuring the transformation's {@code predicate} (and {@code negate}) configuration parameters.\n+ * In particular, the {@code Filter} transformation can be conditionally applied in order to filter\n+ * certain records from further processing.\n+ *\n+ * <p>Implementations of this interface must be public and have a public constructor with no parameters.\n+ *\n+ * @param <R> The type of record.\n+ */\n+public interface Predicate<R extends ConnectRecord<R>> extends Configurable, AutoCloseable {\n+\n+    /**\n+     * Configuration specification for this predicate.\n+     */\n+    ConfigDef config();\n+\n+    /**\n+     * Returns whether the given record satisfies this predicate.\n+     */", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4MTE1OQ==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431281159", "bodyText": "Should we wait until all brokers and Connect workers are available, via something like:\n        connect.assertions().assertExactlyNumBrokersAreUp(numBrokers, \"Brokers did not start in time.\");\n        connect.assertions().assertExactlyNumWorkersAreUp(numWorkers, \"Worker did not start in time.\");", "author": "rhauch", "createdAt": "2020-05-27T16:33:26Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/TransformationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.connect.storage.StringConverter;\n+import org.apache.kafka.connect.transforms.Filter;\n+import org.apache.kafka.connect.transforms.predicates.HasHeaderKey;\n+import org.apache.kafka.connect.transforms.predicates.RecordIsTombstone;\n+import org.apache.kafka.connect.transforms.predicates.TopicNameMatches;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.KEY_CONVERTER_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.PREDICATES_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TRANSFORMS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.VALUE_CONVERTER_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.apache.kafka.connect.runtime.WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * An integration test for connectors with transformations\n+ */\n+@Category(IntegrationTest.class)\n+public class TransformationIntegrationTest {\n+\n+    private static final int NUM_RECORDS_PRODUCED = 2000;\n+    private static final int NUM_TOPIC_PARTITIONS = 3;\n+    private static final long RECORD_TRANSFER_DURATION_MS = TimeUnit.SECONDS.toMillis(30);\n+    private static final long OBSERVED_RECORDS_DURATION_MS = TimeUnit.SECONDS.toMillis(60);\n+    private static final int NUM_TASKS = 3;\n+    private static final int NUM_WORKERS = 3;\n+    private static final String CONNECTOR_NAME = \"simple-conn\";\n+    private static final String SINK_CONNECTOR_CLASS_NAME = MonitorableSinkConnector.class.getSimpleName();\n+    private static final String SOURCE_CONNECTOR_CLASS_NAME = MonitorableSourceConnector.class.getSimpleName();\n+\n+    private EmbeddedConnectCluster connect;\n+    private ConnectorHandle connectorHandle;\n+\n+    @Before\n+    public void setup() {\n+        // setup Connect worker properties\n+        Map<String, String> exampleWorkerProps = new HashMap<>();\n+        exampleWorkerProps.put(OFFSET_COMMIT_INTERVAL_MS_CONFIG, String.valueOf(5_000));\n+\n+        // setup Kafka broker properties\n+        Properties exampleBrokerProps = new Properties();\n+        exampleBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(exampleWorkerProps)\n+                .brokerProps(exampleBrokerProps)\n+                .build();\n+\n+        // start the clusters\n+        connect.start();", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4MjcxMg==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431282712", "bodyText": "This is an asynchronous method, and it's likely the connector will not be started and running before the test proceeds to the next statements. This can lead to very flaky tests.\nWe could instead wait until the connector is actually running, using something like:\n        connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, NUM_TASKS,\n                \"Connector tasks did not start in time.\");", "author": "rhauch", "createdAt": "2020-05-27T16:35:32Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/TransformationIntegrationTest.java", "diffHunk": "@@ -0,0 +1,297 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.integration;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.connect.storage.StringConverter;\n+import org.apache.kafka.connect.transforms.Filter;\n+import org.apache.kafka.connect.transforms.predicates.HasHeaderKey;\n+import org.apache.kafka.connect.transforms.predicates.RecordIsTombstone;\n+import org.apache.kafka.connect.transforms.predicates.TopicNameMatches;\n+import org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster;\n+import org.apache.kafka.test.IntegrationTest;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+\n+import static java.util.Collections.singletonMap;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.CONNECTOR_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.KEY_CONVERTER_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.PREDICATES_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TASKS_MAX_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.TRANSFORMS_CONFIG;\n+import static org.apache.kafka.connect.runtime.ConnectorConfig.VALUE_CONVERTER_CLASS_CONFIG;\n+import static org.apache.kafka.connect.runtime.SinkConnectorConfig.TOPICS_CONFIG;\n+import static org.apache.kafka.connect.runtime.WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG;\n+import static org.apache.kafka.test.TestUtils.waitForCondition;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertNotNull;\n+\n+/**\n+ * An integration test for connectors with transformations\n+ */\n+@Category(IntegrationTest.class)\n+public class TransformationIntegrationTest {\n+\n+    private static final int NUM_RECORDS_PRODUCED = 2000;\n+    private static final int NUM_TOPIC_PARTITIONS = 3;\n+    private static final long RECORD_TRANSFER_DURATION_MS = TimeUnit.SECONDS.toMillis(30);\n+    private static final long OBSERVED_RECORDS_DURATION_MS = TimeUnit.SECONDS.toMillis(60);\n+    private static final int NUM_TASKS = 3;\n+    private static final int NUM_WORKERS = 3;\n+    private static final String CONNECTOR_NAME = \"simple-conn\";\n+    private static final String SINK_CONNECTOR_CLASS_NAME = MonitorableSinkConnector.class.getSimpleName();\n+    private static final String SOURCE_CONNECTOR_CLASS_NAME = MonitorableSourceConnector.class.getSimpleName();\n+\n+    private EmbeddedConnectCluster connect;\n+    private ConnectorHandle connectorHandle;\n+\n+    @Before\n+    public void setup() {\n+        // setup Connect worker properties\n+        Map<String, String> exampleWorkerProps = new HashMap<>();\n+        exampleWorkerProps.put(OFFSET_COMMIT_INTERVAL_MS_CONFIG, String.valueOf(5_000));\n+\n+        // setup Kafka broker properties\n+        Properties exampleBrokerProps = new Properties();\n+        exampleBrokerProps.put(\"auto.create.topics.enable\", \"false\");\n+\n+        // build a Connect cluster backed by Kafka and Zk\n+        connect = new EmbeddedConnectCluster.Builder()\n+                .name(\"connect-cluster\")\n+                .numWorkers(NUM_WORKERS)\n+                .numBrokers(1)\n+                .workerProps(exampleWorkerProps)\n+                .brokerProps(exampleBrokerProps)\n+                .build();\n+\n+        // start the clusters\n+        connect.start();\n+\n+        // get a handle to the connector\n+        connectorHandle = RuntimeHandles.get().connectorHandle(CONNECTOR_NAME);\n+    }\n+\n+    @After\n+    public void close() {\n+        // delete connector handle\n+        RuntimeHandles.get().deleteConnector(CONNECTOR_NAME);\n+\n+        // stop all Connect, Kafka and Zk threads.\n+        connect.stop();\n+    }\n+\n+    /**\n+     * Test the {@link Filter} transformer with a\n+     * {@link TopicNameMatches} predicate on a sink connector.\n+     */\n+    @Test\n+    public void testFilterOnTopicNameWithSinkConnector() throws Exception {\n+        Map<String, Long> observedRecords = observeRecords();\n+\n+        // create test topics\n+        String fooTopic = \"foo-topic\";\n+        String barTopic = \"bar-topic\";\n+        int numFooRecords = NUM_RECORDS_PRODUCED;\n+        int numBarRecords = NUM_RECORDS_PRODUCED;\n+        connect.kafka().createTopic(fooTopic, NUM_TOPIC_PARTITIONS);\n+        connect.kafka().createTopic(barTopic, NUM_TOPIC_PARTITIONS);\n+\n+        // setup up props for the sink connector\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", CONNECTOR_NAME);\n+        props.put(CONNECTOR_CLASS_CONFIG, SINK_CONNECTOR_CLASS_NAME);\n+        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));\n+        props.put(TOPICS_CONFIG, String.join(\",\", fooTopic, barTopic));\n+        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n+        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n+        props.put(TRANSFORMS_CONFIG, \"filter\");\n+        props.put(TRANSFORMS_CONFIG + \".filter.type\", Filter.class.getSimpleName());\n+        props.put(TRANSFORMS_CONFIG + \".filter.predicate\", \"barPredicate\");\n+        props.put(PREDICATES_CONFIG, \"barPredicate\");\n+        props.put(PREDICATES_CONFIG + \".barPredicate.type\", TopicNameMatches.class.getSimpleName());\n+        props.put(PREDICATES_CONFIG + \".barPredicate.pattern\", \"bar-.*\");\n+\n+        // expect all records to be consumed by the connector\n+        connectorHandle.expectedRecords(numFooRecords);\n+\n+        // expect all records to be consumed by the connector\n+        connectorHandle.expectedCommits(numFooRecords);\n+\n+        // start a sink connector\n+        connect.configureConnector(CONNECTOR_NAME, props);", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NjE2MA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431286160", "bodyText": "Here the default is null, which means that the configuration validation allows the name field to not be set. Per the KIP, we want to require that name is set. To do that, we should use ConfigDef.NO_DEFAULT_VALUE:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final ConfigDef CONFIG_DEF = new ConfigDef().define(NAME_CONFIG, ConfigDef.Type.STRING, null,\n          \n          \n            \n                private static final ConfigDef CONFIG_DEF = new ConfigDef().define(NAME_CONFIG, ConfigDef.Type.STRING, ConfigDef.NO_DEFAULT_VALUE,", "author": "rhauch", "createdAt": "2020-05-27T16:39:23Z", "path": "connect/transforms/src/main/java/org/apache/kafka/connect/transforms/predicates/HasHeaderKey.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import java.util.Iterator;\n+import java.util.Map;\n+\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.connect.connector.ConnectRecord;\n+import org.apache.kafka.connect.header.Header;\n+import org.apache.kafka.connect.transforms.util.SimpleConfig;\n+\n+/**\n+ * A predicate which is true for records with at least one header with the configured name.\n+ * @param <R> The type of connect record.\n+ */\n+public class HasHeaderKey<R extends ConnectRecord<R>> implements Predicate<R> {\n+\n+    private static final String NAME_CONFIG = \"name\";\n+    private static final ConfigDef CONFIG_DEF = new ConfigDef().define(NAME_CONFIG, ConfigDef.Type.STRING, null,", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMwNTI3Ng==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431305276", "bodyText": "Ah, thanks, I'd not realised that was the point of ConfigDef.NO_DEFAULT_VALUE.", "author": "tombentley", "createdAt": "2020-05-27T17:08:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NjE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NzYwOA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431287608", "bodyText": "The default doesn't match the KIP. Either we should update the KIP to accept .* as the default pattern, or we should use ConfigDef.NO_DEFAULT_VALUE as the default to require the pattern to be set.", "author": "rhauch", "createdAt": "2020-05-27T16:41:55Z", "path": "connect/transforms/src/main/java/org/apache/kafka/connect/transforms/predicates/TopicNameMatches.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+import java.util.regex.PatternSyntaxException;\n+\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.apache.kafka.connect.connector.ConnectRecord;\n+import org.apache.kafka.connect.transforms.util.RegexValidator;\n+import org.apache.kafka.connect.transforms.util.SimpleConfig;\n+\n+/**\n+ * A predicate which is true for records with a topic name that matches the configured regular expression.\n+ * @param <R> The type of connect record.\n+ */\n+public class TopicNameMatches<R extends ConnectRecord<R>> implements Predicate<R> {\n+\n+    private static final String PATTERN_CONFIG = \"pattern\";\n+    private static final ConfigDef CONFIG_DEF = new ConfigDef().define(PATTERN_CONFIG, ConfigDef.Type.STRING, \".*\",\n+            new RegexValidator(), ConfigDef.Importance.MEDIUM,\n+            \"A Java regular expression for matching against the name of a record's topic.\");", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMwODcyNA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431308724", "bodyText": "I changed it to .* only when I realised that the default had to be valid and before I knew about NO_DEFAULT_VALUE, so using NO_DEFAULT_VALUE is good. Thanks!", "author": "tombentley", "createdAt": "2020-05-27T17:13:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4NzYwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTI4ODkxMw==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431288913", "bodyText": "Can we ever get to line 64? The constructor of the config (line 58) should fail if the pattern validator fails to ensure the pattern is a valid regex, which means that if we make it past 58 then line 62 will never fail.\nAm I missing something?", "author": "rhauch", "createdAt": "2020-05-27T16:43:59Z", "path": "connect/transforms/src/main/java/org/apache/kafka/connect/transforms/predicates/TopicNameMatches.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+import java.util.regex.PatternSyntaxException;\n+\n+import org.apache.kafka.common.config.ConfigDef;\n+import org.apache.kafka.common.config.ConfigException;\n+import org.apache.kafka.connect.connector.ConnectRecord;\n+import org.apache.kafka.connect.transforms.util.RegexValidator;\n+import org.apache.kafka.connect.transforms.util.SimpleConfig;\n+\n+/**\n+ * A predicate which is true for records with a topic name that matches the configured regular expression.\n+ * @param <R> The type of connect record.\n+ */\n+public class TopicNameMatches<R extends ConnectRecord<R>> implements Predicate<R> {\n+\n+    private static final String PATTERN_CONFIG = \"pattern\";\n+    private static final ConfigDef CONFIG_DEF = new ConfigDef().define(PATTERN_CONFIG, ConfigDef.Type.STRING, \".*\",\n+            new RegexValidator(), ConfigDef.Importance.MEDIUM,\n+            \"A Java regular expression for matching against the name of a record's topic.\");\n+    private Pattern pattern;\n+\n+    @Override\n+    public ConfigDef config() {\n+        return CONFIG_DEF;\n+    }\n+\n+    @Override\n+    public boolean test(R record) {\n+        return record.topic() != null && pattern.matcher(record.topic()).matches();\n+    }\n+\n+    @Override\n+    public void close() {\n+\n+    }\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) {\n+        SimpleConfig simpleConfig = new SimpleConfig(config(), configs);\n+        Pattern result;\n+        String value = simpleConfig.getString(PATTERN_CONFIG);\n+        try {\n+            result = Pattern.compile(value);\n+        } catch (PatternSyntaxException e) {\n+            throw new ConfigException(PATTERN_CONFIG, value, \"entry must be a Java-compatible regular expression: \" + e.getMessage());\n+        }", "originalCommit": "e76a0b4d4601310bd080e812668466997ac61268", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "url": "https://github.com/apache/kafka/commit/602a89dad35f2340c48f7c0d0336382c7e94cfb0", "message": "Apply suggestions from code review\n\nCo-authored-by: Randall Hauch <rhauch@gmail.com>", "committedDate": "2020-05-27T17:09:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyMTAxNA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431321014", "bodyText": "Maybe a few more tests that test the ConfigDef and AbstractConfig validation:\n    @Test\n    public void testNameRequiredInConfig() {\n        Map<String, String> props = new HashMap<>();\n        ConfigException e = assertThrows(ConfigException.class, () -> config(props));\n        assertTrue(e.getMessage().contains(\"Missing required configuration \\\"name\\\"\"));\n    }\n\n    @Test\n    public void testNameMayNotBeEmptyInConfig() {\n        Map<String, String> props = new HashMap<>();\n        props.put(\"name\", \"\");\n        ConfigException e = assertThrows(ConfigException.class, () -> config(props));\n        assertTrue(e.getMessage().contains(\"String must be non-empty\"));\n    }\n\n    protected SimpleConfig config(Map<String, String> props) {\n        return new SimpleConfig(new HasHeaderKey().config(), props);\n    }\n\nBTW, note that the new HasHeaderKey().config() is required because there is no accessible static ConfigDef. Might want to just make the static field package protected.", "author": "rhauch", "createdAt": "2020-05-27T17:34:30Z", "path": "connect/transforms/src/test/java/org/apache/kafka/connect/transforms/predicates/HasHeaderKeyTest.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import org.apache.kafka.common.config.ConfigValue;\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.header.Header;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.junit.Test;\n+\n+import static java.util.Collections.singletonList;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+public class HasHeaderKeyTest {\n+", "originalCommit": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY1MjM0OA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431652348", "bodyText": "The empty string is a valid regex, so I used CompositeValidator.of(new NonEmptyString(), new RegexValidator()) in TopicNameMatches, rather than just new RegexValidator().", "author": "tombentley", "createdAt": "2020-05-28T08:01:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyMTAxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY1MzMxOQ==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431653319", "bodyText": "Oops, replied to wrong comment, but I'm sure you guessed what I mean.", "author": "tombentley", "createdAt": "2020-05-28T08:03:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyMTAxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMyODQ2NA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431328464", "bodyText": "Maybe a few more tests that test the ConfigDef and AbstractConfig validation:\n    @Test\n    public void testPatternRequiredInConfig() {\n        Map<String, String> props = new HashMap<>();\n        ConfigException e = assertThrows(ConfigException.class, () -> config(props));\n        assertTrue(e.getMessage().contains(\"Missing required configuration \\\"pattern\\\"\"));\n    }\n\n    @Test\n    public void testPatternMayNotBeEmptyInConfig() {\n        Map<String, String> props = new HashMap<>();\n        props.put(\"pattern\", \"\");\n        ConfigException e = assertThrows(ConfigException.class, () -> config(props));\n        System.out.println(e.getMessage());\n        assertTrue(e.getMessage().contains(\"String must be non-empty\"));\n    }\n\n    @Test\n    public void testPatternIsValidRegexInConfig() {\n        Map<String, String> props = new HashMap<>();\n        props.put(\"pattern\", \"[\");\n        ConfigException e = assertThrows(ConfigException.class, () -> config(props));\n        System.out.println(e.getMessage());\n        assertTrue(e.getMessage().contains(\"Invalid regex\"));\n    }\n\n    protected SimpleConfig config(Map<String, String> props) {\n        return new SimpleConfig(new TopicNameMatches().config(), props);\n    }", "author": "rhauch", "createdAt": "2020-05-27T17:47:12Z", "path": "connect/transforms/src/test/java/org/apache/kafka/connect/transforms/predicates/TopicNameMatchesTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.connect.transforms.predicates;\n+\n+import java.util.Collections;\n+import java.util.List;\n+\n+import org.apache.kafka.common.config.ConfigValue;\n+import org.apache.kafka.connect.source.SourceRecord;\n+import org.junit.Test;\n+\n+import static java.util.Collections.singletonList;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TopicNameMatchesTest {\n+", "originalCommit": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMzMzQ4NA==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431333484", "bodyText": "Should we also check the other two predicate implementations, too? I know it's not strictly required, but it would help to better ensure the pattern matches more than just one implementation.", "author": "rhauch", "createdAt": "2020-05-27T17:52:56Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/isolation/PluginUtilsTest.java", "diffHunk": "@@ -128,6 +131,10 @@ public void testAllowedConnectFrameworkClasses() {\n         assertTrue(PluginUtils.shouldLoadInIsolation(\n                 \"org.apache.kafka.connect.transforms.ExtractField$Key\")\n         );\n+        assertTrue(PluginUtils.shouldLoadInIsolation(\"org.apache.kafka.connect.transforms.predicates.\"));\n+        assertTrue(PluginUtils.shouldLoadInIsolation(\n+                \"org.apache.kafka.connect.transforms.predicates.TopicNameMatches\")\n+        );", "originalCommit": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTU0MjMyMQ==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431542321", "bodyText": "Given the small number of predicates, I agree with @rhauch", "author": "kkonstantine", "createdAt": "2020-05-28T02:07:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMzMzQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMzOTg1Nw==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431339857", "bodyText": "It'd be good to have the test reflect the current behavior.", "author": "rhauch", "createdAt": "2020-05-27T18:00:39Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/ConnectorConfigTest.java", "diffHunk": "@@ -214,6 +216,185 @@ public void abstractKeyValueTransform() {\n         }\n     }\n \n+    @Test(expected = ConfigException.class)\n+    public void wrongPredicateType() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestConnector.class.getName());\n+        new ConnectorConfig(MOCK_PLUGINS, props);\n+    }\n+\n+    @Test\n+    public void singleConditionalTransform() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"transforms.a.negate\", \"true\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, true);\n+    }\n+\n+    @Test\n+    public void predicateNegationDefaultsToFalse() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, false);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void abstractPredicate() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", AbstractTestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, false);\n+    }\n+\n+    private void assertPredicatedTransform(Map<String, String> props, boolean expectedNegated) {\n+        final ConnectorConfig config = new ConnectorConfig(MOCK_PLUGINS, props);\n+        final List<Transformation<R>> transformations = config.transformations();\n+        assertEquals(1, transformations.size());\n+        assertTrue(transformations.get(0) instanceof PredicatedTransformation);\n+        PredicatedTransformation<?> predicated = (PredicatedTransformation<?>) transformations.get(0);\n+\n+        assertEquals(expectedNegated, predicated.negate);\n+\n+        assertTrue(predicated.delegate instanceof ConnectorConfigTest.SimpleTransformation);\n+        assertEquals(42, ((SimpleTransformation<?>) predicated.delegate).magicNumber);\n+\n+        assertTrue(predicated.predicate instanceof ConnectorConfigTest.TestPredicate);\n+        assertEquals(84, ((TestPredicate<?>) predicated.predicate).param);\n+\n+        predicated.close();\n+\n+        assertEquals(0, ((SimpleTransformation<?>) predicated.delegate).magicNumber);\n+        assertEquals(0, ((TestPredicate<?>) predicated.predicate).param);\n+    }\n+\n+    @Test\n+    public void misconfiguredPredicate() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"transforms.a.negate\", \"true\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"79\");\n+        try {\n+            new ConnectorConfig(MOCK_PLUGINS, props);\n+            fail();\n+        } catch (ConfigException e) {\n+            assertTrue(e.getMessage().contains(\"Value must be at least 80\"));\n+        }\n+    }\n+\n+    @Ignore(\"Is this really an error. There's no actual need for the predicates config (unlike transforms where it defines the order).\")", "originalCommit": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTM0MTA3Mg==", "url": "https://github.com/apache/kafka/pull/8699#discussion_r431341072", "bodyText": "We've moved to using assertThrows here, which would look something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    try {\n          \n          \n            \n                        new ConnectorConfig(MOCK_PLUGINS, props);\n          \n          \n            \n                        fail();\n          \n          \n            \n                    } catch (ConfigException e) {\n          \n          \n            \n                        assertTrue(e.getMessage().contains(\"Value must be at least 80\"));\n          \n          \n            \n                    }\n          \n          \n            \n                    ConfigException e = assertThrows(ConfigException.class, () -> new ConnectorConfig(MOCK_PLUGINS, props));\n          \n          \n            \n                    assertTrue(e.getMessage().contains(\"Value must be at least 42\"));", "author": "rhauch", "createdAt": "2020-05-27T18:02:56Z", "path": "connect/runtime/src/test/java/org/apache/kafka/connect/runtime/ConnectorConfigTest.java", "diffHunk": "@@ -214,6 +216,185 @@ public void abstractKeyValueTransform() {\n         }\n     }\n \n+    @Test(expected = ConfigException.class)\n+    public void wrongPredicateType() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestConnector.class.getName());\n+        new ConnectorConfig(MOCK_PLUGINS, props);\n+    }\n+\n+    @Test\n+    public void singleConditionalTransform() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"transforms.a.negate\", \"true\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, true);\n+    }\n+\n+    @Test\n+    public void predicateNegationDefaultsToFalse() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, false);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void abstractPredicate() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", AbstractTestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"84\");\n+        assertPredicatedTransform(props, false);\n+    }\n+\n+    private void assertPredicatedTransform(Map<String, String> props, boolean expectedNegated) {\n+        final ConnectorConfig config = new ConnectorConfig(MOCK_PLUGINS, props);\n+        final List<Transformation<R>> transformations = config.transformations();\n+        assertEquals(1, transformations.size());\n+        assertTrue(transformations.get(0) instanceof PredicatedTransformation);\n+        PredicatedTransformation<?> predicated = (PredicatedTransformation<?>) transformations.get(0);\n+\n+        assertEquals(expectedNegated, predicated.negate);\n+\n+        assertTrue(predicated.delegate instanceof ConnectorConfigTest.SimpleTransformation);\n+        assertEquals(42, ((SimpleTransformation<?>) predicated.delegate).magicNumber);\n+\n+        assertTrue(predicated.predicate instanceof ConnectorConfigTest.TestPredicate);\n+        assertEquals(84, ((TestPredicate<?>) predicated.predicate).param);\n+\n+        predicated.close();\n+\n+        assertEquals(0, ((SimpleTransformation<?>) predicated.delegate).magicNumber);\n+        assertEquals(0, ((TestPredicate<?>) predicated.predicate).param);\n+    }\n+\n+    @Test\n+    public void misconfiguredPredicate() {\n+        Map<String, String> props = new HashMap<>();\n+        props.put(\"name\", \"test\");\n+        props.put(\"connector.class\", TestConnector.class.getName());\n+        props.put(\"transforms\", \"a\");\n+        props.put(\"transforms.a.type\", SimpleTransformation.class.getName());\n+        props.put(\"transforms.a.magic.number\", \"42\");\n+        props.put(\"transforms.a.predicate\", \"my-pred\");\n+        props.put(\"transforms.a.negate\", \"true\");\n+        props.put(\"predicates\", \"my-pred\");\n+        props.put(\"predicates.my-pred.type\", TestPredicate.class.getName());\n+        props.put(\"predicates.my-pred.int\", \"79\");\n+        try {\n+            new ConnectorConfig(MOCK_PLUGINS, props);\n+            fail();\n+        } catch (ConfigException e) {\n+            assertTrue(e.getMessage().contains(\"Value must be at least 80\"));\n+        }", "originalCommit": "602a89dad35f2340c48f7c0d0336382c7e94cfb0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "03ce156772cc890cf0abf6529e960d0c5809dfbe", "url": "https://github.com/apache/kafka/commit/03ce156772cc890cf0abf6529e960d0c5809dfbe", "message": "KAFKA-9673: Fix a few unit and integration tests", "committedDate": "2020-05-27T22:39:53Z", "type": "commit"}, {"oid": "60cd39eb0e17cdf7e3fa52886391e774460123c7", "url": "https://github.com/apache/kafka/commit/60cd39eb0e17cdf7e3fa52886391e774460123c7", "message": "KAFKA-9673: Added some tests, made others a bit more robust, and added more validation to TopicNameMatches", "committedDate": "2020-05-27T23:43:07Z", "type": "commit"}, {"oid": "cbc89818ce2a9ac9dae9ca02288f9d71b1a851da", "url": "https://github.com/apache/kafka/commit/cbc89818ce2a9ac9dae9ca02288f9d71b1a851da", "message": "Trivial correction", "committedDate": "2020-05-28T08:23:37Z", "type": "commit"}]}