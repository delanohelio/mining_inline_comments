{"pr_number": 9103, "pr_title": "KAFKA-10181: Use Envelope RPC to do redirection for (Incremental)AlterConfig, AlterClientQuota and CreateTopics", "pr_createdAt": "2020-07-30T04:55:03Z", "pr_url": "https://github.com/apache/kafka/pull/9103", "timeline": [{"oid": "1e35e371a05ef48761e729690cb67d944b9f1bc8", "url": "https://github.com/apache/kafka/commit/1e35e371a05ef48761e729690cb67d944b9f1bc8", "message": "fix tests", "committedDate": "2020-08-07T18:59:28Z", "type": "forcePushed"}, {"oid": "ccdcb996a98460d1d6db13edd2c5211f84728e1d", "url": "https://github.com/apache/kafka/commit/ccdcb996a98460d1d6db13edd2c5211f84728e1d", "message": "rebase", "committedDate": "2020-09-30T16:09:22Z", "type": "forcePushed"}, {"oid": "0fcd219aa78558dc1a7cec93c25cea0e981df170", "url": "https://github.com/apache/kafka/commit/0fcd219aa78558dc1a7cec93c25cea0e981df170", "message": "unknown client test", "committedDate": "2020-10-09T16:51:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4NjUyNA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504286524", "bodyText": "nit: why don't we call it requestData to be consistent with the name used in the api spec?", "author": "hachikuji", "createdAt": "2020-10-13T22:08:10Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import org.apache.kafka.common.message.DefaultPrincipalData;\n+import org.apache.kafka.common.message.EnvelopeRequestData;\n+import org.apache.kafka.common.message.EnvelopeResponseData;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.protocol.types.Struct;\n+import org.apache.kafka.common.security.auth.KafkaPrincipal;\n+import org.apache.kafka.common.security.auth.KafkaPrincipalSerde;\n+\n+import java.nio.ByteBuffer;\n+\n+public class EnvelopeRequest extends AbstractRequest {\n+\n+    public static class Builder extends AbstractRequest.Builder<EnvelopeRequest> {\n+\n+        private final EnvelopeRequestData data;\n+\n+        public Builder(ByteBuffer embedData, String clientHostName) {\n+            this(embedData, null, clientHostName);\n+        }\n+\n+        public Builder(ByteBuffer embedData,", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4NzcyMw==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504287723", "bodyText": "nit: I think it might be better to pull this out of the request class. The direction we're moving is toward dumber request/response classes. Eventually EnvelopeRequest will go away and we'll just use EnvelopeRequestData.", "author": "hachikuji", "createdAt": "2020-10-13T22:10:46Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeRequest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import org.apache.kafka.common.message.DefaultPrincipalData;\n+import org.apache.kafka.common.message.EnvelopeRequestData;\n+import org.apache.kafka.common.message.EnvelopeResponseData;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.protocol.types.Struct;\n+import org.apache.kafka.common.security.auth.KafkaPrincipal;\n+import org.apache.kafka.common.security.auth.KafkaPrincipalSerde;\n+\n+import java.nio.ByteBuffer;\n+\n+public class EnvelopeRequest extends AbstractRequest {\n+\n+    public static class Builder extends AbstractRequest.Builder<EnvelopeRequest> {\n+\n+        private final EnvelopeRequestData data;\n+\n+        public Builder(ByteBuffer embedData, String clientHostName) {\n+            this(embedData, null, clientHostName);\n+        }\n+\n+        public Builder(ByteBuffer embedData,\n+                       ByteBuffer serializedPrincipal,\n+                       String clientHostName) {\n+            super(ApiKeys.ENVELOPE);\n+            this.data = new EnvelopeRequestData()\n+                            .setRequestData(embedData)\n+                            .setRequestPrincipal(serializedPrincipal)\n+                            .setClientHostName(clientHostName);\n+        }\n+\n+        @Override\n+        public EnvelopeRequest build(short version) {\n+            return new EnvelopeRequest(data, version);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return data.toString();\n+        }\n+    }\n+\n+    private final EnvelopeRequestData data;\n+\n+    public EnvelopeRequest(EnvelopeRequestData data, short version) {\n+        super(ApiKeys.ENVELOPE, version);\n+        this.data = data;\n+    }\n+\n+    public EnvelopeRequest(Struct struct, short version) {\n+        super(ApiKeys.ENVELOPE, version);\n+        this.data = new EnvelopeRequestData(struct, version);\n+    }\n+\n+    public ByteBuffer requestData() {\n+        return data.requestData();\n+    }\n+\n+    public String clientHostName() {\n+        return data.clientHostName();\n+    }\n+\n+    public KafkaPrincipal requestPrincipal(KafkaPrincipalSerde principalSerde) {", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4ODY1OQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504288659", "bodyText": "Not sure why we need this change. I think the convention is to include NONE in error counts.", "author": "hachikuji", "createdAt": "2020-10-13T22:12:59Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/CreateTopicsResponse.java", "diffHunk": "@@ -70,9 +70,12 @@ public int throttleTimeMs() {\n     @Override\n     public Map<Errors, Integer> errorCounts() {\n         HashMap<Errors, Integer> counts = new HashMap<>();\n-        data.topics().forEach(result ->\n-            updateErrorCounts(counts, Errors.forCode(result.errorCode()))\n-        );\n+        for (CreateTopicsResponseData.CreatableTopicResult result : data.topics()) {\n+            Errors error = Errors.forCode(result.errorCode());\n+            if (error != Errors.NONE) {", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMyNzk4NQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504327985", "bodyText": "I guess there are some inconsistency between different RPCs as I spotted cases excluding NONE. I would initiate a separate JIRA for the cleaning and revert the change here.", "author": "abbccdda", "createdAt": "2020-10-14T00:12:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4ODY1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDM0MTA3MQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504341071", "bodyText": "https://issues.apache.org/jira/browse/KAFKA-10607", "author": "abbccdda", "createdAt": "2020-10-14T01:01:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI4ODY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5MzE0NA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504293144", "bodyText": "I'm wondering if we really need the IBP to leak into the common library. It should really only be a broker concern. Seems like the only point is so that we can continue to use the factory methods defined below from the broker code. Is that right? Could we instead move the factories to the broker?", "author": "hachikuji", "createdAt": "2020-10-13T22:24:33Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java", "diffHunk": "@@ -43,15 +43,43 @@\n  */\n public class ApiVersionsResponse extends AbstractResponse {\n \n+    public static final int MIN_CONSTRAINT_IBP_VERSION = 31;", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQwODYzMw==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504408633", "bodyText": "The tricky thing here is that if we handle the api version constraints on the broker side, it means we need to either make changes directly to the returned ApiVersionsResponse or spawn a new instance with applied constraints. That means leaking of the internal architecture of ApiVersionsResponse to the broker level and redundant conversions IMHO. The current approach makes sure the broker level logic is clean with only the necessity of passing the IBP number.", "author": "abbccdda", "createdAt": "2020-10-14T05:23:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5MzE0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5NTAyNA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504295024", "bodyText": "In a similar vein, I think it's better to not include serialization logic in the response object. It tends to hide some of the details like byte buffer allocation that we might want to control at another level.", "author": "hachikuji", "createdAt": "2020-10-13T22:29:23Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeResponse.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import org.apache.kafka.common.message.EnvelopeResponseData;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.protocol.types.Struct;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+\n+public class EnvelopeResponse extends AbstractResponse {\n+\n+    private final EnvelopeResponseData data;\n+\n+    public EnvelopeResponse(int throttleTimeMs, AbstractResponse innerResponse, short innerApiVersion) {", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5NTg3NA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504295874", "bodyText": "Same here. We can return ByteBuffer and leave parsing to higher layers.", "author": "hachikuji", "createdAt": "2020-10-13T22:31:40Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/EnvelopeResponse.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import org.apache.kafka.common.message.EnvelopeResponseData;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.protocol.types.Struct;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+\n+public class EnvelopeResponse extends AbstractResponse {\n+\n+    private final EnvelopeResponseData data;\n+\n+    public EnvelopeResponse(int throttleTimeMs, AbstractResponse innerResponse, short innerApiVersion) {\n+        Struct dataStruct = innerResponse.toStruct(innerApiVersion);\n+        ByteBuffer buffer = ByteBuffer.allocate(dataStruct.sizeOf());\n+        dataStruct.writeTo(buffer);\n+        buffer.flip();\n+\n+        this.data = new EnvelopeResponseData()\n+                        .setThrottleTimeMs(throttleTimeMs)\n+                        .setResponseData(buffer);\n+    }\n+\n+    public EnvelopeResponse(EnvelopeResponseData data) {\n+        this.data = data;\n+    }\n+\n+    public AbstractResponse embedResponse(RequestHeader originalHeader) {", "originalCommit": "d45fb1a048e3d17ca4796acd210ff20c21bdf19a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5ODY2Mw==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504298663", "bodyText": "It is strange to couple the serialization of the principal with the version of the envelope request. This might help us in the case of default principal builder, but users with their own custom builder are on their own, right? I think it is better to be consistent and always leave versioning to the principal builder.", "author": "hachikuji", "createdAt": "2020-10-13T22:39:21Z", "path": "clients/src/main/java/org/apache/kafka/common/security/auth/KafkaPrincipalSerde.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.security.auth;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Serializer/Deserializer interface for {@link KafkaPrincipal} for the forwarding purpose.\n+ */\n+public interface KafkaPrincipalSerde {\n+\n+    ByteBuffer serialize(KafkaPrincipal principal, short version);", "originalCommit": "1059fa3d8d826343729ed6c6950284d39ae7d573", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI5ODg3OQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r504298879", "bodyText": "nit: maybe print forwardingPrincipal only if it is defined", "author": "hachikuji", "createdAt": "2020-10-13T22:39:55Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/RequestContext.java", "diffHunk": "@@ -78,8 +101,7 @@ public RequestAndSize parseRequest(ByteBuffer buffer) {\n                         \", connectionId: \" + connectionId +\n                         \", listenerName: \" + listenerName +\n                         \", principal: \" + principal +\n-                        \", initialPrincipal: \" + initialPrincipalName() +\n-                        \", initialClientId: \" + header.initialClientId(), ex);\n+                        \", forwardingPrincipal: \" + forwardingPrincipal, ex);", "originalCommit": "1059fa3d8d826343729ed6c6950284d39ae7d573", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NTY2NA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r505765664", "bodyText": "What is the benefit of using a different error code instead of CLUSTER_AUTHORIZATION_FAILURE?", "author": "hachikuji", "createdAt": "2020-10-15T18:47:39Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/Errors.java", "diffHunk": "@@ -338,7 +339,9 @@\n     INCONSISTENT_VOTER_SET(94, \"Indicates that the either the sender or recipient of a \" +\n             \"voter-only request is not one of the expected voters\", InconsistentVoterSetException::new),\n     INVALID_UPDATE_VERSION(95, \"The given update version was invalid.\", InvalidUpdateVersionException::new),\n-    FEATURE_UPDATE_FAILED(96, \"Unable to update finalized features due to an unexpected server error.\", FeatureUpdateFailedException::new);\n+    FEATURE_UPDATE_FAILED(96, \"Unable to update finalized features due to an unexpected server error.\", FeatureUpdateFailedException::new),\n+    BROKER_AUTHORIZATION_FAILURE(97, \"Authorization failed for the request during forwarding. \" +", "originalCommit": "9ce9d905e07cae741b79e265a30c87ea4b1e463b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg0MjkwNA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r505842904", "bodyText": "CLUSTER_AUTHORIZATION_FAILURE normally indicates a client side security configuration error. We intentionally define a separate error code to let admin know that there is some security config trouble with the brokers, not the clients.", "author": "abbccdda", "createdAt": "2020-10-15T20:56:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NTY2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTUyODAwOQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r509528009", "bodyText": "Not sure I follow. All current inter-broker APIs are gated by ClusterAction and will return CLUSTER_AUTHORIZATION_FAILURE if the principal does not have access. There is no distinction between clients and brokers. It's not clear to me why we need something different here.", "author": "hachikuji", "createdAt": "2020-10-21T18:01:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NTY2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2ODkwMQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r505768901", "bodyText": "I believe we need to set requiresDelayedAllocation for this API. Typically we will release the underlying buffer allocated for a request when RequestChannel.Request is constructed. However, since we are using \"zeroCopy,\" we need to hold onto the ByteBuffer reference until the API has been handled.", "author": "hachikuji", "createdAt": "2020-10-15T18:53:21Z", "path": "clients/src/main/java/org/apache/kafka/common/protocol/ApiKeys.java", "diffHunk": "@@ -251,7 +253,8 @@ public Struct parseResponse(short version, ByteBuffer buffer) {\n         DescribeQuorumRequestData.SCHEMAS, DescribeQuorumResponseData.SCHEMAS),\n     ALTER_ISR(56, \"AlterIsr\", AlterIsrRequestData.SCHEMAS, AlterIsrResponseData.SCHEMAS),\n     UPDATE_FEATURES(57, \"UpdateFeatures\",\n-        UpdateFeaturesRequestData.SCHEMAS, UpdateFeaturesResponseData.SCHEMAS);\n+        UpdateFeaturesRequestData.SCHEMAS, UpdateFeaturesResponseData.SCHEMAS),\n+    ENVELOPE(58, \"Envelope\", EnvelopeRequestData.SCHEMAS, EnvelopeResponseData.SCHEMAS);", "originalCommit": "9ce9d905e07cae741b79e265a30c87ea4b1e463b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTg1MjkzOQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r505852939", "bodyText": "I think we do have that logic enforced by setting zeroCopy to true for request data field in the RPC json.", "author": "abbccdda", "createdAt": "2020-10-15T21:08:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2ODkwMQ=="}], "type": "inlineReview"}, {"oid": "23381446f23ad627b8bff393f5df78d08c9ea955", "url": "https://github.com/apache/kafka/commit/23381446f23ad627b8bff393f5df78d08c9ea955", "message": "redirection with Envelope request", "committedDate": "2020-10-29T06:16:22Z", "type": "commit"}, {"oid": "256ac60a6629e4b25dfeb2723f4b049a0d00aa3f", "url": "https://github.com/apache/kafka/commit/256ac60a6629e4b25dfeb2723f4b049a0d00aa3f", "message": "address Jason's comments", "committedDate": "2020-10-29T06:16:23Z", "type": "commit"}, {"oid": "498c0f9b376f3bef5be7a7898ec2011d91875064", "url": "https://github.com/apache/kafka/commit/498c0f9b376f3bef5be7a7898ec2011d91875064", "message": "rebase", "committedDate": "2020-10-29T06:40:43Z", "type": "commit"}, {"oid": "498c0f9b376f3bef5be7a7898ec2011d91875064", "url": "https://github.com/apache/kafka/commit/498c0f9b376f3bef5be7a7898ec2011d91875064", "message": "rebase", "committedDate": "2020-10-29T06:40:43Z", "type": "forcePushed"}, {"oid": "8c27f126e6d955a63aeca98d653bba312f35c985", "url": "https://github.com/apache/kafka/commit/8c27f126e6d955a63aeca98d653bba312f35c985", "message": "address more comments", "committedDate": "2020-10-30T21:46:53Z", "type": "commit"}, {"oid": "d0945193c90e7f057cd0236b178b2ea3ffb9dd70", "url": "https://github.com/apache/kafka/commit/d0945193c90e7f057cd0236b178b2ea3ffb9dd70", "message": "additional comments", "committedDate": "2020-10-31T03:20:16Z", "type": "commit"}, {"oid": "632abebffda6f19e17c50f7fe38adaa6168cd6b0", "url": "https://github.com/apache/kafka/commit/632abebffda6f19e17c50f7fe38adaa6168cd6b0", "message": "rebuild envelope response", "committedDate": "2020-10-31T05:49:08Z", "type": "commit"}, {"oid": "882a36306f3196734067baf7bbcfbd5bedc5eb3c", "url": "https://github.com/apache/kafka/commit/882a36306f3196734067baf7bbcfbd5bedc5eb3c", "message": "comment edits", "committedDate": "2020-11-01T03:39:46Z", "type": "commit"}, {"oid": "4c5f72573d3478174fbc645c67a16f5b590e049b", "url": "https://github.com/apache/kafka/commit/4c5f72573d3478174fbc645c67a16f5b590e049b", "message": "fix throttling test", "committedDate": "2020-11-02T17:39:34Z", "type": "commit"}, {"oid": "4c5f72573d3478174fbc645c67a16f5b590e049b", "url": "https://github.com/apache/kafka/commit/4c5f72573d3478174fbc645c67a16f5b590e049b", "message": "fix throttling test", "committedDate": "2020-11-02T17:39:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM0NDk2NQ==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r516344965", "bodyText": "nit: seems this change was not needed", "author": "hachikuji", "createdAt": "2020-11-02T23:57:03Z", "path": "clients/src/main/java/org/apache/kafka/clients/KafkaClient.java", "diffHunk": "@@ -180,7 +180,6 @@ ClientRequest newClientRequest(String nodeId, AbstractRequest.Builder<?> request\n \n     /**\n      * Create a new ClientRequest.\n-     *", "originalCommit": "4c5f72573d3478174fbc645c67a16f5b590e049b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM0OTY2NA==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r516349664", "bodyText": "nit: I feel FailureException is redundant. Can we just call it PrincipalDeserializationException?\nAlso, I am not sure about this extending AuthorizationException. I would consider it more of an invalid request than an authorization failure, though the effect is the same. I think it's probably better to avoid categorizing it and just let it extend ApiException.", "author": "hachikuji", "createdAt": "2020-11-03T00:06:25Z", "path": "clients/src/main/java/org/apache/kafka/common/errors/PrincipalDeserializationFailureException.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.errors;\n+\n+/**\n+ * Exception used to indicate a kafka principal deserialization failure during request forwarding.\n+ */\n+public class PrincipalDeserializationFailureException extends AuthorizationException {", "originalCommit": "4c5f72573d3478174fbc645c67a16f5b590e049b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NTMwMw==", "url": "https://github.com/apache/kafka/pull/9103#discussion_r516375303", "bodyText": "Can you add a javadoc for these methods and mention @throws SerializationException?", "author": "hachikuji", "createdAt": "2020-11-03T01:00:58Z", "path": "clients/src/main/java/org/apache/kafka/common/security/auth/KafkaPrincipalSerde.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.security.auth;\n+\n+import org.apache.kafka.common.errors.SerializationException;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Serializer/Deserializer interface for {@link KafkaPrincipal} for the the purpose of inter-broker forwarding.\n+ * Any serialization/deserialization failure should raise a {@link SerializationException} to be consistent.\n+ */\n+public interface KafkaPrincipalSerde {\n+\n+    ByteBuffer serialize(KafkaPrincipal principal);", "originalCommit": "4c5f72573d3478174fbc645c67a16f5b590e049b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "68a5c33f8ca09c1e3a5b2ae3695b4f99061e87f4", "url": "https://github.com/apache/kafka/commit/68a5c33f8ca09c1e3a5b2ae3695b4f99061e87f4", "message": "run one single integration test", "committedDate": "2020-11-03T08:31:54Z", "type": "commit"}, {"oid": "b396bf789f0435f72d79241248b0a15407f29264", "url": "https://github.com/apache/kafka/commit/b396bf789f0435f72d79241248b0a15407f29264", "message": "fix test", "committedDate": "2020-11-03T17:14:31Z", "type": "commit"}, {"oid": "868d316c19cf5234363046b51633c9d178aacde2", "url": "https://github.com/apache/kafka/commit/868d316c19cf5234363046b51633c9d178aacde2", "message": "A few improvements for envelope handling", "committedDate": "2020-11-03T17:41:17Z", "type": "commit"}, {"oid": "8984adfacb37254ee7e04a42dc9e2472bb63fc10", "url": "https://github.com/apache/kafka/commit/8984adfacb37254ee7e04a42dc9e2472bb63fc10", "message": "revert ssl store changes", "committedDate": "2020-11-03T19:39:18Z", "type": "commit"}, {"oid": "8984adfacb37254ee7e04a42dc9e2472bb63fc10", "url": "https://github.com/apache/kafka/commit/8984adfacb37254ee7e04a42dc9e2472bb63fc10", "message": "revert ssl store changes", "committedDate": "2020-11-03T19:39:18Z", "type": "forcePushed"}, {"oid": "f2bf1919726ab21ff5fcbdd20e664ae7f4ce3172", "url": "https://github.com/apache/kafka/commit/f2bf1919726ab21ff5fcbdd20e664ae7f4ce3172", "message": "test comments", "committedDate": "2020-11-03T22:16:40Z", "type": "commit"}, {"oid": "7d6fd7fdf11fbe24def47cf994466dbe75730405", "url": "https://github.com/apache/kafka/commit/7d6fd7fdf11fbe24def47cf994466dbe75730405", "message": "test fixes", "committedDate": "2020-11-04T01:10:36Z", "type": "commit"}, {"oid": "4e0b307a7276a67dfc874875718614d61dc29a9b", "url": "https://github.com/apache/kafka/commit/4e0b307a7276a67dfc874875718614d61dc29a9b", "message": "disable Envelope until ready", "committedDate": "2020-11-04T01:52:23Z", "type": "commit"}, {"oid": "bd4e1f5d788db78a80bba9b0d5ab8eeebfb7961e", "url": "https://github.com/apache/kafka/commit/bd4e1f5d788db78a80bba9b0d5ab8eeebfb7961e", "message": "set allow disabled api flag", "committedDate": "2020-11-04T04:30:02Z", "type": "commit"}, {"oid": "7f1797ba3fae3fe9339d114062e113e54f665b31", "url": "https://github.com/apache/kafka/commit/7f1797ba3fae3fe9339d114062e113e54f665b31", "message": "let remove all work", "committedDate": "2020-11-04T18:11:30Z", "type": "commit"}, {"oid": "4eb1650d08c23fdd7f169dfda680f0c1514d1156", "url": "https://github.com/apache/kafka/commit/4eb1650d08c23fdd7f169dfda680f0c1514d1156", "message": "Remove redundant envelope api filtering logic", "committedDate": "2020-11-04T19:16:22Z", "type": "commit"}, {"oid": "a4c3bf07f710e1bf12e4b864bfc302a648eec45b", "url": "https://github.com/apache/kafka/commit/a4c3bf07f710e1bf12e4b864bfc302a648eec45b", "message": "Change name of field indicating metadata quorum support", "committedDate": "2020-11-04T19:16:22Z", "type": "commit"}, {"oid": "f9844c4dc13337a68b89d6e1acf772af9246e221", "url": "https://github.com/apache/kafka/commit/f9844c4dc13337a68b89d6e1acf772af9246e221", "message": "Remove unneeded envelope handling in AbstractApiVersionsRequestTest", "committedDate": "2020-11-04T19:19:35Z", "type": "commit"}]}