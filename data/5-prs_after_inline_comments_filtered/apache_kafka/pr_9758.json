{"pr_number": 9758, "pr_title": "MINOR: remove FetchResponse.AbortedTransaction and redundant construc\u2026", "pr_createdAt": "2020-12-16T08:52:35Z", "pr_url": "https://github.com/apache/kafka/pull/9758", "timeline": [{"oid": "0fe301e1ad9e4b8514c75547379465a7b051da01", "url": "https://github.com/apache/kafka/commit/0fe301e1ad9e4b8514c75547379465a7b051da01", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate constructors of PartitionData", "committedDate": "2020-12-16T15:12:27Z", "type": "forcePushed"}, {"oid": "bae931be1b6b558ae70498ec5f25412361d12e5a", "url": "https://github.com/apache/kafka/commit/bae931be1b6b558ae70498ec5f25412361d12e5a", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate  constructors of PartitionData", "committedDate": "2020-12-19T06:35:21Z", "type": "forcePushed"}, {"oid": "2a3ce401125c0b4afbfd357a936d14f7da22c92a", "url": "https://github.com/apache/kafka/commit/2a3ce401125c0b4afbfd357a936d14f7da22c92a", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate  constructors of PartitionData", "committedDate": "2020-12-29T07:06:55Z", "type": "forcePushed"}, {"oid": "3b606da01cf5567a9ab3fd76fc8f223c6200b4a3", "url": "https://github.com/apache/kafka/commit/3b606da01cf5567a9ab3fd76fc8f223c6200b4a3", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate constructors of PartitionData", "committedDate": "2020-12-29T07:25:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxMjEzOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r551412139", "bodyText": "These changes seem unrelated?", "author": "ijuma", "createdAt": "2021-01-04T16:11:11Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -733,11 +733,11 @@ void resetOffsetIfNeeded(TopicPartition partition, OffsetResetStrategy requested\n     }\n \n     private void resetOffsetsAsync(Map<TopicPartition, Long> partitionResetTimestamps) {\n-        Map<Node, Map<TopicPartition, ListOffsetsPartition>> timestampsToSearchByNode =\n+        Map<Node, Map<TopicPartition, ListOffsetsRequestData.ListOffsetsPartition>> timestampsToSearchByNode =\n                 groupListOffsetRequests(partitionResetTimestamps, new HashSet<>());\n-        for (Map.Entry<Node, Map<TopicPartition, ListOffsetsPartition>> entry : timestampsToSearchByNode.entrySet()) {\n+        for (Map.Entry<Node, Map<TopicPartition, ListOffsetsRequestData.ListOffsetsPartition>> entry : timestampsToSearchByNode.entrySet()) {\n             Node node = entry.getKey();\n-            final Map<TopicPartition, ListOffsetsPartition> resetTimestamps = entry.getValue();\n+            final Map<TopicPartition, ListOffsetsRequestData.ListOffsetsPartition> resetTimestamps = entry.getValue();", "originalCommit": "3b606da01cf5567a9ab3fd76fc8f223c6200b4a3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxMzkwMQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r551413901", "bodyText": "Can we remove this altogether?", "author": "ijuma", "createdAt": "2021-01-04T16:13:22Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -59,136 +60,140 @@\n  */\n public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n \n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+    public static FetchResponseData.FetchablePartitionResponse partitionResponse(Errors error) {\n+        return new FetchResponseData.FetchablePartitionResponse()\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecordSet(MemoryRecords.EMPTY)\n+                .setPreferredReadReplica(FetchResponse.INVALID_PREFERRED_REPLICA_ID);\n+    }\n+\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> partitionData;\n+    // lazily instantiate this field\n+    private LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap = null;", "originalCommit": "3b606da01cf5567a9ab3fd76fc8f223c6200b4a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ0MTc4Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r551441782", "bodyText": "partitionData can be removed but responseDataMap is still a response type and it is used by production code. I did not refactor that to avoid big patch.", "author": "chia7712", "createdAt": "2021-01-04T16:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxMzkwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjA0Mzc2Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r552043767", "bodyText": "I understand. It's a bit hard to understand the end state for this class as it stands. We've taken a few intermediate steps to this point. Can we just go to the end state now?", "author": "ijuma", "createdAt": "2021-01-05T16:28:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxMzkwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjA1MzAwMw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r552053003", "bodyText": "You are right. Will address it in next commit.", "author": "chia7712", "createdAt": "2021-01-05T16:42:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxMzkwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxNDk5Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r551414992", "bodyText": "Do we need this class? What does it add over FetchResponseData.FetchablePartitionRespons?", "author": "ijuma", "createdAt": "2021-01-04T16:14:57Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -59,136 +60,140 @@\n  */\n public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n \n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+    public static FetchResponseData.FetchablePartitionResponse partitionResponse(Errors error) {\n+        return new FetchResponseData.FetchablePartitionResponse()\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecordSet(MemoryRecords.EMPTY)\n+                .setPreferredReadReplica(FetchResponse.INVALID_PREFERRED_REPLICA_ID);\n+    }\n+\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> partitionData;\n+    // lazily instantiate this field\n+    private LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap = null;\n \n     @Override\n     public FetchResponseData data() {\n         return data;\n     }\n \n-    public static final class AbortedTransaction {\n-        public final long producerId;\n-        public final long firstOffset;\n+    /**\n+     * From version 3 or later, the entries in `responseData` should be in the same order as the entries in\n+     * `FetchRequest.fetchData`.\n+     *\n+     * @param error             The top-level error code.\n+     * @param responseData      The fetched data grouped by partition.\n+     * @param throttleTimeMs    The time in milliseconds that the response was throttled\n+     * @param sessionId         The fetch session id.\n+     */\n+    public FetchResponse(Errors error,\n+                         LinkedHashMap<TopicPartition, PartitionData<T>> responseData,\n+                         int throttleTimeMs,\n+                         int sessionId) {\n+        this(error, throttleTimeMs, sessionId, responseData.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+            entry -> entry.getValue().partitionResponse, (o1, o2) -> {\n+                throw new RuntimeException(\"this is impossible\");\n+            }, LinkedHashMap::new)));\n+    }\n \n-        public AbortedTransaction(long producerId, long firstOffset) {\n-            this.producerId = producerId;\n-            this.firstOffset = firstOffset;\n-        }\n+    public FetchResponse(Errors error,\n+                         int throttleTimeMs,\n+                         int sessionId,\n+                         LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData) {\n+        super(ApiKeys.FETCH);\n+        this.data = new FetchResponseData()\n+                .setSessionId(sessionId)\n+                .setErrorCode(error.code())\n+                .setThrottleTimeMs(throttleTimeMs);\n+        responseData.forEach((tp, tpData) -> data.responses().add(new FetchResponseData.FetchableTopicResponse()\n+            .setTopic(tp.topic())\n+            .setPartitionResponses(Collections.singletonList(tpData.setPartition(tp.partition())))));\n+        this.partitionData = responseData;\n+    }\n \n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n+    public FetchResponse(FetchResponseData fetchResponseData) {\n+        super(ApiKeys.FETCH);\n+        this.data = fetchResponseData;\n+        this.partitionData = new LinkedHashMap<>();\n+        fetchResponseData.responses().forEach(topicResponse ->\n+            topicResponse.partitionResponses().forEach(partitionResponse ->\n+                partitionData.put(new TopicPartition(topicResponse.topic(), partitionResponse.partition()), partitionResponse))\n+        );\n+    }\n \n-            AbortedTransaction that = (AbortedTransaction) o;\n+    public Errors error() {\n+        return Errors.forCode(data.errorCode());\n+    }\n \n-            return producerId == that.producerId && firstOffset == that.firstOffset;\n+    public LinkedHashMap<TopicPartition, PartitionData<T>> responseData() {\n+        if (responseDataMap == null) {\n+            responseDataMap = new LinkedHashMap<>(partitionData.size());\n+            partitionData.forEach((tp, d) -> responseDataMap.put(tp, new PartitionData<>(d)));\n         }\n+        return responseDataMap;\n+    }\n \n-        @Override\n-        public int hashCode() {\n-            int result = Long.hashCode(producerId);\n-            result = 31 * result + Long.hashCode(firstOffset);\n-            return result;\n-        }\n+    @Override\n+    public int throttleTimeMs() {\n+        return data.throttleTimeMs();\n+    }\n \n-        @Override\n-        public String toString() {\n-            return \"(producerId=\" + producerId + \", firstOffset=\" + firstOffset + \")\";\n-        }\n+    public int sessionId() {\n+        return data.sessionId();\n+    }\n \n-        static AbortedTransaction fromMessage(FetchResponseData.AbortedTransaction abortedTransaction) {\n-            return new AbortedTransaction(abortedTransaction.producerId(), abortedTransaction.firstOffset());\n-        }\n+    @Override\n+    public Map<Errors, Integer> errorCounts() {\n+        Map<Errors, Integer> errorCounts = new HashMap<>();\n+        updateErrorCounts(errorCounts, error());\n+        partitionData.values().forEach(response ->\n+            updateErrorCounts(errorCounts, Errors.forCode(response.errorCode()))\n+        );\n+        return errorCounts;\n     }\n \n-    public static final class PartitionData<T extends BaseRecords> {\n-        private final FetchResponseData.FetchablePartitionResponse partitionResponse;\n+    public static FetchResponse<MemoryRecords> parse(ByteBuffer buffer, short version) {\n+        return new FetchResponse<>(new FetchResponseData(new ByteBufferAccessor(buffer), version));\n+    }\n \n-        // Derived fields\n-        private final Optional<Integer> preferredReplica;\n-        private final List<AbortedTransaction> abortedTransactions;\n-        private final Errors error;\n+    /**\n+     * Convenience method to find the size of a response.\n+     *\n+     * @param version       The version of the response to use.\n+     * @param partIterator  The partition iterator.\n+     * @return              The response size in bytes.\n+     */\n+    public static <T extends Records> int sizeOf(short version,\n+                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+        // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n+        // use arbitrary values here without affecting the result.\n+        LinkedHashMap<TopicPartition, PartitionData<T>> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n+        ObjectSerializationCache cache = new ObjectSerializationCache();\n+        return 4 + new FetchResponse<>(Errors.NONE, data, 0, INVALID_SESSION_ID).data.size(cache, version);\n+    }\n \n-        private PartitionData(FetchResponseData.FetchablePartitionResponse partitionResponse) {\n-            // We partially construct FetchablePartitionResponse since we don't know the partition ID at this point\n-            // When we convert the PartitionData (and other fields) into FetchResponseData down in toMessage, we\n-            // set the partition IDs.\n-            this.partitionResponse = partitionResponse;\n-            this.preferredReplica = Optional.of(partitionResponse.preferredReadReplica())\n-                .filter(replicaId -> replicaId != INVALID_PREFERRED_REPLICA_ID);\n-\n-            if (partitionResponse.abortedTransactions() == null) {\n-                this.abortedTransactions = null;\n-            } else {\n-                this.abortedTransactions = partitionResponse.abortedTransactions().stream()\n-                    .map(AbortedTransaction::fromMessage)\n-                    .collect(Collectors.toList());\n-            }\n-\n-            this.error = Errors.forCode(partitionResponse.errorCode());\n-        }\n+    @Override\n+    public boolean shouldClientThrottle(short version) {\n+        return version >= 8;\n+    }\n \n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             Optional<FetchResponseData.EpochEndOffset> divergingEpoch,\n-                             T records) {\n-            this.preferredReplica = preferredReadReplica;\n-            this.abortedTransactions = abortedTransactions;\n-            this.error = error;\n-\n-            FetchResponseData.FetchablePartitionResponse partitionResponse =\n-                new FetchResponseData.FetchablePartitionResponse();\n-            partitionResponse.setErrorCode(error.code())\n-                .setHighWatermark(highWatermark)\n-                .setLastStableOffset(lastStableOffset)\n-                .setLogStartOffset(logStartOffset);\n-            if (abortedTransactions != null) {\n-                partitionResponse.setAbortedTransactions(abortedTransactions.stream().map(\n-                    aborted -> new FetchResponseData.AbortedTransaction()\n-                        .setProducerId(aborted.producerId)\n-                        .setFirstOffset(aborted.firstOffset))\n-                    .collect(Collectors.toList()));\n-            } else {\n-                partitionResponse.setAbortedTransactions(null);\n-            }\n-            partitionResponse.setPreferredReadReplica(preferredReadReplica.orElse(INVALID_PREFERRED_REPLICA_ID));\n-            partitionResponse.setRecordSet(records);\n-            divergingEpoch.ifPresent(partitionResponse::setDivergingEpoch);\n \n-            this.partitionResponse = partitionResponse;\n-        }\n+    public static final class PartitionData<T extends BaseRecords> {", "originalCommit": "3b606da01cf5567a9ab3fd76fc8f223c6200b4a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQ0MTgyMg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r551441822", "bodyText": "What does it add over FetchResponseData.FetchablePartitionRespons?\n\nIt offers methods to transfer \"non-defined value\" to Optional type.", "author": "chia7712", "createdAt": "2021-01-04T16:57:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxNDk5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjA0NzEzOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r552047139", "bodyText": "It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.", "author": "ijuma", "createdAt": "2021-01-05T16:33:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxNDk5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjEyNjM1MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r552126351", "bodyText": "Nice suggestions. will address it.", "author": "chia7712", "createdAt": "2021-01-05T18:51:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTQxNDk5Mg=="}], "type": "inlineReview"}, {"oid": "86da6527bff7fd091ea88af7f7e86f1464daa443", "url": "https://github.com/apache/kafka/commit/86da6527bff7fd091ea88af7f7e86f1464daa443", "message": "remove unnecessary changes and remove partitionData", "committedDate": "2021-01-04T16:46:43Z", "type": "forcePushed"}, {"oid": "1a5def5bfb97d673243203f90cc9e723b3e24915", "url": "https://github.com/apache/kafka/commit/1a5def5bfb97d673243203f90cc9e723b3e24915", "message": "remove PartitionData", "committedDate": "2021-01-05T20:02:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQwMzIzMQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r552403231", "bodyText": "I don't batch the partitions again in this PR as it create a new FetchResponseData.", "author": "chia7712", "createdAt": "2021-01-06T07:02:12Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -304,58 +115,12 @@ public int sessionId() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n         updateErrorCounts(errorCounts, error());\n-        responseDataMap.values().forEach(response ->\n-            updateErrorCounts(errorCounts, response.error())\n-        );\n+        dataByTopicPartition.values().forEach(response -> updateErrorCounts(errorCounts, Errors.forCode(response.errorCode())));\n         return errorCounts;\n     }\n \n-    public static FetchResponse<MemoryRecords> parse(ByteBuffer buffer, short version) {\n-        return new FetchResponse<>(new FetchResponseData(new ByteBufferAccessor(buffer), version));\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    private static <T extends BaseRecords> LinkedHashMap<TopicPartition, PartitionData<T>> toResponseDataMap(\n-            FetchResponseData message) {\n-        LinkedHashMap<TopicPartition, PartitionData<T>> responseMap = new LinkedHashMap<>();\n-        message.responses().forEach(topicResponse -> {\n-            topicResponse.partitionResponses().forEach(partitionResponse -> {\n-                TopicPartition tp = new TopicPartition(topicResponse.topic(), partitionResponse.partition());\n-                PartitionData<T> partitionData = new PartitionData<>(partitionResponse);\n-                responseMap.put(tp, partitionData);\n-            });\n-        });\n-        return responseMap;\n-    }\n-\n-    private static <T extends BaseRecords> FetchResponseData toMessage(int throttleTimeMs, Errors error,", "originalCommit": "1a5def5bfb97d673243203f90cc9e723b3e24915", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjI5Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172292", "bodyText": "Can you clarify what you mean here?", "author": "ijuma", "createdAt": "2021-02-27T18:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQwMzIzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyNTk3Mw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584225973", "bodyText": "Oh, I planed to remove all usages of this method from production (i.e KafkaApis should generate batched response directly). However, it can produce a big patch so I will keep this method in next commit.", "author": "chia7712", "createdAt": "2021-02-28T03:45:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjQwMzIzMQ=="}], "type": "inlineReview"}, {"oid": "665e6c94bc4c0560c2c46a872844d2890425865b", "url": "https://github.com/apache/kafka/commit/665e6c94bc4c0560c2c46a872844d2890425865b", "message": "add isDivergingEpoch and isPreferredReplica", "committedDate": "2021-01-11T14:04:21Z", "type": "forcePushed"}, {"oid": "b3e592f8e22b60e781e3037a266c3d060432a5fb", "url": "https://github.com/apache/kafka/commit/b3e592f8e22b60e781e3037a266c3d060432a5fb", "message": "MINOR: remove FetchResponse.AbortedTransaction and duplicate constructors of PartitionData", "committedDate": "2021-01-13T13:50:26Z", "type": "commit"}, {"oid": "f217bb53ee96972d639a85348dd862f99e529f42", "url": "https://github.com/apache/kafka/commit/f217bb53ee96972d639a85348dd862f99e529f42", "message": "remove unnecessary changes and remove partitionData", "committedDate": "2021-01-13T13:50:26Z", "type": "commit"}, {"oid": "3f219e5951133f791ab0cc546bb33fcbc199a608", "url": "https://github.com/apache/kafka/commit/3f219e5951133f791ab0cc546bb33fcbc199a608", "message": "remove PartitionData", "committedDate": "2021-01-13T13:51:15Z", "type": "commit"}, {"oid": "83a26f0b0b86af15516556f84130a46deb0ea6a9", "url": "https://github.com/apache/kafka/commit/83a26f0b0b86af15516556f84130a46deb0ea6a9", "message": "add isDivergingEpoch and isPreferredReplica", "committedDate": "2021-01-13T13:51:15Z", "type": "commit"}, {"oid": "7c386a0a9504489fd8db5871d84abfef2dff270d", "url": "https://github.com/apache/kafka/commit/7c386a0a9504489fd8db5871d84abfef2dff270d", "message": "remove unused import", "committedDate": "2021-01-13T13:53:24Z", "type": "commit"}, {"oid": "7c386a0a9504489fd8db5871d84abfef2dff270d", "url": "https://github.com/apache/kafka/commit/7c386a0a9504489fd8db5871d84abfef2dff270d", "message": "remove unused import", "committedDate": "2021-01-13T13:53:24Z", "type": "forcePushed"}, {"oid": "c010e4e154931d6474d89d9bee50be1b594dfff3", "url": "https://github.com/apache/kafka/commit/c010e4e154931d6474d89d9bee50be1b594dfff3", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-14T06:16:14Z", "type": "commit"}, {"oid": "30695f8563a2ebb0eb235d35a652d66aac5c42ad", "url": "https://github.com/apache/kafka/commit/30695f8563a2ebb0eb235d35a652d66aac5c42ad", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-15T19:18:48Z", "type": "commit"}, {"oid": "9122aee548963feca3f50fcebd6b59479a1a07aa", "url": "https://github.com/apache/kafka/commit/9122aee548963feca3f50fcebd6b59479a1a07aa", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-16T19:10:53Z", "type": "commit"}, {"oid": "4106d2fab6241bb5bdbb0706681e16f819114f62", "url": "https://github.com/apache/kafka/commit/4106d2fab6241bb5bdbb0706681e16f819114f62", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-18T17:31:14Z", "type": "commit"}, {"oid": "d97de8ac517e40c4981c2e33a50e547c4d9d0ff6", "url": "https://github.com/apache/kafka/commit/d97de8ac517e40c4981c2e33a50e547c4d9d0ff6", "message": "fix checkstyle", "committedDate": "2021-01-18T17:38:10Z", "type": "commit"}, {"oid": "13f7710839530ffa780d84c24099d4cc0f138bbe", "url": "https://github.com/apache/kafka/commit/13f7710839530ffa780d84c24099d4cc0f138bbe", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-18T19:21:18Z", "type": "commit"}, {"oid": "52ab1569ba84f7ea96253c08acc2817fd7cd6a65", "url": "https://github.com/apache/kafka/commit/52ab1569ba84f7ea96253c08acc2817fd7cd6a65", "message": "tweak style", "committedDate": "2021-01-18T19:25:27Z", "type": "commit"}, {"oid": "cb157fe1696414f0840d1ed8c619bda1f2c240a2", "url": "https://github.com/apache/kafka/commit/cb157fe1696414f0840d1ed8c619bda1f2c240a2", "message": "rename dataByTopicPartition to responseData", "committedDate": "2021-01-18T19:30:34Z", "type": "commit"}, {"oid": "9627cd99d569b90868ae436b43bcc9f53d564a79", "url": "https://github.com/apache/kafka/commit/9627cd99d569b90868ae436b43bcc9f53d564a79", "message": "rename recordSet to records", "committedDate": "2021-01-18T19:41:39Z", "type": "commit"}, {"oid": "e15ee0cc6e57ab00a70c0ed099ce86a7ba778d6e", "url": "https://github.com/apache/kafka/commit/e15ee0cc6e57ab00a70c0ed099ce86a7ba778d6e", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-19T10:19:26Z", "type": "commit"}, {"oid": "868ff0ceb01ecbb8313839554c302c48a6d095e7", "url": "https://github.com/apache/kafka/commit/868ff0ceb01ecbb8313839554c302c48a6d095e7", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-19T16:40:01Z", "type": "commit"}, {"oid": "ef45f01869c65f68be019c9f833d3ad2a15a4ba6", "url": "https://github.com/apache/kafka/commit/ef45f01869c65f68be019c9f833d3ad2a15a4ba6", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-21T04:11:38Z", "type": "commit"}, {"oid": "bc5c494c16a750c8624fd6440cc68149550de4be", "url": "https://github.com/apache/kafka/commit/bc5c494c16a750c8624fd6440cc68149550de4be", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-01-27T07:55:25Z", "type": "commit"}, {"oid": "ce991c36425c1941127c69b701c9dc814ddd047e", "url": "https://github.com/apache/kafka/commit/ce991c36425c1941127c69b701c9dc814ddd047e", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-01T07:42:04Z", "type": "commit"}, {"oid": "4a83601ad09c96081fded8cf9118e372fff21938", "url": "https://github.com/apache/kafka/commit/4a83601ad09c96081fded8cf9118e372fff21938", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-02T08:48:00Z", "type": "commit"}, {"oid": "3b55cd7bbb53f221ac2e30e6eaf8689f7a39b09b", "url": "https://github.com/apache/kafka/commit/3b55cd7bbb53f221ac2e30e6eaf8689f7a39b09b", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-12T19:51:05Z", "type": "commit"}, {"oid": "cd1c981d487be38f19ee2b116995650af8c5257f", "url": "https://github.com/apache/kafka/commit/cd1c981d487be38f19ee2b116995650af8c5257f", "message": "fix build", "committedDate": "2021-02-12T19:54:46Z", "type": "commit"}, {"oid": "fbca0494018d96d583bbef4c146d01dd00ca1db6", "url": "https://github.com/apache/kafka/commit/fbca0494018d96d583bbef4c146d01dd00ca1db6", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-17T05:21:06Z", "type": "commit"}, {"oid": "4077553bb23057cd41a80db90998343fa5b1354b", "url": "https://github.com/apache/kafka/commit/4077553bb23057cd41a80db90998343fa5b1354b", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-18T03:25:37Z", "type": "commit"}, {"oid": "d513d855ad7990371d80792255f7c46143726f34", "url": "https://github.com/apache/kafka/commit/d513d855ad7990371d80792255f7c46143726f34", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-20T03:17:01Z", "type": "commit"}, {"oid": "9e17a7eeac81d554a43917a0022ede41e4a8ff5e", "url": "https://github.com/apache/kafka/commit/9e17a7eeac81d554a43917a0022ede41e4a8ff5e", "message": "fix build error", "committedDate": "2021-02-20T03:23:07Z", "type": "commit"}, {"oid": "568d8f56fc0a9c052031d87f4b506c27383442ae", "url": "https://github.com/apache/kafka/commit/568d8f56fc0a9c052031d87f4b506c27383442ae", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-23T10:02:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA0NDU1Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581044552", "bodyText": "FetchablePartitionResponse is a bit long and redundant. Could we find a shorter name for it now that PartitionData is gone?", "author": "ijuma", "createdAt": "2021-02-23T13:43:52Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -290,7 +291,7 @@ public void onSuccess(ClientResponse resp) {\n                             Set<TopicPartition> partitions = new HashSet<>(response.responseData().keySet());\n                             FetchResponseMetricAggregator metricAggregator = new FetchResponseMetricAggregator(sensors, partitions);\n \n-                            for (Map.Entry<TopicPartition, FetchResponse.PartitionData<Records>> entry : response.responseData().entrySet()) {\n+                            for (Map.Entry<TopicPartition, FetchResponseData.FetchablePartitionResponse> entry : response.responseData().entrySet()) {", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA4ODY4MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581088681", "bodyText": "sure. I reuse the name PartitionData", "author": "chia7712", "createdAt": "2021-02-23T14:37:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA0NDU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA1NDAzOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581054038", "bodyText": "Could we encapsulate this cast in a utility method?", "author": "ijuma", "createdAt": "2021-02-23T13:56:24Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java", "diffHunk": "@@ -1257,7 +1259,7 @@ private CompletedFetch initializeCompletedFetch(CompletedFetch nextCompletedFetc\n \n                 log.trace(\"Preparing to read {} bytes of data for partition {} with offset {}\",\n                         partition.records().sizeInBytes(), tp, position);\n-                Iterator<? extends RecordBatch> batches = partition.records().batches().iterator();\n+                Iterator<? extends RecordBatch> batches = ((Records) partition.records()).batches().iterator();", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA1ODE2Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581058162", "bodyText": "Maybe we can remove the defaults from this and every other place where we build FetchablePartitionResponse", "author": "ijuma", "createdAt": "2021-02-23T14:01:46Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetchsession/FetchSessionBenchmark.java", "diffHunk": "@@ -70,24 +70,26 @@ public void setUp() {\n         handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n         FetchSessionHandler.Builder builder = handler.newBuilder();\n \n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> respMap = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> respMap = new LinkedHashMap<>();\n         for (int i = 0; i < partitionCount; i++) {\n             TopicPartition tp = new TopicPartition(\"foo\", i);\n             FetchRequest.PartitionData partitionData = new FetchRequest.PartitionData(0, 0, 200,\n                     Optional.empty());\n             fetches.put(tp, partitionData);\n             builder.add(tp, partitionData);\n-            respMap.put(tp, new FetchResponse.PartitionData<>(\n-                    Errors.NONE,\n-                    0L,\n-                    0L,\n-                    0,\n-                    null,\n-                    null));\n+            respMap.put(tp, new FetchResponseData.FetchablePartitionResponse()\n+                            .setPartition(tp.partition())\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(0)\n+                            .setLastStableOffset(0)\n+                            .setLogStartOffset(0)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(null)\n+                            .setPreferredReadReplica(FetchResponse.INVALID_PREFERRED_REPLICA_ID));", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA2NDY2OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581064669", "bodyText": "I think it would be better to make this a static factory method and keep the constructor for the case where we receive FetchResponseData.", "author": "ijuma", "createdAt": "2021-02-23T14:09:15Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +55,51 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData;\n \n     @Override\n     public FetchResponseData data() {\n         return data;\n     }\n \n-    public static final class AbortedTransaction {\n-        public final long producerId;\n-        public final long firstOffset;\n-\n-        public AbortedTransaction(long producerId, long firstOffset) {\n-            this.producerId = producerId;\n-            this.firstOffset = firstOffset;\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            AbortedTransaction that = (AbortedTransaction) o;\n-\n-            return producerId == that.producerId && firstOffset == that.firstOffset;\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            int result = Long.hashCode(producerId);\n-            result = 31 * result + Long.hashCode(firstOffset);\n-            return result;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(producerId=\" + producerId + \", firstOffset=\" + firstOffset + \")\";\n-        }\n-\n-        static AbortedTransaction fromMessage(FetchResponseData.AbortedTransaction abortedTransaction) {\n-            return new AbortedTransaction(abortedTransaction.producerId(), abortedTransaction.firstOffset());\n-        }\n-    }\n-\n-    public static final class PartitionData<T extends BaseRecords> {\n-        private final FetchResponseData.FetchablePartitionResponse partitionResponse;\n-\n-        // Derived fields\n-        private final Optional<Integer> preferredReplica;\n-        private final List<AbortedTransaction> abortedTransactions;\n-        private final Errors error;\n-\n-        private PartitionData(FetchResponseData.FetchablePartitionResponse partitionResponse) {\n-            // We partially construct FetchablePartitionResponse since we don't know the partition ID at this point\n-            // When we convert the PartitionData (and other fields) into FetchResponseData down in toMessage, we\n-            // set the partition IDs.\n-            this.partitionResponse = partitionResponse;\n-            this.preferredReplica = Optional.of(partitionResponse.preferredReadReplica())\n-                .filter(replicaId -> replicaId != INVALID_PREFERRED_REPLICA_ID);\n-\n-            if (partitionResponse.abortedTransactions() == null) {\n-                this.abortedTransactions = null;\n-            } else {\n-                this.abortedTransactions = partitionResponse.abortedTransactions().stream()\n-                    .map(AbortedTransaction::fromMessage)\n-                    .collect(Collectors.toList());\n-            }\n-\n-            this.error = Errors.forCode(partitionResponse.errorCode());\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             Optional<FetchResponseData.EpochEndOffset> divergingEpoch,\n-                             T records) {\n-            this.preferredReplica = preferredReadReplica;\n-            this.abortedTransactions = abortedTransactions;\n-            this.error = error;\n-\n-            FetchResponseData.FetchablePartitionResponse partitionResponse =\n-                new FetchResponseData.FetchablePartitionResponse();\n-            partitionResponse.setErrorCode(error.code())\n-                .setHighWatermark(highWatermark)\n-                .setLastStableOffset(lastStableOffset)\n-                .setLogStartOffset(logStartOffset);\n-            if (abortedTransactions != null) {\n-                partitionResponse.setAbortedTransactions(abortedTransactions.stream().map(\n-                    aborted -> new FetchResponseData.AbortedTransaction()\n-                        .setProducerId(aborted.producerId)\n-                        .setFirstOffset(aborted.firstOffset))\n-                    .collect(Collectors.toList()));\n-            } else {\n-                partitionResponse.setAbortedTransactions(null);\n-            }\n-            partitionResponse.setPreferredReadReplica(preferredReadReplica.orElse(INVALID_PREFERRED_REPLICA_ID));\n-            partitionResponse.setRecordSet(records);\n-            divergingEpoch.ifPresent(partitionResponse::setDivergingEpoch);\n-\n-            this.partitionResponse = partitionResponse;\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, preferredReadReplica,\n-                abortedTransactions, Optional.empty(), records);\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, Optional.empty(), abortedTransactions, records);\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            PartitionData that = (PartitionData) o;\n-\n-            return this.partitionResponse.equals(that.partitionResponse);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return this.partitionResponse.hashCode();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(error=\" + error() +\n-                    \", highWaterMark=\" + highWatermark() +\n-                    \", lastStableOffset = \" + lastStableOffset() +\n-                    \", logStartOffset = \" + logStartOffset() +\n-                    \", preferredReadReplica = \" + preferredReadReplica().map(Object::toString).orElse(\"absent\") +\n-                    \", abortedTransactions = \" + abortedTransactions() +\n-                    \", divergingEpoch =\" + divergingEpoch() +\n-                    \", recordsSizeInBytes=\" + records().sizeInBytes() + \")\";\n-        }\n-\n-        public Errors error() {\n-            return error;\n-        }\n-\n-        public long highWatermark() {\n-            return partitionResponse.highWatermark();\n-        }\n-\n-        public long lastStableOffset() {\n-            return partitionResponse.lastStableOffset();\n-        }\n-\n-        public long logStartOffset() {\n-            return partitionResponse.logStartOffset();\n-        }\n-\n-        public Optional<Integer> preferredReadReplica() {\n-            return preferredReplica;\n-        }\n-\n-        public List<AbortedTransaction> abortedTransactions() {\n-            return abortedTransactions;\n-        }\n-\n-        public Optional<FetchResponseData.EpochEndOffset> divergingEpoch() {\n-            FetchResponseData.EpochEndOffset epochEndOffset = partitionResponse.divergingEpoch();\n-            if (epochEndOffset.epoch() < 0) {\n-                return Optional.empty();\n-            } else {\n-                return Optional.of(epochEndOffset);\n-            }\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        public T records() {\n-            return (T) partitionResponse.recordSet();\n-        }\n-    }\n-\n-    /**\n-     * From version 3 or later, the entries in `responseData` should be in the same order as the entries in\n-     * `FetchRequest.fetchData`.\n-     *\n-     * @param error             The top-level error code.\n-     * @param responseData      The fetched data grouped by partition.\n-     * @param throttleTimeMs    The time in milliseconds that the response was throttled\n-     * @param sessionId         The fetch session id.\n-     */\n     public FetchResponse(Errors error,", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTA2OTA3MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r581069071", "bodyText": "This isn't needed when we return a fetch from the broker, right? If this is true, can we remove it from the fetch response and build it on the client when needed?", "author": "ijuma", "createdAt": "2021-02-23T14:14:28Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +55,51 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    private final LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData;\n \n     @Override\n     public FetchResponseData data() {\n         return data;\n     }\n \n-    public static final class AbortedTransaction {\n-        public final long producerId;\n-        public final long firstOffset;\n-\n-        public AbortedTransaction(long producerId, long firstOffset) {\n-            this.producerId = producerId;\n-            this.firstOffset = firstOffset;\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            AbortedTransaction that = (AbortedTransaction) o;\n-\n-            return producerId == that.producerId && firstOffset == that.firstOffset;\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            int result = Long.hashCode(producerId);\n-            result = 31 * result + Long.hashCode(firstOffset);\n-            return result;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(producerId=\" + producerId + \", firstOffset=\" + firstOffset + \")\";\n-        }\n-\n-        static AbortedTransaction fromMessage(FetchResponseData.AbortedTransaction abortedTransaction) {\n-            return new AbortedTransaction(abortedTransaction.producerId(), abortedTransaction.firstOffset());\n-        }\n-    }\n-\n-    public static final class PartitionData<T extends BaseRecords> {\n-        private final FetchResponseData.FetchablePartitionResponse partitionResponse;\n-\n-        // Derived fields\n-        private final Optional<Integer> preferredReplica;\n-        private final List<AbortedTransaction> abortedTransactions;\n-        private final Errors error;\n-\n-        private PartitionData(FetchResponseData.FetchablePartitionResponse partitionResponse) {\n-            // We partially construct FetchablePartitionResponse since we don't know the partition ID at this point\n-            // When we convert the PartitionData (and other fields) into FetchResponseData down in toMessage, we\n-            // set the partition IDs.\n-            this.partitionResponse = partitionResponse;\n-            this.preferredReplica = Optional.of(partitionResponse.preferredReadReplica())\n-                .filter(replicaId -> replicaId != INVALID_PREFERRED_REPLICA_ID);\n-\n-            if (partitionResponse.abortedTransactions() == null) {\n-                this.abortedTransactions = null;\n-            } else {\n-                this.abortedTransactions = partitionResponse.abortedTransactions().stream()\n-                    .map(AbortedTransaction::fromMessage)\n-                    .collect(Collectors.toList());\n-            }\n-\n-            this.error = Errors.forCode(partitionResponse.errorCode());\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             Optional<FetchResponseData.EpochEndOffset> divergingEpoch,\n-                             T records) {\n-            this.preferredReplica = preferredReadReplica;\n-            this.abortedTransactions = abortedTransactions;\n-            this.error = error;\n-\n-            FetchResponseData.FetchablePartitionResponse partitionResponse =\n-                new FetchResponseData.FetchablePartitionResponse();\n-            partitionResponse.setErrorCode(error.code())\n-                .setHighWatermark(highWatermark)\n-                .setLastStableOffset(lastStableOffset)\n-                .setLogStartOffset(logStartOffset);\n-            if (abortedTransactions != null) {\n-                partitionResponse.setAbortedTransactions(abortedTransactions.stream().map(\n-                    aborted -> new FetchResponseData.AbortedTransaction()\n-                        .setProducerId(aborted.producerId)\n-                        .setFirstOffset(aborted.firstOffset))\n-                    .collect(Collectors.toList()));\n-            } else {\n-                partitionResponse.setAbortedTransactions(null);\n-            }\n-            partitionResponse.setPreferredReadReplica(preferredReadReplica.orElse(INVALID_PREFERRED_REPLICA_ID));\n-            partitionResponse.setRecordSet(records);\n-            divergingEpoch.ifPresent(partitionResponse::setDivergingEpoch);\n-\n-            this.partitionResponse = partitionResponse;\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             Optional<Integer> preferredReadReplica,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, preferredReadReplica,\n-                abortedTransactions, Optional.empty(), records);\n-        }\n-\n-        public PartitionData(Errors error,\n-                             long highWatermark,\n-                             long lastStableOffset,\n-                             long logStartOffset,\n-                             List<AbortedTransaction> abortedTransactions,\n-                             T records) {\n-            this(error, highWatermark, lastStableOffset, logStartOffset, Optional.empty(), abortedTransactions, records);\n-        }\n-\n-        @Override\n-        public boolean equals(Object o) {\n-            if (this == o)\n-                return true;\n-            if (o == null || getClass() != o.getClass())\n-                return false;\n-\n-            PartitionData that = (PartitionData) o;\n-\n-            return this.partitionResponse.equals(that.partitionResponse);\n-        }\n-\n-        @Override\n-        public int hashCode() {\n-            return this.partitionResponse.hashCode();\n-        }\n-\n-        @Override\n-        public String toString() {\n-            return \"(error=\" + error() +\n-                    \", highWaterMark=\" + highWatermark() +\n-                    \", lastStableOffset = \" + lastStableOffset() +\n-                    \", logStartOffset = \" + logStartOffset() +\n-                    \", preferredReadReplica = \" + preferredReadReplica().map(Object::toString).orElse(\"absent\") +\n-                    \", abortedTransactions = \" + abortedTransactions() +\n-                    \", divergingEpoch =\" + divergingEpoch() +\n-                    \", recordsSizeInBytes=\" + records().sizeInBytes() + \")\";\n-        }\n-\n-        public Errors error() {\n-            return error;\n-        }\n-\n-        public long highWatermark() {\n-            return partitionResponse.highWatermark();\n-        }\n-\n-        public long lastStableOffset() {\n-            return partitionResponse.lastStableOffset();\n-        }\n-\n-        public long logStartOffset() {\n-            return partitionResponse.logStartOffset();\n-        }\n-\n-        public Optional<Integer> preferredReadReplica() {\n-            return preferredReplica;\n-        }\n-\n-        public List<AbortedTransaction> abortedTransactions() {\n-            return abortedTransactions;\n-        }\n-\n-        public Optional<FetchResponseData.EpochEndOffset> divergingEpoch() {\n-            FetchResponseData.EpochEndOffset epochEndOffset = partitionResponse.divergingEpoch();\n-            if (epochEndOffset.epoch() < 0) {\n-                return Optional.empty();\n-            } else {\n-                return Optional.of(epochEndOffset);\n-            }\n-        }\n-\n-        @SuppressWarnings(\"unchecked\")\n-        public T records() {\n-            return (T) partitionResponse.recordSet();\n-        }\n-    }\n-\n-    /**\n-     * From version 3 or later, the entries in `responseData` should be in the same order as the entries in\n-     * `FetchRequest.fetchData`.\n-     *\n-     * @param error             The top-level error code.\n-     * @param responseData      The fetched data grouped by partition.\n-     * @param throttleTimeMs    The time in milliseconds that the response was throttled\n-     * @param sessionId         The fetch session id.\n-     */\n     public FetchResponse(Errors error,\n-                         LinkedHashMap<TopicPartition, PartitionData<T>> responseData,\n                          int throttleTimeMs,\n-                         int sessionId) {\n-        super(ApiKeys.FETCH);\n-        this.data = toMessage(throttleTimeMs, error, responseData.entrySet().iterator(), sessionId);\n-        this.responseDataMap = responseData;\n+                         int sessionId,\n+                         LinkedHashMap<TopicPartition, FetchResponseData.FetchablePartitionResponse> responseData) {\n+        this(new FetchResponseData()\n+            .setSessionId(sessionId)\n+            .setErrorCode(error.code())\n+            .setThrottleTimeMs(throttleTimeMs)\n+            .setResponses(responseData.entrySet().stream().map(entry -> new FetchResponseData.FetchableTopicResponse()\n+                .setTopic(entry.getKey().topic())\n+                .setPartitionResponses(Collections.singletonList(entry.getValue().setPartition(entry.getKey().partition()))))\n+                .collect(Collectors.toList())));\n     }\n \n     public FetchResponse(FetchResponseData fetchResponseData) {\n         super(ApiKeys.FETCH);\n         this.data = fetchResponseData;\n-        this.responseDataMap = toResponseDataMap(fetchResponseData);\n+        this.responseData = new LinkedHashMap<>();", "originalCommit": "568d8f56fc0a9c052031d87f4b506c27383442ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eddfffd349a34cc26ddc5db284b5526c40f5fcc8", "url": "https://github.com/apache/kafka/commit/eddfffd349a34cc26ddc5db284b5526c40f5fcc8", "message": "rename FetchablePartitionResponse to PartitionData; add helper method to construct FetchResponse; add helper method to cast records", "committedDate": "2021-02-23T15:15:35Z", "type": "commit"}, {"oid": "9b7637645b76d04eed4a606e75580aa8d1c1a2d0", "url": "https://github.com/apache/kafka/commit/9b7637645b76d04eed4a606e75580aa8d1c1a2d0", "message": "rename index to partitionIndex", "committedDate": "2021-02-23T15:29:46Z", "type": "commit"}, {"oid": "7d5a5a3800ebf01665fe97c935428fb2e0ec2601", "url": "https://github.com/apache/kafka/commit/7d5a5a3800ebf01665fe97c935428fb2e0ec2601", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-25T15:36:24Z", "type": "commit"}, {"oid": "a4edde39d57282bb0acb018ff3eb91a5cf1321e8", "url": "https://github.com/apache/kafka/commit/a4edde39d57282bb0acb018ff3eb91a5cf1321e8", "message": "fix broken build", "committedDate": "2021-02-25T15:42:50Z", "type": "commit"}, {"oid": "b929215cae4ebcfb5e104d4d387c9c48b507fdf1", "url": "https://github.com/apache/kafka/commit/b929215cae4ebcfb5e104d4d387c9c48b507fdf1", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-26T04:07:38Z", "type": "commit"}, {"oid": "e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "url": "https://github.com/apache/kafka/commit/e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-02-27T15:20:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584141887", "bodyText": "This is not thread-safe and requests are typically thread-safe. What's the thinking here?", "author": "ijuma", "createdAt": "2021-02-27T15:32:17Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -57,238 +56,39 @@\n  *     the fetch offset after the index lookup\n  * - {@link Errors#UNKNOWN_SERVER_ERROR} For any unexpected errors\n  */\n-public class FetchResponse<T extends BaseRecords> extends AbstractResponse {\n-\n-    public static final long INVALID_HIGHWATERMARK = -1L;\n+public class FetchResponse extends AbstractResponse {\n+    public static final long INVALID_HIGH_WATERMARK = -1L;\n     public static final long INVALID_LAST_STABLE_OFFSET = -1L;\n     public static final long INVALID_LOG_START_OFFSET = -1L;\n     public static final int INVALID_PREFERRED_REPLICA_ID = -1;\n \n     private final FetchResponseData data;\n-    private final LinkedHashMap<TopicPartition, PartitionData<T>> responseDataMap;\n+    // we build responseData when needed.\n+    private LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = null;", "originalCommit": "e6e1478661e398fb813c8ca77f9d25bc5bd37d86", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MjA3NA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584142074", "bodyText": "Looks like this method is used only Fetcher.sendFetches outside of tests, benchmaks, etc.. Also once in errorCounts, but we can change that code. Maybe we can remove this altogether. Thoughts?", "author": "ijuma", "createdAt": "2021-02-27T15:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MjE4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584142186", "bodyText": "I think I would move the method to a test utility so that tests can use that instead.", "author": "ijuma", "createdAt": "2021-02-27T15:35:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0ODgxNw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584148817", "bodyText": "It is used by FetchSessionHandler also. I prefer to rewrite that code by another PR to avoid big patch :(\nIt seems to me using synchronization block can resolve the thread issue. Also, I will file a jira as follow-up. WDYT?", "author": "chia7712", "createdAt": "2021-02-27T15:58:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE1MTcxNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584151716", "bodyText": "Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.", "author": "ijuma", "createdAt": "2021-02-27T16:18:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE2NTAzMw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584165033", "bodyText": "jira: https://issues.apache.org/jira/browse/KAFKA-12385\n\nyou can use a volatile field and synchronize on the assignment if still null.\n\nupdated", "author": "chia7712", "createdAt": "2021-02-27T17:40:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE0MTg4Nw=="}], "type": "inlineReview"}, {"oid": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "url": "https://github.com/apache/kafka/commit/ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "message": "make FetchResponse thread-safe", "committedDate": "2021-02-27T17:40:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjE3Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172177", "bodyText": "Can we update this not to use responseData? Then we at least have the right behavior for the broker and we can fix the clients in the subsequent PR.", "author": "ijuma", "createdAt": "2021-02-27T18:30:35Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -304,58 +108,12 @@ public int sessionId() {\n     public Map<Errors, Integer> errorCounts() {\n         Map<Errors, Integer> errorCounts = new HashMap<>();\n         updateErrorCounts(errorCounts, error());\n-        responseDataMap.values().forEach(response ->\n-            updateErrorCounts(errorCounts, response.error())\n-        );\n+        responseData().values().forEach(response -> updateErrorCounts(errorCounts, Errors.forCode(response.errorCode())));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjQ0NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172445", "bodyText": "Aren't many of these set automatically by the generated classes?", "author": "ijuma", "createdAt": "2021-02-27T18:33:25Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +123,70 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+                .setPartitionIndex(partition)\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY);", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMTY2MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584221661", "bodyText": "you are right. Except for HighWatermark, other args have default value. remove duplicate assignment!", "author": "chia7712", "createdAt": "2021-02-28T02:50:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjUzMA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172530", "bodyText": "Does this ever fail? If so, it would be good to explain under which conditions it can fail. Also \"This is used to eliminate duplicate code of type casting.\" seems a bit redundant.", "author": "ijuma", "createdAt": "2021-02-27T18:34:16Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +123,70 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+                .setPartitionIndex(partition)\n+                .setErrorCode(error.code())\n+                .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. This is used to eliminate duplicate code of type casting.", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMTAzNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584221036", "bodyText": "the data from KRPC always use MemoryRecords so it should never fail if the data is from KRPC. I will add more comments for this case.", "author": "chia7712", "createdAt": "2021-02-28T02:43:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjUzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjYwNg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172606", "bodyText": "Nit: indenting seems excessive.", "author": "ijuma", "createdAt": "2021-02-27T18:35:10Z", "path": "clients/src/test/java/org/apache/kafka/clients/FetchSessionHandlerTest.java", "diffHunk": "@@ -150,22 +150,23 @@ private static void assertListEquals(List<TopicPartition> expected, List<TopicPa\n \n     private static final class RespEntry {\n         final TopicPartition part;\n-        final FetchResponse.PartitionData<MemoryRecords> data;\n+        final FetchResponseData.PartitionData data;\n \n         RespEntry(String topic, int partition, long highWatermark, long lastStableOffset) {\n             this.part = new TopicPartition(topic, partition);\n-            this.data = new FetchResponse.PartitionData<>(\n-                Errors.NONE,\n-                highWatermark,\n-                lastStableOffset,\n-                0,\n-                null,\n-                null);\n+\n+            this.data = new FetchResponseData.PartitionData()\n+                        .setErrorCode(Errors.NONE.code())", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MjkzNw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172937", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null))", "author": "ijuma", "createdAt": "2021-02-27T18:37:41Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -2377,14 +2378,19 @@ private ListOffsetsResponse listOffsetsResponse(Map<TopicPartition, Long> partit\n                     builder.append(0L, (\"key-\" + i).getBytes(), (\"value-\" + i).getBytes());\n                 records = builder.build();\n             }\n-            tpResponses.put(partition, new FetchResponse.PartitionData<>(\n-                    Errors.NONE, highWatermark, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                    logStartOffset, null, records));\n+            tpResponses.put(partition,\n+                    new FetchResponseData.PartitionData()\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(highWatermark)\n+                            .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                            .setLogStartOffset(logStartOffset)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(records));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3Mjk4NA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584172984", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null))", "author": "ijuma", "createdAt": "2021-02-27T18:38:01Z", "path": "clients/src/test/java/org/apache/kafka/clients/FetchSessionHandlerTest.java", "diffHunk": "@@ -150,22 +150,23 @@ private static void assertListEquals(List<TopicPartition> expected, List<TopicPa\n \n     private static final class RespEntry {\n         final TopicPartition part;\n-        final FetchResponse.PartitionData<MemoryRecords> data;\n+        final FetchResponseData.PartitionData data;\n \n         RespEntry(String topic, int partition, long highWatermark, long lastStableOffset) {\n             this.part = new TopicPartition(topic, partition);\n-            this.data = new FetchResponse.PartitionData<>(\n-                Errors.NONE,\n-                highWatermark,\n-                lastStableOffset,\n-                0,\n-                null,\n-                null);\n+\n+            this.data = new FetchResponseData.PartitionData()\n+                        .setErrorCode(Errors.NONE.code())\n+                        .setHighWatermark(highWatermark)\n+                        .setLastStableOffset(lastStableOffset)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(null)\n+                        .setRecords(null);", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE3MzE1Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584173156", "bodyText": "Are some of these redundant? (eg setAbortedTransactions(null)). Other examples in the same file.", "author": "ijuma", "createdAt": "2021-02-27T18:39:09Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/internals/FetcherTest.java", "diffHunk": "@@ -1270,13 +1271,24 @@ public void testFetchPositionAfterException() {\n \n         assertEquals(1, fetcher.sendFetches());\n \n-        Map<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> partitions = new LinkedHashMap<>();\n-        partitions.put(tp1, new FetchResponse.PartitionData<>(Errors.NONE, 100,\n-            FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, null, records));\n-        partitions.put(tp0, new FetchResponse.PartitionData<>(Errors.OFFSET_OUT_OF_RANGE, 100,\n-            FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, null, MemoryRecords.EMPTY));\n-        client.prepareResponse(new FetchResponse<>(Errors.NONE, new LinkedHashMap<>(partitions),\n-            0, INVALID_SESSION_ID));\n+\n+        Map<TopicPartition, FetchResponseData.PartitionData> partitions = new LinkedHashMap<>();\n+        partitions.put(tp1, new FetchResponseData.PartitionData()\n+                .setErrorCode(Errors.NONE.code())\n+                .setHighWatermark(100)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(records));\n+        partitions.put(tp0, new FetchResponseData.PartitionData()\n+                .setErrorCode(Errors.OFFSET_OUT_OF_RANGE.code())\n+                .setHighWatermark(100)\n+                .setLastStableOffset(FetchResponse.INVALID_LAST_STABLE_OFFSET)\n+                .setLogStartOffset(FetchResponse.INVALID_LOG_START_OFFSET)\n+                .setAbortedTransactions(null)\n+                .setRecords(MemoryRecords.EMPTY));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjU2NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186565", "bodyText": "We can remove some redundant set calls?", "author": "ijuma", "createdAt": "2021-02-27T20:24:50Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetchsession/FetchSessionBenchmark.java", "diffHunk": "@@ -70,24 +70,25 @@ public void setUp() {\n         handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n         FetchSessionHandler.Builder builder = handler.newBuilder();\n \n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> respMap = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> respMap = new LinkedHashMap<>();\n         for (int i = 0; i < partitionCount; i++) {\n             TopicPartition tp = new TopicPartition(\"foo\", i);\n             FetchRequest.PartitionData partitionData = new FetchRequest.PartitionData(0, 0, 200,\n                     Optional.empty());\n             fetches.put(tp, partitionData);\n             builder.add(tp, partitionData);\n-            respMap.put(tp, new FetchResponse.PartitionData<>(\n-                    Errors.NONE,\n-                    0L,\n-                    0L,\n-                    0,\n-                    null,\n-                    null));\n+            respMap.put(tp, new FetchResponseData.PartitionData()\n+                            .setPartitionIndex(tp.partition())\n+                            .setErrorCode(Errors.NONE.code())\n+                            .setHighWatermark(0)\n+                            .setLastStableOffset(0)\n+                            .setLogStartOffset(0)\n+                            .setAbortedTransactions(null)\n+                            .setRecords(null));", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjQ0OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222449", "bodyText": "updated", "author": "chia7712", "createdAt": "2021-02-28T03:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjU2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjYxOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186619", "bodyText": "We can remove some redundant setters?", "author": "ijuma", "createdAt": "2021-02-27T20:25:10Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetcher/ReplicaFetcherThreadBenchmark.java", "diffHunk": "@@ -174,8 +173,14 @@ public int sizeInBytes() {\n                     return null;\n                 }\n             };\n-            initialFetched.put(tp, new FetchResponse.PartitionData<>(Errors.NONE, 0, 0, 0,\n-                    new LinkedList<>(), fetched));\n+            initialFetched.put(tp, new FetchResponseData.PartitionData()\n+                    .setPartitionIndex(tp.partition())\n+                    .setErrorCode(Errors.NONE.code())\n+                    .setHighWatermark(0)\n+                    .setLastStableOffset(0)\n+                    .setLogStartOffset(0)", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjE4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222186", "bodyText": "I will remove redundant setter setHighWatermark(0). Other values are different from default value in KRPC.", "author": "chia7712", "createdAt": "2021-02-28T02:57:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjY4Nw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584186687", "bodyText": "We can remove some redundant setters?", "author": "ijuma", "createdAt": "2021-02-27T20:25:28Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/common/FetchResponseBenchmark.java", "diffHunk": "@@ -78,19 +78,25 @@ public void setup() {\n         for (int topicIdx = 0; topicIdx < topicCount; topicIdx++) {\n             String topic = UUID.randomUUID().toString();\n             for (int partitionId = 0; partitionId < partitionCount; partitionId++) {\n-                FetchResponse.PartitionData<MemoryRecords> partitionData = new FetchResponse.PartitionData<>(\n-                    Errors.NONE, 0, 0, 0, Optional.empty(), Collections.emptyList(), records);\n+                FetchResponseData.PartitionData partitionData = new FetchResponseData.PartitionData()\n+                                .setPartitionIndex(partitionId)\n+                                .setErrorCode(Errors.NONE.code())\n+                                .setHighWatermark(0)\n+                                .setLastStableOffset(0)\n+                                .setLogStartOffset(0)", "originalCommit": "ff57d4e58c1fc1389a5e87bf4734fd5ded385ee9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDIyMjQwOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584222409", "bodyText": "updated", "author": "chia7712", "createdAt": "2021-02-28T03:00:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDE4NjY4Nw=="}], "type": "inlineReview"}, {"oid": "0e9e84739ea59f6ad2aaba99f5926bf469adf8a9", "url": "https://github.com/apache/kafka/commit/0e9e84739ea59f6ad2aaba99f5926bf469adf8a9", "message": "remove duplicate assignments; batch data; add more comments", "committedDate": "2021-02-28T04:09:03Z", "type": "commit"}, {"oid": "033b9338f148ed87c22206e08ede12f16d2ead35", "url": "https://github.com/apache/kafka/commit/033b9338f148ed87c22206e08ede12f16d2ead35", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-01T10:41:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxMjU1Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584812552", "bodyText": "Aborted transactions is empty by default.", "author": "ijuma", "createdAt": "2021-03-01T15:36:47Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -791,15 +791,18 @@ public void produceRequestGetErrorResponseTest() {\n \n     @Test\n     public void fetchResponseVersionTest() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n \n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(\n-                Errors.NONE, 1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> v0Response = new FetchResponse<>(Errors.NONE, responseData, 0, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> v1Response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n+        responseData.put(new TopicPartition(\"test\", 0),\n+                new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxNTI4OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584815289", "bodyText": "Do we need to set the partition id here? There are a few other cases in this file that are similar.", "author": "ijuma", "createdAt": "2021-03-01T15:39:13Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -808,22 +811,32 @@ public void fetchResponseVersionTest() {\n \n     @Test\n     public void testFetchResponseV4() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n \n-        List<FetchResponse.AbortedTransaction> abortedTransactions = asList(\n-                new FetchResponse.AbortedTransaction(10, 100),\n-                new FetchResponse.AbortedTransaction(15, 50)\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = asList(\n+                new FetchResponseData.AbortedTransaction().setProducerId(10).setFirstOffset(100),\n+                new FetchResponseData.AbortedTransaction().setProducerId(15).setFirstOffset(50)\n         );\n-        responseData.put(new TopicPartition(\"bar\", 0), new FetchResponse.PartitionData<>(Errors.NONE, 100000,\n-                FetchResponse.INVALID_LAST_STABLE_OFFSET, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), abortedTransactions, records));\n-        responseData.put(new TopicPartition(\"bar\", 1), new FetchResponse.PartitionData<>(Errors.NONE, 900000,\n-                5, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), null, records));\n-        responseData.put(new TopicPartition(\"foo\", 0), new FetchResponse.PartitionData<>(Errors.NONE, 70000,\n-                6, FetchResponse.INVALID_LOG_START_OFFSET, Optional.empty(), emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> deserialized = FetchResponse.parse(response.serialize((short) 4), (short) 4);\n+        responseData.put(new TopicPartition(\"bar\", 0),\n+                new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setAbortedTransactions(abortedTransactions)\n+                        .setRecords(records));\n+        responseData.put(new TopicPartition(\"bar\", 1),\n+                new FetchResponseData.PartitionData()", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxNzQ5Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584817492", "bodyText": "No need to set aborted transactions.", "author": "ijuma", "createdAt": "2021-03-01T15:40:40Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1159,47 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgxODk0Mw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584818943", "bodyText": "Aborted transactions is empty by default.", "author": "ijuma", "createdAt": "2021-03-01T15:41:34Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1159,47 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgyNjUxOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584826519", "bodyText": "Redundant.", "author": "ijuma", "createdAt": "2021-03-01T15:46:18Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/common/FetchResponseBenchmark.java", "diffHunk": "@@ -78,19 +78,23 @@ public void setup() {\n         for (int topicIdx = 0; topicIdx < topicCount; topicIdx++) {\n             String topic = UUID.randomUUID().toString();\n             for (int partitionId = 0; partitionId < partitionCount; partitionId++) {\n-                FetchResponse.PartitionData<MemoryRecords> partitionData = new FetchResponse.PartitionData<>(\n-                    Errors.NONE, 0, 0, 0, Optional.empty(), Collections.emptyList(), records);\n+                FetchResponseData.PartitionData partitionData = new FetchResponseData.PartitionData()\n+                                .setPartitionIndex(partitionId)\n+                                .setLastStableOffset(0)\n+                                .setLogStartOffset(0)\n+                                .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgyNjg3Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584826872", "bodyText": "Redundant.", "author": "ijuma", "createdAt": "2021-03-01T15:46:31Z", "path": "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/fetcher/ReplicaFetcherThreadBenchmark.java", "diffHunk": "@@ -174,8 +173,12 @@ public int sizeInBytes() {\n                     return null;\n                 }\n             };\n-            initialFetched.put(tp, new FetchResponse.PartitionData<>(Errors.NONE, 0, 0, 0,\n-                    new LinkedList<>(), fetched));\n+            initialFetched.put(tp, new FetchResponseData.PartitionData()\n+                    .setPartitionIndex(tp.partition())\n+                    .setLastStableOffset(0)\n+                    .setLogStartOffset(0)\n+                    .setAbortedTransactions(Collections.emptyList())", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgzNjEwOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584836108", "bodyText": "There is one place in this PR that we check for null when computing the records size, maybe we can use this utility function there.", "author": "ijuma", "createdAt": "2021-03-01T15:57:20Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIzNTU4Ng==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585235586", "bodyText": "good point. will copy that", "author": "chia7712", "createdAt": "2021-03-02T04:15:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDgzNjEwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTIxNA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584841214", "bodyText": "Suggestion:\nReturns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n\nIf this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire).", "author": "ijuma", "createdAt": "2021-03-01T16:03:25Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIyNjY2Mw==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585226663", "bodyText": "good one. will copy that", "author": "chia7712", "createdAt": "2021-03-02T03:46:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTYxNQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r584841615", "bodyText": "Instead of casting blindly, can we include a reasonable error message if the cast fails?", "author": "ijuma", "createdAt": "2021-03-01T16:03:57Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,92 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * cast the BaseRecords of PartitionData to Records. KRPC converts the byte array to MemoryRecords so this method\n+     * never fail if the data is from KRPC.\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {\n+        return partition.records() == null ? MemoryRecords.EMPTY : (Records) partition.records();", "originalCommit": "033b9338f148ed87c22206e08ede12f16d2ead35", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTIyOTg2MA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585229860", "bodyText": "will copy that", "author": "chia7712", "createdAt": "2021-03-02T03:56:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NDg0MTYxNQ=="}], "type": "inlineReview"}, {"oid": "8263bda330b3736447900a86728e779699eaeaf8", "url": "https://github.com/apache/kafka/commit/8263bda330b3736447900a86728e779699eaeaf8", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-02T03:14:56Z", "type": "commit"}, {"oid": "529d81df199555611e7721753ba2ea29cbef3880", "url": "https://github.com/apache/kafka/commit/529d81df199555611e7721753ba2ea29cbef3880", "message": "remove redundant code; add more comment for casting; use helper method to get records size", "committedDate": "2021-03-02T04:17:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585656111", "bodyText": "No else needed since we used return for both other cases. For the exception, I think we can just throw ClassCastException since IllegalStateException doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more Records subtypes. For example:\n\"The record type is \" + partition.records().getClass().getSimpleName() + \", which is not a subtype of \" +\nRecords.class.getSimpleName() + \". This method is only safe to call if the `FetchResponse` was\ndeserialized from bytes.\"", "author": "ijuma", "createdAt": "2021-03-02T15:21:38Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,98 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));\n         ObjectSerializationCache cache = new ObjectSerializationCache();\n-        return 4 + data.size(cache, version);\n+        return 4 + FetchResponse.of(Errors.NONE, 0, INVALID_SESSION_ID, data).data.size(cache, version);\n     }\n \n     @Override\n     public boolean shouldClientThrottle(short version) {\n         return version >= 8;\n     }\n-}\n+\n+    public static Optional<FetchResponseData.EpochEndOffset> divergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() < 0 ? Optional.empty()\n+                : Optional.of(partitionResponse.divergingEpoch());\n+    }\n+\n+    public static boolean isDivergingEpoch(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.divergingEpoch().epoch() >= 0;\n+    }\n+\n+    public static Optional<Integer> preferredReadReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() == INVALID_PREFERRED_REPLICA_ID ? Optional.empty()\n+                : Optional.of(partitionResponse.preferredReadReplica());\n+    }\n+\n+    public static boolean isPreferredReplica(FetchResponseData.PartitionData partitionResponse) {\n+        return partitionResponse.preferredReadReplica() != INVALID_PREFERRED_REPLICA_ID;\n+    }\n+\n+    public static FetchResponseData.PartitionData partitionResponse(int partition, Errors error) {\n+        return new FetchResponseData.PartitionData()\n+            .setPartitionIndex(partition)\n+            .setErrorCode(error.code())\n+            .setHighWatermark(FetchResponse.INVALID_HIGH_WATERMARK);\n+    }\n+\n+    /**\n+     * Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`.\n+     *\n+     * If this response was deserialized after a fetch, this method should never fail. An example where this would\n+     * fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and\n+     * sent on the wire).\n+     *\n+     * @param partition partition data\n+     * @return Records or empty record if the records in PartitionData is null.\n+     */\n+    public static Records records(FetchResponseData.PartitionData partition) {\n+        if (partition.records() == null) return MemoryRecords.EMPTY;\n+        else if (partition.records() instanceof Records) return (Records) partition.records();\n+        else throw new IllegalStateException(\"the record type is \" + partition.records().getClass().getSimpleName() +", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY2MDk2Mg==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585660962", "bodyText": "One more thing, let's call this recordsOrFail to make it clear that the operation is not necessarily safe.", "author": "ijuma", "createdAt": "2021-03-02T15:26:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY3NDQyMA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585674420", "bodyText": "Will address those nice comments", "author": "chia7712", "createdAt": "2021-03-02T15:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NjExMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1Njc5MQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585656791", "bodyText": "Set partition id.", "author": "ijuma", "createdAt": "2021-03-02T15:22:21Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -791,15 +791,17 @@ public void produceRequestGetErrorResponseTest() {\n \n     @Test\n     public void fetchResponseVersionTest() {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n \n         MemoryRecords records = MemoryRecords.readableRecords(ByteBuffer.allocate(10));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(\n-                Errors.NONE, 1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET,\n-                0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        FetchResponse<MemoryRecords> v0Response = new FetchResponse<>(Errors.NONE, responseData, 0, INVALID_SESSION_ID);\n-        FetchResponse<MemoryRecords> v1Response = new FetchResponse<>(Errors.NONE, responseData, 10, INVALID_SESSION_ID);\n+        responseData.put(new TopicPartition(\"test\", 0),\n+                new FetchResponseData.PartitionData()", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzExOQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657119", "bodyText": "Set partition id.", "author": "ijuma", "createdAt": "2021-03-02T15:22:43Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzI3OQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657279", "bodyText": "Set partition id.", "author": "ijuma", "createdAt": "2021-03-02T15:22:52Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1NzU1NQ==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657555", "bodyText": "Set partition id.", "author": "ijuma", "createdAt": "2021-03-02T15:23:08Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTY1Nzc2OA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r585657768", "bodyText": "Set partition id.", "author": "ijuma", "createdAt": "2021-03-02T15:23:20Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -1146,38 +1160,45 @@ private FetchRequest createFetchRequest(int version) {\n         return FetchRequest.Builder.forConsumer(100, 100000, fetchData).setMaxBytes(1000).build((short) version);\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(Errors error, int sessionId) {\n-        return new FetchResponse<>(error, new LinkedHashMap<>(), 25, sessionId);\n+    private FetchResponse createFetchResponse(Errors error, int sessionId) {\n+        return FetchResponse.of(error, 25, sessionId, new LinkedHashMap<>());\n     }\n \n-    private FetchResponse<MemoryRecords> createFetchResponse(int sessionId) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+    private FetchResponse createFetchResponse(int sessionId) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.singletonList(\n-            new FetchResponse.AbortedTransaction(234L, 999L));\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-            1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n-        return new FetchResponse<>(Errors.NONE, responseData, 25, sessionId);\n-    }\n-\n-    private FetchResponse<MemoryRecords> createFetchResponse(boolean includeAborted) {\n-        LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.singletonList(\n+            new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setAbortedTransactions(abortedTransactions));\n+        return FetchResponse.of(Errors.NONE, 25, sessionId, responseData);\n+    }\n+\n+    private FetchResponse createFetchResponse(boolean includeAborted) {\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> responseData = new LinkedHashMap<>();\n         MemoryRecords records = MemoryRecords.withRecords(CompressionType.NONE, new SimpleRecord(\"blah\".getBytes()));\n+        responseData.put(new TopicPartition(\"test\", 0), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)\n+                        .setLogStartOffset(0)\n+                        .setRecords(records));\n \n-        responseData.put(new TopicPartition(\"test\", 0), new FetchResponse.PartitionData<>(Errors.NONE,\n-                1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), Collections.emptyList(), records));\n-\n-        List<FetchResponse.AbortedTransaction> abortedTransactions = Collections.emptyList();\n+        List<FetchResponseData.AbortedTransaction> abortedTransactions = Collections.emptyList();\n         if (includeAborted) {\n             abortedTransactions = Collections.singletonList(\n-                    new FetchResponse.AbortedTransaction(234L, 999L));\n+                    new FetchResponseData.AbortedTransaction().setProducerId(234L).setFirstOffset(999L));\n         }\n-        responseData.put(new TopicPartition(\"test\", 1), new FetchResponse.PartitionData<>(Errors.NONE,\n-                1000000, FetchResponse.INVALID_LAST_STABLE_OFFSET, 0L, Optional.empty(), abortedTransactions, MemoryRecords.EMPTY));\n+        responseData.put(new TopicPartition(\"test\", 1), new FetchResponseData.PartitionData()\n+                        .setHighWatermark(1000000)", "originalCommit": "529d81df199555611e7721753ba2ea29cbef3880", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9f8e97b9822c12c0e56e4bc37a07a48f27993769", "url": "https://github.com/apache/kafka/commit/9f8e97b9822c12c0e56e4bc37a07a48f27993769", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-02T15:32:44Z", "type": "commit"}, {"oid": "4fa69c58ffe3e9a40dbb3556da92ed8a30f23936", "url": "https://github.com/apache/kafka/commit/4fa69c58ffe3e9a40dbb3556da92ed8a30f23936", "message": "fix build error", "committedDate": "2021-03-02T15:37:19Z", "type": "commit"}, {"oid": "55b35ab5764d8129e23f386229eb350603b7b0aa", "url": "https://github.com/apache/kafka/commit/55b35ab5764d8129e23f386229eb350603b7b0aa", "message": "set partition index; add recordsSize;", "committedDate": "2021-03-02T16:22:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzE5MTAwOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r587191008", "bodyText": "Is this an additional copy compared to previous behavior?", "author": "ijuma", "createdAt": "2021-03-04T06:33:33Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchResponse.java", "diffHunk": "@@ -365,17 +126,105 @@ public int sessionId() {\n      * @param partIterator  The partition iterator.\n      * @return              The response size in bytes.\n      */\n-    public static <T extends BaseRecords> int sizeOf(short version,\n-                                                     Iterator<Map.Entry<TopicPartition, PartitionData<T>>> partIterator) {\n+    public static int sizeOf(short version,\n+                             Iterator<Map.Entry<TopicPartition, FetchResponseData.PartitionData>> partIterator) {\n         // Since the throttleTimeMs and metadata field sizes are constant and fixed, we can\n         // use arbitrary values here without affecting the result.\n-        FetchResponseData data = toMessage(0, Errors.NONE, partIterator, INVALID_SESSION_ID);\n+        LinkedHashMap<TopicPartition, FetchResponseData.PartitionData> data = new LinkedHashMap<>();\n+        partIterator.forEachRemaining(entry -> data.put(entry.getKey(), entry.getValue()));", "originalCommit": "55b35ab5764d8129e23f386229eb350603b7b0aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzIxNjQxOA==", "url": "https://github.com/apache/kafka/pull/9758#discussion_r587216418", "bodyText": "nice question. will revert to previous code :)", "author": "chia7712", "createdAt": "2021-03-04T07:32:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzE5MTAwOA=="}], "type": "inlineReview"}, {"oid": "821c307389bf613b15c92bd868cdeeac557b39d4", "url": "https://github.com/apache/kafka/commit/821c307389bf613b15c92bd868cdeeac557b39d4", "message": "Merge branch 'trunk' into MINOR-9758", "committedDate": "2021-03-04T07:29:06Z", "type": "commit"}, {"oid": "ae25551171fd4e3b889ca94d494e3207545320e5", "url": "https://github.com/apache/kafka/commit/ae25551171fd4e3b889ca94d494e3207545320e5", "message": "revert sizeOf", "committedDate": "2021-03-04T07:33:05Z", "type": "commit"}]}