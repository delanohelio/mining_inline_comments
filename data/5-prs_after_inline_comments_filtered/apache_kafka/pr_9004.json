{"pr_number": 9004, "pr_title": "KAFKA-10261: Introduce the KIP-478 apis with adapters", "pr_createdAt": "2020-07-09T22:42:23Z", "pr_url": "https://github.com/apache/kafka/pull/9004", "timeline": [{"oid": "082875d7d8de84cda5d2439a9802d6890cc632b1", "url": "https://github.com/apache/kafka/commit/082875d7d8de84cda5d2439a9802d6890cc632b1", "message": "new interfaces", "committedDate": "2020-07-09T22:27:02Z", "type": "commit"}, {"oid": "cbec07f73bb05f7e9f38f021d1b3162421a5e96f", "url": "https://github.com/apache/kafka/commit/cbec07f73bb05f7e9f38f021d1b3162421a5e96f", "message": "convert ProcessorNode (passes)", "committedDate": "2020-07-09T22:27:02Z", "type": "commit"}, {"oid": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "url": "https://github.com/apache/kafka/commit/29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "message": "merge with trunk", "committedDate": "2020-07-09T22:40:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NjA3MA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452586070", "bodyText": "I'll have to update the KIP. Replacing ProcessorContext instead of just adding the generic parameters is going to avoid the Scala compatibility issue we faced last time.", "author": "vvcephei", "createdAt": "2020-07-10T02:16:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.TimestampExtractor;\n+import org.apache.kafka.streams.processor.To;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+/**\n+ * Processor context interface.\n+ *\n+ * @param <KForward>> a bound on the types of keys that may be forwarded\n+ * @param <VForward>> a bound on the types of values that may be forwarded\n+ */\n+public interface ProcessorContext<KForward, VForward> {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTIxNQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460341215", "bodyText": "Sounds good.", "author": "abbccdda", "createdAt": "2020-07-25T00:39:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NjA3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NjQ1MA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452586450", "bodyText": "Since this is a new class, I've dropped the deprecated members. Everything else from the old ProcessorContext is preserved.", "author": "vvcephei", "createdAt": "2020-07-10T02:17:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.TimestampExtractor;\n+import org.apache.kafka.streams.processor.To;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+/**\n+ * Processor context interface.\n+ *\n+ * @param <KForward>> a bound on the types of keys that may be forwarded\n+ * @param <VForward>> a bound on the types of values that may be forwarded\n+ */\n+public interface ProcessorContext<KForward, VForward> {\n+\n+    /**\n+     * Returns the application id.\n+     *\n+     * @return the application id\n+     */\n+    String applicationId();\n+\n+    /**\n+     * Returns the task id.\n+     *\n+     * @return the task id\n+     */\n+    TaskId taskId();\n+\n+    /**\n+     * Returns the default key serde.\n+     *\n+     * @return the key serializer\n+     */\n+    Serde<?> keySerde();\n+\n+    /**\n+     * Returns the default value serde.\n+     *\n+     * @return the value serializer\n+     */\n+    Serde<?> valueSerde();\n+\n+    /**\n+     * Returns the state directory for the partition.\n+     *\n+     * @return the state directory\n+     */\n+    File stateDir();\n+\n+    /**\n+     * Returns Metrics instance.\n+     *\n+     * @return StreamsMetrics\n+     */\n+    StreamsMetrics metrics();\n+\n+    /**\n+     * Registers and possibly restores the specified storage engine.\n+     *\n+     * @param store the storage engine\n+     * @param stateRestoreCallback the restoration callback logic for log-backed state stores upon restart\n+     *\n+     * @throws IllegalStateException If store gets registered after initialized is already finished\n+     * @throws StreamsException if the store's change log does not contain the partition\n+     */\n+    void register(final StateStore store,\n+                  final StateRestoreCallback stateRestoreCallback);\n+\n+    /**\n+     * Get the state store given the store name.\n+     *\n+     * @param name The store name\n+     * @return The state store instance\n+     */\n+    StateStore getStateStore(final String name);\n+\n+    /**\n+     * Schedules a periodic operation for processors. A processor may call this method during\n+     * {@link Processor#init(org.apache.kafka.streams.processor.ProcessorContext) initialization} or\n+     * {@link Processor#process(Object, Object) processing} to\n+     * schedule a periodic callback &mdash; called a punctuation &mdash; to {@link Punctuator#punctuate(long)}.\n+     * The type parameter controls what notion of time is used for punctuation:\n+     * <ul>\n+     *   <li>{@link PunctuationType#STREAM_TIME} &mdash; uses \"stream time\", which is advanced by the processing of messages\n+     *   in accordance with the timestamp as extracted by the {@link TimestampExtractor} in use.\n+     *   The first punctuation will be triggered by the first record that is processed.\n+     *   <b>NOTE:</b> Only advanced if messages arrive</li>\n+     *   <li>{@link PunctuationType#WALL_CLOCK_TIME} &mdash; uses system time (the wall-clock time),\n+     *   which is advanced independent of whether new messages arrive.\n+     *   The first punctuation will be triggered after interval has elapsed.\n+     *   <b>NOTE:</b> This is best effort only as its granularity is limited by how long an iteration of the\n+     *   processing loop takes to complete</li>\n+     * </ul>\n+     *\n+     * <b>Skipping punctuations:</b> Punctuations will not be triggered more than once at any given timestamp.\n+     * This means that \"missed\" punctuation will be skipped.\n+     * It's possible to \"miss\" a punctuation if:\n+     * <ul>\n+     *   <li>with {@link PunctuationType#STREAM_TIME}, when stream time advances more than interval</li>\n+     *   <li>with {@link PunctuationType#WALL_CLOCK_TIME}, on GC pause, too short interval, ...</li>\n+     * </ul>\n+     *\n+     * @param interval the time interval between punctuations (supported minimum is 1 millisecond)\n+     * @param type one of: {@link PunctuationType#STREAM_TIME}, {@link PunctuationType#WALL_CLOCK_TIME}\n+     * @param callback a function consuming timestamps representing the current stream or system time\n+     * @return a handle allowing cancellation of the punctuation schedule established by this method\n+     */\n+    Cancellable schedule(final Duration interval,\n+                         final PunctuationType type,\n+                         final Punctuator callback);\n+\n+    /**\n+     * Forwards a key/value pair to all downstream processors.\n+     * Used the input record's timestamp as timestamp for the output record.\n+     *\n+     * @param key key\n+     * @param value value\n+     */\n+    <K extends KForward, V extends VForward> void forward(final K key, final V value);", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NzE5MA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452587190", "bodyText": "As you're about to find out, this kind of thing is the bulk of the changes.\nSince I've only converted the ProcessorNode (an internal class) in this PR, you'll see the arguments right now are overwhelmingly wildcards and Object. ProcessorNode is almost exclusively used in the \"machine room\" parts of Streams where we don't have access to, or any benefit from, the actual generic type parameters of the Processors.\nIn the follow-on PRs, where I convert the actual Processors to the new API is when we'll start to see the benefits.", "author": "vvcephei", "createdAt": "2020-07-10T02:20:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContext.java", "diffHunk": "@@ -42,7 +42,7 @@\n     private final Serde<?> valueSerde;\n     private boolean initialized;\n     protected ProcessorRecordContext recordContext;\n-    protected ProcessorNode<?, ?> currentNode;\n+    protected ProcessorNode<?, ?, ?, ?> currentNode;", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NzYxMA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452587610", "bodyText": "Oh, just saw this again. The thing I have to fix is the assumption that the child's result arguments are also KIn and VIn.", "author": "vvcephei", "createdAt": "2020-07-10T02:22:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalProcessorContextImpl.java", "diffHunk": "@@ -57,12 +57,12 @@ public StateStore getStateStore(final String name) {\n \n     @SuppressWarnings(\"unchecked\")\n     @Override\n-    public <K, V> void forward(final K key, final V value) {\n-        final ProcessorNode<?, ?> previousNode = currentNode();\n+    public <KIn, VIn> void forward(final KIn key, final VIn value) {\n+        final ProcessorNode<?, ?, ?, ?> previousNode = currentNode();\n         try {\n-            for (final ProcessorNode<?, ?> child : currentNode().children()) {\n+            for (final ProcessorNode<?, ?, ?, ?> child : currentNode().children()) {\n                 setCurrentNode(child);\n-                ((ProcessorNode<K, V>) child).process(key, value);\n+                ((ProcessorNode<KIn, VIn, KIn, VIn>) child).process(key, value); // FIXME", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA1NTMzMQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r462055331", "bodyText": "Could we leave a more clear comment on what needs to be fixed?", "author": "abbccdda", "createdAt": "2020-07-29T05:56:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4NzYxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4Nzk4MQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452587981", "bodyText": "This is the \"InternalProcessorContext\" equivalent for the new ProcessorContext API. It's also identical to the old one, except for the new arguments.\nUnlike the old public APIs, once I finish up the KIP implementation, we'll be able to delete the old InternalProcessorContext, at which point, I'll probably rename this class back to InternalProcessorContext.", "author": "vvcephei", "createdAt": "2020-07-10T02:24:06Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalApiProcessorContext.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.processor.RecordContext;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.internals.Task.TaskType;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.streams.state.internals.ThreadCache.DirtyEntryFlushListener;\n+\n+/**\n+ * For internal use so we can update the {@link RecordContext} and current\n+ * {@link ProcessorNode} when we are forwarding items that have been evicted or flushed from\n+ * {@link ThreadCache}\n+ */\n+public interface InternalApiProcessorContext<KForward, VForward> extends ProcessorContext<KForward, VForward> {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4ODQ3OA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452588478", "bodyText": "This is a shim converting the new internal context back to the old one, so that it can be injected to the old Processor instances, which need the old interface.", "author": "vvcephei", "createdAt": "2020-07-10T02:26:05Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextReverseShim.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.To;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+public final class ProcessorContextReverseShim implements InternalProcessorContext {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjI1NQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460342255", "bodyText": "We are missing the implementation for transitionToActive", "author": "abbccdda", "createdAt": "2020-07-25T00:46:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4ODQ3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3NTA2Mg==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461275062", "bodyText": "Thanks. Maybe it's not in the place you were looking for it. I see it on line 133.", "author": "vvcephei", "createdAt": "2020-07-28T02:10:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4ODQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4ODc2Nw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452588767", "bodyText": "You'll see this block in all the shims. There are times when the internal code would wind up converting new to old and then back to new. This block prevents us from jumping though multiple layers in that case.", "author": "vvcephei", "createdAt": "2020-07-10T02:27:19Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextReverseShim.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.To;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+public final class ProcessorContextReverseShim implements InternalProcessorContext {\n+    final InternalApiProcessorContext<Object, Object> delegate;\n+\n+    static InternalProcessorContext shim(final InternalApiProcessorContext<Object, Object> delegate) {\n+        if (delegate instanceof ProcessorContextShim) {\n+            return ((ProcessorContextShim<Object, Object>) delegate).delegate;", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU4OTE3NQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r452589175", "bodyText": "We also need shims for the processors.", "author": "vvcephei", "createdAt": "2020-07-10T02:28:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorShim.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+\n+public final class ProcessorShim<KIn, VIn, KOut, VOut> implements Processor<KIn, VIn, KOut, VOut> {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTI1MQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460341251", "bodyText": "duplicate >", "author": "abbccdda", "createdAt": "2020-07-25T00:39:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.TimestampExtractor;\n+import org.apache.kafka.streams.processor.To;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+/**\n+ * Processor context interface.\n+ *\n+ * @param <KForward>> a bound on the types of keys that may be forwarded", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjQwMQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460342401", "bodyText": "Seems both serializer are not used.", "author": "abbccdda", "createdAt": "2020-07-25T00:47:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalApiProcessorContext.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.processor.RecordContext;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.internals.Task.TaskType;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.streams.state.internals.ThreadCache.DirtyEntryFlushListener;\n+\n+/**\n+ * For internal use so we can update the {@link RecordContext} and current\n+ * {@link ProcessorNode} when we are forwarding items that have been evicted or flushed from\n+ * {@link ThreadCache}\n+ */\n+public interface InternalApiProcessorContext<KForward, VForward> extends ProcessorContext<KForward, VForward> {\n+    BytesSerializer BYTES_KEY_SERIALIZER = new BytesSerializer();", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3ODc2Nw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461278767", "bodyText": "Good eye :)", "author": "vvcephei", "createdAt": "2020-07-28T02:24:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjQwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjQzNw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460342437", "bodyText": "typo", "author": "abbccdda", "createdAt": "2020-07-25T00:47:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalApiProcessorContext.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.serialization.ByteArraySerializer;\n+import org.apache.kafka.common.serialization.BytesSerializer;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.processor.RecordContext;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.internals.Task.TaskType;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+import org.apache.kafka.streams.state.internals.ThreadCache.DirtyEntryFlushListener;\n+\n+/**\n+ * For internal use so we can update the {@link RecordContext} and current\n+ * {@link ProcessorNode} when we are forwarding items that have been evicted or flushed from\n+ * {@link ThreadCache}\n+ */\n+public interface InternalApiProcessorContext<KForward, VForward> extends ProcessorContext<KForward, VForward> {\n+    BytesSerializer BYTES_KEY_SERIALIZER = new BytesSerializer();\n+    ByteArraySerializer BYTEARRAY_VALUE_SERIALIZER = new ByteArraySerializer();\n+\n+    @Override\n+    StreamsMetricsImpl metrics();\n+\n+    /**\n+     * @param timeMs current wall-clock system timestamp in milliseconds\n+     */\n+    void setSystemTimeMs(long timeMs);\n+\n+    /**\n+     * @retun the current wall-clock system timestamp in milliseconds", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3ODczNw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461278737", "bodyText": "Good eye. I'll also fix it in InternalProcessorContext.", "author": "vvcephei", "createdAt": "2020-07-28T02:24:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjQzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjcxMg==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460342712", "bodyText": "Why do we use Object here instead of ??", "author": "abbccdda", "createdAt": "2020-07-25T00:49:26Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -880,40 +880,41 @@ public synchronized ProcessorTopology buildGlobalStateTopology() {\n         return globalGroups;\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n     private ProcessorTopology build(final Set<String> nodeGroup) {\n         Objects.requireNonNull(applicationId, \"topology has not completed optimization\");\n \n-        final Map<String, ProcessorNode<?, ?>> processorMap = new LinkedHashMap<>();\n-        final Map<String, SourceNode<?, ?>> topicSourceMap = new HashMap<>();\n-        final Map<String, SinkNode<?, ?>> topicSinkMap = new HashMap<>();\n+        final Map<String, ProcessorNode<?, ?, ?, ?>> processorMap = new LinkedHashMap<>();\n+        final Map<String, SourceNode<?, ?, ?, ?>> topicSourceMap = new HashMap<>();\n+        final Map<String, SinkNode<?, ?, ?, ?>> topicSinkMap = new HashMap<>();\n         final Map<String, StateStore> stateStoreMap = new LinkedHashMap<>();\n         final Set<String> repartitionTopics = new HashSet<>();\n \n         // create processor nodes in a topological order (\"nodeFactories\" is already topologically sorted)\n         // also make sure the state store map values following the insertion ordering\n-        for (final NodeFactory<?, ?> factory : nodeFactories.values()) {\n+        for (final NodeFactory<?, ?, ?, ?> factory : nodeFactories.values()) {\n             if (nodeGroup == null || nodeGroup.contains(factory.name)) {\n-                final ProcessorNode<?, ?> node = factory.build();\n+                final ProcessorNode<?, ?, ?, ?> node = factory.build();\n                 processorMap.put(node.name(), node);\n \n                 if (factory instanceof ProcessorNodeFactory) {\n                     buildProcessorNode(processorMap,\n                                        stateStoreMap,\n-                                       (ProcessorNodeFactory<?, ?>) factory,\n-                                       node);\n+                                       (ProcessorNodeFactory<?, ?, ?, ?>) factory,\n+                                       (ProcessorNode<Object, Object, Object, Object>) node);\n \n                 } else if (factory instanceof SourceNodeFactory) {\n                     buildSourceNode(topicSourceMap,\n                                     repartitionTopics,\n-                                    (SourceNodeFactory<?, ?>) factory,\n-                                    (SourceNode<?, ?>) node);\n+                                    (SourceNodeFactory<?, ?, ?, ?>) factory,\n+                                    (SourceNode<?, ?, ?, ?>) node);\n \n                 } else if (factory instanceof SinkNodeFactory) {\n                     buildSinkNode(processorMap,\n                                   topicSinkMap,\n                                   repartitionTopics,\n-                                  (SinkNodeFactory<?, ?>) factory,\n-                                  (SinkNode<?, ?>) node);\n+                                  (SinkNodeFactory<?, ?, ?, ?>) factory,\n+                                  (SinkNode<Object, Object, Object, Object>) node);", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3MTI3Ng==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461271276", "bodyText": "They have subtly different meanings, which I'm not 100% clear on all the time. Usually, the reason I switched to Object because the wildcard makes the type system want to bind the type to something unfortunate, and it can't prove that the usage is actually ok.\nI'm not sure if I had to change this one, of if it was an accident. I'll give it a closer look.", "author": "vvcephei", "createdAt": "2020-07-28T01:56:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjcxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3NzY1Ng==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461277656", "bodyText": "Ah, yes, indeed. It's because inside buildSinkNode, we are calling getProcessor(...).addChild(node), and the type system is unable to prove that the forward types of the parent match the input types of the child, because in this internal layer, we have already lost all the type information of the nodes.\nIt doesn't really matter in the internals anyway (note that this class always just had wildcards/Object as the generic parameters. The real benefit of KIP-478 is for users of the PAPI (including the DSL implementation), not this internal plumbing logic.", "author": "vvcephei", "createdAt": "2020-07-28T02:20:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MjcxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzEzNw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460343137", "bodyText": "As I'm not a native speaker, is it common to the word shim to represent such conversion? I was thinking whether a ProcessorConverter would also do the job, or I'm missing the term meaning here.", "author": "abbccdda", "createdAt": "2020-07-25T00:52:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorShim.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+\n+import org.apache.kafka.streams.processor.api.Processor;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+\n+public final class ProcessorShim<KIn, VIn, KOut, VOut> implements Processor<KIn, VIn, KOut, VOut> {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3MTgyMw==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461271823", "bodyText": "I think \"adapter\" is the standard design pattern name for this type of thing. Not sure why I thought \"shim\" was a good choice in the heat of the moment. Maybe because I'm kind of slipping these classes in the middle to make everything line up? I can change them to \"adapter\".", "author": "vvcephei", "createdAt": "2020-07-28T01:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzI1Ng==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460343256", "bodyText": "nit: breakdown the line", "author": "abbccdda", "createdAt": "2020-07-25T00:53:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorNode.java", "diffHunk": "@@ -57,9 +57,9 @@ public ProcessorNode(final String name) {\n         this(name, null, null);\n     }\n \n-    public ProcessorNode(final String name, final Processor<K, V> processor, final Set<String> stateStores) {\n+    public ProcessorNode(final String name, final org.apache.kafka.streams.processor.Processor<KIn, VIn> processor, final Set<String> stateStores) {", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0Mzk0NA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r460343944", "bodyText": "Why are we removing these checks?", "author": "abbccdda", "createdAt": "2020-07-25T00:58:31Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalProcessorContextImplTest.java", "diffHunk": "@@ -82,20 +79,12 @@ public void setup() {\n             null,\n             null);\n \n-        final ProcessorNode<?, ?> processorNode = mock(ProcessorNode.class);\n-        globalContext.setCurrentNode(processorNode);\n+        final ProcessorNode<Object, Object, Object, Object> processorNode = new ProcessorNode<>(\"testNode\");\n \n         child = mock(ProcessorNode.class);\n+        processorNode.addChild(child);\n \n-        expect(processorNode.children())", "originalCommit": "29bb5d6913f652cf5e87cfa1a95395f4bda6fc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI3ODU4OQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r461278589", "bodyText": "Ah, it's because I swapped out the mock of the ProcessorNode for a real processor node (on line 82). Note that these were not checks, they were just dummy returns, since we never verified them, and it was a nice mock.\nNow, all the tests behave the same, and we don't need as much boilerplace test setup.", "author": "vvcephei", "createdAt": "2020-07-28T02:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0Mzk0NA=="}], "type": "inlineReview"}, {"oid": "29a02711c78e8a146541a23d9f11f1d34f03f517", "url": "https://github.com/apache/kafka/commit/29a02711c78e8a146541a23d9f11f1d34f03f517", "message": "Merge remote-tracking branch 'apache/trunk' into kip-478-part-1", "committedDate": "2020-07-28T02:06:54Z", "type": "commit"}, {"oid": "969c0d7e8311fe697cb453ed6001e85e36d73016", "url": "https://github.com/apache/kafka/commit/969c0d7e8311fe697cb453ed6001e85e36d73016", "message": "code review", "committedDate": "2020-07-28T02:34:32Z", "type": "commit"}, {"oid": "6d131dddbc1577d04e6343f7f9c0e6c5aea0c768", "url": "https://github.com/apache/kafka/commit/6d131dddbc1577d04e6343f7f9c0e6c5aea0c768", "message": "code review", "committedDate": "2020-07-28T02:35:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA1NDM4NQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r462054385", "bodyText": "nit: remove extra line", "author": "abbccdda", "createdAt": "2020-07-29T05:53:18Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.Processor;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.TimestampExtractor;\n+import org.apache.kafka.streams.processor.To;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+/**\n+ * Processor context interface.\n+ *\n+ * @param <KForward> a bound on the types of keys that may be forwarded\n+ * @param <VForward> a bound on the types of values that may be forwarded\n+ */\n+public interface ProcessorContext<KForward, VForward> {\n+\n+    /**\n+     * Returns the application id.\n+     *\n+     * @return the application id\n+     */\n+    String applicationId();\n+\n+    /**\n+     * Returns the task id.\n+     *\n+     * @return the task id\n+     */\n+    TaskId taskId();\n+\n+    /**\n+     * Returns the default key serde.\n+     *\n+     * @return the key serializer\n+     */\n+    Serde<?> keySerde();\n+\n+    /**\n+     * Returns the default value serde.\n+     *\n+     * @return the value serializer\n+     */\n+    Serde<?> valueSerde();\n+\n+    /**\n+     * Returns the state directory for the partition.\n+     *\n+     * @return the state directory\n+     */\n+    File stateDir();\n+\n+    /**\n+     * Returns Metrics instance.\n+     *\n+     * @return StreamsMetrics\n+     */\n+    StreamsMetrics metrics();\n+\n+    /**\n+     * Registers and possibly restores the specified storage engine.\n+     *\n+     * @param store the storage engine\n+     * @param stateRestoreCallback the restoration callback logic for log-backed state stores upon restart\n+     *\n+     * @throws IllegalStateException If store gets registered after initialized is already finished\n+     * @throws StreamsException if the store's change log does not contain the partition\n+     */\n+    void register(final StateStore store,\n+                  final StateRestoreCallback stateRestoreCallback);\n+\n+    /**\n+     * Get the state store given the store name.\n+     *\n+     * @param name The store name\n+     * @return The state store instance\n+     */\n+    StateStore getStateStore(final String name);\n+\n+    /**\n+     * Schedules a periodic operation for processors. A processor may call this method during\n+     * {@link Processor#init(org.apache.kafka.streams.processor.ProcessorContext) initialization} or\n+     * {@link Processor#process(Object, Object) processing} to\n+     * schedule a periodic callback &mdash; called a punctuation &mdash; to {@link Punctuator#punctuate(long)}.\n+     * The type parameter controls what notion of time is used for punctuation:\n+     * <ul>\n+     *   <li>{@link PunctuationType#STREAM_TIME} &mdash; uses \"stream time\", which is advanced by the processing of messages\n+     *   in accordance with the timestamp as extracted by the {@link TimestampExtractor} in use.\n+     *   The first punctuation will be triggered by the first record that is processed.\n+     *   <b>NOTE:</b> Only advanced if messages arrive</li>\n+     *   <li>{@link PunctuationType#WALL_CLOCK_TIME} &mdash; uses system time (the wall-clock time),\n+     *   which is advanced independent of whether new messages arrive.\n+     *   The first punctuation will be triggered after interval has elapsed.\n+     *   <b>NOTE:</b> This is best effort only as its granularity is limited by how long an iteration of the\n+     *   processing loop takes to complete</li>\n+     * </ul>\n+     *\n+     * <b>Skipping punctuations:</b> Punctuations will not be triggered more than once at any given timestamp.\n+     * This means that \"missed\" punctuation will be skipped.\n+     * It's possible to \"miss\" a punctuation if:\n+     * <ul>\n+     *   <li>with {@link PunctuationType#STREAM_TIME}, when stream time advances more than interval</li>\n+     *   <li>with {@link PunctuationType#WALL_CLOCK_TIME}, on GC pause, too short interval, ...</li>\n+     * </ul>\n+     *\n+     * @param interval the time interval between punctuations (supported minimum is 1 millisecond)\n+     * @param type one of: {@link PunctuationType#STREAM_TIME}, {@link PunctuationType#WALL_CLOCK_TIME}\n+     * @param callback a function consuming timestamps representing the current stream or system time\n+     * @return a handle allowing cancellation of the punctuation schedule established by this method\n+     */\n+    Cancellable schedule(final Duration interval,\n+                         final PunctuationType type,\n+                         final Punctuator callback);\n+\n+    /**\n+     * Forwards a key/value pair to all downstream processors.\n+     * Used the input record's timestamp as timestamp for the output record.\n+     *\n+     * @param key key\n+     * @param value value\n+     */\n+    <K extends KForward, V extends VForward> void forward(final K key, final V value);\n+\n+    /**\n+     * Forwards a key/value pair to the specified downstream processors.\n+     * Can be used to set the timestamp of the output record.\n+     *\n+     * @param key key\n+     * @param value value\n+     * @param to the options to use when forwarding\n+     */\n+    <K extends KForward, V extends VForward> void forward(final K key, final V value, final To to);\n+\n+    /**\n+     * Requests a commit.\n+     */\n+    void commit();\n+\n+    /**\n+     * Returns the topic name of the current input record; could be null if it is not\n+     * available (for example, if this method is invoked from the punctuate call).\n+     *\n+     * @return the topic name\n+     */\n+    String topic();\n+\n+    /**\n+     * Returns the partition id of the current input record; could be -1 if it is not\n+     * available (for example, if this method is invoked from the punctuate call).\n+     *\n+     * @return the partition id\n+     */\n+    int partition();\n+\n+    /**\n+     * Returns the offset of the current input record; could be -1 if it is not\n+     * available (for example, if this method is invoked from the punctuate call).\n+     *\n+     * @return the offset\n+     */\n+    long offset();\n+\n+    /**\n+     * Returns the headers of the current input record; could be null if it is not\n+     * available (for example, if this method is invoked from the punctuate call).\n+     *\n+     * @return the headers\n+     */\n+    Headers headers();\n+\n+    /**\n+     * Returns the current timestamp.\n+     *\n+     * <p> If it is triggered while processing a record streamed from the source processor,\n+     * timestamp is defined as the timestamp of the current input record; the timestamp is extracted from\n+     * {@link org.apache.kafka.clients.consumer.ConsumerRecord ConsumerRecord} by {@link TimestampExtractor}.\n+     *\n+     * <p> If it is triggered while processing a record generated not from the source processor (for example,\n+     * if this method is invoked from the punctuate call), timestamp is defined as the current\n+     * task's stream time, which is defined as the largest timestamp of any record processed by the task.\n+     *\n+     * @return the timestamp\n+     */\n+    long timestamp();\n+\n+    /**\n+     * Returns all the application config properties as key/value pairs.\n+     *\n+     * <p> The config properties are defined in the {@link org.apache.kafka.streams.StreamsConfig}\n+     * object and associated to the ProcessorContext.\n+     *\n+     * <p> The type of the values is dependent on the {@link org.apache.kafka.common.config.ConfigDef.Type type} of the property\n+     * (e.g. the value of {@link org.apache.kafka.streams.StreamsConfig#DEFAULT_KEY_SERDE_CLASS_CONFIG DEFAULT_KEY_SERDE_CLASS_CONFIG}\n+     * will be of type {@link Class}, even if it was specified as a String to\n+     * {@link org.apache.kafka.streams.StreamsConfig#StreamsConfig(Map) StreamsConfig(Map)}).\n+     *\n+     * @return all the key/values from the StreamsConfig properties\n+     */\n+    Map<String, Object> appConfigs();\n+\n+    /**\n+     * Returns all the application config properties with the given key prefix, as key/value pairs\n+     * stripping the prefix.\n+     *\n+     * <p> The config properties are defined in the {@link org.apache.kafka.streams.StreamsConfig}\n+     * object and associated to the ProcessorContext.\n+     *\n+     * @param prefix the properties prefix\n+     * @return the key/values matching the given prefix from the StreamsConfig properties.\n+     */\n+    Map<String, Object> appConfigsWithPrefix(final String prefix);\n+", "originalCommit": "6d131dddbc1577d04e6343f7f9c0e6c5aea0c768", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA1Nzc0NA==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r462057744", "bodyText": "format looks weird, maybe just do 4 spaces", "author": "abbccdda", "createdAt": "2020-07-29T06:03:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalTopologyBuilder.java", "diffHunk": "@@ -764,12 +764,12 @@ private void connectProcessorAndStateStore(final String processorName,\n \n         if (!sourceTopics.isEmpty()) {\n             stateStoreNameToSourceTopics.put(stateStoreName,\n-                    Collections.unmodifiableSet(sourceTopics));\n+                                             Collections.unmodifiableSet(sourceTopics));", "originalCommit": "6d131dddbc1577d04e6343f7f9c0e6c5aea0c768", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjA1ODk1MQ==", "url": "https://github.com/apache/kafka/pull/9004#discussion_r462058951", "bodyText": "nit: could make access private and get an accessor.", "author": "abbccdda", "createdAt": "2020-07-29T06:06:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextAdapter.java", "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.To;\n+import org.apache.kafka.streams.processor.api.ProcessorContext;\n+import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n+import org.apache.kafka.streams.state.StoreBuilder;\n+import org.apache.kafka.streams.state.internals.ThreadCache;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+public final class ProcessorContextAdapter<KForward, VForward>\n+    implements ProcessorContext<KForward, VForward>, InternalApiProcessorContext<KForward, VForward> {\n+\n+    final InternalProcessorContext delegate;", "originalCommit": "6d131dddbc1577d04e6343f7f9c0e6c5aea0c768", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4c00bae20dd29c2c016752bbf729cb54aacebf11", "url": "https://github.com/apache/kafka/commit/4c00bae20dd29c2c016752bbf729cb54aacebf11", "message": "Merge remote-tracking branch 'apache/trunk' into kip-478-part-1", "committedDate": "2020-08-09T19:45:41Z", "type": "commit"}, {"oid": "5471848c9a2eeae5a17ee5ae2504a6b6979697df", "url": "https://github.com/apache/kafka/commit/5471848c9a2eeae5a17ee5ae2504a6b6979697df", "message": "final review comments", "committedDate": "2020-08-09T19:52:02Z", "type": "commit"}]}