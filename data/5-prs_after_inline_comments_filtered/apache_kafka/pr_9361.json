{"pr_number": 9361, "pr_title": "KAFKA-10535: Split ProcessorContext into Processor/StateStore/Record Contexts", "pr_createdAt": "2020-10-01T17:08:40Z", "pr_url": "https://github.com/apache/kafka/pull/9361", "timeline": [{"oid": "22b9c3ab92dcaac8afae628547500e043e44de87", "url": "https://github.com/apache/kafka/commit/22b9c3ab92dcaac8afae628547500e043e44de87", "message": "KAFKA-10535: Split ProcessorContext into Processor/StateStore/RecordContext", "committedDate": "2020-10-01T16:20:08Z", "type": "commit"}, {"oid": "d3321aa0d199c80b04ab9e1121b4501b333db7a5", "url": "https://github.com/apache/kafka/commit/d3321aa0d199c80b04ab9e1121b4501b333db7a5", "message": "move metadata to context", "committedDate": "2020-10-01T17:06:18Z", "type": "commit"}, {"oid": "6a28f18b92189ae2e0df950d014230d4172f57ad", "url": "https://github.com/apache/kafka/commit/6a28f18b92189ae2e0df950d014230d4172f57ad", "message": "cleanup", "committedDate": "2020-10-01T17:13:30Z", "type": "commit"}, {"oid": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "url": "https://github.com/apache/kafka/commit/5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "message": "cleanup", "committedDate": "2020-10-01T17:23:06Z", "type": "commit"}, {"oid": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "url": "https://github.com/apache/kafka/commit/4c9934241e7488bd7836255c8793bc087bdf1c4d", "message": "comment", "committedDate": "2020-10-01T20:40:34Z", "type": "commit"}, {"oid": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "url": "https://github.com/apache/kafka/commit/1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "message": "cleanup", "committedDate": "2020-10-01T21:32:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM5NzcxMQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498397711", "bodyText": "Since we have to define a timestamp now, I'm showing the use of the punctuation time in the dev guide.", "author": "vvcephei", "createdAt": "2020-10-01T17:13:26Z", "path": "streams/examples/src/test/java/org/apache/kafka/streams/examples/docs/DeveloperGuideTesting.java", "diffHunk": "@@ -160,24 +161,24 @@ public void shouldPunctuateIfWallClockTimeAdvances() {\n         @Override\n         public void init(final ProcessorContext<String, Long> context) {\n             this.context = context;\n-            context.schedule(Duration.ofSeconds(60), PunctuationType.WALL_CLOCK_TIME, time -> flushStore());\n-            context.schedule(Duration.ofSeconds(10), PunctuationType.STREAM_TIME, time -> flushStore());\n+            context.schedule(Duration.ofSeconds(60), PunctuationType.WALL_CLOCK_TIME, this::flushStore);\n+            context.schedule(Duration.ofSeconds(10), PunctuationType.STREAM_TIME, this::flushStore);\n             store = context.getStateStore(\"aggStore\");\n         }\n \n         @Override\n-        public void process(final String key, final Long value) {\n-            final Long oldValue = store.get(key);\n-            if (oldValue == null || value > oldValue) {\n-                store.put(key, value);\n+        public void process(final Record<String, Long> record) {\n+            final Long oldValue = store.get(record.key());\n+            if (oldValue == null || record.value() > oldValue) {\n+                store.put(record.key(), record.value());\n             }\n         }\n \n-        private void flushStore() {\n+        private void flushStore(final long timestamp) {\n             final KeyValueIterator<String, Long> it = store.all();\n             while (it.hasNext()) {\n                 final KeyValue<String, Long> next = it.next();\n-                context.forward(next.key, next.value);\n+                context.forward(new Record<>(next.key, next.value, timestamp));", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM5ODI4MQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498398281", "bodyText": "now that we can implement both the new and old contexts with the same Impl, we need this to resolve a clash. It's backward compatible and a nice quality-of-life improvement anyway.", "author": "vvcephei", "createdAt": "2020-10-01T17:14:25Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/ProcessorContext.java", "diffHunk": "@@ -88,9 +88,12 @@ void register(final StateStore store,\n      * Get the state store given the store name.\n      *\n      * @param name The store name\n+     * @param <S> The type or interface of the store to return\n      * @return The state store instance\n+     *\n+     * @throws ClassCastException if the return type isn't a type or interface of the actual returned store.\n      */\n-    StateStore getStateStore(final String name);\n+    <S extends StateStore> S getStateStore(final String name);", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMDUwNQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498400505", "bodyText": "Not sure what's up with this diff, but this is the old API.", "author": "vvcephei", "createdAt": "2020-10-01T17:18:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/StateStore.java", "diffHunk": "@@ -49,7 +51,28 @@\n      * Initializes this state store.\n      * <p>\n      * The implementation of this function must register the root store in the context via the\n-     * {@link ProcessorContext#register(StateStore, StateRestoreCallback)} function, where the\n+     * {@link org.apache.kafka.streams.processor.ProcessorContext#register(StateStore, StateRestoreCallback)} function,\n+     * where the first {@link StateStore} parameter should always be the passed-in {@code root} object, and\n+     * the second parameter should be an object of user's implementation\n+     * of the {@link StateRestoreCallback} interface used for restoring the state store from the changelog.\n+     * <p>\n+     * Note that if the state store engine itself supports bulk writes, users can implement another\n+     * interface {@link BatchingStateRestoreCallback} which extends {@link StateRestoreCallback} to\n+     * let users implement bulk-load restoration logic instead of restoring one record at a time.\n+     * <p>\n+     * This method is not called if {@link StateStore#init(StateStoreContext, StateStore)}\n+     * is implemented.\n+     *\n+     * @throws IllegalStateException If store gets registered after initialized is already finished\n+     * @throws StreamsException if the store's change log does not contain the partition\n+     */\n+    void init(org.apache.kafka.streams.processor.ProcessorContext context, StateStore root);", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMDc1Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498400757", "bodyText": "This is the new API. Note the default implementation that delegates to the old API.", "author": "vvcephei", "createdAt": "2020-10-01T17:19:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/StateStore.java", "diffHunk": "@@ -61,7 +84,9 @@\n      * @throws IllegalStateException If store gets registered after initialized is already finished\n      * @throws StreamsException if the store's change log does not contain the partition\n      */\n-    void init(ProcessorContext context, StateStore root);\n+    default void init(final StateStoreContext context, final StateStore root) {\n+        init(StoreToProcessorContextAdapter.adapt(context), root);\n+    }", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMDk0OQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498400949", "bodyText": "The new state store context proposed in the KIP.", "author": "vvcephei", "createdAt": "2020-10-01T17:19:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/StateStoreContext.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.errors.StreamsException;\n+\n+import java.io.File;\n+import java.util.Map;\n+\n+/**\n+ * State store context interface.\n+ */\n+public interface StateStoreContext {", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMTE5MQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498401191", "bodyText": "The new Processor API (with Record) proposed in the KIP.", "author": "vvcephei", "createdAt": "2020-10-01T17:19:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/Processor.java", "diffHunk": "@@ -46,12 +46,11 @@\n     default void init(final ProcessorContext<KOut, VOut> context) {}\n \n     /**\n-     * Process the record with the given key and value.\n+     * Process the record. Note that record metadata is undefined in cases such as a forward call from a punctuator.\n      *\n-     * @param key the key for the record\n-     * @param value the value for the record\n+     * @param record the record to process\n      */\n-    void process(KIn key, VIn value);\n+    void process(Record<KIn, VIn> record);", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMTY1MQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498401651", "bodyText": "The new RecordMetadata context proposed in the KIP. Hopefully, the Javadoc is clear on why it's Optional.", "author": "vvcephei", "createdAt": "2020-10-01T17:20:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -55,6 +52,16 @@\n      */\n     TaskId taskId();\n \n+    /**\n+     * The metadata of the record, if it is defined. Note that as long as the processor is\n+     * receiving a record downstream of a Source (i.e., the current record is coming from an\n+     * input topic), the metadata is defined. On the other hand, if a parent processor has\n+     * registered a punctuator and called {@link ProcessorContext#forward(Record)} from that\n+     * punctuator, then there is no record from an input topic, and therefore the metadata\n+     * would be undefined.\n+     */\n+    Optional<RecordMetadata> recordMetadata();", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMTcyNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498401726", "bodyText": "Moved to the StateStoreContext.", "author": "vvcephei", "createdAt": "2020-10-01T17:20:51Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -83,30 +90,21 @@\n      */\n     StreamsMetrics metrics();\n \n-    /**\n-     * Registers and possibly restores the specified storage engine.\n-     *\n-     * @param store the storage engine\n-     * @param stateRestoreCallback the restoration callback logic for log-backed state stores upon restart\n-     *\n-     * @throws IllegalStateException If store gets registered after initialized is already finished\n-     * @throws StreamsException if the store's change log does not contain the partition\n-     */\n-    void register(final StateStore store,\n-                  final StateRestoreCallback stateRestoreCallback);\n-", "originalCommit": "6a28f18b92189ae2e0df950d014230d4172f57ad", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMzQwNw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498403407", "bodyText": "Migrated to the new Record argument.", "author": "vvcephei", "createdAt": "2020-10-01T17:23:55Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -140,76 +138,25 @@ Cancellable schedule(final Duration interval,\n                          final Punctuator callback);\n \n     /**\n-     * Forwards a key/value pair to all downstream processors.\n-     * Used the input record's timestamp as timestamp for the output record.\n+     * Forwards a record to all child processors.\n      *\n-     * @param key key\n-     * @param value value\n+     * @param record The record to forward to all children\n      */\n-    <K extends KForward, V extends VForward> void forward(final K key, final V value);\n+    <K extends KForward, V extends VForward> void forward(Record<K, V> record);", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU1OTg4Mg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498559882", "bodyText": "I'd suggest we add a few more sentences about \"always create a new Record upon forwarding\" v.s. \"reuse the object overriding its key/value/timestamp/header fields\", e.g. which way is more plausible when.", "author": "guozhangwang", "createdAt": "2020-10-01T23:30:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMzQwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU5MTgyNQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498591825", "bodyText": "Thanks, this sounds like a good place to put that guidance.", "author": "vvcephei", "createdAt": "2020-10-02T02:10:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMzQwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMzY4Mg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498403682", "bodyText": "These are moved to RecordMetadata", "author": "vvcephei", "createdAt": "2020-10-01T17:24:23Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -140,76 +138,25 @@ Cancellable schedule(final Duration interval,\n                          final Punctuator callback);\n \n     /**\n-     * Forwards a key/value pair to all downstream processors.\n-     * Used the input record's timestamp as timestamp for the output record.\n+     * Forwards a record to all child processors.\n      *\n-     * @param key key\n-     * @param value value\n+     * @param record The record to forward to all children\n      */\n-    <K extends KForward, V extends VForward> void forward(final K key, final V value);\n+    <K extends KForward, V extends VForward> void forward(Record<K, V> record);\n \n     /**\n-     * Forwards a key/value pair to the specified downstream processors.\n-     * Can be used to set the timestamp of the output record.\n+     * Forwards a record to the specified child processor.\n      *\n-     * @param key key\n-     * @param value value\n-     * @param to the options to use when forwarding\n+     * @param record The record to forward\n+     * @param childName The name of the child processor to receive the record\n      */\n-    <K extends KForward, V extends VForward> void forward(final K key, final V value, final To to);\n+    <K extends KForward, V extends VForward> void forward(Record<K, V> record, final String childName);\n \n     /**\n      * Requests a commit.\n      */\n     void commit();\n \n-    /**\n-     * Returns the topic name of the current input record; could be null if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the topic name\n-     */\n-    String topic();\n-\n-    /**\n-     * Returns the partition id of the current input record; could be -1 if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the partition id\n-     */\n-    int partition();\n-\n-    /**\n-     * Returns the offset of the current input record; could be -1 if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the offset\n-     */\n-    long offset();", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwMzc4Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498403787", "bodyText": "These are moved to Record.", "author": "vvcephei", "createdAt": "2020-10-01T17:24:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -140,76 +138,25 @@ Cancellable schedule(final Duration interval,\n                          final Punctuator callback);\n \n     /**\n-     * Forwards a key/value pair to all downstream processors.\n-     * Used the input record's timestamp as timestamp for the output record.\n+     * Forwards a record to all child processors.\n      *\n-     * @param key key\n-     * @param value value\n+     * @param record The record to forward to all children\n      */\n-    <K extends KForward, V extends VForward> void forward(final K key, final V value);\n+    <K extends KForward, V extends VForward> void forward(Record<K, V> record);\n \n     /**\n-     * Forwards a key/value pair to the specified downstream processors.\n-     * Can be used to set the timestamp of the output record.\n+     * Forwards a record to the specified child processor.\n      *\n-     * @param key key\n-     * @param value value\n-     * @param to the options to use when forwarding\n+     * @param record The record to forward\n+     * @param childName The name of the child processor to receive the record\n      */\n-    <K extends KForward, V extends VForward> void forward(final K key, final V value, final To to);\n+    <K extends KForward, V extends VForward> void forward(Record<K, V> record, final String childName);\n \n     /**\n      * Requests a commit.\n      */\n     void commit();\n \n-    /**\n-     * Returns the topic name of the current input record; could be null if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the topic name\n-     */\n-    String topic();\n-\n-    /**\n-     * Returns the partition id of the current input record; could be -1 if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the partition id\n-     */\n-    int partition();\n-\n-    /**\n-     * Returns the offset of the current input record; could be -1 if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the offset\n-     */\n-    long offset();\n-\n-    /**\n-     * Returns the headers of the current input record; could be null if it is not\n-     * available (for example, if this method is invoked from the punctuate call).\n-     *\n-     * @return the headers\n-     */\n-    Headers headers();\n-\n-    /**\n-     * Returns the current timestamp.\n-     *\n-     * <p> If it is triggered while processing a record streamed from the source processor,\n-     * timestamp is defined as the timestamp of the current input record; the timestamp is extracted from\n-     * {@link org.apache.kafka.clients.consumer.ConsumerRecord ConsumerRecord} by {@link TimestampExtractor}.\n-     *\n-     * <p> If it is triggered while processing a record generated not from the source processor (for example,\n-     * if this method is invoked from the punctuate call), timestamp is defined as the current\n-     * task's stream time, which is defined as the largest timestamp of any record processed by the task.\n-     *\n-     * @return the timestamp\n-     */\n-    long timestamp();", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwNDAzOQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498404039", "bodyText": "The new Record class proposed in the KIP.", "author": "vvcephei", "createdAt": "2020-10-01T17:25:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/Record.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+import org.apache.kafka.streams.errors.StreamsException;\n+\n+/**\n+ * A data class representing an incoming record for processing in a {@link Processor}\n+ * or a record to forward to downstream processors via {@link ProcessorContext}.\n+ *\n+ * This class encapsulates all the data attributes of a record: the key and value, but\n+ * also the timestamp of the record and any record headers.\n+ *\n+ * This class is immutable, though the objects referenced in the attributes of this class\n+ * may themselves be mutable.\n+ *\n+ * @param <K> The type of the key\n+ * @param <V> The type of the value\n+ */\n+public class Record<K, V> {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwNDM3Ng==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498404376", "bodyText": "The new metadata proposed in the KIP. Note that it's an interface because in reality, it's just going to be a view onto the ProcessorRecordContext.", "author": "vvcephei", "createdAt": "2020-10-01T17:25:37Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/RecordMetadata.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+public interface RecordMetadata {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwNTQ0OQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498405449", "bodyText": "The prior code was a bit misleading. I could not find any code path where the context was actually null before, since we always initialized it with a \"dummy context\". This change simplifies the codebase by just moving the dummy values here and we now really do set the record context to null to (internally) signify when it is undefined.", "author": "vvcephei", "createdAt": "2020-10-01T17:27:32Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContext.java", "diffHunk": "@@ -112,64 +114,69 @@ public void register(final StateStore store,\n         stateManager().registerStore(store, stateRestoreCallback);\n     }\n \n-    /**\n-     * @throws IllegalStateException if the task's record is null\n-     */\n     @Override\n     public String topic() {\n         if (recordContext == null) {\n-            throw new IllegalStateException(\"This should not happen as topic() should only be called while a record is processed\");\n-        }\n-\n-        final String topic = recordContext.topic();\n-\n-        if (NONEXIST_TOPIC.equals(topic)) {\n+            // This is only exposed via the deprecated ProcessorContext,\n+            // in which case, we're preserving the pre-existing behavior\n+            // of returning dummy values when the record context is undefined.\n+            // For topic, the dummy value is `null`.", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwNTgzNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498405836", "bodyText": "Just implementing the interface.", "author": "vvcephei", "createdAt": "2020-10-01T17:28:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ForwardingDisabledProcessorContext.java", "diffHunk": "@@ -86,7 +86,7 @@ public void register(final StateStore store,\n     }\n \n     @Override\n-    public StateStore getStateStore(final String name) {\n+    public <S extends StateStore> S getStateStore(final String name) {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwNjk4Mg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498406982", "bodyText": "Just implementing the new APIs while preserving the existing patterns.", "author": "vvcephei", "createdAt": "2020-10-01T17:30:13Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalProcessorContextImpl.java", "diffHunk": "@@ -49,26 +50,38 @@ protected StateManager stateManager() {\n         return stateManager;\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n     @Override\n-    public StateStore getStateStore(final String name) {\n+    public <S extends StateStore> S getStateStore(final String name) {\n         final StateStore store = stateManager.getGlobalStore(name);\n-        return getReadWriteStore(store);\n+        return (S) getReadWriteStore(store);\n     }\n \n     @SuppressWarnings(\"unchecked\")\n     @Override\n-    public <KIn, VIn> void forward(final KIn key, final VIn value) {\n+    public <K, V> void forward(final Record<K, V> record) {\n         final ProcessorNode<?, ?, ?, ?> previousNode = currentNode();\n         try {\n             for (final ProcessorNode<?, ?, ?, ?> child : currentNode().children()) {\n                 setCurrentNode(child);\n-                ((ProcessorNode<KIn, VIn, ?, ?>) child).process(key, value);\n+                ((ProcessorNode<K, V, ?, ?>) child).process(record);\n             }\n         } finally {\n             setCurrentNode(previousNode);\n         }\n     }\n \n+    @Override\n+    public <K, V> void forward(final Record<K, V> record, final String childName) {\n+        throw new UnsupportedOperationException(\"this should not happen: forward() not supported in global processor context.\");", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQwODQyNQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498408425", "bodyText": "These are scattered throughout this PR. It's just selecting the init method we want to invoke. It's only necessary because the globalProcessorContext here actually implements both ProcessorContext and StateStoreContext. This is only true of our internal contexts, so users will not face a similar need to change code.", "author": "vvcephei", "createdAt": "2020-10-01T17:33:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateManagerImpl.java", "diffHunk": "@@ -147,7 +148,7 @@ public void setGlobalProcessorContext(final InternalProcessorContext globalProce\n             globalStoreNames.add(stateStore.name());\n             final String sourceTopic = storeToChangelogTopic.get(stateStore.name());\n             changelogTopics.add(sourceTopic);\n-            stateStore.init(globalProcessorContext, stateStore);\n+            stateStore.init((StateStoreContext) globalProcessorContext, stateStore);", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQyNDg3Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498424877", "bodyText": "This is a pretty common pattern where we need to bridge the new and old APIs. We construct the \"record\" by filling in the timestamp and headers from the context.", "author": "vvcephei", "createdAt": "2020-10-01T18:03:07Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStateUpdateTask.java", "diffHunk": "@@ -104,7 +105,13 @@ public void update(final ConsumerRecord<byte[], byte[]> record) {\n                     deserialized.headers());\n             processorContext.setRecordContext(recordContext);\n             processorContext.setCurrentNode(sourceNodeAndDeserializer.sourceNode());\n-            ((SourceNode<Object, Object, Object, Object>) sourceNodeAndDeserializer.sourceNode()).process(deserialized.key(), deserialized.value());\n+            final Record<Object, Object> toProcess = new Record<>(\n+                deserialized.key(),\n+                deserialized.value(),\n+                processorContext.timestamp(),\n+                processorContext.headers()\n+            );\n+            ((SourceNode<Object, Object, Object, Object>) sourceNodeAndDeserializer.sourceNode()).process(toProcess);", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mjk3OQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498492979", "bodyText": "Note: each time we create a new Record, we copy the headers. This is an improvement over the current situation where there's no mutability barriers across the whole subtopology, so changes to headers in one processor can have unexpected effects on other processors that are very far away in the dependency diagram.\nHowever, it doesn't completely solve the problem: changes in children can still be visible to parents and siblings. @mjsax and I discussed an alternative option of providing a completely immutable implementation (copy on write) of Headers as a complete solution. But it also seems to be a pretty severe performance penalty. Instead, perhaps we can just document a safe pattern. E.g.,\nrecord = new Record(...)\ncontext.forward(record, \"childA\")\nrecord.headers().add(new header)\n// or\nrecord.withHeaders(record.headers().add(new header))\ncontext.forward(record, \"childB\")\n\nis unsafe because childA may modify the headers, affecting both the parent and childB. Instead, you should do something like:\nrecord1 = new Record(...)\nrecord2 = new Record(...)\nrecord2.headers().add(new header)\ncontext.forward(record1, \"childA\")\ncontext.forward(record2, \"childB\")\n\nNow, the headers for both children are completely independent objects.", "author": "vvcephei", "createdAt": "2020-10-01T20:22:25Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/Record.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+import org.apache.kafka.streams.errors.StreamsException;\n+\n+/**\n+ * A data class representing an incoming record for processing in a {@link Processor}\n+ * or a record to forward to downstream processors via {@link ProcessorContext}.\n+ *\n+ * This class encapsulates all the data attributes of a record: the key and value, but\n+ * also the timestamp of the record and any record headers.\n+ *\n+ * This class is immutable, though the objects referenced in the attributes of this class\n+ * may themselves be mutable.\n+ *\n+ * @param <K> The type of the key\n+ * @param <V> The type of the value\n+ */\n+public class Record<K, V> {\n+    private final K key;\n+    private final V value;\n+    private final long timestamp;\n+    private final Headers headers;\n+\n+    /**\n+     * The full constructor, specifying all the attributes of the record.\n+     *\n+     * @param key The key of the record. May be null.\n+     * @param value The value of the record. May be null.\n+     * @param timestamp The timestamp of the record. May not be negative.\n+     * @param headers The headers of the record. May be null, which will cause subsequent calls\n+     *                to {@link this#headers()} to return a non-null, empty, {@link Headers} collection.\n+     *\n+     * @throws IllegalArgumentException if the timestamp is negative.\n+     */\n+    public Record(final K key, final V value, final long timestamp, final Headers headers) {\n+        this.key = key;\n+        this.value = value;\n+        if (timestamp < 0) {\n+            throw new StreamsException(\n+                \"Malformed Record\",\n+                new IllegalArgumentException(\"Timestamp may not be negative. Got: \" + timestamp)\n+            );\n+        }\n+        this.timestamp = timestamp;\n+        this.headers = new RecordHeaders(headers);", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2MjQ5Mw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498562493", "bodyText": "That looks reasonable to me. More generally I'd suggest to document either in this class or in the forward class what side-effects the user need to consider if they decided to reuse the object passed in as parameters and mutate its fields / forward to downstream. And as long as we do that I feel this would be okay.", "author": "guozhangwang", "createdAt": "2020-10-01T23:40:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mjk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU5MTk2NA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498591964", "bodyText": "Thanks. I like the idea of putting it in forward. Maybe with a short mention here as well.", "author": "vvcephei", "createdAt": "2020-10-02T02:11:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mjk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5MzUyOQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498493529", "bodyText": "Don't need this anymore, since the InternalProcessorContext can now implement all of the new and old Contexts.", "author": "vvcephei", "createdAt": "2020-10-01T20:23:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalApiProcessorContext.java", "diffHunk": "@@ -1,119 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.processor.internals;\n-\n-import org.apache.kafka.common.utils.Bytes;\n-import org.apache.kafka.streams.processor.RecordContext;\n-import org.apache.kafka.streams.processor.StateStore;\n-import org.apache.kafka.streams.processor.api.ProcessorContext;\n-import org.apache.kafka.streams.processor.internals.Task.TaskType;\n-import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n-import org.apache.kafka.streams.state.StoreBuilder;\n-import org.apache.kafka.streams.state.internals.ThreadCache;\n-import org.apache.kafka.streams.state.internals.ThreadCache.DirtyEntryFlushListener;\n-\n-/**\n- * For internal use so we can update the {@link RecordContext} and current\n- * {@link ProcessorNode} when we are forwarding items that have been evicted or flushed from\n- * {@link ThreadCache}\n- */\n-public interface InternalApiProcessorContext<KForward, VForward> extends ProcessorContext<KForward, VForward> {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5Mzk4NA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498493984", "bodyText": "Thanks to this, all our internal Impls are suitable to pass in to any of the new APIs.", "author": "vvcephei", "createdAt": "2020-10-01T20:24:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/InternalProcessorContext.java", "diffHunk": "@@ -33,7 +34,9 @@\n  * {@link ProcessorNode} when we are forwarding items that have been evicted or flushed from\n  * {@link ThreadCache}\n  */\n-public interface InternalProcessorContext extends ProcessorContext {\n+public interface InternalProcessorContext\n+    extends ProcessorContext, org.apache.kafka.streams.processor.api.ProcessorContext<Object, Object>, StateStoreContext {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODQ5NDYzOQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498494639", "bodyText": "We also don't need these adapters anymore.", "author": "vvcephei", "createdAt": "2020-10-01T20:25:59Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextAdapter.java", "diffHunk": "@@ -1,235 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.processor.internals;\n-\n-import org.apache.kafka.common.header.Headers;\n-import org.apache.kafka.common.serialization.Serde;\n-import org.apache.kafka.common.utils.Bytes;\n-import org.apache.kafka.streams.processor.Cancellable;\n-import org.apache.kafka.streams.processor.PunctuationType;\n-import org.apache.kafka.streams.processor.Punctuator;\n-import org.apache.kafka.streams.processor.StateRestoreCallback;\n-import org.apache.kafka.streams.processor.StateStore;\n-import org.apache.kafka.streams.processor.TaskId;\n-import org.apache.kafka.streams.processor.To;\n-import org.apache.kafka.streams.processor.api.ProcessorContext;\n-import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n-import org.apache.kafka.streams.state.StoreBuilder;\n-import org.apache.kafka.streams.state.internals.ThreadCache;\n-\n-import java.io.File;\n-import java.time.Duration;\n-import java.util.Map;\n-\n-public final class ProcessorContextAdapter<KForward, VForward>\n-    implements ProcessorContext<KForward, VForward>, InternalApiProcessorContext<KForward, VForward> {", "originalCommit": "5d7bf4abb687a1d6f6ecf28843370b633ae1497b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNTgxNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498505816", "bodyText": "Don't need this adapter anymore, either.", "author": "vvcephei", "createdAt": "2020-10-01T20:50:35Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextReverseAdapter.java", "diffHunk": "@@ -1,248 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements. See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License. You may obtain a copy of the License at\n- *\n- *    http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.kafka.streams.processor.internals;\n-\n-import org.apache.kafka.common.header.Headers;\n-import org.apache.kafka.common.serialization.Serde;\n-import org.apache.kafka.common.utils.Bytes;\n-import org.apache.kafka.streams.processor.Cancellable;\n-import org.apache.kafka.streams.processor.PunctuationType;\n-import org.apache.kafka.streams.processor.Punctuator;\n-import org.apache.kafka.streams.processor.StateRestoreCallback;\n-import org.apache.kafka.streams.processor.StateStore;\n-import org.apache.kafka.streams.processor.TaskId;\n-import org.apache.kafka.streams.processor.To;\n-import org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl;\n-import org.apache.kafka.streams.state.StoreBuilder;\n-import org.apache.kafka.streams.state.internals.ThreadCache;\n-\n-import java.io.File;\n-import java.time.Duration;\n-import java.util.Map;\n-\n-public final class ProcessorContextReverseAdapter implements InternalProcessorContext {", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNjc2Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498506767", "bodyText": "Casting to add the generic params (the InternalProcessorContext is parameterized as <Object, Object>).", "author": "vvcephei", "createdAt": "2020-10-01T20:52:33Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorNode.java", "diffHunk": "@@ -114,7 +117,7 @@ public void init(final InternalProcessorContext context) {\n             maybeMeasureLatency(\n                 () -> {\n                     if (processor != null) {\n-                        processor.init(ProcessorContextAdapter.adapt(context));\n+                        processor.init((ProcessorContext<KOut, VOut>) context);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwNjk0MA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498506940", "bodyText": "Here's the implementation of RecordMetadata.", "author": "vvcephei", "createdAt": "2020-10-01T20:52:56Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorRecordContext.java", "diffHunk": "@@ -29,7 +30,7 @@\n import static java.util.Objects.requireNonNull;\n import static org.apache.kafka.common.utils.Utils.getNullableSizePrefixedArray;\n \n-public class ProcessorRecordContext implements RecordContext {\n+public class ProcessorRecordContext implements RecordContext, RecordMetadata {", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwOTE0NQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498509145", "bodyText": "This allows us to transparently delegate the new API to the old one for StateStore implementations. Our internal StateStoreContext implementations all implement both APIs, so they just get casted, while if you use a separate implementation of StateStoreContext (e.g., in unit tests), it'll get adapted, which works just as long as the underlying store implementation doesn't try to call forward or anything.", "author": "vvcephei", "createdAt": "2020-10-01T20:57:26Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StoreToProcessorContextAdapter.java", "diffHunk": "@@ -0,0 +1,163 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.streams.StreamsMetrics;\n+import org.apache.kafka.streams.processor.Cancellable;\n+import org.apache.kafka.streams.processor.ProcessorContext;\n+import org.apache.kafka.streams.processor.PunctuationType;\n+import org.apache.kafka.streams.processor.Punctuator;\n+import org.apache.kafka.streams.processor.StateRestoreCallback;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.apache.kafka.streams.processor.StateStoreContext;\n+import org.apache.kafka.streams.processor.TaskId;\n+import org.apache.kafka.streams.processor.To;\n+\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.Map;\n+\n+public final class StoreToProcessorContextAdapter implements ProcessorContext {\n+    private final StateStoreContext delegate;\n+\n+    public static ProcessorContext adapt(final StateStoreContext delegate) {\n+        if (delegate instanceof ProcessorContext) {\n+            return (ProcessorContext) delegate;\n+        } else {\n+            return new StoreToProcessorContextAdapter(delegate);\n+        }\n+    }", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUwOTc4NQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498509785", "bodyText": "This is pulling out the timestamp and headers that we just set a few lines earlier.", "author": "vvcephei", "createdAt": "2020-10-01T20:58:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -670,9 +671,26 @@ public boolean process(final long wallClockTime) {\n \n             log.trace(\"Start processing one record [{}]\", record);\n \n-            updateProcessorContext(record, currNode, wallClockTime);\n+            updateProcessorContext(\n+                currNode,\n+                wallClockTime,\n+                new ProcessorRecordContext(\n+                    record.timestamp,\n+                    record.offset(),\n+                    record.partition(),\n+                    record.topic(),\n+                    record.headers()\n+                )\n+            );\n+\n             maybeRecordE2ELatency(record.timestamp, wallClockTime, currNode.name());\n-            maybeMeasureLatency(() -> currNode.process(record.key(), record.value()), time, processLatencySensor);\n+            final Record<Object, Object> toProcess = new Record<>(\n+                record.key(),\n+                record.value(),\n+                processorContext.timestamp(),\n+                processorContext.headers()", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMDEwMg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498510102", "bodyText": "Instead of setting a dummy context, we're now just setting the context to null aka \"undefined\".", "author": "vvcephei", "createdAt": "2020-10-01T20:59:21Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -742,8 +760,7 @@ public void punctuate(final ProcessorNode<?, ?, ?, ?> node,\n             throw new IllegalStateException(String.format(\"%sCurrent node is not null\", logPrefix));\n         }\n \n-        updateProcessorContext(new StampedRecord(new ConsumerRecord<>(ProcessorContextImpl.NONEXIST_TOPIC, -1, -1L, null, null),\n-            timestamp), node, time.milliseconds());\n+        updateProcessorContext(node, time.milliseconds(), null);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMDcwMg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498510702", "bodyText": "A copy constructor helped with the ProcessorContextImpl refactoring.", "author": "vvcephei", "createdAt": "2020-10-01T21:00:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ToInternal.java", "diffHunk": "@@ -23,6 +23,10 @@ public ToInternal() {\n         super(To.all());\n     }\n \n+    public ToInternal(final To to) {\n+        super(to);\n+    }", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMDkyNA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498510924", "bodyText": "A good example of updating just the value for the child.", "author": "vvcephei", "createdAt": "2020-10-01T21:01:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -866,9 +867,9 @@ public void init(final ProcessorContext<String, String> context) {\n                     }\n \n                     @Override\n-                    public void process(final String key, final String value) {\n-                        if (value.length() % 2 == 0) {\n-                            context.forward(key, key + value);\n+                    public void process(final Record<String, String> record) {\n+                        if (record.value().length() % 2 == 0) {\n+                            context.forward(record.withValue(record.key() + record.value()));", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMTExOQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498511119", "bodyText": "You're going to see a lot of these in the tests.", "author": "vvcephei", "createdAt": "2020-10-01T21:01:31Z", "path": "streams/src/test/java/org/apache/kafka/streams/KafkaStreamsTest.java", "diffHunk": "@@ -967,11 +968,11 @@ public void init(final ProcessorContext<String, String> context) {\n                 }\n \n                 @Override\n-                public void process(final String key, final String value) {\n+                public void process(final Record<String, String> record) {\n                     final KeyValueStore<String, Long> kvStore = context.getStateStore(storeName);\n-                    kvStore.put(key, 5L);\n+                    kvStore.put(record.key(), 5L);\n \n-                    context.forward(key, \"5\");\n+                    context.forward(record.withValue(\"5\"));", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMjE3NA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498512174", "bodyText": "The prior code here was actually relying on a strange effect in which we set the (undefined) processor context's timestamp to the punctuation time. I could preserve that behavior, but it looked like a bug to me.", "author": "vvcephei", "createdAt": "2020-10-01T21:03:51Z", "path": "streams/src/test/java/org/apache/kafka/streams/kstream/internals/KStreamTransformTest.java", "diffHunk": "@@ -60,7 +61,7 @@ public void init(final ProcessorContext context) {\n                     context.schedule(\n                         Duration.ofMillis(1),\n                         PunctuationType.WALL_CLOCK_TIME,\n-                        timestamp -> context.forward(-1, (int) timestamp)\n+                        timestamp -> context.forward(-1, (int) timestamp, To.all().withTimestamp(timestamp))", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMjcyMg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498512722", "bodyText": "These tests were enforcing a behavior that would never have actually happened in practice. Since I changed these methods to return the dummy values when the context is undefined, these tests also have to change.", "author": "vvcephei", "createdAt": "2020-10-01T21:05:08Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/AbstractProcessorContextTest.java", "diffHunk": "@@ -81,14 +84,9 @@ public void shouldThrowNullPointerOnRegisterIfStateStoreIsNull() {\n     }\n \n     @Test\n-    public void shouldThrowIllegalStateExceptionOnTopicIfNoRecordContext() {\n+    public void shouldReturnNullTopicIfNoRecordContext() {", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxMzUzNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498513536", "bodyText": "That constructor of ConsumerRecord set the timestamp to -1, which is now prohibited because we construct a Record before processing, and Record enforces no negative timestamps.\nThis seems fine to me, since it would only happen in unit tests (as ConsumerRecords returned from the broker never have negative timestamps).", "author": "vvcephei", "createdAt": "2020-10-01T21:07:03Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/GlobalStateTaskTest.java", "diffHunk": "@@ -127,7 +128,7 @@ public void shouldInitializeProcessorTopology() {\n     @Test\n     public void shouldProcessRecordsForTopic() {\n         globalStateTask.initialize();\n-        globalStateTask.update(new ConsumerRecord<>(topic1, 1, 1, \"foo\".getBytes(), \"bar\".getBytes()));\n+        globalStateTask.update(record(topic1, 1, 1, \"foo\".getBytes(), \"bar\".getBytes()));", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxNDI5Mw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498514293", "bodyText": "just a simple passthrough", "author": "vvcephei", "createdAt": "2020-10-01T21:08:45Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorTopologyTest.java", "diffHunk": "@@ -775,8 +775,8 @@ public void init(final ProcessorContext<String, String> context) {\n         }\n \n         @Override\n-        public void process(final String key, final String value) {\n-            context.forward(key, value);\n+        public void process(final Record<String, String> record) {\n+            context.forward(record);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxNDM2Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498514367", "bodyText": "An example of setting only the timestamp.", "author": "vvcephei", "createdAt": "2020-10-01T21:08:56Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/ProcessorTopologyTest.java", "diffHunk": "@@ -792,8 +792,8 @@ public void init(final ProcessorContext<String, String> context) {\n         }\n \n         @Override\n-        public void process(final String key, final String value) {\n-            context.forward(key, value, To.all().withTimestamp(context.timestamp() + 10));\n+        public void process(final Record<String, String> record) {\n+            context.forward(record.withTimestamp(record.timestamp() + 10));", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxNTcwNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498515706", "bodyText": "Example of filtering but otherwise passing the record through.", "author": "vvcephei", "createdAt": "2020-10-01T21:12:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -466,10 +467,11 @@ public void init(final InternalProcessorContext context) {\n                 this.context = context;\n                 super.init(context);\n             }\n+\n             @Override\n-            public void process(final Integer key, final Integer value) {\n-                if (key % 2 == 0) {\n-                    context.forward(key, value);\n+            public void process(final Record<Integer, Integer> record) {\n+                if (record.key() % 2 == 0) {\n+                    context.forward(record);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxNjgyMg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498516822", "bodyText": "This test was actually testing a slightly wrong thing: recordContext was never exposed to users, they would have accessed the headers as processorContext.header(). It's important here because I've refactored the internal code to set recordContext to null when there is no defined context (such as in a punctuation like here).", "author": "vvcephei", "createdAt": "2020-10-01T21:14:43Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamTaskTest.java", "diffHunk": "@@ -1230,10 +1232,10 @@ public void shouldNotShareHeadersBetweenPunctuateIterations() {\n         task.completeRestoration();\n \n         task.punctuate(processorSystemTime, 1, PunctuationType.WALL_CLOCK_TIME, timestamp -> {\n-            task.processorContext().recordContext().headers().add(\"dummy\", (byte[]) null);\n+            task.processorContext().headers().add(\"dummy\", (byte[]) null);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxNzc4NA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498517784", "bodyText": "This is the utility method I replaced the ConsumerRecord constructor with earlier in the PR.", "author": "vvcephei", "createdAt": "2020-10-01T21:16:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/testutil/ConsumerRecordUtil.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.internals.testutil;\n+\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.common.record.TimestampType;\n+\n+public final class ConsumerRecordUtil {\n+    private ConsumerRecordUtil() {}\n+\n+    public static <K, V> ConsumerRecord<K, V> record(final String topic,\n+                                                     final int partition,\n+                                                     final long offset,\n+                                                     final K key,\n+                                                     final V value) {\n+        // the no-time constructor in ConsumerRecord initializes the\n+        // timestamp to -1, which is an invalid configuration. Here,\n+        // we initialize it to 0.\n+        return new ConsumerRecord<>(\n+            topic,\n+            partition,\n+            offset,\n+            0L,\n+            TimestampType.CREATE_TIME,\n+            0L,\n+            0,\n+            0,\n+            key,\n+            value\n+        );\n+    }", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxODA3Nw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498518077", "bodyText": "Words cannot express how tired of this change I was by this point.", "author": "vvcephei", "createdAt": "2020-10-01T21:17:32Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingKeyValueBytesStoreTest.java", "diffHunk": "@@ -55,7 +56,7 @@ public void before() {\n             collector,\n             new ThreadCache(new LogContext(\"testCache \"), 0, new MockStreamsMetrics(new Metrics())));\n         context.setTime(0);\n-        store.init(context, store);\n+        store.init((StateStoreContext) context, store);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxODU3MQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498518571", "bodyText": "Just a quick note. We do still expect the inner store to have the old init method invoked because none of the wrapper stores are implementing the new init method, so they're using the default implementation that delegates to the old init method. I'm going to take care of that in a follow-on PR.", "author": "vvcephei", "createdAt": "2020-10-01T21:18:44Z", "path": "streams/src/test/java/org/apache/kafka/streams/state/internals/ChangeLoggingTimestampedWindowBytesStoreTest.java", "diffHunk": "@@ -57,11 +59,11 @@ public void setUp() {\n     private void init() {\n         EasyMock.expect(context.taskId()).andReturn(taskId);\n         EasyMock.expect(context.recordCollector()).andReturn(collector);\n-        inner.init(context, store);\n+        inner.init((ProcessorContext) context, store);", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUxOTY5Mw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498519693", "bodyText": "This can become a method reference now because those assertions on partition and offset are meaningless now.", "author": "vvcephei", "createdAt": "2020-10-01T21:21:46Z", "path": "streams/src/test/java/org/apache/kafka/test/MockApiProcessor.java", "diffHunk": "@@ -65,25 +66,19 @@ public void init(final ProcessorContext<KOut, VOut> context) {\n             scheduleCancellable = context.schedule(\n                 Duration.ofMillis(scheduleInterval),\n                 punctuationType,\n-                timestamp -> {\n-                    if (punctuationType == PunctuationType.STREAM_TIME) {\n-                        assertThat(context.timestamp(), is(timestamp));\n-                    }\n-                    assertThat(context.partition(), is(-1));\n-                    assertThat(context.offset(), is(-1L));\n-\n-                    (punctuationType == PunctuationType.STREAM_TIME ? punctuatedStreamTime : punctuatedSystemTime)\n-                        .add(timestamp);\n-                });\n+                (punctuationType == PunctuationType.STREAM_TIME ? punctuatedStreamTime : punctuatedSystemTime)::add", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUyMDkwNQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498520905", "bodyText": "This was a bit funny to run into by this point in the implementation. It turns out we already had a class called \"Record\", and now we need to reference both of them in this test. I felt like it was more readable to just give this class a new name instead of referencing it by fully qualified name.", "author": "vvcephei", "createdAt": "2020-10-01T21:24:58Z", "path": "streams/test-utils/src/test/java/org/apache/kafka/streams/TopologyTestDriverTest.java", "diffHunk": "@@ -148,16 +149,16 @@ public TopologyTestDriverTest(final boolean eosEnabled) {\n         }\n     }\n \n-    private final static class Record {\n+    private final static class TTDTestRecord {", "originalCommit": "4c9934241e7488bd7836255c8793bc087bdf1c4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUyMzkyNw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498523927", "bodyText": "We used to check this only in SinkNode, but it seems better to fail fast since we actually have the opportunity to do so now.", "author": "vvcephei", "createdAt": "2020-10-01T21:32:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/Record.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+import org.apache.kafka.streams.errors.StreamsException;\n+\n+/**\n+ * A data class representing an incoming record for processing in a {@link Processor}\n+ * or a record to forward to downstream processors via {@link ProcessorContext}.\n+ *\n+ * This class encapsulates all the data attributes of a record: the key and value, but\n+ * also the timestamp of the record and any record headers.\n+ *\n+ * This class is immutable, though the objects referenced in the attributes of this class\n+ * may themselves be mutable.\n+ *\n+ * @param <K> The type of the key\n+ * @param <V> The type of the value\n+ */\n+public class Record<K, V> {\n+    private final K key;\n+    private final V value;\n+    private final long timestamp;\n+    private final Headers headers;\n+\n+    /**\n+     * The full constructor, specifying all the attributes of the record.\n+     *\n+     * @param key The key of the record. May be null.\n+     * @param value The value of the record. May be null.\n+     * @param timestamp The timestamp of the record. May not be negative.\n+     * @param headers The headers of the record. May be null, which will cause subsequent calls\n+     *                to {@link this#headers()} to return a non-null, empty, {@link Headers} collection.\n+     *\n+     * @throws IllegalArgumentException if the timestamp is negative.\n+     */\n+    public Record(final K key, final V value, final long timestamp, final Headers headers) {\n+        this.key = key;\n+        this.value = value;\n+        if (timestamp < 0) {\n+            throw new StreamsException(\n+                \"Malformed Record\",\n+                new IllegalArgumentException(\"Timestamp may not be negative. Got: \" + timestamp)\n+            );\n+        }", "originalCommit": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUzMTE0OQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498531149", "bodyText": "I think this is a proof of code simplicity that recordContext is unnecessarily passing around here :)", "author": "guozhangwang", "createdAt": "2020-10-01T21:51:17Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamTask.java", "diffHunk": "@@ -692,8 +690,7 @@ public boolean process(final long wallClockTime) {\n                 processorContext.timestamp(),\n                 processorContext.headers()\n             );\n-            final Optional<RecordMetadata> recordMetadata = Optional.ofNullable(processorContext.recordContext());\n-            maybeMeasureLatency(() -> currNode.process(toProcess, recordMetadata), time, processLatencySensor);\n+            maybeMeasureLatency(() -> currNode.process(toProcess), time, processLatencySensor);", "originalCommit": "d3321aa0d199c80b04ab9e1121b4501b333db7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODg3MTMwNQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498871305", "bodyText": "Yeah, I agree. I think this is much simpler for both the implementation and the API. Sorry I didn't see it at first ;)", "author": "vvcephei", "createdAt": "2020-10-02T14:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUzMTE0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUzMTkwMg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498531902", "bodyText": "nit: maybe also state that the metadata would be the one from the source record?", "author": "guozhangwang", "createdAt": "2020-10-01T21:53:20Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -52,6 +52,16 @@\n      */\n     TaskId taskId();\n \n+    /**\n+     * The metadata of the record, if it is defined. Note that as long as the processor is\n+     * receiving a record downstream of a Source (i.e., the current record is coming from an", "originalCommit": "d3321aa0d199c80b04ab9e1121b4501b333db7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU5MjQ5OA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498592498", "bodyText": "Sure!", "author": "vvcephei", "createdAt": "2020-10-02T02:14:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODUzMTkwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2MDI3NQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498560275", "bodyText": "nit: see my other comment above, maybe we can leave some guidance on when it is preferable to reuse the Record with mutable fields than creating a new Record object?", "author": "guozhangwang", "createdAt": "2020-10-01T23:31:59Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/Record.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.streams.processor.api;\n+\n+import org.apache.kafka.common.header.Headers;\n+import org.apache.kafka.common.header.internals.RecordHeaders;\n+import org.apache.kafka.streams.errors.StreamsException;\n+\n+/**\n+ * A data class representing an incoming record for processing in a {@link Processor}\n+ * or a record to forward to downstream processors via {@link ProcessorContext}.\n+ *\n+ * This class encapsulates all the data attributes of a record: the key and value, but\n+ * also the timestamp of the record and any record headers.\n+ *\n+ * This class is immutable, though the objects referenced in the attributes of this class\n+ * may themselves be mutable.", "originalCommit": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYwMzU1NA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498603554", "bodyText": "Sounds good.", "author": "vvcephei", "createdAt": "2020-10-02T03:19:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2MDI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498564327", "bodyText": "I was hoping that with the new strong typing API, during forwarding we do not need to cast to (ProcessorNode<K, V, ?, ?>) and not need this suppression any more.. Could we add the typing into currentNode (e.g. validate that the currentNode.children is indeed in K, V) instead of force casting?", "author": "guozhangwang", "createdAt": "2020-10-01T23:48:41Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -159,84 +157,123 @@ public StateStore getStateStore(final String name) {\n         }\n \n         final StateStore store = stateManager.getStore(name);\n-        return getReadWriteStore(store);\n+        return (S) getReadWriteStore(store);\n     }\n \n     @Override\n     public <K, V> void forward(final K key,\n                                final V value) {\n-        throwUnsupportedOperationExceptionIfStandby(\"forward\");\n-        forward(key, value, SEND_TO_ALL);\n+        final Record<K, V> toForward = new Record<>(\n+            key,\n+            value,\n+            timestamp(),\n+            headers()\n+        );\n+        forward(toForward);\n     }\n \n     @Override\n     @Deprecated\n     public <K, V> void forward(final K key,\n                                final V value,\n                                final int childIndex) {\n-        throwUnsupportedOperationExceptionIfStandby(\"forward\");\n-        forward(\n+        final Record<K, V> toForward = new Record<>(\n             key,\n             value,\n-            To.child((currentNode().children()).get(childIndex).name()));\n+            timestamp(),\n+            headers()\n+        );\n+        forward(toForward, (currentNode().children()).get(childIndex).name());\n     }\n \n     @Override\n     @Deprecated\n     public <K, V> void forward(final K key,\n                                final V value,\n                                final String childName) {\n-        throwUnsupportedOperationExceptionIfStandby(\"forward\");\n-        forward(key, value, To.child(childName));\n+        final Record<K, V> toForward = new Record<>(\n+            key,\n+            value,\n+            timestamp(),\n+            headers()\n+        );\n+        forward(toForward, childName);\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n     @Override\n     public <K, V> void forward(final K key,\n                                final V value,\n                                final To to) {\n+        final ToInternal toInternal = new ToInternal(to);\n+        final Record<K, V> toForward = new Record<>(\n+            key,\n+            value,\n+            toInternal.hasTimestamp() ? toInternal.timestamp() : timestamp(),\n+            headers()\n+        );\n+        forward(toForward, toInternal.child());\n+    }\n+\n+    @Override\n+    public <K, V> void forward(final Record<K, V> record) {\n+        forward(record, null);\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")", "originalCommit": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYwNjA2Ng==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498606066", "bodyText": "I'll have to think about this, but offhand, it doesn't seem like that would work.\nIn general, the type safety we're providing is on the user side of the PAPI (of course, the DSL internals is a user of the PAPI). On the internals side of the PAPI implementation, we generally can't get any more safety. For example, the ProcessorContextImpl is instantiated for the whole Task, which would handle a number of different record types and ProcessorNode types, so the internal implementation of the ProcessorContextImpl would have to be agnostic wrt the actual types of the nodes.\nI think that by the time I'm done with the full implementation of this KIP, you'll see most of the unchecked suppressions and casts gone from the DSL implementation, but there will still be some in classes like this one.", "author": "vvcephei", "createdAt": "2020-10-02T03:35:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYwODY0Mg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498608642", "bodyText": "What I'm wondering is that, within a processor node of <KIn, VIn, KOut, VOut>, if a context.forward() is called with Record<KOut2, VOut2>, would we only throw a casting exception at runtime, or we could capture this at compiler time. From this suppression it seems we still cannot achieve the former.. do you think this can be improved alongside with this KIP too?", "author": "guozhangwang", "createdAt": "2020-10-02T03:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODkxNDAzNA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498914034", "bodyText": "I see.\nSo, within the Processor<KIn, Vin, KOut, VOut>, the ProcessorContext is bounded to <KOut, VOut>, and therefore forward will only accept a Record<KOut, VOut>. The compiler will check the source code of the processor and enforce this at compile time. It sounds like this is one part of what you are thinking about.\nBut inside the ProcessorContextImpl, we're outside of the Processor, and in the \"plumbing\" of Streams. In this context, we cannot have compile-time type safety, since we can't bound all of KafkaStreams to accept only one kind of record and processor.\nHowever, what we can check at compile time is that we only attach compatible children to parents. This isn't a way to do this in Topology right now, and I didn't want to expand this KIP to that extent. My plan for getting the full benefit of this KIP in the DSL internals is to actually add an internal utility method for registering pairs of processors, like this:\n    void addGraphNode(final StreamsGraphNode<KIn, VIn, KIntermediate, VIntermediate> parent,\n                      final StreamsGraphNode<KIntermediate, VIntermediate, KOut, VOut> child);\nThen, in addition to a compile-time guarantee that a processor can only forward its declared output type, we also get a guarantee that the builder can only attach compatible parent-child pairs. Assuming you don't do any casting in \"user space\",\nwe don't need any further compiler checking to render cast exceptions impossible. The \"plumbing code\" like in this ProcessorContextImpl is akin to the JVM runtime after type erasure... the \"compiler\" has already done its job on the \"source code\" (the user-facing side of the PAPI), so we don't need the types anymore at \"run time\".", "author": "vvcephei", "createdAt": "2020-10-02T16:06:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODkxNTYwMQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498915601", "bodyText": "I think it would have been nice to get some kind of public-facing API into Topology like what I quoted above, but at this point, I think we can just cut scope on KIP-478 and implement it for 2.7 as-is. Then, we can follow up with a new KIP to add some kind of Topology#attachChildToParent API in a later KIP).\nAside from cutting scope, I wanted to do it as an internal API while migrating the DSL internals so I could be sure the \"attach\" method is really the best approach.", "author": "vvcephei", "createdAt": "2020-10-02T16:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODk1MTI0Mg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498951242", "bodyText": "Thanks for your thoughts, and I agree it is too stretch for KIP-478 to extend to that. Let's just keep it as is now.", "author": "guozhangwang", "createdAt": "2020-10-02T17:21:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDM5OQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498564399", "bodyText": "Why we'd need to add this suppression?", "author": "guozhangwang", "createdAt": "2020-10-01T23:49:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/ProcessorContextImpl.java", "diffHunk": "@@ -135,16 +132,17 @@ public void logChange(final String storeName,\n      * @throws StreamsException if an attempt is made to access this state store from an unknown node\n      * @throws UnsupportedOperationException if the current streamTask type is standby\n      */\n+    @SuppressWarnings(\"unchecked\")", "originalCommit": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYwNDgyMQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498604821", "bodyText": "It's because we're returning a subtype of StateStore now, but the stores are still internally not typed, so someone still has to cast it.\nFor example, here's what the old API was like:\nKeyValueStore<String, Integer> store = (KeyValueStore<String, Integer>) context.getStateStore(\"asdf\");\nThe cast is in the user's code.\nNow, it will be like this:\nKeyValueStore<String, Integer> store = context.getStateStore(\"asdf\");\nThe return type is resolved by the type system, and the cast moves into our code.\nJust to clarify, there's no extra safety here, it's a cast either way. It's just more convenient for callers not to have to cast on their end.", "author": "vvcephei", "createdAt": "2020-10-02T03:27:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDM5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYwNTU3OA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498605578", "bodyText": "Got it, thanks!", "author": "guozhangwang", "createdAt": "2020-10-02T03:32:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU2NDM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYxMDIxOQ==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498610219", "bodyText": "(I'll offer an opinion here because I stressed the importance of it on the mailing list, though I do think this is already pretty good.  Feel free to take it or leave it, it's just a rewording that may or may not add clarity)\n\nNote that as long as the processor is receiving a record downstream of a Source\n\nIsn't every record received downstream of a source one way or another?  IMO the up front emphasis should be on how the record came from the upstream processor.  My attempt:\n\nThe record metadata is defined if the record currently being processed was passed through parent processor(s) directly from a Source.  It is undefined if the record was forwarded from within a Punctuator.", "author": "pgwhalen", "createdAt": "2020-10-02T04:03:00Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/api/ProcessorContext.java", "diffHunk": "@@ -55,6 +52,16 @@\n      */\n     TaskId taskId();\n \n+    /**\n+     * The metadata of the record, if it is defined. Note that as long as the processor is", "originalCommit": "1bdf5c8c2da3d69521d2fe258f97e6836d74fa70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODkwNDUyNg==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498904526", "bodyText": "Thanks, @pgwhalen !\nI agree, the docs I wrote were a little too terse. How about this:\n    /**\n     * The metadata of the source record, if is one. Processors may be invoked to\n     * process a source record from an input topic, to run a scheduled punctuation\n     * (see {@link ProcessorContext#schedule(Duration, PunctuationType, Punctuator)} ),\n     * or because a parent processor called {@link ProcessorContext#forward(Record)}.\n     * <p>\n     * In the case of a punctuation, there is no source record, so this metadata would be\n     * undefined. Note that when a punctuator invokes {@link ProcessorContext#forward(Record)},\n     * downstream processors will receive the forwarded record as a regular\n     * {@link Processor#process(Record)} invocation. In other words, it wouldn't be apparent to\n     * downstream processors whether or not the record being processed came from an input topic\n     * or punctuation and therefore whether or not this metadata is defined. This is why\n     * the return type of this method is {@link Optional}.\n     * <p>\n     * If there is any possibility of punctuators upstream, any access\n     * to this field should consider the case of\n     * \"{@code recordMetadata().isPresent() == false}\".\n     * Of course, it would be safest to always guard this condition.\n     */", "author": "vvcephei", "createdAt": "2020-10-02T15:48:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYxMDIxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODkwNTY2OA==", "url": "https://github.com/apache/kafka/pull/9361#discussion_r498905668", "bodyText": "I've just updated the PR with this change.", "author": "vvcephei", "createdAt": "2020-10-02T15:50:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODYxMDIxOQ=="}], "type": "inlineReview"}, {"oid": "a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1", "url": "https://github.com/apache/kafka/commit/a8de75f6f16cf8bdcccbcb1bc1fc0a11dd40c1d1", "message": "docs", "committedDate": "2020-10-02T15:51:29Z", "type": "commit"}]}