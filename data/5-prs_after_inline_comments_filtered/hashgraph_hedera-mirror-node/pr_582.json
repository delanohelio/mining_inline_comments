{"pr_number": 582, "pr_title": "JUnit parser performance tests for 1k tps record files", "pr_createdAt": "2020-03-04T15:09:55Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/582", "timeline": [{"oid": "3feaf18046299556ca6d5a3872b11a68b902394d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3feaf18046299556ca6d5a3872b11a68b902394d", "message": "Junit parser performance tests for 1k tps record files\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-04T04:00:45Z", "type": "commit"}, {"oid": "476f0434f9b175cdf193923841525534733594f4", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/476f0434f9b175cdf193923841525534733594f4", "message": "Add circle ci maven_ perf stage\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-04T15:19:55Z", "type": "commit"}, {"oid": "a6e4bd903cd1353fa627b29bba5c9bbf6ceb39d7", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/a6e4bd903cd1353fa627b29bba5c9bbf6ceb39d7", "message": "Updated circleci config with restore and save maven_cache. Also moved perf to end\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-04T15:26:14Z", "type": "commit"}, {"oid": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "message": "Added missing checkout step for perf_maven\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-04T15:37:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg2ODQ1OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387868459", "bodyText": "do we want to keep this general (and add balance tests here in future) or keep it just for record and isolate balance test in other class?", "author": "apeksharma", "createdAt": "2020-03-04T18:58:18Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4NTk3MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387885970", "bodyText": "It should be record specific. Recommend adding Record to name", "author": "steven-sheehy", "createdAt": "2020-03-04T19:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg2ODQ1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk0MzY5Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387943693", "bodyText": "I envisioned multiple classes, so the later.", "author": "Nana-EC", "createdAt": "2020-03-04T21:25:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg2ODQ1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3MTAxNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387871016", "bodyText": "we can make filter string a param and move rest of the code here to parse(..) too", "author": "apeksharma", "createdAt": "2020-03-04T19:02:59Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @Value(\"classpath:data\")\n+    Path testPath;\n+\n+    @Resource\n+    private RecordFileParser recordFileParser;\n+\n+    @Resource\n+    private RecordParserProperties parserProperties;\n+\n+    private FileCopier fileCopier;\n+\n+    private StreamType streamType;\n+\n+    @BeforeEach\n+    void before() {\n+        streamType = parserProperties.getStreamType();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath);\n+        parserProperties.init();\n+    }\n+\n+    @Test\n+    void parseAndIngestSingleFile5000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3NzU0Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387877547", "bodyText": "imo, just this one  is enough.\nOthers will have too less of runtime and data (data point for single file) to be of much significance.\nJust this test is perfect, one run of this will be good enough data point to be significant since it's ingesting multiple files(so in a way, it's aggregate of multiple data points), and running for extended time.\nUp to you, just a suggestion.", "author": "apeksharma", "createdAt": "2020-03-04T19:15:22Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @Value(\"classpath:data\")\n+    Path testPath;\n+\n+    @Resource\n+    private RecordFileParser recordFileParser;\n+\n+    @Resource\n+    private RecordParserProperties parserProperties;\n+\n+    private FileCopier fileCopier;\n+\n+    private StreamType streamType;\n+\n+    @BeforeEach\n+    void before() {\n+        streamType = parserProperties.getStreamType();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath);\n+        parserProperties.init();\n+    }\n+\n+    @Test\n+    void parseAndIngestSingleFile5000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")\n+                .filterFiles(\"2020-02-09T18_30_00.000084Z.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        fileCopier.copy();\n+        parse(40);\n+    }\n+\n+    @Test\n+    void parseAndIngestMultipleFiles10000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")\n+                .filterFiles(\"2020-02-09T18_30_0*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        fileCopier.copy();\n+        parse(70);\n+    }\n+\n+    @Test\n+    void parseAndIngestMultipleFiles60000Transactions() throws Exception {", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5MTQ1MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387891450", "bodyText": "Agreed", "author": "steven-sheehy", "createdAt": "2020-03-04T19:40:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3NzU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk0NTAxMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387945013", "bodyText": "I thought the 5000 and 10000 case might offer smaller units that you can use to estimate performance when you're not able to run tests or need to do a quick estimate e.g. we've seen 5k use of a record file produced at 1k tps take x, so in y scenario it might take z.\nGranted this assumes linear relationship which may not hold with the the table indexes", "author": "Nana-EC", "createdAt": "2020-03-04T21:28:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3NzU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk1MzM1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387953351", "bodyText": "We don't need to worry about non-automated use cases like quick estimates. Goal here is to push multiple files through to validate performance doesn't regress  and run those tests on every commit or nightly if tests take too long to run.", "author": "steven-sheehy", "createdAt": "2020-03-04T21:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3NzU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAxMTA3Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r388011077", "bodyText": "Reduced it to the single one", "author": "Nana-EC", "createdAt": "2020-03-05T00:16:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg3NzU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4NjM1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387886351", "bodyText": "It's more important to run cleanup before than after, but can just add both", "author": "steven-sheehy", "createdAt": "2020-03-04T19:31:04Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk5ODcxMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387998713", "bodyText": "Will add", "author": "Nana-EC", "createdAt": "2020-03-04T23:37:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4NjM1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4ODg5MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387888891", "bodyText": "Recommend just using @Timeout on each test method and removing this parse method. Logging not necessary", "author": "steven-sheehy", "createdAt": "2020-03-04T19:35:46Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @Value(\"classpath:data\")\n+    Path testPath;\n+\n+    @Resource\n+    private RecordFileParser recordFileParser;\n+\n+    @Resource\n+    private RecordParserProperties parserProperties;\n+\n+    private FileCopier fileCopier;\n+\n+    private StreamType streamType;\n+\n+    @BeforeEach\n+    void before() {\n+        streamType = parserProperties.getStreamType();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath);\n+        parserProperties.init();\n+    }\n+\n+    @Test\n+    void parseAndIngestSingleFile5000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")\n+                .filterFiles(\"2020-02-09T18_30_00.000084Z.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        fileCopier.copy();\n+        parse(40);\n+    }\n+\n+    @Test\n+    void parseAndIngestMultipleFiles10000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")\n+                .filterFiles(\"2020-02-09T18_30_0*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        fileCopier.copy();\n+        parse(70);\n+    }\n+\n+    @Test\n+    void parseAndIngestMultipleFiles60000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")\n+                .filterFiles(\"*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        fileCopier.copy();\n+        parse(400);\n+    }\n+\n+    private void parse(long parseTimeThreshold) {", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk5ODY3Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387998672", "bodyText": "Good idea", "author": "Nana-EC", "createdAt": "2020-03-04T23:37:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4ODg5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4OTM2Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387889363", "bodyText": "There should be some sort of warmup in a @BeforeAll or @BeforeEach to get accurate performance numbers", "author": "steven-sheehy", "createdAt": "2020-03-04T19:36:39Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @Value(\"classpath:data\")\n+    Path testPath;\n+\n+    @Resource\n+    private RecordFileParser recordFileParser;\n+\n+    @Resource\n+    private RecordParserProperties parserProperties;\n+\n+    private FileCopier fileCopier;\n+\n+    private StreamType streamType;\n+", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTk3MDI2Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r389970267", "bodyText": "Done", "author": "Nana-EC", "createdAt": "2020-03-09T21:24:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg4OTM2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5MTUzNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387891537", "bodyText": "These files should be in a different folder than the normal v1 and v2 tests. Suggestion: src/test/resources/data/recordstreams/performance/. It doesn't need the name of the node account id.", "author": "steven-sheehy", "createdAt": "2020-03-04T19:40:38Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @Value(\"classpath:data\")\n+    Path testPath;\n+\n+    @Resource\n+    private RecordFileParser recordFileParser;\n+\n+    @Resource\n+    private RecordParserProperties parserProperties;\n+\n+    private FileCopier fileCopier;\n+\n+    private StreamType streamType;\n+\n+    @BeforeEach\n+    void before() {\n+        streamType = parserProperties.getStreamType();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath);\n+        parserProperties.init();\n+    }\n+\n+    @Test\n+    void parseAndIngestSingleFile5000Transactions() throws Exception {\n+        fileCopier = FileCopier.create(testPath, dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3_1k_tps\")", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODAxMTE1NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r388011155", "bodyText": "Done", "author": "Nana-EC", "createdAt": "2020-03-05T00:17:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5MTUzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5NjkxNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387896917", "bodyText": "@Tag(\"performance\"). Also, since most of our tests can be considered integration tests (they all extend IntegrationTest and start a DB), can we rename this to end in test? I think if you use groups and tags to include/exclude maven failsafe it should pick that suffix up.", "author": "steven-sheehy", "createdAt": "2020-03-04T19:50:17Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/benchmark/ParserIngestionIT.java", "diffHunk": "@@ -0,0 +1,87 @@\n+package com.hedera.mirror.importer.benchmark;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import com.google.common.base.Stopwatch;\n+import java.nio.file.Path;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Resource;\n+import lombok.extern.log4j.Log4j2;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.springframework.beans.factory.annotation.Value;\n+import org.springframework.test.context.jdbc.Sql;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.IntegrationTest;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.record.RecordFileParser;\n+import com.hedera.mirror.importer.parser.record.RecordParserProperties;\n+\n+@Log4j2\n+@Sql(executionPhase = Sql.ExecutionPhase.AFTER_TEST_METHOD, scripts = \"classpath:db/scripts/cleanup.sql\")\n+public class ParserIngestionIT extends IntegrationTest {", "originalCommit": "285a13d37ca7674e254ebe7ddc4f75b52bf2e5fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzk5MjIwNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/582#discussion_r387992207", "bodyText": "Same comment as above. Had tried with a @tag(\"benchmark\") with no luck but might have been blocked by other issues. Will revisit to get it working.", "author": "Nana-EC", "createdAt": "2020-03-04T23:18:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg5NjkxNw=="}], "type": "inlineReview"}, {"oid": "d5f6ee6d65a19c290e6d3c69ded775be60cd9076", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/d5f6ee6d65a19c290e6d3c69ded775be60cd9076", "message": "Reduced perf test down to 60k transactions. Renamed file with Record.\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-05T00:12:41Z", "type": "commit"}, {"oid": "18b056ac44385d138e7f0e7cbf94db8d20150a99", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/18b056ac44385d138e7f0e7cbf94db8d20150a99", "message": "Utilized junit5 tag feature instead of pom properties to filter\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-05T17:44:47Z", "type": "commit"}, {"oid": "6fd98e06fc2e3b30c2727f6f0cf6bbe7f30b90ad", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/6fd98e06fc2e3b30c2727f6f0cf6bbe7f30b90ad", "message": "Used special mapping keys for docker alias in circle ci yaml\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-05T21:51:25Z", "type": "commit"}, {"oid": "747b7c3e4a049a8e303c0d73582532ef5e153eea", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/747b7c3e4a049a8e303c0d73582532ef5e153eea", "message": "Added warmUp method\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-09T21:22:55Z", "type": "commit"}, {"oid": "5bb6d17bdf03bce2f253c9daace8f63801f22467", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/5bb6d17bdf03bce2f253c9daace8f63801f22467", "message": "Fixed parseAndIngestMultipleFiles60000Transactions test calling single file\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-09T21:26:03Z", "type": "commit"}, {"oid": "bd12f1203513838b9927cb1ba39fbb1284f4dd3f", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/bd12f1203513838b9927cb1ba39fbb1284f4dd3f", "message": "Removing skip.integration.tests and skip.unit.tests properties that are no longer used\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-03-09T21:55:02Z", "type": "commit"}]}