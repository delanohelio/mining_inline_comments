{"pr_number": 585, "pr_title": "Move file handling logic from RecordItemParser to RecordFileParser", "pr_createdAt": "2020-03-05T01:11:16Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/585", "timeline": [{"oid": "6803b540b924cd29d57d8397b72a7126ec97151b", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/6803b540b924cd29d57d8397b72a7126ec97151b", "message": "Move file handling logic from RecordItemParser to RecordFileParser\n\n- Move connection ownership to RecordFileParser\n  - initConnection: earlier RecordItemParser.start()\n  - closeConnection: earlier RecordItemParser.finish()\n- Move db file handling to RecordFileParser\n  - initFile\n  - closeFileAndCommit: eariler RecordItemParser.completeFile()\n  - Move file testing from RecordItemParserTest to RecordFileParserTest\n- RecordItemParser is completely agnostic of 'file' concept now.\n- Remove checks for recordFileRepository from RecordItemParser tests\n\nFollowup: Remove fileId in t_transactions.\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-05T01:10:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDM2OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388580368", "bodyText": "I don't agree with this change, which is apparently the entire purpose of this PR. The connection should be internal state managed by the PostgresWritingRecordParsedItemHandler. With connection pools, opening and closing it for every file doesn't mean a new connection is actually opened or closed, negating any performance benefits.", "author": "steven-sheehy", "createdAt": "2020-03-05T21:37:00Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -64,6 +71,8 @@\n     private final RecordParserProperties parserProperties;\n     private final MeterRegistry meterRegistry;\n     private final RecordItemParser recordItemParser;\n+    private final PostgresWritingRecordParsedItemHandler postgresWriter;\n+    private Connection connect;", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYxMDYzMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388610630", "bodyText": "I agree with this. The DB connection logic should stay within the PostrgresWriter and not be known to RecordFileParser.", "author": "Nana-EC", "createdAt": "2020-03-05T22:45:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDM2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MDQ2Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389080467", "bodyText": "absolutely, i was planning to change to per-file connection in followup (had the change in a local branch). Well, it's in this PR now.", "author": "apeksharma", "createdAt": "2020-03-06T18:51:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDgwOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388580809", "bodyText": "The RecordFileParser should not be tightly coupled to a concrete implementation of ParsedItemHandler", "author": "steven-sheehy", "createdAt": "2020-03-05T21:37:54Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -64,6 +71,8 @@\n     private final RecordParserProperties parserProperties;\n     private final MeterRegistry meterRegistry;\n     private final RecordItemParser recordItemParser;\n+    private final PostgresWritingRecordParsedItemHandler postgresWriter;", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYxNDI4Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388614283", "bodyText": "Would you suggest an interfaced wrapper, that hides the fact that it's Postgres and allows for it to be configureable without RecordFileParser knowing the difference?", "author": "Nana-EC", "createdAt": "2020-03-05T22:54:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDgwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYzNzcwNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388637706", "bodyText": "There already is an interface wrapper: ParsedItemHandler", "author": "steven-sheehy", "createdAt": "2020-03-06T00:11:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDgwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MDc1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389080753", "bodyText": "after latest change, it now only depends on interfaces.", "author": "apeksharma", "createdAt": "2020-03-06T18:52:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MTY5OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388581698", "bodyText": "This method should be moved to a repository to separate db logic from application logic. This method can be used as is or better yet, the f_file_create be deleted and repositories used directly. There can be an argument to using copymanager for performance reasons in itemhandlers, but record files only occur once per file and can definitely use repository. Stored procedures can't participate in an existing transaction anyway so have it using the same connection and rolling back, etc is pointless.", "author": "steven-sheehy", "createdAt": "2020-03-05T21:39:55Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -127,16 +138,85 @@ public static String readPrevFileHash(String fileName) {\n         return null;\n     }\n \n-    private RecordItemParser.INIT_RESULT initFile(String filename) {\n-        return recordItemParser.initFile(filename);\n+    /**\n+     * @return 0 if row with given filename already exists, otherwise id of newly added row.\n+     *         In case of failure, returns -1;\n+     */\n+    public long initFile(String fileName) {\n+        try {\n+            long fileId;\n+\n+            try (CallableStatement fileCreate = connect.prepareCall(\"{? = call f_file_create( ? ) }\")) {", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MTEzMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389081130", "bodyText": "will be done in followup where fileID is being removed. In this PR, just moving the logic as is.", "author": "apeksharma", "createdAt": "2020-03-06T18:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MTY5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MTg5Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388581896", "bodyText": "Should be private", "author": "steven-sheehy", "createdAt": "2020-03-05T21:40:23Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -127,16 +138,85 @@ public static String readPrevFileHash(String fileName) {\n         return null;\n     }\n \n-    private RecordItemParser.INIT_RESULT initFile(String filename) {\n-        return recordItemParser.initFile(filename);\n+    /**\n+     * @return 0 if row with given filename already exists, otherwise id of newly added row.\n+     *         In case of failure, returns -1;\n+     */\n+    public long initFile(String fileName) {", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MjAyOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388582028", "bodyText": "private", "author": "steven-sheehy", "createdAt": "2020-03-05T21:40:43Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -127,16 +138,85 @@ public static String readPrevFileHash(String fileName) {\n         return null;\n     }\n \n-    private RecordItemParser.INIT_RESULT initFile(String filename) {\n-        return recordItemParser.initFile(filename);\n+    /**\n+     * @return 0 if row with given filename already exists, otherwise id of newly added row.\n+     *         In case of failure, returns -1;\n+     */\n+    public long initFile(String fileName) {\n+        try {\n+            long fileId;\n+\n+            try (CallableStatement fileCreate = connect.prepareCall(\"{? = call f_file_create( ? ) }\")) {\n+                fileCreate.registerOutParameter(1, Types.BIGINT);\n+                fileCreate.setString(2, fileName);\n+                fileCreate.execute();\n+                fileId = fileCreate.getLong(1);\n+            }\n+\n+            if (fileId == 0) {\n+                log.trace(\"File {} already exists in the database.\", fileName);\n+            } else {\n+                log.trace(\"Added file {} to the database.\", fileName);\n+            }\n+            return fileId;\n+        } catch (SQLException e) {\n+            log.error(\"Error saving file in database: {}\",  fileName, e);\n+            return -1L;\n+        }\n+    }\n+\n+    public void closeFileAndCommit(long fileId, String fileHash, String previousHash) throws SQLException {", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MzAyMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388583022", "bodyText": "Same statement above about repository", "author": "steven-sheehy", "createdAt": "2020-03-05T21:42:49Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -127,16 +138,85 @@ public static String readPrevFileHash(String fileName) {\n         return null;\n     }\n \n-    private RecordItemParser.INIT_RESULT initFile(String filename) {\n-        return recordItemParser.initFile(filename);\n+    /**\n+     * @return 0 if row with given filename already exists, otherwise id of newly added row.\n+     *         In case of failure, returns -1;\n+     */\n+    public long initFile(String fileName) {\n+        try {\n+            long fileId;\n+\n+            try (CallableStatement fileCreate = connect.prepareCall(\"{? = call f_file_create( ? ) }\")) {\n+                fileCreate.registerOutParameter(1, Types.BIGINT);\n+                fileCreate.setString(2, fileName);\n+                fileCreate.execute();\n+                fileId = fileCreate.getLong(1);\n+            }\n+\n+            if (fileId == 0) {\n+                log.trace(\"File {} already exists in the database.\", fileName);\n+            } else {\n+                log.trace(\"Added file {} to the database.\", fileName);\n+            }\n+            return fileId;\n+        } catch (SQLException e) {\n+            log.error(\"Error saving file in database: {}\",  fileName, e);\n+            return -1L;\n+        }\n+    }\n+\n+    public void closeFileAndCommit(long fileId, String fileHash, String previousHash) throws SQLException {\n+        try (CallableStatement fileClose = connect.prepareCall(\"{call f_file_complete( ?, ?, ? ) }\")) {", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MTg2OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389081868", "bodyText": "let's tackle t_record_files related parts in followup. Moving it as in for now.", "author": "apeksharma", "createdAt": "2020-03-06T18:54:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MzAyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4NTUxMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388585512", "bodyText": "Should not increase visibility of methods just for testing. Just test the parse method", "author": "steven-sheehy", "createdAt": "2020-03-05T21:48:01Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -149,12 +229,12 @@ private void rollback() {\n      * @return return boolean indicating method success\n      * @throws Exception\n      */\n-    private boolean loadRecordFile(String fileName, InputStream inputStream, String expectedPrevFileHash,\n+    public boolean loadRecordFile(String fileName, InputStream inputStream, String expectedPrevFileHash,", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODYxNTYwOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388615608", "bodyText": "I do see the desire to improve testability. Can we utilize a different scope that allows for testing but doesn't open it up publicly?", "author": "Nana-EC", "createdAt": "2020-03-05T22:58:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4NTUxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MjcxMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389082713", "bodyText": "we'll be changing RecordFileParser to following (from design) where this function will be public, so i believe it's okay for now.\npublic class RecordFileParser {\n\n    private final RecordItemListener recordItemListener;  // injected dependency\n    private final RecordParsedItemHandler recordParsedItemHandler;  // injected dependency\n\n    void onFile(StreamFileData streamFileData) {\n        // process stream file\n    }\n}", "author": "apeksharma", "createdAt": "2020-03-06T18:56:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4NTUxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4Njk2Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388586963", "bodyText": "This logic is unnecessarily complex (before and after change). It would be a lot clearer for initFile to return a Optional<RecordFile>.", "author": "steven-sheehy", "createdAt": "2020-03-05T21:50:09Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -149,12 +229,12 @@ private void rollback() {\n      * @return return boolean indicating method success\n      * @throws Exception\n      */\n-    private boolean loadRecordFile(String fileName, InputStream inputStream, String expectedPrevFileHash,\n+    public boolean loadRecordFile(String fileName, InputStream inputStream, String expectedPrevFileHash,\n                                    String thisFileHash) {\n-        var result = initFile(fileName);\n-        if (result == RecordItemParser.INIT_RESULT.SKIP) {\n+        var fileId = initFile(fileName);", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MzEyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389083126", "bodyText": "change to Optional and exception based failing.\nCan do further improvements later.", "author": "apeksharma", "createdAt": "2020-03-06T18:57:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4Njk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4NzgwOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388587809", "bodyText": "RecordItemParser should not know about a concrete implementation of ParsedItemHandler. This negates the whole purpose of this parser refactoring: to easily swap out implementations or support multiple different implementations concurrently (e.g. send to postgres and bigquery).", "author": "steven-sheehy", "createdAt": "2020-03-05T21:52:01Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordItemParser.java", "diffHunk": "@@ -84,10 +78,6 @@\n     private final Predicate<com.hedera.mirror.importer.domain.Transaction> transactionFilter;\n     private final PostgresWritingRecordParsedItemHandler postgresWriter;", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MzI1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389083251", "bodyText": "after latest changes, it depends on only interface.", "author": "apeksharma", "createdAt": "2020-03-06T18:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4NzgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MzgyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388593826", "bodyText": "If you're removing t_transactions.fk_rec_file_id in the future, it makes t_record_files pretty pointless. Have we checked with BRD if they're not using it so we can remove the table entirely? Or if we need to keep it do we need to add start and end transaction consensus timestamp to it so the associated transactions can be calculated that way?", "author": "steven-sheehy", "createdAt": "2020-03-05T22:03:25Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/Transaction.java", "diffHunk": "@@ -64,7 +64,9 @@\n     @ManyToOne(cascade = CascadeType.PERSIST)\n     private Entities entity;\n \n+    // Deprecated, value set to 0 until removed.\n     @Column(name = \"fk_rec_file_id\")\n+    @Deprecated(forRemoval = true, since = \"v0.7.0\")", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MzM5OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389083398", "bodyText": "in followup :)", "author": "apeksharma", "createdAt": "2020-03-06T18:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MzgyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQxMTE5Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r392411196", "bodyText": "#600", "author": "apeksharma", "createdAt": "2020-03-13T18:50:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5MzgyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NDIzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r388594232", "bodyText": "This should be private and not leaked to upper layers", "author": "steven-sheehy", "createdAt": "2020-03-05T22:04:22Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/PostgresWritingRecordParsedItemHandler.java", "diffHunk": "@@ -90,16 +90,12 @@ void initSqlStatements(Connection connection) throws ParserSQLException {\n         }\n     }\n \n-    public void finish() {\n-        closeStatements();\n-    }\n-\n     @Override\n     public void onFileComplete() {\n         executeBatches();\n     }\n \n-    private void closeStatements() {\n+    public void closeStatements() {", "originalCommit": "6803b540b924cd29d57d8397b72a7126ec97151b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "44baf34f4535439c52d2787105db64476b3bce20", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/44baf34f4535439c52d2787105db64476b3bce20", "message": "address review comments. working of fixing tests. early preview of changes for now\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-06T18:59:05Z", "type": "commit"}, {"oid": "075404b0bfb8a1856d87a6c219f7874f3c2488ed", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/075404b0bfb8a1856d87a6c219f7874f3c2488ed", "message": "fix tests\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-06T23:02:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4ODYzNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389188636", "bodyText": "any improvements suggestions here?\nwould like to make this neater in next PR ('fileId removal')", "author": "apeksharma", "createdAt": "2020-03-06T23:14:37Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -127,43 +136,33 @@ public static String readPrevFileHash(String fileName) {\n         return null;\n     }\n \n-    private RecordItemParser.INIT_RESULT initFile(String filename) {\n-        return recordItemParser.initFile(filename);\n-    }\n-\n-    private void closeFileAndCommit(String fileHash, String previousHash) throws SQLException {\n-        recordItemParser.completeFile(fileHash, previousHash);\n-    }\n-\n-    private void rollback() {\n-        recordItemParser.rollback();\n-    }\n-\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param fileName             the name of record file to read\n-     * @param inputStream          input stream of bytes in the record file\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n+     * @param streamFileData containing information about file to be processed\n      * @return return boolean indicating method success\n      * @throws Exception\n      */\n-    private boolean loadRecordFile(String fileName, InputStream inputStream, String expectedPrevFileHash,\n-                                   String thisFileHash) {\n-        var result = initFile(fileName);\n-        if (result == RecordItemParser.INIT_RESULT.SKIP) {\n-            return true; // skip this fle\n-        } else if (result == RecordItemParser.INIT_RESULT.FAIL) {\n-            rollback();\n+    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+        String fileName = streamFileData.getFilename();", "originalCommit": "075404b0bfb8a1856d87a6c219f7874f3c2488ed", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIxNjE0NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389216145", "bodyText": "For next PR, I would suggest not returning boolean and let exceptions propagate. The current hash should be loaded within RecordFileParser and passed to it. I would also suggest not keeping previous hash around and passing to loadRecordFile. This can be retrieved from applicationStatus each time. While slightly less efficient, it makes the interface cleaner and the parser more self contained and less coupled.", "author": "steven-sheehy", "createdAt": "2020-03-07T01:51:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4ODYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTM5NDA5OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389394099", "bodyText": "Followup: #587", "author": "apeksharma", "createdAt": "2020-03-08T18:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4ODYzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4OTc4Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389189787", "bodyText": "mocked in test.\nIf there's a better way, let's revisit this when moving to repository.", "author": "apeksharma", "createdAt": "2020-03-06T23:19:06Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/PostgresWritingRecordParsedItemHandler.java", "diffHunk": "@@ -52,8 +60,88 @@\n     private PreparedStatement sqlInsertLiveHashes;\n     private PreparedStatement sqlInsertTopicMessage;\n     private final PostgresWriterProperties properties;\n+    private final DataSource dataSource;", "originalCommit": "075404b0bfb8a1856d87a6c219f7874f3c2488ed", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d80f4ec826688c6f5fbf927f1f82acb287cdbbf9", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/d80f4ec826688c6f5fbf927f1f82acb287cdbbf9", "message": "Add more tests.\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-06T23:47:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMzIyOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389203229", "bodyText": "given when then is the typical bdd expression used.", "author": "steven-sheehy", "createdAt": "2020-03-07T00:21:39Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -73,88 +94,177 @@ void before() {\n                 .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n                 .filterFiles(\"*.rcd\")\n                 .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(0L, file1.getPath(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"\");\n+        recordFile2 = new RecordFile(0L, file2.getPath(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash());\n     }\n \n-    @Test\n-    void parse() throws Exception {\n-        fileCopier.copy();\n-        recordFileParser.parse();\n+    // Asserts that recordStreamFileListener.onStart is called exactly with given fileNames.\n+    private void assertOnStart(String... fileNames) {\n+        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n+        verify(recordStreamFileListener, times(fileNames.length)).onStart(captor.capture());\n+        List<StreamFileData> actualArgs = captor.getAllValues();\n+        assertThat(actualArgs)\n+                .extracting(StreamFileData::getFilename)\n+                .contains(fileNames);\n+    }\n \n+    // Asserts that recordStreamFileListener.onEnd is called exactly with given params, in given order\n+    private void assertOnEnd(RecordFile... recordFiles) {\n+        ArgumentCaptor<RecordFile> captor = ArgumentCaptor.forClass(RecordFile.class);\n+        verify(recordStreamFileListener, times(recordFiles.length)).onEnd(captor.capture());\n+        List<RecordFile> actualArgs = captor.getAllValues();\n+        for (int i = 0; i < recordFiles.length; i++) {\n+            RecordFile actual = actualArgs.get(i);\n+            RecordFile expected = recordFiles[i];\n+            assertEquals(expected.getId(), actual.getId());\n+            assertEquals(expected.getName(), actual.getName());\n+            assertEquals(expected.getFileHash(), actual.getFileHash());\n+            assertEquals(expected.getPreviousHash(), actual.getPreviousHash());\n+        }\n+    }\n+\n+    // Asserts that parsed directory contains exactly the files with given fileNames\n+    private void assertParsedFiles(String... fileNames) throws Exception {\n         assertThat(Files.walk(parserProperties.getParsedPath()))\n                 .filteredOn(p -> !p.toFile().isDirectory())\n-                .hasSize(2)\n+                .hasSize(fileNames.length)\n                 .extracting(Path::getFileName)\n-                .contains(Paths.get(\"2019-08-30T18_10_05.249678Z.rcd\"))\n-                .contains(Paths.get(\"2019-08-30T18_10_00.419072Z.rcd\"));\n+                .extracting(Path::toString)\n+                .contains(fileNames);\n+    }\n \n-        Assertions.assertThat(transactionRepository.findAll())\n-                .hasSize(19 + 15)\n-                .extracting(Transaction::getType)\n-                .containsOnlyElementsOf(Sets.newHashSet(11, 12, 14));\n+    @Test\n+    void parse() throws Exception {\n+        // setup\n+        fileCopier.copy();\n+        when(recordStreamFileListener.onStart(any())).thenAnswer(invocation -> {\n+            StreamFileData streamFileData = invocation.getArgument(0, StreamFileData.class);\n+            RecordFile recordFile = new RecordFile();\n+            recordFile.setId(0L);\n+            recordFile.setName(streamFileData.getFilename());\n+            return Optional.of(recordFile);\n+        });\n+\n+        // when\n+        recordFileParser.parse();\n+\n+        // expect\n+        assertParsedFiles(file1.getName(), file2.getName());\n+        verify(recordItemListener, times(NUM_TXNS_FILE_1 + NUM_TXNS_FILE_2)).onItem(any());\n+        assertOnStart(file1.getPath(), file2.getPath());\n+        assertOnEnd(recordFile1, recordFile2);\n     }\n \n     @Test\n     void disabled() throws Exception {\n+        // setup\n         parserProperties.setEnabled(false);\n         fileCopier.copy();\n+\n+        // when\n         recordFileParser.parse();\n-        assertThat(Files.walk(parserProperties.getParsedPath())).filteredOn(p -> !p.toFile().isDirectory()).hasSize(0);\n-        assertThat(transactionRepository.count()).isEqualTo(0L);\n+\n+        // expect\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verifyNoInteractions(recordStreamFileListener);\n     }\n \n     @Test\n     void noFiles() throws Exception {\n+        // when\n         recordFileParser.parse();\n-        assertThat(Files.walk(parserProperties.getParsedPath())).filteredOn(p -> !p.toFile().isDirectory()).hasSize(0);\n-        assertThat(transactionRepository.count()).isEqualTo(0L);\n+\n+        // expect\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verifyNoInteractions(recordStreamFileListener);\n     }\n \n     @Test\n     void invalidFile() throws Exception {\n-        File recordFile = dataPath.resolve(streamType.getPath()).resolve(streamType.getValid())\n-                .resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n-        FileUtils.writeStringToFile(recordFile, \"corrupt\", \"UTF-8\");\n+        // setup", "originalCommit": "44baf34f4535439c52d2787105db64476b3bce20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIxMjg2Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389212863", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-07T01:23:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMzIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMzM2MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389203360", "bodyText": "helpers should be at the bottom of the class so that tests are more visible", "author": "steven-sheehy", "createdAt": "2020-03-07T00:22:26Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -73,88 +94,177 @@ void before() {\n                 .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n                 .filterFiles(\"*.rcd\")\n                 .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(0L, file1.getPath(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"\");\n+        recordFile2 = new RecordFile(0L, file2.getPath(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash());\n     }\n \n-    @Test\n-    void parse() throws Exception {\n-        fileCopier.copy();\n-        recordFileParser.parse();\n+    // Asserts that recordStreamFileListener.onStart is called exactly with given fileNames.\n+    private void assertOnStart(String... fileNames) {", "originalCommit": "44baf34f4535439c52d2787105db64476b3bce20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIxMjg0MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389212841", "bodyText": "done.", "author": "apeksharma", "createdAt": "2020-03-07T01:23:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwMzM2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNTQwOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389205408", "bodyText": "This should return Optional.empty() to match the previous behavior of skipping if already exists", "author": "steven-sheehy", "createdAt": "2020-03-07T00:33:43Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/PostgresWritingRecordParsedItemHandler.java", "diffHunk": "@@ -52,8 +60,88 @@\n     private PreparedStatement sqlInsertLiveHashes;\n     private PreparedStatement sqlInsertTopicMessage;\n     private final PostgresWriterProperties properties;\n+    private final DataSource dataSource;\n+    private Connection connection;\n \n-    void initSqlStatements(Connection connection) throws ParserSQLException {\n+    @Override\n+    public Optional<RecordFile> onStart(StreamFileData streamFileData) {\n+        String fileName = streamFileData.getFilename();\n+        try {\n+            initConnectionAndStatements();\n+            long fileId;\n+\n+            try (CallableStatement fileCreate = connection.prepareCall(\"{? = call f_file_create( ? ) }\")) {\n+                fileCreate.registerOutParameter(1, Types.BIGINT);\n+                fileCreate.setString(2, fileName);\n+                fileCreate.execute();\n+                fileId = fileCreate.getLong(1);\n+            }\n+\n+            if (fileId == 0) {\n+                log.trace(\"File {} already exists in the database.\", fileName);\n+                closeConnectionAndStatements();", "originalCommit": "44baf34f4535439c52d2787105db64476b3bce20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIxMjc3OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389212778", "bodyText": "emm, it's returning in next line?\nit wasn't earlier though, i believe you saw it when it wasn't :)", "author": "apeksharma", "createdAt": "2020-03-07T01:23:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNTQwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIyNTE2Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389225162", "bodyText": "You're right, didn't see your previous commit.", "author": "steven-sheehy", "createdAt": "2020-03-07T03:54:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNTQwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNjMzOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389206339", "bodyText": "None of these methods need to be overridden in the sub-interface. Please remove", "author": "steven-sheehy", "createdAt": "2020-03-07T00:38:50Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/RecordStreamFileListener.java", "diffHunk": "@@ -0,0 +1,18 @@\n+package com.hedera.mirror.importer.parser;\n+\n+import java.util.Optional;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.exception.ImporterException;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+\n+public interface RecordStreamFileListener extends StreamFileListener<RecordFile> {\n+    @Override", "originalCommit": "44baf34f4535439c52d2787105db64476b3bce20", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIxMjgwNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389212806", "bodyText": "oops.", "author": "apeksharma", "createdAt": "2020-03-07T01:23:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNjMzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIyNTMxOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389225318", "bodyText": "You just removed the override annotations. I meant the methods themselves don't need to be there as they're in the parent and it uses generics. I won't block this PR for that though, so please fix in follow up.", "author": "steven-sheehy", "createdAt": "2020-03-07T03:56:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNjMzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTI5ODQ0NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/585#discussion_r389298444", "bodyText": "\ud83d\udc4d included in followup PR.", "author": "apeksharma", "createdAt": "2020-03-07T17:37:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTIwNjMzOQ=="}], "type": "inlineReview"}, {"oid": "57da8b30b228e339654b930dec83efc1152c6c19", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/57da8b30b228e339654b930dec83efc1152c6c19", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>", "committedDate": "2020-03-07T01:40:54Z", "type": "commit"}]}