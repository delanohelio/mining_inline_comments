{"pr_number": 597, "pr_title": "Switch from R2DBC to Hibernate", "pr_createdAt": "2020-03-13T15:54:36Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/597", "timeline": [{"oid": "3998672f56be9823ab4c3ae819f8868e194182b4", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3998672f56be9823ab4c3ae819f8868e194182b4", "message": "Remove R2DBC in favor of Hibernate/JPA\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-13T16:05:58Z", "type": "commit"}, {"oid": "3998672f56be9823ab4c3ae819f8868e194182b4", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3998672f56be9823ab4c3ae819f8868e194182b4", "message": "Remove R2DBC in favor of Hibernate/JPA\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-13T16:05:58Z", "type": "forcePushed"}, {"oid": "092e879fc86b35d1d99476135a391c9c0c026144", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/092e879fc86b35d1d99476135a391c9c0c026144", "message": "Self review\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-13T18:32:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTczNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392549736", "bodyText": "q: did you not need topicNum?\nThen maybe additionally sequenceNumber and realm_num?", "author": "Nana-EC", "createdAt": "2020-03-14T02:43:11Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/domain/TopicMessage.java", "diffHunk": "@@ -50,4 +63,31 @@\n     public int compareTo(TopicMessage other) {\n         return Comparator.nullsFirst(Comparator.comparingLong(TopicMessage::getSequenceNumber)).compare(this, other);\n     }\n+\n+    public Instant getConsensusTimestampInstant() {\n+        return longToInstantConverter.convert(consensusTimestamp);\n+    }\n+\n+    @Override\n+    public Long getId() {\n+        return consensusTimestamp;\n+    }\n+\n+    @Override\n+    public boolean isNew() {\n+        return true;\n+    }\n+\n+    public static class TopicMessageBuilder {\n+        private long consensusTimestamp;\n+\n+        public TopicMessageBuilder consensusTimestamp(Instant consensusTimestamp) {", "originalCommit": "092e879fc86b35d1d99476135a391c9c0c026144", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MjEyMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392552121", "bodyText": "It's added automatically by Lombok.", "author": "steven-sheehy", "createdAt": "2020-03-14T03:20:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTkwNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392549905", "bodyText": "Just checking that the benefits of the limit 1 are no longer valid or needed here? Just in case you missed it in your refactor", "author": "Nana-EC", "createdAt": "2020-03-14T02:45:51Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/repository/EntityRepository.java", "diffHunk": "@@ -20,14 +20,18 @@\n  * \u200d\n  */\n \n-import org.springframework.data.r2dbc.repository.Query;\n-import org.springframework.data.repository.reactive.ReactiveCrudRepository;\n-import reactor.core.publisher.Mono;\n+import java.util.Optional;\n+import org.springframework.cache.annotation.Cacheable;\n+import org.springframework.data.jpa.repository.Query;\n+import org.springframework.data.repository.CrudRepository;\n \n+import com.hedera.mirror.grpc.config.CacheConfiguration;\n import com.hedera.mirror.grpc.domain.Entity;\n \n-public interface EntityRepository extends ReactiveCrudRepository<Entity, Long> {\n+public interface EntityRepository extends CrudRepository<Entity, Long> {\n \n-    @Query(\"select * from t_entities where entity_shard = $1 and entity_realm = $2 and entity_num = $3 limit 1\")\n-    Mono<Entity> findByCompositeKey(long shard, long realm, long num);\n+    @Cacheable(cacheNames = \"entity\", cacheManager = CacheConfiguration.ENTITY_CACHE, sync = true)\n+    @Query(value = \"select * from t_entities where entity_shard = ?1 and entity_realm = ?2 and entity_num = ?3\",", "originalCommit": "092e879fc86b35d1d99476135a391c9c0c026144", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MjM3NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392552374", "bodyText": "True, since it's a native query Hibernate/Spring isn't going to add that automatically. Technically this is a unique composite key so there are never more than one, but will add to be safe.", "author": "steven-sheehy", "createdAt": "2020-03-14T03:25:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTkwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MDI5MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392550291", "bodyText": "q: So do we have other options for getting those metrics? Not sure how crucial the were.", "author": "Nana-EC", "createdAt": "2020-03-14T02:51:37Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/repository/TopicMessageRepositoryCustomImpl.java", "diffHunk": "@@ -39,37 +40,32 @@\n @RequiredArgsConstructor\n public class TopicMessageRepositoryCustomImpl implements TopicMessageRepositoryCustom {\n \n-    private final DatabaseClient databaseClient;\n-    private final InstantToLongConverter instantToLongConverter;\n+    private final EntityManager entityManager;\n+    private final InstantToLongConverter converter;\n \n     @Override\n-    public Flux<TopicMessage> findByFilter(TopicMessageFilter filter) {\n-        Criteria whereClause = Criteria.where(\"realm_num\")\n-                .is(filter.getRealmNum())\n-                .and(\"topic_num\")\n-                .is(filter.getTopicNum())\n-                .and(\"consensus_timestamp\")\n-                .greaterThanOrEquals(instantToLongConverter.convert(filter.getStartTime()));\n+    public Stream<TopicMessage> findByFilter(TopicMessageFilter filter) {\n+        CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n+        CriteriaQuery<TopicMessage> query = cb.createQuery(TopicMessage.class);\n+        Root<TopicMessage> root = query.from(TopicMessage.class);\n+\n+        Predicate predicate = cb.and(\n+                cb.equal(root.get(\"realmNum\"), filter.getRealmNum()),\n+                cb.equal(root.get(\"topicNum\"), filter.getTopicNum()),\n+                cb.greaterThanOrEqualTo(root.get(\"consensusTimestamp\"), converter.convert(filter.getStartTime()))\n+        );\n \n         if (filter.getEndTime() != null) {\n-            whereClause = whereClause.and(\"consensus_timestamp\")\n-                    .lessThan(instantToLongConverter.convert(filter.getEndTime()));\n+            predicate = cb.and(predicate, cb\n+                    .lessThan(root.get(\"consensusTimestamp\"), converter.convert(filter.getEndTime())));\n         }\n \n-        Pageable pageable = filter.hasLimit() ? PageRequest.of(0, (int) filter.getLimit()) : Pageable.unpaged();\n+        query = query.select(root).where(predicate).orderBy(cb.asc(root.get(\"consensusTimestamp\")));\n \n-        return databaseClient.select()\n-                .from(TopicMessage.class)\n-                .matching(whereClause)\n-                .orderBy(Sort.by(\"consensus_timestamp\"))\n-                .page(pageable)\n-                .fetch()\n-                .all()\n-                .name(\"findByFilter\")\n-                .metrics()\n-                .doOnSubscribe(s -> log.debug(\"Executing query: {}\", filter))\n-                .doOnCancel(() -> log.debug(\"[{}] Cancelled query\", filter.getSubscriberId()))\n-                .doOnComplete(() -> log.debug(\"[{}] Completed query\", filter.getSubscriberId()))\n-                .doOnNext(t -> log.trace(\"[{}] Next message: {}\", filter.getSubscriberId(), t));\n+        TypedQuery<TopicMessage> typedQuery = entityManager.createQuery(query);\n+        if (filter.hasLimit()) {\n+            typedQuery.setMaxResults((int) filter.getLimit());\n+        }\n+        return typedQuery.getResultList().stream(); // getResultStream()'s cursor doesn't work with reactive streams", "originalCommit": "092e879fc86b35d1d99476135a391c9c0c026144", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyMDExNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392620116", "bodyText": "I found a way by putting it in the retriever.", "author": "steven-sheehy", "createdAt": "2020-03-14T21:19:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MDI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MDM4MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392550380", "bodyText": "q: curious, why the change to Stream vs converting to Flux?", "author": "Nana-EC", "createdAt": "2020-03-14T02:53:09Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -61,36 +61,34 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n         }\n \n         PollingContext context = new PollingContext(filter);\n-        Duration frequency = retrieverProperties.getPollingFrequency();\n-\n-        return Flux.defer(() -> poll(context))\n+        return Flux.fromStream(() -> poll(context))\n                 .repeatWhen(Repeat.create(r -> !context.isComplete(), Long.MAX_VALUE)\n-                        .fixedBackoff(frequency)\n+                        .fixedBackoff(retrieverProperties.getPollingFrequency())\n                         .jitter(Jitter.random(0.1))\n                         .withBackoffScheduler(scheduler))\n                 .name(\"retriever\")\n                 .metrics()\n                 .timeout(retrieverProperties.getTimeout(), scheduler)\n                 .doOnCancel(context::onComplete)\n                 .doOnComplete(context::onComplete)\n-                .doOnNext(context::onNext)\n-                .doOnSubscribe(s -> log.info(\"Starting to poll every {}ms: {}\", frequency.toMillis(), filter));\n+                .doOnNext(context::onNext);\n     }\n \n-    private Flux<TopicMessage> poll(PollingContext context) {\n+    private Stream<TopicMessage> poll(PollingContext context) {", "originalCommit": "092e879fc86b35d1d99476135a391c9c0c026144", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjYyMDE0MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r392620140", "bodyText": "Because the database layer can't be a flux and it wasn't really necessary to have it be reactive. But since I added back the metrics it became useful so converted it back to a flux", "author": "steven-sheehy", "createdAt": "2020-03-14T21:20:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1MDM4MA=="}], "type": "inlineReview"}, {"oid": "21040ff84e943271131bfbc6c53a5619a9e06df5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/21040ff84e943271131bfbc6c53a5619a9e06df5", "message": "Review feedback\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-14T21:09:38Z", "type": "commit"}, {"oid": "796c7b0838db414016e1989087fd6d8372255fac", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/796c7b0838db414016e1989087fd6d8372255fac", "message": "Merge remote-tracking branch 'origin/master' into grpc-hibernate\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-14T21:17:00Z", "type": "commit"}, {"oid": "49558a05a8d4999dd02b54e70a0e03a49956b6b3", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/49558a05a8d4999dd02b54e70a0e03a49956b6b3", "message": "Small fixes\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-16T15:04:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE0MjI1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393142251", "bodyText": "q: should this be conditional on consensusTimestamp being not null?", "author": "Nana-EC", "createdAt": "2020-03-16T16:14:18Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/domain/TopicMessage.java", "diffHunk": "@@ -50,4 +63,31 @@\n     public int compareTo(TopicMessage other) {\n         return Comparator.nullsFirst(Comparator.comparingLong(TopicMessage::getSequenceNumber)).compare(this, other);\n     }\n+\n+    public Instant getConsensusTimestampInstant() {\n+        return longToInstantConverter.convert(consensusTimestamp);\n+    }\n+\n+    @Override\n+    public Long getId() {\n+        return consensusTimestamp;\n+    }\n+\n+    @Override\n+    public boolean isNew() {\n+        return true;", "originalCommit": "49558a05a8d4999dd02b54e70a0e03a49956b6b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE4ODY0OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393188649", "bodyText": "topic_message.consensus_timestamp can never be null, it's a required field. We don't ever update topic messages, we only insert. Hence why we can avoid the query for existence that JPA does for natural IDs by always returning true for isNew.", "author": "steven-sheehy", "createdAt": "2020-03-16T17:20:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzE0MjI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM5NjkyOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393396929", "bodyText": "Thinking about new topics.\nSay i create a new topic, and immediately subscribe for it. The topic will take ~5-10 seconds to be created in db. So the first lookup will return empty, and also all the subsequent lookups until cache gets invalidated.\nI believe the tests may be working since they share the Repo instance, but that won't be the case in prod were importer inserts the data.\nIf we cache only non-null values, that should work and should be okay (since this isn't anywhere near being the perf bottleneck in our system). Further optimizations can be in future.\nSide question for my understanding: does the cache has any internal time based invalidation too if size limit is never reached? Not saying we need it, just random q.", "author": "apeksharma", "createdAt": "2020-03-17T01:30:32Z", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/repository/EntityRepository.java", "diffHunk": "@@ -20,14 +20,18 @@\n  * \u200d\n  */\n \n-import org.springframework.data.r2dbc.repository.Query;\n-import org.springframework.data.repository.reactive.ReactiveCrudRepository;\n-import reactor.core.publisher.Mono;\n+import java.util.Optional;\n+import org.springframework.cache.annotation.Cacheable;\n+import org.springframework.data.jpa.repository.Query;\n+import org.springframework.data.repository.CrudRepository;\n \n+import com.hedera.mirror.grpc.config.CacheConfiguration;\n import com.hedera.mirror.grpc.domain.Entity;\n \n-public interface EntityRepository extends ReactiveCrudRepository<Entity, Long> {\n+public interface EntityRepository extends CrudRepository<Entity, Long> {\n \n-    @Query(\"select * from t_entities where entity_shard = $1 and entity_realm = $2 and entity_num = $3 limit 1\")\n-    Mono<Entity> findByCompositeKey(long shard, long realm, long num);\n+    @Cacheable(cacheNames = \"entity\", cacheManager = CacheConfiguration.ENTITY_CACHE, sync = true)\n+    @Query(value = \"select * from t_entities where entity_shard = ?1 and entity_realm = ?2 and entity_num = ?3 limit 1\",", "originalCommit": "49558a05a8d4999dd02b54e70a0e03a49956b6b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQyNDUxMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393424510", "bodyText": "Good catch. I've pushed a fix to not cache if null.\nThere is no cache invalidation for this particular cache. I didn't feel we needed it since entities are never deleted and we aren't using any of the fields that are mutable by the importer.", "author": "steven-sheehy", "createdAt": "2020-03-17T03:23:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM5NjkyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg3NDgzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393874832", "bodyText": "This was critical bug we just found, there should be a test for this.", "author": "apeksharma", "createdAt": "2020-03-17T18:09:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM5NjkyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM5OTUyMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393399523", "bodyText": "in future,  maybe we can let domainBuilder keep track of seq numbers for topics.", "author": "apeksharma", "createdAt": "2020-03-17T01:41:13Z", "path": "hedera-mirror-grpc/src/test/java/com/hedera/mirror/grpc/service/TopicMessageServiceTest.java", "diffHunk": "@@ -446,13 +456,13 @@ void bothMessagesWithTopicNum() {\n     void bothMessagesWithRealmNum() {\n         domainBuilder.entity(e -> e.entityRealm(1L)).block();\n         domainBuilder.entity(e -> e.entityRealm(2L)).block();\n-        domainBuilder.topicMessage(t -> t.realmNum(0)).block();\n-        domainBuilder.topicMessage(t -> t.realmNum(1)).block();\n+        domainBuilder.topicMessage(t -> t.realmNum(0).sequenceNumber(1)).block();", "originalCommit": "49558a05a8d4999dd02b54e70a0e03a49956b6b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQyMzA1OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393423058", "bodyText": "DomainBuilder does keep track of sequenceNumbers for simple case of same sequence number for all topic/realm numbers. But I didn't feel it was worth updating it for separate sequence numbers for multiple topic/realm numbers since it's only done in a couple tests and would make it more complex.", "author": "steven-sheehy", "createdAt": "2020-03-17T03:16:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM5OTUyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQwMjMxNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393402315", "bodyText": "We should not use grpc server's Repository instances (here and in other places) to insert data.\nCorrect setup, and one analogous to production would be, where writers and readers are isolated. Writers would be analogous to mirror-node-importer, and readers would be grpc server's repository instances (since the tests are to test them).", "author": "apeksharma", "createdAt": "2020-03-17T01:52:45Z", "path": "hedera-mirror-grpc/src/test/java/com/hedera/mirror/grpc/domain/DomainBuilder.java", "diffHunk": "@@ -103,12 +106,13 @@ void setup() {\n         return Flux.concat(publishers);\n     }\n \n-    private <T> Mono<?> insert(T domainObject) {\n-        return databaseClient.insert()\n-                .into((Class<T>) domainObject.getClass())\n-                .using(domainObject)\n-                .fetch()\n-                .first()\n-                .doOnNext(d -> log.debug(\"Inserted: {}\", domainObject));\n+    private Mono<Entity> insert(Entity entity) {\n+        return Mono.defer(() -> Mono.just(entityRepository.save(entity)))", "originalCommit": "49558a05a8d4999dd02b54e70a0e03a49956b6b3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQyNDA5MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393424091", "bodyText": "I would disagree with you. Repository should be the only means of interacting with the database for both reading and writing. This is the entire point of a repository: to act as the higher level API for CRUD operations to a backend database. Using a Repository allows us to swap out the implementation easily (e.g. PostgreSQL to BigQuery/MongoDB/etc).\nCase in point, if we would've use the repository in the domain builder for R2DBC then we would've minimized our changes when switching to Hibernate.", "author": "steven-sheehy", "createdAt": "2020-03-17T03:21:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQwMjMxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg4NTAyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/597#discussion_r393885026", "bodyText": "The tests right now are violating a major correctness abstraction - there are separate writer (importer) and readers (grpc) in production, but in tests, same instance is both reader and writer.\nThat coupled with the fact that a feature which majorly interacts with reads/writes - caching - is disabled in tests but enabled in production just seems very wrong to me.\nImo, correctness comes first, then design.\nWe should strive for correct testing. Whether it's with or without repository, am agnostic to that.\nDo or not, up to you, just stating my strong opinion.", "author": "apeksharma", "createdAt": "2020-03-17T18:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQwMjMxNQ=="}], "type": "inlineReview"}, {"oid": "b69cc8bec8874cba20b0815eb2bb89e755425aa2", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/b69cc8bec8874cba20b0815eb2bb89e755425aa2", "message": "Review feedback\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-03-17T03:24:02Z", "type": "commit"}]}