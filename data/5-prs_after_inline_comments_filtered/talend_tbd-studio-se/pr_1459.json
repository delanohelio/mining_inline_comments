{"pr_number": 1459, "pr_title": "feat(TBD-10000): R2020-07: Support CDP Milestone II Dynamic Distro for CDP Data Center 7.x", "pr_createdAt": "2020-06-18T13:27:13Z", "pr_url": "https://github.com/Talend/tbd-studio-se/pull/1459", "timeline": [{"oid": "5960ecf5bc764e27f1a8262c531b9c9ea411fde9", "url": "https://github.com/Talend/tbd-studio-se/commit/5960ecf5bc764e27f1a8262c531b9c9ea411fde9", "message": "sqoop part", "committedDate": "2020-06-18T13:23:01Z", "type": "commit"}, {"oid": "9a6c284baa93088d2a7386c783b30b832aea422a", "url": "https://github.com/Talend/tbd-studio-se/commit/9a6c284baa93088d2a7386c783b30b832aea422a", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000", "committedDate": "2020-06-29T06:29:01Z", "type": "commit"}, {"oid": "fae0c69158c46c2ae9ef7fdf9a68ac5a6e93cd04", "url": "https://github.com/Talend/tbd-studio-se/commit/fae0c69158c46c2ae9ef7fdf9a68ac5a6e93cd04", "message": "sqoop part", "committedDate": "2020-06-29T08:36:28Z", "type": "commit"}, {"oid": "b75663adb104efb4fb95e24ef7a3c5c86719f994", "url": "https://github.com/Talend/tbd-studio-se/commit/b75663adb104efb4fb95e24ef7a3c5c86719f994", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000", "committedDate": "2020-07-02T07:07:37Z", "type": "commit"}, {"oid": "5f2cd4971307a76ae450adf573262ffa616c4524", "url": "https://github.com/Talend/tbd-studio-se/commit/5f2cd4971307a76ae450adf573262ffa616c4524", "message": "sqoop and avro dependencies on cluster side", "committedDate": "2020-07-03T08:38:10Z", "type": "commit"}, {"oid": "53acdca82b8efc9fe758ec103869e50b88383080", "url": "https://github.com/Talend/tbd-studio-se/commit/53acdca82b8efc9fe758ec103869e50b88383080", "message": "missing refacto", "committedDate": "2020-07-03T08:44:24Z", "type": "commit"}, {"oid": "7c705d8773eba01e125938cba9463e505999cba4", "url": "https://github.com/Talend/tbd-studio-se/commit/7c705d8773eba01e125938cba9463e505999cba4", "message": "missing sqoop lib", "committedDate": "2020-07-03T14:23:03Z", "type": "commit"}, {"oid": "c63bdd2a212cacfb361a6b741b69a0d27f6f3a23", "url": "https://github.com/Talend/tbd-studio-se/commit/c63bdd2a212cacfb361a6b741b69a0d27f6f3a23", "message": "missing dependencies", "committedDate": "2020-07-03T14:23:36Z", "type": "commit"}, {"oid": "32862e9face1e515d42562bcabb7f509dc0f3473", "url": "https://github.com/Talend/tbd-studio-se/commit/32862e9face1e515d42562bcabb7f509dc0f3473", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000", "committedDate": "2020-07-07T07:33:10Z", "type": "commit"}, {"oid": "9c2318beaf44a3e44d9710a7083f2534644572f9", "url": "https://github.com/Talend/tbd-studio-se/commit/9c2318beaf44a3e44d9710a7083f2534644572f9", "message": "sqoop issue java.lang.NoClassDefFoundError\norg/apache/avro/mapred/AvroWrapper", "committedDate": "2020-07-07T08:00:09Z", "type": "commit"}, {"oid": "23995f38fb8d9cbfd67f8564d81c4fe3a71451e0", "url": "https://github.com/Talend/tbd-studio-se/commit/23995f38fb8d9cbfd67f8564d81c4fe3a71451e0", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000", "committedDate": "2020-07-14T06:58:32Z", "type": "commit"}, {"oid": "a96340002e2c6c06a77152cfc186d133c39dc292", "url": "https://github.com/Talend/tbd-studio-se/commit/a96340002e2c6c06a77152cfc186d133c39dc292", "message": "WIP impala on cdp", "committedDate": "2020-07-14T13:49:01Z", "type": "commit"}, {"oid": "2108c63e3904e42c1c38fa0c775658bb2ddd4bcc", "url": "https://github.com/Talend/tbd-studio-se/commit/2108c63e3904e42c1c38fa0c775658bb2ddd4bcc", "message": "wip update the built-in template to support impala", "committedDate": "2020-07-14T17:27:41Z", "type": "commit"}, {"oid": "c1dc4ee4f52f576a8476f4f1e938f57aa41f8b3b", "url": "https://github.com/Talend/tbd-studio-se/commit/c1dc4ee4f52f576a8476f4f1e938f57aa41f8b3b", "message": "delete unsued variables and add kerberos configuration", "committedDate": "2020-07-14T17:29:54Z", "type": "commit"}, {"oid": "248d815b93ed618f59984e9133f128fa0327ded4", "url": "https://github.com/Talend/tbd-studio-se/commit/248d815b93ed618f59984e9133f128fa0327ded4", "message": "issue sqoop import with avro", "committedDate": "2020-07-15T03:28:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454876199", "bodyText": "should not it be spark 24 ?", "author": "AlixMetivier", "createdAt": "2020-07-15T08:19:33Z", "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";\n+\tpublic final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n+\n+\tprivate final static String YARN_APPLICATION_CLASSPATH = \n+\t\t\tDEFAULT_LIB_ROOT + \"/spark/jars/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hive/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/impala/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hbase/lib/*\" + SEPARATOR\n+\t\t\t+ DEFAULT_LIB_ROOT + \"/sqoop/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/kudu/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-mapreduce/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/avro/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop/lib/*\";\n+\n+\tpublic CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n+\t\tsuper(pluginAdapter);\n+\t}\n+\t@Override\n+\tpublic boolean doSupportImpalaConnector() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic boolean doImpalaSupportSSL() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic String getSqoopPackageName() {\n+\t\treturn ESqoopPackageName.ORG_APACHE_SQOOP.toString();\n+\t}\n+\n+\t@Override\n+\tpublic String getTemplateId() {\n+\t\treturn TEMPLATE_ID;\n+\t}\n+\n+\t@Override\n+\tpublic String getYarnApplicationClasspath() {\n+\t\treturn YARN_APPLICATION_CLASSPATH;\n+\t}\n+\n+\t@Override\n+\tpublic String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n+\t\treturn getYarnApplicationClasspath();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSequenceFileShortType() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportNewHBaseAPI() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportCrossPlatformSubmission() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportImpersonation() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportEmbeddedMode() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStandaloneMode() {\n+\t\treturn super.doSupportStandaloneMode();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive1() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive2() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportTezForHive() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBaseForHive() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBase2x() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSSL() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportORCFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportAvroFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStoreAsParquet() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISupportStorePasswordInFile() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportClouderaNavigator() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetOutput() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ESparkVersion> getSparkVersions() {\n+\t\tSet<ESparkVersion> version = new HashSet<>();\n+\t\tSet<ESparkVersion> sparkVersions = super.getSparkVersions();\n+\t\tif (sparkVersions == null || sparkVersions.isEmpty()) {\n+\t\t\tversion.add(ESparkVersion.SPARK_2_2);", "originalCommit": "248d815b93ed618f59984e9133f128fa0327ded4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ5OTU0MA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455499540", "bodyText": "yes will fix it", "author": "Redwene", "createdAt": "2020-07-16T04:14:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUyMDM5OA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455520398", "bodyText": "done", "author": "Redwene", "createdAt": "2020-07-16T05:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNTExOA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455235118", "bodyText": "I don't get why this was moved to superinterface HaddopComponent.\nIt should stay in ImpalaComponent as it is related to Impala", "author": "lbourgeois", "createdAt": "2020-07-15T17:54:08Z", "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/component/ImpalaComponent.java", "diffHunk": "@@ -18,17 +18,6 @@\n  */\n public interface ImpalaComponent extends HadoopComponent {\n \n-    /**\n-     * indicate if we support the impala native protocol.\n-     * connection with jdbc:impala://[Host]:[Port]/[Schema];[Property1]=[Value];[Property2]=[Value];\n-     * @return\n-     */\n-    default boolean doSupportImpalaConnector() {", "originalCommit": "248d815b93ed618f59984e9133f128fa0327ded4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwNDA0NA==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455504044", "bodyText": "I moved it to Haddo Component to find out if its impala is supported before converting the distribution object to impala. We can thus refactor more easily the code between the choice of the driver hive and impala.", "author": "Redwene", "createdAt": "2020-07-16T04:33:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNTExOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNjc5Nw==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455236797", "bodyText": "Is it still CDH in path ?", "author": "lbourgeois", "createdAt": "2020-07-15T17:56:35Z", "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";", "originalCommit": "248d815b93ed618f59984e9133f128fa0327ded4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwNDQ1OQ==", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455504459", "bodyText": "yes this is cloudera standard path", "author": "Redwene", "createdAt": "2020-07-16T04:35:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNjc5Nw=="}], "type": "inlineReview"}, {"oid": "d4597cb6f8898bc29fab7b268b2d3d6ab8f8b557", "url": "https://github.com/Talend/tbd-studio-se/commit/d4597cb6f8898bc29fab7b268b2d3d6ab8f8b557", "message": "fix default value", "committedDate": "2020-07-16T04:56:06Z", "type": "commit"}, {"oid": "a4fc1ece433eddc9265240179623bc4e06b147bb", "url": "https://github.com/Talend/tbd-studio-se/commit/a4fc1ece433eddc9265240179623bc4e06b147bb", "message": "set log level for impala driver", "committedDate": "2020-07-16T04:57:51Z", "type": "commit"}, {"oid": "5569d60b2db0afef120c357e3fb85b65b1719bc7", "url": "https://github.com/Talend/tbd-studio-se/commit/5569d60b2db0afef120c357e3fb85b65b1719bc7", "message": "use log activation from advanced setting", "committedDate": "2020-07-16T05:28:21Z", "type": "commit"}, {"oid": "aef9c346b4effc1348bde8ba005d63547d65ccfe", "url": "https://github.com/Talend/tbd-studio-se/commit/aef9c346b4effc1348bde8ba005d63547d65ccfe", "message": "modification following the PR ssl activation", "committedDate": "2020-07-16T05:29:48Z", "type": "commit"}, {"oid": "a6494ed717d2ddb3c67cf76126500d1f6844a3f5", "url": "https://github.com/Talend/tbd-studio-se/commit/a6494ed717d2ddb3c67cf76126500d1f6844a3f5", "message": "following alix's PR", "committedDate": "2020-07-16T05:34:27Z", "type": "commit"}, {"oid": "2990a05aff1e79f3b96aa948097edcce54819f6f", "url": "https://github.com/Talend/tbd-studio-se/commit/2990a05aff1e79f3b96aa948097edcce54819f6f", "message": "Following Alix's review", "committedDate": "2020-07-16T05:37:21Z", "type": "commit"}, {"oid": "48dca28999086f08bfeee6530dddc28317a478b6", "url": "https://github.com/Talend/tbd-studio-se/commit/48dca28999086f08bfeee6530dddc28317a478b6", "message": "kerberos part", "committedDate": "2020-07-16T06:01:19Z", "type": "commit"}, {"oid": "54c3c0daf4100c9ad701a18fcc1cc25b656c5600", "url": "https://github.com/Talend/tbd-studio-se/commit/54c3c0daf4100c9ad701a18fcc1cc25b656c5600", "message": "fix issue No suitable driver found", "committedDate": "2020-07-16T07:22:35Z", "type": "commit"}]}