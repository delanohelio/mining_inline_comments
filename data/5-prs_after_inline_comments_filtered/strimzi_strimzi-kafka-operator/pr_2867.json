{"pr_number": 2867, "pr_title": "Dynamically update EO logging", "pr_createdAt": "2020-04-21T10:22:34Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867", "timeline": [{"oid": "c0773ab0b0ac147355a4a56adf462fc9378aacb6", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c0773ab0b0ac147355a4a56adf462fc9378aacb6", "message": "Dynamically update EO logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-04-21T10:23:50Z", "type": "forcePushed"}, {"oid": "f9003a66181317abdfd6658c89a7caaf882b2fa7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f9003a66181317abdfd6658c89a7caaf882b2fa7", "message": "Dynamically update EO logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-04-21T10:24:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM0OTA0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413349040", "bodyText": "This looks a bit weird ... by the name it is supposed to add something, but it just returns what it gets. Is this something what still needs to be added?", "author": "scholzj", "createdAt": "2020-04-22T21:34:08Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -368,6 +368,10 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n         }\n     }\n \n+    protected String addMonitorIntervalToExternalLogging(String data) {\n+        return data;", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1MjI3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413552273", "bodyText": "Yeah, it is my poor design. For all models, we do not need to add anything. This method is overridden in EO models to add monitorInterval.", "author": "sknot-rh", "createdAt": "2020-04-23T06:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM0OTA0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MDk4NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413350984", "bodyText": "Is this 15 seconds? How do we know that is the right number? Also, since it is used on several places, should we have a constant?", "author": "scholzj", "createdAt": "2020-04-22T21:37:36Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java", "diffHunk": "@@ -310,8 +310,28 @@ public void setContainerEnvVars(List<ContainerEnvVar> envVars) {\n         templateContainerEnvVars = envVars;\n     }\n \n-\n     public void setContainerSecurityContext(SecurityContext securityContext) {\n         templateContainerSecurityContext = securityContext;\n     }\n+\n+    /**\n+     * Transforms map to log4j properties file format\n+     * @param properties map with properties\n+     * @return\n+     */\n+    @Override\n+    protected String createPropertiesString(OrderedProperties properties) {\n+        properties.addPair(\"monitorInterval\", \"15\");", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1MTY0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413551649", "bodyText": "It is 15 seconds. I consider it a reasonable value. The log4j2.properties file is rewritten after periodic reconciliation.", "author": "sknot-rh", "createdAt": "2020-04-23T06:46:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MDk4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MTMxMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413351313", "bodyText": "These seem to be duplicates with the EnttityTopicOperator. Should we factor them out somewhere?", "author": "scholzj", "createdAt": "2020-04-22T21:38:18Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java", "diffHunk": "@@ -332,4 +332,25 @@ public void setContainerEnvVars(List<ContainerEnvVar> envVars) {\n     public void setContainerSecurityContext(SecurityContext securityContext) {\n         templateContainerSecurityContext = securityContext;\n     }\n+\n+    /**\n+     * Transforms map to log4j properties file format\n+     * @param properties map with properties\n+     * @return\n+     */\n+    @Override\n+    protected String createPropertiesString(OrderedProperties properties) {", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MjQ0Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413352447", "bodyText": "This is f*cking confusing as hell. Is it testing that pod name did or didn't changed? I guess it is that it didn't?", "author": "scholzj", "createdAt": "2020-04-22T21:40:36Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java", "diffHunk": "@@ -479,6 +482,138 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)\n+    void testDynamicallySetEOloggingLevels() {\n+        String eoName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoName);\n+\n+        // change inline logging\n+        InlineLogging il = new InlineLogging();\n+        il.setLoggers(Collections.singletonMap(\"rootLogger.level\", INFO));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(il);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(il);\n+        });\n+\n+        String eoPodName = eoPods.keySet().iterator().next();\n+        String eoPodHash = eoPods.get(eoPodName);\n+        String finalEoPodName = eoPodName;\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {\n+                return cmdKubeClient().execInPodContainer(finalEoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                && cmdKubeClient().execInPodContainer(finalEoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\");\n+            }\n+        );\n+\n+        eoPods = DeploymentUtils.depSnapshot(eoName);\n+        String eoPodNameAfterLoggingChange = eoPods.keySet().iterator().next();\n+        assertThat(\"Pod name changed after logging changed\", eoPodNameAfterLoggingChange.equals(eoPodName), is(true));\n+        assertThat(\"Pod hash changed after logging changed\", eoPods.get(eoPodNameAfterLoggingChange).equals(eoPodHash), is(true));\n+\n+\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name = TOConfig\\n\" +\n+                        \"\\n\" +\n+                        \"appender.console.type = Console\\n\" +\n+                        \"appender.console.name = STDOUT\\n\" +\n+                        \"appender.console.layout.type = PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern = [%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"\\n\" +\n+                        \"rootLogger.level = TRACE\\n\" +\n+                        \"rootLogger.appenderRefs = stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+                        \"rootLogger.additivity = false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name = UOConfig\\n\" +\n+                        \"\\n\" +\n+                        \"appender.console.type = Console\\n\" +\n+                        \"appender.console.name = STDOUT\\n\" +\n+                        \"appender.console.layout.type = PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern = [%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"\\n\" +\n+                        \"rootLogger.level = TRACE\\n\" +\n+                        \"rootLogger.appenderRefs = stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+                        \"rootLogger.additivity = false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        String finalEoPodName1 = eoPodName;\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {\n+                return cmdKubeClient().execInPodContainer(finalEoPodName1, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level = TRACE\")\n+                        && cmdKubeClient().execInPodContainer(finalEoPodName1, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level = TRACE\");\n+            }\n+        );\n+\n+        eoPodName = eoPods.keySet().iterator().next();\n+        eoPodHash = eoPods.get(eoPodName);\n+        eoPods = DeploymentUtils.depSnapshot(eoName);\n+        eoPodNameAfterLoggingChange = eoPods.keySet().iterator().next();\n+        assertThat(\"Pod name changed after logging changed\", eoPodNameAfterLoggingChange.equals(eoPodName), is(true));", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU0OTc2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413549766", "bodyText": "Sorry about that. Yes, it is testing the name is not changed. As EO is deployment, RU=new suffix for the pod name. So if the RU did not happen (it should not when dynamically changing), the name should remain.", "author": "sknot-rh", "createdAt": "2020-04-23T06:42:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MjQ0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzE5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413353193", "bodyText": "What kind of Hash is this comparing?", "author": "scholzj", "createdAt": "2020-04-22T21:41:54Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java", "diffHunk": "@@ -479,6 +482,138 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)\n+    void testDynamicallySetEOloggingLevels() {\n+        String eoName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoName);\n+\n+        // change inline logging\n+        InlineLogging il = new InlineLogging();\n+        il.setLoggers(Collections.singletonMap(\"rootLogger.level\", INFO));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(il);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(il);\n+        });\n+\n+        String eoPodName = eoPods.keySet().iterator().next();\n+        String eoPodHash = eoPods.get(eoPodName);\n+        String finalEoPodName = eoPodName;\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {\n+                return cmdKubeClient().execInPodContainer(finalEoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                && cmdKubeClient().execInPodContainer(finalEoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\");\n+            }\n+        );\n+\n+        eoPods = DeploymentUtils.depSnapshot(eoName);\n+        String eoPodNameAfterLoggingChange = eoPods.keySet().iterator().next();\n+        assertThat(\"Pod name changed after logging changed\", eoPodNameAfterLoggingChange.equals(eoPodName), is(true));\n+        assertThat(\"Pod hash changed after logging changed\", eoPods.get(eoPodNameAfterLoggingChange).equals(eoPodHash), is(true));\n+\n+\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name = TOConfig\\n\" +\n+                        \"\\n\" +\n+                        \"appender.console.type = Console\\n\" +\n+                        \"appender.console.name = STDOUT\\n\" +\n+                        \"appender.console.layout.type = PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern = [%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"\\n\" +\n+                        \"rootLogger.level = TRACE\\n\" +\n+                        \"rootLogger.appenderRefs = stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+                        \"rootLogger.additivity = false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name = UOConfig\\n\" +\n+                        \"\\n\" +\n+                        \"appender.console.type = Console\\n\" +\n+                        \"appender.console.name = STDOUT\\n\" +\n+                        \"appender.console.layout.type = PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern = [%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"\\n\" +\n+                        \"rootLogger.level = TRACE\\n\" +\n+                        \"rootLogger.appenderRefs = stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref = STDOUT\\n\" +\n+                        \"rootLogger.additivity = false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        String finalEoPodName1 = eoPodName;\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {\n+                return cmdKubeClient().execInPodContainer(finalEoPodName1, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level = TRACE\")\n+                        && cmdKubeClient().execInPodContainer(finalEoPodName1, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level = TRACE\");\n+            }\n+        );\n+\n+        eoPodName = eoPods.keySet().iterator().next();\n+        eoPodHash = eoPods.get(eoPodName);\n+        eoPods = DeploymentUtils.depSnapshot(eoName);\n+        eoPodNameAfterLoggingChange = eoPods.keySet().iterator().next();\n+        assertThat(\"Pod name changed after logging changed\", eoPodNameAfterLoggingChange.equals(eoPodName), is(true));\n+        assertThat(\"Pod hash changed after logging changed\", eoPods.get(eoPodNameAfterLoggingChange).equals(eoPodHash), is(true));", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU0OTEzMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413549133", "bodyText": "Whatever depSnapshot() is returning. @Frawless could you enlight us?", "author": "sknot-rh", "createdAt": "2020-04-23T06:41:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1Njg5MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413556890", "bodyText": "I assume you want to wait for rolling update of EO. You should use something like\nDeploymentUtils.waitTillDepHasRolled(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1, eoPods);", "author": "Frawless", "createdAt": "2020-04-23T06:52:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzE5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU2MDExMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413560110", "bodyText": "Oh no, I misunderstand few parts. If you want to check, that EO doesn't roll, you should store DeploymentUtils.depSnapshot(eoName); before you starting with any changes and compare the value with DeploymentUtils.depSnapshot(eoName); when the changes are applied. This method returns map with all pods connected to specific deployment and it's UIDs", "author": "Frawless", "createdAt": "2020-04-23T06:58:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzE5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzczMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413353730", "bodyText": "How do ou know you are changing it? Aran't INFO levels usually the defaults?", "author": "scholzj", "createdAt": "2020-04-22T21:42:57Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java", "diffHunk": "@@ -479,6 +482,138 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)\n+    void testDynamicallySetEOloggingLevels() {\n+        String eoName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoName);\n+\n+        // change inline logging\n+        InlineLogging il = new InlineLogging();\n+        il.setLoggers(Collections.singletonMap(\"rootLogger.level\", INFO));", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU0ODY2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413548666", "bodyText": "The test are using DEBUG.", "author": "sknot-rh", "createdAt": "2020-04-23T06:40:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1MzczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413354636", "bodyText": "Maybe I missed it. But I'm not sure where this really tests the reloading. But I do not see any test that the log4j2.properties was reloaded and the new log level is used. I think that is the mainpoint odf this change so it should be tested.", "author": "scholzj", "createdAt": "2020-04-22T21:44:55Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java", "diffHunk": "@@ -479,6 +482,138 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)\n+    void testDynamicallySetEOloggingLevels() {", "originalCommit": "eef5f038315cc85ca5b732297d1a140c8b668d45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU0ODU0Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413548546", "bodyText": "It is testing th e log4j2.properties has been changed: https://github.com/strimzi/strimzi-kafka-operator/pull/2867/files/eef5f038315cc85ca5b732297d1a140c8b668d45#diff-406f189535ad433ebe2d832137206aa6R502\nYou are right we should also test the change really takes an effect. I gues I need help from @Frawless @see-quick there.", "author": "sknot-rh", "createdAt": "2020-04-23T06:40:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzU1MjA3Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413552072", "bodyText": "https://github.com/strimzi/strimzi-kafka-operator/blob/master/systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java#L689   Maybe we can add there a check that logging config file rly changed, but it's not a good idea to see if new debug level is available in logs, because oc cluster up is not friendly with that and from time to time just drop the logs", "author": "Frawless", "createdAt": "2020-04-23T06:47:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzYxMTc3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r413611778", "bodyText": "I can understand that the reliability might be an issue here. But without that we should maybe consider the usefulness of this test maybe? Right now it really tests that Kube refreshs the config map volume. Does that need to be tested? Is it worth the testing time? If we actually check the logs, I would say yes. Without it? I'm not sure.", "author": "scholzj", "createdAt": "2020-04-23T08:20:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMjY3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r430912673", "bodyText": "I think this comment stands ... this test does not test dynamic logging reconfiguration. It just tests how Kuberetes update the mounted config map.", "author": "scholzj", "createdAt": "2020-05-27T07:31:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MTUzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432261536", "bodyText": "I see. IMHO it has to be tested by ST.", "author": "sknot-rh", "createdAt": "2020-05-29T05:23:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM3ODUxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432378514", "bodyText": "Why does the update of the ConfigMap which is Kubernetes thing need to be tested by our ST?", "author": "scholzj", "createdAt": "2020-05-29T09:51:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzM1NDYzNg=="}], "type": "inlineReview"}, {"oid": "db3b651650f52d8596faa12c606ea22d2f3c0c9b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/db3b651650f52d8596faa12c606ea22d2f3c0c9b", "message": "checkstyle\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-05-18T08:41:15Z", "type": "forcePushed"}, {"oid": "bfa8483c65929106aa424f8b12e1c394ebb719c3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/bfa8483c65929106aa424f8b12e1c394ebb719c3", "message": "forgotten assertion\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-05-22T06:22:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDE1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r430910152", "bodyText": "How can the users change this? Through the logger configuration in the CR? Or only with external logging configuration? In general, 5 seconds (is it seconds?) seems very short ... logging is not changed so often ... would 30 seconds or 1 minute be ore suitable?", "author": "scholzj", "createdAt": "2020-05-27T07:26:36Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -398,6 +398,21 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n         }\n     }\n \n+    /**\n+     * Adds 'monitorInterval=5' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.\n+     * This property is ignored by log4j but used by log4j2.\n+     * @param data\n+     * @return\n+     */\n+    protected String addMonitorIntervalToExternalLogging(String data) {\n+        if (!data.contains(\"monitorInterval=\")) {\n+            // do not override custom value\n+            return data + \"\\nmonitorInterval=5\";", "originalCommit": "bfa8483c65929106aa424f8b12e1c394ebb719c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI2MDYxNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432260616", "bodyText": "I do not think it is crucial to make it changeable by user. Basically it should be <5, reconciliationPeriod>. 5 seconds is the minimum from log4j2. Setting it to low value will have effect she logging will be updated shortly after the reconciliation. Some bigger value will take a long time to reload new configuration although there will be less reloads from log4j2.", "author": "sknot-rh", "createdAt": "2020-05-29T05:19:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDE1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM4NjA3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432386076", "bodyText": "Have you done any tests how much does the reloading cost? I think 5 seconds is quite agressive given how much often would this happen. If the costs are negligible it is fine. If not, we should use some higher value I think.", "author": "scholzj", "createdAt": "2020-05-29T10:06:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDE1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM4Nzg3OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432387879", "bodyText": "No I did not. I increased the value to 30s.", "author": "sknot-rh", "createdAt": "2020-05-29T10:10:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDE1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDg3MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r430910871", "bodyText": "The javadoc suggests that this is Log4j specific method? If yes, it should be reflected in the name ... e.g. createLog4j2Properties", "author": "scholzj", "createdAt": "2020-05-27T07:27:57Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java", "diffHunk": "@@ -313,8 +313,19 @@ public void setContainerEnvVars(List<ContainerEnvVar> envVars) {\n         templateContainerEnvVars = envVars;\n     }\n \n-\n     public void setContainerSecurityContext(SecurityContext securityContext) {\n         templateContainerSecurityContext = securityContext;\n     }\n+\n+    /**\n+     * Transforms properties to log4j2 properties file format and adds property for reloading the config\n+     * @param properties map with properties\n+     * @return modified string with monitorInterval\n+     */\n+    @Override\n+    public String createPropertiesString(OrderedProperties properties) {", "originalCommit": "bfa8483c65929106aa424f8b12e1c394ebb719c3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjI1OTI5NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432259295", "bodyText": "It is called from the abstract model class (\n  \n    \n      strimzi-kafka-operator/cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java\n    \n    \n         Line 386\n      in\n      8f49fff\n    \n    \n    \n    \n\n        \n          \n           return createPropertiesString(newSettings); \n        \n    \n  \n\n)\nI am not sure whether renaming this is worth of overriding entire parseLogging method.", "author": "sknot-rh", "createdAt": "2020-05-29T05:14:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjM4NTQ4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r432385488", "bodyText": "If that function is specific to log4j you should name it like that. I'm not sure you need to override anything - just rename it eevrywhere, or? Ad if it is not specific for Log4j, it should not say so in the comment.", "author": "scholzj", "createdAt": "2020-05-29T10:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMDg3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDkxMTI3Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r430911272", "bodyText": "So, what does this test? Is it missing some assert?", "author": "scholzj", "createdAt": "2020-05-27T07:28:42Z", "path": "cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java", "diffHunk": "@@ -93,6 +93,14 @@\n \n     private final EntityOperator entityOperator = EntityOperator.fromCrd(resource, VERSIONS);\n \n+    @Test\n+    public void lala() {\n+        OrderedProperties op = new OrderedProperties();\n+        op.addPair(\"karel\", \"42\");\n+        String res = entityOperator.createPropertiesString(op);", "originalCommit": "bfa8483c65929106aa424f8b12e1c394ebb719c3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "98056c1fd8b56ddb06f60d15e89040e6021a3bff", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/98056c1fd8b56ddb06f60d15e89040e6021a3bff", "message": "comment\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-05-29T05:23:51Z", "type": "forcePushed"}, {"oid": "03833a2facfbd56919385cb9f7f2261a0ad19ef8", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/03833a2facfbd56919385cb9f7f2261a0ad19ef8", "message": "update the test (#2)\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-01T06:12:26Z", "type": "forcePushed"}, {"oid": "08f4267d26272f5b498d61d08d491f7f3f8e8175", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/08f4267d26272f5b498d61d08d491f7f3f8e8175", "message": "external logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-01T09:23:44Z", "type": "forcePushed"}, {"oid": "085e27008db8a59ddf0fb30453b3d6213d6a40e3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/085e27008db8a59ddf0fb30453b3d6213d6a40e3", "message": "external logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-01T09:27:07Z", "type": "forcePushed"}, {"oid": "10583dee30358505108f708b7dc62602127ac1dd", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/10583dee30358505108f708b7dc62602127ac1dd", "message": "external logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-01T09:39:43Z", "type": "forcePushed"}, {"oid": "c6b3aed23499831b1476a82099936dcd4a451625", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c6b3aed23499831b1476a82099936dcd4a451625", "message": "what\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-01T13:03:16Z", "type": "forcePushed"}, {"oid": "1d02c041207c7587574f203c75bd553488e893d4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1d02c041207c7587574f203c75bd553488e893d4", "message": "what\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-02T05:49:22Z", "type": "forcePushed"}, {"oid": "ed5ba0bf115468050c074f4a09e2e7db4a3510a1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ed5ba0bf115468050c074f4a09e2e7db4a3510a1", "message": "add another assertions, add logs (#3)\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-03T05:43:53Z", "type": "forcePushed"}, {"oid": "31a4031db18fe50f3bbabacd01d9df196a49871f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/31a4031db18fe50f3bbabacd01d9df196a49871f", "message": "add another assertions, add logs (#3)\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-05T06:34:07Z", "type": "forcePushed"}, {"oid": "d2bf0a3d02a26a4885eeb67fb7d862aa442e88bf", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d2bf0a3d02a26a4885eeb67fb7d862aa442e88bf", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-08T10:22:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY4NzgyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r436687829", "bodyText": "Can you please delete this @Order(14)? As we have new suite, we don't need to order the tests (because we are not deleting anything)", "author": "im-konge", "createdAt": "2020-06-08T13:14:16Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +184,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)", "originalCommit": "d2bf0a3d02a26a4885eeb67fb7d862aa442e88bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY4OTE1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r436689159", "bodyText": "The test will fail, because Kafka is not setup. Can you add it there? Or should I take a look at it?", "author": "im-konge", "createdAt": "2020-06-08T13:15:43Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +184,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @Order(14)\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {", "originalCommit": "d2bf0a3d02a26a4885eeb67fb7d862aa442e88bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM1NDg1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437354853", "bodyText": "what's data?", "author": "ppatierno", "createdAt": "2020-06-09T12:03:42Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +407,35 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return addMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));\n             } else {\n                 log.warn(\"ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.\",\n                         ((ExternalLogging) getLogging()).getName(),\n                         getAncillaryConfigMapKeyLogConfig());\n-                return createPropertiesString(getDefaultLogConfig());\n+                return createLog4jProperties(getDefaultLogConfig());\n             }\n \n         } else {\n             log.debug(\"logging is not set, using default loggers\");\n-            return createPropertiesString(getDefaultLogConfig());\n+            return createLog4jProperties(getDefaultLogConfig());\n+        }\n+    }\n+\n+    /**\n+     * Adds 'monitorInterval=5' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.\n+     * This property is ignored by log4j but used by log4j2.\n+     * @param data", "originalCommit": "06cfd037f77c84bd2992caf3af8ef01f47de2b1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM5Mjk3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437392976", "bodyText": "data from configmap", "author": "sknot-rh", "createdAt": "2020-06-09T12:58:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM1NDg1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU5Njk4Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437596982", "bodyText": "So, maybe it should be described there what exactly is this expected to be and in which format.", "author": "scholzj", "createdAt": "2020-06-09T17:25:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM1NDg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM2MTc1Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437361753", "bodyText": "my doubt is ...\nThis feature seems to be available only when the user uses external logging configuration (via ConfigMap) and what we are doing here is just adding a field (the monitorInterval one). It means that the user could do that by himself, if we document it or if the user already knows about this feature.\nOr did I get it wrong on how it works?", "author": "ppatierno", "createdAt": "2020-06-09T12:16:27Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +407,35 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return addMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));", "originalCommit": "06cfd037f77c84bd2992caf3af8ef01f47de2b1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM5NjQ1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437396452", "bodyText": "No, it works for internal logging as well (see method createLog4jProperties(OrderedProperties) overriden in EO classes). This monitorInterval=30 is added in both cases. If user specifies his own monitorInterval it is respected and his value is used.", "author": "sknot-rh", "createdAt": "2020-06-09T13:02:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM2MTc1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU5NjE0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437596144", "bodyText": "The interval is not 30 seconds.", "author": "scholzj", "createdAt": "2020-06-09T17:23:38Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +407,35 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return addMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));\n             } else {\n                 log.warn(\"ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.\",\n                         ((ExternalLogging) getLogging()).getName(),\n                         getAncillaryConfigMapKeyLogConfig());\n-                return createPropertiesString(getDefaultLogConfig());\n+                return createLog4jProperties(getDefaultLogConfig());\n             }\n \n         } else {\n             log.debug(\"logging is not set, using default loggers\");\n-            return createPropertiesString(getDefaultLogConfig());\n+            return createLog4jProperties(getDefaultLogConfig());\n+        }\n+    }\n+\n+    /**\n+     * Adds 'monitorInterval=5' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzU5NjY3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437596673", "bodyText": "Does this mean we are adding this to both Log4j2 logs where it is used as well as to log4j logs where it is ignored? That would be wrong since it would be confusing to anyone who checks the map. You should add it only in the place where it is supported.", "author": "scholzj", "createdAt": "2020-06-09T17:24:36Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +407,35 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return addMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));\n             } else {\n                 log.warn(\"ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.\",\n                         ((ExternalLogging) getLogging()).getName(),\n                         getAncillaryConfigMapKeyLogConfig());\n-                return createPropertiesString(getDefaultLogConfig());\n+                return createLog4jProperties(getDefaultLogConfig());\n             }\n \n         } else {\n             log.debug(\"logging is not set, using default loggers\");\n-            return createPropertiesString(getDefaultLogConfig());\n+            return createLog4jProperties(getDefaultLogConfig());\n+        }\n+    }\n+\n+    /**\n+     * Adds 'monitorInterval=5' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.\n+     * This property is ignored by log4j but used by log4j2.", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNDc5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437604793", "bodyText": "Quite a lot of waiting here. Is all needed?\n\nYou first wait for some unknown time for rolling update to not happen. How long is that waiting?\nThen you wait for the ConfigMap reload\nThan you wait 2*Reconciliation interval for the logging to ... reload?\n\nI wonder if this can be done faster. For example maybe you can check that the pod did not roll just after the other waits instead of waiting for it on the beginning?\nThis applies all over this test - maybe it is really what is needed ... but I wanna raise it just in case you did not considered it.", "author": "scholzj", "createdAt": "2020-06-09T17:38:14Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1).done();\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"5m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"5m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MDEwNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437890105", "bodyText": "The first thing is 50s (it is the same as testing pod stability).\nI do wait for 2*Reconciliation because it is the worst-case time after which is the logging really set to the new value. Reconciliation in tests is 30s so in the worst case the log4j2.properties file is regenerated 30s after the change is applied. Then, there is another 30s monitorInterval after which the configuration is reloaded.", "author": "sknot-rh", "createdAt": "2020-06-10T06:35:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNDc5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzg5MzA1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437893056", "bodyText": "Just because today the intervals in the tests are the same you should not count on it for the future. So maybe it is better to use the timeout based on your calculation and explain it in comments than use 2*Reconciliation which might change and be different in the future (e.g. the default reconciliation in CO is 2 minutes and not 30 seconds, so it might not be something to rely on if your logic is based on 30 seconds comming from something else).", "author": "scholzj", "createdAt": "2020-06-10T06:43:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNDc5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437606629", "bodyText": "Why do you need to switch it off again before the external logging part of the test?", "author": "scholzj", "createdAt": "2020-06-09T17:41:21Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1).done();\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"5m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"5m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYzNTE4Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437635186", "bodyText": "The idea here was to see if the logging is really changed (you see the difference that it will log something).", "author": "im-konge", "createdAt": "2020-06-09T18:30:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYzNzU1NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437637554", "bodyText": "Right ... but you seem to go OFF -> INFO -> OFF ... why is OFF-> INFO not enough?", "author": "scholzj", "createdAt": "2020-06-09T18:34:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY1MzI1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437653251", "bodyText": "We wanted to try inline logging and external logging, so we done it this way. I can simplify it if you agree.", "author": "im-konge", "createdAt": "2020-06-09T19:02:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY1NzMwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437657308", "bodyText": "I can simplify it like this -> setup the inline logging when we are deploying Kafka, then switch it to OFF and then using external logging change it to INFO -> WDYT @scholzj @Frawless @stanlyDoge ?", "author": "im-konge", "createdAt": "2020-06-09T19:10:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY3MDIyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437670227", "bodyText": "That sounds like it might save some time.", "author": "scholzj", "createdAt": "2020-06-09T19:34:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkwNTAzNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437905035", "bodyText": "The idea of this test is to do OFF->INFO for inline and OFF->INFO for external logging, so the steps are (OFF->INFO)->(OFF->INFO).", "author": "sknot-rh", "createdAt": "2020-06-10T07:10:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkwNjMwMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437906302", "bodyText": "That might have been the idea, but since both OFFs are done with internal logging, it is really (OFF -> INFO -> OFF) and the reloading of external logging changes is not tested.", "author": "scholzj", "createdAt": "2020-06-10T07:12:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzkwNjU1Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437906557", "bodyText": "I think the idea makes sense, but the second OFF should be done with external logging.", "author": "scholzj", "createdAt": "2020-06-10T07:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNjYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNzEwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437607103", "bodyText": "Why is this waiting for 5 minutes while for no logs only 30 seconds? If 30 seconds are good there, shouldn't they be good also here and vice versa?", "author": "scholzj", "createdAt": "2020-06-09T17:42:06Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1).done();\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"5m\"), is(not(emptyString())));", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYzNzY5Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437637697", "bodyText": "I did this change -> if I remember what --since (I have this in the getLogFromPodByTime method) takes last x seconds/minutes/hours until the moment you execute ... so I thought that will cause some race conditions when we set only 30s to get log and the EO will not log anything in that time. I can try that and see, if I'm correct.", "author": "im-konge", "createdAt": "2020-06-09T18:35:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNzEwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY0MzY2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437643666", "bodyText": "Right. But, when switching the logging OFF, you approach it that 30s without any log message is enough to take it as configured. But when enabling the INFO level, you seem to suggest that 5 minutes are needed to ensure there is some log message. If you need 5 minutes to be sure you got some message, you also need 5 minutes to ensure you got no message, or?", "author": "scholzj", "createdAt": "2020-06-09T18:45:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNzEwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY1Mjc3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437652778", "bodyText": "Yeah, you are right, I gonna edit this :) thanks Jakub.", "author": "im-konge", "createdAt": "2020-06-09T19:01:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNzEwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzYwNzg0MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r437607841", "bodyText": "I wonder if we should follow with another part where you check that changes to external logging config map were applied as well.", "author": "scholzj", "createdAt": "2020-06-09T17:43:21Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,162 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1).done();\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"5m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"5m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Setting external logging INFO\");\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name=TOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=DEBUG\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name=UOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=DEBUG\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to INFO - records should appear in log\");\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+        );\n+\n+        LOGGER.info(\"Waiting {}ms for INFO log will appear\", RECONCILIATION_INTERVAL * 2);\n+        // wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"5m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"5m\"), is(not(emptyString())));", "originalCommit": "422dabcff73bf5407e8526c1eebaf241c0d2b411", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b1e3b37cee5142e4504fa1c3e9ece39c82624706", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b1e3b37cee5142e4504fa1c3e9ece39c82624706", "message": "change cm\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-10T10:15:18Z", "type": "forcePushed"}, {"oid": "578f2ab84b18915006846b32060707235005e860", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/578f2ab84b18915006846b32060707235005e860", "message": "fix another race\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-10T11:43:54Z", "type": "forcePushed"}, {"oid": "511be1b491742d30ac2a01473bbdebef3a680a23", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/511be1b491742d30ac2a01473bbdebef3a680a23", "message": "change cm\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-15T07:32:14Z", "type": "forcePushed"}, {"oid": "521b9d5d679ab764e0acd0bef5db57cd3f32ba3c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/521b9d5d679ab764e0acd0bef5db57cd3f32ba3c", "message": "change cm\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-15T08:40:13Z", "type": "forcePushed"}, {"oid": "a18661932e12affe2cfba21f1526ef884d0d7305", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a18661932e12affe2cfba21f1526ef884d0d7305", "message": "change cm\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-18T06:10:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4NDI1Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r442984257", "bodyText": "Should 30 be a constant defined somewhere? Just with doign this for EO, you seem to have already 4 places with hardcoded 30.", "author": "scholzj", "createdAt": "2020-06-19T18:18:52Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +407,34 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return maybeAddMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));\n             } else {\n                 log.warn(\"ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.\",\n                         ((ExternalLogging) getLogging()).getName(),\n                         getAncillaryConfigMapKeyLogConfig());\n-                return createPropertiesString(getDefaultLogConfig());\n+                return createLog4jProperties(getDefaultLogConfig());\n             }\n \n         } else {\n             log.debug(\"logging is not set, using default loggers\");\n-            return createPropertiesString(getDefaultLogConfig());\n+            return createLog4jProperties(getDefaultLogConfig());\n+        }\n+    }\n+\n+    /**\n+     * Adds 'monitorInterval=30' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.\n+     * @param data String with log4j(2) properties in format key=value separated by new lines\n+     * @return\n+     */\n+    protected String maybeAddMonitorIntervalToExternalLogging(String data) {\n+        if (getAncillaryConfigMapKeyLogConfig().equals(\"log4j2.properties\") && !data.contains(\"monitorInterval\")) {\n+            // do not override custom value\n+            return data + \"\\nmonitorInterval=30\\n\";", "originalCommit": "f9530c2048a35d672f7396a207904a0274b27946", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4NjExNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r442986117", "bodyText": "Should you wait double the interval? With reloading every 30 seconds, this might basically hit at the same time without any log message, or? Or does the waitForNoRollingUpdate incure some waiting time as well?", "author": "scholzj", "createdAt": "2020-06-19T18:23:13Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,179 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)\n+                .editSpec()\n+                    .editEntityOperator()\n+                        .editTopicOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endTopicOperator()\n+                        .editUserOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endUserOperator()\n+                    .endEntityOperator()\n+                .endSpec()\n+                .done();\n+\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", LOGGING_RELOADING_INTERVAL);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL);", "originalCommit": "f9530c2048a35d672f7396a207904a0274b27946", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4Njc1NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r442986755", "bodyText": "Similar to above ... The sleep is for 30 seconds but you collect logs for one minute ... with previous logging off it should not hurt but seems unexplained. Maybe adding some comments explaining where we wait for how long and why would help.", "author": "scholzj", "createdAt": "2020-06-19T18:24:54Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,179 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)\n+                .editSpec()\n+                    .editEntityOperator()\n+                        .editTopicOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endTopicOperator()\n+                        .editUserOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endUserOperator()\n+                    .endEntityOperator()\n+                .endSpec()\n+                .done();\n+\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", LOGGING_RELOADING_INTERVAL);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(not(emptyString())));", "originalCommit": "f9530c2048a35d672f7396a207904a0274b27946", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk4NzM3Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r442987377", "bodyText": "Same as above ... I think this no logical ... the logs might have just reloaded?", "author": "scholzj", "createdAt": "2020-06-19T18:26:34Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,179 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)\n+                .editSpec()\n+                    .editEntityOperator()\n+                        .editTopicOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endTopicOperator()\n+                        .editUserOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endUserOperator()\n+                    .endEntityOperator()\n+                .endSpec()\n+                .done();\n+\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"INFO\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=INFO\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will appear\", LOGGING_RELOADING_INTERVAL);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting external logging OFF\");\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name=TOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name=UOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - records should not appear in log\");\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", LOGGING_RELOADING_INTERVAL);\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(emptyString()));", "originalCommit": "f9530c2048a35d672f7396a207904a0274b27946", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7c77938028c8b6ef3da85f870d645e811b6ac601", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7c77938028c8b6ef3da85f870d645e811b6ac601", "message": "nits\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-30T09:03:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzU2OTEyNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r447569124", "bodyText": "Is the double empty line needed?", "author": "scholzj", "createdAt": "2020-06-30T10:08:21Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,179 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)\n+                .editSpec()\n+                    .editEntityOperator()\n+                        .editTopicOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endTopicOperator()\n+                        .editUserOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endUserOperator()\n+                    .endEntityOperator()\n+                .endSpec()\n+                .done();\n+\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Changing rootLogger level to DEBUG with inline logging\");\n+        InlineLogging ilDebug = new InlineLogging();\n+        ilDebug.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"DEBUG\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilDebug);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilDebug);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for DEBUG log will appear\", LOGGING_RELOADING_INTERVAL);\n+        // wait some time and check whether logs (UO and TO) after this time contain anything\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting external logging OFF\");\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name=TOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name=UOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - records should not appear in log\");\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for DEBUG log will disappear\", LOGGING_RELOADING_INTERVAL);\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(emptyString()));\n+\n+", "originalCommit": "7c77938028c8b6ef3da85f870d645e811b6ac601", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzU3MDgzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r447570839", "bodyText": "I think I still don't get this. You update the configuration and wait 2*30 seconds for the log reload. In the worst case, the reload happens at the end of the first 30 seconds and the new settings will be valid for the second 30 seconds. So checking the logs for last minut still does not seem to work for me. The same on the line 232.", "author": "scholzj", "createdAt": "2020-06-30T10:11:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java", "diffHunk": "@@ -174,6 +183,179 @@ void testJSONFormatLogging() {\n         assertThat(StUtils.checkLogForJSONFormat(eoPods, \"user-operator\"), is(true));\n     }\n \n+    @Test\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"OFF\"));\n+\n+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)\n+                .editSpec()\n+                    .editEntityOperator()\n+                        .editTopicOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endTopicOperator()\n+                        .editUserOperator()\n+                            .withInlineLogging(ilOff)\n+                        .endUserOperator()\n+                    .endEntityOperator()\n+                .endSpec()\n+                .done();\n+\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Changing rootLogger level to DEBUG with inline logging\");\n+        InlineLogging ilDebug = new InlineLogging();\n+        ilDebug.setLoggers(Collections.singletonMap(\"rootLogger.level\", \"DEBUG\"));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilDebug);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilDebug);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=DEBUG\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for DEBUG log will appear\", LOGGING_RELOADING_INTERVAL);\n+        // wait some time and check whether logs (UO and TO) after this time contain anything\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log will contain some records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(not(emptyString())));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(not(emptyString())));\n+\n+        LOGGER.info(\"Setting external logging OFF\");\n+        ConfigMap configMapTo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-to\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withData(Collections.singletonMap(\"log4j2.properties\", \"name=TOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        ConfigMap configMapUo = new ConfigMapBuilder()\n+                .withNewMetadata()\n+                .withName(\"external-configmap-uo\")\n+                .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .addToData(Collections.singletonMap(\"log4j2.properties\", \"name=UOConfig\\n\" +\n+                        \"appender.console.type=Console\\n\" +\n+                        \"appender.console.name=STDOUT\\n\" +\n+                        \"appender.console.layout.type=PatternLayout\\n\" +\n+                        \"appender.console.layout.pattern=[%d] %-5p <%-12.12c{1}:%L> [%-12.12t] %m%n\\n\" +\n+                        \"rootLogger.level=OFF\\n\" +\n+                        \"rootLogger.appenderRefs=stdout\\n\" +\n+                        \"rootLogger.appenderRef.console.ref=STDOUT\\n\" +\n+                        \"rootLogger.additivity=false\"))\n+                .build();\n+\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapTo);\n+        kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapUo);\n+\n+        ExternalLogging elTo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-to\")\n+                .build();\n+\n+        ExternalLogging elUo = new ExternalLoggingBuilder()\n+                .withName(\"external-configmap-uo\")\n+                .build();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - records should not appear in log\");\n+        // change to external logging\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(elTo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(elUo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+                        && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"monitorInterval=30\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for DEBUG log will disappear\", LOGGING_RELOADING_INTERVAL);\n+        Thread.sleep(LOGGING_RELOADING_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"1m\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"1m\"), is(emptyString()));", "originalCommit": "7c77938028c8b6ef3da85f870d645e811b6ac601", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "20f0866a79cdabe5537b4ad3340171d3277b8fa2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/20f0866a79cdabe5537b4ad3340171d3277b8fa2", "message": "st times\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-30T11:02:29Z", "type": "forcePushed"}, {"oid": "e2f528909915f21ee3e9efa7e534e9646e88b744", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e2f528909915f21ee3e9efa7e534e9646e88b744", "message": "st times\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-30T11:12:44Z", "type": "forcePushed"}, {"oid": "7213f99ccb08554ab43964b862c8b76621b9c5d0", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7213f99ccb08554ab43964b862c8b76621b9c5d0", "message": "st times\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-06-30T11:23:03Z", "type": "forcePushed"}, {"oid": "3821e4a185f096db11d2927641aa58255597ccd2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3821e4a185f096db11d2927641aa58255597ccd2", "message": "rebase+revert install file\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-01T07:25:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ5OTc0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r448499744", "bodyText": "I don't think this is really good enough. monitorInterval could appear in a log4j2 properties config in numerous places other than the top level. You should at least use a regex like ^monitorInterval\\s+= (though you should verify even that). Or we just parse it as an OrderedProperties and check for the monitorInterval key, which I see you're also doing further on....???", "author": "tombentley", "createdAt": "2020-07-01T17:02:59Z", "path": "cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java", "diffHunk": "@@ -408,21 +408,34 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {\n                 newSettings.addMapPairs(inlineLogging.getLoggers());\n             }\n \n-            return createPropertiesString(newSettings);\n-\n+            return createLog4jProperties(newSettings);\n         } else if (logging instanceof ExternalLogging) {\n             if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(getAncillaryConfigMapKeyLogConfig())) {\n-                return externalCm.getData().get(getAncillaryConfigMapKeyLogConfig());\n+                return maybeAddMonitorIntervalToExternalLogging(externalCm.getData().get(getAncillaryConfigMapKeyLogConfig()));\n             } else {\n                 log.warn(\"ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.\",\n                         ((ExternalLogging) getLogging()).getName(),\n                         getAncillaryConfigMapKeyLogConfig());\n-                return createPropertiesString(getDefaultLogConfig());\n+                return createLog4jProperties(getDefaultLogConfig());\n             }\n \n         } else {\n             log.debug(\"logging is not set, using default loggers\");\n-            return createPropertiesString(getDefaultLogConfig());\n+            return createLog4jProperties(getDefaultLogConfig());\n+        }\n+    }\n+\n+    /**\n+     * Adds 'monitorInterval=30' to external logging ConfigMap. If ConfigMap already has this value, it is persisted.\n+     * @param data String with log4j2 properties in format key=value separated by new lines\n+     * @return\n+     */\n+    protected String maybeAddMonitorIntervalToExternalLogging(String data) {\n+        if (getAncillaryConfigMapKeyLogConfig().equals(\"log4j2.properties\") && !data.contains(\"monitorInterval\")) {", "originalCommit": "eee0fb11f4d92520bbee45fd54a02040b639e2d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODUwMzU0MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r448503541", "bodyText": "Rather than adding these calls (which AFAICS just slow the test down) can't you take a pod snapshot (DeploymentUtils.depSnapshot()) at the start and verify that it's the same at the end?", "author": "tombentley", "createdAt": "2020-07-01T17:10:35Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java", "diffHunk": "@@ -329,6 +341,162 @@ private String configMap(String configMapName) {\n         return configMapData.get(configMapKey);\n     }\n \n+    @Test\n+    @Order(14)\n+    @SuppressWarnings({\"checkstyle:MethodLength\"})\n+    void testDynamicallySetEOloggingLevels() throws InterruptedException {\n+        String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);\n+        Map<String, String> eoPods = DeploymentUtils.depSnapshot(eoDeploymentName);\n+\n+        final String eoPodName = eoPods.keySet().iterator().next();\n+\n+        LOGGER.info(\"Setting log level of TO and UO to OFF - no records should appear in log\");\n+        // change inline logging\n+        InlineLogging ilOff = new InlineLogging();\n+        ilOff.setLoggers(Collections.singletonMap(\"rootLogger.level\", OFF));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilOff);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilOff);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);\n+\n+        LOGGER.info(\"Waiting for log4j2.properties will contain desired settings\");\n+        TestUtils.waitFor(\"Logger change\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> cmdKubeClient().execInPodContainer(eoPodName, \"topic-operator\", \"cat\", \"/opt/topic-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+                && cmdKubeClient().execInPodContainer(eoPodName, \"user-operator\", \"cat\", \"/opt/user-operator/custom-config/log4j2.properties\").out().contains(\"rootLogger.level=OFF\")\n+        );\n+\n+        LOGGER.info(\"Waiting {} ms for INFO log will disappear\", RECONCILIATION_INTERVAL * 2);\n+        //wait some time if TO and UO will log something\n+        Thread.sleep(RECONCILIATION_INTERVAL * 2);\n+\n+        LOGGER.info(\"Asserting if log is without records\");\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"topic-operator\", \"30s\"), is(emptyString()));\n+        assertThat(StUtils.getLogFromPodByTime(eoPodName, \"user-operator\", \"30s\"), is(emptyString()));\n+\n+        LOGGER.info(\"Changing rootLogger level to INFO with inline logging\");\n+        InlineLogging ilInfo = new InlineLogging();\n+        ilInfo.setLoggers(Collections.singletonMap(\"rootLogger.level\", INFO));\n+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {\n+            k.getSpec().getEntityOperator().getTopicOperator().setLogging(ilInfo);\n+            k.getSpec().getEntityOperator().getUserOperator().setLogging(ilInfo);\n+        });\n+\n+        LOGGER.info(\"The EO shouldn't roll - verifying pod stability\");\n+        DeploymentUtils.waitForNoRollingUpdate(eoDeploymentName, eoPods);", "originalCommit": "eee0fb11f4d92520bbee45fd54a02040b639e2d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d362363b7c3a88bd4092aa58649c7e857db20efa", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d362363b7c3a88bd4092aa58649c7e857db20efa", "message": "different approach\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-03T10:45:51Z", "type": "forcePushed"}, {"oid": "ca4dcc593850c2ccb1395c504da7d6c83aa27d90", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ca4dcc593850c2ccb1395c504da7d6c83aa27d90", "message": "an attempt to be more optimal\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-03T13:12:29Z", "type": "forcePushed"}, {"oid": "3f3c86883c62c7d76e8f2eb8ababbf8aedc930fa", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3f3c86883c62c7d76e8f2eb8ababbf8aedc930fa", "message": "remove dup test\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-07T11:17:43Z", "type": "forcePushed"}, {"oid": "853916b54010021e2a654b090327b894c4f74582", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/853916b54010021e2a654b090327b894c4f74582", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-08T07:17:51Z", "type": "forcePushed"}, {"oid": "0f70e5986237f025cd4c3501f873d603a387ae24", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0f70e5986237f025cd4c3501f873d603a387ae24", "message": "Dynamically update EO logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "99787c084abec8214efd04a75a8b26a7102d3a20", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/99787c084abec8214efd04a75a8b26a7102d3a20", "message": "checkstyle\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "6328e508f79e68be433b1b0a57bceb0741d1fd5a", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6328e508f79e68be433b1b0a57bceb0741d1fd5a", "message": "comments\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "a92b0f19fa4e9f2218fdc8f14eb5f0770759908d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a92b0f19fa4e9f2218fdc8f14eb5f0770759908d", "message": "fix\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "ed80163d096b85c39f7677211d2f1ad96592bd86", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ed80163d096b85c39f7677211d2f1ad96592bd86", "message": "forgotten assertion\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "337c4d0a3406c123e684d2063aa3af0f8d525e65", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/337c4d0a3406c123e684d2063aa3af0f8d525e65", "message": "removed testing method\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "f3714442bbeddebc2bc9759b45201264ad1c8f6b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f3714442bbeddebc2bc9759b45201264ad1c8f6b", "message": "comment\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "95a18b80e1743e78d10006dead4f3012cd462649", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/95a18b80e1743e78d10006dead4f3012cd462649", "message": "add annotation\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "2b03ca62d481cd5a0e8e81d5c1be10bf70270aa9", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2b03ca62d481cd5a0e8e81d5c1be10bf70270aa9", "message": "increase intervalg\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "7430409207655dc6bfb43d6a28bfb03ddb94f21b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/7430409207655dc6bfb43d6a28bfb03ddb94f21b", "message": "unambiguous method name\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:23Z", "type": "commit"}, {"oid": "d8799ca7b1e74a84c6cb22c4023a6bbb0bd2b05c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d8799ca7b1e74a84c6cb22c4023a6bbb0bd2b05c", "message": "update the test (#2)\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "24c1a745ae82846d82f9c6e31e2f54aef8733e90", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/24c1a745ae82846d82f9c6e31e2f54aef8733e90", "message": "external logging\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "b5db241e8ec5309b94b06df0a6ccc974b93efe7f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b5db241e8ec5309b94b06df0a6ccc974b93efe7f", "message": "what\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "5ee4205f12cf9162cc2eb20a94fb09ff739a7751", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5ee4205f12cf9162cc2eb20a94fb09ff739a7751", "message": "test\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "708c5ffed02e4934672374184fe9345cecc08e68", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/708c5ffed02e4934672374184fe9345cecc08e68", "message": "add another assertions, add logs (#3)\n\nSigned-off-by: Lukas Kral <lukywill16@gmail.com>\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "dc01156b10ce7831e47c57eb90f4137e9178021c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/dc01156b10ce7831e47c57eb90f4137e9178021c", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "70a7da0562a8e69a5dfc1775ee21c63972d5ddea", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/70a7da0562a8e69a5dfc1775ee21c63972d5ddea", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "eacdfdec75b514dabb6fcee69fde79fd0ca714ce", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/eacdfdec75b514dabb6fcee69fde79fd0ca714ce", "message": "respect interval in inline\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "710e2a787fd735956bda50dbd74a44b607457b0b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/710e2a787fd735956bda50dbd74a44b607457b0b", "message": "test\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "00934fad5a0febfad3b9892d1ef5dddf767f39f2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/00934fad5a0febfad3b9892d1ef5dddf767f39f2", "message": "change cm\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "6e88d25a3e2c778a4088f32930b8006b6ef9c180", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6e88d25a3e2c778a4088f32930b8006b6ef9c180", "message": "fix changeloh\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "04649659b5f288b6bbf4a7b8bf1fff553e3c5c71", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/04649659b5f288b6bbf4a7b8bf1fff553e3c5c71", "message": "nits\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "8ffbe2c80021e7516b63481a941e440a4d5f9acc", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/8ffbe2c80021e7516b63481a941e440a4d5f9acc", "message": "st times\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "24e280e34d94ff64698450f815920425e2230785", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/24e280e34d94ff64698450f815920425e2230785", "message": "rebase+revert install file\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "1adccffa141f6b45b2144cf484123869fe176454", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1adccffa141f6b45b2144cf484123869fe176454", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "27f16cd7b3b9a27b8a2195398bf197aa11624b34", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/27f16cd7b3b9a27b8a2195398bf197aa11624b34", "message": "comments\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "2d43bf25c4b6d666a3273f7569a0130868658c62", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/2d43bf25c4b6d666a3273f7569a0130868658c62", "message": "remove dup test\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "4c7bf869e0c0d8e1a4fcf03942a66ece7fc0ccf4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4c7bf869e0c0d8e1a4fcf03942a66ece7fc0ccf4", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "commit"}, {"oid": "4c7bf869e0c0d8e1a4fcf03942a66ece7fc0ccf4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4c7bf869e0c0d8e1a4fcf03942a66ece7fc0ccf4", "message": "rebase\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T07:46:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA0NjA3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r452046075", "bodyText": "just curious, why should we have a different annotation to highlight that this is updated dynamically? Just because we haven't moved yet the others components to use the dynamic logging and we want to distinguish it? Does it mean that when all will be moved to use dynamic logging, we can revert back to use just \"logging\" annotation? I don't see great value to have \"dynamic-\" prefix.", "author": "ppatierno", "createdAt": "2020-07-09T08:19:53Z", "path": "operator-common/src/main/java/io/strimzi/operator/common/Annotations.java", "diffHunk": "@@ -18,6 +18,7 @@\n \n     public static final String STRIMZI_DOMAIN = \"strimzi.io/\";\n     public static final String STRIMZI_LOGGING_ANNOTATION = STRIMZI_DOMAIN + \"logging\";\n+    public static final String STRIMZI_DYNAMIC_LOGGING_ANNOTATION = STRIMZI_DOMAIN + \"dynamic-logging\";", "originalCommit": "4c7bf869e0c0d8e1a4fcf03942a66ece7fc0ccf4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA0OTIyNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r452049226", "bodyText": "Not sure what name this annotation should have. Let me describe why we need this. Let's say user is running a strimzi without the dyn. logging and does not have monitorInterval entry in the log4j2.properties file. CO would add it but it does not have any effect until the pod is rolled and the log4j2 is started with log4j2.properties containing this entry. So it is necessary to roll the pod once the dynamic logging change is available.", "author": "sknot-rh", "createdAt": "2020-07-09T08:25:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA0NjA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA1MDkxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r452050915", "bodyText": "That does not sound to me like a valid reason. When upgrading the CO, it will need to roll all pods to the newest image version. And that should also automatically roll it to use the monitorInterval, or? So I would say it is not needed really.", "author": "scholzj", "createdAt": "2020-07-09T08:27:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA0NjA3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA2NDEyNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2867#discussion_r452064124", "bodyText": "In that case, I can remove it. Thanks.", "author": "sknot-rh", "createdAt": "2020-07-09T08:50:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA0NjA3NQ=="}], "type": "inlineReview"}, {"oid": "4a5c50e73679d4e4157ab720c2b5223a5e1ce8b5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4a5c50e73679d4e4157ab720c2b5223a5e1ce8b5", "message": "remove redundant anno\n\nSigned-off-by: Stanislav Knot <sknot@redhat.com>", "committedDate": "2020-07-09T08:58:34Z", "type": "commit"}]}