{"pr_number": 2482, "pr_title": "[MO] - [system test] -> oauth authorization", "pr_createdAt": "2020-01-30T15:28:16Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482", "timeline": [{"oid": "833a1fda50ec8e401f2d0521e7df4c06c3cd3fe5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/833a1fda50ec8e401f2d0521e7df4c06c3cd3fe5", "message": "[MO] - [system test] -> test cases added 5/7 passing\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-01-31T15:56:30Z", "type": "forcePushed"}, {"oid": "a7e333f0abfa863bc5d95cf1531f9096c807eff7", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a7e333f0abfa863bc5d95cf1531f9096c807eff7", "message": "[MO] - [rebase] -> conflicts\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-04T15:22:41Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxNjYxMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376416610", "bodyText": "Wouldn't it be better to overload createProducerProperties instead of passing \"\" so many times?", "author": "Frawless", "createdAt": "2020-02-07T14:26:03Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -51,18 +62,48 @@\n      * @param clusterName kafka cluster name\n      * @return producer properties\n      */\n-    static Properties createBasicProducerProperties(String namespace, String clusterName) {\n-        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName), \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.BASIC, null);\n+    static Properties createBasicProducerProperties(String namespace, String clusterName) throws KeyStoreException, IOException {\n+        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName),\n+                \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.BASIC, null,", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxNjc3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376416774", "bodyText": "same as above", "author": "Frawless", "createdAt": "2020-02-07T14:26:25Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -51,18 +62,48 @@\n      * @param clusterName kafka cluster name\n      * @return producer properties\n      */\n-    static Properties createBasicProducerProperties(String namespace, String clusterName) {\n-        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName), \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.BASIC, null);\n+    static Properties createBasicProducerProperties(String namespace, String clusterName) throws KeyStoreException, IOException {\n+        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName),\n+                \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.BASIC, null,\n+                \"\", \"\", \"\");\n     }\n \n     /**\n-     * Create producer properties with PLAINTEXT security\n+     * Create tracing producer properties with PLAINTEXT security\n      * @param namespace kafka namespace\n      * @param clusterName kafka cluster name\n      * @return producer properties\n      */\n-    static Properties createTracingProducerProperties(String namespace, String clusterName, String serviceName) {\n-        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName), \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.TRACING, serviceName);\n+    static Properties createTracingProducerProperties(String namespace, String clusterName, String serviceName) throws KeyStoreException, IOException {\n+        return createProducerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName),\n+                \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, EClientType.TRACING, serviceName,", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxNzY0Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376417646", "bodyText": "This is misleading I think. You are passing only one specific type here", "author": "Frawless", "createdAt": "2020-02-07T14:28:10Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -72,9 +113,16 @@ static Properties createTracingProducerProperties(String namespace, String clust\n      * @param caSecretName CA secret name\n      * @param userName user name for authorization\n      * @param securityProtocol security protocol\n+     * @param clientType enum for all supported clients", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQxODY5Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376418693", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-02-07T14:30:02Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -86,7 +134,61 @@ static Properties createProducerProperties(String namespace, String clusterName,\n \n         producerProperties.putAll(sharedClientProperties(namespace, caSecretName, userName, securityProtocol));\n \n-        // TODO: create Tracing client properties if (clientType == EClientType.TRACING) { setTracingProperties().... serviceName} same with Oauth\n+        LOGGER.info(\"Username has name:{}\", userName);\n+\n+        if (clientType == EClientType.OAUTH) {\n+            // plain\n+            if (userName.equals(\"\")) {\n+                LOGGER.info(\"Enabling Plaintext with setting {}={}\", CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+\n+                producerProperties.setProperty(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+                producerProperties.setProperty(\"sasl.mechanism\", \"OAUTHBEARER\");\n+                producerProperties.setProperty(\"sasl.login.callback.handler.class\", \"io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\");\n+                producerProperties.setProperty(\"sasl.jaas.config\",\n+                        \"org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule \" +\n+                                \"required \" +\n+                                \"oauth.client.id=\\\"\" + clientId + \"\\\" \" +\n+                                \"oauth.client.secret=\\\"\" + clientSecretName + \"\\\" \" +\n+                                \"oauth.token.endpoint.uri=\\\"\" + oauthTokenEndpointUri + \"\\\";\");\n+            } else {\n+            // tls", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMDQ0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376420442", "bodyText": "same as above", "author": "Frawless", "createdAt": "2020-02-07T14:33:10Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -97,8 +199,41 @@ static Properties createProducerProperties(String namespace, String clusterName,\n      * @param clusterName kafka cluster name\n      * @return consumer configuration\n      */\n-    static Properties createConsumerProperties(String namespace, String clusterName, String consumerGroup) {\n-        return createConsumerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName), \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, consumerGroup);\n+    static Properties createConsumerProperties(String namespace, String clusterName, String consumerGroup) throws IOException {\n+        return createConsumerProperties(namespace, clusterName, KafkaResources.clusterCaCertificateSecretName(clusterName),\n+                \"\", CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL, consumerGroup, EClientType.BASIC,", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMTM4NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376421385", "bodyText": "This while indicates a possibility that keycloak will contains more than one secret, is that correct? If no, simple if could be enough?", "author": "Frawless", "createdAt": "2020-02-07T14:34:57Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -122,6 +259,60 @@ static Properties createConsumerProperties(String namespace, String clusterName,\n \n         consumerProperties.putAll(sharedClientProperties(namespace, caSecretName, userName, securityProtocol));\n \n+        if (clientType == EClientType.OAUTH) {\n+            // plain\n+            if (userName.equals(\"\")) {\n+                LOGGER.info(\"Enabling Plaintext with setting {}={}\", CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+\n+                consumerProperties.setProperty(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+                consumerProperties.setProperty(\"sasl.mechanism\", \"OAUTHBEARER\");\n+                consumerProperties.setProperty(\"sasl.login.callback.handler.class\", \"io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\");\n+                consumerProperties.setProperty(\"sasl.jaas.config\",\n+                        \"org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule \" +\n+                                \"required \" +\n+                                \"oauth.client.id=\\\"\" + clientId + \"\\\" \" +\n+                                \"oauth.client.secret=\\\"\" + clientSecretName + \"\\\" \" +\n+                                \"oauth.token.endpoint.uri=\\\"\" + oauthTokenEndpointUri + \"\\\";\");\n+            } else {\n+                String responseKeycloak = Exec.exec(\"openssl\", \"s_client\", \"-showcerts\", \"-connect\", kubeClient().getNodeAddress() + \":\" + Constants.HTTPS_KEYCLOAK_DEFAULT_NODE_PORT).out();\n+                Matcher matcher = Pattern.compile(\"-----(?s)(.*)-----\").matcher(responseKeycloak);\n+\n+                String keycloakCertificateData = null;\n+\n+                while (matcher.find()) {", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMTgwMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376421801", "bodyText": "Debug level with some additional info?", "author": "Frawless", "createdAt": "2020-02-07T14:35:39Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -166,7 +357,9 @@ private static Properties sharedClientProperties(String namespace, String caSecr\n             }\n \n             properties.setProperty(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, \"PKCS12\");\n+            LOGGER.info(tsPassword);", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMjA3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376422078", "bodyText": "Debug level with some additional info? Or it's needed for better understanding on INFO log level?", "author": "Frawless", "createdAt": "2020-02-07T14:36:06Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -166,7 +357,9 @@ private static Properties sharedClientProperties(String namespace, String caSecr\n             }\n \n             properties.setProperty(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, \"PKCS12\");\n+            LOGGER.info(tsPassword);\n             properties.setProperty(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, tsPassword);\n+            LOGGER.info(\"SSL truststore locaation {}\", tsFile.getAbsolutePath());", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwODM0Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376708343", "bodyText": "no need to have it on level INFO.", "author": "see-quick", "createdAt": "2020-02-08T12:49:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMjA3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyMjIwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376422203", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-02-07T14:36:19Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -199,6 +392,7 @@ private static Properties sharedClientProperties(String namespace, String caSecr\n                         Base64.getDecoder().decode(userCaCert),\n                         Base64.getDecoder().decode(userCaKey),\n                         ksPassword);\n+                LOGGER.info(\"Keystore location is here:{}\", ksFile.getAbsolutePath());", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyOTM5Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376429392", "bodyText": "Why printing this? What is the output of it?", "author": "Frawless", "createdAt": "2020-02-07T14:49:33Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthKafkaClient.java", "diffHunk": "@@ -5,28 +5,172 @@\n package io.strimzi.systemtest.kafkaclients.externalClients;\n \n import io.strimzi.systemtest.kafkaclients.IKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.vertx.core.Vertx;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n \n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n \n public class OauthKafkaClient implements IKafkaClient {\n \n+    private Vertx vertx = Vertx.vertx();\n+    private static final Logger LOGGER = LogManager.getLogger(KafkaClient.class);\n+\n+    private String caCertName;\n+    private String clientId;\n+    private String clientSecretName;\n+    private String oauthTokenEndpointUri;\n+\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) throws KeyStoreException, IOException {\n+        return sendMessages(topicName, namespace, clusterName, messageCount, 120);\n+    }\n+\n     @Override\n-    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount, int timeoutInSeconds) throws KeyStoreException, IOException {\n+        String clientName = \"sender-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createOauthProducerProperties(namespace, clusterName, \"\",\n+                this.clientId, this.clientSecretName, this.oauthTokenEndpointUri), resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) throws IOException, KeyStoreException {\n+        return sendMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, 120);\n     }\n \n     @Override\n-    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, int timeoutInSeconds) throws IOException, KeyStoreException {\n+        String clientName = \"sender-ssl\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        String caCertName = this.caCertName == null ? KafkaResource.getKafkaExternalListenerCaCertName(namespace, clusterName) : this.caCertName;\n+        LOGGER.info(\"Going to use the following CA certificate: {}\", caCertName);\n+\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createOauthProducerTlsProperties(namespace, clusterName,\n+                caCertName, kafkaUsername, securityProtocol, null, this.clientId, this.clientSecretName,\n+                this.oauthTokenEndpointUri), resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount, String consumerGroup) throws IOException {\n+        return receiveMessages(topicName, namespace, clusterName, messageCount, consumerGroup, 120);\n     }\n \n     @Override\n-    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount, String consumerGroup) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount, String consumerGroup, int timeoutInSeconds) throws IOException {\n+        String clientName = \"receiver-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        vertx.deployVerticle(new Consumer(KafkaClientProperties.createOauthConsumerProperties(namespace, clusterName, consumerGroup,\n+                this.clientId, this.clientSecretName, this.oauthTokenEndpointUri), resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, String consumerGroup) throws IOException {\n+        return receiveMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, consumerGroup, 120);\n+    }\n+\n+    @Override\n+    public Future<Integer> receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, String consumerGroup, int timeoutInSeconds) throws IOException {\n+        String clientName = \"receiver-ssl-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        String caCertName = this.caCertName == null ? KafkaResource.getKafkaExternalListenerCaCertName(namespace, clusterName) : this.caCertName;\n+        LOGGER.info(\"Going to use the following CA certificate: {}\", caCertName);\n+\n+        vertx.deployVerticle(new Consumer(KafkaClientProperties.createOauthTlsConsumerProperties(namespace, clusterName,\n+                caCertName, kafkaUsername, securityProtocol, consumerGroup, this.clientId, this.clientSecretName, this.oauthTokenEndpointUri),\n+                resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public String getCaCertName() {\n+        return caCertName;\n+    }\n+\n+    public void setCaCertName(String caCertName) {\n+        this.caCertName = caCertName;\n+    }\n+\n+    public String getClientId() {\n+        return clientId;\n+    }\n+\n+    public void setClientId(String clientId) {\n+        this.clientId = clientId;\n+    }\n+\n+    public String getClientSecretName() {\n+        return clientSecretName;\n+    }\n+\n+    public void setClientSecretName(String clientSecretName) {\n+        this.clientSecretName = clientSecretName;\n+    }\n+\n+    public String getOauthTokenEndpointUri() {\n+        return oauthTokenEndpointUri;\n+    }\n+\n+    public void setOauthTokenEndpointUri(String oauthTokenEndpointUri) {\n+        this.oauthTokenEndpointUri = oauthTokenEndpointUri;\n     }\n \n     @Override\n-    public Future<Integer> receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, String consumerGroup) {\n-        throw new UnsupportedOperationException();\n+    public String toString() {\n+        return \"OauthKafkaClient{\" +\n+                \"vertx=\" + vertx +", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwODUwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376708503", "bodyText": "For instance, if you deploy the client you want to see how it is setup. I am using it in the test suites.", "author": "see-quick", "createdAt": "2020-02-08T12:53:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyOTM5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njg4OTU4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376889580", "bodyText": "\"vertx=\" + vertx +", "author": "Frawless", "createdAt": "2020-02-10T06:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyOTM5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQyOTgzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376429839", "bodyText": "use constant for timeout?", "author": "Frawless", "createdAt": "2020-02-07T14:50:24Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -78,10 +78,9 @@ private Integer sendMessages(String topicName, String namespace, String clusterN\n      * @param securityProtocol option for tls listener inside kafka cluster\n      * @return count of send and acknowledged messages\n      */\n-    @Override\n     public Integer sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) throws InterruptedException {\n         LOGGER.info(\"Sending messages to pod: {}\", this.podName);\n-        return sendMessages(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, this.podName);\n+        return sendMessages(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, this.podName, 120_000);", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzMDE3MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376430170", "bodyText": "same as above", "author": "Frawless", "createdAt": "2020-02-07T14:50:56Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -160,16 +186,50 @@ public Integer receiveMessagesTls(String topicName, String namespace, String clu\n         return received;\n     }\n \n+\n+    /**\n+     * Method for receive messages from specific kafka cluster. It uses test-client API for communication with deployed clients inside kubernetes cluster\n+     * @param messageCount message count\n+     * @param clusterName cluster name\n+     * @param topicName topic name\n+     * @return count of received messages\n+     */\n+    public Integer receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUserName, int messageCount, String securityProtocol, String consumerGroup) {\n+        return receiveMessagesTls(topicName, namespace, clusterName, kafkaUserName, messageCount, securityProtocol, consumerGroup, 120_000);", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzMDkwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376430903", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-02-07T14:52:10Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -183,7 +243,7 @@ public Integer receiveMessages(String topicName, String namespace, String cluste\n      * @return count of received messages\n      */\n     public Integer receiveMessages(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String consumerGroup) {\n-        return receiveMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, \"PLAIN\", consumerGroup);\n+        return receiveMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, \"PLAIN\", consumerGroup, 120_000);", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzMTU2Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376431567", "bodyText": "indent", "author": "Frawless", "createdAt": "2020-02-07T14:53:21Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java", "diffHunk": "@@ -258,6 +258,23 @@ public static DoneableService createServiceResource(Service service, String clie\n         return new DoneableService(service);\n     }\n \n+    public static Service deployKeycloakNodePortHttpService(String namespace) {\n+        String keycloakName = \"keycloak\";\n+\n+        Map<String, String> keycloakLabels = new HashMap<>();\n+        keycloakLabels.put(\"app\", keycloakName);\n+\n+        return getSystemtestsServiceResource(keycloakName + \"service-http\",\n+                Constants.HTTP_KEYCLOAK_DEFAULT_PORT, namespace, \"TCP\")\n+                .editSpec()\n+                .withType(\"NodePort\")\n+                .withSelector(keycloakLabels)\n+                .editFirstPort()\n+                .withNodePort(Constants.HTTP_KEYCLOAK_DEFAULT_NODE_PORT)\n+                .endPort()", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzNTI1Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376435257", "bodyText": "typo, i -> I", "author": "Frawless", "createdAt": "2020-02-07T15:00:22Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MjUwOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376442508", "bodyText": "Maybe As a member of team A, I should be able to read and write to all topics starting with a-", "author": "Frawless", "createdAt": "2020-02-07T15:13:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzNTI1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQzNTU4NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376435585", "bodyText": "typo", "author": "Frawless", "createdAt": "2020-02-07T15:00:57Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MDE1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376440151", "bodyText": "I think you should do assertThrown instead of this call, it will work every time.", "author": "Frawless", "createdAt": "2020-02-07T15:09:01Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MDY0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376440649", "bodyText": "This better fits as a comment instead of log message, WDYT?", "author": "Frawless", "createdAt": "2020-02-07T15:09:53Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a team B, i has full access on topics starting with 'b-'\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MDk1Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376440956", "bodyText": "Same as above", "author": "Frawless", "createdAt": "2020-02-07T15:10:21Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a team B, i has full access on topics starting with 'b-'\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MTY2Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376441667", "bodyText": "@Disalbed(\"Will e implemented in next PR\")", "author": "Frawless", "createdAt": "2020-02-07T15:11:36Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a team B, i has full access on topics starting with 'b-'\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_B);\n+\n+        Future<Integer> producer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_\" + CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n+\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A,  can write to topics starting with 'x-' and Team B can read from topics starting with 'x-'\")\n+    @Test\n+    void testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        // only write means that Team A can not create new topic 'x-.*'\n+        String topicName = TOPIC_X + \"-example\";\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_consumer_group_b\");\n+\n+        assertThat(consumer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testListTopics() {", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MTcxOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376441718", "bodyText": "@Disalbed(\"Will e implemented in next PR\")", "author": "Frawless", "createdAt": "2020-02-07T15:11:41Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a team B, i has full access on topics starting with 'b-'\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_B);\n+\n+        Future<Integer> producer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_\" + CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n+\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A,  can write to topics starting with 'x-' and Team B can read from topics starting with 'x-'\")\n+    @Test\n+    void testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        // only write means that Team A can not create new topic 'x-.*'\n+        String topicName = TOPIC_X + \"-example\";\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_consumer_group_b\");\n+\n+        assertThat(consumer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testListTopics() {\n+        // TODO: in the new PR add AdminClient support with operations listTopics(), etc.\n+    }\n+\n+    @Test\n+    void testClusterVerification() {", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0Mjc0OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376442749", "bodyText": "More info? Which uris? What is it good for?", "author": "Frawless", "createdAt": "2020-02-07T15:13:28Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+    @Description(\"As a team A, i can do anything with topics starting with 'a-'\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As i team A, i can write to topics that starts with 'x-' on any cluster and do anything to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A, has only access that consumer group starts with 'a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        try {\n+            teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a team B, i has full access on topics starting with 'b-'\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        try {\n+            Future<Integer> invalidProducer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                    MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+\n+        } catch (Exception e) {\n+            LOGGER.info(\"Excepted message:{}\", e.getMessage());\n+        }\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_B);\n+\n+        Future<Integer> producer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_\" + CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n+\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a team A,  can write to topics starting with 'x-' and Team B can read from topics starting with 'x-'\")\n+    @Test\n+    void testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        // only write means that Team A can not create new topic 'x-.*'\n+        String topicName = TOPIC_X + \"-example\";\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_consumer_group_b\");\n+\n+        assertThat(consumer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Test\n+    void testListTopics() {\n+        // TODO: in the new PR add AdminClient support with operations listTopics(), etc.\n+    }\n+\n+    @Test\n+    void testClusterVerification() {\n+        // TODO: create more examples via cluster wide stuff\n+    }\n+\n+    @BeforeAll\n+    void setUp()  {\n+        LOGGER.info(\"Replacing all URIs\");", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwOTcwMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376709700", "bodyText": "validIssuerUri, jwksEndpointUri,  oauthTokenEndpointUri. This one URIs, I know that it would be better to have an abstraction but this way you just change pointing Keycloak to another realm", "author": "see-quick", "createdAt": "2020-02-08T13:18:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0Mjc0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcwOTcyNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376709725", "bodyText": "but of course, I will change this log message )", "author": "see-quick", "createdAt": "2020-02-08T13:19:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0Mjc0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ0MzkxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376443915", "bodyText": "in deployTestSpecificResources you deploy CO so you should remove it from it, or don't call super.recreateTestEnv", "author": "Frawless", "createdAt": "2020-02-07T15:15:29Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthBaseST.java", "diffHunk": "@@ -122,80 +123,64 @@ void setup() throws InterruptedException {\n \n         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1)\n                 .editSpec()\n-                .editKafka()\n-                .editListeners()\n-                .withNewPlain()\n-                .withNewKafkaListenerAuthenticationOAuth()\n-                .withValidIssuerUri(validIssuerUri)\n-                .withJwksEndpointUri(jwksEndpointUri)\n-                .withJwksExpirySeconds(500)\n-                .withJwksRefreshSeconds(400)\n-                .withEnableECDSA(true)\n-                .withUserNameClaim(userNameClaim)\n-                .withTlsTrustedCertificates(\n-                        new CertSecretSourceBuilder()\n-                                .withSecretName(SECRET_OF_KEYCLOAK)\n-                                .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                                .build())\n-                .withDisableTlsHostnameVerification(true)\n-                .endKafkaListenerAuthenticationOAuth()\n-                .endPlain()\n-                .withNewTls()\n-                .withNewKafkaListenerAuthenticationOAuth()\n-                .withValidIssuerUri(validIssuerUri)\n-                .withJwksEndpointUri(jwksEndpointUri)\n-                .withJwksExpirySeconds(500)\n-                .withJwksRefreshSeconds(400)\n-                .withEnableECDSA(true)\n-                .withUserNameClaim(userNameClaim)\n-                .withTlsTrustedCertificates(\n-                        new CertSecretSourceBuilder()\n-                                .withSecretName(SECRET_OF_KEYCLOAK)\n-                                .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                                .build())\n-                .withDisableTlsHostnameVerification(true)\n-                .endKafkaListenerAuthenticationOAuth()\n-                .endTls()\n-                .withNewKafkaListenerExternalNodePort()\n-                .withNewKafkaListenerAuthenticationOAuth()\n-                .withValidIssuerUri(validIssuerUri)\n-                .withJwksExpirySeconds(500)\n-                .withJwksRefreshSeconds(400)\n-                .withJwksEndpointUri(jwksEndpointUri)\n-                .withEnableECDSA(true)\n-                .withUserNameClaim(userNameClaim)\n-                .withTlsTrustedCertificates(\n-                        new CertSecretSourceBuilder()\n-                                .withSecretName(SECRET_OF_KEYCLOAK)\n-                                .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                                .build())\n-                .withDisableTlsHostnameVerification(true)\n-                .endKafkaListenerAuthenticationOAuth()\n-                .endKafkaListenerExternalNodePort()\n-                .endListeners()\n-                .endKafka()\n+                    .editKafka()\n+                        .editListeners()\n+                            .withNewTls()\n+                                .withNewKafkaListenerAuthenticationOAuth()\n+                                    .withValidIssuerUri(validIssuerUri)\n+                                    .withJwksExpirySeconds(JWKS_EXPIRE_SECONDS)\n+                                    .withJwksRefreshSeconds(JWKS_REFRESH_SECONDS)\n+                                    .withJwksEndpointUri(jwksEndpointUri)\n+                                    .withUserNameClaim(userNameClaim)\n+                                    .withTlsTrustedCertificates(\n+                                        new CertSecretSourceBuilder()\n+                                            .withSecretName(SECRET_OF_KEYCLOAK)\n+                                            .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n+                                            .build())\n+                                    .withDisableTlsHostnameVerification(true)\n+                                .endKafkaListenerAuthenticationOAuth()\n+                            .endTls()\n+                            .withNewKafkaListenerExternalNodePort()\n+                                .withNewKafkaListenerAuthenticationOAuth()\n+                                    .withValidIssuerUri(validIssuerUri)\n+                                    .withJwksExpirySeconds(JWKS_EXPIRE_SECONDS)\n+                                    .withJwksRefreshSeconds(JWKS_REFRESH_SECONDS)\n+                                    .withJwksEndpointUri(jwksEndpointUri)\n+                                    .withUserNameClaim(userNameClaim)\n+                                    .withTlsTrustedCertificates(\n+                                        new CertSecretSourceBuilder()\n+                                            .withSecretName(SECRET_OF_KEYCLOAK)\n+                                            .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n+                                            .build())\n+                                    .withDisableTlsHostnameVerification(true)\n+                                .endKafkaListenerAuthenticationOAuth()\n+                            .endKafkaListenerExternalNodePort()\n+                        .endListeners()\n+                    .endKafka()\n                 .endSpec()\n                 .done();\n \n         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();\n-        KafkaTopicResource.topic(CLUSTER_NAME, REVERSE_TOPIC_NAME).done();\n \n         createSecretsForDeployments();\n \n-        KafkaUserResource.tlsUser(CLUSTER_NAME, PRODUCER_USER_NAME).done();\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, CONSUMER_USER_NAME).done();\n-        KafkaUserResource.tlsUser(CLUSTER_NAME, STREAMS_USER_NAME).done();\n+        KafkaUserResource.tlsUser(CLUSTER_NAME, OAUTH_CLIENT_NAME).done();\n     }\n \n     private void createSecretsForDeployments() {\n-        SecretUtils.createSecret(PRODUCER_OAUTH_SECRET, OAUTH_KEY, \"aGVsbG8td29ybGQtcHJvZHVjZXItc2VjcmV0\");\n-        SecretUtils.createSecret(CONSUMER_OAUTH_SECRET, OAUTH_KEY, \"aGVsbG8td29ybGQtY29uc3VtZXItc2VjcmV0\");\n-        SecretUtils.createSecret(STREAMS_OAUTH_SECRET, OAUTH_KEY, \"aGVsbG8td29ybGQtc3RyZWFtcy1zZWNyZXQ=\");\n         SecretUtils.createSecret(CONNECT_OAUTH_SECRET, OAUTH_KEY, \"a2Fma2EtY29ubmVjdC1zZWNyZXQ=\");\n         SecretUtils.createSecret(MIRROR_MAKER_OAUTH_SECRET, OAUTH_KEY, \"a2Fma2EtbWlycm9yLW1ha2VyLXNlY3JldA==\");\n         SecretUtils.createSecret(MIRROR_MAKER_2_OAUTH_SECRET, OAUTH_KEY, \"a2Fma2EtbWlycm9yLW1ha2VyLTItc2VjcmV0\");\n         SecretUtils.createSecret(BRIDGE_OAUTH_SECRET, OAUTH_KEY, \"a2Fma2EtYnJpZGdlLXNlY3JldA==\");\n     }\n+\n+    @Override\n+    protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) throws InterruptedException {\n+        super.recreateTestEnv(coNamespace, bindingsNamespaces);\n+\n+        createSecretsForDeployments();\n+        deployTestSpecificResources();", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5MzAyOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376493028", "bodyText": "Typos", "author": "Frawless", "createdAt": "2020-02-07T16:44:49Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java", "diffHunk": "@@ -49,165 +65,103 @@\n @Tag(NODEPORT_SUPPORTED)\n public class OauthPlainST extends OauthBaseST {\n \n-    @Test\n-    void testProducerConsumer() {\n-        KafkaClientsResource.producerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-        KafkaClientsResource.consumerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-\n-        String producerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(producerPodName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(producerPodName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n-\n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n-\n-        String consumerLogs = kubeClient().logs(consumerPodName);\n-\n-        for (int i = 0; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n-    }\n+    private OauthKafkaClient oauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n \n+    @Description(\n+            \"As an oauth producer, i am able to produce messages to the kafka broker\\n\" +", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NDAwNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376494007", "bodyText": "Add description why it's disabled", "author": "Frawless", "createdAt": "2020-02-07T16:46:48Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java", "diffHunk": "@@ -49,165 +65,103 @@\n @Tag(NODEPORT_SUPPORTED)\n public class OauthPlainST extends OauthBaseST {\n \n-    @Test\n-    void testProducerConsumer() {\n-        KafkaClientsResource.producerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-        KafkaClientsResource.consumerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-\n-        String producerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(producerPodName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(producerPodName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n-\n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n-\n-        String consumerLogs = kubeClient().logs(consumerPodName);\n-\n-        for (int i = 0; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n-    }\n+    private OauthKafkaClient oauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n \n+    @Description(\n+            \"As an oauth producer, i am able to produce messages to the kafka broker\\n\" +\n+            \"As an oauth consumer, i am able to consumer messages from the kafka broker.\")\n     @Test\n-    void testProducerConsumerStreams() {\n-        KafkaClientsResource.producerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-        KafkaClientsResource.consumerWithOauth(oauthTokenEndpointUri, \"my-topic-reversed\", KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-        KafkaClientsResource.kafkaStreamsWithOauth(oauthTokenEndpointUri, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-\n-        String producerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n+    void testProducerConsumer() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = oauthKafkaClient.sendMessages(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT);\n+        Future<Integer> consumer = oauthKafkaClient.receiveMessages(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT,\n+                CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n \n-        PodUtils.waitUntilMessageIsInPodLogs(producerPodName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(producerPodName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n-\n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"\" + reverseNumber(END_MESSAGE_OFFSET) + \" - dlrow olleH\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n-\n-        String consumerLogs = kubeClient().logs(consumerPodName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"\" + reverseNumber(i) + \" - dlrow olleH\\\"\"));\n-        }\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n     }\n \n+    @Description(\"As an oauth kafka connect, i am able to sink messages from kafka broker topic.\")\n     @Test\n-    void testProducerConsumerConnect() {\n-        KafkaClientsResource.producerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n-        KafkaClientsResource.consumerWithOauth(oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME)).done();\n+    void testProducerConsumerConnect() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = oauthKafkaClient.sendMessages(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT);\n+        Future<Integer> consumer = oauthKafkaClient.receiveMessages(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT,\n+                CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n \n         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n                 .editMetadata()\n                     .addToLabels(\"type\", \"kafka-connect\")\n                 .endMetadata()\n-                .editSpec()\n+                .withNewSpec()\n+                    .withReplicas(1)\n+                    .withBootstrapServers(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n                     .addToConfig(\"key.converter.schemas.enable\", false)\n                     .addToConfig(\"value.converter.schemas.enable\", false)\n+                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n                     .withNewKafkaClientAuthenticationOAuth()\n                         .withTokenEndpointUri(oauthTokenEndpointUri)\n                         .withClientId(\"kafka-connect\")\n                         .withNewClientSecret()\n                             .withSecretName(CONNECT_OAUTH_SECRET)\n                             .withKey(OAUTH_KEY)\n                         .endClientSecret()\n-                        .withTlsTrustedCertificates(\n-                            new CertSecretSourceBuilder()\n-                                    .withSecretName(SECRET_OF_KEYCLOAK)\n-                                    .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                                    .build())\n-                        .withDisableTlsHostnameVerification(true)\n                     .endKafkaClientAuthenticationOAuth()\n+                    .withTls(null)\n                 .endSpec()\n                 .done();\n \n         String kafkaConnectPodName = kubeClient().listPods(\"type\", \"kafka-connect\").get(0).getMetadata().getName();\n-        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);\n \n         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);\n \n-        KafkaConnectUtils.createFileSinkConnector(execPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n+        KafkaConnectUtils.createFileSinkConnector(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n \n-        String message = \"Hello world - \" + END_MESSAGE_OFFSET;\n+        String message = \"Sending messages: Hello-world - 99\";\n \n-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, message);\n+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName,  Constants.DEFAULT_SINK_FILE_NAME);\n \n         assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, \"/bin/bash\", \"-c\", \"cat \" + Constants.DEFAULT_SINK_FILE_NAME).out(),\n                 containsString(message));\n     }\n \n+    @Disabled", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NTI1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376495252", "bodyText": "Add description why it's disabled", "author": "Frawless", "createdAt": "2020-02-07T16:49:11Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java", "diffHunk": "@@ -217,57 +171,52 @@ void testProducerConsumerMirrorMaker() {\n         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, CLUSTER_NAME, targetKafkaCluster,\n                 \"my-group\" +  new Random().nextInt(Integer.MAX_VALUE), 1, false)\n                 .editSpec()\n-                    .editConsumer()\n+                    .withNewConsumer()\n+                        .withBootstrapServers(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n+                        .withGroupId(\"my-group\" +  new Random().nextInt(Integer.MAX_VALUE))\n+                        .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\")\n                         .withNewKafkaClientAuthenticationOAuth()\n                             .withNewTokenEndpointUri(oauthTokenEndpointUri)\n                             .withClientId(\"kafka-mirror-maker\")\n                             .withNewClientSecret()\n                                 .withSecretName(MIRROR_MAKER_OAUTH_SECRET)\n                                 .withKey(OAUTH_KEY)\n                             .endClientSecret()\n-                            .addNewTlsTrustedCertificate()\n-                                .withSecretName(SECRET_OF_KEYCLOAK)\n-                                .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                            .endTlsTrustedCertificate()\n-                            .withDisableTlsHostnameVerification(true)\n                         .endKafkaClientAuthenticationOAuth()\n+                        .withTls(null)\n                     .endConsumer()\n-                    .editProducer()\n+                    .withNewProducer()\n+                        .withBootstrapServers(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))\n                         .withNewKafkaClientAuthenticationOAuth()\n                             .withNewTokenEndpointUri(oauthTokenEndpointUri)\n                             .withClientId(\"kafka-mirror-maker\")\n                             .withNewClientSecret()\n                                 .withSecretName(MIRROR_MAKER_OAUTH_SECRET)\n                                 .withKey(OAUTH_KEY)\n                             .endClientSecret()\n-                            .addNewTlsTrustedCertificate()\n-                                .withSecretName(SECRET_OF_KEYCLOAK)\n-                                .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n-                            .endTlsTrustedCertificate()\n-                            .withDisableTlsHostnameVerification(true)\n                         .endKafkaClientAuthenticationOAuth()\n+                        .addToConfig(ProducerConfig.ACKS_CONFIG, \"all\")\n+                        .withTls(null)\n                     .endProducer()\n                 .endSpec()\n                 .done();\n \n-        KafkaClientsResource.consumerWithOauth(\"hello-world-consumer-target\", oauthTokenEndpointUri, TOPIC_NAME, KafkaResources.plainBootstrapAddress(targetKafkaCluster)).done();\n-\n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-target-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n-\n-        String consumerLogs = kubeClient().logs(consumerPodName);\n+        // TODO: doesn't work...\n+        consumer = oauthKafkaClient.receiveMessages(TOPIC_NAME, NAMESPACE, targetKafkaCluster, MESSAGE_COUNT,\n+                CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n \n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"MirrorMaker doesn't replicated data to target kafka cluster\", consumerLogs, containsString(\"value: \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n     }\n \n+    @Disabled", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NjI4Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376496283", "bodyText": "typos", "author": "Frawless", "createdAt": "2020-02-07T16:51:13Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java", "diffHunk": "@@ -43,143 +54,113 @@\n @Tag(NODEPORT_SUPPORTED)\n public class OauthTlsST extends OauthBaseST {\n \n-    @Test\n-    void testProducerConsumer() {\n-        deployProducerWithOauthTls();\n-        deployConsumerWithOauthTls(TOPIC_NAME);\n-\n-        String podName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        LOGGER.info(\"Waiting for:\" + producerMessage);\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(podName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(podName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+    private OauthKafkaClient oauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n \n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n+    @Description(\n+            \"As an oauth producer, i am able to produce messages to the kafka broker\\n\" +", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NjM4Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376496383", "bodyText": "Typos", "author": "Frawless", "createdAt": "2020-02-07T16:51:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java", "diffHunk": "@@ -43,143 +54,113 @@\n @Tag(NODEPORT_SUPPORTED)\n public class OauthTlsST extends OauthBaseST {\n \n-    @Test\n-    void testProducerConsumer() {\n-        deployProducerWithOauthTls();\n-        deployConsumerWithOauthTls(TOPIC_NAME);\n-\n-        String podName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        LOGGER.info(\"Waiting for:\" + producerMessage);\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(podName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(podName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+    private OauthKafkaClient oauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n \n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n+    @Description(\n+            \"As an oauth producer, i am able to produce messages to the kafka broker\\n\" +\n+            \"As an oauth consumer, i am able to consumer messages from the kafka broker using encrypted communication\")\n+    @Test\n+    void testProducerConsumer() throws IOException, KeyStoreException, InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {\n+        Future<Integer> producer = oauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\");\n \n-        String consumerLogs = kubeClient().logs(consumerPodName);\n+        Future<Integer> consumer = oauthKafkaClient.receiveMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\", CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n \n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n     }\n \n+    @Description(\"As an oauth kafka connect, i am able to sink messages from kafka broker topic using encrypted communication.\")", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NzAyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376497023", "bodyText": "Typos", "author": "Frawless", "createdAt": "2020-02-07T16:52:41Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java", "diffHunk": "@@ -43,143 +54,113 @@\n @Tag(NODEPORT_SUPPORTED)\n public class OauthTlsST extends OauthBaseST {\n \n-    @Test\n-    void testProducerConsumer() {\n-        deployProducerWithOauthTls();\n-        deployConsumerWithOauthTls(TOPIC_NAME);\n-\n-        String podName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        LOGGER.info(\"Waiting for:\" + producerMessage);\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(podName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(podName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+    private OauthKafkaClient oauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n \n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-        String consumerMessage = \"value: \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n+    @Description(\n+            \"As an oauth producer, i am able to produce messages to the kafka broker\\n\" +\n+            \"As an oauth consumer, i am able to consumer messages from the kafka broker using encrypted communication\")\n+    @Test\n+    void testProducerConsumer() throws IOException, KeyStoreException, InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {\n+        Future<Integer> producer = oauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\");\n \n-        String consumerLogs = kubeClient().logs(consumerPodName);\n+        Future<Integer> consumer = oauthKafkaClient.receiveMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\", CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n \n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n     }\n \n+    @Description(\"As an oauth kafka connect, i am able to sink messages from kafka broker topic using encrypted communication.\")\n     @Test\n-    void testProducerConsumerStreams() {\n-        deployProducerWithOauthTls();\n-        deployConsumerWithOauthTls(REVERSE_TOPIC_NAME);\n-        deployKafkaStreamsOauthTls();\n-\n-        String producerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-producer-\").get(0).getMetadata().getName();\n-        String producerMessage = \"Sending messages \\\"Hello world - \" + END_MESSAGE_OFFSET + \"\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(producerPodName, producerMessage);\n-\n-        String producerLogs = kubeClient().logs(producerPodName);\n+    void testProducerConsumerConnect() throws IOException, KeyStoreException, InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {\n+        Future<Integer> producer = oauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\");\n \n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, producerLogs, containsString(\"Sending messages \\\"Hello world - \" + i + \"\\\"\"));\n-        }\n+        Future<Integer> consumer = oauthKafkaClient.receiveMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME, OAUTH_CLIENT_NAME,\n+                MESSAGE_COUNT, \"SSL\", CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n \n-        String consumerPodName = kubeClient().listPodsByPrefixInName(\"hello-world-consumer-\").get(0).getMetadata().getName();\n-\n-        String consumerMessage = \"value: \\\"\" + reverseNumber(END_MESSAGE_OFFSET) + \" - dlrow olleH\\\"\";\n-\n-        PodUtils.waitUntilMessageIsInPodLogs(consumerPodName, consumerMessage);\n-\n-        String consumerLogs = kubeClient().logs(consumerPodName);\n-\n-        for (int i = START_MESSAGE_OFFSET; i < END_MESSAGE_OFFSET; i++) {\n-            assertThat(\"Producer doesn't send message\" + i, consumerLogs, containsString(\"value: \\\"\" + reverseNumber(i) + \" - dlrow olleH\\\"\"));\n-        }\n-    }\n-\n-    @Test\n-    void testProducerConsumerConnect() {\n-        deployProducerWithOauthTls();\n-        deployConsumerWithOauthTls(TOPIC_NAME);\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n \n         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)\n                 .editMetadata()\n-                .addToLabels(\"type\", \"kafka-connect\")\n+                    .addToLabels(\"type\", \"kafka-connect\")\n                 .endMetadata()\n                 .editSpec()\n-                .addToConfig(\"key.converter.schemas.enable\", false)\n-                .addToConfig(\"value.converter.schemas.enable\", false)\n-                .withNewKafkaClientAuthenticationOAuth()\n-                .withTokenEndpointUri(oauthTokenEndpointUri)\n-                .withClientId(\"kafka-connect\")\n-                .withNewClientSecret()\n-                .withSecretName(\"my-connect-oauth\")\n-                .withKey(OAUTH_KEY)\n-                .endClientSecret()\n-                .withTlsTrustedCertificates(\n-                        new CertSecretSourceBuilder()\n+                    .addToConfig(\"key.converter.schemas.enable\", false)\n+                    .addToConfig(\"value.converter.schemas.enable\", false)\n+                    .addToConfig(\"key.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                    .addToConfig(\"value.converter\", \"org.apache.kafka.connect.storage.StringConverter\")\n+                    .withNewKafkaClientAuthenticationOAuth()\n+                        .withTokenEndpointUri(oauthTokenEndpointUri)\n+                        .withClientId(\"kafka-connect\")\n+                        .withNewClientSecret()\n+                        .withSecretName(\"my-connect-oauth\")\n+                        .withKey(OAUTH_KEY)\n+                        .endClientSecret()\n+                        .withTlsTrustedCertificates(\n+                            new CertSecretSourceBuilder()\n                                 .withSecretName(SECRET_OF_KEYCLOAK)\n                                 .withCertificate(CERTIFICATE_OF_KEYCLOAK)\n                                 .build())\n-                .withDisableTlsHostnameVerification(true)\n-                .endKafkaClientAuthenticationOAuth()\n-                .withNewTls()\n-                .addNewTrustedCertificate()\n-                .withSecretName(CLUSTER_NAME + \"-cluster-ca-cert\")\n-                .withCertificate(\"ca.crt\")\n-                .endTrustedCertificate()\n-                .endTls()\n-                .withBootstrapServers(CLUSTER_NAME + \"-kafka-bootstrap:9093\")\n+                        .withDisableTlsHostnameVerification(true)\n+                    .endKafkaClientAuthenticationOAuth()\n+                    .withNewTls()\n+                        .addNewTrustedCertificate()\n+                            .withSecretName(CLUSTER_NAME + \"-cluster-ca-cert\")\n+                            .withCertificate(\"ca.crt\")\n+                        .endTrustedCertificate()\n+                    .endTls()\n+                    .withBootstrapServers(CLUSTER_NAME + \"-kafka-bootstrap:9093\")\n                 .endSpec()\n                 .done();\n \n         String kafkaConnectPodName = kubeClient().listPods(\"type\", \"kafka-connect\").get(0).getMetadata().getName();\n-        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);\n \n         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);\n \n-        KafkaConnectUtils.createFileSinkConnector(execPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n-\n-        String message = \"Hello world - \" + END_MESSAGE_OFFSET;\n+        KafkaConnectUtils.createFileSinkConnector(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));\n \n-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, message);\n+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME);\n \n         assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, \"/bin/bash\", \"-c\", \"cat \" + Constants.DEFAULT_SINK_FILE_NAME).out(),\n-                containsString(message));\n+                containsString(\"Sending messages: Hello-world - 99\"));\n     }\n \n+    @Description(\"As a oauth bridge, i am able to send messages to bridge endpoint using encrypted communication\")", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njk1MjEyOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376952128", "bodyText": "still typos :D", "author": "Frawless", "createdAt": "2020-02-10T09:39:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NzAyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NzkzNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376497934", "bodyText": "Are you sure it's not breaking changes for Connect tests?", "author": "Frawless", "createdAt": "2020-02-07T16:54:25Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -58,7 +58,8 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN\n     }\n \n     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName) {", "originalCommit": "3a18898bc3c2cae1f4515741a4e638f39a3d83bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjcxMDM4MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376710380", "bodyText": "Good point, I change all dependencies on that matching string. Now it will do not break anything.", "author": "see-quick", "createdAt": "2020-02-08T13:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjQ5NzkzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMDUzNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376930537", "bodyText": "Same value is probably in Constants.java", "author": "Frawless", "createdAt": "2020-02-10T08:55:37Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -21,6 +21,7 @@\n \n     private static final Logger LOGGER = LogManager.getLogger(InternalKafkaClient.class);\n \n+    private static final int TIMEOUT = 120_000;", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMTU1MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376931551", "bodyText": "from pod? this.podName is clients pod name or?", "author": "Frawless", "createdAt": "2020-02-10T08:57:43Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -90,11 +90,38 @@ public Integer sendMessagesTls(String topicName, String namespace, String cluste\n      * @param namespace namespace\n      * @param clusterName cluster name\n      * @param messageCount messages count\n+     * @param securityProtocol option for tls listener inside kafka cluster\n      * @return count of send and acknowledged messages\n      */\n     @Override\n+    public Integer sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, int timeout) throws InterruptedException {\n+        LOGGER.info(\"Sending messages to pod: {}\", this.podName);", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUxOTM2Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377519367", "bodyText": "yeah", "author": "see-quick", "createdAt": "2020-02-11T09:28:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjkzMTU1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njk0MDAzNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r376940034", "bodyText": "typo", "author": "Frawless", "createdAt": "2020-02-10T09:16:30Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java", "diffHunk": "@@ -0,0 +1,247 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.oauth;\n+\n+import io.strimzi.api.kafka.model.CertSecretSourceBuilder;\n+import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;\n+import io.strimzi.api.kafka.model.KafkaResources;\n+import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;\n+import io.strimzi.systemtest.kafkaclients.ClientFactory;\n+import io.strimzi.systemtest.kafkaclients.EClientType;\n+import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;\n+import io.strimzi.systemtest.resources.crd.KafkaUserResource;\n+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;\n+import io.vertx.core.cli.annotations.Description;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Disabled;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;\n+import static io.strimzi.systemtest.Constants.OAUTH;\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.junit.jupiter.api.Assertions.assertThrows;\n+\n+@Tag(OAUTH)\n+@Tag(REGRESSION)\n+@Tag(NODEPORT_SUPPORTED)\n+public class OauthAuthorizationST extends OauthBaseST {\n+\n+    private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+    private OauthKafkaClient teamBOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH.getClientType());\n+\n+    private static final String TEAM_A_CLIENT = \"team-a-client\";\n+    private static final String TEAM_B_CLIENT = \"team-b-client\";\n+    private static final String KAFKA_CLIENT_ID = \"kafka\";\n+\n+    private static final String TEAM_A_CLIENT_SECRET = \"team-a-client-secret\";\n+    private static final String TEAM_B_CLIENT_SECRET = \"team-b-client-secret\";\n+\n+    private static final int MESSAGE_COUNT = 100;\n+    private static final int TIMEOUT_SEND_RECV_MESSAGES = 10;\n+\n+    private static final String TOPIC_A = \"a-topic\";\n+    private static final String TOPIC_B = \"b-topic\";\n+    private static final String TOPIC_X = \"x-topic\";\n+\n+\n+    @Description(\"As a member of team A, I should be able to read and write to all topics starting with a-\")\n+    @Test\n+    void smokeTestForClients() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        Future<Integer> consumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_consumer_group\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a member of team A, I should be able to write to topics that starts with x- on any cluster and \" +\n+            \"and should also write and read to topics starting with 'a-'\")\n+    @Test\n+    void testTeamAWriteToTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        LOGGER.info(\"Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\");\n+\n+        assertThrows(Exception.class, () -> {\n+            Future<Integer> invalidProducer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE,\n+                    CLUSTER_NAME, TEAM_A_CLIENT, MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+        });\n+\n+        String topicXName = TOPIC_X + \"-example-1\";\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, topicXName);\n+\n+        // Team A can not create topic starting with 'x-' only write to existing on\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicXName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicXName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a member of team A, I should be able only read from consumer that starts with a_\")\n+    @Test\n+    void testTeamAReadFromTopic() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_A);\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(1, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        assertThrows(Exception.class, () -> {\n+            Future<Integer> invalidConsumer = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME,\n+                    TEAM_A_CLIENT, MESSAGE_COUNT, \"SSL\", \"bad_consumer_group\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidConsumer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+        });\n+\n+        Future<Integer> consumerWithCorrectConsumerGroup = teamAOauthKafkaClient.receiveMessagesTls(TOPIC_A, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"a_correct_consumer_group\");\n+\n+        assertThat(consumerWithCorrectConsumerGroup.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+    }\n+\n+    @Description(\"As a member of team B, I should be able to write and read from topics that starts with b-\")\n+    @Test\n+    void testTeamBWriteToTopic() throws IOException, KeyStoreException, ExecutionException, InterruptedException, TimeoutException {\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_NAME);\n+\n+        // Producer will not produce messages because authorization topic will failed. Team A can write only to topic starting with 'x-'\n+        assertThrows(Exception.class, () -> {\n+            Future<Integer> invalidProducer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_NAME, NAMESPACE, CLUSTER_NAME,\n+                    TEAM_B_CLIENT, MESSAGE_COUNT, \"SSL\", TIMEOUT_SEND_RECV_MESSAGES);\n+            invalidProducer.get(TIMEOUT_SEND_RECV_MESSAGES, TimeUnit.SECONDS);\n+        });\n+\n+        LOGGER.info(\"Sending {} messages to broker with topic name {}\", MESSAGE_COUNT, TOPIC_B);\n+\n+        Future<Integer> producer = teamBOauthKafkaClient.sendMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(TOPIC_B, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_\" + CONSUMER_GROUP_NAME + \"-\" + rng.nextInt(Integer.MAX_VALUE));\n+\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Description(\"As a member of team A, I can write to topics starting with 'x-' and \" +\n+            \"as a member of team B can read from topics starting with 'x-'\")\n+    @Test\n+    void testTeamAWriteToTopicStartingWithXAndTeamBReadFromTopicStartingWithX() throws IOException, KeyStoreException, InterruptedException, ExecutionException, TimeoutException {\n+        // only write means that Team A can not create new topic 'x-.*'\n+        String topicName = TOPIC_X + \"-example\";\n+\n+        KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();\n+\n+        Future<Integer> producer = teamAOauthKafkaClient.sendMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_A_CLIENT,\n+                MESSAGE_COUNT, \"SSL\");\n+\n+        assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+\n+        Future<Integer> consumer = teamBOauthKafkaClient.receiveMessagesTls(topicName, NAMESPACE, CLUSTER_NAME, TEAM_B_CLIENT,\n+                MESSAGE_COUNT, \"SSL\", \"x_consumer_group_b\");\n+\n+        assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));\n+    }\n+\n+    @Disabled(\"Will be implemented in next PR\")\n+    @Test\n+    void testListTopics() {\n+        // TODO: in the new PR add AdminClient support with operations listTopics(), etc.\n+    }\n+\n+    @Disabled(\"Will e implemented in next PR\")", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ4MTUxMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377481510", "bodyText": "missing @param securityProtocol in the Javadoc", "author": "ppatierno", "createdAt": "2020-02-11T07:52:19Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java", "diffHunk": "@@ -44,23 +57,37 @@ public void close() {\n      * @return future with sent message count\n      */\n     @Override\n-    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) {\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount, int timeoutInSeconds) throws IOException {\n         String clientName = \"sender-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n         CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n \n         IntPredicate msgCntPredicate = x -> x == messageCount;\n \n         vertx.deployVerticle(new Producer(KafkaClientProperties.createBasicProducerProperties(namespace, clusterName), resultPromise, msgCntPredicate, topicName, clientName));\n \n         try {\n-            resultPromise.get(2, TimeUnit.MINUTES);\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n         } catch (Exception e) {\n             resultPromise.completeExceptionally(e);\n         }\n         vertx.close();\n         return resultPromise;\n     }\n \n+    /**\n+     * Send messages to external entrypoint of the cluster with SSL security protocol setting\n+     * @param topicName topic name\n+     * @param namespace kafka namespace\n+     * @param clusterName kafka cluster name\n+     * @param kafkaUsername user name for authorization\n+     * @param messageCount message count", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ4MTg3NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377481875", "bodyText": "missing @param consumerGroup in the Javadoc", "author": "ppatierno", "createdAt": "2020-02-11T07:53:27Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java", "diffHunk": "@@ -128,24 +155,15 @@ public void sendMessagesExternalScramSha(String clusterName, String namespace, S\n     }\n \n     /**\n-     * Send messages to external entrypoint until stop notification is received by producer. SSL used as a security protocol setting.\n+     * Receive messages to external entrypoint of the cluster with PLAINTEXT security protocol setting\n      * @param topicName topic name\n      * @param namespace kafka namespace\n      * @param clusterName kafka cluster name\n-     * @param userName user name for authorization\n-     * @param clientName client name\n-     * @return future\n+     * @param messageCount message count", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ5MTkzMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377491933", "bodyText": "it seems to be the same code as the producer, I would suggest to factor out a common method for it.", "author": "ppatierno", "createdAt": "2020-02-11T08:24:13Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -122,6 +373,60 @@ static Properties createConsumerProperties(String namespace, String clusterName,\n \n         consumerProperties.putAll(sharedClientProperties(namespace, caSecretName, userName, securityProtocol));\n \n+        if (clientType == EClientType.OAUTH) {\n+            // plain\n+            if (userName.equals(\"\")) {\n+                LOGGER.info(\"Enabling Plaintext with setting {}={}\", CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+\n+                consumerProperties.setProperty(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_PLAINTEXT\");\n+                consumerProperties.setProperty(\"sasl.mechanism\", \"OAUTHBEARER\");\n+                consumerProperties.setProperty(\"sasl.login.callback.handler.class\", \"io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\");\n+                consumerProperties.setProperty(\"sasl.jaas.config\",\n+                        \"org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule \" +\n+                                \"required \" +\n+                                \"oauth.client.id=\\\"\" + clientId + \"\\\" \" +\n+                                \"oauth.client.secret=\\\"\" + clientSecretName + \"\\\" \" +\n+                                \"oauth.token.endpoint.uri=\\\"\" + oauthTokenEndpointUri + \"\\\";\");\n+            } else {\n+                // tls\n+                String responseKeycloak = Exec.exec(\"openssl\", \"s_client\", \"-showcerts\", \"-connect\", kubeClient().getNodeAddress() + \":\" + Constants.HTTPS_KEYCLOAK_DEFAULT_NODE_PORT).out();\n+                Matcher matcher = Pattern.compile(\"-----(?s)(.*)-----\").matcher(responseKeycloak);\n+\n+                if (matcher.find()) {\n+                    String keycloakCertificateData = matcher.group(0);\n+                    LOGGER.info(\"Keycloak cert is:{}\\n\", keycloakCertificateData);\n+\n+                    LOGGER.info(\"Creating keycloak.crt file\");\n+                    File keycloakCertFile = File.createTempFile(\"keycloak\", \".crt\");\n+\n+                    Files.write(keycloakCertFile.toPath(), keycloakCertificateData.getBytes(StandardCharsets.UTF_8));\n+\n+                    LOGGER.info(\"Importing keycloak certificate {} to truststore\", keycloakCertFile.getAbsolutePath());\n+                    Exec.exec(\"keytool\", \"-v\", \"-import\", \"-trustcacerts\", \"-file\", keycloakCertFile.getAbsolutePath(),\n+                            \"-alias\", \"keycloakCrt1\", \"-keystore\", consumerProperties.get(\"ssl.truststore.location\").toString(),\n+                            \"-noprompt\", \"-storepass\", consumerProperties.get(\"ssl.truststore.password\").toString());\n+                }\n+\n+\n+                LOGGER.info(\"Setting oauth properties\");\n+\n+                LOGGER.info(\"Enabling SSL with setting {}={}\", CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_SSL\");\n+                consumerProperties.setProperty(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, \"SASL_SSL\");\n+                consumerProperties.setProperty(\"sasl.mechanism\", \"OAUTHBEARER\");\n+                consumerProperties.setProperty(\"sasl.login.callback.handler.class\", \"io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\");\n+                consumerProperties.setProperty(\"sasl.jaas.config\",\n+                        \"org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule \" +\n+                                \"required \" +\n+                                \"oauth.client.id=\\\"\" + clientId + \"\\\" \" +\n+                                \"oauth.client.secret=\\\"\" + clientSecretName + \"\\\" \" +\n+                                \"oauth.token.endpoint.uri=\\\"\" + oauthTokenEndpointUri + \"\\\" \" +\n+                                \"oauth.ssl.endpoint.identification.algorithm=\\\"\\\"\" +\n+                                \"oauth.ssl.truststore.location=\\\"\" + consumerProperties.get(\"ssl.truststore.location\") + \"\\\" \" +\n+                                \"oauth.ssl.truststore.password=\\\"\" + consumerProperties.get(\"ssl.truststore.password\") + \"\\\" \" +\n+                                \"oauth.ssl.truststore.type=\\\"\" + consumerProperties.get(\"ssl.truststore.type\") + \"\\\" ;\");\n+            }", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ5NDM3Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377494376", "bodyText": "As a general point, with something like a timeout it's worth using the parameter name to convey the units (e.g. timeoutSeconds or timeoutMs).", "author": "tombentley", "createdAt": "2020-02-11T08:30:47Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/IKafkaClient.java", "diffHunk": "@@ -4,11 +4,14 @@\n  */\n package io.strimzi.systemtest.kafkaclients;\n \n+import java.io.IOException;\n+import java.security.KeyStoreException;\n+\n public interface IKafkaClient<T> {\n \n-    T sendMessages(String topicName, String namespace, String clusterName, int messageCount) throws InterruptedException;\n-    T sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) throws InterruptedException;\n+    T sendMessages(String topicName, String namespace, String clusterName, int messageCount, int timeout) throws InterruptedException, KeyStoreException, IOException;", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUyMDY3MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377520670", "bodyText": "Additionally, unless the declared checked exception is supposed to be used somewhere up the stack to do error handling specific to the exception type I'd say it's a better practice to wrap it into a RuntimeException, and not declare it. If InterruptedException just results in ending the test, just the same way as KeyStoreException, IOException or any other RuntimeException I'd just scrap them all.", "author": "mstruk", "createdAt": "2020-02-11T09:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ5NDM3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzYyNjk1Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377626952", "bodyText": "I understand the idea but this change is on separate PR. Can you also please create a [QE] JIRA for that?", "author": "see-quick", "createdAt": "2020-02-11T13:17:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQ5NDM3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNDYyMg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377534622", "bodyText": "It is not quite visible here, but this method returns a resultPromise after calling get(), which means there is no asynchronicity left here. This whole method could as well be declared as:\npublic Integer sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, int timeInSeconds) { ... }\n\nIt would make code that uses it easier to read.\nI see many occurrences like this around the testsuite.", "author": "mstruk", "createdAt": "2020-02-11T09:58:17Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java", "diffHunk": "@@ -81,12 +108,12 @@ public void close() {\n         String caCertName = this.caCertName == null ? KafkaResource.getKafkaExternalListenerCaCertName(namespace, clusterName) : this.caCertName;\n         LOGGER.info(\"Going to use the following CA certificate: {}\", caCertName);\n \n-        vertx.deployVerticle(new Producer(KafkaClientProperties.createProducerProperties(namespace, clusterName,\n-                caCertName, kafkaUsername, securityProtocol, EClientType.BASIC, null),\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createBasicProducerTlsProperties(namespace, clusterName,\n+                caCertName, kafkaUsername, securityProtocol),\n                 resultPromise, msgCntPredicate, topicName, clientName));\n \n         try {\n-            resultPromise.get(2, TimeUnit.MINUTES);\n+            resultPromise.get(timeInSeconds, TimeUnit.SECONDS);\n         } catch (Exception e) {\n             resultPromise.completeExceptionally(e);\n         }", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzYxODkzOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377618939", "bodyText": "Ok, make sense can you please create [QE] JIRA and we will take a look.", "author": "see-quick", "createdAt": "2020-02-11T13:00:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNDYyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNjc5NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377536795", "bodyText": "It would make sense to make the default value configurable somehow. A static constant with static initializer, that reads a system property maybe. Generally that goes for all the time constants. It's just several different values used around the tests, and could be replaced with just several constants initialized from system properties.", "author": "mstruk", "createdAt": "2020-02-11T10:02:56Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java", "diffHunk": "@@ -44,23 +57,37 @@ public void close() {\n      * @return future with sent message count\n      */\n     @Override\n-    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) {\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount, int timeoutInSeconds) throws IOException {\n         String clientName = \"sender-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n         CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n \n         IntPredicate msgCntPredicate = x -> x == messageCount;\n \n         vertx.deployVerticle(new Producer(KafkaClientProperties.createBasicProducerProperties(namespace, clusterName), resultPromise, msgCntPredicate, topicName, clientName));\n \n         try {\n-            resultPromise.get(2, TimeUnit.MINUTES);\n+            resultPromise.get(timeoutInSeconds, TimeUnit.SECONDS);\n         } catch (Exception e) {\n             resultPromise.completeExceptionally(e);\n         }\n         vertx.close();\n         return resultPromise;\n     }\n \n+    /**\n+     * Send messages to external entrypoint of the cluster with SSL security protocol setting\n+     * @param topicName topic name\n+     * @param namespace kafka namespace\n+     * @param clusterName kafka cluster name\n+     * @param kafkaUsername user name for authorization\n+     * @param messageCount message count\n+     * @return future with sent message count\n+     */\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) throws KeyStoreException, IOException {\n+        return sendMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, 120);", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzYyNzU4NQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377627585", "bodyText": "This is already done in this PR and to be concrete with value -> long GLOBAL_CLIENTS_TIMEOUT = Duration.ofMinutes(2).toMillis();", "author": "see-quick", "createdAt": "2020-02-11T13:18:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNjc5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzY2NjAzOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377666038", "bodyText": "Ok, that's half of the solution, the other half would be to actually be able to rerun the testsuite with different timeout without changing the code.", "author": "mstruk", "createdAt": "2020-02-11T14:26:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNjc5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzY2Nzg2Nw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377667867", "bodyText": "This is already done in PR -> #2520. We changing approach how to deploy the clients using builder pattern.", "author": "see-quick", "createdAt": "2020-02-11T14:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzUzNjc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzU0MTY5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377541698", "bodyText": "As a general note, lines like this mean you don't have trust in your error handling code or logging configuration :)", "author": "mstruk", "createdAt": "2020-02-11T10:12:31Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java", "diffHunk": "@@ -310,14 +328,14 @@ public void sendNotificationToClient(String clientName, String notification) {\n      * @param messageCount message count which will be send and receive by consumer and producer\n      * @throws Exception exception\n      */\n-    public void sendAndRecvMessagesTls(String userName, String namespace, String clusterName, String topicName, int messageCount) throws InterruptedException, ExecutionException, TimeoutException {\n+    public void sendAndRecvMessagesTls(String userName, String namespace, String clusterName, String topicName, int messageCount) throws InterruptedException, ExecutionException, TimeoutException, KeyStoreException, IOException {\n         try (KafkaClient testClient = new KafkaClient()) {\n             Future producer = testClient.sendMessagesTls(topicName, namespace, clusterName, userName, messageCount, \"SSL\");\n             Future consumer = testClient.receiveMessagesTls(topicName, namespace, clusterName, userName, messageCount, \"SSL\");\n \n             assertThat(\"Producer produced all messages\", producer.get(1, TimeUnit.MINUTES), is(messageCount));\n             assertThat(\"Consumer consumed all messages\", consumer.get(1, TimeUnit.MINUTES), is(messageCount));\n-        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+        } catch (InterruptedException | ExecutionException | TimeoutException | KeyStoreException | IOException e) {\n             e.printStackTrace();", "originalCommit": "dd9f939fc997c9c805e4496738454bd86043dcc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzY2NjY2MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r377666661", "bodyText": "This is no longer needed. In #2518 PR is all these methods are removed.", "author": "see-quick", "createdAt": "2020-02-11T14:27:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzU0MTY5OA=="}], "type": "inlineReview"}, {"oid": "560bace343b2d5a0d85e25cae2c07ae0c56366f1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/560bace343b2d5a0d85e25cae2c07ae0c56366f1", "message": "[MO] - [rebase] -> do\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-11T12:26:22Z", "type": "forcePushed"}, {"oid": "bf0fe3bebb86ed0c8ebb4d1474390e5fd7ada848", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/bf0fe3bebb86ed0c8ebb4d1474390e5fd7ada848", "message": "[MO] - [system test] -> oauth authorization\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-11T12:35:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODExODkyOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378118928", "bodyText": "If this is to work around a bug in keycloak you should include include a link to the bug report in keycloak (and ideally watch that bug so we know when it gets fixed and this workaround can be removed)", "author": "tombentley", "createdAt": "2020-02-12T09:08:02Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java", "diffHunk": "@@ -292,4 +505,69 @@ private static File createKeystore(byte[] ca, byte[] cert, byte[] key, String pa\n         keystore.deleteOnExit();\n         return keystore;\n     }\n+\n+    /**\n+     * Use Keycloak Admin API to update Authorization Services 'decisionStrategy' on 'kafka' client to AFFIRMATIVE\n+     *\n+     * @throws IOException\n+     */\n+    static void fixBadlyImportedAuthzSettings() throws IOException {", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMDExNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378120114", "bodyText": "Can you add a Javadoc to explain what this class is for, and how it differs other implementations of IKafkaClient.", "author": "tombentley", "createdAt": "2020-02-12T09:10:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthKafkaClient.java", "diffHunk": "@@ -4,29 +4,257 @@\n  */\n package io.strimzi.systemtest.kafkaclients.externalClients;\n \n+import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.kafkaclients.IKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.test.executor.Exec;\n+import io.vertx.core.Vertx;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Properties;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n-public class OauthKafkaClient implements IKafkaClient {\n+import static io.strimzi.systemtest.kafkaclients.externalClients.KafkaClientProperties.fixBadlyImportedAuthzSettings;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+\n+public class OauthKafkaClient implements IKafkaClient<Future<Integer>> {", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMDY0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378120644", "bodyText": "This difference between this method and sendMessages above appear to be minimal: Can you factor out a common method?", "author": "tombentley", "createdAt": "2020-02-12T09:11:28Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthKafkaClient.java", "diffHunk": "@@ -4,29 +4,257 @@\n  */\n package io.strimzi.systemtest.kafkaclients.externalClients;\n \n+import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.kafkaclients.IKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.test.executor.Exec;\n+import io.vertx.core.Vertx;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Properties;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n-public class OauthKafkaClient implements IKafkaClient {\n+import static io.strimzi.systemtest.kafkaclients.externalClients.KafkaClientProperties.fixBadlyImportedAuthzSettings;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+\n+public class OauthKafkaClient implements IKafkaClient<Future<Integer>> {\n+\n+    private Vertx vertx = Vertx.vertx();\n+    private static final Logger LOGGER = LogManager.getLogger(KafkaClient.class);\n+\n+    private String caCertName;\n+    private String clientId;\n+    private String clientSecretName;\n+    private String oauthTokenEndpointUri;\n+\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) throws RuntimeException, IOException {\n+        return sendMessages(topicName, namespace, clusterName, messageCount, Constants.GLOBAL_CLIENTS_TIMEOUT);\n+    }\n \n     @Override\n-    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount,\n+                                        long timeoutMs) throws RuntimeException, IOException {\n+        String clientName = \"sender-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createOauthProducerProperties(namespace, clusterName,\n+                this.clientId, this.clientSecretName, this.oauthTokenEndpointUri), resultPromise, msgCntPredicate,\n+                topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutMs, TimeUnit.MILLISECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,\n+                                           int messageCount, String securityProtocol) throws RuntimeException, IOException {\n+        return sendMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol,\n+                Constants.GLOBAL_CLIENTS_TIMEOUT);\n     }\n \n     @Override\n-    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMTExOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378121118", "bodyText": "Similarly, how much does this differ from the non-TLS receive? Can you factor out a common method?", "author": "tombentley", "createdAt": "2020-02-12T09:12:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthKafkaClient.java", "diffHunk": "@@ -4,29 +4,257 @@\n  */\n package io.strimzi.systemtest.kafkaclients.externalClients;\n \n+import io.strimzi.systemtest.Constants;\n import io.strimzi.systemtest.kafkaclients.IKafkaClient;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.test.executor.Exec;\n+import io.vertx.core.Vertx;\n+import org.apache.kafka.clients.CommonClientConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Properties;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.Future;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.IntPredicate;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n \n-public class OauthKafkaClient implements IKafkaClient {\n+import static io.strimzi.systemtest.kafkaclients.externalClients.KafkaClientProperties.fixBadlyImportedAuthzSettings;\n+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n+\n+public class OauthKafkaClient implements IKafkaClient<Future<Integer>> {\n+\n+    private Vertx vertx = Vertx.vertx();\n+    private static final Logger LOGGER = LogManager.getLogger(KafkaClient.class);\n+\n+    private String caCertName;\n+    private String clientId;\n+    private String clientSecretName;\n+    private String oauthTokenEndpointUri;\n+\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) throws RuntimeException, IOException {\n+        return sendMessages(topicName, namespace, clusterName, messageCount, Constants.GLOBAL_CLIENTS_TIMEOUT);\n+    }\n \n     @Override\n-    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessages(String topicName, String namespace, String clusterName, int messageCount,\n+                                        long timeoutMs) throws RuntimeException, IOException {\n+        String clientName = \"sender-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createOauthProducerProperties(namespace, clusterName,\n+                this.clientId, this.clientSecretName, this.oauthTokenEndpointUri), resultPromise, msgCntPredicate,\n+                topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutMs, TimeUnit.MILLISECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,\n+                                           int messageCount, String securityProtocol) throws RuntimeException, IOException {\n+        return sendMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol,\n+                Constants.GLOBAL_CLIENTS_TIMEOUT);\n     }\n \n     @Override\n-    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,\n+                                           int messageCount, String securityProtocol, long timeoutMs) throws RuntimeException, IOException {\n+        String clientName = \"sender-ssl\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        String caCertName = this.caCertName == null ?\n+                KafkaResource.getKafkaExternalListenerCaCertName(namespace, clusterName) : this.caCertName;\n+        LOGGER.info(\"Going to use the following CA certificate: {}\", caCertName);\n+\n+        vertx.deployVerticle(new Producer(KafkaClientProperties.createOauthProducerTlsProperties(namespace, clusterName,\n+                caCertName, kafkaUsername, securityProtocol, this.clientId, this.clientSecretName,\n+                this.oauthTokenEndpointUri), resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutMs, TimeUnit.MILLISECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount,\n+                                           String consumerGroup) throws IOException {\n+        return receiveMessages(topicName, namespace, clusterName, messageCount, consumerGroup, Constants.GLOBAL_CLIENTS_TIMEOUT);\n+    }\n+\n+    @Override\n+    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount,\n+                                           String consumerGroup, long timeoutMs) throws RuntimeException, IOException {\n+        String clientName = \"receiver-plain-\" + clusterName;\n+        vertx = Vertx.vertx();\n+        CompletableFuture<Integer> resultPromise = new CompletableFuture<>();\n+\n+        IntPredicate msgCntPredicate = x -> x == messageCount;\n+\n+        vertx.deployVerticle(new Consumer(KafkaClientProperties.createOauthConsumerProperties(namespace, clusterName, consumerGroup,\n+                this.clientId, this.clientSecretName, this.oauthTokenEndpointUri), resultPromise, msgCntPredicate, topicName, clientName));\n+\n+        try {\n+            resultPromise.get(timeoutMs, TimeUnit.MILLISECONDS);\n+        } catch (Exception e) {\n+            resultPromise.completeExceptionally(e);\n+        }\n+        vertx.close();\n+        return resultPromise;\n+    }\n+\n+    public Future<Integer> receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,\n+                                              int messageCount, String securityProtocol, String consumerGroup) throws RuntimeException, IOException {\n+        return receiveMessagesTls(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol,\n+                consumerGroup, Constants.GLOBAL_CLIENTS_TIMEOUT);\n     }\n \n     @Override\n-    public Future<Integer> receiveMessages(String topicName, String namespace, String clusterName, int messageCount, String consumerGroup) {\n-        throw new UnsupportedOperationException();\n+    public Future<Integer> receiveMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername,", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODI5MzU2Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378293562", "bodyText": "I have added this note to the existing JIRA, which created Marko. It would take more time and i don't want to make really small quick change.", "author": "see-quick", "createdAt": "2020-02-12T14:42:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMTExOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMTQ3OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378121479", "bodyText": "Javadoc", "author": "tombentley", "createdAt": "2020-02-12T09:13:04Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/TracingKafkaClient.java", "diffHunk": "@@ -10,30 +10,34 @@\n \n import java.util.concurrent.Future;\n \n-public class TracingKafkaClient implements IKafkaClient {\n+public class TracingKafkaClient implements IKafkaClient<Future<Integer>> {", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyMTYzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378121636", "bodyText": "Javadoc", "author": "tombentley", "createdAt": "2020-02-12T09:13:22Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java", "diffHunk": "@@ -17,7 +18,7 @@\n import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;\n import static org.hamcrest.MatcherAssert.assertThat;\n \n-public class InternalKafkaClient implements IKafkaClient {\n+public class InternalKafkaClient implements IKafkaClient<Integer> {", "originalCommit": "0ea336aa065849533febeb4dceadef99b66a0971", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyNjIzMQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378126231", "bodyText": "You don't declare RuntimeExceptions, that's the whole beauty of them.\nSimply:\nT sendMessages(String topicName, String namespace, String clusterName, int messageCount, long timeoutMs) throws IOException;\n\nwill suffice.", "author": "mstruk", "createdAt": "2020-02-12T09:22:24Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/IKafkaClient.java", "diffHunk": "@@ -5,13 +5,12 @@\n package io.strimzi.systemtest.kafkaclients;\n \n import java.io.IOException;\n-import java.security.KeyStoreException;\n \n public interface IKafkaClient<T> {\n \n-    T sendMessages(String topicName, String namespace, String clusterName, int messageCount, long timeoutMs) throws InterruptedException, KeyStoreException, IOException;\n-    T sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol, long timeoutMs) throws InterruptedException, KeyStoreException, IOException;\n+    T sendMessages(String topicName, String namespace, String clusterName, int messageCount, long timeoutMs) throws RuntimeException, IOException;", "originalCommit": "cbb5e437771c3eebcceadf7a504278d74f8ca741", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODI5MzkwMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2482#discussion_r378293903", "bodyText": "Done and thanks for the catch.", "author": "see-quick", "createdAt": "2020-02-12T14:43:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODEyNjIzMQ=="}], "type": "inlineReview"}, {"oid": "5183fc1e8377e9e085d9b1e907c626fe9464b17a", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5183fc1e8377e9e085d9b1e907c626fe9464b17a", "message": "[MO] - [commends] -> resolve commends\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-13T14:47:46Z", "type": "forcePushed"}, {"oid": "173f2c5bbe7c2794144846413b8b2be9a4cc27af", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/173f2c5bbe7c2794144846413b8b2be9a4cc27af", "message": "[MO] - [system test] -> oauth authorization\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-13T14:54:42Z", "type": "commit"}, {"oid": "173f2c5bbe7c2794144846413b8b2be9a4cc27af", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/173f2c5bbe7c2794144846413b8b2be9a4cc27af", "message": "[MO] - [system test] -> oauth authorization\n\nSigned-off-by: Seequick1 <morsak@redhat.com>", "committedDate": "2020-02-13T14:54:42Z", "type": "forcePushed"}]}