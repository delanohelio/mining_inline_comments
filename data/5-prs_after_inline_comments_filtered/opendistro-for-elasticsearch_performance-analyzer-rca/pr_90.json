{"pr_number": 90, "pr_title": "RCA persistence framework refactorings.", "pr_createdAt": "2020-02-06T20:43:30Z", "pr_url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/90", "timeline": [{"oid": "2b5e4dcd3ff9e36e7fb3a2edfc09e541255aede2", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/2b5e4dcd3ff9e36e7fb3a2edfc09e541255aede2", "message": "decoupling file gc and file rotation from the PersistorBase", "committedDate": "2020-02-06T20:21:47Z", "type": "commit"}, {"oid": "7c7512d0e70bb6cc080525a152419ac5914fc80c", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/7c7512d0e70bb6cc080525a152419ac5914fc80c", "message": "Attenmpting a write to db file after creating a new db file. trying hard not to throw away data", "committedDate": "2020-02-06T20:41:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA3NzIyMQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/90#discussion_r376077221", "bodyText": "that that -> that", "author": "ktkrg", "createdAt": "2020-02-06T20:56:30Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/framework/util/RcaConsts.java", "diffHunk": "@@ -60,6 +60,10 @@\n   public static final String DATASTORE_STATE_COL_NAME = \"state\";\n   public static final String DATASTORE_STORAGE_FILE_RETENTION_COUNT = \"storage-file-retention-count\";\n \n+  // The next two lines says that that the RCA sqlite files needs to be rotated every hour", "originalCommit": "7c7512d0e70bb6cc080525a152419ac5914fc80c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjExMTU2MQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/90#discussion_r376111561", "bodyText": "Do we need to catch exception here ?", "author": "rguo-aws", "createdAt": "2020-02-06T22:12:26Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/persistence/FileGC.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ *  Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\").\n+ *  You may not use this file except in compliance with the License.\n+ *  A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  or in the \"license\" file accompanying this file. This file is distributed\n+ *  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ *  express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.persistence;\n+\n+import java.io.File;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Deque;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.commons.io.comparator.LastModifiedFileComparator;\n+import org.apache.commons.io.filefilter.WildcardFileFilter;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/** This makes sure that we only keep a fixed number of DB files based on age and count. */\n+public class FileGC {\n+  private static final Logger LOG = LogManager.getLogger(FileGC.class);\n+\n+  private final Path DB_DIR;\n+  private final String BASE_DB_FILENAME;\n+  private final TimeUnit TIME_UNIT;\n+  private final long PERIODICITY;\n+  private final int FILES_COUNT;\n+\n+  private final String WILDCARD_CHARACTER = \"*\";\n+\n+  protected Deque<File> eligibleForGc;\n+\n+  FileGC(\n+      Path db_dir,\n+      String base_db_filename,\n+      TimeUnit time_unit,\n+      long periodicity1,\n+      int files_count) {\n+    this(\n+        db_dir, base_db_filename, time_unit, periodicity1, files_count, System.currentTimeMillis());\n+  }\n+\n+  FileGC(\n+      Path db_dir,\n+      String base_db_filename,\n+      TimeUnit time_unit,\n+      long periodicity1,\n+      int files_count,\n+      long currentMillis) {\n+    DB_DIR = db_dir;\n+    BASE_DB_FILENAME = base_db_filename;\n+\n+    TIME_UNIT = time_unit;\n+    PERIODICITY = periodicity1;\n+    FILES_COUNT = files_count;\n+\n+    List<File> remainingFiles = cleanupAndGetRemaining(currentMillis);\n+\n+    eligibleForGc = new LinkedList<>(remainingFiles);\n+  }\n+\n+  /**\n+   * When we add a newly rotated file, this method checks if the current count of the garbage files\n+   * is above the threshold, then it removes the oldest file to keep the count under FILES_COUNT.\n+   *\n+   * @param filename The name of the new file to be added.\n+   */\n+  void eligibleForGc(String filename) {\n+    File file = Paths.get(DB_DIR.toString(), filename).toFile();\n+    if (file.exists()) {\n+      eligibleForGc.addLast(file);\n+\n+      if (eligibleForGc.size() > FILES_COUNT) {\n+        File oldestFile = eligibleForGc.removeFirst();\n+        delete(oldestFile);\n+      }\n+    }\n+  }\n+\n+  protected List<File> cleanupAndGetRemaining(long currentMillis) {\n+    String[] files = getDbFiles();\n+    List<File> afterCleaningOldFiles = timeBasedCleanup(files, currentMillis);\n+    return countBasedCleanup(afterCleaningOldFiles);\n+  }\n+\n+  protected String[] getDbFiles() {\n+    return DB_DIR\n+        .toFile()\n+        .list(new WildcardFileFilter(BASE_DB_FILENAME + \".\" + WILDCARD_CHARACTER));\n+  }\n+\n+  protected List<File> timeBasedCleanup(String[] files, final long currentMillis) {\n+    long timeDelta = TimeUnit.MILLISECONDS.convert(PERIODICITY, TIME_UNIT) * (FILES_COUNT + 1);\n+    long timeLimit = currentMillis - timeDelta;\n+\n+    List<File> remainingFiles = new ArrayList<>();\n+\n+    for (String file : files) {\n+      Path filePath = Paths.get(DB_DIR.toString(), file);\n+      long lastModified = filePath.toFile().lastModified();\n+\n+      if (lastModified < timeLimit) {\n+        delete(filePath.toFile());\n+      } else {\n+        remainingFiles.add(filePath.toFile());\n+      }\n+    }\n+    return remainingFiles;\n+  }\n+\n+  protected List<File> countBasedCleanup(List<File> files) {\n+    int numToDelete = files.size() - FILES_COUNT;\n+    Collections.sort(files, LastModifiedFileComparator.LASTMODIFIED_COMPARATOR);\n+\n+    int deletedSoFar = 0;\n+    List<File> remainingFiles = new ArrayList<>();\n+\n+    for (File file : files) {\n+      if (deletedSoFar < numToDelete) {\n+        delete(file);\n+        deletedSoFar += 1;\n+      } else {\n+        remainingFiles.add(file);\n+      }\n+    }\n+    return remainingFiles;\n+  }\n+\n+  private void delete(File file) {\n+    if (!file.delete()) {", "originalCommit": "7c7512d0e70bb6cc080525a152419ac5914fc80c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE0NTI5Mw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/90#discussion_r376145293", "bodyText": "Good catch! we should. Added a revision to throw exception if we fail to delete not just silently logging it", "author": "yojs", "createdAt": "2020-02-06T23:45:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjExMTU2MQ=="}], "type": "inlineReview"}, {"oid": "2a2098a1668d943e8da3d3fd68af71ba39875495", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/2a2098a1668d943e8da3d3fd68af71ba39875495", "message": "throwing exception when FileGC could not delete the file.", "committedDate": "2020-02-06T23:44:34Z", "type": "commit"}]}