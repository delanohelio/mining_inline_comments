{"pr_number": 265, "pr_title": "FieldData and Shard Request Cache RCA", "pr_createdAt": "2020-07-07T19:04:19Z", "pr_url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265", "timeline": [{"oid": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "message": "Squashed commit of the following:\n\ncommit e72afa1051640480bf4cea301025e1318e657016\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 11:34:59 2020 -0700\n\n    Refreshing from Mainline\n\ncommit d1b3f21da20d594b27c5f32b4999c7bd5831225b\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 11:13:49 2020 -0700\n\n    Removing a comment from the util file\n\ncommit 63ddab2539d50887594643eaab945db54bdad79b\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 02:47:36 2020 -0700\n\n    Adding final set of changes for Cache RCAs\n\ncommit 09537c24ccfcd3c485efbf56938b62818d895ea6\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 23:54:28 2020 -0700\n\n    Adding weight check for async evictions in FieldDataCache\n\ncommit 65d8f438a03f5ab28501e0d0d690a4af029c1b91\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 16:04:59 2020 -0700\n\n    Addinf UT for ShardRequestCacheRca\n\ncommit cdec05b58f62b2138316fd0daa06efc384c90c09\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 10:45:07 2020 -0700\n\n    Adding UT for FieldDataCacheRca\n\ncommit ebdbc7e8beea059f49da077943fbc2048487d662\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Sun Jul 5 23:16:57 2020 -0700\n\n    Refreshing from master\n\ncommit 4238148ce976a38fdf5540f231c93b2cdedbb148\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Sun Jul 5 23:15:08 2020 -0700\n\n    Adding the FieldDataCacheRca and ShardRequestCacheRca\n\ncommit b6f1a51eb78abad87b3bbd4a6be27c05284c4ff4\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Wed Jul 1 14:17:01 2020 -0700\n\n    Including the Protobuf re-factoring changes\n\ncommit 03cc597d008871e2ab13bf04762121e713b309ff\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Wed Jun 24 21:53:08 2020 -0700\n\n    Refreshing from master", "committedDate": "2020-07-07T18:55:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzOTM1NQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451239355", "bodyText": "nit: The year has to be updated to 2020 now.", "author": "vigyasharma", "createdAt": "2020-07-08T02:01:11Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU3ODI0Mw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454578243", "bodyText": "Updated.", "author": "khushbr", "createdAt": "2020-07-14T19:02:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTIzOTM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MTEwOQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451241109", "bodyText": "nit: \"either the cache weight exceeds\" maximum weight OR ...", "author": "vigyasharma", "createdAt": "2020-07-08T02:07:52Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYyNjAyMA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454626020", "bodyText": "Updated.", "author": "khushbr", "createdAt": "2020-07-14T20:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MTEwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MTUzNg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451241536", "bodyText": "cacheMaxSize != 0  is mentioned twice", "author": "vigyasharma", "createdAt": "2020-07-08T02:09:44Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MjcwNQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451242705", "bodyText": "Floating point comparisons have rounding errors which can affect the places where this value is used. Should we just convert it to KB and use long values such that we tolerate a rounding error of 1kb?", "author": "vigyasharma", "createdAt": "2020-07-08T02:14:22Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+\n+public class CacheUtil {\n+    private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n+    private static final double CONVERT_BYTES_TO_MEGABYTES = Math.pow(1024, 3);\n+\n+    public static Double getTotalSizeInMB(final Metric sizeMetric) {\n+        double sizeTotalInMB = 0;\n+\n+        // we expect the Metric to have single flow unit since it is consumed locally\n+        MetricFlowUnit flowUnit = sizeMetric.getFlowUnits().get(0);\n+        if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n+            return sizeTotalInMB;\n+        }\n+\n+        for (Record record : flowUnit.getData()) {\n+            double size = record.getValue(MetricsDB.MAX, Double.class);\n+            if (Double.isNaN(size)) {\n+                LOG.error(\"Failed to parse metric in FlowUnit from {}\", sizeMetric.getClass().getName());\n+            } else {\n+                sizeTotalInMB += size / CONVERT_BYTES_TO_MEGABYTES;", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDczMTM0Nw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454731347", "bodyText": "Thank you Vigya for the suggestion, I agree we can go with KB and tolerate the 1KB rounding error. I have updated the code for the same.", "author": "khushbr", "createdAt": "2020-07-15T01:09:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0MjcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0NTQ4Mw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451245483", "bodyText": "Do we implement this for node level rcas?", "author": "vigyasharma", "createdAt": "2020-07-08T02:25:26Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+            if (cacheEvictionCollector.isUnhealthy(currTimestamp) && exceedsSize) {\n+                context = new ResourceContext(Resources.State.UNHEALTHY);\n+                nodeSummary = new HotNodeSummary(currentNode.getId(), currentNode.getHostAddress());\n+                nodeSummary.appendNestedSummary(cacheEvictionCollector.generateSummary(currTimestamp));\n+            }\n+            else {\n+                context = new ResourceContext(Resources.State.HEALTHY);\n+                nodeSummary = null;\n+            }\n+\n+            counter = 0;\n+            exceedsSize = Boolean.FALSE;\n+            return new ResourceFlowUnit<>(currTimestamp, context, nodeSummary, !currentNode.getIsMasterNode());\n+        }\n+        else {\n+            return new ResourceFlowUnit<>(currTimestamp);\n+        }\n+    }\n+\n+    @Override\n+    public void generateFlowUnitListFromWire(FlowUnitOperationArgWrapper args) {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYzMjc2MA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454632760", "bodyText": "Yes, ideally we should refactor and move this function back to RCA Base class.", "author": "khushbr", "createdAt": "2020-07-14T20:43:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI0NTQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyNjkzOA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451626938", "bodyText": "Do we need the exceedsSize check for unhealthy? It's not clear to me why.", "author": "vigyasharma", "createdAt": "2020-07-08T15:19:35Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+            if (cacheEvictionCollector.isUnhealthy(currTimestamp) && exceedsSize) {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4MDg5OA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453080898", "bodyText": "agree, and I don't think we need exceedsSize here. exceedsSize will immediately jump to non-zero when a scaling down action is applied so it is not a good indicator for cache healthiness", "author": "rguo-aws", "createdAt": "2020-07-10T21:16:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyNjkzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDczNjAyNg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454736026", "bodyText": "Field Data Cache Eviction metric is present for cases other than Size based eviction. For example, in case when the cache is invalidated via clear() API. We can go with the proposed cacheMaxSize - cacheSize > threshold instead of exceedsSize\nFor the \"exceedsSize will immediately jump to non-zero when a scaling down action is applied so it is not a good indicator for cache healthiness\" case, we will anyway have to handle it separately in decider since we will see evictions post the cache scale down.", "author": "khushbr", "createdAt": "2020-07-15T01:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYyNjkzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzMDU1Ng==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451630556", "bodyText": "flowUnit.getData().stream() -- Can each flowUnit here have multiple data points?", "author": "vigyasharma", "createdAt": "2020-07-08T15:24:43Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+            if (cacheEvictionCollector.isUnhealthy(currTimestamp) && exceedsSize) {\n+                context = new ResourceContext(Resources.State.UNHEALTHY);\n+                nodeSummary = new HotNodeSummary(currentNode.getId(), currentNode.getHostAddress());\n+                nodeSummary.appendNestedSummary(cacheEvictionCollector.generateSummary(currTimestamp));\n+            }\n+            else {\n+                context = new ResourceContext(Resources.State.HEALTHY);\n+                nodeSummary = null;\n+            }\n+\n+            counter = 0;\n+            exceedsSize = Boolean.FALSE;\n+            return new ResourceFlowUnit<>(currTimestamp, context, nodeSummary, !currentNode.getIsMasterNode());\n+        }\n+        else {\n+            return new ResourceFlowUnit<>(currTimestamp);\n+        }\n+    }\n+\n+    @Override\n+    public void generateFlowUnitListFromWire(FlowUnitOperationArgWrapper args) {\n+        final List<FlowUnitMessage> flowUnitMessages =\n+                args.getWireHopper().readFromWire(args.getNode());\n+        List<ResourceFlowUnit<HotNodeSummary>> flowUnitList = new ArrayList<>();\n+        LOG.debug(\"rca: Executing fromWire: {}\", this.getClass().getSimpleName());\n+        for (FlowUnitMessage flowUnitMessage : flowUnitMessages) {\n+            flowUnitList.add(ResourceFlowUnit.buildFlowUnitFromWrapper(flowUnitMessage));\n+        }\n+        setFlowUnits(flowUnitList);\n+    }\n+\n+    /**\n+     * A collector class to collect eviction metrics\n+     */\n+    private static class CacheEvictionCollector {\n+        private final Resource cache;\n+        private final Metric cacheEvictionMetrics;\n+        private boolean hasEvictions;\n+        private long evictionTimestamp;\n+        private long evictionTimePeriodThreshold;\n+\n+        private CacheEvictionCollector(final Resource cache, final Metric cacheEvictionMetrics,\n+                                       final long threshold) {\n+            this.cache = cache;\n+            this.cacheEvictionMetrics = cacheEvictionMetrics;\n+            this.hasEvictions = false;\n+            this.evictionTimestamp = 0;\n+            this.evictionTimePeriodThreshold = threshold;\n+        }\n+\n+        public void collect(final long currTimestamp) {\n+            for (MetricFlowUnit flowUnit : cacheEvictionMetrics.getFlowUnits()) {\n+                if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n+                    continue;\n+                }\n+\n+                double evictionCount = flowUnit.getData().stream().mapToDouble(", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyNjQ1MA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454726450", "bodyText": "Yes, this is how the flowUnit.getData() looks like.\n+------------+-------+-----+-----+-----+-----+\n|IndexName   |ShardID|  sum|  avg|  min|  max|\n+------------+-------+-----+-----+-----+-----+\n|.kibana_1   |0      |  0.0|  0.0|  0.0|  0.0|\n|osmgeoshapes|1      |  0.0|  0.0|  0.0|  0.0|\n|osmgeoshapes|3      |  0.0|  0.0|  0.0|  0.0|\n|sonested    |0      |243.0|243.0|243.0|243.0|\n+------------+-------+-----+-----+-----+-----+", "author": "khushbr", "createdAt": "2020-07-15T00:51:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzMDU1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTIzMDA4OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r459230089", "bodyText": "Got it, so we need to sum the stream because this is a shard level metric?", "author": "vigyasharma", "createdAt": "2020-07-23T06:03:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzMDU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzMzA5OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451633099", "bodyText": "Same as above", "author": "vigyasharma", "createdAt": "2020-07-08T15:28:15Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYzNTU5NA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454635594", "bodyText": "Updated.", "author": "khushbr", "createdAt": "2020-07-14T20:48:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzMzA5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTYzNDE3Ng==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451634176", "bodyText": "same as above", "author": "vigyasharma", "createdAt": "2020-07-08T15:29:46Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Shard Request Cache, TTL is defined via `indices.requests.cache.expire` setting which is never used\n+ * in production clusters and only provided for backward compatibility, thus we ignore time based evictions.\n+ * The weight based evictions(removal from Cache Map and LRU linked List with entry updated to EVICTED) occur\n+ * when the cache_weight exceeds the max_cache_weight, eviction.\n+ *\n+ * <p>The Entry Invalidation is performed manually on cache clear(), index close() and for cached results from\n+ * timed-out requests. A scheduled runnable, running every 10 minutes cleans up all the invalidated entries which\n+ * have not been read/written to since invalidation.\n+ *\n+ * <p>The Cache Hit and Eviction metric presence implies cache is undergoing frequent load and eviction or undergoing\n+ * scheduled cleanup for entries which had timed-out during execution.\n+ *\n+ * <p>This RCA reads 'shardRequestCacheEvictions',  'shardRequestCacheHits', 'shardRequestCacheSize' and\n+ * 'shardRequestCacheMaxSize' from upstream metrics and maintains collectors which keeps track of the time window\n+ * period(tp) where we repeatedly see evictions and hits for the last tp duration. This RCA is marked as unhealthy\n+ * if tp we find tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class ShardRequestCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(ShardRequestCacheRca.class);\n+    private static final long THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric shardRequestCacheEvictions;\n+    private final Metric shardRequestCacheHits;\n+    private final Metric shardRequestCacheSize;\n+    private final Metric shardRequestCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheCollector cacheEvictionCollector;\n+    private final CacheCollector cacheHitCollector;\n+\n+    public <M extends Metric> ShardRequestCacheRca(final int rcaPeriod, final M shardRequestCacheEvictions,\n+                                                   final M shardRequestCacheHits, final M shardRequestCacheSize,\n+                                                   final M shardRequestCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.shardRequestCacheEvictions = shardRequestCacheEvictions;\n+        this.shardRequestCacheHits = shardRequestCacheHits;\n+        this.shardRequestCacheSize = shardRequestCacheSize;\n+        this.shardRequestCacheMaxSize = shardRequestCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheCollector(SHARD_REQUEST_CACHE_EVICTION,\n+                shardRequestCacheEvictions, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+        this.cacheHitCollector = new CacheCollector(SHARD_REQUEST_CACHE_HIT,\n+                shardRequestCacheHits, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        cacheHitCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(shardRequestCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(shardRequestCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MTQyMA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451641420", "bodyText": "It's not clear why exceedsSize is important for thrashing.\nIs this to remove false positives due to TTL based evictions? The doc string mentions that TTL based evictions are not performed because setting is not present and so we ignore it.\nEven to remove the TTL eviction false +ves, cacheSize may not exceed maxCacheSize because -\n\nES accounting should mostly be accurate, which prevents cacheSize from exceeding cacheMaxSize.\nEvictions should have brought down the cacheSize.\n\nMaybe we should check for cacheSize to be within a threshold of cacheMaxSize: assume evictions were due to TTL if cacheMaxSize - cacheSize > Threshold", "author": "vigyasharma", "createdAt": "2020-07-08T15:40:15Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Shard Request Cache, TTL is defined via `indices.requests.cache.expire` setting which is never used\n+ * in production clusters and only provided for backward compatibility, thus we ignore time based evictions.\n+ * The weight based evictions(removal from Cache Map and LRU linked List with entry updated to EVICTED) occur\n+ * when the cache_weight exceeds the max_cache_weight, eviction.\n+ *\n+ * <p>The Entry Invalidation is performed manually on cache clear(), index close() and for cached results from\n+ * timed-out requests. A scheduled runnable, running every 10 minutes cleans up all the invalidated entries which\n+ * have not been read/written to since invalidation.\n+ *\n+ * <p>The Cache Hit and Eviction metric presence implies cache is undergoing frequent load and eviction or undergoing\n+ * scheduled cleanup for entries which had timed-out during execution.\n+ *\n+ * <p>This RCA reads 'shardRequestCacheEvictions',  'shardRequestCacheHits', 'shardRequestCacheSize' and\n+ * 'shardRequestCacheMaxSize' from upstream metrics and maintains collectors which keeps track of the time window\n+ * period(tp) where we repeatedly see evictions and hits for the last tp duration. This RCA is marked as unhealthy\n+ * if tp we find tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class ShardRequestCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(ShardRequestCacheRca.class);\n+    private static final long THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric shardRequestCacheEvictions;\n+    private final Metric shardRequestCacheHits;\n+    private final Metric shardRequestCacheSize;\n+    private final Metric shardRequestCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheCollector cacheEvictionCollector;\n+    private final CacheCollector cacheHitCollector;\n+\n+    public <M extends Metric> ShardRequestCacheRca(final int rcaPeriod, final M shardRequestCacheEvictions,\n+                                                   final M shardRequestCacheHits, final M shardRequestCacheSize,\n+                                                   final M shardRequestCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.shardRequestCacheEvictions = shardRequestCacheEvictions;\n+        this.shardRequestCacheHits = shardRequestCacheHits;\n+        this.shardRequestCacheSize = shardRequestCacheSize;\n+        this.shardRequestCacheMaxSize = shardRequestCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheCollector(SHARD_REQUEST_CACHE_EVICTION,\n+                shardRequestCacheEvictions, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+        this.cacheHitCollector = new CacheCollector(SHARD_REQUEST_CACHE_HIT,\n+                shardRequestCacheHits, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        cacheHitCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(shardRequestCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(shardRequestCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+\n+            // if eviction and hit counts persists in last 5 minutes and cache size exceeds the max cache size configured,\n+            // the cache is considered as unhealthy\n+            if (cacheEvictionCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && cacheHitCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && exceedsSize) {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc0MDI0NQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454740245", "bodyText": "The evictions in Elasticsearch cache fall under 2 category :\n\nDirect Evictions :  Exceeds Weight and TTL expiry based\nAsync Eviction : Entry Invalidation, followed by forced eviction [Cache clear(), index close()] or in case of request cache, entry invalidation for timed out requests with a runnable clearing up the invalidated entries.\n\nThe reason for using exceedsSize was to handle the 2nd category, that we do not increase the cache size unless we notice eviction plus, the cache is filling up.\nI agree, we can use cacheMaxSize - cacheSize > threshold, where the threshold is percentage of the cacheMaxSize", "author": "khushbr", "createdAt": "2020-07-15T01:42:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MTQyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MTgxMg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451641812", "bodyText": "same as above", "author": "vigyasharma", "createdAt": "2020-07-08T15:40:50Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Shard Request Cache, TTL is defined via `indices.requests.cache.expire` setting which is never used\n+ * in production clusters and only provided for backward compatibility, thus we ignore time based evictions.\n+ * The weight based evictions(removal from Cache Map and LRU linked List with entry updated to EVICTED) occur\n+ * when the cache_weight exceeds the max_cache_weight, eviction.\n+ *\n+ * <p>The Entry Invalidation is performed manually on cache clear(), index close() and for cached results from\n+ * timed-out requests. A scheduled runnable, running every 10 minutes cleans up all the invalidated entries which\n+ * have not been read/written to since invalidation.\n+ *\n+ * <p>The Cache Hit and Eviction metric presence implies cache is undergoing frequent load and eviction or undergoing\n+ * scheduled cleanup for entries which had timed-out during execution.\n+ *\n+ * <p>This RCA reads 'shardRequestCacheEvictions',  'shardRequestCacheHits', 'shardRequestCacheSize' and\n+ * 'shardRequestCacheMaxSize' from upstream metrics and maintains collectors which keeps track of the time window\n+ * period(tp) where we repeatedly see evictions and hits for the last tp duration. This RCA is marked as unhealthy\n+ * if tp we find tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class ShardRequestCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(ShardRequestCacheRca.class);\n+    private static final long THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric shardRequestCacheEvictions;\n+    private final Metric shardRequestCacheHits;\n+    private final Metric shardRequestCacheSize;\n+    private final Metric shardRequestCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheCollector cacheEvictionCollector;\n+    private final CacheCollector cacheHitCollector;\n+\n+    public <M extends Metric> ShardRequestCacheRca(final int rcaPeriod, final M shardRequestCacheEvictions,\n+                                                   final M shardRequestCacheHits, final M shardRequestCacheSize,\n+                                                   final M shardRequestCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.shardRequestCacheEvictions = shardRequestCacheEvictions;\n+        this.shardRequestCacheHits = shardRequestCacheHits;\n+        this.shardRequestCacheSize = shardRequestCacheSize;\n+        this.shardRequestCacheMaxSize = shardRequestCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheCollector(SHARD_REQUEST_CACHE_EVICTION,\n+                shardRequestCacheEvictions, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+        this.cacheHitCollector = new CacheCollector(SHARD_REQUEST_CACHE_HIT,\n+                shardRequestCacheHits, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        cacheHitCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(shardRequestCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(shardRequestCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+\n+            // if eviction and hit counts persists in last 5 minutes and cache size exceeds the max cache size configured,\n+            // the cache is considered as unhealthy\n+            if (cacheEvictionCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && cacheHitCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && exceedsSize) {\n+                context = new ResourceContext(Resources.State.UNHEALTHY);\n+                nodeSummary = new HotNodeSummary(currentNode.getId(), currentNode.getHostAddress());\n+                nodeSummary.appendNestedSummary(cacheEvictionCollector.generateSummary(currTimestamp));\n+            } else {\n+                context = new ResourceContext(Resources.State.HEALTHY);\n+                nodeSummary = null;\n+            }\n+\n+            counter = 0;\n+            exceedsSize = Boolean.FALSE;\n+            return new ResourceFlowUnit<>(currTimestamp, context, nodeSummary, !currentNode.getIsMasterNode());\n+        }\n+        else {\n+            return new ResourceFlowUnit<>(currTimestamp);\n+        }\n+    }\n+\n+    @Override\n+    public void generateFlowUnitListFromWire(FlowUnitOperationArgWrapper args) {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYzODk1OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454638959", "bodyText": "Yes. generateFlowUnitListFromWire() is required for all Node level RCAs and this should be refactored and moved to base RCA class.", "author": "khushbr", "createdAt": "2020-07-14T20:54:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0MTgxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0NDE2NA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451644164", "bodyText": "same as above", "author": "vigyasharma", "createdAt": "2020-07-08T15:44:28Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Shard Request Cache, TTL is defined via `indices.requests.cache.expire` setting which is never used\n+ * in production clusters and only provided for backward compatibility, thus we ignore time based evictions.\n+ * The weight based evictions(removal from Cache Map and LRU linked List with entry updated to EVICTED) occur\n+ * when the cache_weight exceeds the max_cache_weight, eviction.\n+ *\n+ * <p>The Entry Invalidation is performed manually on cache clear(), index close() and for cached results from\n+ * timed-out requests. A scheduled runnable, running every 10 minutes cleans up all the invalidated entries which\n+ * have not been read/written to since invalidation.\n+ *\n+ * <p>The Cache Hit and Eviction metric presence implies cache is undergoing frequent load and eviction or undergoing\n+ * scheduled cleanup for entries which had timed-out during execution.\n+ *\n+ * <p>This RCA reads 'shardRequestCacheEvictions',  'shardRequestCacheHits', 'shardRequestCacheSize' and\n+ * 'shardRequestCacheMaxSize' from upstream metrics and maintains collectors which keeps track of the time window\n+ * period(tp) where we repeatedly see evictions and hits for the last tp duration. This RCA is marked as unhealthy\n+ * if tp we find tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class ShardRequestCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(ShardRequestCacheRca.class);\n+    private static final long THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric shardRequestCacheEvictions;\n+    private final Metric shardRequestCacheHits;\n+    private final Metric shardRequestCacheSize;\n+    private final Metric shardRequestCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheCollector cacheEvictionCollector;\n+    private final CacheCollector cacheHitCollector;\n+\n+    public <M extends Metric> ShardRequestCacheRca(final int rcaPeriod, final M shardRequestCacheEvictions,\n+                                                   final M shardRequestCacheHits, final M shardRequestCacheSize,\n+                                                   final M shardRequestCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.shardRequestCacheEvictions = shardRequestCacheEvictions;\n+        this.shardRequestCacheHits = shardRequestCacheHits;\n+        this.shardRequestCacheSize = shardRequestCacheSize;\n+        this.shardRequestCacheMaxSize = shardRequestCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheCollector(SHARD_REQUEST_CACHE_EVICTION,\n+                shardRequestCacheEvictions, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+        this.cacheHitCollector = new CacheCollector(SHARD_REQUEST_CACHE_HIT,\n+                shardRequestCacheHits, THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        cacheHitCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(shardRequestCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(shardRequestCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+\n+            // if eviction and hit counts persists in last 5 minutes and cache size exceeds the max cache size configured,\n+            // the cache is considered as unhealthy\n+            if (cacheEvictionCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && cacheHitCollector.isMetricPresentForThresholdTime(currTimestamp)\n+                    && exceedsSize) {\n+                context = new ResourceContext(Resources.State.UNHEALTHY);\n+                nodeSummary = new HotNodeSummary(currentNode.getId(), currentNode.getHostAddress());\n+                nodeSummary.appendNestedSummary(cacheEvictionCollector.generateSummary(currTimestamp));\n+            } else {\n+                context = new ResourceContext(Resources.State.HEALTHY);\n+                nodeSummary = null;\n+            }\n+\n+            counter = 0;\n+            exceedsSize = Boolean.FALSE;\n+            return new ResourceFlowUnit<>(currTimestamp, context, nodeSummary, !currentNode.getIsMasterNode());\n+        }\n+        else {\n+            return new ResourceFlowUnit<>(currTimestamp);\n+        }\n+    }\n+\n+    @Override\n+    public void generateFlowUnitListFromWire(FlowUnitOperationArgWrapper args) {\n+        final List<FlowUnitMessage> flowUnitMessages =\n+                args.getWireHopper().readFromWire(args.getNode());\n+        List<ResourceFlowUnit<HotNodeSummary>> flowUnitList = new ArrayList<>();\n+        LOG.debug(\"rca: Executing fromWire: {}\", this.getClass().getSimpleName());\n+        for (FlowUnitMessage flowUnitMessage : flowUnitMessages) {\n+            flowUnitList.add(ResourceFlowUnit.buildFlowUnitFromWrapper(flowUnitMessage));\n+        }\n+        setFlowUnits(flowUnitList);\n+    }\n+\n+    /**\n+     * A collector class to collect metrics (eviction and hit) for cache\n+     */\n+    private static class CacheCollector {\n+        private final Resource cache;\n+        private final Metric cacheMetrics;\n+        private boolean hasMetric;\n+        private long metricTimestamp;\n+        private long metricTimePeriodThreshold;\n+\n+        public CacheCollector(final Resource cache, final Metric cacheMetrics, final long threshold) {\n+            this.cache = cache;\n+            this.cacheMetrics = cacheMetrics;\n+            this.hasMetric = false;\n+            this.metricTimestamp = 0;\n+            this.metricTimePeriodThreshold = threshold;\n+        }\n+\n+        public void collect(final long currTimestamp) {\n+            for (MetricFlowUnit flowUnit : cacheMetrics.getFlowUnits()) {\n+                if (flowUnit.isEmpty()) {\n+                    continue;\n+                }\n+\n+                Result<Record> records = flowUnit.getData();\n+                double metricCount = records.stream().mapToDouble(", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyNzg5MA==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454727890", "bodyText": "Yes. This is what the records looks like, and the metricCount is sum of the sum column of the record set\n[2020-07-14T17:19:11,289][INFO ][c.a.o.e.p.r.s.r.c.ShardRequestCacheRca] records --> +------------+-------+-----+-----+-----+-----+\n|IndexName   |ShardID|  sum|  avg|  min|  max|\n+------------+-------+-----+-----+-----+-----+\n|.kibana_1   |0      |  0.0|  0.0|  0.0|  0.0|\n|osmgeoshapes|1      |  0.0|  0.0|  0.0|  0.0|\n|osmgeoshapes|3      |  0.0|  0.0|  0.0|  0.0|\n|sonested    |0      |243.0|243.0|243.0|243.0|\n+------------+-------+-----+-----+-----+-----+\n[2020-07-14T17:19:11,290][INFO ][c.a.o.e.p.r.s.r.c.ShardRequestCacheRca] metricCount --> 243.0", "author": "khushbr", "createdAt": "2020-07-15T00:57:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY0NDE2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY2MzEwNQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r451663105", "bodyText": "We are checking if cacheMaxSize is not zero twice.", "author": "sruti1312", "createdAt": "2020-07-08T16:12:41Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYyNzg2OQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454627869", "bodyText": "Good Catch. Updated.", "author": "khushbr", "createdAt": "2020-07-14T20:34:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY2MzEwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3NjM5Ng==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453076396", "bodyText": "should we check the size the flowunit list to avoid null pointer exception ?", "author": "rguo-aws", "createdAt": "2020-07-10T21:04:01Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+\n+public class CacheUtil {\n+    private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n+    private static final double CONVERT_BYTES_TO_MEGABYTES = Math.pow(1024, 3);\n+\n+    public static Double getTotalSizeInMB(final Metric sizeMetric) {\n+        double sizeTotalInMB = 0;\n+\n+        // we expect the Metric to have single flow unit since it is consumed locally\n+        MetricFlowUnit flowUnit = sizeMetric.getFlowUnits().get(0);", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDU4MDkyNw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454580927", "bodyText": "Good Point, updated to check for size of flowunit list.", "author": "khushbr", "createdAt": "2020-07-14T19:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3NjM5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3NzQ5Nw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453077497", "bodyText": "instead of iterating through the list of tuples in record, can we extend the cache metric class and leverage the SQL group by statement when reading from the db ?", "author": "rguo-aws", "createdAt": "2020-07-10T21:06:53Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/CacheUtil.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+\n+public class CacheUtil {\n+    private static final Logger LOG = LogManager.getLogger(CacheUtil.class);\n+    private static final double CONVERT_BYTES_TO_MEGABYTES = Math.pow(1024, 3);\n+\n+    public static Double getTotalSizeInMB(final Metric sizeMetric) {\n+        double sizeTotalInMB = 0;\n+\n+        // we expect the Metric to have single flow unit since it is consumed locally\n+        MetricFlowUnit flowUnit = sizeMetric.getFlowUnits().get(0);\n+        if (flowUnit.isEmpty() || flowUnit.getData() == null) {\n+            return sizeTotalInMB;\n+        }\n+\n+        for (Record record : flowUnit.getData()) {\n+            double size = record.getValue(MetricsDB.MAX, Double.class);", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDcyMzA0Nw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454723047", "bodyText": "Updated the code to use aggregate Size and Max Size metrics to avoid the per-record iteration.", "author": "khushbr", "createdAt": "2020-07-15T00:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3NzQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3OTgzMQ==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453079831", "bodyText": "let's add node summary to healthy flowunit and send it as a heartbeat to cluster rca", "author": "rguo-aws", "createdAt": "2020-07-10T21:13:20Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {\n+        super(5);\n+        this.rcaPeriod = rcaPeriod;\n+        this.fieldDataCacheEvictions = fieldDataCacheEvictions;\n+        this.fieldDataCacheSize = fieldDataCacheSize;\n+        this.fieldDataCacheMaxSize = fieldDataCacheMaxSize;\n+        this.counter = 0;\n+        this.exceedsSize = Boolean.FALSE;\n+        this.clock = Clock.systemUTC();\n+        this.cacheEvictionCollector = new CacheEvictionCollector(FIELD_DATA_CACHE_EVICTION,\n+                fieldDataCacheEvictions, EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND);\n+    }\n+\n+    @VisibleForTesting\n+    public void setClock(Clock clock) {\n+        this.clock = clock;\n+    }\n+\n+    @Override\n+    public ResourceFlowUnit<HotNodeSummary> operate() {\n+        counter += 1;\n+        long currTimestamp = clock.millis();\n+\n+        cacheEvictionCollector.collect(currTimestamp);\n+        if (counter >= rcaPeriod) {\n+            ResourceContext context;\n+            HotNodeSummary nodeSummary;\n+\n+            ClusterDetailsEventProcessor.NodeDetails currentNode = ClusterDetailsEventProcessor.getCurrentNodeDetails();\n+            double cacheSize = getTotalSizeInMB(fieldDataCacheSize);\n+            double cacheMaxSize = getTotalSizeInMB(fieldDataCacheMaxSize);\n+            exceedsSize = cacheMaxSize != 0 && cacheMaxSize != 0 && cacheSize > cacheMaxSize;\n+            if (cacheEvictionCollector.isUnhealthy(currTimestamp) && exceedsSize) {\n+                context = new ResourceContext(Resources.State.UNHEALTHY);\n+                nodeSummary = new HotNodeSummary(currentNode.getId(), currentNode.getHostAddress());\n+                nodeSummary.appendNestedSummary(cacheEvictionCollector.generateSummary(currTimestamp));\n+            }\n+            else {\n+                context = new ResourceContext(Resources.State.HEALTHY);\n+                nodeSummary = null;", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYzMzQ1Nw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454633457", "bodyText": "We don't send node summary for healthy flow units in any other RCA. Let me know if I am missing anything.", "author": "khushbr", "createdAt": "2020-07-14T20:44:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA3OTgzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4MTM4Nw==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453081387", "bodyText": "fieldDataCacheMaxSize will be collected as part of node config RCA. Do we need a separate metric here ?", "author": "rguo-aws", "createdAt": "2020-07-10T21:17:48Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/FieldDataCacheRca.java", "diffHunk": "@@ -0,0 +1,204 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.FIELD_DATA_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+/**\n+ * Field Data Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction count, cache current weight(size) and\n+ * cache max weight(size) configured.\n+ * Note : For Field Data Cache, Hit and Miss metrics aren't available.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios :\n+ * <ol>\n+ *   <li>Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li>Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Field Data Cache, no expire setting is present, so only in case of cache_weight exceeding the\n+ * max_cache_weight, eviction(removal from Cache Map and LRU linked List, entry updated to EVICTED)\n+ * happens.\n+ *\n+ * <p>Contrarily, the Cache Invalidation is performed manually on cache clear() and index close()\n+ * invocation, with removalReason as INVALIDATED and a force eviction is performed to ensure cleanup.\n+ *\n+ * <p>This RCA reads 'fieldDataCacheEvictions', 'fieldDataCacheSize' and 'fieldDataCacheMaxSize'\n+ * from upstream metrics and maintains a collector which keeps track of the time window period(tp)\n+ * where we repeatedly see evictions for the last tp duration. This RCA is marked as unhealthy if\n+ * tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class FieldDataCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {\n+    private static final Logger LOG = LogManager.getLogger(FieldDataCacheRca.class);\n+    private static final long EVICTION_THRESHOLD_TIME_PERIOD_IN_MILLISECOND = TimeUnit.SECONDS.toMillis(300);\n+\n+    private final Metric fieldDataCacheEvictions;\n+    private final Metric fieldDataCacheSize;\n+    private final Metric fieldDataCacheMaxSize;\n+    private final int rcaPeriod;\n+    private int counter;\n+    private boolean exceedsSize;\n+    protected Clock clock;\n+    private final CacheEvictionCollector cacheEvictionCollector;\n+\n+    public <M extends Metric> FieldDataCacheRca(final int rcaPeriod, final M fieldDataCacheEvictions,\n+                                                final M fieldDataCacheSize, final M fieldDataCacheMaxSize) {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYyNzQzMg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454627432", "bodyText": "Right, the metric collected by Node Config RCA will be re-used here. This will be updated depending on how Node Config RCA is propagating the metric", "author": "khushbr", "createdAt": "2020-07-14T20:33:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4MTM4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4MjM0Mg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r453082342", "bodyText": "can we combine ShardRequestCacheRca and FieldDataCacheRca into one RCA and use different collector to collect those caches individually to reduce overhead ? Is there any benefit of creating two separate RCAs ?", "author": "rguo-aws", "createdAt": "2020-07-10T21:20:27Z", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rca/store/rca/cache/ShardRequestCacheRca.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ *  permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_EVICTION;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.ResourceUtil.SHARD_REQUEST_CACHE_HIT;\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.store.rca.cache.CacheUtil.getTotalSizeInMB;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.FlowUnitMessage;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.grpc.Resource;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Rca;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.Resources;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.contexts.ResourceContext;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.MetricFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.flow_units.ResourceFlowUnit;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotNodeSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.framework.api.summaries.HotResourceSummary;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.rca.scheduler.FlowUnitOperationArgWrapper;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ClusterDetailsEventProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import java.time.Clock;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Shard Request Cache RCA is to identify when the cache is unhealthy(thrashing) and otherwise, healthy.\n+ * The dimension we are using for this analysis is cache eviction, hit count, cache current weight(size)\n+ * and cache max weight(size) configured.\n+ *\n+ * <p>Cache eviction within Elasticsearch happens in following scenarios:\n+ * <ol>\n+ *   <li> Mutation to Cache (Entry Insertion/Promotion and Manual Invalidation)\n+ *   <li> Explicit call to refresh()\n+ * </ol>\n+ *\n+ * <p>The Cache Eviction requires that either the cache weight exceeds OR the entry TTL is expired.\n+ * For Shard Request Cache, TTL is defined via `indices.requests.cache.expire` setting which is never used\n+ * in production clusters and only provided for backward compatibility, thus we ignore time based evictions.\n+ * The weight based evictions(removal from Cache Map and LRU linked List with entry updated to EVICTED) occur\n+ * when the cache_weight exceeds the max_cache_weight, eviction.\n+ *\n+ * <p>The Entry Invalidation is performed manually on cache clear(), index close() and for cached results from\n+ * timed-out requests. A scheduled runnable, running every 10 minutes cleans up all the invalidated entries which\n+ * have not been read/written to since invalidation.\n+ *\n+ * <p>The Cache Hit and Eviction metric presence implies cache is undergoing frequent load and eviction or undergoing\n+ * scheduled cleanup for entries which had timed-out during execution.\n+ *\n+ * <p>This RCA reads 'shardRequestCacheEvictions',  'shardRequestCacheHits', 'shardRequestCacheSize' and\n+ * 'shardRequestCacheMaxSize' from upstream metrics and maintains collectors which keeps track of the time window\n+ * period(tp) where we repeatedly see evictions and hits for the last tp duration. This RCA is marked as unhealthy\n+ * if tp we find tp is above the threshold(300 seconds) and cache size exceeds the max cache size configured.\n+ *\n+ */\n+public class ShardRequestCacheRca extends Rca<ResourceFlowUnit<HotNodeSummary>> {", "originalCommit": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDYzODA4Mg==", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/265#discussion_r454638082", "bodyText": "One major use case I can think of is muting, if we want to mute FieldDataCache or ShardRequest RCA, currently it will be straightforward to mute the RCA node.\nAdditionally, FieldDataCache uses size, maxsize and evictions where Shard Request Cache uses the additional hit count metric as well.", "author": "khushbr", "createdAt": "2020-07-14T20:53:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4MjM0Mg=="}], "type": "inlineReview"}, {"oid": "cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/cff19819087b2fee29c8ab523b5c91b01c9ed6a3", "message": "Squashed commit of the following:\n\ncommit e72afa1051640480bf4cea301025e1318e657016\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 11:34:59 2020 -0700\n\n    Refreshing from Mainline\n\ncommit d1b3f21da20d594b27c5f32b4999c7bd5831225b\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 11:13:49 2020 -0700\n\n    Removing a comment from the util file\n\ncommit 63ddab2539d50887594643eaab945db54bdad79b\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Tue Jul 7 02:47:36 2020 -0700\n\n    Adding final set of changes for Cache RCAs\n\ncommit 09537c24ccfcd3c485efbf56938b62818d895ea6\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 23:54:28 2020 -0700\n\n    Adding weight check for async evictions in FieldDataCache\n\ncommit 65d8f438a03f5ab28501e0d0d690a4af029c1b91\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 16:04:59 2020 -0700\n\n    Addinf UT for ShardRequestCacheRca\n\ncommit cdec05b58f62b2138316fd0daa06efc384c90c09\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Mon Jul 6 10:45:07 2020 -0700\n\n    Adding UT for FieldDataCacheRca\n\ncommit ebdbc7e8beea059f49da077943fbc2048487d662\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Sun Jul 5 23:16:57 2020 -0700\n\n    Refreshing from master\n\ncommit 4238148ce976a38fdf5540f231c93b2cdedbb148\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Sun Jul 5 23:15:08 2020 -0700\n\n    Adding the FieldDataCacheRca and ShardRequestCacheRca\n\ncommit b6f1a51eb78abad87b3bbd4a6be27c05284c4ff4\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Wed Jul 1 14:17:01 2020 -0700\n\n    Including the Protobuf re-factoring changes\n\ncommit 03cc597d008871e2ab13bf04762121e713b309ff\nAuthor: khushbr <khushbr@amazon.com>\nDate:   Wed Jun 24 21:53:08 2020 -0700\n\n    Refreshing from master", "committedDate": "2020-07-07T18:55:23Z", "type": "forcePushed"}, {"oid": "361003cda6b7a8c0e3abaaa396e4206190aa23c4", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/361003cda6b7a8c0e3abaaa396e4206190aa23c4", "message": "Addressing the PR comments", "committedDate": "2020-07-15T06:10:26Z", "type": "commit"}, {"oid": "14127b2c8809eae0a12979b693183645ee168a11", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/14127b2c8809eae0a12979b693183645ee168a11", "message": "Merge branch 'master' into khushbr-cache-rca", "committedDate": "2020-07-23T19:10:19Z", "type": "commit"}]}