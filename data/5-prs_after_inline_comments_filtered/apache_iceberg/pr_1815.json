{"pr_number": 1815, "pr_title": "Flink : add list partitions for FlinkCatalog", "pr_createdAt": "2020-11-24T09:17:51Z", "pr_url": "https://github.com/apache/iceberg/pull/1815", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwMjM3OQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r529802379", "bodyText": "This should not be public. The public interface is StructLike.", "author": "rdblue", "createdAt": "2020-11-24T18:47:53Z", "path": "core/src/main/java/org/apache/iceberg/PartitionData.java", "diffHunk": "@@ -36,7 +36,7 @@\n import org.apache.iceberg.types.Type;\n import org.apache.iceberg.types.Types;\n \n-class PartitionData\n+public class PartitionData", "originalCommit": "3f811946c672986511a19ee4b99a376a519892e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwMzI4Mw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r529803283", "bodyText": "To get data from StructLike, this can call String.valueOf(partition.get(i, Object.class)).\nPartition values can be null, so using String.valueOf will avoid NullPointerException.", "author": "rdblue", "createdAt": "2020-11-24T18:49:32Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +625,23 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+    CloseableIterable<FileScanTask> tasks = table.newScan().planFiles();\n+    List<DataFile> dataFiles = Lists.newArrayList(CloseableIterable.transform(tasks, FileScanTask::file));\n+\n+    Set<CatalogPartitionSpec> set = Sets.newHashSet();\n+    for (DataFile dataFile : dataFiles) {\n+      Map<String, String> map = new HashMap<>();\n+      PartitionData partitionData = (PartitionData) dataFile.partition();\n+      Types.StructType structType = partitionData.getPartitionType();\n+      for (int i = 0; i < partitionData.size(); i++) {\n+        map.put(structType.fields().get(i).name(), partitionData.get(i).toString());", "originalCommit": "3f811946c672986511a19ee4b99a376a519892e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwODAyMA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r529808020", "bodyText": "You can get the partition type for each file using DataFile.specId() and looking up the spec in the table.", "author": "rdblue", "createdAt": "2020-11-24T18:57:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwMzI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwMzQ4OQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r529803489", "bodyText": "We like to use the factory method instead: Maps.newHashMap().", "author": "rdblue", "createdAt": "2020-11-24T18:49:46Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +625,23 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+    CloseableIterable<FileScanTask> tasks = table.newScan().planFiles();\n+    List<DataFile> dataFiles = Lists.newArrayList(CloseableIterable.transform(tasks, FileScanTask::file));\n+\n+    Set<CatalogPartitionSpec> set = Sets.newHashSet();\n+    for (DataFile dataFile : dataFiles) {\n+      Map<String, String> map = new HashMap<>();", "originalCommit": "3f811946c672986511a19ee4b99a376a519892e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTgwNjg1MQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r529806851", "bodyText": "This needs to be closed when this method is finished:\nSet<CatalogPartitionSpec> set = Sets.newHashSet();\ntry (CloseableIterable<FileScanTask> tasks = table.newScan().planFiles()) {\n  for (DataFile dataFile : CloseableIterable.transform(tasks, FileScanTask::file)) {\n    ...\n  }\n}\nIn that code, I've also removed the intermediate list of DataFile. The iterable returned by planFiles() is designed to avoid keeping everything in memory at one time, so you should iterate over that or using a transformed iterable. Loading all the files into memory will cause this to run out of memory for large tables.", "author": "rdblue", "createdAt": "2020-11-24T18:55:19Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +625,23 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+    CloseableIterable<FileScanTask> tasks = table.newScan().planFiles();", "originalCommit": "3f811946c672986511a19ee4b99a376a519892e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "469805e3cad35b9ea0fae1aa2472c4f76f8e4445", "url": "https://github.com/apache/iceberg/commit/469805e3cad35b9ea0fae1aa2472c4f76f8e4445", "message": "add show partitions", "committedDate": "2020-11-25T02:27:05Z", "type": "forcePushed"}, {"oid": "869cc30007ef03da95a0bd7d935395b7a6675e94", "url": "https://github.com/apache/iceberg/commit/869cc30007ef03da95a0bd7d935395b7a6675e94", "message": "add show partitions", "committedDate": "2020-11-25T02:33:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyNTI0Mw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530225243", "bodyText": "Better to use the FlinkCatalog#loadIcebergTable,  because it's wrapped to throw a TableNotExistException for flink.", "author": "openinx", "createdAt": "2020-11-25T09:29:13Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +624,25 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzMzA5OA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530233098", "bodyText": "I updated it", "author": "zhangjun0x01", "createdAt": "2020-11-25T09:40:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyNTI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzMzAwNw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530233007", "bodyText": "nit: use INSERT INTO %s SELECT 1, 'a'", "author": "openinx", "createdAt": "2020-11-25T09:40:27Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsEmpty() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzNDczOQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530234739", "bodyText": "For an unpartitioned table, seems we need to throw a TableNotPartitionedException ?  I read the java doc from listPartitions  in flink's Catalog interface:\n\t/**\n\t * Get CatalogPartitionSpec of all partitions of the table.\n\t *\n\t * @param tablePath\tpath of the table\n\t * @return a list of CatalogPartitionSpec of the table\n\t *\n\t * @throws TableNotExistException thrown if the table does not exist in the catalog\n\t * @throws TableNotPartitionedException thrown if the table is not partitioned\n\t * @throws CatalogException\tin case of any runtime exception\n\t */\n\tList<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n\t\tthrows TableNotExistException, TableNotPartitionedException, CatalogException;", "author": "openinx", "createdAt": "2020-11-25T09:42:57Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +624,25 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+    Set<CatalogPartitionSpec> set = Sets.newHashSet();\n+    try (CloseableIterable<FileScanTask> tasks = table.newScan().planFiles()) {\n+      for (DataFile dataFile : CloseableIterable.transform(tasks, FileScanTask::file)) {\n+        Map<String, String> map = Maps.newHashMap();\n+        StructLike structLike = dataFile.partition();\n+        PartitionSpec spec = table.specs().get(dataFile.specId());\n+        for (int i = 0; i < structLike.size(); i++) {\n+          map.put(spec.fields().get(i).name(), String.valueOf(structLike.get(i, Object.class)));\n+        }\n+        // if the table is unpartitioned table, do not add it to set\n+        if (map.size() > 0) {", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzNTEyOA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530235128", "bodyText": "@throws CatalogException\tin case of any runtime exception", "author": "openinx", "createdAt": "2020-11-25T09:43:33Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -619,7 +624,25 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n       throws CatalogException {\n-    throw new UnsupportedOperationException();\n+    Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+    Set<CatalogPartitionSpec> set = Sets.newHashSet();\n+    try (CloseableIterable<FileScanTask> tasks = table.newScan().planFiles()) {\n+      for (DataFile dataFile : CloseableIterable.transform(tasks, FileScanTask::file)) {\n+        Map<String, String> map = Maps.newHashMap();\n+        StructLike structLike = dataFile.partition();\n+        PartitionSpec spec = table.specs().get(dataFile.specId());\n+        for (int i = 0; i < structLike.size(); i++) {\n+          map.put(spec.fields().get(i).name(), String.valueOf(structLike.get(i, Object.class)));\n+        }\n+        // if the table is unpartitioned table, do not add it to set\n+        if (map.size() > 0) {\n+          set.add(new CatalogPartitionSpec(map));\n+        }\n+      }\n+    } catch (IOException e) {\n+      throw new UncheckedIOException(e);", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzNTc3MQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530235771", "bodyText": "ditto.", "author": "openinx", "createdAt": "2020-11-25T09:44:23Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsEmpty() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    List<CatalogPartitionSpec> list = flinkCatalog.listPartitions(objectPath);\n+    Assert.assertEquals(\"Should have empty partition\", 0, list.size());\n+  }\n+\n+\n+  @Test\n+  public void testListPartitions() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar) PARTITIONED BY (data)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzNjQ1Mw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530236453", "bodyText": "Just use the ImmutableMap.of(\"data\", \"a\") ?", "author": "openinx", "createdAt": "2020-11-25T09:45:18Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsEmpty() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    List<CatalogPartitionSpec> list = flinkCatalog.listPartitions(objectPath);\n+    Assert.assertEquals(\"Should have empty partition\", 0, list.size());\n+  }\n+\n+\n+  @Test\n+  public void testListPartitions() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar) PARTITIONED BY (data)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);\n+    sql(\"insert into %s select 2,'b'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    List<CatalogPartitionSpec> list = flinkCatalog.listPartitions(objectPath);\n+    Assert.assertEquals(\"Should have 2 partition\", 2, list.size());\n+\n+    List<CatalogPartitionSpec> expected = Lists.newArrayList();\n+    CatalogPartitionSpec partitionSpec1 = new CatalogPartitionSpec(new HashMap<String, String>() {{", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIzNjg4Mw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530236883", "bodyText": "Should produce the expected catalog partition specs.", "author": "openinx", "createdAt": "2020-11-25T09:45:53Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsEmpty() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    List<CatalogPartitionSpec> list = flinkCatalog.listPartitions(objectPath);\n+    Assert.assertEquals(\"Should have empty partition\", 0, list.size());\n+  }\n+\n+\n+  @Test\n+  public void testListPartitions() throws TableNotExistException {\n+    sql(\"CREATE TABLE %s (id int, data varchar) PARTITIONED BY (data)\", tableName);\n+    sql(\"insert into %s select 1,'a'\", tableName);\n+    sql(\"insert into %s select 2,'b'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    List<CatalogPartitionSpec> list = flinkCatalog.listPartitions(objectPath);\n+    Assert.assertEquals(\"Should have 2 partition\", 2, list.size());\n+\n+    List<CatalogPartitionSpec> expected = Lists.newArrayList();\n+    CatalogPartitionSpec partitionSpec1 = new CatalogPartitionSpec(new HashMap<String, String>() {{\n+        put(\"data\", \"a\");\n+      }}\n+    );\n+    CatalogPartitionSpec partitionSpec2 = new CatalogPartitionSpec(new HashMap<String, String>() {{\n+        put(\"data\", \"b\");\n+      }}\n+    );\n+    expected.add(partitionSpec1);\n+    expected.add(partitionSpec2);\n+    Assert.assertEquals(\"Should produce the expected record\", list, expected);", "originalCommit": "869cc30007ef03da95a0bd7d935395b7a6675e94", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU4MDgxNg==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530580816", "bodyText": "Nit: please add empty lines after control flow blocks like if, try, while, and for.", "author": "rdblue", "createdAt": "2020-11-25T18:48:53Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -618,8 +623,27 @@ public void alterPartitionColumnStatistics(ObjectPath tablePath, CatalogPartitio\n \n   @Override\n   public List<CatalogPartitionSpec> listPartitions(ObjectPath tablePath)\n-      throws CatalogException {\n-    throw new UnsupportedOperationException();\n+      throws TableNotExistException, TableNotPartitionedException, CatalogException {\n+    Table table = loadIcebergTable(tablePath);\n+\n+    if (table.spec().isUnpartitioned()) {\n+      throw new TableNotPartitionedException(icebergCatalog.name(), tablePath);\n+    }\n+    Set<CatalogPartitionSpec> set = Sets.newHashSet();", "originalCommit": "643bc9ad927c117cf994fc5ad9465aea38659aa1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU4MjE2NA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530582164", "bodyText": "Minor: Tests should generally use AssertHelpers.assertThrows instead of expected so that other assertions can be checked after the failure. It's okay here because listPartitions doesn't modify the table.", "author": "rdblue", "createdAt": "2020-11-25T18:51:35Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotPartitionedException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test(expected = TableNotPartitionedException.class)", "originalCommit": "643bc9ad927c117cf994fc5ad9465aea38659aa1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDU4Mjc2Ng==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530582766", "bodyText": "This test name is not correct. It should be testListPartitionsWithUnpartitionedTable.", "author": "rdblue", "createdAt": "2020-11-25T18:52:52Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotPartitionedException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test(expected = TableNotPartitionedException.class)\n+  public void testListPartitionsEmpty() throws TableNotExistException, TableNotPartitionedException {", "originalCommit": "643bc9ad927c117cf994fc5ad9465aea38659aa1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "99423d888d20d7f36660922ff88bea8b8e4ed8a5", "url": "https://github.com/apache/iceberg/commit/99423d888d20d7f36660922ff88bea8b8e4ed8a5", "message": "add list partitions for FlinkCatalog", "committedDate": "2020-11-26T01:21:05Z", "type": "commit"}, {"oid": "6aef0e351ab8d5637bb0d2e5439b83f7fd3c7ff5", "url": "https://github.com/apache/iceberg/commit/6aef0e351ab8d5637bb0d2e5439b83f7fd3c7ff5", "message": "add show partitions", "committedDate": "2020-11-26T01:21:05Z", "type": "commit"}, {"oid": "f23b521b38c1e620fc56e670d7cfb8b90ed0dbc1", "url": "https://github.com/apache/iceberg/commit/f23b521b38c1e620fc56e670d7cfb8b90ed0dbc1", "message": "use loadIcebergTable to load iceberg table", "committedDate": "2020-11-26T01:21:05Z", "type": "commit"}, {"oid": "bc6a14aa3de01dff83d117d1a96d19a479aed6dd", "url": "https://github.com/apache/iceberg/commit/bc6a14aa3de01dff83d117d1a96d19a479aed6dd", "message": "add exception for listPartitions", "committedDate": "2020-11-26T01:21:05Z", "type": "commit"}, {"oid": "bfe234fddc7883ec68f43c2c7637a793eeacf11b", "url": "https://github.com/apache/iceberg/commit/bfe234fddc7883ec68f43c2c7637a793eeacf11b", "message": "rename test method and modify some code format", "committedDate": "2020-11-26T01:21:29Z", "type": "forcePushed"}, {"oid": "345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "url": "https://github.com/apache/iceberg/commit/345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "message": "rename test method and modify some code format", "committedDate": "2020-11-26T01:25:47Z", "type": "commit"}, {"oid": "345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "url": "https://github.com/apache/iceberg/commit/345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "message": "rename test method and modify some code format", "committedDate": "2020-11-26T01:25:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczOTQ1Mg==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530739452", "bodyText": "nit:  the throwing TableNotPartitionedException could be removed now ?", "author": "openinx", "createdAt": "2020-11-26T02:31:48Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotPartitionedException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsWithUnpartitionedTable() throws TableNotExistException, TableNotPartitionedException {", "originalCommit": "345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTA3MQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530741071", "bodyText": "Do we need this refresh sentence ?  For the newly loaded iceberg table will refresh the latest metadata automatically ,  so I don't think we need this.", "author": "openinx", "createdAt": "2020-11-26T02:38:15Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotPartitionedException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsWithUnpartitionedTable() throws TableNotExistException, TableNotPartitionedException {\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR)\", tableName);\n+    sql(\"INSERT INTO %s SELECT 1,'a'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();", "originalCommit": "345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0NzMxNQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530747315", "bodyText": "For unpartitioned tables, refresh is really not needed, but for partitioned tables, if we  do not add refresh , data will not be queried.\nWhen I wrote the test case, the result of the test is that if usevalidationCatalog.loadTable(..).refresh()after insert sql in the test case, it is also invalid.\nSo I add flinkCatalog.loadIcebergTable(objectPath).refresh();  to refresh the table.\nIn addition, if I write the following flink program to get the partition, it is no problem. It does not need to be refreshed, which proves that the main program is no problem.\n\tStreamTableEnvironment tenv = StreamTableEnvironment.create(env);\n\t\tString sql = \" CREATE CATALOG iceberg WITH (\\n\" +\n\t\t             \"  'type'='iceberg',\\n\" +\n\t\t             \"   'catalog-type'='hive',\\n\" +\n\t\t             \"   'hive-conf-dir'='/Users/user/work/hive/conf/',\\n\" +\n\t\t             \"    'uri'='thrift://localhost:9083'\\n\" +\n\t\t             \" )\";\n\t\ttenv.executeSql(sql);\n\t\ttenv.useCatalog(\"iceberg\");\n\t\tFlinkCatalog catalog = (FlinkCatalog) tenv.getCatalog(\"iceberg\").get();\n\t\tList<CatalogPartitionSpec> list = catalog.listPartitions(new ObjectPath(\"iceberg_db\", \"iceberg_table\"));", "author": "zhangjun0x01", "createdAt": "2020-11-26T03:03:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTA3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc1Mzc0OA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530753748", "bodyText": "I think that's because the FlinkCatalogFactory have created a cached iceberg catalog (see here).  Even if the table has written few new partitions, the stale table won't catch the changes.", "author": "openinx", "createdAt": "2020-11-26T03:30:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTA3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc1NjMxNQ==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530756315", "bodyText": "Instead of refreshing the iceberg table in this unit test,   I think we need to refresh the loaded iceberg table in loadIcebergTable if the cacheEnabled  is true.   In SparkTable,  I saw we had a switch named refreshEagerly  which have the similar effect.\nbtw,  we may need more unit tests to cover both cache enabled and disabled cases for listPartitions.", "author": "openinx", "createdAt": "2020-11-26T03:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTA3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc5NzU2Nw==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530797567", "bodyText": "I added the cache enabled test case", "author": "zhangjun0x01", "createdAt": "2020-11-26T06:27:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTA3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDc0MTEyOA==", "url": "https://github.com/apache/iceberg/pull/1815#discussion_r530741128", "bodyText": "ditto", "author": "openinx", "createdAt": "2020-11-26T02:38:31Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogTablePartitions.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotPartitionedException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogTablePartitions extends FlinkCatalogTestBase {\n+\n+  private String tableName = \"partition_table\";\n+\n+  public TestFlinkCatalogTablePartitions(String catalogName, String[] baseNamespace) {\n+    super(catalogName, baseNamespace);\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+  }\n+\n+  @After\n+  public void cleanNamespaces() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, tableName);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testListPartitionsWithUnpartitionedTable() throws TableNotExistException, TableNotPartitionedException {\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR)\", tableName);\n+    sql(\"INSERT INTO %s SELECT 1,'a'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();\n+    AssertHelpers.assertThrows(\"Should not list partitions for unpartitioned table.\",\n+        TableNotPartitionedException.class, () -> flinkCatalog.listPartitions(objectPath));\n+  }\n+\n+  @Test\n+  public void testListPartitionsWithPartitionedTable() throws TableNotExistException, TableNotPartitionedException {\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR) PARTITIONED BY (data)\", tableName);\n+    sql(\"INSERT INTO %s SELECT 1,'a'\", tableName);\n+    sql(\"INSERT INTO %s SELECT 2,'b'\", tableName);\n+\n+    ObjectPath objectPath = new ObjectPath(DATABASE, tableName);\n+    FlinkCatalog flinkCatalog = (FlinkCatalog) getTableEnv().getCatalog(catalogName).get();\n+    flinkCatalog.loadIcebergTable(objectPath).refresh();", "originalCommit": "345e4610a8e1d00ccd7bb98e1ee24e8df6ef3fdf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "595bd9470214f4bc4ef9662060898fd34df7f91a", "url": "https://github.com/apache/iceberg/commit/595bd9470214f4bc4ef9662060898fd34df7f91a", "message": "add cacheEnabled for list partitions", "committedDate": "2020-11-26T11:01:08Z", "type": "commit"}, {"oid": "595bd9470214f4bc4ef9662060898fd34df7f91a", "url": "https://github.com/apache/iceberg/commit/595bd9470214f4bc4ef9662060898fd34df7f91a", "message": "add cacheEnabled for list partitions", "committedDate": "2020-11-26T11:01:08Z", "type": "forcePushed"}]}