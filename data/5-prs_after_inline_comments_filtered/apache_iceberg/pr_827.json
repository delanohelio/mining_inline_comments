{"pr_number": 827, "pr_title": "Refactor metadata Table tests to use a common parent", "pr_createdAt": "2020-03-05T02:46:51Z", "pr_url": "https://github.com/apache/iceberg/pull/827", "timeline": [{"oid": "3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "url": "https://github.com/apache/iceberg/commit/3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "message": "Refactored Table tests to use a common parent", "committedDate": "2020-03-05T08:12:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyOTE2Ng==", "url": "https://github.com/apache/iceberg/pull/827#discussion_r388529166", "bodyText": "It isn't necessary to use super here. Could you remove those?", "author": "rdblue", "createdAt": "2020-03-05T19:57:05Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceHadoopTables.java", "diffHunk": "@@ -101,31 +79,7 @@ public void testEntriesTable() throws Exception {\n     System.out.println(tableLocation);\n     Table entriesTable = TABLES.load(tableLocation + \"#entries\");\n \n-    List<SimpleRecord> records = Lists.newArrayList(new SimpleRecord(1, \"1\"));\n-\n-    Dataset<Row> inputDf = spark.createDataFrame(records, SimpleRecord.class);\n-    inputDf.select(\"id\", \"data\").write()\n-        .format(\"iceberg\")\n-        .mode(\"append\")\n-        .save(tableLocation);\n-\n-    table.refresh();\n-\n-    List<Row> actual = spark.read()\n-        .format(\"iceberg\")\n-        .load(tableLocation + \"#entries\")\n-        .collectAsList();\n-\n-    Assert.assertEquals(\"Should only contain one manifest\", 1, table.currentSnapshot().manifests().size());\n-    InputFile manifest = table.io().newInputFile(table.currentSnapshot().manifests().get(0).path());\n-    List<GenericData.Record> expected;\n-    try (CloseableIterable<GenericData.Record> rows = Avro.read(manifest).project(entriesTable.schema()).build()) {\n-      expected = Lists.newArrayList(rows);\n-    }\n-\n-    Assert.assertEquals(\"Entries table should have one row\", 1, expected.size());\n-    Assert.assertEquals(\"Actual results should have one row\", 1, actual.size());\n-    TestHelpers.assertEqualsSafe(entriesTable.schema().asStruct(), expected.get(0), actual.get(0));\n+    super.testEntriesTable(table, entriesTable, tableLocation, tableLocation + \"#entries\");", "originalCommit": "3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyOTQ5Mg==", "url": "https://github.com/apache/iceberg/pull/827#discussion_r388529492", "bodyText": "Can you revert these changes? The indentation was correct.", "author": "rdblue", "createdAt": "2020-03-05T19:57:42Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceHiveTables.java", "diffHunk": "@@ -695,63 +298,13 @@ public synchronized void testHiveAllManifestsTable() throws Exception {\n     TableIdentifier tableIdentifier = TableIdentifier.of(\"db\", \"manifests_test\");\n     try {\n       Table table = catalog.createTable(\n-          tableIdentifier,\n-          SCHEMA,\n-          PartitionSpec.builderFor(SCHEMA).identity(\"id\").build());\n+              tableIdentifier,", "originalCommit": "3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUyOTc4Nw==", "url": "https://github.com/apache/iceberg/pull/827#discussion_r388529787", "bodyText": "Continuing indentation is 4 spaces, not 8. Could you update this?", "author": "rdblue", "createdAt": "2020-03-05T19:58:14Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceHadoopTables.java", "diffHunk": "@@ -185,92 +97,23 @@ public void testFilesTable() throws Exception {\n     Table entriesTable = TABLES.load(tableLocation + \"#entries\");\n     Table filesTable = TABLES.load(tableLocation + \"#files\");\n \n-    Dataset<Row> df1 = spark.createDataFrame(Lists.newArrayList(new SimpleRecord(1, \"a\")), SimpleRecord.class);\n-    Dataset<Row> df2 = spark.createDataFrame(Lists.newArrayList(new SimpleRecord(2, \"b\")), SimpleRecord.class);\n-\n-    df1.select(\"id\", \"data\").write()\n-        .format(\"iceberg\")\n-        .mode(\"append\")\n-        .save(tableLocation);\n-\n-    // add a second file\n-    df2.select(\"id\", \"data\").write()\n-        .format(\"iceberg\")\n-        .mode(\"append\")\n-        .save(tableLocation);\n-\n-    // delete the first file to test that only live files are listed\n-    table.newDelete().deleteFromRowFilter(Expressions.equal(\"id\", 1)).commit();\n-\n-    List<Row> actual = spark.read()\n-        .format(\"iceberg\")\n-        .load(tableLocation + \"#files\")\n-        .collectAsList();\n-\n-    List<GenericData.Record> expected = Lists.newArrayList();\n-    for (ManifestFile manifest : table.currentSnapshot().manifests()) {\n-      InputFile in = table.io().newInputFile(manifest.path());\n-      try (CloseableIterable<GenericData.Record> rows = Avro.read(in).project(entriesTable.schema()).build()) {\n-        for (GenericData.Record record : rows) {\n-          if ((Integer) record.get(\"status\") < 2 /* added or existing */) {\n-            expected.add((GenericData.Record) record.get(\"data_file\"));\n-          }\n-        }\n-      }\n-    }\n-\n-    Assert.assertEquals(\"Files table should have one row\", 1, expected.size());\n-    Assert.assertEquals(\"Actual results should have one row\", 1, actual.size());\n-    TestHelpers.assertEqualsSafe(filesTable.schema().asStruct(), expected.get(0), actual.get(0));\n+    super.testFilesTable(table, entriesTable, filesTable, tableLocation, tableLocation + \"#files\");\n   }\n \n   @Test\n   public void testFilesTableWithSnapshotIdInheritance() throws Exception {\n-    Table table = TABLES.create(SCHEMA, PartitionSpec.builderFor(SCHEMA).identity(\"id\").build(), tableLocation);\n-\n-    table.updateProperties()\n-        .set(TableProperties.SNAPSHOT_ID_INHERITANCE_ENABLED, \"true\")\n-        .commit();\n-\n-    Table entriesTable = TABLES.load(tableLocation + \"#entries\");\n-    Table filesTable = TABLES.load(tableLocation + \"#files\");\n+    try {\n+      Table table = TABLES.create(SCHEMA, PartitionSpec.builderFor(SCHEMA).identity(\"id\").build(), tableLocation);\n \n-    List<SimpleRecord> records = Lists.newArrayList(\n-        new SimpleRecord(1, \"a\"),\n-        new SimpleRecord(2, \"b\")\n-     );\n+      table.updateProperties()\n+              .set(TableProperties.SNAPSHOT_ID_INHERITANCE_ENABLED, \"true\")", "originalCommit": "3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzNDM1Mg==", "url": "https://github.com/apache/iceberg/pull/827#discussion_r388534352", "bodyText": "The problem with passing in the table is that this creates a dependency between the caller and this code: this assumes that the caller has created the table with the correct schema, for example.\nInstead, what about creating abstract methods to create the table, drop the table if it exists, and load the entries table? That way, you could write these test cases as @Test methods that are inherited and the Hive and Hadoop subclasses would just need to implement a few methods.", "author": "rdblue", "createdAt": "2020-03-05T20:07:30Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceTablesBase.java", "diffHunk": "@@ -0,0 +1,586 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import com.google.common.collect.Lists;\n+import java.util.Comparator;\n+import java.util.List;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.spark.SparkTableUtil;\n+import org.apache.iceberg.spark.data.TestHelpers;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.catalyst.TableIdentifier;\n+import org.junit.Assert;\n+\n+public abstract class TestIcebergSourceTablesBase {\n+\n+  protected static SparkSession spark;\n+\n+  public void testEntriesTable(Table table, Table entriesTable,", "originalCommit": "3e4f731cfaaba7c7fa25d50cc3a6310d9a24793f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTA4MDExMA==", "url": "https://github.com/apache/iceberg/pull/827#discussion_r389080110", "bodyText": "Thanks for the feedback @rdblue! Just updated the PR to use the abstract methods you described, hopefully this is closer to what you are looking for.", "author": "golammott", "createdAt": "2020-03-06T18:51:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODUzNDM1Mg=="}], "type": "inlineReview"}, {"oid": "6278eecf8cd10b07b1da93b94631c881d5563b65", "url": "https://github.com/apache/iceberg/commit/6278eecf8cd10b07b1da93b94631c881d5563b65", "message": "Make table tests have common abstract parent", "committedDate": "2020-03-06T18:36:48Z", "type": "commit"}, {"oid": "6278eecf8cd10b07b1da93b94631c881d5563b65", "url": "https://github.com/apache/iceberg/commit/6278eecf8cd10b07b1da93b94631c881d5563b65", "message": "Make table tests have common abstract parent", "committedDate": "2020-03-06T18:36:48Z", "type": "forcePushed"}]}