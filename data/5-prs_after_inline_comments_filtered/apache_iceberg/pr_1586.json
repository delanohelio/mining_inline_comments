{"pr_number": 1586, "pr_title": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "pr_createdAt": "2020-10-12T14:07:27Z", "pr_url": "https://github.com/apache/iceberg/pull/1586", "timeline": [{"oid": "8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "url": "https://github.com/apache/iceberg/commit/8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "message": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "committedDate": "2020-10-13T13:38:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzk2NTQwOQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r503965409", "bodyText": "The user can choose to set warehouse property or load hive-site.xml when creating the iceberg catalog.  If use the former,  the warehouse path may be different with the hive metastore, that means it will create files under the user specified directory.\nIf use the hive-site.xml,  then it should be the same configuration as the metastore.", "author": "openinx", "createdAt": "2020-10-13T13:46:44Z", "path": "flink/src/main/java/org/apache/iceberg/flink/CatalogLoader.java", "diffHunk": "@@ -38,8 +40,13 @@ static CatalogLoader hadoop(String name, Configuration hadoopConf, String wareho\n     return new HadoopCatalogLoader(name, hadoopConf, warehouseLocation);\n   }\n \n-  static CatalogLoader hive(String name, Configuration hadoopConf, String uri, int clientPoolSize) {\n-    return new HiveCatalogLoader(name, hadoopConf, uri, clientPoolSize);\n+  static CatalogLoader hive(String name, Configuration hadoopConf, String uri, String warehouse, int clientPoolSize) {", "originalCommit": "8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ1MDI4Ng==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r504450286", "bodyText": "Moving those tow method inside this super class, because the newly introduced unit test TestFlinkHiveCatalog  would use them.", "author": "openinx", "createdAt": "2020-10-14T07:11:23Z", "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -53,4 +64,36 @@ public static void stopMetastore() {\n     flinkCatalogs.values().forEach(Catalog::close);\n     flinkCatalogs.clear();\n   }\n+\n+  protected TableEnvironment getTableEnv() {", "originalCommit": "eb7fe6f4b1dcf891952181d985d4fabdd5df71b3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "12f0a5b0b5488f17e94e3217dd9b8410ca1cbff0", "url": "https://github.com/apache/iceberg/commit/12f0a5b0b5488f17e94e3217dd9b8410ca1cbff0", "message": "Rebase to master", "committedDate": "2020-10-15T10:22:43Z", "type": "forcePushed"}, {"oid": "423eecbdac3840c14a8a9114c4f61996f7f0865a", "url": "https://github.com/apache/iceberg/commit/423eecbdac3840c14a8a9114c4f61996f7f0865a", "message": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2aba22991fc8f4c3e0f8112ef27ed8fb6e8df813", "url": "https://github.com/apache/iceberg/commit/2aba22991fc8f4c3e0f8112ef27ed8fb6e8df813", "message": "Loading hive config from classpath if neccessary.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "dd9d1c84ea4b26d04ca039013984bbe59dd2a17f", "url": "https://github.com/apache/iceberg/commit/dd9d1c84ea4b26d04ca039013984bbe59dd2a17f", "message": "Fix the broken unit tests.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2602e4882c9a830db75bf4397b940dae3e6d9c02", "url": "https://github.com/apache/iceberg/commit/2602e4882c9a830db75bf4397b940dae3e6d9c02", "message": "Revert \"Fix the broken unit tests.\"\n\nThis reverts commit ef87f5378f8e4e3982f25ae5a74e83eb4b3938de.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "6dec7b10ef8187ba404aaa4b1328775c7bd8c12c", "url": "https://github.com/apache/iceberg/commit/6dec7b10ef8187ba404aaa4b1328775c7bd8c12c", "message": "Fix the broken unit tests", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "342c3eca8f4cfd1230b0e1f23d36edc97569dceb", "url": "https://github.com/apache/iceberg/commit/342c3eca8f4cfd1230b0e1f23d36edc97569dceb", "message": "Checkstyle issues", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2166bdfde3920afec8002d25351ac3056e57ff85", "url": "https://github.com/apache/iceberg/commit/2166bdfde3920afec8002d25351ac3056e57ff85", "message": "Add document", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "7c3c59410620295e3b99edfc66c8c81ae19cb185", "url": "https://github.com/apache/iceberg/commit/7c3c59410620295e3b99edfc66c8c81ae19cb185", "message": "Rebase to master", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "12b742cc44a8c63c4b3451d61c6f5b2508288014", "url": "https://github.com/apache/iceberg/commit/12b742cc44a8c63c4b3451d61c6f5b2508288014", "message": "Fix the broken unit tests", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "51b6abb4bc7ff664bd0f9725ffc0808a363bc402", "url": "https://github.com/apache/iceberg/commit/51b6abb4bc7ff664bd0f9725ffc0808a363bc402", "message": "Checkstyle issues", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "de034032848848aaafdab978c251d7a7024a7b11", "url": "https://github.com/apache/iceberg/commit/de034032848848aaafdab978c251d7a7024a7b11", "message": "Set the thrift pool size.", "committedDate": "2020-10-19T10:12:56Z", "type": "commit"}, {"oid": "de034032848848aaafdab978c251d7a7024a7b11", "url": "https://github.com/apache/iceberg/commit/de034032848848aaafdab978c251d7a7024a7b11", "message": "Set the thrift pool size.", "committedDate": "2020-10-19T10:12:56Z", "type": "forcePushed"}, {"oid": "c15399ff0553f4ce374550e6c7e08195870eb667", "url": "https://github.com/apache/iceberg/commit/c15399ff0553f4ce374550e6c7e08195870eb667", "message": "Update site/docs/flink.md\n\nCo-authored-by: Adrian Woodhead <massdosage@gmail.com>", "committedDate": "2020-10-21T02:13:36Z", "type": "commit"}, {"oid": "c23e16fd3f6548d358fb4e8c378f7cd96b2c8886", "url": "https://github.com/apache/iceberg/commit/c23e16fd3f6548d358fb4e8c378f7cd96b2c8886", "message": "Addressing the comments.", "committedDate": "2020-10-21T02:31:42Z", "type": "commit"}, {"oid": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "url": "https://github.com/apache/iceberg/commit/38b83b2654a87a61bb5fccb14eca0667d08bdf83", "message": "Precheck for the existence of hive-conf-dir", "committedDate": "2020-10-21T02:42:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzQ2MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509453461", "bodyText": "Why did this change? Needing to increase the number of threads used by the Hive MetaStore is a red flag that this may be leaking Hive connections. In cases where all of the connections are handled by a ClientPool, we should not need to increase the number of handler threads. This helps us avoid leaks because we catch them in testing rather than at runtime.", "author": "rdblue", "createdAt": "2020-10-21T17:03:17Z", "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -34,23 +40,53 @@\n   private static TestHiveMetastore metastore = null;\n   protected static HiveConf hiveConf = null;\n   protected static HiveCatalog catalog = null;\n-  protected static ConcurrentMap<String, Catalog> flinkCatalogs;\n+\n+  private volatile TableEnvironment tEnv = null;\n \n   @BeforeClass\n   public static void startMetastore() {\n     FlinkTestBase.metastore = new TestHiveMetastore();\n-    metastore.start();\n+    metastore.start(15);", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1NDI2Nw==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509854267", "bodyText": "I thought the hive handlers were not enough in the TestFlinkCatalogDatabase  test suite, but today I checked the logs carefully, it's indeed a connection leak issue.   The catalog connection would be closed only when unregistering the catalog, means executing the sql DROP CATALOG test_catalog.  I found we did not release the connection after a test case finished.   No need to increase the handler number here, just need to provide Before/After to create/release connection, pls see f2740c6.", "author": "openinx", "createdAt": "2020-10-22T03:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzQ2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Njc4MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509456781", "bodyText": "Style nit: we typically add an empty line after control flow statements. This removes one and doesn't add one after the new if.", "author": "rdblue", "createdAt": "2020-10-21T17:08:37Z", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java", "diffHunk": "@@ -72,13 +72,19 @@ public HiveCatalog(Configuration conf) {\n   }\n \n   public HiveCatalog(String name, String uri, int clientPoolSize, Configuration conf) {\n+    this(name, uri, null, clientPoolSize, conf);\n+  }\n+\n+  public HiveCatalog(String name, String uri, String warehouse, int clientPoolSize, Configuration conf) {\n     this.name = name;\n     this.conf = new Configuration(conf);\n     // before building the client pool, overwrite the configuration's URIs if the argument is non-null\n     if (uri != null) {\n       this.conf.set(HiveConf.ConfVars.METASTOREURIS.varname, uri);\n     }\n-\n+    if (warehouse != null) {\n+      this.conf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, warehouse);\n+    }", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509457751", "bodyText": "Why not keep this location as a field in the HiveCatalog instead of storing it in conf? Then the default logic would only need to be run once.", "author": "rdblue", "createdAt": "2020-10-21T17:10:07Z", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java", "diffHunk": "@@ -72,13 +72,19 @@ public HiveCatalog(Configuration conf) {\n   }\n \n   public HiveCatalog(String name, String uri, int clientPoolSize, Configuration conf) {\n+    this(name, uri, null, clientPoolSize, conf);\n+  }\n+\n+  public HiveCatalog(String name, String uri, String warehouse, int clientPoolSize, Configuration conf) {\n     this.name = name;\n     this.conf = new Configuration(conf);\n     // before building the client pool, overwrite the configuration's URIs if the argument is non-null\n     if (uri != null) {\n       this.conf.set(HiveConf.ConfVars.METASTOREURIS.varname, uri);\n     }\n-\n+    if (warehouse != null) {\n+      this.conf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, warehouse);", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MzY1Mg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509843652", "bodyText": "As we discussed in this comment,   we could set warehouse string or hive-conf-dir to get the hive warehouse.   If use a local field,  then in getWarehouseLocation,  we would check the local field first and then read the hiveConf ?  I want to unify the parse path so I  put this key-value into hiveConf (It's a deep-cloned conf, so should not affect the origin conf).", "author": "openinx", "createdAt": "2020-10-22T02:33:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDQyNw==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509850427", "bodyText": "Yes, It can be handled in the same way as URIs.", "author": "JingsongLi", "createdAt": "2020-10-22T02:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE2MjEzMg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r511162132", "bodyText": "I think handling this the same way that we handle the URI makes sense. We set the URI because we need to pass it back into Hive to connect, which I don't think applies to the warehouse path, but handling both the same way is reasonable.", "author": "rdblue", "createdAt": "2020-10-23T21:25:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}], "type": "inlineReview"}, {"oid": "7fdda77ee9942d3a26239498741a12b078c004df", "url": "https://github.com/apache/iceberg/commit/7fdda77ee9942d3a26239498741a12b078c004df", "message": "Addressing the comment from Ryan", "committedDate": "2020-10-22T02:40:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDg0OA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509850848", "bodyText": "Maybe I missed something. Why not load hive-conf into hadoopConf here?", "author": "JingsongLi", "createdAt": "2020-10-22T03:00:28Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalogFactory.java", "diffHunk": "@@ -71,12 +72,16 @@ protected CatalogLoader createCatalogLoader(String name, Map<String, String> pro\n     String catalogType = properties.getOrDefault(ICEBERG_CATALOG_TYPE, \"hive\");\n     switch (catalogType) {\n       case \"hive\":\n-        int clientPoolSize = Integer.parseInt(properties.getOrDefault(HIVE_CLIENT_POOL_SIZE, \"2\"));\n+        // The values of properties 'uri', 'warehouse', 'hive-conf-dir' are allowed to be null, in that case it will\n+        // fallback to parse those values from hadoop configuration which is loaded from classpath.\n         String uri = properties.get(HIVE_URI);\n-        return CatalogLoader.hive(name, hadoopConf, uri, clientPoolSize);\n+        String warehouse = properties.get(WAREHOUSE_LOCATION);\n+        int clientPoolSize = Integer.parseInt(properties.getOrDefault(HIVE_CLIENT_POOL_SIZE, \"2\"));\n+        String hiveConfDir = properties.get(HIVE_CONF_DIR);\n+        return CatalogLoader.hive(name, hadoopConf, uri, warehouse, clientPoolSize, hiveConfDir);", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2MzM3MA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509863370", "bodyText": "Oh, I almost forgot that the loadCatalog would be executed at task manager side for flink.   we should merge hive conf into hadoop conf before initializing the catalog loader, so that we won't miss to load a non-existed path in task manager node.", "author": "openinx", "createdAt": "2020-10-22T03:50:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDg0OA=="}], "type": "inlineReview"}, {"oid": "f2740c6cf4f7aa5e090a4b3df60e853aaa140e38", "url": "https://github.com/apache/iceberg/commit/f2740c6cf4f7aa5e090a4b3df60e853aaa140e38", "message": "Fix the hive connection leak issues", "committedDate": "2020-10-22T03:04:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MzQ5NA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509853494", "bodyText": "NIT: use hiveConf.get(HiveConf.ConfVars.METASTOREWAREHOUSE.varname) instead of null.", "author": "JingsongLi", "createdAt": "2020-10-22T03:10:25Z", "path": "flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkInputFormatReaderDeletes.java", "diffHunk": "@@ -107,7 +107,7 @@ protected StructLikeSet rowSet(String name, Table testTable, String... columns)\n     RowType rowType = FlinkSchemaUtil.convert(projected);\n     CatalogLoader hiveCatalogLoader = CatalogLoader.hive(catalog.name(),\n         hiveConf,\n-        hiveConf.get(HiveConf.ConfVars.METASTOREURIS.varname),\n+        hiveConf.get(HiveConf.ConfVars.METASTOREURIS.varname), null,", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "247f5d769b6dde6f26f2a361ce8507e87b91934e", "url": "https://github.com/apache/iceberg/commit/247f5d769b6dde6f26f2a361ce8507e87b91934e", "message": "Loading hive-site configuration when initialize the Iceberg catalog loader.", "committedDate": "2020-10-22T03:46:33Z", "type": "commit"}, {"oid": "4ad9aafa55f80dd74abd3d65c2adf4ca42b6b242", "url": "https://github.com/apache/iceberg/commit/4ad9aafa55f80dd74abd3d65c2adf4ca42b6b242", "message": "Make the document more clear", "committedDate": "2020-10-22T04:08:39Z", "type": "commit"}]}