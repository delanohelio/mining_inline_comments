{"pr_number": 778, "pr_title": "ORC: Implement TestGenericData and fix reader and writer issues", "pr_createdAt": "2020-02-05T08:59:00Z", "pr_url": "https://github.com/apache/iceberg/pull/778", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxODUyNA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378018524", "bodyText": "nit: might as well remove empty message, or update with proper javadoc if required", "author": "rdsr", "createdAt": "2020-02-12T03:04:43Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriter.java", "diffHunk": "@@ -40,10 +50,13 @@\n import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n \n+\n /**", "originalCommit": "0e47ae5777e61b2986592ebd334134d77f125c48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUwMjAyOA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378502028", "bodyText": "Removed empty message", "author": "shardulm94", "createdAt": "2020-02-12T20:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAxODUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTEyMQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378035121", "bodyText": "Seems like vector.nanos[row] is not absolute time in nanos and is like java.sql.Time.getNanos. In that case we don't need to take the % ?", "author": "rdsr", "createdAt": "2020-02-12T04:26:08Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -172,14 +208,13 @@ public Double convert(ColumnVector vector, int row) {\n     }\n   }\n \n-  private static class TimestampConverter implements Converter<Long> {\n-    private Long convert(TimestampColumnVector vector, int row) {\n-      // compute microseconds past 1970.\n-      return (vector.time[row] / 1000) * 1_000_000 + vector.nanos[row] / 1000;\n+  private static class TimestampTzConverter implements Converter<OffsetDateTime> {\n+    private OffsetDateTime convert(TimestampColumnVector vector, int row) {\n+      return EPOCH.plus(vector.time[row], ChronoUnit.MILLIS).plus(vector.nanos[row] % 1_000_000, ChronoUnit.NANOS);", "originalCommit": "0e47ae5777e61b2986592ebd334134d77f125c48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ3NTg4Ng==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378475886", "bodyText": "From https://issues.apache.org/jira/browse/ORC-546,\n\nHive's TimestampColumnVector has a bad design with millis from 1970 and nanos within the second. This is consistent with java.sql.Timestamp, but it causes the millis to overlap with the nanos\n\nBasically, the millis component of timestamp is double counted in both vector.time and also vector.nanos. Here we remove it from vector.nanos and only use it from vector.time", "author": "shardulm94", "createdAt": "2020-02-12T19:49:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTEyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUwMTY1Mw==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378501653", "bodyText": "I also made a small change to not use millis from vector.time and rather use millis from vector.nanos. This is consistent with other places where we are handling ORC timestamps.", "author": "shardulm94", "createdAt": "2020-02-12T20:43:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTEyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTgzNg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378035836", "bodyText": "Maybe take out this comment?", "author": "rdsr", "createdAt": "2020-02-12T04:30:10Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -284,9 +370,9 @@ public BigDecimal convert(ColumnVector vector, int row) {\n       final int length = (int) vector.lengths[row];\n \n       // serialize the keys", "originalCommit": "0e47ae5777e61b2986592ebd334134d77f125c48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUwMTY5MA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378501690", "bodyText": "Done", "author": "shardulm94", "createdAt": "2020-02-12T20:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzNTgzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzOTg0MQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378039841", "bodyText": "nit: maybe log the long type?", "author": "rdsr", "createdAt": "2020-02-12T04:52:11Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriter.java", "diffHunk": "@@ -429,26 +537,51 @@ private static Converter buildConverter(TypeDescription schema) {\n       case SHORT:\n         return new ShortConverter();\n       case DATE:\n+        return new DateConverter();\n       case INT:\n         return new IntConverter();\n       case LONG:\n-        return new LongConverter();\n+        ORCSchemaUtil.LongType longType = ORCSchemaUtil.LongType.valueOf(\n+            schema.getAttributeValue(ORCSchemaUtil.ICEBERG_LONG_TYPE_ATTRIBUTE));\n+        switch (longType) {\n+          case TIME:\n+            return new TimeConverter();\n+          case LONG:\n+            return new LongConverter();\n+          default:\n+            throw new IllegalStateException(\"Invalid Long type found in ORC type attribute\");", "originalCommit": "0e47ae5777e61b2986592ebd334134d77f125c48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUwMTgyNA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378501824", "bodyText": "Done", "author": "shardulm94", "createdAt": "2020-02-12T20:44:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzOTg0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODAzOTg4OA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378039888", "bodyText": "log the invalid binary type?", "author": "rdsr", "createdAt": "2020-02-12T04:52:25Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriter.java", "diffHunk": "@@ -429,26 +537,51 @@ private static Converter buildConverter(TypeDescription schema) {\n       case SHORT:\n         return new ShortConverter();\n       case DATE:\n+        return new DateConverter();\n       case INT:\n         return new IntConverter();\n       case LONG:\n-        return new LongConverter();\n+        ORCSchemaUtil.LongType longType = ORCSchemaUtil.LongType.valueOf(\n+            schema.getAttributeValue(ORCSchemaUtil.ICEBERG_LONG_TYPE_ATTRIBUTE));\n+        switch (longType) {\n+          case TIME:\n+            return new TimeConverter();\n+          case LONG:\n+            return new LongConverter();\n+          default:\n+            throw new IllegalStateException(\"Invalid Long type found in ORC type attribute\");\n+        }\n       case FLOAT:\n         return new FloatConverter();\n       case DOUBLE:\n         return new DoubleConverter();\n       case BINARY:\n-        return new BytesConverter();\n+        ORCSchemaUtil.BinaryType binaryType = ORCSchemaUtil.BinaryType.valueOf(\n+            schema.getAttributeValue(ORCSchemaUtil.ICEBERG_BINARY_TYPE_ATTRIBUTE));\n+        switch (binaryType) {\n+          case UUID:\n+            return new UUIDConverter();\n+          case FIXED:\n+            return new FixedConverter();\n+          case BINARY:\n+            return new BytesConverter();\n+          default:\n+            throw new IllegalStateException(\"Invalid Binary type found in ORC type attribute\");", "originalCommit": "0e47ae5777e61b2986592ebd334134d77f125c48", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk1ODQ2OQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378958469", "bodyText": "What's Type.TypeID.TIMESTAMP now mapping to?", "author": "edgarRd", "createdAt": "2020-02-13T16:06:35Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -70,20 +70,19 @@ public TypeDescription type() {\n   private static final String ICEBERG_ID_ATTRIBUTE = \"iceberg.id\";\n   private static final String ICEBERG_REQUIRED_ATTRIBUTE = \"iceberg.required\";\n \n-  private static final String ICEBERG_BINARY_TYPE_ATTRIBUTE = \"iceberg.binary-type\";\n-  private static final String ICEBERG_INTEGER_TYPE_ATTRIBUTE = \"iceberg.integer-type\";\n-  private static final String ICEBERG_FIELD_LENGTH = \"iceberg.length\";\n+  public static final String ICEBERG_BINARY_TYPE_ATTRIBUTE = \"iceberg.binary-type\";\n+  public static final String ICEBERG_LONG_TYPE_ATTRIBUTE = \"iceberg.long-type\";\n+  public static final String ICEBERG_FIELD_LENGTH = \"iceberg.length\";\n \n   private static final ImmutableMap<Type.TypeID, TypeDescription.Category> TYPE_MAPPING =\n       ImmutableMap.<Type.TypeID, TypeDescription.Category>builder()\n           .put(Type.TypeID.BOOLEAN, TypeDescription.Category.BOOLEAN)\n           .put(Type.TypeID.INTEGER, TypeDescription.Category.INT)\n-          .put(Type.TypeID.TIME, TypeDescription.Category.INT)\n           .put(Type.TypeID.LONG, TypeDescription.Category.LONG)\n+          .put(Type.TypeID.TIME, TypeDescription.Category.LONG)\n           .put(Type.TypeID.FLOAT, TypeDescription.Category.FLOAT)\n           .put(Type.TypeID.DOUBLE, TypeDescription.Category.DOUBLE)\n           .put(Type.TypeID.DATE, TypeDescription.Category.DATE)\n-          .put(Type.TypeID.TIMESTAMP, TypeDescription.Category.TIMESTAMP)", "originalCommit": "fdc1df63f63b15564659f498d0e57268c10d5830", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU5OTg1Mg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r383599852", "bodyText": "Type.TypeID.TIMESTAMP now can map to either TypeDescription.Category.TIMESTAMP or TypeDescription.Category.TIMESTAMP_INSTANT depending on with/without zone. The code for the same is present in isSameType where this map is being used.", "author": "shardulm94", "createdAt": "2020-02-25T00:47:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk1ODQ2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk2NDY0OA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378964648", "bodyText": "Should we create an issue to track this?", "author": "edgarRd", "createdAt": "2020-02-13T16:16:15Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriter.java", "diffHunk": "@@ -429,26 +534,51 @@ private static Converter buildConverter(TypeDescription schema) {\n       case SHORT:\n         return new ShortConverter();\n       case DATE:\n+        return new DateConverter();\n       case INT:\n         return new IntConverter();\n       case LONG:\n-        return new LongConverter();\n+        ORCSchemaUtil.LongType longType = ORCSchemaUtil.LongType.valueOf(\n+            schema.getAttributeValue(ORCSchemaUtil.ICEBERG_LONG_TYPE_ATTRIBUTE));\n+        switch (longType) {\n+          case TIME:\n+            return new TimeConverter();\n+          case LONG:\n+            return new LongConverter();\n+          default:\n+            throw new IllegalStateException(\"Unhandled Long type found in ORC type attribute: \" + longType);\n+        }\n       case FLOAT:\n         return new FloatConverter();\n       case DOUBLE:\n         return new DoubleConverter();\n       case BINARY:\n-        return new BytesConverter();\n+        ORCSchemaUtil.BinaryType binaryType = ORCSchemaUtil.BinaryType.valueOf(\n+            schema.getAttributeValue(ORCSchemaUtil.ICEBERG_BINARY_TYPE_ATTRIBUTE));\n+        switch (binaryType) {\n+          case UUID:\n+            return new UUIDConverter();\n+          case FIXED:\n+            return new FixedConverter();\n+          case BINARY:\n+            return new BytesConverter();\n+          default:\n+            throw new IllegalStateException(\"Unhandled Binary type found in ORC type attribute: \" + binaryType);\n+        }\n       case STRING:\n       case CHAR:\n       case VARCHAR:\n         return new StringConverter();\n       case DECIMAL:\n-        return schema.getPrecision() <= 18 ?\n-            new Decimal18Converter(schema) :\n-            new Decimal38Converter(schema);\n+        // TODO: Figure out the right cases in which to use the fastpath Decimal18Converter", "originalCommit": "fdc1df63f63b15564659f498d0e57268c10d5830", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzI5OQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r384737299", "bodyText": "I just ended up fixing the issue in the latest commit. So should no longer be required.", "author": "shardulm94", "createdAt": "2020-02-26T20:09:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk2NDY0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk2NTg5OA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r378965898", "bodyText": "Can we add a brief description javadoc on the now public constants?", "author": "edgarRd", "createdAt": "2020-02-13T16:18:13Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -70,20 +70,19 @@ public TypeDescription type() {\n   private static final String ICEBERG_ID_ATTRIBUTE = \"iceberg.id\";\n   private static final String ICEBERG_REQUIRED_ATTRIBUTE = \"iceberg.required\";\n \n-  private static final String ICEBERG_BINARY_TYPE_ATTRIBUTE = \"iceberg.binary-type\";\n-  private static final String ICEBERG_INTEGER_TYPE_ATTRIBUTE = \"iceberg.integer-type\";\n-  private static final String ICEBERG_FIELD_LENGTH = \"iceberg.length\";\n+  public static final String ICEBERG_BINARY_TYPE_ATTRIBUTE = \"iceberg.binary-type\";", "originalCommit": "fdc1df63f63b15564659f498d0e57268c10d5830", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzYxODUzNw==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r383618537", "bodyText": "Done", "author": "shardulm94", "createdAt": "2020-02-25T01:56:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODk2NTg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxMzU3NQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r389313575", "bodyText": "should this test go in the super class DataTest?", "author": "rdsr", "createdAt": "2020-03-07T21:30:29Z", "path": "data/src/test/java/org/apache/iceberg/data/orc/TestGenericData.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.io.IOException;\n+import java.time.LocalDateTime;\n+import java.time.OffsetDateTime;\n+import java.util.List;\n+import java.util.TimeZone;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.DataTest;\n+import org.apache.iceberg.data.DataTestHelpers;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.RandomGenericData;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.orc.ORC;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestGenericData extends DataTest {\n+\n+  @Override\n+  protected void writeAndValidate(Schema schema) throws IOException {\n+    List<Record> expected = RandomGenericData.generate(schema, 100, 0L);\n+\n+    File testFile = temp.newFile();\n+    Assert.assertTrue(\"Delete should succeed\", testFile.delete());\n+\n+    try (FileAppender<Record> writer = ORC.write(Files.localOutput(testFile))\n+        .schema(schema)\n+        .createWriterFunc(GenericOrcWriter::buildWriter)\n+        .build()) {\n+      for (Record rec : expected) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    List<Record> rows;\n+    try (CloseableIterable<Record> reader = ORC.read(Files.localInput(testFile))\n+        .schema(schema)\n+        .createReaderFunc(fileSchema -> GenericOrcReader.buildReader(schema, fileSchema))\n+        .build()) {\n+      rows = Lists.newArrayList(reader);\n+    }\n+\n+    for (int i = 0; i < expected.size(); i += 1) {\n+      DataTestHelpers.assertEquals(schema.asStruct(), expected.get(i), rows.get(i));\n+    }\n+  }\n+\n+  @Test\n+  public void writeAndValidateTimestamps() throws IOException {", "originalCommit": "67c9ee1d2fc92d51dc207d5e3e41f0ed163288f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NzIzMg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r394077232", "bodyText": "Today the Parquet implementation does not support Timestamp without Timezone. So this would fail if added to the super class. Can we address this in a separate issue?", "author": "shardulm94", "createdAt": "2020-03-18T02:44:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxMzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2Mjc0NA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162744", "bodyText": "Yeah, we need to update Parquet now that the new logical types API is out. (FYI @Fokko)", "author": "rdblue", "createdAt": "2020-03-22T23:55:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxMzU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI4NDQzMQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r401284431", "bodyText": "Make sense!", "author": "rdsr", "createdAt": "2020-04-01T00:07:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTMxMzU3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzNTc5NQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r392535795", "bodyText": "Any use of ByteBuffer.array() without arrayOffset(), position(), and limit() is concerning. Here, there is a strong dependence between this code and the behavior of the wrapped converter: it must almost always allocate a new ByteBuffer to return.", "author": "rdblue", "createdAt": "2020-03-14T00:20:00Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -189,30 +224,85 @@ public Long convert(ColumnVector vector, int row) {\n     }\n   }\n \n-  private static class BinaryConverter implements Converter<byte[]> {\n+  private static class TimestampConverter implements Converter<LocalDateTime> {\n+    private final ZoneOffset localZoneOffset;\n+\n+    TimestampConverter() {\n+      this.localZoneOffset = OffsetDateTime.now().getOffset();\n+    }\n+\n+    private LocalDateTime convert(TimestampColumnVector vector, int row) {\n+      return LocalDateTime.ofEpochSecond(vector.time[row] / 1_000, vector.nanos[row], localZoneOffset);\n+    }\n+\n+    @Override\n+    public LocalDateTime convert(ColumnVector vector, int row) {\n+      int rowIndex = vector.isRepeating ? 0 : row;\n+      if (!vector.noNulls && vector.isNull[rowIndex]) {\n+        return null;\n+      } else {\n+        return convert((TimestampColumnVector) vector, rowIndex);\n+      }\n+    }\n+  }\n+\n+  private static class FixedConverter implements Converter<byte[]> {\n     @Override\n     public byte[] convert(ColumnVector vector, int row) {\n       int rowIndex = vector.isRepeating ? 0 : row;\n       if (!vector.noNulls && vector.isNull[rowIndex]) {\n         return null;\n       } else {\n         BytesColumnVector bytesVector = (BytesColumnVector) vector;\n-        return Arrays.copyOfRange(bytesVector.vector[rowIndex],\n-            bytesVector.start[rowIndex],\n+        return Arrays.copyOfRange(bytesVector.vector[rowIndex], bytesVector.start[rowIndex],\n             bytesVector.start[rowIndex] + bytesVector.length[rowIndex]);\n       }\n     }\n   }\n \n+  private static class BinaryConverter implements Converter<ByteBuffer> {\n+    @Override\n+    public ByteBuffer convert(ColumnVector vector, int row) {\n+      int rowIndex = vector.isRepeating ? 0 : row;\n+      if (!vector.noNulls && vector.isNull[rowIndex]) {\n+        return null;\n+      } else {\n+        BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+        ByteBuffer buf = ByteBuffer.allocate(bytesVector.length[rowIndex]);\n+        buf.put(bytesVector.vector[rowIndex], bytesVector.start[rowIndex], bytesVector.length[rowIndex]);\n+        buf.rewind();\n+        return buf;\n+      }\n+    }\n+  }\n+\n+  private static class UUIDConverter implements Converter<UUID> {\n+    @Override\n+    public UUID convert(ColumnVector vector, int row) {\n+      int rowIndex = vector.isRepeating ? 0 : row;\n+      if (!vector.noNulls && vector.isNull[rowIndex]) {\n+        return null;\n+      } else {\n+        BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+        ByteBuffer buf = ByteBuffer.allocate(16);\n+        buf.put(bytesVector.vector[rowIndex], bytesVector.start[rowIndex], 16);\n+        buf.rewind();\n+        long mostSigBits = buf.getLong();\n+        long leastSigBits = buf.getLong();\n+        return new UUID(mostSigBits, leastSigBits);\n+      }\n+    }\n+  }\n+\n   private static class StringConverter implements Converter<String> {\n     @Override\n     public String convert(ColumnVector vector, int row) {\n       BinaryConverter converter = new BinaryConverter();\n-      byte[] byteData = converter.convert(vector, row);\n-      if (byteData == null) {\n+      ByteBuffer byteBuffer = converter.convert(vector, row);\n+      if (byteBuffer == null) {\n         return null;\n       }\n-      return new String(byteData, StandardCharsets.UTF_8);\n+      return new String(byteBuffer.array(), StandardCharsets.UTF_8);", "originalCommit": "67c9ee1d2fc92d51dc207d5e3e41f0ed163288f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NzEwOQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r394077109", "bodyText": "I replaced this by not using ByteBuffers and directly creating a String from the vectors returned by ORC.", "author": "shardulm94", "createdAt": "2020-03-18T02:44:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzNTc5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MTczNQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r393381735", "bodyText": "Doesn't this report milliseconds twice?\nOffsetDateTime now = OffsetDateTime.now(); // 2020-03-17T00:21:46.844Z\nlong micros = ChronoUnit.MICROS.between(EPOCH, now); // 1584404506844000\nlong millis = micros / 1_000; // 1584404506844 <--- note 844 is millis\nlong nanos = (micros % 1_000_000) * 1_000; // 844000000 <--- millis are included\n\nDoes the millis/nanos format discard digits above 1,000,000 by convention? (ping @omalley)", "author": "rdblue", "createdAt": "2020-03-17T00:27:05Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriter.java", "diffHunk": "@@ -229,27 +293,68 @@ public void addValue(int rowId, byte[] data, ColumnVector output) {\n         output.isNull[rowId] = true;\n       } else {\n         output.isNull[rowId] = false;\n-        // getBinary always makes a copy, so we don't need to worry about it\n-        // being changed behind our back.\n         ((BytesColumnVector) output).setRef(rowId, data, 0, data.length);\n       }\n     }\n   }\n \n-  static class TimestampConverter implements Converter<Long> {\n+  static class DateConverter implements Converter<LocalDate> {\n     @Override\n-    public Class<Long> getJavaClass() {\n-      return Long.class;\n+    public Class<LocalDate> getJavaClass() {\n+      return LocalDate.class;\n     }\n \n-    public void addValue(int rowId, Long data, ColumnVector output) {\n+    public void addValue(int rowId, LocalDate data, ColumnVector output) {\n+      if (data == null) {\n+        output.noNulls = false;\n+        output.isNull[rowId] = true;\n+      } else {\n+        output.isNull[rowId] = false;\n+        ((LongColumnVector) output).vector[rowId] = ChronoUnit.DAYS.between(EPOCH_DAY, data);\n+      }\n+    }\n+  }\n+\n+  static class TimestampTzConverter implements Converter<OffsetDateTime> {\n+    @Override\n+    public Class<OffsetDateTime> getJavaClass() {\n+      return OffsetDateTime.class;\n+    }\n+\n+    public void addValue(int rowId, OffsetDateTime data, ColumnVector output) {\n+      if (data == null) {\n+        output.noNulls = false;\n+        output.isNull[rowId] = true;\n+      } else {\n+        output.isNull[rowId] = false;\n+        TimestampColumnVector cv = (TimestampColumnVector) output;\n+        long micros = ChronoUnit.MICROS.between(EPOCH, data);\n+        cv.time[rowId] = micros / 1_000; // millis\n+        cv.nanos[rowId] = (int) (micros % 1_000_000) * 1_000; // nanos", "originalCommit": "67c9ee1d2fc92d51dc207d5e3e41f0ed163288f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDA3NTA4Mw==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r394075083", "bodyText": "Yes we report the millis twice. ORC code only keeps seconds from cv.time and so handles this transparently. Since ORC expects the double reporting, I think it should be fine if we keep double reporting. @omalley Thoughts?\nNote that the ORC reader double reports millis even if the writer does not double report millis.  Details in https://issues.apache.org/jira/browse/ORC-546", "author": "shardulm94", "createdAt": "2020-03-18T02:35:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MTczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjM3Mg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162372", "bodyText": "Let's make sure this behavior is clear in the spec.", "author": "rdblue", "createdAt": "2020-03-22T23:51:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MTczNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0Nzg0NQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400847845", "bodyText": "Added this behaviour as a note for the timestamp types in the ORC type mapping in the spec", "author": "shardulm94", "createdAt": "2020-03-31T11:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MTczNQ=="}], "type": "inlineReview"}, {"oid": "59f13547766c134721be3ace46507750a9856f8a", "url": "https://github.com/apache/iceberg/commit/59f13547766c134721be3ace46507750a9856f8a", "message": "Address PR comments", "committedDate": "2020-03-18T02:33:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MTkzMw==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396161933", "bodyText": "This should not copy. Instead, it should point a ByteBuffer at the underlying bytes in the vector using ByteBuffer.wrap(array, offset, length).", "author": "rdblue", "createdAt": "2020-03-22T23:47:21Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -189,30 +226,89 @@ public Long convert(ColumnVector vector, int row) {\n     }\n   }\n \n-  private static class BinaryConverter implements Converter<byte[]> {\n+  private static class TimestampConverter implements Converter<LocalDateTime> {\n+    private final ZoneId localZoneId;\n+\n+    TimestampConverter() {\n+      this.localZoneId = ZoneId.systemDefault();\n+    }\n+\n+    private LocalDateTime convert(TimestampColumnVector vector, int row) {\n+      return ZonedDateTime\n+          .ofInstant(Instant.ofEpochSecond(vector.time[row] / 1_000, vector.nanos[row]), localZoneId)\n+          .toLocalDateTime();\n+    }\n+\n+    @Override\n+    public LocalDateTime convert(ColumnVector vector, int row) {\n+      int rowIndex = vector.isRepeating ? 0 : row;\n+      if (!vector.noNulls && vector.isNull[rowIndex]) {\n+        return null;\n+      } else {\n+        return convert((TimestampColumnVector) vector, rowIndex);\n+      }\n+    }\n+  }\n+\n+  private static class FixedConverter implements Converter<byte[]> {\n     @Override\n     public byte[] convert(ColumnVector vector, int row) {\n       int rowIndex = vector.isRepeating ? 0 : row;\n       if (!vector.noNulls && vector.isNull[rowIndex]) {\n         return null;\n       } else {\n         BytesColumnVector bytesVector = (BytesColumnVector) vector;\n-        return Arrays.copyOfRange(bytesVector.vector[rowIndex],\n-            bytesVector.start[rowIndex],\n+        return Arrays.copyOfRange(bytesVector.vector[rowIndex], bytesVector.start[rowIndex],\n             bytesVector.start[rowIndex] + bytesVector.length[rowIndex]);\n       }\n     }\n   }\n \n+  private static class BinaryConverter implements Converter<ByteBuffer> {\n+    @Override\n+    public ByteBuffer convert(ColumnVector vector, int row) {\n+      int rowIndex = vector.isRepeating ? 0 : row;\n+      if (!vector.noNulls && vector.isNull[rowIndex]) {\n+        return null;\n+      } else {\n+        BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+        ByteBuffer buf = ByteBuffer.allocate(bytesVector.length[rowIndex]);\n+        buf.put(bytesVector.vector[rowIndex], bytesVector.start[rowIndex], bytesVector.length[rowIndex]);\n+        buf.rewind();", "originalCommit": "5c16f7c4ce5688737030fb08731ebfc186dda3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0NzI0OA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400847248", "bodyText": "Done", "author": "shardulm94", "createdAt": "2020-03-31T11:45:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MTkzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjE2Mg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162162", "bodyText": "I prefer this style, but it's better not to make non-functional changes like this to avoid commit conflicts.", "author": "rdblue", "createdAt": "2020-03-22T23:49:33Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -236,11 +332,7 @@ public BigDecimal convert(ColumnVector vector, int row) {\n       Preconditions.checkArgument(icebergField.type().isListType());\n       TypeDescription child = schema.getChildren().get(0);\n \n-      childConverter = buildConverter(icebergField\n-          .type()\n-          .asListType()\n-          .fields()\n-          .get(0), child);\n+      childConverter = buildConverter(icebergField.type().asListType().fields().get(0), child);", "originalCommit": "5c16f7c4ce5688737030fb08731ebfc186dda3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0NzE4Nw==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400847187", "bodyText": "Reverted", "author": "shardulm94", "createdAt": "2020-03-31T11:45:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjE2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjI2NQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162265", "bodyText": "Is the spec up to date with these ORC metadata fields?", "author": "rdblue", "createdAt": "2020-03-22T23:50:35Z", "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReader.java", "diffHunk": "@@ -351,20 +441,43 @@ private static Converter buildConverter(final Types.NestedField icebergField,\n       case SHORT:\n         return new ShortConverter();\n       case DATE:\n+        return new DateConverter();\n       case INT:\n         return new IntConverter();\n       case LONG:\n-        return new LongConverter();\n+        ORCSchemaUtil.LongType longType =\n+            ORCSchemaUtil.LongType.valueOf(schema.getAttributeValue(ORCSchemaUtil.ICEBERG_LONG_TYPE_ATTRIBUTE));", "originalCommit": "5c16f7c4ce5688737030fb08731ebfc186dda3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0NzM5Mg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400847392", "bodyText": "Updated the spec now", "author": "shardulm94", "createdAt": "2020-03-31T11:45:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjI2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjQwNQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162405", "bodyText": "Is this rename necessary?", "author": "rdblue", "createdAt": "2020-03-22T23:52:07Z", "path": "data/src/test/java/org/apache/iceberg/data/DataTest.java", "diffHunk": "@@ -48,7 +48,7 @@\n       optional(105, \"f\", Types.FloatType.get()),\n       required(106, \"d\", Types.DoubleType.get()),\n       optional(107, \"date\", Types.DateType.get()),\n-      required(108, \"ts\", Types.TimestampType.withZone()),\n+      required(108, \"tsTz\", Types.TimestampType.withZone()),", "originalCommit": "5c16f7c4ce5688737030fb08731ebfc186dda3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg0NzkwOQ==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400847909", "bodyText": "Reverted", "author": "shardulm94", "createdAt": "2020-03-31T11:46:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjQwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjgwMA==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r396162800", "bodyText": "Why is this now public?", "author": "rdblue", "createdAt": "2020-03-22T23:55:34Z", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -41,12 +41,12 @@\n  */\n public final class ORCSchemaUtil {\n \n-  private enum BinaryType {\n+  public enum BinaryType {", "originalCommit": "5c16f7c4ce5688737030fb08731ebfc186dda3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1MDg3Mg==", "url": "https://github.com/apache/iceberg/pull/778#discussion_r400850872", "bodyText": "In the readers and writers, e.g. GenericOrcReader and GenericOrcWriter, I would like to instantiate different converters for fixed v/s binary v/s uuid. Making this public will allow us to reference this enum while parsing the ORC type attribute in those classes. I think it might be cleaner to use a visitor similar to AvroSchemaWithTypeVisitor in GenericOrcReader/Writer so that we don't need to reference these classes there as we get enough information from iceberg types to disambiguate. But the ORC implementation today lacks such visitors.", "author": "shardulm94", "createdAt": "2020-03-31T11:52:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjE2MjgwMA=="}], "type": "inlineReview"}, {"oid": "3927723631379aec0da36d58f667904230a10e0e", "url": "https://github.com/apache/iceberg/commit/3927723631379aec0da36d58f667904230a10e0e", "message": "ORC: Implement DataTest for ORC Generics", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "f68a55eec019cce0d6211c65418b29894ca4a0d6", "url": "https://github.com/apache/iceberg/commit/f68a55eec019cce0d6211c65418b29894ca4a0d6", "message": "F", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "284a4ef9bf6f9b613b72e91a21b087b2d31b455f", "url": "https://github.com/apache/iceberg/commit/284a4ef9bf6f9b613b72e91a21b087b2d31b455f", "message": "Address PR comments", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "fdc87cd18789251311399e1a61b0cfdc61af97bd", "url": "https://github.com/apache/iceberg/commit/fdc87cd18789251311399e1a61b0cfdc61af97bd", "message": "Fix Spark tests", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "d1b88aa049adad9178652ae9cacd6d5c6d101bfa", "url": "https://github.com/apache/iceberg/commit/d1b88aa049adad9178652ae9cacd6d5c6d101bfa", "message": "Fix timestamp print value in Spark rowEntryToString", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "707556d2ccf45e77263fda9317490f67b11c4166", "url": "https://github.com/apache/iceberg/commit/707556d2ccf45e77263fda9317490f67b11c4166", "message": "Address PR comments", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "e9278d7548d8fa586e1299f080106583c759d6c5", "url": "https://github.com/apache/iceberg/commit/e9278d7548d8fa586e1299f080106583c759d6c5", "message": "Fix Decimal18Converter for GenericORCWriter", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "2fe9508a596b996526423c29c2417af4aa22a6be", "url": "https://github.com/apache/iceberg/commit/2fe9508a596b996526423c29c2417af4aa22a6be", "message": "Address PR comments", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "75547316c8be13304c9dcdc9b6e5ad3ab08dc517", "url": "https://github.com/apache/iceberg/commit/75547316c8be13304c9dcdc9b6e5ad3ab08dc517", "message": "Fix versions.lock after rebase", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "eeebd09005012ec729f5b0adbe01f918442c77e1", "url": "https://github.com/apache/iceberg/commit/eeebd09005012ec729f5b0adbe01f918442c77e1", "message": "Address PR comments", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "52e4a75d7024a70cb591cb8fc66095aa54a85398", "url": "https://github.com/apache/iceberg/commit/52e4a75d7024a70cb591cb8fc66095aa54a85398", "message": "Incorporate changes from omalley's timestamp fixes", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "93ea69c53fe1f1a21233c54a190f9e9ec832788d", "url": "https://github.com/apache/iceberg/commit/93ea69c53fe1f1a21233c54a190f9e9ec832788d", "message": "Add timestamp data test for dates before epoch", "committedDate": "2020-03-31T12:37:54Z", "type": "commit"}, {"oid": "9217f87235ffecb8463e78aaca2849767606688a", "url": "https://github.com/apache/iceberg/commit/9217f87235ffecb8463e78aaca2849767606688a", "message": "Fix GenericDataTest after rebasing from latest master", "committedDate": "2020-03-31T12:42:48Z", "type": "commit"}, {"oid": "9217f87235ffecb8463e78aaca2849767606688a", "url": "https://github.com/apache/iceberg/commit/9217f87235ffecb8463e78aaca2849767606688a", "message": "Fix GenericDataTest after rebasing from latest master", "committedDate": "2020-03-31T12:42:48Z", "type": "forcePushed"}, {"oid": "d388c9e06bb422f346dd44c3e409af0716c68597", "url": "https://github.com/apache/iceberg/commit/d388c9e06bb422f346dd44c3e409af0716c68597", "message": "Fix typo", "committedDate": "2020-03-31T21:00:56Z", "type": "commit"}]}