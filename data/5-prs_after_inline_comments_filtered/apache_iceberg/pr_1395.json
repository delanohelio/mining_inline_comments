{"pr_number": 1395, "pr_title": "Changes default collect behavior of ExpireSnapshotActions", "pr_createdAt": "2020-08-27T19:32:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1395", "timeline": [{"oid": "67176fe5dc103ac785c9aa5530662696f95fc00a", "url": "https://github.com/apache/iceberg/commit/67176fe5dc103ac785c9aa5530662696f95fc00a", "message": "Changes default collect behavior of ExpireSnapshotActions\n\nPreviously ExpireSnapshotAction would always use toLocalIterator which\nends up costing significantly more time on smaller data sets. Since even\nthe largest lists of files are expected to fit in memory we are changing\nthe default to Collect. Collect will bring back the results more quickly\nat the cost of additional memory. An option to streamDeleteResults will still\nbe available for extremely large expire operations.", "committedDate": "2020-08-27T19:02:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MDc1Ng==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478660756", "bodyText": "nit: I think it should be 4 spaces for continued indentation. Applies to the whole test.", "author": "aokolnychyi", "createdAt": "2020-08-27T19:56:24Z", "path": "spark/src/test/java/org/apache/iceberg/actions/TestExpireSnapshotsAction.java", "diffHunk": "@@ -1008,4 +1008,37 @@ public void testExpireAction() {\n     Assert.assertSame(\"Multiple calls to expire should return the same deleted files\",\n         pendingDeletes, action.expire());\n   }\n+\n+  @Test\n+  public void testUseLocalIterator() {\n+    table.newFastAppend()\n+            .appendFile(FILE_A)", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDc4OA==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664788", "bodyText": "Got it!", "author": "RussellSpitzer", "createdAt": "2020-08-27T20:04:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MDc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MTEzMA==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478661130", "bodyText": "nit: to use stream -> to stream", "author": "aokolnychyi", "createdAt": "2020-08-27T19:57:10Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -90,6 +91,19 @@ protected Table table() {\n     return table;\n   }\n \n+  /**\n+   * Whether or not to use stream the expired file list to the driver. The default (false) will use", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478662813", "bodyText": "What about this? By default, all files to delete are brought to the driver at once which may be an issue with very long file lists. Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting the list of files to be deleted.", "author": "aokolnychyi", "createdAt": "2020-08-27T20:00:34Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -90,6 +91,19 @@ protected Table table() {\n     return table;\n   }\n \n+  /**\n+   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n+   * collect to bring back all results to the driver at once which may be an issue with very long file lists.", "originalCommit": "67176fe5dc103ac785c9aa5530662696f95fc00a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDg3OQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664879", "bodyText": "Sgtm", "author": "RussellSpitzer", "createdAt": "2020-08-27T20:04:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NDkzMQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478664931", "bodyText": "Sounds good to me, except that it creates a dead link because Dataset#toLocalIterator is not in Iceberg Javadoc.", "author": "rdblue", "createdAt": "2020-08-27T20:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjgxMw=="}], "type": "inlineReview"}, {"oid": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "url": "https://github.com/apache/iceberg/commit/764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "message": "Reviewer Comments", "committedDate": "2020-08-27T20:24:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY3ODY0Ng==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478678646", "bodyText": "These are broken links because we don't have Spark's API in our Javadoc, right?", "author": "rdblue", "createdAt": "2020-08-27T20:31:58Z", "path": "spark/src/main/java/org/apache/iceberg/actions/ExpireSnapshotsAction.java", "diffHunk": "@@ -92,11 +92,10 @@ protected Table table() {\n   }\n \n   /**\n-   * Whether or not to use stream the expired file list to the driver. The default (false) will use\n-   * collect to bring back all results to the driver at once which may be an issue with very long file lists.\n-   * Set this to true to use toLocalIterator if you are running into memory issues when collecting the list of files\n-   * to be deleted.\n-   * @param stream whether to use toLocalIterator to stream results instead of collect.\n+   * By default, all files to delete are brought to the driver at once which may be an issue with very long file lists.\n+   * Set this to true to use {@link Dataset#toLocalIterator()} if you are running into memory issues when collecting\n+   * the list of files to be deleted.\n+   * @param stream whether to use {@link Dataset#toLocalIterator} to stream results instead of {@link Dataset#collect}.", "originalCommit": "764a58bf2f1e9ba0eaaa5b47cfc7491c3c29e14d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY4MTg5NQ==", "url": "https://github.com/apache/iceberg/pull/1395#discussion_r478681895", "bodyText": "You are right, my bad.", "author": "aokolnychyi", "createdAt": "2020-08-27T20:38:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY3ODY0Ng=="}], "type": "inlineReview"}, {"oid": "ea2dff674bb2019e7bdcde1aa6c342ce26317fdd", "url": "https://github.com/apache/iceberg/commit/ea2dff674bb2019e7bdcde1aa6c342ce26317fdd", "message": "Fix Tests and Doc Links\n\nUnfortunately we can't predicate accurately the exact number of jobs that will be\nproduced because of test run-order and caching (I think). So instead we will just make\nsure that we have more jobs run than we had Shuffle Partitions.", "committedDate": "2020-08-27T22:11:59Z", "type": "commit"}]}