{"pr_number": 1728, "pr_title": "Spark: Add Spark3 extensions module", "pr_createdAt": "2020-11-05T20:35:14Z", "pr_url": "https://github.com/apache/iceberg/pull/1728", "timeline": [{"oid": "c982ca0d9899bce0aff547b630f29d70f79f41d5", "url": "https://github.com/apache/iceberg/commit/c982ca0d9899bce0aff547b630f29d70f79f41d5", "message": "Spark: Add Spark3 extensions module", "committedDate": "2020-11-05T20:39:37Z", "type": "commit"}, {"oid": "c982ca0d9899bce0aff547b630f29d70f79f41d5", "url": "https://github.com/apache/iceberg/commit/c982ca0d9899bce0aff547b630f29d70f79f41d5", "message": "Spark: Add Spark3 extensions module", "committedDate": "2020-11-05T20:39:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQwNjE1NQ==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518406155", "bodyText": "Minor: there are a few casts in these tests that aren't checked. What about adding a checkCast method?\nprivate <T> T checkCast(Object value, Class<T> expectedClass) {\n  Assert.assertTrue(\"Expected instance of \" + expectedClass.getName(), expectedClass.isInstance(value));\n  return expectedClass.cast(value);\n}", "author": "rdblue", "createdAt": "2020-11-05T22:23:05Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestIcebergSparkSqlExtensionsParser.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.math.BigDecimal;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.catalyst.expressions.Literal;\n+import org.apache.spark.sql.catalyst.expressions.Literal$;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+import org.apache.spark.sql.catalyst.parser.ParserInterface;\n+import org.apache.spark.sql.catalyst.plans.logical.CallArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.CallStatement;\n+import org.apache.spark.sql.catalyst.plans.logical.NamedArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.PositionalArgument;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import scala.collection.JavaConverters;\n+\n+public class TestIcebergSparkSqlExtensionsParser {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static SparkSession spark = null;\n+  private static ParserInterface parser = null;\n+\n+  @BeforeClass\n+  public static void startSpark() {\n+    TestIcebergSparkSqlExtensionsParser.spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .config(\"spark.sql.extensions\", IcebergSparkSessionExtensions.class.getName())\n+        .getOrCreate();\n+    TestIcebergSparkSqlExtensionsParser.parser = spark.sessionState().sqlParser();\n+  }\n+\n+  @AfterClass\n+  public static void stopSpark() {\n+    SparkSession currentSpark = TestIcebergSparkSqlExtensionsParser.spark;\n+    TestIcebergSparkSqlExtensionsParser.spark = null;\n+    TestIcebergSparkSqlExtensionsParser.parser = null;\n+    currentSpark.stop();\n+  }\n+\n+  @Test\n+  public void testPositionalArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL c.n.func(1, '2', 3L, true, 1.0D, 9.0e1, 900e-1BD)\");\n+    Assert.assertEquals(ImmutableList.of(\"c\", \"n\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(7, call.args().size());\n+\n+    checkArg(call, 0, 1);\n+    checkArg(call, 1, \"2\");\n+    checkArg(call, 2, 3L);\n+    checkArg(call, 3, true);\n+    checkArg(call, 4, 1.0D);\n+    checkArg(call, 5, 9.0e1);\n+    checkArg(call, 6, new BigDecimal(\"900e-1\"));\n+  }\n+\n+  @Test\n+  public void testNamedArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL cat.system.func(c1 => 1, c2 => '2', c3 => true)\");\n+    Assert.assertEquals(ImmutableList.of(\"cat\", \"system\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(3, call.args().size());\n+\n+    checkArg(call, 0, \"c1\", 1);\n+    checkArg(call, 1, \"c2\", \"2\");\n+    checkArg(call, 2, \"c3\", true);\n+  }\n+\n+  private void checkArg(CallStatement call, int index, Object expectedValue) {\n+    checkArg(call, index, null, expectedValue);\n+  }\n+\n+  private void checkArg(CallStatement call, int index, String expectedName, Object expectedValue) {\n+    if (expectedName != null) {\n+      NamedArgument arg = (NamedArgument) call.args().apply(index);", "originalCommit": "c982ca0d9899bce0aff547b630f29d70f79f41d5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg5MjA1OA==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518892058", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-11-06T17:18:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQwNjE1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQwNzIwMA==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518407200", "bodyText": "Can you also add testMixedArgs() that validates order doesn't change when positional and named arguments are mixed together? Even if this isn't allowed by a later rule, the parser accepts it.", "author": "rdblue", "createdAt": "2020-11-05T22:25:25Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestIcebergSparkSqlExtensionsParser.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.math.BigDecimal;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.catalyst.expressions.Literal;\n+import org.apache.spark.sql.catalyst.expressions.Literal$;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+import org.apache.spark.sql.catalyst.parser.ParserInterface;\n+import org.apache.spark.sql.catalyst.plans.logical.CallArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.CallStatement;\n+import org.apache.spark.sql.catalyst.plans.logical.NamedArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.PositionalArgument;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import scala.collection.JavaConverters;\n+\n+public class TestIcebergSparkSqlExtensionsParser {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static SparkSession spark = null;\n+  private static ParserInterface parser = null;\n+\n+  @BeforeClass\n+  public static void startSpark() {\n+    TestIcebergSparkSqlExtensionsParser.spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .config(\"spark.sql.extensions\", IcebergSparkSessionExtensions.class.getName())\n+        .getOrCreate();\n+    TestIcebergSparkSqlExtensionsParser.parser = spark.sessionState().sqlParser();\n+  }\n+\n+  @AfterClass\n+  public static void stopSpark() {\n+    SparkSession currentSpark = TestIcebergSparkSqlExtensionsParser.spark;\n+    TestIcebergSparkSqlExtensionsParser.spark = null;\n+    TestIcebergSparkSqlExtensionsParser.parser = null;\n+    currentSpark.stop();\n+  }\n+\n+  @Test\n+  public void testPositionalArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL c.n.func(1, '2', 3L, true, 1.0D, 9.0e1, 900e-1BD)\");\n+    Assert.assertEquals(ImmutableList.of(\"c\", \"n\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(7, call.args().size());\n+\n+    checkArg(call, 0, 1);\n+    checkArg(call, 1, \"2\");\n+    checkArg(call, 2, 3L);\n+    checkArg(call, 3, true);\n+    checkArg(call, 4, 1.0D);\n+    checkArg(call, 5, 9.0e1);\n+    checkArg(call, 6, new BigDecimal(\"900e-1\"));\n+  }\n+\n+  @Test\n+  public void testNamedArgs() throws ParseException {", "originalCommit": "c982ca0d9899bce0aff547b630f29d70f79f41d5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg5MjUwMg==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518892502", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-11-06T17:19:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQwNzIwMA=="}], "type": "inlineReview"}, {"oid": "889d172d20c0efbd1f41f23e18ee4ae6e5d4d9af", "url": "https://github.com/apache/iceberg/commit/889d172d20c0efbd1f41f23e18ee4ae6e5d4d9af", "message": "Rewort extensions", "committedDate": "2020-11-06T17:15:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk0Mjg2Ng==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518942866", "bodyText": "For test portability, it's always better to construct Timestamp using an instant: Timestamp.from(Instant.parse(\"2020-01-01 00:00:00\")).", "author": "rdblue", "createdAt": "2020-11-06T18:54:53Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestCallStatementParser.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.math.BigDecimal;\n+import java.sql.Timestamp;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.catalyst.expressions.Expression;\n+import org.apache.spark.sql.catalyst.expressions.Literal;\n+import org.apache.spark.sql.catalyst.expressions.Literal$;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+import org.apache.spark.sql.catalyst.parser.ParserInterface;\n+import org.apache.spark.sql.catalyst.plans.logical.CallArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.CallStatement;\n+import org.apache.spark.sql.catalyst.plans.logical.NamedArgument;\n+import org.apache.spark.sql.catalyst.plans.logical.PositionalArgument;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import scala.collection.JavaConverters;\n+\n+public class TestCallStatementParser {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static SparkSession spark = null;\n+  private static ParserInterface parser = null;\n+\n+  @BeforeClass\n+  public static void startSpark() {\n+    TestCallStatementParser.spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .config(\"spark.sql.extensions\", IcebergSparkSessionExtensions.class.getName())\n+        .config(\"spark.extra.prop\", \"value\")\n+        .getOrCreate();\n+    TestCallStatementParser.parser = spark.sessionState().sqlParser();\n+  }\n+\n+  @AfterClass\n+  public static void stopSpark() {\n+    SparkSession currentSpark = TestCallStatementParser.spark;\n+    TestCallStatementParser.spark = null;\n+    TestCallStatementParser.parser = null;\n+    currentSpark.stop();\n+  }\n+\n+  @Test\n+  public void testCallWithPositionalArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL c.n.func(1, '2', 3L, true, 1.0D, 9.0e1, 900e-1BD)\");\n+    Assert.assertEquals(ImmutableList.of(\"c\", \"n\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(7, call.args().size());\n+\n+    checkArg(call, 0, 1, DataTypes.IntegerType);\n+    checkArg(call, 1, \"2\", DataTypes.StringType);\n+    checkArg(call, 2, 3L, DataTypes.LongType);\n+    checkArg(call, 3, true, DataTypes.BooleanType);\n+    checkArg(call, 4, 1.0D, DataTypes.DoubleType);\n+    checkArg(call, 5, 9.0e1, DataTypes.DoubleType);\n+    checkArg(call, 6, new BigDecimal(\"900e-1\"), DataTypes.createDecimalType(3, 1));\n+  }\n+\n+  @Test\n+  public void testCallWithNamedArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL cat.system.func(c1 => 1, c2 => '2', c3 => true)\");\n+    Assert.assertEquals(ImmutableList.of(\"cat\", \"system\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(3, call.args().size());\n+\n+    checkArg(call, 0, \"c1\", 1, DataTypes.IntegerType);\n+    checkArg(call, 1, \"c2\", \"2\", DataTypes.StringType);\n+    checkArg(call, 2, \"c3\", true, DataTypes.BooleanType);\n+  }\n+\n+  @Test\n+  public void testCallWithMixedArgs() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL cat.system.func(c1 => 1, '2')\");\n+    Assert.assertEquals(ImmutableList.of(\"cat\", \"system\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(2, call.args().size());\n+\n+    checkArg(call, 0, \"c1\", 1, DataTypes.IntegerType);\n+    checkArg(call, 1, \"2\", DataTypes.StringType);\n+  }\n+\n+  @Test\n+  public void testCallWithTimestampArg() throws ParseException {\n+    CallStatement call = (CallStatement) parser.parsePlan(\"CALL cat.system.func(TIMESTAMP '2020-01-01 00:00:00')\");\n+    Assert.assertEquals(ImmutableList.of(\"cat\", \"system\", \"func\"), JavaConverters.seqAsJavaList(call.name()));\n+\n+    Assert.assertEquals(1, call.args().size());\n+\n+    checkArg(call, 0, Timestamp.valueOf(\"2020-01-01 00:00:00\"), DataTypes.TimestampType);", "originalCommit": "889d172d20c0efbd1f41f23e18ee4ae6e5d4d9af", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk4NjEzNg==", "url": "https://github.com/apache/iceberg/pull/1728#discussion_r518986136", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-11-06T20:21:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk0Mjg2Ng=="}], "type": "inlineReview"}, {"oid": "a16346beeac286fad907103b1e3e0d7740983f31", "url": "https://github.com/apache/iceberg/commit/a16346beeac286fad907103b1e3e0d7740983f31", "message": "Minor fixes", "committedDate": "2020-11-06T20:19:58Z", "type": "commit"}, {"oid": "9553da0595914551f6c5361d2b9bc76ec3cb64ee", "url": "https://github.com/apache/iceberg/commit/9553da0595914551f6c5361d2b9bc76ec3cb64ee", "message": "Fix test", "committedDate": "2020-11-06T20:52:17Z", "type": "commit"}]}