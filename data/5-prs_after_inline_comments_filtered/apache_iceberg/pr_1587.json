{"pr_number": 1587, "pr_title": "Nessie support for core ", "pr_createdAt": "2020-10-12T15:25:48Z", "pr_url": "https://github.com/apache/iceberg/pull/1587", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNTkwMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528905901", "bodyText": "Nit: static final constants should use upper case names, like LOGGER. I'm not sure why style checks didn't catch this.\n(Not a blocker)", "author": "rdblue", "createdAt": "2020-11-23T18:18:32Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDQ2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914465", "bodyText": "fixed. I was just arguing w/ @jacques-n on this point on Fri ;-) He sided with you.", "author": "rymurr", "createdAt": "2020-11-23T18:33:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNTkwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNjg2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528906862", "bodyText": "Nit: threw is no longer needed so this could be simply return true. That simplifies the logic at the end of the method to just return false.\nUp to you whether to change this or not. I know some people strongly prefer only one exit point from a method.", "author": "rdblue", "createdAt": "2020-11-23T18:20:14Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.reference() != null) {\n+      newReference = loadReference(pti.reference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.tableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    boolean threw = true;\n+    try {\n+      Tasks.foreach(identifier)\n+           .retry(5)\n+           .stopRetryOn(NessieNotFoundException.class)\n+           .throwFailureWhenFinished()\n+           .run(this::dropTableInner, BaseNessieClientServerException.class);\n+      threw = false;", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDkxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914919", "bodyText": "fixed. I like your way better too..just a hangover from the refactor", "author": "rymurr", "createdAt": "2020-11-23T18:34:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNjg2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528910205", "bodyText": "Did you intend to change this to \"ref\"? Your reply seemed to imply that: #1587 (comment)", "author": "rdblue", "createdAt": "2020-11-23T18:26:05Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));", "originalCommit": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkyOTY1Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528929656", "bodyText": "It is just ref now, the removePrefix method strips the nessie.from the constant in the nessie class. Didn't want to duplicate the constants already in NessieClient", "author": "rymurr", "createdAt": "2020-11-23T19:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkzODkwMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528938903", "bodyText": "I missed the removePrefix call. Thanks!", "author": "rdblue", "createdAt": "2020-11-23T19:17:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503393453", "bodyText": "not sure if this is the best way to get hold of a directory to write tables into. Anyone have any suggestions?", "author": "rymurr", "createdAt": "2020-10-12T16:03:59Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  public static final String CONF_NESSIE_URL = \"nessie.url\";\n+  public static final String CONF_NESSIE_USERNAME = \"nessie.username\";\n+  public static final String CONF_NESSIE_PASSWORD = \"nessie.password\";\n+  public static final String CONF_NESSIE_AUTH_TYPE = \"nessie.auth_type\";\n+  public static final String NESSIE_AUTH_TYPE_DEFAULT = \"BASIC\";\n+  public static final String CONF_NESSIE_REF = \"nessie.ref\";\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+    String path = url == null ? config.get(CONF_NESSIE_URL) : url;\n+    String username = config.get(CONF_NESSIE_USERNAME);\n+    String password = config.get(CONF_NESSIE_PASSWORD);\n+    String authTypeStr = config.get(CONF_NESSIE_AUTH_TYPE, NESSIE_AUTH_TYPE_DEFAULT);\n+    AuthType authType = AuthType.valueOf(authTypeStr);\n+    this.client = new NessieClient(authType, path, username, password);\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NTQ5NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511175494", "bodyText": "In general, I would discourage depending so heavily on Hadoop Configuration. Spark and Flink have a way to pass catalog-specific options, which is the best way to configure catalogs.\nThere is some discussion about this in #1640. I think that catalogs should primarily depend on config passed in a string map, and should only use Hadoop Configuration when dependencies (like HadoopFileIO or HiveClient) require it.", "author": "rdblue", "createdAt": "2020-10-23T22:05:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NTE5MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512165191", "bodyText": "I have cleaned this up a bit and tried to follow the pattern you suggested in #1640", "author": "rymurr", "createdAt": "2020-10-26T18:04:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NDkzNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503394937", "bodyText": "The nessie specific tests all modify spark settings and reset the settings at the end. This is to interfere as little as possible w/ the 'normal' iceberg path.", "author": "rymurr", "createdAt": "2020-10-12T16:06:38Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.nessie.NessieCatalog;\n+import org.apache.iceberg.spark.SparkTestBase;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+public abstract class TestIcebergSourceNessieTables extends TestIcebergSourceTablesBase {\n+\n+  private static TableIdentifier currentIdentifier;\n+\n+  private NessieClient client;\n+  private String branch;\n+\n+  private Configuration getConfig() throws IOException {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTU5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395596", "bodyText": "We identify Nessie as the core catalog/source when there are specific parameters available on the classpath or hadoop config. The idea here is to be fully backwards compatible w/ Hive and Hadoop catalogs.", "author": "rymurr", "createdAt": "2020-10-12T16:07:50Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -133,16 +135,29 @@ protected Table findTable(DataSourceOptions options, Configuration conf) {\n     Optional<String> path = options.get(\"path\");\n     Preconditions.checkArgument(path.isPresent(), \"Cannot open table: path is not set\");\n \n-    if (path.get().contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path.get());\n+    if (nessie(options.asMap(), conf)) {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTIxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181217", "bodyText": "This is probably an area to revisit. Right now, this is written to have minimal changes between 2.4.x and 3.0.x, but I think we will probably want to route all loading from here through a catalog. That will allow us to delegate all of this to Nessie or Hive the same way.", "author": "rdblue", "createdAt": "2020-10-23T22:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTU5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTkyMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395922", "bodyText": "All Nessie tests are run in their own branch to not interfere with parallel test execution", "author": "rymurr", "createdAt": "2020-10-12T16:08:31Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java", "diffHunk": "@@ -83,12 +90,40 @@ public static void dropWarehouse() {\n   protected final SupportsNamespaces validationNamespaceCatalog;\n   protected final TableIdentifier tableIdent = TableIdentifier.of(Namespace.of(\"default\"), \"table\");\n   protected final String tableName;\n+  protected NessieClient client;\n+  protected String branch;\n \n   public SparkCatalogTestBase(String catalogName, String implementation, Map<String, String> config) {\n     this.catalogName = catalogName;\n-    this.validationCatalog = catalogName.equals(\"testhadoop\") ?\n-        new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse) :\n-        catalog;\n+    switch (catalogName) {\n+      case \"testhadoop\":\n+        this.validationCatalog = new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse);\n+        break;\n+      case \"testnessie\":\n+        String path = \"http://localhost:19121/api/v1\";\n+        branch = config.get(\"nessie_ref\");\n+        setHadoopConfig(path, branch);\n+\n+        this.client = new NessieClient(NessieClient.AuthType.NONE, path, null, null);\n+        try {\n+          try {\n+            this.client.getTreeApi().createEmptyBranch(branch);", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397068", "bodyText": "The concept of a namespace is implicit in Nessie and are therefore not managed through the normal SupportsNamespaces interface. We skip tests of this interface when the catalog is a NessieCatalog.", "author": "rymurr", "createdAt": "2020-10-12T16:10:38Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java", "diffHunk": "@@ -56,6 +56,8 @@ public void cleanNamespaces() {\n \n   @Test\n   public void testCreateNamespace() {\n+    // Nessie namespaces are explicit and do not need to be explicitly managed\n+    Assume.assumeFalse(catalogName.endsWith(\"testnessie\"));", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MjE5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511182190", "bodyText": "There are a lot of tests that need this. Should we separate the test cases into different suites?", "author": "rdblue", "createdAt": "2020-10-23T22:29:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0Njk4OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512046988", "bodyText": "Sure, the hadoop catalog is also skipped for most of these. Makes sense to have separate tests", "author": "rymurr", "createdAt": "2020-10-26T15:24:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397814", "bodyText": "We do not extend SupportsNamespaces as a Nessie object store supports the concept of namespaces implicitly. A Nessie namespace can be arbitrarily deep but is not explicitly created or stored. Similar to empty folders in git.", "author": "rymurr", "createdAt": "2020-10-12T16:11:58Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {", "originalCommit": "df32d8e297bd5db0b085972c64e58992284e1ebf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3MzcxNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511173716", "bodyText": "Should be fine, but I think the trade-off is that you won't be able to list namespaces in a namespace. It will be harder to find the namespaces themselves.", "author": "rdblue", "createdAt": "2020-10-23T21:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk5NDc2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511994761", "bodyText": "I will take another pass at this today, I can see totally valid reasons to support listing namespaces if they have tables in them. The problem as I see it comes from creating or deleting namespaces, and storing namespace metadata.\n\n\ncreate/delete: in Nessie (similar to git) a namespace would be created implicitly with the first table in that namespace tree and deleted with the last table in that namespace tree. Separate crerate/delete options in nessie are either no-ops or require a dummy to be placed in that namespace. Both of which are odd operations. eg if its a no-op then creating namespace foo.bar then asking if foo.bar exists will return false.\n\n\nnamespace metadata: What is the use case envisioned for those operations? I think for Nessie we would start with the same behaviour as the hdfs catalog but am curious to know the benefit of supporting those apis.", "author": "rymurr", "createdAt": "2020-10-26T14:18:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NzkyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512167927", "bodyText": "Having another look we could add valid impls for namespaceExists and listNamespaces and do no-op or throw for the others. Then the clients can still navigate namespaces. Thoughts?", "author": "rymurr", "createdAt": "2020-10-26T18:08:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176255", "bodyText": "Looks like this will return all tables underneath the given namespace, even if they are nested in other namespaces?\nI haven't tested this in spark, does it work as expected?", "author": "rdblue", "createdAt": "2020-10-23T22:07:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwMDI3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512000270", "bodyText": "You are correct, it will return everythiing in and below namespace. What is the contract supposed to be? Only tables in this namespace?", "author": "rymurr", "createdAt": "2020-10-26T14:25:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjE2NjIxMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512166211", "bodyText": "Just checked and the contract is Return all the identifiers under this namespace. I took this to mean everything under this and all sub namespaces. If that was not the intention of the method I will fix the predicate.", "author": "rymurr", "createdAt": "2020-10-26T18:06:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjM5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176395", "bodyText": "Probably shouldn't use RuntimeException here. How about NoSuchNamespaceException?", "author": "rdblue", "createdAt": "2020-10-23T22:08:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(\"Unable to list tables due to missing ref.\", ex);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwMDg2OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512000869", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-10-26T14:26:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NzY3Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511177676", "bodyText": "Style: Most Iceberg error messages use the form Cannot <some action>: <reason> (<workaround>). Consistency here tends to make at least Iceberg errors more readable and easy to consume.", "author": "rdblue", "createdAt": "2020-10-23T22:13:03Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAwNjM0NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512006345", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-10-26T14:33:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NzY3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODcxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178717", "bodyText": "I think this should throw NoSuchTableException if the existing metadata is not null because the table was deleted under the reference. You'll probably want to follow the same behavior as the Hive catalog.", "author": "rdblue", "createdAt": "2020-10-23T22:16:53Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODkyMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178920", "bodyText": "Doesn't look like the format here is quite correct. Missing a space?", "author": "rdblue", "createdAt": "2020-10-23T22:17:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxMzc5MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512013791", "bodyText": "good eye, the first char of the applicationId is a newline. I've put no space between commit and %s to not have extra trailing whitespace in message.\nAlso note that the handling of commit messages in nessie is still fairly primitive. This should get replaced by a structured object in the near future.", "author": "rymurr", "createdAt": "2020-10-26T14:42:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTA2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179065", "bodyText": "Is this right for NotFoundException? Iceberg will retry failed commits.", "author": "rdblue", "createdAt": "2020-10-23T22:18:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxOTY2MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512019660", "bodyText": "good eye, cleaned up exception message and handled throwing better", "author": "rymurr", "createdAt": "2020-10-26T14:49:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTA2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTIzNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179235", "bodyText": "You can use the DynFields helpers to do this a bit more easily.", "author": "rdblue", "createdAt": "2020-10-23T22:18:52Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new CommitFailedException(ex, \"failed\");\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {\n+    try {\n+      if (sparkConfMethod == null) {\n+        Class sparkEnvClazz = Class.forName(\"org.apache.spark.SparkEnv\");\n+        sparkEnvMethod = sparkEnvClazz.getMethod(\"get\");\n+        Class sparkConfClazz = Class.forName(\"org.apache.spark.SparkConf\");\n+        sparkConfMethod = sparkEnvClazz.getMethod(\"conf\");\n+        appIdMethod = sparkConfClazz.getMethod(\"getAppId\");", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAyODUyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512028521", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-10-26T15:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTIzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MDI0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511180243", "bodyText": "We prefer using AssertHelpers.assertThrows so that state after the exception was thrown can be validated. For example, testing catalog.createTable(invalid) would not only check ValidationException but also verify that the table was not created.", "author": "rdblue", "createdAt": "2020-10-23T22:22:45Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestParsedTableIdentifier {\n+\n+\n+  @Test\n+  public void noMarkings() {\n+    String path = \"foo\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(path, pti.getTableIdentifier().name());\n+    Assert.assertNull(pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test\n+  public void branchOnly() {\n+    String path = \"foo@bar\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(\"foo\", pti.getTableIdentifier().name());\n+    Assert.assertEquals(\"bar\", pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void timestampOnly() {\n+    String path = \"foo#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void branchAndTimestamp() {\n+    String path = \"foo@bar#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAzMzY5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512033695", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-10-26T15:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MDI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTYxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181610", "bodyText": "Please have a look at #1640, I'd like to standardize how we do this. I do like using type = nessie, so we may want to have a lookup that points to the NessieCatalog implementation.", "author": "rdblue", "createdAt": "2020-10-23T22:27:29Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -103,6 +106,10 @@ protected Catalog buildIcebergCatalog(String name, CaseInsensitiveStringMap opti\n         String warehouseLocation = options.get(\"warehouse\");\n         return new HadoopCatalog(name, conf, warehouseLocation);\n \n+      case \"nessie\":\n+        String defaultBranch = options.getOrDefault(\"nessie_ref\", \"main\");\n+        String nessieUrl = options.get(\"nessie_url\");\n+        return new NessieCatalog(name, conf, defaultBranch, nessieUrl);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTkwOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181909", "bodyText": "Why was this needed?", "author": "rdblue", "createdAt": "2020-10-23T22:28:37Z", "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java", "diffHunk": "@@ -50,6 +50,7 @@ public TestCreateTableAsSelect(String catalogName, String implementation, Map<St\n   @After\n   public void removeTables() {\n     sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);", "originalCommit": "834c3549f5709828c633444de3bae63ac9ecbbd5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjA0NTYyOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r512045629", "bodyText": "The way I was running in the test made it get deleted on the backend nessie server but not in the cached spark context I will clean this up as part of the Spark rework", "author": "rymurr", "createdAt": "2020-10-26T15:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTkwOQ=="}], "type": "inlineReview"}, {"oid": "da33d558c0f1a283f8315dbea9fba82824dfa600", "url": "https://github.com/apache/iceberg/commit/da33d558c0f1a283f8315dbea9fba82824dfa600", "message": "some more updates for code review", "committedDate": "2020-10-26T18:09:38Z", "type": "forcePushed"}, {"oid": "4ac611f4b827b2216be431c2c28a1e80349b9b60", "url": "https://github.com/apache/iceberg/commit/4ac611f4b827b2216be431c2c28a1e80349b9b60", "message": "fix tests and bump plugin version", "committedDate": "2020-10-30T23:44:33Z", "type": "forcePushed"}, {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372", "url": "https://github.com/apache/iceberg/commit/31ddd6b77be8814008663d1aafdf01e373e1b372", "message": "update to support #1640", "committedDate": "2020-11-05T14:21:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTUwOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r519081508", "bodyText": "For Spark writes, we pass the application ID in through snapshot.summary(): \n  \n    \n      iceberg/spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\n    \n    \n         Line 153\n      in\n      9af545e\n    \n    \n    \n    \n\n        \n          \n           operation.set(\"spark.app.id\", applicationId);", "author": "rdblue", "createdAt": "2020-11-07T02:05:00Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {", "originalCommit": "31ddd6b77be8814008663d1aafdf01e373e1b372", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTc3OTMyMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r519779322", "bodyText": "Ahh, thanks for that. Much cleaner this way.", "author": "rymurr", "createdAt": "2020-11-09T12:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTUwOA=="}], "type": "inlineReview"}, {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58", "url": "https://github.com/apache/iceberg/commit/6eba2838dd053690f7f0e66ed0f3095147465a58", "message": "simpler way to get spark app id", "committedDate": "2020-11-09T12:44:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520813255", "bodyText": "#1640 is in. It uses a no-arg constructor and adds an initialize(String name, Map<String, String> config) method to initialize and configure the catalog. I think you should be able to update this now.\nI'm hoping that this removes the need to make Spark and Flink depend on the new Nessie and Glue modules. We should make sure we have a test suite we can include here that uses Flink and Spark.", "author": "rdblue", "createdAt": "2020-11-10T19:16:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxODQwMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520818403", "bodyText": "This is fixed now, apologies. I fixed the constructor but didn't remove the comment.\nI agree that the Catalog portion of Spark3 should work fine now w/o explicitly adding Nessie (or Glue etc). I believe we still need to update the IcebergSource to handle custom (Iceberg) catalogs right?\nIs the intention to add the new catalogs to the Iceberg shaded jar?", "author": "rymurr", "createdAt": "2020-11-10T19:25:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNDkzNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521614936", "bodyText": "Is the intention to add the new catalogs to the Iceberg shaded jar?\n\nI think it depends. If a catalog pulls in a ton of dependencies and requires updating a lot of the shaded Jar's documentation, then it comes at a high cost. On the other hand, if it uses existing bundled libraries or libraries that can be pulled from the Spark runtime, then it would be easier.\n\nI believe we still need to update the IcebergSource to handle custom (Iceberg) catalogs right?\n\nYes, we will need to come up with a way for IcebergSource to work with custom catalogs. Spark has a way for the source to return a catalog and identifier that is used instead of the source directly. That's a much better model, but the problem is that we don't necessarily know what the catalog should be. And, if we redirect to a catalog, we will need to also have a catalog that can load Hadoop tables from a URI. I think this is more of a follow-up.", "author": "rdblue", "createdAt": "2020-11-11T20:19:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI5ODA1OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526298059", "bodyText": "Which mechanism were you thinking for this? Was it LookupCatalog? That is rather scala-y but it works. I have something basic working along the lines of LookupCatalog but I have some concerns about it. Shall I post a PR as a straw man?", "author": "rymurr", "createdAt": "2020-11-18T17:48:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520814377", "bodyText": "I don't think that any configuration should come from the Hadoop Configuration unless it is used for a Hadoop component, like HadoopFileIO. Can you initialize this from the catalog config passed to initialize?", "author": "rdblue", "createdAt": "2020-11-10T19:18:09Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjU3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822572", "bodyText": "Hey @rdblue these parameters are initialised in the initialize method (I have moved the method up to near the constructor as it was hidden at teh bottom of the class). The initialisation uses the passed options where possible and falls back to Configuration if not found. This is to make it compatible with Spark2/3 IcebergSource. However I am happy to remove this once IcebergSource supports custom catalogs (which I hope to tackle next if its not already being worked on)", "author": "rymurr", "createdAt": "2020-11-10T19:32:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTU2NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521615564", "bodyText": "We support the Hive warehouse property because that's how to set it up in Hive. Since we are introducing new configuration for Nessie, I'd really rather not make it so people can depend on using the Hadoop config. Then we will never be able to get rid of it.", "author": "rdblue", "createdAt": "2020-11-11T20:20:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2ODczMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526068733", "bodyText": "Ok, removed. The consequence of this is the custom catalog work for IcebergSource has to be done before the next release if we want a valid/usable nessie in the release", "author": "rymurr", "createdAt": "2020-11-18T13:02:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNTM2Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520815363", "bodyText": "This error message could easily be incorrect because it doesn't use CONF_NESSIE_REF directly. It assumes the caller did.", "author": "rdblue", "createdAt": "2020-11-10T19:19:45Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816050", "bodyText": "Here as well, I don't think this should pull config from Configuration.", "author": "rdblue", "createdAt": "2020-11-10T19:20:57Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNzk2Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520827966", "bodyText": "re-jigged this and above a little bit to make it clear that the hadoop config is only used as a fallback. Hopefully that is more clear. As stated before I hope to remove Configuration for anything but IO in a further PR.", "author": "rymurr", "createdAt": "2020-11-10T19:41:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNTkxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521615910", "bodyText": "Why remove it in a follow-up? I'd be concerned about not remembering and then needing to break behavior later.", "author": "rdblue", "createdAt": "2020-11-11T20:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA2OTA3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526069072", "bodyText": "removed later as stated above", "author": "rymurr", "createdAt": "2020-11-18T13:03:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjM2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816362", "bodyText": "Looks like reference must never be null, correct?", "author": "rdblue", "createdAt": "2020-11-10T19:21:32Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyOTA1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520829057", "bodyText": "correct. The only way to return from get is with a valid reference, otherwise an exception would be thrown. Would you prefer an explicit null check here?", "author": "rymurr", "createdAt": "2020-11-10T19:43:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjM2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzE0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817143", "bodyText": "I think it would be helpful for get to have a better name for uses like this. What about findReference or loadReference?", "author": "rdblue", "createdAt": "2020-11-10T19:22:54Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyOTM0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520829341", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T19:43:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzE0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzg2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817861", "bodyText": "How about passing ImmutableMap.of() instead of new HashMap<>()? That avoids unnecessary object creation. Better yet, what about a version of this that doesn't need to pass a map if there isn't one?", "author": "rdblue", "createdAt": "2020-11-10T19:24:13Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzMDU0Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520830542", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T19:45:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzg2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819559", "bodyText": "Is this assuming that the NessieNotFoundException is referring to the ref because the table was loaded just above? Or is that always used for a ref?", "author": "rdblue", "createdAt": "2020-11-10T19:27:11Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNjI0OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520836248", "bodyText": "You are correct NessieNotFoundException  refers to the ref. If the table were deleted it would be a conflict exception. This is similar to comparing the error modes of git if you committed to a non-existent ref compared to a merge conflict in the case of changing files in the repo", "author": "rymurr", "createdAt": "2020-11-10T19:55:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNzEyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520837127", "bodyText": "I am not 100% certain that RuntimeException is the best avenue here, its definitely an unexpected error and in a sense unrecoverable. There are no exceptions referenced in the javadoc so perhaps a log line and returning false is more appropriate?", "author": "rymurr", "createdAt": "2020-11-10T19:57:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNjY1MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521616651", "bodyText": "Yeah, I like logging and returning false.", "author": "rdblue", "createdAt": "2020-11-11T20:22:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA3MDg1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526070852", "bodyText": "done", "author": "rymurr", "createdAt": "2020-11-18T13:06:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTk0Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819942", "bodyText": "Can't this refresh and complete the operation?", "author": "rdblue", "createdAt": "2020-11-10T19:27:49Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0MjcyNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520842724", "bodyText": "correct, now refreshes and tries again", "author": "rymurr", "createdAt": "2020-11-10T20:07:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDMyNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820327", "bodyText": "In this case, just remove the purge. We do that in our catalog as well because we never delete data as a result of a user action. We garbage collect it later.", "author": "rdblue", "createdAt": "2020-11-10T19:28:28Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNzg4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520837887", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-11-10T19:58:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDQ1NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820455", "bodyText": "What is this referring to?", "author": "rdblue", "createdAt": "2020-11-10T19:28:42Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0NDM5OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520844399", "bodyText": "We don't strictly need to refresh immediately after an operation. This generates an extra call to the backend which typically isn't required. We have to do it because tests do require it. Tests tend to switch branches, perform multiple actions and make several conflicting changes in short order in the same jvm so need explicit refresh. Since the api call isn't expensive we have left the refresh in until a better strategy (or better tests) are devised", "author": "rymurr", "createdAt": "2020-11-10T20:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDQ1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjM1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822354", "bodyText": "Util methods seem to be mixed in. I think it may help readability if these were at the bottom, or were static methods in a NessieUtil class.", "author": "rdblue", "createdAt": "2020-11-10T19:31:57Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0NzcxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520847714", "bodyText": "good idea, fixed. Static methods have been moved to a util class and private methods have been moved to the bottom with Override methods grouped above", "author": "rymurr", "createdAt": "2020-11-10T20:16:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjM1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjc3NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822774", "bodyText": "Is there a more specific name for this? It isn't clear what catalog.getHash() should be.\nAlso, style nit: we avoid using get where a more specific verb would add value.", "author": "rdblue", "createdAt": "2020-11-10T19:32:49Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0ODQ1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520848457", "bodyText": "changed to currentHash. Thoughts? The method returns the current hash as teh catalog understands it.", "author": "rymurr", "createdAt": "2020-11-10T20:17:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjc3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823402", "bodyText": "Should we create a trait just for listing namespaces that are implicit?", "author": "rdblue", "createdAt": "2020-11-10T19:33:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTA4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520849087", "bodyText": "How do you mean? A new interface that no-ops create, load, drop from SupportsNamespaces?", "author": "rymurr", "createdAt": "2020-11-10T20:19:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMTM3OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520901378", "bodyText": "Just an interface that omits those. All this needs is to list namespaces, not do anything else.\nI guess we can take a closer look if anything else needs this.", "author": "rdblue", "createdAt": "2020-11-10T22:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzczNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823736", "bodyText": "Ignore my comments above, since it looks like you've already added this. Can you merge this with init and the constructors?", "author": "rdblue", "createdAt": "2020-11-10T19:34:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzNDM3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520834377", "bodyText": "done :-)", "author": "rymurr", "createdAt": "2020-11-10T19:52:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDA4NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824084", "bodyText": "Nessie URL? In other places, we configure the connection using uri.", "author": "rdblue", "createdAt": "2020-11-10T19:34:56Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg0OTY4Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520849682", "bodyText": "removed the builder and any URL refs I found", "author": "rymurr", "createdAt": "2020-11-10T20:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDA4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDU5NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824595", "bodyText": "This is the default ref, right? Tables can override it. I think that would be a better name if you can use this catalog to load other refs.", "author": "rdblue", "createdAt": "2020-11-10T19:35:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {\n+      this.url = url;\n+      return this;\n+    }\n+\n+    public Builder setRef(String ref) {", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgzMzc3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520833770", "bodyText": "I've deleted the builder as its superfluous after #1640", "author": "rymurr", "createdAt": "2020-11-10T19:51:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDU5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520825564", "bodyText": "If an update doesn't create a snapshot, then this method will return the app ID that committed the last snapshot. That may not be correct. Should we create a class in core to hold this information instead? Then we could set it somewhere in Spark and Flink so you'd always have identifiers without needing to resort to reflection?", "author": "rdblue", "createdAt": "2020-11-10T19:37:21Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private String applicationId() {\n+    String appId = null;\n+    TableMetadata current = current();\n+    if (current != null) {\n+      Snapshot snapshot = current.currentSnapshot();\n+      if (snapshot != null) {\n+        Map<String, String> summary = snapshot.summary();\n+        appId = summary.get(\"spark.app.id\");", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1MjM5OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520852398", "bodyText": "Ahh, good point. Do you mean setting some static state somewhere which holds the current app id? I don't love setting static state, is there a way to tell if the snapshot is the 'correct' snapshot we are looking for?\nWe were just talking today about how to better handle Nessie commit info, perhaps somethign we could discuss tomorrow on the sync call? cc @jacques-n", "author": "rymurr", "createdAt": "2020-11-10T20:25:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMTk5Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520901997", "bodyText": "Maybe we should pass this in through catalog properties?", "author": "rdblue", "createdAt": "2020-11-10T22:02:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxNzg2OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521617869", "bodyText": "I think we should update our SparkCatalog to pass information into catalogs.", "author": "rdblue", "createdAt": "2020-11-11T20:25:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA3NTczNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526075735", "bodyText": "cool, we can add it to the CaseInsensitiveStrngMap when SparkCatalog is initialised? I am not sure of the effect of changing this map from inside SparkCatalog though, perhaps passing a copy w/ the extra params?", "author": "rymurr", "createdAt": "2020-11-18T13:13:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTE1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539150", "bodyText": "Yeah, we should copy and add it. Let's go forward with this for now and we can fix it in a follow-up.", "author": "rdblue", "createdAt": "2020-11-19T01:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY0NDE0MTkxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r644141910", "bodyText": "I opened #2664 to address that", "author": "nastra", "createdAt": "2021-06-02T16:39:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNjQ4OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520826489", "bodyText": "What about doing this delete in a finally block if threw is false? That's usually a better way than catching Throwable and wrapping it in a RuntimeException.", "author": "rdblue", "createdAt": "2020-11-10T19:39:03Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1NDIxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520854219", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-10T20:29:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNjQ4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520828053", "bodyText": "This doesn't seem correct to me. I try to maintain single-table state by catalog, so that all uses of a table stay in sync. I think it would make sense to do the same with refs. If you update a branch by refreshing or committing any table, it should also refresh everything that is related to stay in sync. Otherwise, you're left with the problem of not knowing whether two tables with the same ref are in sync.", "author": "rdblue", "createdAt": "2020-11-10T19:41:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();", "originalCommit": "6eba2838dd053690f7f0e66ed0f3095147465a58", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg1NTUyNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520855525", "bodyText": "Cool, that makes sense to me. Have removed the comment.", "author": "rymurr", "createdAt": "2020-11-10T20:31:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTYxODM5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521618396", "bodyText": "@rymurr, do we need to request a refresh for all other tables that use this ref?", "author": "rdblue", "createdAt": "2020-11-11T20:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjA5ODcxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526098717", "bodyText": "Yes and no, but the option should at least be there. However I think doing this properly is a bigger question. Whether to refresh depends on the isolation level and the use case.\nCurrently if two tables were modified by a different process on the same branch and an iceberg client, who had both those tables cached, committed to only one then the two tables would be out of sync on that iceberg client. But I think that would be true if they were using Hive or Hadoop also, correct? I think rather than addressing this use case in here it would be better to have a wider discussion on how to handle consistency across iceberg catalogs. Thoughts?", "author": "rymurr", "createdAt": "2020-11-18T13:46:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw=="}], "type": "inlineReview"}, {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99", "url": "https://github.com/apache/iceberg/commit/e3748801b817a76dc1c71f76904271222c7a5f99", "message": "address code review", "committedDate": "2020-11-10T20:54:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTEzMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899130", "bodyText": "We try to use simpler error messages and avoid referring to specific people, like \"we\" or \"you\". A good rule of thumb is \"Cannot [some action]: [problem[ [(suggestion to fix)]\" or \"Invalid [something]: [problem]\". How about \"Invalid table name: # is not allowed (reference by timestamp is not supported)\"?", "author": "rdblue", "createdAt": "2020-11-10T21:56:24Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MjQ1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521362452", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-11T13:37:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTIxNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899217", "bodyText": "Can we use a simpler verb, like parse or parseTableIdentifier? It's wordy to use \"get\" and then a past tense verb.", "author": "rdblue", "createdAt": "2020-11-10T21:56:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    TableIdentifier identifier = TableIdentifier.parse(path);\n+    String reference = properties.get(NessieClient.CONF_NESSIE_REF);\n+    return new ParsedTableIdentifier(identifier, null, reference);\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path, Map<String, String> properties) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2NjM3Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521366373", "bodyText": "fixed", "author": "rymurr", "createdAt": "2020-11-11T13:43:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTIxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDQ4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520900487", "bodyText": "I'm wondering if there is a more specific name for this class. Maybe something like TableReference because it has both an identifier and a ref? Or maybe NessieIdentifier? ParsedTableIdentifier doesn't really tell me what is different about this as opposed to TableIdentifier.", "author": "rdblue", "createdAt": "2020-11-10T21:59:10Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2Nzk3OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521367979", "bodyText": "I chose TableReference in the end. I don't love it but its way better than ParsedTableIdentifier. I don't know how to concisely state that its a TableIdentifier tied to a specific Reference. I have updated the javadoc which I hope clarifies it", "author": "rymurr", "createdAt": "2020-11-11T13:45:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDQ4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjcwOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520902708", "bodyText": "Table no longer exists? Or the ref no longer exists?\nAlso, NotFoundException is for files that don't exist. Tables should use NoSuchTableException", "author": "rdblue", "createdAt": "2020-11-10T22:03:39Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Hash;\n+import com.dremio.nessie.model.Reference;\n+import org.apache.iceberg.exceptions.NotFoundException;\n+\n+class UpdateableReference {\n+\n+  private Reference reference;\n+  private final TreeApi client;\n+\n+  UpdateableReference(Reference reference, TreeApi client) {\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  public boolean refresh() {\n+    if (reference instanceof Hash) {\n+      return false;\n+    }\n+    Reference oldReference = reference;\n+    try {\n+      reference = client.getReferenceByName(reference.getName());\n+    } catch (NessieNotFoundException e) {\n+      throw new NotFoundException(e, \"Failure refreshing data, table no longer exists.\");", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3NzI2Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521377267", "bodyText": "fixed the comment and simplified the exception handling", "author": "rymurr", "createdAt": "2020-11-11T14:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjcwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMzc1MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520903750", "bodyText": "Most tests use @Rule TemporaryFolder temp so that JUnit handles temp lifecycle. I'd recommend doing that here, too.", "author": "rdblue", "createdAt": "2020-11-10T22:05:48Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3Nzk0OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521377949", "bodyText": "agreed! Bizarre that wasn't used in the first place :-)", "author": "rymurr", "createdAt": "2020-11-11T14:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMzc1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNDY2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520904662", "bodyText": "This looks like it should have a more specific name because it returns the metadata location for a table.", "author": "rdblue", "createdAt": "2020-11-10T22:07:45Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    catalog.close();\n+    client.close();\n+    catalog = null;\n+    client = null;\n+    hadoopConfig = null;\n+  }\n+\n+  @AfterClass\n+  public static void destroy() throws Exception {\n+    tempDir.delete();\n+  }\n+\n+  static String getContent(NessieCatalog catalog, TableIdentifier tableIdentifier) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3ODkyNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521378924", "bodyText": "fixed, contents is an internal nessie name for the objects stored in the Nessie object database. Changed it to content held for iceberg", "author": "rymurr", "createdAt": "2020-11-11T14:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNDY2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNTA2Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520905063", "bodyText": "Looks like this could just always pass hash.", "author": "rdblue", "createdAt": "2020-11-10T22:08:31Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM3OTU4Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521379587", "bodyText": ":-) i think you are correct", "author": "rymurr", "createdAt": "2020-11-11T14:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNTA2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520906352", "bodyText": "I prefer to separate tests into distinct cases. It looks like this combines testRename with testListTables. Combining test cases into a single method causes failures to prevent other tests from running, which makes the whole suite harder to work with.\nIt is also a lot easier to spot missing test cases and add new ones when tests are separate. I'd recommend taking a look at most of these test suites.\nThat said, I think that you'll be the primary reviewers here so in the end it is mostly up to you what conventions you want to maintain.", "author": "rdblue", "createdAt": "2020-11-10T22:11:02Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.util.List;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalog extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-catalog-branch\";\n+\n+  public TestCatalog() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void test() {\n+    createTable(TableIdentifier.of(\"foo\", \"bar\"));\n+    List<TableIdentifier> tables = catalog.listTables(Namespace.of(\"foo\"));\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"bar\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.renameTable(TableIdentifier.of(\"foo\", \"bar\"), TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(null);\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"baz\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.dropTable(TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(Namespace.empty());\n+    Assert.assertTrue(tables.isEmpty());", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4NTcyNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521385726", "bodyText": "I prefer splitting as well. I have split into 3 tests, its a little more cluttered this way but let me know what you think, happy to go either way.", "author": "rymurr", "createdAt": "2020-11-11T14:13:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTE5Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526541193", "bodyText": "Looks good.", "author": "rdblue", "createdAt": "2020-11-19T01:56:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzg3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520907870", "bodyText": "What is this suppressing?", "author": "rdblue", "createdAt": "2020-11-10T22:14:01Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4NjY4MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521386680", "bodyText": "absolutely nothing! It got carried over from the nessie repo (which has militant checkstyle rules) and I forgot to remove it. Gone now.", "author": "rymurr", "createdAt": "2020-11-11T14:15:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzg3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwODUxOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520908518", "bodyText": "Can you use AssertHelpers.assertThrows instead? That way, you can add assertions after the exception to check other things, like that the table has not been modified.", "author": "rdblue", "createdAt": "2020-11-10T22:15:19Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location1)\n+                              .withFileSizeInBytes(Files.localInput(location2).getLength())\n+                              .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location2)\n+                              .withFileSizeInBytes(Files.localInput(location1).getLength())\n+                              .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+                                  .current()\n+                                  .metadataFileLocation()\n+                                  .replace(\"file:\", \"\"))\n+                             .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test(expected = CommitFailedException.class)", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM4ODE2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521388161", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-11T14:17:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwODUxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTExMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909112", "bodyText": "We've moved the other implementations to create a FileIO at the catalog level and pass it into TableOperations. You may want to do the same. Also, you'll probably want to update to use the same logic so that the implementation can be overridden dynamically.", "author": "rdblue", "createdAt": "2020-11-10T22:16:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } finally {\n+      if (threw) {\n+        io().deleteFile(newMetadataLocation);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5MTUzMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521391533", "bodyText": "thanks for the pointer, copied the Hive Catalog now.", "author": "rymurr", "createdAt": "2020-11-11T14:22:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTExMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTg0Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909846", "bodyText": "Does this need properties? The only thing that is used is an optional ref. That could be passed by itself rather than as a map.", "author": "rdblue", "createdAt": "2020-11-10T22:18:10Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5ODE2Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521398167", "bodyText": "correct, even further the ref isn't really needed. Thanks for pointing that out, much cleaner now.", "author": "rymurr", "createdAt": "2020-11-11T14:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTg0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxMDIwNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520910207", "bodyText": "We typically use a continuation indent of 2 indents / 4 spaces, rather than aligning with the previous method call.", "author": "rdblue", "createdAt": "2020-11-10T22:19:00Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {", "originalCommit": "e3748801b817a76dc1c71f76904271222c7a5f99", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM5ODYzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r521398634", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-11T14:32:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxMDIwNw=="}], "type": "inlineReview"}, {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "url": "https://github.com/apache/iceberg/commit/b46dbf7a2599e7bd8cea384cd968366ce4767382", "message": "respond to code review comments", "committedDate": "2020-11-18T13:52:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526529343", "bodyText": "Minor: It seems strange to me to default this in the catalog rather than in the tests. I would probably use a precondition to validate it isn't null instead.", "author": "rdblue", "createdAt": "2020-11-19T01:19:41Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3MTU3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527671572", "bodyText": "Just to make sure I am looking at the right line of the diff: you mean the name right? I have updated the test to set the catalog name to nessie but I was following the other Catalog impls which set the name to eg 'hive' or 'hadoop' if name is unset.", "author": "rymurr", "createdAt": "2020-11-20T12:53:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyMjc0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527822741", "bodyText": "If that's what the other catalogs do, then that seems reasonable. I think we eventually want to guarantee that there is always a name, but there are probably cases where we didn't have one. We can look into that separately.", "author": "rdblue", "createdAt": "2020-11-20T16:50:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526530130", "bodyText": "Other catalogs use \"warehouse\" instead of a catalog-specific property. It would be slightly better for consistency to do the same, although it is fine this way. If the NessieClient is expecting config like this, it may well be more consistent for Nessie users to always use the full namespaced names.\nJust be aware that this will require properties like spark.sql.catalog.some_name.nessie.warehouse.dir=...", "author": "rdblue", "createdAt": "2020-11-19T01:22:12Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3NTMyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527675321", "bodyText": "I am not sure I understand what you mean by 'warehouse' here. The original version of this patch used the same as the hadoop catalog (conf.get(\"fs.defaultFS\") + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE) but I believe a change was suggested/requested. I personally would much prefer a standard approach than the custom nessie directory. Do you prefer using the Hadoop style one above or the CatalogProperties.WAREHOUSE_LOCATION one?\nI have switched in the most recent patch to using WAREHOUSE_LOCATION", "author": "rymurr", "createdAt": "2020-11-20T13:00:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyMzgzMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527823831", "bodyText": "Yeah, I meant using CatalogProperties.WAREHOUSE_LOCATION. That's what the other catalogs use for a config property.", "author": "rdblue", "createdAt": "2020-11-20T16:52:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTIxOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526531219", "bodyText": "Similar, it may be easier to configure using just \"ref\".", "author": "rdblue", "createdAt": "2020-11-19T01:25:36Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3NjkyNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527676926", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T13:03:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTIxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMzU2Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526533562", "bodyText": "You can replace this with Tasks:\nTasks.foreach(identifier)\n    .retry(5)\n    .stopRetryOn(NessieNotFoundException.class)\n    .throwFailureWhenFinished()\n    .run(this::dropTableInner)\nTasks is pretty flexible and allows you to configure exponential backoff, whether to retry on all exceptions but a known list (stopRetryOn), whether to retry on specific exceptions (onlyRetryOn), and set up callbacks (onFailure).\nIt helps us avoid logic like this everywhere.", "author": "rdblue", "createdAt": "2020-11-19T01:32:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY3OTkxMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527679913", "bodyText": "\ud83d\udc4d I have updated to use Tasks. Fun class :-)", "author": "rymurr", "createdAt": "2020-11-20T13:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMzU2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM3Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534372", "bodyText": "I'd prefer an error message with more context, like Failed to rename X to Y. There's no guarantee that the error message from Nessie has that information. It probably has information about the state of the ref, rather than what was being attempted.", "author": "rdblue", "createdAt": "2020-11-19T01:35:28Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY5NzQxMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527697410", "bodyText": "yup. Not sure why I was being lazy. Fixed now", "author": "rymurr", "createdAt": "2020-11-20T13:41:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDc5NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534794", "bodyText": "This can't happen if the to table has already been dropped? Seems like this assumes that the NessieNotFoundException refers to the ref.\nMaybe we're guaranteed that the ref hasn't changed because this isn't a NessieConflictException? If so, a comment would help.", "author": "rdblue", "createdAt": "2020-11-19T01:36:56Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcwODM0OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527708348", "bodyText": "If to table has already been dropped and our ref wasn't up to date we would get a conflict exception. This is similar to a merge conflict in git: the table has been changed by someone else so there is a conflict exception. The fact that the change is a delete is irrelevant nessie, same error would be thrown if the table had been appended to or the schema were to be changed.\nI have opened projectnessie/nessie#477 to track the lack of documentation on the exception classes. In the meantime I have added a comment here", "author": "rymurr", "createdAt": "2020-11-20T13:59:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDc5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNTEwNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526535107", "bodyText": "Why is this public?\nNot a blocker, just normal code lint.", "author": "rdblue", "createdAt": "2020-11-19T01:37:43Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcwOTgyMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527709821", "bodyText": "\ud83e\udd14 I expect there was a reason at some point. It is only used by tests so I have made it package private for now. The original intention was likely to expose CRUD ops on branches/tags to the user but I think a more structured interface would be better for that", "author": "rymurr", "createdAt": "2020-11-20T14:02:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNTEwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjI3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536270", "bodyText": "We may want to let the original exception propagate instead of throwing a RuntimeException so that people working with the table can take action if the ref is gone. I'm not really sure what the right thing is here.", "author": "rdblue", "createdAt": "2020-11-19T01:41:18Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxMzUwNg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527713506", "bodyText": "I would normally agree but NessieNotFoundException is a checked exception and I don't want to add that throws clause to the interface. Is there a more specialised unchecked exception that you think would suit?\nIf it helps the likelihood of this throwing should be very low in real life. Typically a user/service would own their branches and deleting a branch when someone else is actively working on it would be an organisational issue rather than something that should be handled in code. An analogy in git would be someone deleting your branch which is an active PR (without closing the PR).", "author": "rymurr", "createdAt": "2020-11-20T14:08:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjI3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjY5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536690", "bodyText": "NessieTableOperations calls unwrap instead of using instanceof.", "author": "rdblue", "createdAt": "2020-11-19T01:42:35Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() throws NessieNotFoundException {\n+    reference.refresh();\n+  }\n+\n+  public String currentHash() {\n+    return reference.getHash();\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(NessieUtil.toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxNDgzNw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527714837", "bodyText": "nice catch", "author": "rymurr", "createdAt": "2020-11-20T14:10:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjY5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzODY5Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526538697", "bodyText": "CommitFailedException is used to trigger a table refresh and a retry. Throwing it for NessieConflictException seems correct to me, but reading the error messages makes me less sure.\nIf the ref is a tag, then we don't want to retry because it can't be updated, right? In that case, this should throw some other exception because the table is read-only.\nIf the ref is a branch, then the ref should be refreshed using the normal retry logic so everything looks good. doRefresh will update the ref and then update the table content.", "author": "rdblue", "createdAt": "2020-11-19T01:48:53Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcxNjc2NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527716765", "bodyText": "Yep! exactly! On line 87 we do reference.checkMutable() which will throw IllegalArgumentException if its a tag. So by the time we commit we know its a branch. I have cleaned up the erroneous error msg.", "author": "rymurr", "createdAt": "2020-11-20T14:13:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzODY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTAwMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539000", "bodyText": "Like above, do we know this is the ref because the current ref already loaded the table?", "author": "rdblue", "createdAt": "2020-11-19T01:49:47Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMDg2MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527720861", "bodyText": "I think my comment above covers this as well. The only sensible way this could ever throw is if someone deleted your branch between when you loaded the table and when you tried to commit.\nI have made that a bit more explicit in the comment", "author": "rymurr", "createdAt": "2020-11-20T14:17:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTAwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTcwNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539705", "bodyText": "Nit: We usually omit get from getter method names because it doesn't add value and looks weird in other languages (like Scala and Kotlin).", "author": "rdblue", "createdAt": "2020-11-19T01:51:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMTY0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527721641", "bodyText": "fixed. The pythonista in me doesn't like get either :-)", "author": "rymurr", "createdAt": "2020-11-20T14:18:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526540334", "bodyText": "Looks like this check is the only one needed for #. It doesn't matter if the identifier also contains @ and it also doesn't matter if there is more than one #.", "author": "rdblue", "createdAt": "2020-11-19T01:53:51Z", "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(TableIdentifier path) {\n+    TableReference pti = parse(path.name());\n+    return new TableReference(TableIdentifier.of(path.namespace(), pti.getTableIdentifier().name()),\n+        pti.getTimestamp(),\n+        pti.getReference());\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(String path) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new TableReference(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyMjYyOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527722629", "bodyText": "If it doesn't matter much to you I would like to leave it in. I will be adding timestamp support here very soon.\nHappy to remove it till then if you prefer too.", "author": "rymurr", "createdAt": "2020-11-20T14:20:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyNjU0MQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527826541", "bodyText": "Sounds fine to me if you're going to update this soon. I just wanted to make sure we didn't have an unnecessarily long method.", "author": "rdblue", "createdAt": "2020-11-20T16:55:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526541498", "bodyText": "Isn't it automatically refreshed because it is shared with the NessieTableOperations?", "author": "rdblue", "createdAt": "2020-11-19T01:57:15Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NTM3MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527755370", "bodyText": "References aren't refreshed on commits. So while the ref is shared its out of date everywhere.\nThis normally isn't a problem but since in this test we are creating a branch off the current state of the 'test-branch-hash' branch we explicitly need the up to date hash. Note: in the TableOperations the metadata would be up to date so querying the data would work fine. In normal practice the ref being out of date will only mean we don't get any updates from other users (not the recommended usage pattern) or we would get a merge conflict if we updated the table after someone else has.", "author": "rymurr", "createdAt": "2020-11-20T15:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzgyOTIzNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527829234", "bodyText": "Hm. The commit is going to trigger a refresh on the table the next time its metadata is accessed. That is usually right away because operations will read the latest metadata to clean up unused files. For Nessie, doRefresh is going to update the shared ref. That's why I thought this was redundant. I guess there could be cases where the metadata isn't accessed yet and you do need the refresh.\nNot a big deal, so let's not worry about it.", "author": "rdblue", "createdAt": "2020-11-20T16:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjI5MA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542290", "bodyText": "Using the table name \"foo.bar\" is fine, but using foobar as a variable name makes the test harder to read because it isn't obvious what metadataLocation(catalog, foobar) does exactly. If foobar is a Namespace, then it would be the default location for a table, for example. It would be easier to read if this were something more descriptive, like tableIdent.", "author": "rdblue", "createdAt": "2020-11-19T01:59:42Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NjM3Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527756373", "bodyText": "agreed, fixed", "author": "rymurr", "createdAt": "2020-11-20T15:11:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjI5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjQ5Ng==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542496", "bodyText": "Similar, it would be good to name this table for clarity later on in this long test method.", "author": "rdblue", "createdAt": "2020-11-19T02:00:18Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc1NjUwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527756502", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T15:11:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjQ5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzAwMQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543001", "bodyText": "This is another test I think could be broken into distinct cases with a @Before to set up the default branch and table.", "author": "rdblue", "createdAt": "2020-11-19T02:01:46Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+\n+    bar.updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+\n+    // metadata location changed no longer matches\n+    Assert.assertNotEquals(metadataLocation(catalog, foobar), metadataLocation(newCatalog, foobar));\n+\n+    // points to the previous metadata location\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(newCatalog, foobar));\n+\n+\n+    String mainHash = tree.getReferenceByName(BRANCH).getHash();\n+    // catalog created with ref and no hash points to same catalog as above\n+    NessieCatalog refCatalog = initCatalog(\"test\");\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar), metadataLocation(refCatalog, foobar));\n+    // catalog created with ref and hash points to\n+    NessieCatalog refHashCatalog = initCatalog(mainHash);\n+    Assert.assertEquals(metadataLocation(catalog, foobar), metadataLocation(refHashCatalog, foobar));\n+\n+    // asking for table@branch gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@test\")));\n+    // asking for table@branch#hash gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(catalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@\" + mainHash)));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzc2MDMxNA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527760314", "bodyText": "\ud83d\udc4d", "author": "rymurr", "createdAt": "2020-11-20T15:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzAwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543532", "bodyText": "Context helpers would make this test more readable and would be helpful if it ever fails.", "author": "rdblue", "createdAt": "2020-11-19T02:03:23Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    Table bar = createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(newCatalog, foobaz), metadataLocation(catalog, foobaz));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTYyOA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849628", "bodyText": "ive re-worked this test class. Let me know if thats easier to read", "author": "rymurr", "createdAt": "2020-11-20T17:28:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNDAwMg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528914002", "bodyText": "Looks a lot better!", "author": "rdblue", "createdAt": "2020-11-23T18:33:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0Mzc0Mw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543743", "bodyText": "What does this suppress?", "author": "rdblue", "createdAt": "2020-11-19T02:04:05Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTc4OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849789", "bodyText": "leftover from strict checkstyle checks, removed", "author": "rymurr", "createdAt": "2020-11-20T17:28:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0Mzc0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDAxNQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544015", "bodyText": "What is the main difference between this suite and the branch suite above? Seems very similar to me, so I think I've missed the point. Smaller test cases that are well named would help.", "author": "rdblue", "createdAt": "2020-11-19T02:04:50Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0OTkyMA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527849920", "bodyText": "effectively none, removed", "author": "rymurr", "createdAt": "2020-11-20T17:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDAxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDI4Mg==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544282", "bodyText": "Nit: println usage.", "author": "rdblue", "createdAt": "2020-11-19T02:05:35Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg1MDA0Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527850047", "bodyText": "removed", "author": "rymurr", "createdAt": "2020-11-20T17:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDI4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDQ3Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544477", "bodyText": "This is another test that doesn't seem very different from the others. Can these be combined into a single suite with good test case names that calls out what is unique about each test?", "author": "rdblue", "createdAt": "2020-11-19T02:06:22Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    forwardCatalog.refresh();\n+    tree.assignBranch(\"main\",\n+        tree.getReferenceByName(\"main\").getHash(),\n+        Branch.of(\"main\", forwardCatalog.currentHash()));\n+\n+    catalog.refresh();\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobar),\n+                            metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobaz),\n+                            metadataLocation(catalog, foobaz));\n+\n+    catalog.dropTable(foobar);\n+    catalog.dropTable(foobaz);\n+    tree.deleteBranch(\"FORWARD\", tree.getReferenceByName(\"FORWARD\").getHash());", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg1MDE0NQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527850145", "bodyText": "agreed, deleted", "author": "rymurr", "createdAt": "2020-11-20T17:29:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDQ3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526545279", "bodyText": "Could this be refactored to be smaller and use a couple of util functions? Something like addFile(table, filename) could help.", "author": "rdblue", "createdAt": "2020-11-19T02:08:46Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg4NTg1Nw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527885857", "bodyText": "Can do, I original copied this from one of the catalog tests. I believe those are all package private static methods. Do you know of any test class that has these utils available publicly?", "author": "rymurr", "createdAt": "2020-11-20T18:11:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxNTM1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528915354", "bodyText": "I think there's something in Flink, but this is an area where we can generally improve tests.", "author": "rdblue", "createdAt": "2020-11-23T18:35:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526546123", "bodyText": "Do you have a test for concurrent writes to the same table from multiple catalogs? That would be good with two cases: two tables that share the same ref (loaded by the same catalog) and two tables that were loaded by different catalogs and have separate refs.", "author": "rdblue", "createdAt": "2020-11-19T02:11:22Z", "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location1)\n+        .withFileSizeInBytes(Files.localInput(location2).getLength())\n+        .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location2)\n+        .withFileSizeInBytes(Files.localInput(location1).getLength())\n+        .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+            .current()\n+            .metadataFileLocation()\n+            .replace(\"file:\", \"\"))\n+        .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test\n+  public void testFailure() throws NessieNotFoundException, NessieConflictException {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    Branch branch = (Branch) client.getTreeApi().getReferenceByName(BRANCH);\n+\n+    IcebergTable table = client.getContentsApi().getContents(KEY, BRANCH).unwrap(IcebergTable.class).get();\n+\n+    client.getContentsApi().setContents(KEY, branch.getName(), branch.getHash(), \"\",\n+        IcebergTable.of(\"dummytable.metadata.json\"));\n+\n+    AssertHelpers.assertThrows(\"Update schema fails with conflict exception, ref not up to date\",\n+        CommitFailedException.class,\n+        () -> icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit());", "originalCommit": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg4NDk1NA==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527884954", "bodyText": "TestCatalogBranch does this for the positive case (ie concurrent changes that succeed) and internal nessie for teh negative case. I have added a negative case to TestCatalogBranch also. (and renamed the class)", "author": "rymurr", "createdAt": "2020-11-20T18:09:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkxOTUzOQ==", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r527919539", "bodyText": "Cleaned this up a bit more. We do both tests you suggested, thought it may not be clear its happening. Let me know if the extra comments aren't enough.", "author": "rymurr", "createdAt": "2020-11-20T19:16:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw=="}], "type": "inlineReview"}, {"oid": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "url": "https://github.com/apache/iceberg/commit/52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "message": "initial commit of nessie:\n\n* nessie catalog/table ops\n* modifications to catalog/source for spark\n* add nessie to tests\n\nleft to do:\n* support namespaces\n* start/stop nessie as part of gradle build", "committedDate": "2020-11-20T12:57:08Z", "type": "commit"}, {"oid": "dd7278d84c2d2c01c15192420f8b50410374308c", "url": "https://github.com/apache/iceberg/commit/dd7278d84c2d2c01c15192420f8b50410374308c", "message": "working nessie\n\n* remove namespace for nessie, handled implicitly\n* add gradle plugin", "committedDate": "2020-11-20T12:57:09Z", "type": "commit"}, {"oid": "a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "url": "https://github.com/apache/iceberg/commit/a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "message": "fix versions", "committedDate": "2020-11-20T12:57:10Z", "type": "commit"}, {"oid": "a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "url": "https://github.com/apache/iceberg/commit/a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "message": "tidy up", "committedDate": "2020-11-20T12:57:11Z", "type": "commit"}, {"oid": "0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "url": "https://github.com/apache/iceberg/commit/0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "message": "fix up quarkus plugin", "committedDate": "2020-11-20T12:57:12Z", "type": "commit"}, {"oid": "491e7c2018385169a388e582c6625936ffd82de6", "url": "https://github.com/apache/iceberg/commit/491e7c2018385169a388e582c6625936ffd82de6", "message": "code review comments", "committedDate": "2020-11-20T12:57:13Z", "type": "commit"}, {"oid": "c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "url": "https://github.com/apache/iceberg/commit/c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "message": "revert spark changes", "committedDate": "2020-11-20T12:57:14Z", "type": "commit"}, {"oid": "a52e751fae2f126d0d86a5e2be29111ac219b45f", "url": "https://github.com/apache/iceberg/commit/a52e751fae2f126d0d86a5e2be29111ac219b45f", "message": "some more updates for code review", "committedDate": "2020-11-20T12:57:15Z", "type": "commit"}, {"oid": "823e5bca690dde951ead0f7a6cd96f385d28f41e", "url": "https://github.com/apache/iceberg/commit/823e5bca690dde951ead0f7a6cd96f385d28f41e", "message": "basic support for Namespaces", "committedDate": "2020-11-20T12:57:16Z", "type": "commit"}, {"oid": "4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "url": "https://github.com/apache/iceberg/commit/4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "message": "fix tests and bump plugin version", "committedDate": "2020-11-20T12:57:16Z", "type": "commit"}, {"oid": "6fa22bb3967de6918f39ac45e688dfe94ffe7306", "url": "https://github.com/apache/iceberg/commit/6fa22bb3967de6918f39ac45e688dfe94ffe7306", "message": "update to support #1640", "committedDate": "2020-11-20T12:57:17Z", "type": "commit"}, {"oid": "b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "url": "https://github.com/apache/iceberg/commit/b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "message": "simpler way to get spark app id", "committedDate": "2020-11-20T12:57:18Z", "type": "commit"}, {"oid": "8a9009b06ba78c3ff62c22f13ec8908156dd5151", "url": "https://github.com/apache/iceberg/commit/8a9009b06ba78c3ff62c22f13ec8908156dd5151", "message": "address code review", "committedDate": "2020-11-20T12:57:19Z", "type": "commit"}, {"oid": "bf52afa2053150ff079ba6918518b78b95e8d86e", "url": "https://github.com/apache/iceberg/commit/bf52afa2053150ff079ba6918518b78b95e8d86e", "message": "another round of code review", "committedDate": "2020-11-20T12:57:20Z", "type": "commit"}, {"oid": "5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "url": "https://github.com/apache/iceberg/commit/5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "message": "respond to code review comments", "committedDate": "2020-11-20T12:57:21Z", "type": "commit"}, {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "message": "next round of code review", "committedDate": "2020-11-20T19:17:59Z", "type": "commit"}, {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "message": "next round of code review", "committedDate": "2020-11-20T19:17:59Z", "type": "forcePushed"}, {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "url": "https://github.com/apache/iceberg/commit/fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "message": "clarify branch/table visibility tests", "committedDate": "2020-11-23T17:48:13Z", "type": "commit"}]}