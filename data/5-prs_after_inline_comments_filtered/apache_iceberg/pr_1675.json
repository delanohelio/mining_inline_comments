{"pr_number": 1675, "pr_title": "API: Extend partitioning and sort order", "pr_createdAt": "2020-10-28T21:32:22Z", "pr_url": "https://github.com/apache/iceberg/pull/1675", "timeline": [{"oid": "24b8ccfd186142fa1913e840ecc9e9eea6454b4f", "url": "https://github.com/apache/iceberg/commit/24b8ccfd186142fa1913e840ecc9e9eea6454b4f", "message": "API: Extend partitioning and sort order.", "committedDate": "2020-10-28T21:22:47Z", "type": "commit"}, {"oid": "375e1bc9a4ae4ae810e65ab36af837d66ca0e041", "url": "https://github.com/apache/iceberg/commit/375e1bc9a4ae4ae810e65ab36af837d66ca0e041", "message": "Minor updates.", "committedDate": "2020-10-28T21:41:24Z", "type": "commit"}, {"oid": "ac8ed68cf8db134bd20a61bb0e051ff19b23f933", "url": "https://github.com/apache/iceberg/commit/ac8ed68cf8db134bd20a61bb0e051ff19b23f933", "message": "Add CopySortOrderFields.", "committedDate": "2020-10-28T21:45:57Z", "type": "commit"}, {"oid": "441b7d7e7c748cc81a7d9622bae1565b17e5e8b4", "url": "https://github.com/apache/iceberg/commit/441b7d7e7c748cc81a7d9622bae1565b17e5e8b4", "message": "Fix checkstyle.", "committedDate": "2020-10-28T23:09:20Z", "type": "commit"}, {"oid": "7b4cab8ee53042ec922f1f16fe2d25c5307f514f", "url": "https://github.com/apache/iceberg/commit/7b4cab8ee53042ec922f1f16fe2d25c5307f514f", "message": "Fix copyright.", "committedDate": "2020-10-29T18:47:21Z", "type": "commit"}, {"oid": "04654991f73ae40dbae82b8f1109fdacbb656e97", "url": "https://github.com/apache/iceberg/commit/04654991f73ae40dbae82b8f1109fdacbb656e97", "message": "Fix TestForwardCompatibility.", "committedDate": "2020-11-01T19:58:43Z", "type": "commit"}, {"oid": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "url": "https://github.com/apache/iceberg/commit/cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "message": "Fix checkstyle.", "committedDate": "2020-11-03T00:54:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMjQ1MQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517002451", "bodyText": "I'm not familiar with this; I think in SortOrderVisitor L75 both Dates.YEAR and Timestamps.YEAR will end up in here, but Expressions.year will only produce Timestamp transform (from here). Would this cause compatibility issue?", "author": "yyanyy", "createdAt": "2020-11-03T22:53:01Z", "path": "core/src/main/java/org/apache/iceberg/CopySortOrderFields.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.transforms.SortOrderVisitor;\n+\n+class CopySortOrderFields implements SortOrderVisitor<Void> {\n+  private final SortOrder.Builder builder;\n+\n+  CopySortOrderFields(SortOrder.Builder builder) {\n+    this.builder = builder;\n+  }\n+\n+  @Override\n+  public Void field(String sourceName, int sourceId, SortDirection direction, NullOrder nullOrder) {\n+    if (direction == SortDirection.ASC) {\n+      builder.asc(sourceName, nullOrder);\n+    } else {\n+      builder.desc(sourceName, nullOrder);\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public Void bucket(String sourceName, int sourceId, int numBuckets, SortDirection direction, NullOrder nullOrder) {\n+    if (direction == SortDirection.ASC) {\n+      builder.asc(Expressions.bucket(sourceName, numBuckets), nullOrder);\n+    } else {\n+      builder.desc(Expressions.bucket(sourceName, numBuckets), nullOrder);\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public Void truncate(String sourceName, int sourceId, int width, SortDirection direction, NullOrder nullOrder) {\n+    if (direction == SortDirection.ASC) {\n+      builder.asc(Expressions.truncate(sourceName, width), nullOrder);\n+    } else {\n+      builder.desc(Expressions.truncate(sourceName, width), nullOrder);\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public Void year(String sourceName, int sourceId, SortDirection direction, NullOrder nullOrder) {\n+    if (direction == SortDirection.ASC) {\n+      builder.asc(Expressions.year(sourceName), nullOrder);", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxOTQwNw==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517019407", "bodyText": "No, because the expressions here are all unbound, so there is no guarantee that the types match or that the expression can be evaluated. That is guaranteed after an expression is bound.\nFor example, I can create Expressions.lessThan(\"x\", 34). The type of x in a table is unknown and could be long. When the expression is bound, the type of x is taken from the schema the expression is bound with, and the value is coerced to that type.\nTransforms are also fixed up when an expression is bound. Although the code initially assumes that the column identified by sourceName is a timestamp, binding will create the right transform based on the actual column type.", "author": "rdblue", "createdAt": "2020-11-03T23:42:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMjQ1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU2MjMxNw==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517562317", "bodyText": "Ah I see, I overlooked Timestamps/Dates.valueOf() in fromString. Thank you for the explanation!", "author": "yyanyy", "createdAt": "2020-11-04T18:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMjQ1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMjY3MA==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517002670", "bodyText": "width -> numBuckets? Same as in SortOrderVisitorL34", "author": "yyanyy", "createdAt": "2020-11-03T22:53:29Z", "path": "api/src/main/java/org/apache/iceberg/transforms/PartitionSpecVisitor.java", "diffHunk": "@@ -26,20 +26,94 @@\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n \n public interface PartitionSpecVisitor<T> {\n-  T identity(String sourceName, int sourceId);\n+  default T identity(int fieldId, String sourceName, int sourceId) {\n+    return identity(sourceName, sourceId);\n+  }\n+\n+  default T identity(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Identity transform is not supported\");\n+  }\n+\n+  default T bucket(int fieldId, String sourceName, int sourceId, int width) {", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyNjQwOA==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517526408", "bodyText": "Fixed.", "author": "rdblue", "createdAt": "2020-11-04T17:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMjY3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMzY2OQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517003669", "bodyText": "\"equivalent to\" -> I thought it would be \"satisfies\"?", "author": "yyanyy", "createdAt": "2020-11-03T22:55:48Z", "path": "api/src/main/java/org/apache/iceberg/transforms/Transform.java", "diffHunk": "@@ -58,6 +58,29 @@\n    */\n   Type getResultType(Type sourceType);\n \n+  /**\n+   * Whether the transform preserves the order of values (is monotonic).\n+   * <p>\n+   * A transform preserves order for values when for any given a and b, if a &lt; b then apply(a) &lt;= apply(b).\n+   *\n+   * @return true if the transform preserves the order of values\n+   */\n+  default boolean preservesOrder() {\n+    return false;\n+  }\n+\n+  /**\n+   * Whether ordering by this transform's result satisfies the ordering of another transform's result.\n+   * <p>\n+   * For example, sorting by day(ts) will produce an ordering that is also by month(ts) or year(ts). However, sorting\n+   * by day(ts) will not satisfy the order of hour(ts) or identity(ts).\n+   *\n+   * @return true if ordering by this transform is equivalent to ordering by the other transform", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxNzYyOA==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517017628", "bodyText": "I think \"equivalent to\" is more specific in this case because \"satisfies\" is in the method name. I'm trying to avoid using the term in the definition, and the meaning of \"satisfies\" is that ordering by one is equivalent to ordering by the other.", "author": "rdblue", "createdAt": "2020-11-03T23:36:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMzY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU2MzIwNQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517563205", "bodyText": "Makes sense, it's the orderings that are equivalent.", "author": "yyanyy", "createdAt": "2020-11-04T18:56:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwMzY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxODcwNQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517018705", "bodyText": "Wouldn't it also be the case that a = b; then apply(a) = apply(b)?", "author": "danielcweeks", "createdAt": "2020-11-03T23:40:13Z", "path": "api/src/main/java/org/apache/iceberg/transforms/Transform.java", "diffHunk": "@@ -58,6 +58,29 @@\n    */\n   Type getResultType(Type sourceType);\n \n+  /**\n+   * Whether the transform preserves the order of values (is monotonic).\n+   * <p>\n+   * A transform preserves order for values when for any given a and b, if a &lt; b then apply(a) &lt;= apply(b).", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNTQxNw==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517035417", "bodyText": "If a = b, then apply(a) should always equal apply(b). This is concerned with the case where a and b are not equal.\nFor example, a year transform has this property. year(2020-12-31) = 2020 and year(2021-01-01) = 2021. Because the first date comes before the second, its year must be before (or the same as) any date after it.", "author": "rdblue", "createdAt": "2020-11-04T00:40:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxODcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyNzc4NQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517027785", "bodyText": "I feel like should be able to really reduce the amount of boilerplate if/else for asc/desc by exposing sort direction directly from the builder.  Seems like you could just add a Builder::addSort(term, direction, nullOrder) and make this much cleaner.", "author": "danielcweeks", "createdAt": "2020-11-04T00:11:13Z", "path": "core/src/main/java/org/apache/iceberg/CopySortOrderFields.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.transforms.SortOrderVisitor;\n+\n+class CopySortOrderFields implements SortOrderVisitor<Void> {\n+  private final SortOrder.Builder builder;\n+\n+  CopySortOrderFields(SortOrder.Builder builder) {\n+    this.builder = builder;\n+  }\n+\n+  @Override\n+  public Void field(String sourceName, int sourceId, SortDirection direction, NullOrder nullOrder) {\n+    if (direction == SortDirection.ASC) {\n+      builder.asc(sourceName, nullOrder);", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNTU2MQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517035561", "bodyText": "Yeah, we should probably do that.", "author": "rdblue", "createdAt": "2020-11-04T00:40:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyNzc4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyNTc1NQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517525755", "bodyText": "Added sortBy to the builder for this.", "author": "rdblue", "createdAt": "2020-11-04T17:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyNzc4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMTUyMw==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517031523", "bodyText": "Are we guaranteed to have only one bucket column?  I actually didn't think of this until now, but Hive allows for bucketing on multiple columns (though those are combined and hashed I believe).  However, I didn't immedaitely see anything that prevents someone from defining multiple bucket columns.", "author": "danielcweeks", "createdAt": "2020-11-04T00:25:02Z", "path": "core/src/main/java/org/apache/iceberg/Partitioning.java", "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.util.List;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.transforms.PartitionSpecVisitor;\n+\n+public class Partitioning {\n+  private Partitioning() {\n+  }\n+\n+  /**\n+   * Check whether the spec contains a bucketed partition field.\n+   *\n+   * @param spec a partition spec\n+   * @return true if the spec has field with a bucket transform\n+   */\n+  public static boolean hasBucketField(PartitionSpec spec) {\n+    List<Boolean> bucketList = PartitionSpecVisitor.visit(spec, new PartitionSpecVisitor<Boolean>() {\n+      @Override\n+      public Boolean identity(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean bucket(int fieldId, String sourceName, int sourceId, int width) {\n+        return true;\n+      }\n+\n+      @Override\n+      public Boolean truncate(int fieldId, String sourceName, int sourceId, int width) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean year(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean month(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean day(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean hour(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean alwaysNull(int fieldId, String sourceName, int sourceId) {\n+        return false;\n+      }\n+\n+      @Override\n+      public Boolean unknown(int fieldId, String sourceName, int sourceId, String transform) {\n+        return false;\n+      }\n+    });\n+\n+    return bucketList.stream().anyMatch(Boolean::booleanValue);\n+  }\n+\n+  /**\n+   * Create a sort order that will group data for a partition spec.\n+   * <p>\n+   * If the partition spec contains bucket columns, the sort order will also have a field to sort by a column that is\n+   * bucketed in the spec. The column is selected by the highest number of buckets in the transform.\n+   *\n+   * @param spec a partition spec\n+   * @return a sort order that will cluster data for the spec\n+   */\n+  public static SortOrder sortOrderFor(PartitionSpec spec) {\n+    if (spec.isUnpartitioned()) {\n+      return SortOrder.unsorted();\n+    }\n+\n+    SortOrder.Builder builder = SortOrder.builderFor(spec.schema());\n+    SpecToOrderVisitor converter = new SpecToOrderVisitor(builder);\n+    PartitionSpecVisitor.visit(spec, converter);\n+\n+    // columns used for bucketing are high cardinality; add one to the sort at the end\n+    String bucketColumn = converter.bucketColumn();\n+    if (bucketColumn != null) {\n+      builder.asc(bucketColumn);\n+    }\n+\n+    return builder.build();\n+  }\n+\n+  private static class SpecToOrderVisitor implements PartitionSpecVisitor<Void> {\n+    private final SortOrder.Builder builder;\n+    private String bucketColumn = null;", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzA0MA==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517037040", "bodyText": "There's no reason why we can't have more than one bucket transform, but Iceberg doesn't mix fields together in bucket transforms. The reason is that each bucket column should be useful independently.\nFor example, you might have PARTITION BY (bucket(8, user_id), bucket(16, item_id)). Joining to both users and items independently could take advantage of those bucketed columns. And joining two tables with user_id and item_id (like purchases and reviews) could use a combination of both: user_bucket << 16 | item_bucket.", "author": "rdblue", "createdAt": "2020-11-04T00:45:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMTUyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTA1MA==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517039050", "bodyText": "I guess I wasn't clear on my point.  I understand why we're not doing what Hive does in this case, but rather how we are only using a single bucket in the sort order above on line 106.", "author": "danielcweeks", "createdAt": "2020-11-04T00:53:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMTUyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MTA2Mg==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517041062", "bodyText": "Oh, sorry about that. The bucket column is tracked because it is assumed to be a high cardinality column. Since we want to end a sort order with a high cardinality column, we keep track of the bucket column with the largest number of buckets and add that to the inferred sort order.\n      // the column with highest cardinality is usually the one with the highest number of buckets\n      if (numBuckets > highestNumBuckets) {\n        this.highestNumBuckets = numBuckets;\n        this.bucketColumn = sourceName;\n      }\nThen above in sortOrderFor(PartitionSpec), if the bucket column is present, it is added to the order.", "author": "rdblue", "createdAt": "2020-11-04T01:01:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMTUyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MjUyMw==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517042523", "bodyText": "Ah, ok.  That makes sense.", "author": "danielcweeks", "createdAt": "2020-11-04T01:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMTUyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ3NDE3OQ==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517474179", "bodyText": "nit: should we add default T alwaysNull(String sourceName, int sourceId) as well?", "author": "jun-he", "createdAt": "2020-11-04T16:32:22Z", "path": "api/src/main/java/org/apache/iceberg/transforms/PartitionSpecVisitor.java", "diffHunk": "@@ -26,20 +26,94 @@\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n \n public interface PartitionSpecVisitor<T> {\n-  T identity(String sourceName, int sourceId);\n+  default T identity(int fieldId, String sourceName, int sourceId) {\n+    return identity(sourceName, sourceId);\n+  }\n+\n+  default T identity(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Identity transform is not supported\");\n+  }\n+\n+  default T bucket(int fieldId, String sourceName, int sourceId, int width) {\n+    return bucket(sourceName, sourceId, width);\n+  }\n+\n+  default T bucket(String sourceName, int sourceId, int width) {\n+    throw new UnsupportedOperationException(\"Bucket transform is not supported\");\n+  }\n \n-  T bucket(String sourceName, int sourceId, int width);\n+  default T truncate(int fieldId, String sourceName, int sourceId, int width) {\n+    return truncate(sourceName, sourceId, width);\n+  }\n \n-  T truncate(String sourceName, int sourceId, int width);\n+  default T truncate(String sourceName, int sourceId, int width) {\n+    throw new UnsupportedOperationException(\"Truncate transform is not supported\");\n+  }\n \n-  T year(String sourceName, int sourceId);\n+  default T year(int fieldId, String sourceName, int sourceId) {\n+    return year(sourceName, sourceId);\n+  }\n \n-  T month(String sourceName, int sourceId);\n+  default T year(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Year transform is not supported\");\n+  }\n \n-  T day(String sourceName, int sourceId);\n+  default T month(int fieldId, String sourceName, int sourceId) {\n+    return month(sourceName, sourceId);\n+  }\n+\n+  default T month(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Month transform is not supported\");\n+  }\n \n-  T hour(String sourceName, int sourceId);\n+  default T day(int fieldId, String sourceName, int sourceId) {\n+    return day(sourceName, sourceId);\n+  }\n+\n+  default T day(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Day transform is not supported\");\n+  }\n+\n+  default T hour(int fieldId, String sourceName, int sourceId) {\n+    return hour(sourceName, sourceId);\n+  }\n+\n+  default T hour(String sourceName, int sourceId) {\n+    throw new UnsupportedOperationException(\"Hour transform is not supported\");\n+  }\n+\n+  default T alwaysNull(int fieldId, String sourceName, int sourceId) {", "originalCommit": "cbf104c81a5909fa96f5a9690bd6ccd55e97ca8e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ4OTQ4Ng==", "url": "https://github.com/apache/iceberg/pull/1675#discussion_r517489486", "bodyText": "No, the methods without fieldId are only there for backward compatibility.", "author": "rdblue", "createdAt": "2020-11-04T16:54:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzQ3NDE3OQ=="}], "type": "inlineReview"}, {"oid": "9b3f6459ac1cf32b8e8562ad68f9883913b2dacb", "url": "https://github.com/apache/iceberg/commit/9b3f6459ac1cf32b8e8562ad68f9883913b2dacb", "message": "Add sortBy to SortOrder.Builder.", "committedDate": "2020-11-04T17:49:02Z", "type": "commit"}, {"oid": "ce427a991d9ef9a4eb48b9a603a1fd52cede6a2e", "url": "https://github.com/apache/iceberg/commit/ce427a991d9ef9a4eb48b9a603a1fd52cede6a2e", "message": "Rename bucket width to numBuckets.", "committedDate": "2020-11-04T17:52:17Z", "type": "commit"}]}