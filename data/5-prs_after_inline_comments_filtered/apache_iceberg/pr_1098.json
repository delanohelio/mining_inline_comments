{"pr_number": 1098, "pr_title": "Refactor MergingSnapshotProducer", "pr_createdAt": "2020-06-05T22:19:23Z", "pr_url": "https://github.com/apache/iceberg/pull/1098", "timeline": [{"oid": "05ea1adf392b48362ee20eda12f9914983b74b28", "url": "https://github.com/apache/iceberg/commit/05ea1adf392b48362ee20eda12f9914983b74b28", "message": "Refactor MergingSnapshotProducer into separate classes.", "committedDate": "2020-06-05T22:24:29Z", "type": "forcePushed"}, {"oid": "83dedc7458636cc8da48632dbb9098483de56381", "url": "https://github.com/apache/iceberg/commit/83dedc7458636cc8da48632dbb9098483de56381", "message": "Refactor MergingSnapshotProducer into separate classes.", "committedDate": "2020-06-05T22:39:09Z", "type": "forcePushed"}, {"oid": "c51ef26874e7f4b2d8152920a1ab379aa78c0590", "url": "https://github.com/apache/iceberg/commit/c51ef26874e7f4b2d8152920a1ab379aa78c0590", "message": "Refactor MergingSnapshotProducer into separate classes.", "committedDate": "2020-06-05T23:43:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTY1NA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r436209654", "bodyText": "This introduces a slight behavior change. Before, the first new manifest was used to identify the starting bin to apply the minimum merge count. As a result, the min count had no effect if there were no added files or appended manifests.\nNow, this uses the first manifest in the manifest list passed to merge to identify the initial bin. This will result in some operations that did not add files or manifests not being merged, like the delete operations. This is what required the change to the v2 sequence number transaction test.", "author": "rdblue", "createdAt": "2020-06-05T23:51:55Z", "path": "core/src/main/java/org/apache/iceberg/ManifestMergeManager.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Array;\n+import java.util.Comparator;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.iceberg.ManifestEntry.Status;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.iceberg.relocated.com.google.common.collect.ListMultimap;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Multimaps;\n+import org.apache.iceberg.util.BinPacking.ListPacker;\n+import org.apache.iceberg.util.Tasks;\n+import org.apache.iceberg.util.ThreadPools;\n+\n+abstract class ManifestMergeManager<F extends ContentFile<F>> {\n+  private final long targetSizeBytes;\n+  private final int minCountToMerge;\n+  private final boolean mergeEnabled;\n+\n+  // cache merge results to reuse when retrying\n+  private final Map<List<ManifestFile>, ManifestFile> mergedManifests = Maps.newConcurrentMap();\n+\n+  ManifestMergeManager(long targetSizeBytes, int minCountToMerge, boolean mergeEnabled) {\n+    this.targetSizeBytes = targetSizeBytes;\n+    this.minCountToMerge = minCountToMerge;\n+    this.mergeEnabled = mergeEnabled;\n+  }\n+\n+  protected abstract long snapshotId();\n+  protected abstract PartitionSpec spec(int specId);\n+  protected abstract void deleteFile(String location);\n+  protected abstract ManifestWriter<F> newManifestWriter(PartitionSpec spec);\n+  protected abstract ManifestReader<F> newManifestReader(ManifestFile manifest);\n+\n+  Iterable<ManifestFile> mergeManifests(Iterable<ManifestFile> manifests) {\n+    Iterator<ManifestFile> manifestIter = manifests.iterator();\n+    if (!mergeEnabled || !manifestIter.hasNext()) {\n+      return manifests;\n+    }\n+\n+    ManifestFile first = manifestIter.next();\n+\n+    List<ManifestFile> merged = Lists.newArrayList();\n+    ListMultimap<Integer, ManifestFile> groups = groupBySpec(first, manifestIter);\n+    for (Integer specId : groups.keySet()) {\n+      Iterables.addAll(merged, mergeGroup(first, specId, groups.get(specId)));\n+    }\n+\n+    return merged;\n+  }\n+\n+  void cleanUncommitted(Set<ManifestFile> committed) {\n+    // iterate over a copy of entries to avoid concurrent modification\n+    List<Map.Entry<List<ManifestFile>, ManifestFile>> entries =\n+        Lists.newArrayList(mergedManifests.entrySet());\n+\n+    for (Map.Entry<List<ManifestFile>, ManifestFile> entry : entries) {\n+      // delete any new merged manifests that aren't in the committed list\n+      ManifestFile merged = entry.getValue();\n+      if (!committed.contains(merged)) {\n+        deleteFile(merged.path());\n+        // remove the deleted file from the cache\n+        mergedManifests.remove(entry.getKey());\n+      }\n+    }\n+  }\n+\n+  private ListMultimap<Integer, ManifestFile> groupBySpec(ManifestFile first, Iterator<ManifestFile> remaining) {\n+    ListMultimap<Integer, ManifestFile> groups = Multimaps.newListMultimap(\n+        Maps.newTreeMap(Comparator.<Integer>reverseOrder()),\n+        Lists::newArrayList);\n+    groups.put(first.partitionSpecId(), first);\n+    remaining.forEachRemaining(manifest -> groups.put(manifest.partitionSpecId(), manifest));\n+    return groups;\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  private Iterable<ManifestFile> mergeGroup(ManifestFile first, int specId, List<ManifestFile> group) {\n+    // use a lookback of 1 to avoid reordering the manifests. using 1 also means this should pack\n+    // from the end so that the manifest that gets under-filled is the first one, which will be\n+    // merged the next time.\n+    ListPacker<ManifestFile> packer = new ListPacker<>(targetSizeBytes, 1, false);\n+    List<List<ManifestFile>> bins = packer.packEnd(group, ManifestFile::length);\n+\n+    // process bins in parallel, but put results in the order of the bins into an array to preserve\n+    // the order of manifests and contents. preserving the order helps avoid random deletes when\n+    // data files are eventually aged off.\n+    List<ManifestFile>[] binResults = (List<ManifestFile>[])\n+        Array.newInstance(List.class, bins.size());\n+\n+    Tasks.range(bins.size())\n+        .stopOnFailure().throwFailureWhenFinished()\n+        .executeWith(ThreadPools.getWorkerPool())\n+        .run(index -> {\n+          List<ManifestFile> bin = bins.get(index);\n+          List<ManifestFile> outputManifests = Lists.newArrayList();\n+          binResults[index] = outputManifests;\n+\n+          if (bin.size() == 1) {\n+            // no need to rewrite\n+            outputManifests.add(bin.get(0));\n+            return;\n+          }\n+\n+          // if the bin has the first manifest (the new data files or an appended manifest file) then only merge it\n+          // if the number of manifests is above the minimum count. this is applied only to bins with an in-memory\n+          // manifest so that large manifests don't prevent merging older groups.\n+          if (bin.contains(first) && bin.size() < minCountToMerge) {", "originalCommit": "c51ef26874e7f4b2d8152920a1ab379aa78c0590", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzE3MzI4OQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437173289", "bodyText": "Could you please help me to understand the following case?\nIf we append 5 manifests (m1-m5) on a table that has 1 existing manifest(m6), and they are packed into 2 bins according to targetWeight. Assume we set minCountToMerge to 4.\nSince it packs from the end, we must have a layout: [(m1, m2), (m3, m4, m5, m6)]\nThe first is m1, right?  then the first bin will not get merged while m3-m5 are merged.", "author": "chenjunjiedada", "createdAt": "2020-06-09T06:47:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzY0NjE4NQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437646185", "bodyText": "m1 is used to detect the first bin, so it would not be merged because it only has 2 (< minCount) manifests. The other bin would be merged because it isn't the first.\nOverall, the behavior is the same as before. The difference is that now we can detect the first bin even if there are no appended manifests. In your example, that commit would end with [m1, m2, m7], where m7 is the merged bin. A delete commit after that would produce bins [(m1, m2), (m7)] but this time the first bin, (m1, m2) would get merged because there was no appended manifest used to detect that it was the first bin. Now, we use the first manifest, m1, to identify the first bin and it would not get merged.", "author": "rdblue", "createdAt": "2020-06-09T18:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4NTA4MA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437785080", "bodyText": "Seems reasonable!", "author": "aokolnychyi", "createdAt": "2020-06-09T23:54:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTY1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgzNjg2NQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437836865", "bodyText": "Thanks for your elaboration!", "author": "chenjunjiedada", "createdAt": "2020-06-10T03:16:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjIwOTY1NA=="}], "type": "inlineReview"}, {"oid": "ec5479d997f2c9ffbe57f79460611dceb8c59e12", "url": "https://github.com/apache/iceberg/commit/ec5479d997f2c9ffbe57f79460611dceb8c59e12", "message": "Fix checkstyle problems.", "committedDate": "2020-06-08T20:01:15Z", "type": "forcePushed"}, {"oid": "449047381b8a698bc6c8f23d0f13b5ed9072f656", "url": "https://github.com/apache/iceberg/commit/449047381b8a698bc6c8f23d0f13b5ed9072f656", "message": "Refactor MergingSnapshotProducer into separate classes.", "committedDate": "2020-06-09T18:44:57Z", "type": "commit"}, {"oid": "30764a5006fb95c33cddf544b8840df3247c22a1", "url": "https://github.com/apache/iceberg/commit/30764a5006fb95c33cddf544b8840df3247c22a1", "message": "Fix checkstyle problems.", "committedDate": "2020-06-09T18:44:57Z", "type": "commit"}, {"oid": "30764a5006fb95c33cddf544b8840df3247c22a1", "url": "https://github.com/apache/iceberg/commit/30764a5006fb95c33cddf544b8840df3247c22a1", "message": "Fix checkstyle problems.", "committedDate": "2020-06-09T18:44:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1Njc2OQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437756769", "bodyText": "Did we migrate from CharSequenceWrapper on purpose here?", "author": "aokolnychyi", "createdAt": "2020-06-09T22:26:48Z", "path": "core/src/main/java/org/apache/iceberg/ManifestFilterManager.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.expressions.Evaluator;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.ManifestEvaluator;\n+import org.apache.iceberg.expressions.Projections;\n+import org.apache.iceberg.expressions.StrictMetricsEvaluator;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.util.CharSequenceSet;\n+import org.apache.iceberg.util.CharSequenceWrapper;\n+import org.apache.iceberg.util.ManifestFileUtil;\n+import org.apache.iceberg.util.StructLikeWrapper;\n+import org.apache.iceberg.util.Tasks;\n+import org.apache.iceberg.util.ThreadPools;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+abstract class ManifestFilterManager<F extends ContentFile<F>> {\n+  private static final Logger LOG = LoggerFactory.getLogger(ManifestFilterManager.class);\n+  private static final Joiner COMMA = Joiner.on(\",\");\n+\n+  protected static class DeleteException extends ValidationException {\n+    private final String partition;\n+\n+    private DeleteException(String partition) {\n+      super(\"Operation would delete existing data\");\n+      this.partition = partition;\n+    }\n+\n+    public String partition() {\n+      return partition;\n+    }\n+  }\n+\n+  private final Set<CharSequence> deletePaths = CharSequenceSet.empty();", "originalCommit": "30764a5006fb95c33cddf544b8840df3247c22a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1NzI4OQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437757289", "bodyText": "Oh, we actually switched to to our own CharSequenceSet. +1", "author": "aokolnychyi", "createdAt": "2020-06-09T22:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1Njc2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NDEzNA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437794134", "bodyText": "Yeah, and I think we should probably also create a StructLikeSet that does the same thing. That will help with equality deletes and clean things up a bit.", "author": "rdblue", "createdAt": "2020-06-10T00:26:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc1Njc2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc3NDA3NA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437774074", "bodyText": "We used to have a flag filterUpdated and take it into in apply. It seems okay to invalidate eagerly too.", "author": "aokolnychyi", "createdAt": "2020-06-09T23:18:13Z", "path": "core/src/main/java/org/apache/iceberg/ManifestFilterManager.java", "diffHunk": "@@ -0,0 +1,426 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.expressions.Evaluator;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.ManifestEvaluator;\n+import org.apache.iceberg.expressions.Projections;\n+import org.apache.iceberg.expressions.StrictMetricsEvaluator;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.util.CharSequenceSet;\n+import org.apache.iceberg.util.CharSequenceWrapper;\n+import org.apache.iceberg.util.ManifestFileUtil;\n+import org.apache.iceberg.util.StructLikeWrapper;\n+import org.apache.iceberg.util.Tasks;\n+import org.apache.iceberg.util.ThreadPools;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+abstract class ManifestFilterManager<F extends ContentFile<F>> {\n+  private static final Logger LOG = LoggerFactory.getLogger(ManifestFilterManager.class);\n+  private static final Joiner COMMA = Joiner.on(\",\");\n+\n+  protected static class DeleteException extends ValidationException {\n+    private final String partition;\n+\n+    private DeleteException(String partition) {\n+      super(\"Operation would delete existing data\");\n+      this.partition = partition;\n+    }\n+\n+    public String partition() {\n+      return partition;\n+    }\n+  }\n+\n+  private final Set<CharSequence> deletePaths = CharSequenceSet.empty();\n+  private final Set<StructLikeWrapper> deleteFilePartitions = Sets.newHashSet();\n+  private final Set<StructLikeWrapper> dropPartitions = Sets.newHashSet();\n+  private Expression deleteExpression = Expressions.alwaysFalse();\n+  private boolean hasPathOnlyDeletes = false;\n+  private boolean failAnyDelete = false;\n+  private boolean failMissingDeletePaths = false;\n+  private int duplicateDeleteCount = 0;\n+\n+  // cache filtered manifests to avoid extra work when commits fail.\n+  private final Map<ManifestFile, ManifestFile> filteredManifests = Maps.newConcurrentMap();\n+\n+  // tracking where files were deleted to validate retries quickly\n+  private final Map<ManifestFile, Iterable<F>> filteredManifestToDeletedFiles =\n+      Maps.newConcurrentMap();\n+\n+  protected abstract PartitionSpec spec(int specId);\n+  protected abstract void deleteFile(String location);\n+  protected abstract ManifestWriter<F> newManifestWriter(PartitionSpec spec);\n+  protected abstract ManifestReader<F> newManifestReader(ManifestFile manifest);\n+\n+  protected void failAnyDelete() {\n+    this.failAnyDelete = true;\n+  }\n+\n+  protected void failMissingDeletePaths() {\n+    this.failMissingDeletePaths = true;\n+  }\n+\n+  /**\n+   * Add a filter to match files to delete. A file will be deleted if all of the rows it contains\n+   * match this or any other filter passed to this method.\n+   *\n+   * @param expr an expression to match rows.\n+   */\n+  protected void deleteByRowFilter(Expression expr) {\n+    Preconditions.checkNotNull(expr, \"Cannot delete files using filter: null\");\n+    invalidateFilteredCache();", "originalCommit": "30764a5006fb95c33cddf544b8840df3247c22a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4MDUyNA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437780524", "bodyText": "nit: Would it make sense to move private classes to the bottom of the file so that people will focus on the main logic?", "author": "aokolnychyi", "createdAt": "2020-06-09T23:39:15Z", "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "diffHunk": "@@ -62,73 +41,91 @@\n import static org.apache.iceberg.TableProperties.SNAPSHOT_ID_INHERITANCE_ENABLED_DEFAULT;\n \n abstract class MergingSnapshotProducer<ThisT> extends SnapshotProducer<ThisT> {\n-  private static final Logger LOG = LoggerFactory.getLogger(MergingSnapshotProducer.class);\n+  private final String tableName;\n+  private final TableOperations ops;\n+  private final PartitionSpec spec;\n+  private final SnapshotSummary.Builder summaryBuilder = SnapshotSummary.builder();\n+  private final ManifestMergeManager<DataFile> mergeManager;\n+  private final ManifestFilterManager<DataFile> filterManager;\n+  private final boolean snapshotIdInheritanceEnabled;\n \n-  private static final Joiner COMMA = Joiner.on(\",\");\n+  private class DataFileFilterManager extends ManifestFilterManager<DataFile> {", "originalCommit": "30764a5006fb95c33cddf544b8840df3247c22a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc5NDQ3OQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437794479", "bodyText": "I do that in #1105.", "author": "rdblue", "createdAt": "2020-06-10T00:27:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzc4MDUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgzODc5NA==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r437838794", "bodyText": "This is because we don't merge the first bin, right?", "author": "chenjunjiedada", "createdAt": "2020-06-10T03:25:12Z", "path": "core/src/test/java/org/apache/iceberg/TestSequenceNumberForV2Table.java", "diffHunk": "@@ -272,7 +276,7 @@ public void testConcurrentTransaction() {\n     manifestFile = table.currentSnapshot().allManifests().stream()\n         .filter(manifest -> manifest.snapshotId() == commitId4)\n         .collect(Collectors.toList()).get(0);\n-    validateManifest(manifestFile, seqs(3, 2, 4), ids(commitId3, commitId2, commitId4), files(FILE_C, FILE_B, FILE_A));\n+    validateManifest(manifestFile, seqs(4), ids(commitId4), files(FILE_A), statuses(Status.DELETED));", "originalCommit": "30764a5006fb95c33cddf544b8840df3247c22a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIyMDc5MQ==", "url": "https://github.com/apache/iceberg/pull/1098#discussion_r438220791", "bodyText": "Yes, the manifest for commitId4 will not be combined with others and therefore will only contain FILE_A.", "author": "aokolnychyi", "createdAt": "2020-06-10T15:38:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgzODc5NA=="}], "type": "inlineReview"}]}