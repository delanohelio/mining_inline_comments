{"pr_number": 1497, "pr_title": "MR: apply row-level delete files when reading", "pr_createdAt": "2020-09-23T13:39:47Z", "pr_url": "https://github.com/apache/iceberg/pull/1497", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0ODkyMg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493948922", "bodyText": "Can you import this class directly to avoid so many changes in this file?", "author": "rdblue", "createdAt": "2020-09-23T23:16:58Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -148,15 +144,15 @@ public void testMixedPositionAndEqualityDeletes() throws IOException {\n     );\n \n     DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, dataSchema);\n+        table, Files.localOutput(temp.newFile()), TestHelpers.Row.of(0), dataDeletes, dataSchema);", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjA2Ng==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016066", "bodyText": "Done.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:26:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0ODkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0ODk3OQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493948979", "bodyText": "Nit: unnecessary whitespace change", "author": "rdblue", "createdAt": "2020-09-23T23:17:10Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -269,4 +265,5 @@ private StructLikeSet rowSetWithoutIds(int... idsToRemove) {\n         .forEach(set::add);\n     return set;\n   }\n+", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxODM0NQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494018345", "bodyText": "Removed.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:36:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0ODk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493949680", "bodyText": "While I would like to get the encryption manager and io changes in, I don't think that they should be mixed into this commit. Was it necessary to do this for some reason?", "author": "rdblue", "createdAt": "2020-09-23T23:19:39Z", "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -129,7 +133,7 @@\n           // TODO: We do not support residual evaluation for HIVE and PIG in memory data model yet\n           checkResiduals(task);\n         }\n-        splits.add(new IcebergSplit(conf, task));\n+        splits.add(new IcebergSplit(conf, task, table.io(), table.encryption()));", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk4NzY5Mg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493987692", "bodyText": "The GenericDeleteFilter constructor needs FileIO as parameter.", "author": "chenjunjiedada", "createdAt": "2020-09-24T01:30:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3OTA2Mw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496279063", "bodyText": "In that case, this can pass the FileIO somehow, or we can work on getting the other PR done before this one. But I don't think we should mix the two features together.", "author": "rdblue", "createdAt": "2020-09-28T22:53:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI4MTg0Mw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496281843", "bodyText": "For now, this could create a new HadoopFileIO and use that instead. That would be the easiest path forward.", "author": "rdblue", "createdAt": "2020-09-28T23:01:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjMwNTIxNw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496305217", "bodyText": "@holdenk just added a FileIO instance to this class, so you can use that instead of mixing the two PRs together. Thanks @holdenk!", "author": "rdblue", "createdAt": "2020-09-29T00:20:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM2NTEwNQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496365105", "bodyText": "Thank you @holdenk @rdblue. I updated this.", "author": "chenjunjiedada", "createdAt": "2020-09-29T04:04:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk0OTY4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MDYxMw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493950613", "bodyText": "Why not put the schema and spec in the parent class, DeletesReadTest? The data it generates is for this schema.", "author": "rdblue", "createdAt": "2020-09-23T23:22:47Z", "path": "data/src/test/java/org/apache/iceberg/data/GenericReaderDeletesTest.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.TestTables;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class GenericReaderDeletesTest extends DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjIzOA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016238", "bodyText": "Updated.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:27:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MDYxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTQzOA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493951438", "bodyText": "We prefer using Lists.newArrayList()", "author": "rdblue", "createdAt": "2020-09-23T23:25:20Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -92,6 +72,22 @@ public void testEqualityDeletes() throws IOException {\n     Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n   }\n \n+  protected void generateTestData() throws IOException {\n+    this.records = new ArrayList<>();", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjI2NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016264", "bodyText": "Done.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:27:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTQzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTUyMw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493951523", "bodyText": "I think a better way to break down the class would be to have an abstract Table createTable(String name, Schema, Spec) method. Then the table and dataFile fields don't need to be shared. I also don't think that there is a need to make records public either.", "author": "rdblue", "createdAt": "2020-09-23T23:25:40Z", "path": "data/src/test/java/org/apache/iceberg/data/GenericReaderDeletesTest.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.TestTables;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class GenericReaderDeletesTest extends DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n+\n+  @Before\n+  public void writeTestDataFile() throws IOException {\n+    File tableDir = temp.newFolder();\n+    tableDir.delete();\n+    this.table = TestTables.create(tableDir, \"test\", SCHEMA, SPEC, 2);", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjM2Mw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016363", "bodyText": "Make sense to me. Updated.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:27:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTUyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTk4Mg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493951982", "bodyText": "Why is this needed?", "author": "rdblue", "createdAt": "2020-09-23T23:27:12Z", "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -248,6 +258,26 @@ public void close() throws IOException {\n       return iterable;\n     }\n \n+    @SuppressWarnings(\"unchecked\")", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNTQ3Mg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494015472", "bodyText": "deletes.filter(...) needs this.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:24:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTk4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3ODYxOA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496278618", "bodyText": "Okay, makes sense.", "author": "rdblue", "createdAt": "2020-09-28T22:51:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MTk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MjIwMA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493952200", "bodyText": "Why not return deletes.filter(...) here? That would remove the need for iter and break.", "author": "rdblue", "createdAt": "2020-09-23T23:27:56Z", "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -248,6 +258,26 @@ public void close() throws IOException {\n       return iterable;\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n+    private CloseableIterable<T> open(FileScanTask currentTask, Schema readSchema) {\n+      CloseableIterable<T> iter;\n+      switch (inMemoryDataModel) {\n+        case PIG:\n+        case HIVE:\n+          // TODO implement value readers for Pig and Hive\n+          throw new UnsupportedOperationException(\"Avro support not yet supported for Pig and Hive\");\n+        case GENERIC:\n+          DeleteFilter deletes = new GenericDeleteFilter(io, currentTask, tableSchema, readSchema);\n+          Schema requiredSchema = deletes.requiredSchema();\n+          iter = deletes.filter(openTask(currentTask, requiredSchema));", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjQ3MQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016471", "bodyText": "Updated.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:28:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MjIwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MjYyOQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493952629", "bodyText": "Is there a simpler way to configure this? Normally, we build these using literals instead of a block of code.", "author": "rdblue", "createdAt": "2020-09-23T23:29:25Z", "path": "mr/src/test/java/org/apache/iceberg/mr/TestMrReadDeletes.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Locale;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.data.DeletesReadTest;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+@RunWith(Parameterized.class)\n+public class TestMrReadDeletes extends DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n+\n+  // parametrized variables\n+  private final TestIcebergInputFormats.TestInputFormat.Factory<Record> testInputFormat;\n+  private final FileFormat fileFormat;\n+\n+  @Parameterized.Parameters\n+  public static Object[][] parameters() {\n+    Object[][] parameters = new Object[TestIcebergInputFormats.TESTED_INPUT_FORMATS.size() *\n+        TestIcebergInputFormats.TESTED_FILE_FORMATS.size()][2];\n+\n+    int idx = 0;\n+\n+    for (TestIcebergInputFormats.TestInputFormat.Factory<Record> inputFormat :\n+        TestIcebergInputFormats.TESTED_INPUT_FORMATS) {\n+      for (String fileFormat : TestIcebergInputFormats.TESTED_FILE_FORMATS) {\n+        parameters[idx++] = new Object[] {inputFormat, fileFormat};\n+      }\n+    }\n+\n+    return parameters;", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNjU2OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494016568", "bodyText": "Yes, I just updated it.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:28:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1MjYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1NDM0NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r493954344", "bodyText": "This method is what reads the rows from the table using Spark. Deleting this method and using the one in DeletesReadTest makes this test suite use the exact same read path as the generics -- IcebergGenerics.\nYou can probably make this method abstract and implement it in both classes to get around this. You'll also need to implement a read using the input format or Hive runner to test the Hive code.", "author": "rdblue", "createdAt": "2020-09-23T23:35:08Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java", "diffHunk": "@@ -93,212 +102,4 @@ public void createTable() throws IOException {\n   public void dropTable() {\n     catalog.dropTable(TableIdentifier.of(\"default\", \"table\"));\n   }\n-\n-  @Test\n-  public void testEqualityDeletes() throws IOException {\n-    Schema deleteRowSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(deleteRowSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testEqualityDeletesWithRequiredEqColumn() throws IOException {\n-    Schema deleteRowSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(deleteRowSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = selectColumns(rowSetWithoutIds(29, 89, 122), \"id\");\n-    StructLikeSet actual = rowSet(table, \"id\"); // data is added by the reader to apply the eq deletes\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testPositionDeletes() throws IOException {\n-    List<Pair<CharSequence, Long>> deletes = Lists.newArrayList(\n-        Pair.of(dataFile.path(), 0L), // id = 29\n-        Pair.of(dataFile.path(), 3L), // id = 89\n-        Pair.of(dataFile.path(), 6L) // id = 122\n-    );\n-\n-    DeleteFile posDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), deletes);\n-\n-    table.newRowDelta()\n-        .addDeletes(posDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testMixedPositionAndEqualityDeletes() throws IOException {\n-    Schema dataSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(dataSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, dataSchema);\n-\n-    List<Pair<CharSequence, Long>> deletes = Lists.newArrayList(\n-        Pair.of(dataFile.path(), 3L), // id = 89\n-        Pair.of(dataFile.path(), 5L) // id = 121\n-    );\n-\n-    DeleteFile posDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), deletes);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .addDeletes(posDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 121, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testMultipleEqualityDeleteSchemas() throws IOException {\n-    Schema dataSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(dataSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile dataEqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, dataSchema);\n-\n-    Schema idSchema = table.schema().select(\"id\");\n-    Record idDelete = GenericRecord.create(idSchema);\n-    List<Record> idDeletes = Lists.newArrayList(\n-        idDelete.copy(\"id\", 121), // id = 121\n-        idDelete.copy(\"id\", 29) // id = 29\n-    );\n-\n-    DeleteFile idEqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), idDeletes, idSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(dataEqDeletes)\n-        .addDeletes(idEqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 121, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testEqualityDeleteByNull() throws IOException {\n-    // data is required in the test table; make it optional for this test\n-    table.updateSchema()\n-        .makeColumnOptional(\"data\")\n-        .commit();\n-\n-    // add a new data file with a record where data is null\n-    Record record = GenericRecord.create(table.schema());\n-    DataFile dataFileWithNull = FileHelpers.writeDataFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0),\n-        Lists.newArrayList(record.copy(\"id\", 131, \"data\", null)));\n-\n-    table.newAppend()\n-        .appendFile(dataFileWithNull)\n-        .commit();\n-\n-    // delete where data is null\n-    Schema dataSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(dataSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", null) // id = 131\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, dataSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(131);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  private static StructLikeSet rowSet(Table table) {\n-    return rowSet(table, \"*\");\n-  }\n-\n-  private static StructLikeSet rowSet(Table table, String... columns) {", "originalCommit": "994b230a0c2c109fbb2d91f87362ab2141f87291", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAxNTk2OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r494015968", "bodyText": "Sorry, I missed this. I just added this back and also use input format to read records.", "author": "chenjunjiedada", "createdAt": "2020-09-24T03:26:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk1NDM0NA=="}], "type": "inlineReview"}, {"oid": "84310d9737e3fc2957c1d3edc2e5498c58340300", "url": "https://github.com/apache/iceberg/commit/84310d9737e3fc2957c1d3edc2e5498c58340300", "message": "address comments", "committedDate": "2020-09-24T03:30:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NDg0Nw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496274847", "bodyText": "Why is this public and not protected to expose it to child classes?", "author": "rdblue", "createdAt": "2020-09-28T22:40:12Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,49 +25,45 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n import org.junit.Assert;\n-import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n \n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n \n-  @Before\n-  public void writeTestDataFile() throws IOException {\n-    this.records = Lists.newArrayList();\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n \n-    // records all use IDs that are in bucket id_bucket=0\n-    GenericRecord record = GenericRecord.create(table.schema());\n-    records.add(record.copy(\"id\", 29, \"data\", \"a\"));\n-    records.add(record.copy(\"id\", 43, \"data\", \"b\"));\n-    records.add(record.copy(\"id\", 61, \"data\", \"c\"));\n-    records.add(record.copy(\"id\", 89, \"data\", \"d\"));\n-    records.add(record.copy(\"id\", 100, \"data\", \"e\"));\n-    records.add(record.copy(\"id\", 121, \"data\", \"f\"));\n-    records.add(record.copy(\"id\", 122, \"data\", \"g\"));\n+  protected Table table;\n+  protected DataFile dataFile;\n \n-    this.dataFile = FileHelpers.writeDataFile(table, Files.localOutput(temp.newFile()), Row.of(0), records);\n+  private List<Record> records;\n \n-    table.newAppend()\n-        .appendFile(dataFile)\n-        .commit();\n-  }\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  public abstract Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException;", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1NjYxNw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496456617", "bodyText": "Updated to protected.", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:51:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NDg0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NTM0Nw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496275347", "bodyText": "Why is this @Before here and not in the base class?", "author": "rdblue", "createdAt": "2020-09-28T22:41:49Z", "path": "data/src/test/java/org/apache/iceberg/data/GenericReaderDeletesTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TestTables;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.util.StructLikeSet;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+public class GenericReaderDeletesTest extends DeletesReadTest {\n+\n+  @Override\n+  public Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException {\n+    File tableDir = temp.newFolder();\n+    tableDir.delete();\n+\n+    return TestTables.create(tableDir, name, schema, spec, 2);\n+  }\n+\n+  @Override\n+  public StructLikeSet rowSet(Table table, String... columns) throws IOException {\n+    StructLikeSet set = StructLikeSet.create(table.schema().asStruct());\n+    try (CloseableIterable<Record> reader = IcebergGenerics.read(table).select(columns).build()) {\n+      reader.forEach(set::add);\n+    }\n+    return set;\n+  }\n+\n+  @Before\n+  public void writeTestDataFile() throws IOException {\n+    this.table = createTable(\"test\", SCHEMA, SPEC);\n+    generateTestData();\n+    table.newAppend()\n+        .appendFile(dataFile)\n+        .commit();", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1Njc4NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496456784", "bodyText": "Updated to the base class.", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:51:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NTM0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NTU2NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496275564", "bodyText": "Isn't this identical to the one in the generics test? I think this should be in the base class instead.", "author": "rdblue", "createdAt": "2020-09-28T22:42:27Z", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkReaderDeletes.java", "diffHunk": "@@ -20,285 +20,111 @@\n package org.apache.iceberg.spark.source;\n \n import java.io.IOException;\n-import java.util.List;\n-import java.util.Set;\n+import org.apache.hadoop.hive.conf.HiveConf;\n import org.apache.iceberg.BaseTable;\n-import org.apache.iceberg.DataFile;\n-import org.apache.iceberg.DeleteFile;\n-import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n-import org.apache.iceberg.TestHelpers.Row;\n+import org.apache.iceberg.catalog.Namespace;\n import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.data.FileHelpers;\n-import org.apache.iceberg.data.GenericRecord;\n-import org.apache.iceberg.data.Record;\n-import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n-import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.data.DeletesReadTest;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.hive.HiveCatalog;\n+import org.apache.iceberg.hive.TestHiveMetastore;\n import org.apache.iceberg.spark.SparkStructLike;\n-import org.apache.iceberg.spark.SparkTestBase;\n import org.apache.iceberg.types.Types;\n-import org.apache.iceberg.util.ArrayUtil;\n-import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n-import org.apache.iceberg.util.StructProjection;\n import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.internal.SQLConf;\n import org.junit.After;\n-import org.junit.Assert;\n+import org.junit.AfterClass;\n import org.junit.Before;\n-import org.junit.Rule;\n-import org.junit.Test;\n-import org.junit.rules.TemporaryFolder;\n+import org.junit.BeforeClass;\n \n-public abstract class TestSparkReaderDeletes extends SparkTestBase {\n-  private static final Schema SCHEMA = new Schema(\n-      Types.NestedField.required(1, \"id\", Types.IntegerType.get()),\n-      Types.NestedField.required(2, \"data\", Types.StringType.get()));\n-  private Table table = null;\n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+import static org.apache.hadoop.hive.conf.HiveConf.ConfVars.METASTOREURIS;\n \n-  @Rule\n-  public TemporaryFolder temp = new TemporaryFolder();\n+public abstract class TestSparkReaderDeletes extends DeletesReadTest {\n \n-  @Before\n-  public void createTable() throws IOException {\n-    this.table = catalog.createTable(TableIdentifier.of(\"default\", \"table\"), SCHEMA);\n-    TableOperations ops = ((BaseTable) table).operations();\n-    TableMetadata meta = ops.current();\n-    ops.commit(meta, meta.upgradeToFormatVersion(2));\n-\n-    this.records = Lists.newArrayList();\n+  private static TestHiveMetastore metastore = null;\n+  protected static SparkSession spark = null;\n+  protected static HiveCatalog catalog = null;\n \n-    // records all use IDs that are in bucket id_bucket=0\n-    GenericRecord record = GenericRecord.create(table.schema());\n-    records.add(record.copy(\"id\", 29, \"data\", \"a\"));\n-    records.add(record.copy(\"id\", 43, \"data\", \"b\"));\n-    records.add(record.copy(\"id\", 61, \"data\", \"c\"));\n-    records.add(record.copy(\"id\", 89, \"data\", \"d\"));\n-    records.add(record.copy(\"id\", 100, \"data\", \"e\"));\n-    records.add(record.copy(\"id\", 121, \"data\", \"f\"));\n-    records.add(record.copy(\"id\", 122, \"data\", \"g\"));\n+  @BeforeClass\n+  public static void startMetastoreAndSpark() {\n+    metastore = new TestHiveMetastore();\n+    metastore.start();\n+    HiveConf hiveConf = metastore.hiveConf();\n \n-    this.dataFile = FileHelpers.writeDataFile(table, Files.localOutput(temp.newFile()), Row.of(0), records);\n+    spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .config(SQLConf.PARTITION_OVERWRITE_MODE().key(), \"dynamic\")\n+        .config(\"spark.hadoop.\" + METASTOREURIS.varname, hiveConf.get(METASTOREURIS.varname))\n+        .enableHiveSupport()\n+        .getOrCreate();\n \n-    table.newAppend()\n-        .appendFile(dataFile)\n-        .commit();\n-  }\n+    catalog = new HiveCatalog(spark.sessionState().newHadoopConf());\n \n-  @After\n-  public void dropTable() {\n-    catalog.dropTable(TableIdentifier.of(\"default\", \"table\"));\n+    try {\n+      catalog.createNamespace(Namespace.of(\"default\"));\n+    } catch (AlreadyExistsException ignored) {\n+      // the default namespace already exists. ignore the create error\n+    }\n   }\n \n-  @Test\n-  public void testEqualityDeletes() throws IOException {\n-    Schema deleteRowSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(deleteRowSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n+  @AfterClass\n+  public static void stopMetastoreAndSpark() {\n+    catalog.close();\n+    catalog = null;\n+    metastore.stop();\n+    metastore = null;\n+    spark.stop();\n+    spark = null;\n   }\n \n-  @Test\n-  public void testEqualityDeletesWithRequiredEqColumn() throws IOException {\n-    Schema deleteRowSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(deleteRowSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n-\n-    table.newRowDelta()\n-        .addDeletes(eqDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = selectColumns(rowSetWithoutIds(29, 89, 122), \"id\");\n-    StructLikeSet actual = rowSet(table, \"id\"); // data is added by the reader to apply the eq deletes\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testPositionDeletes() throws IOException {\n-    List<Pair<CharSequence, Long>> deletes = Lists.newArrayList(\n-        Pair.of(dataFile.path(), 0L), // id = 29\n-        Pair.of(dataFile.path(), 3L), // id = 89\n-        Pair.of(dataFile.path(), 6L) // id = 122\n-    );\n-\n-    DeleteFile posDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), deletes);\n-\n-    table.newRowDelta()\n-        .addDeletes(posDeletes)\n-        .commit();\n-\n-    StructLikeSet expected = rowSetWithoutIds(29, 89, 122);\n-    StructLikeSet actual = rowSet(table);\n-\n-    Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n-  }\n-\n-  @Test\n-  public void testMixedPositionAndEqualityDeletes() throws IOException {\n-    Schema dataSchema = table.schema().select(\"data\");\n-    Record dataDelete = GenericRecord.create(dataSchema);\n-    List<Record> dataDeletes = Lists.newArrayList(\n-        dataDelete.copy(\"data\", \"a\"), // id = 29\n-        dataDelete.copy(\"data\", \"d\"), // id = 89\n-        dataDelete.copy(\"data\", \"g\") // id = 122\n-    );\n-\n-    DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, dataSchema);\n-\n-    List<Pair<CharSequence, Long>> deletes = Lists.newArrayList(\n-        Pair.of(dataFile.path(), 3L), // id = 89\n-        Pair.of(dataFile.path(), 5L) // id = 121\n-    );\n+  @Before\n+  public void prepareData() throws IOException {\n+    this.table = createTable(\"table\", SCHEMA, SPEC);", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1NTMzOA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496455338", "bodyText": "Make sense, Updated", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3NTU2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3ODg0OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496278848", "bodyText": "This error message is for Avro, but I think it should be that Pig and Hive are not supported for any format.", "author": "rdblue", "createdAt": "2020-09-28T22:52:33Z", "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -248,6 +258,22 @@ public void close() throws IOException {\n       return iterable;\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n+    private CloseableIterable<T> open(FileScanTask currentTask, Schema readSchema) {\n+      switch (inMemoryDataModel) {\n+        case PIG:\n+        case HIVE:\n+          // TODO implement value readers for Pig and Hive\n+          throw new UnsupportedOperationException(\"Avro support not yet supported for Pig and Hive\");", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1Njk2OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496456968", "bodyText": "This is a copy-paste issue, just updated.", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:52:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3ODg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3OTI5NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496279294", "bodyText": "This constructor should be just below the parameters, and then abstract method implementations should come just afterwards.", "author": "rdblue", "createdAt": "2020-09-28T22:54:01Z", "path": "mr/src/test/java/org/apache/iceberg/mr/TestMrReadDeletes.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.data.DeletesReadTest;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.util.StructLikeSet;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+@RunWith(Parameterized.class)\n+public class TestMrReadDeletes extends DeletesReadTest {\n+  private TestHelper helper;\n+  private InputFormatConfig.ConfigBuilder builder;\n+  private Configuration conf;\n+\n+  // parametrized variables\n+  private final TestIcebergInputFormats.TestInputFormat.Factory<Record> testInputFormat;\n+  private final FileFormat fileFormat;\n+\n+  @Parameterized.Parameters\n+  public static Object[][] parameters() {\n+    return new Object[][] {\n+        new Object[] { \"IcebergInputFormat\", FileFormat.PARQUET },\n+        new Object[] { \"IcebergInputFormat\", FileFormat.AVRO },\n+        new Object[] { \"IcebergInputFormat\", FileFormat.ORC },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.PARQUET },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.AVRO },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.ORC },\n+    };\n+  }\n+\n+  @Override\n+  public Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException {\n+    Table table;\n+    conf = new Configuration();\n+    HadoopTables tables = new HadoopTables(conf);\n+    File location = temp.newFolder(testInputFormat.name(), fileFormat.name());\n+    Assert.assertTrue(location.delete());\n+    helper = new TestHelper(conf, tables, location.toString(), schema, spec, fileFormat, temp);\n+    table = helper.createTable();\n+\n+    TableOperations ops = ((BaseTable) table).operations();\n+    TableMetadata meta = ops.current();\n+    ops.commit(meta, meta.upgradeToFormatVersion(2));\n+\n+    return table;\n+  }\n+\n+  @Override\n+  public StructLikeSet rowSet(Table table, String... columns) {\n+    Schema projected = table.schema().select(columns);\n+    StructLikeSet set = StructLikeSet.create(projected.asStruct());\n+    set.addAll(testInputFormat.create(builder.project(projected).conf()).getRecords());\n+\n+    return set;\n+  }\n+\n+  public TestMrReadDeletes(String inputFormat, FileFormat fileFormat) {", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1NzAzNg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496457036", "bodyText": "Fixed.", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:52:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3OTI5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3OTcyNQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496279725", "bodyText": "Why does this create a new configuration?", "author": "rdblue", "createdAt": "2020-09-28T22:55:18Z", "path": "mr/src/test/java/org/apache/iceberg/mr/TestMrReadDeletes.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.data.DeletesReadTest;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.util.StructLikeSet;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+@RunWith(Parameterized.class)\n+public class TestMrReadDeletes extends DeletesReadTest {\n+  private TestHelper helper;\n+  private InputFormatConfig.ConfigBuilder builder;\n+  private Configuration conf;\n+\n+  // parametrized variables\n+  private final TestIcebergInputFormats.TestInputFormat.Factory<Record> testInputFormat;\n+  private final FileFormat fileFormat;\n+\n+  @Parameterized.Parameters\n+  public static Object[][] parameters() {\n+    return new Object[][] {\n+        new Object[] { \"IcebergInputFormat\", FileFormat.PARQUET },\n+        new Object[] { \"IcebergInputFormat\", FileFormat.AVRO },\n+        new Object[] { \"IcebergInputFormat\", FileFormat.ORC },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.PARQUET },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.AVRO },\n+        new Object[] { \"MapredIcebergInputFormat\", FileFormat.ORC },\n+    };\n+  }\n+\n+  @Override\n+  public Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException {\n+    Table table;\n+    conf = new Configuration();", "originalCommit": "84310d9737e3fc2957c1d3edc2e5498c58340300", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjQ1ODI3OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496458278", "bodyText": "Hmm, it should be allocated once. I moved allocation to class level.", "author": "chenjunjiedada", "createdAt": "2020-09-29T06:55:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI3OTcyNQ=="}], "type": "inlineReview"}, {"oid": "e1102d746051e804b76c4bd7c32a942011a7d8c3", "url": "https://github.com/apache/iceberg/commit/e1102d746051e804b76c4bd7c32a942011a7d8c3", "message": "address comments", "committedDate": "2020-09-29T06:28:08Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDIwNA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496880204", "bodyText": "Why are these protected and not private?\nMy earlier suggestion was to avoid sharing fields with subclasses because the tests are all in this class. Only creating a table and reading it needs to be customized by subclasses, and we can pass in anything necessary to do that.", "author": "rdblue", "createdAt": "2020-09-29T16:33:21Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,53 +25,68 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n+import org.junit.After;\n import org.junit.Assert;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n \n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n \n-  @Before\n-  public void writeTestDataFile() throws IOException {\n-    this.records = Lists.newArrayList();\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n \n-    // records all use IDs that are in bucket id_bucket=0\n-    GenericRecord record = GenericRecord.create(table.schema());\n-    records.add(record.copy(\"id\", 29, \"data\", \"a\"));\n-    records.add(record.copy(\"id\", 43, \"data\", \"b\"));\n-    records.add(record.copy(\"id\", 61, \"data\", \"c\"));\n-    records.add(record.copy(\"id\", 89, \"data\", \"d\"));\n-    records.add(record.copy(\"id\", 100, \"data\", \"e\"));\n-    records.add(record.copy(\"id\", 121, \"data\", \"f\"));\n-    records.add(record.copy(\"id\", 122, \"data\", \"g\"));\n+  protected final String testTableName = \"test\";\n+  protected Table testTable;\n+  protected DataFile dataFile;", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEzNzc1NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497137754", "bodyText": "It should be private now. Updated.", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:28:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MDIwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MjIxOQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496882219", "bodyText": "I think this method should no longer exist, and there is no reason for it to be accessible to subclasses. It is also not a good idea to write methods like this one that have assumptions about other variables and operate by creating side-effects. It is less of a problem now that it is not called by subclasses. Now, there is just little reason for it to exist when this could be moved into the @Before method.", "author": "rdblue", "createdAt": "2020-09-29T16:36:18Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -80,21 +95,37 @@ public void testEqualityDeletes() throws IOException {\n     );\n \n     DeleteFile eqDeletes = FileHelpers.writeDeleteFile(\n-        table, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n+        testTable, Files.localOutput(temp.newFile()), Row.of(0), dataDeletes, deleteRowSchema);\n \n-    table.newRowDelta()\n+    testTable.newRowDelta()\n         .addDeletes(eqDeletes)\n         .commit();\n \n     StructLikeSet expected = rowSetWithoutIds(29, 89, 122);\n-    StructLikeSet actual = rowSet(table);\n+    StructLikeSet actual = rowSet(testTable);\n \n     Assert.assertEquals(\"Table should contain expected rows\", expected, actual);\n   }\n \n+  protected void generateTestData() throws IOException {", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEzODQ2Mw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497138463", "bodyText": "Okay, make sense to me. Moved to @Before.", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:29:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MjIxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MjQ5Mw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496882493", "bodyText": "Renaming table -> testTable introduces unnecessary changes and doesn't add much value. What was the rationale for doing this?", "author": "rdblue", "createdAt": "2020-09-29T16:36:44Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,53 +25,68 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n+import org.junit.After;\n import org.junit.Assert;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n \n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n \n-  @Before\n-  public void writeTestDataFile() throws IOException {\n-    this.records = Lists.newArrayList();\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n \n-    // records all use IDs that are in bucket id_bucket=0\n-    GenericRecord record = GenericRecord.create(table.schema());\n-    records.add(record.copy(\"id\", 29, \"data\", \"a\"));\n-    records.add(record.copy(\"id\", 43, \"data\", \"b\"));\n-    records.add(record.copy(\"id\", 61, \"data\", \"c\"));\n-    records.add(record.copy(\"id\", 89, \"data\", \"d\"));\n-    records.add(record.copy(\"id\", 100, \"data\", \"e\"));\n-    records.add(record.copy(\"id\", 121, \"data\", \"f\"));\n-    records.add(record.copy(\"id\", 122, \"data\", \"g\"));\n+  protected final String testTableName = \"test\";\n+  protected Table testTable;\n+  protected DataFile dataFile;\n+\n+  private List<Record> records;\n \n-    this.dataFile = FileHelpers.writeDataFile(table, Files.localOutput(temp.newFile()), Row.of(0), records);\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n \n-    table.newAppend()\n+  @Before\n+  public void prepareData() throws IOException {\n+    this.testTable = createTable(testTableName, SCHEMA, SPEC);\n+    generateTestData();\n+    testTable.newAppend()\n         .appendFile(dataFile)\n         .commit();\n   }\n \n+  @After\n+  public void cleanup() throws IOException {\n+    dropTable(testTableName);\n+  }\n+\n+  protected abstract Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException;\n+\n+  protected abstract void dropTable(String name) throws IOException;\n+\n   @Test\n   public void testEqualityDeletes() throws IOException {\n-    Schema deleteRowSchema = table.schema().select(\"data\");\n+    Schema deleteRowSchema = testTable.schema().select(\"data\");", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEzOTYyNA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497139624", "bodyText": "The checkstyle complaints hidden field since the rowSet use the parameter name table. I just reverted the changes back to change rowSet parameter name.", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4MjQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzE4NQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496887185", "bodyText": "This shouldn't be public when the abstract method is protected.", "author": "rdblue", "createdAt": "2020-09-29T16:44:02Z", "path": "data/src/test/java/org/apache/iceberg/data/GenericReaderDeletesTest.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TestTables;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.util.StructLikeSet;\n+import org.junit.After;\n+\n+public class GenericReaderDeletesTest extends DeletesReadTest {\n+\n+  @Override\n+  public Table createTable(String name, Schema schema, PartitionSpec spec) throws IOException {", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEzOTc4OQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497139789", "bodyText": "Fixed.", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:31:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzE4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzgxMA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496887810", "bodyText": "This should be clear that Pig and Hive object models are not supported. Pig and Hive engines can read using generics.", "author": "rdblue", "createdAt": "2020-09-29T16:44:55Z", "path": "mr/src/main/java/org/apache/iceberg/mr/mapreduce/IcebergInputFormat.java", "diffHunk": "@@ -250,6 +252,22 @@ public void close() throws IOException {\n       return iterable;\n     }\n \n+    @SuppressWarnings(\"unchecked\")\n+    private CloseableIterable<T> open(FileScanTask currentTask, Schema readSchema) {\n+      switch (inMemoryDataModel) {\n+        case PIG:\n+        case HIVE:\n+          // TODO implement value readers for Pig and Hive\n+          throw new UnsupportedOperationException(\"Pig and Hive are not supported for any format\");", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEzOTkxNg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497139916", "bodyText": "Updated.", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4NzgxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4OTQ4Mg==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r496889482", "bodyText": "Why was this changed to public?", "author": "rdblue", "createdAt": "2020-09-29T16:47:25Z", "path": "mr/src/test/java/org/apache/iceberg/mr/TestIcebergInputFormats.java", "diffHunk": "@@ -370,7 +370,7 @@ public void testCustomCatalog() throws IOException {\n     testInputFormat.create(builder.conf()).validate(expectedRecords);\n   }\n \n-  private abstract static class TestInputFormat<T> {\n+  public abstract static class TestInputFormat<T> {", "originalCommit": "1cbaaa0ce100ddf1f4f4b78548209ce2fae48789", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzE0MTI1Nw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497141257", "bodyText": "This is because the testInputFormat is type of TestIcebergInputFormats.TestInputFormat.Factory<Record> which needs to access the TestInputFormat", "author": "chenjunjiedada", "createdAt": "2020-09-29T23:33:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4OTQ4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzMwMzMwMw==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r497303303", "bodyText": "I tried to minimize the changes to access modifiers in TestIcebergInputFormat, the last place that needs the modifier of TestInputFormat to be public is getRecords method.", "author": "chenjunjiedada", "createdAt": "2020-09-30T07:39:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njg4OTQ4Mg=="}], "type": "inlineReview"}, {"oid": "0a952f9954e4b65282643f95c8cb98e9e9e2890a", "url": "https://github.com/apache/iceberg/commit/0a952f9954e4b65282643f95c8cb98e9e9e2890a", "message": "address comments", "committedDate": "2020-09-29T23:37:04Z", "type": "forcePushed"}, {"oid": "f5d382da0cb71892efc7aa9eb156a19fe9a4ab3e", "url": "https://github.com/apache/iceberg/commit/f5d382da0cb71892efc7aa9eb156a19fe9a4ab3e", "message": "address comments", "committedDate": "2020-09-30T00:06:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM3OTI0OA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r498379248", "bodyText": "Nit: whitespace-only change.", "author": "rdblue", "createdAt": "2020-10-01T16:39:38Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -63,12 +82,20 @@ public void writeTestDataFile() throws IOException {\n     records.add(record.copy(\"id\", 122, \"data\", \"g\"));\n \n     this.dataFile = FileHelpers.writeDataFile(table, Files.localOutput(temp.newFile()), Row.of(0), records);\n-", "originalCommit": "ddd747d4b21bd1531e3344dfd0b40807df0defef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM3OTUwNQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r498379505", "bodyText": "Nit: unnecessary method renames cause more changed lines than needed.", "author": "rdblue", "createdAt": "2020-10-01T16:40:06Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,31 +25,50 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n+import org.junit.After;\n import org.junit.Assert;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n+\n+  protected final String testTableName = \"test\";\n+  protected Table table;\n \n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+  private DataFile dataFile;\n+  private List<Record> records;\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n \n   @Before\n-  public void writeTestDataFile() throws IOException {\n+  public void prepareData() throws IOException {", "originalCommit": "ddd747d4b21bd1531e3344dfd0b40807df0defef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM3OTg2NA==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r498379864", "bodyText": "Changing the order of these two lines and dropping the default also causes unnecessary changes.", "author": "rdblue", "createdAt": "2020-10-01T16:40:42Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,31 +25,50 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n+import org.junit.After;\n import org.junit.Assert;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n+\n+  protected final String testTableName = \"test\";\n+  protected Table table;\n \n-  private List<Record> records = null;\n-  private DataFile dataFile = null;\n+  private DataFile dataFile;\n+  private List<Record> records;", "originalCommit": "ddd747d4b21bd1531e3344dfd0b40807df0defef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODM4Mzc1MQ==", "url": "https://github.com/apache/iceberg/pull/1497#discussion_r498383751", "bodyText": "I think this should be private. If it is needed by subclases, it should be passed into methods, not shared. I think this is only used by Spark, so it should be easy to fix.", "author": "rdblue", "createdAt": "2020-10-01T16:47:59Z", "path": "data/src/test/java/org/apache/iceberg/data/DeletesReadTest.java", "diffHunk": "@@ -25,31 +25,50 @@\n import org.apache.iceberg.DataFile;\n import org.apache.iceberg.DeleteFile;\n import org.apache.iceberg.Files;\n+import org.apache.iceberg.PartitionSpec;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.Table;\n-import org.apache.iceberg.TableTestBase;\n import org.apache.iceberg.TestHelpers.Row;\n-import org.apache.iceberg.io.CloseableIterable;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Types;\n import org.apache.iceberg.util.ArrayUtil;\n import org.apache.iceberg.util.Pair;\n import org.apache.iceberg.util.StructLikeSet;\n import org.apache.iceberg.util.StructProjection;\n+import org.junit.After;\n import org.junit.Assert;\n import org.junit.Before;\n+import org.junit.Rule;\n import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n \n-public class TestGenericReaderDeletes extends TableTestBase {\n-  public TestGenericReaderDeletes() {\n-    super(2 /* format v2 with delete files */);\n-  }\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class DeletesReadTest {\n+  // Schema passed to create tables\n+  public static final Schema SCHEMA = new Schema(\n+      required(1, \"id\", Types.IntegerType.get()),\n+      required(2, \"data\", Types.StringType.get())\n+  );\n+\n+  // Partition spec used to create tables\n+  public static final PartitionSpec SPEC = PartitionSpec.builderFor(SCHEMA)\n+      .bucket(\"data\", 16)\n+      .build();\n+\n+  protected final String testTableName = \"test\";", "originalCommit": "ddd747d4b21bd1531e3344dfd0b40807df0defef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8d1053ba3adb98f7924396a855d39fdb5a6fa875", "url": "https://github.com/apache/iceberg/commit/8d1053ba3adb98f7924396a855d39fdb5a6fa875", "message": "MR: apply row-level delete files when reeding", "committedDate": "2020-10-02T13:51:25Z", "type": "commit"}, {"oid": "d37e9e091fffa30ec49434e18b7d54d230f7b561", "url": "https://github.com/apache/iceberg/commit/d37e9e091fffa30ec49434e18b7d54d230f7b561", "message": "address comments", "committedDate": "2020-10-02T13:51:25Z", "type": "commit"}, {"oid": "a0b9a69e746b17a267926e359a297c3f4ffce098", "url": "https://github.com/apache/iceberg/commit/a0b9a69e746b17a267926e359a297c3f4ffce098", "message": "address comments", "committedDate": "2020-10-02T13:51:50Z", "type": "commit"}, {"oid": "48bbec703b5f05703a8458c0d35ed0597e090c11", "url": "https://github.com/apache/iceberg/commit/48bbec703b5f05703a8458c0d35ed0597e090c11", "message": "update naming", "committedDate": "2020-10-02T13:51:50Z", "type": "commit"}, {"oid": "389bbd4256bb093f921db7a4c5e3cf53f1d2c21b", "url": "https://github.com/apache/iceberg/commit/389bbd4256bb093f921db7a4c5e3cf53f1d2c21b", "message": "address comments", "committedDate": "2020-10-02T13:51:50Z", "type": "commit"}, {"oid": "ef7e00606bb2f1c4ee97fe7367a70bb7c62af73b", "url": "https://github.com/apache/iceberg/commit/ef7e00606bb2f1c4ee97fe7367a70bb7c62af73b", "message": "refactor unit test constructor", "committedDate": "2020-10-02T13:51:50Z", "type": "commit"}, {"oid": "f20d63354fa27d99c3a73b4375d42d6ad323d4e5", "url": "https://github.com/apache/iceberg/commit/f20d63354fa27d99c3a73b4375d42d6ad323d4e5", "message": "minor fixes", "committedDate": "2020-10-02T13:53:32Z", "type": "commit"}, {"oid": "f20d63354fa27d99c3a73b4375d42d6ad323d4e5", "url": "https://github.com/apache/iceberg/commit/f20d63354fa27d99c3a73b4375d42d6ad323d4e5", "message": "minor fixes", "committedDate": "2020-10-02T13:53:32Z", "type": "forcePushed"}, {"oid": "01e21552ade08fc079c5641b89ed625af71a3c46", "url": "https://github.com/apache/iceberg/commit/01e21552ade08fc079c5641b89ed625af71a3c46", "message": "Fix remaining issues. (#5)", "committedDate": "2020-10-03T00:47:28Z", "type": "commit"}, {"oid": "32db3c428902e00f9533db587e829dbf48792b0a", "url": "https://github.com/apache/iceberg/commit/32db3c428902e00f9533db587e829dbf48792b0a", "message": "Merge branch 'master' into apply-row-level-deletes-when-reading", "committedDate": "2020-10-03T00:48:49Z", "type": "commit"}]}