{"pr_number": 1177, "pr_title": "Add schema upsert API for adding new fields and updating type (where applicable) using an input schema", "pr_createdAt": "2020-07-07T19:50:51Z", "pr_url": "https://github.com/apache/iceberg/pull/1177", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5NzM1Mw==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r451297353", "bodyText": "We may also need to handle renames and deletes. These can be detected if we do the updates [additions, type widening and renames and deletes] using field ids instead of names. This was one of the main comments by @rdblue  on #759", "author": "rdsr", "createdAt": "2020-07-08T05:47:57Z", "path": "core/src/main/java/org/apache/iceberg/SchemaUpdate.java", "diffHunk": "@@ -308,6 +314,159 @@ public UpdateSchema moveAfter(String name, String afterName) {\n     return this;\n   }\n \n+  @Override\n+  public UpdateSchema upsertSchema(Schema newSchema) {\n+    TypeUtil.visit(newSchema, new ApplyUpdates(this, schema));\n+    return this;\n+  }\n+\n+  private static class ApplyUpdates extends TypeUtil.SchemaVisitor<Void> {\n+    private static final Joiner DOT = Joiner.on(\".\");\n+    private final Deque<String> fieldNames = Lists.newLinkedList();\n+    private NestedField currentField = null;\n+\n+    private final Schema baseSchema;\n+    private final UpdateSchema api;\n+    private final Map<String, Integer> indexByName;\n+\n+    private ApplyUpdates(UpdateSchema api, Schema baseSchema) {\n+      this.api = api;\n+      this.baseSchema = baseSchema;\n+      this.indexByName = TypeUtil.indexByName(baseSchema.asStruct());\n+    }\n+\n+    @Override\n+    public void beforeListElement(NestedField elementField) {\n+      beforeField(elementField);\n+    }\n+\n+    @Override\n+    public void afterListElement(NestedField elementField) {\n+      afterField(elementField);\n+    }\n+\n+    @Override\n+    public void beforeMapKey(Types.NestedField keyField) {\n+      beforeField(keyField);\n+    }\n+\n+    @Override\n+    public void afterMapKey(Types.NestedField keyField) {\n+      afterField(keyField);\n+    }\n+\n+    @Override\n+    public void beforeMapValue(Types.NestedField valueField) {\n+      beforeField(valueField);\n+    }\n+\n+    @Override\n+    public void afterMapValue(Types.NestedField valueField) {\n+      afterField(valueField);\n+    }\n+\n+    @Override\n+    public void beforeField(NestedField field) {\n+      fieldNames.push(field.name()); // we don't expect `element` to show up - it breaks\n+      currentField = field;\n+    }\n+\n+    @Override\n+    public void afterField(NestedField field) {\n+      fieldNames.pop();\n+    }\n+\n+    @Override\n+    public Void field(NestedField field, Void fieldResult) {\n+      return super.field(field, fieldResult);\n+    }\n+\n+    @Override\n+    public Void list(ListType list, Void elementResult) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.ListType.ofOptional(0,   list.elementType()), ancestors());\n+      } else if (!field.type().isListType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + fullName + \" of type: \" + field\n+                .type() + \" to type list\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void map(MapType map, Void keyResult, Void valueResult) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.MapType.ofOptional(0, 1,   map.keyType(), map.valueType()), ancestors());\n+      } else if (!field.type().isMapType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + fullName + \" of type: \" + field\n+                .type() + \" to type map\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void struct(Types.StructType struct, List<Void> fieldResults) {\n+      if(fieldNames.isEmpty()) return null; // this is the root struct\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.StructType.of(struct.fields()), ancestors());\n+      } else if (!field.type().isStructType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + fullName + \" of type: \" + field.type()\n+                + \" to type struct\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void primitive(PrimitiveType primitive) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      PrimitiveType newFieldType = Types.fromPrimitiveString(primitive.toString());\n+      if (field == null) {\n+        addColumn(currentField.name(), Types.fromPrimitiveString(primitive.toString()), ancestors());\n+      } else if (!field.type().isPrimitiveType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + field.name() + \" of type: \"\n+                + field.type() + \" to primitive type: \" + primitive.typeId().name());\n+      } else if (!newFieldType.equals(field.type())) {", "originalCommit": "e74bdbd696c508d30b0f1cff7d6e61c3ab51c931", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r451298044", "bodyText": "seems like \"value\" is missing from newSchema.  I think deletes are not handled that's why. We should consider adding deletes and renames too", "author": "rdsr", "createdAt": "2020-07-08T05:50:02Z", "path": "core/src/test/java/org/apache/iceberg/TestSchemaUpdateSync.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import org.apache.iceberg.types.Type.PrimitiveType;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.BinaryType;\n+import org.apache.iceberg.types.Types.BooleanType;\n+import org.apache.iceberg.types.Types.DateType;\n+import org.apache.iceberg.types.Types.DecimalType;\n+import org.apache.iceberg.types.Types.DoubleType;\n+import org.apache.iceberg.types.Types.FixedType;\n+import org.apache.iceberg.types.Types.FloatType;\n+import org.apache.iceberg.types.Types.IntegerType;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.NestedField;\n+import org.apache.iceberg.types.Types.StringType;\n+import org.apache.iceberg.types.Types.TimeType;\n+import org.apache.iceberg.types.Types.TimestampType;\n+import org.apache.iceberg.types.Types.UUIDType;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+\n+public class TestSchemaUpdateSync {\n+\n+  @Rule\n+  public ExpectedException thrown = ExpectedException.none();\n+\n+  private static List<? extends PrimitiveType> primitiveTypes() {\n+    return Lists.newArrayList(StringType.get(),\n+        TimeType.get(),\n+        TimestampType.withoutZone(),\n+        TimestampType.withZone(),\n+        UUIDType.get(),\n+        DateType.get(),\n+        BooleanType.get(),\n+        BinaryType.get(),\n+        DoubleType.get(),\n+        IntegerType.get(),\n+        FixedType.ofLength(10),\n+        DecimalType.of(10, 2),\n+        LongType.get(),\n+        FloatType.get()\n+    );\n+  }\n+\n+  private static NestedField[] primitiveFields(Integer initialValue, List<? extends PrimitiveType> primitiveTypes) {\n+    AtomicInteger i = new AtomicInteger(initialValue);\n+    return primitiveTypes.stream()\n+        .map(type -> optional(i.incrementAndGet(), type.toString(),\n+            Types.fromPrimitiveString(type.toString()))).toArray(NestedField[]::new);\n+  }\n+\n+  @Test\n+  public void testAddTopLevelPrimitives() {\n+    Schema newSchema = new Schema(primitiveFields(0, primitiveTypes()));\n+    Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testAddTopLevelListOfPrimitives() {\n+    for(PrimitiveType primitiveType : primitiveTypes()) {\n+      Schema newSchema = new Schema(optional(1, \"aList\", Types.ListType.ofOptional(2, primitiveType)));\n+      Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+      Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+    }\n+  }\n+\n+  @Test\n+  public void testAddTopLevelMapOfPrimitives() {\n+    for(PrimitiveType primitiveType : primitiveTypes()) {\n+      Schema newSchema = new Schema(optional(1, \"aMap\", Types.MapType.ofOptional(2, 3, primitiveType, primitiveType)));\n+      Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+      Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+    }\n+  }\n+\n+  @Test\n+  public void testAddTopLevelStructOfPrimitives() {\n+    for(PrimitiveType primitiveType : primitiveTypes()) {\n+      Schema currentSchema = new Schema(optional(1, \"aStruct\", Types.StructType.of(\n+          optional(2, \"primitive\", primitiveType))));\n+      Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(currentSchema).apply();\n+      Assert.assertEquals(currentSchema.asStruct(), applied.asStruct());\n+    }\n+  }\n+\n+  @Test\n+  public void testAddNestedPrimitive() {\n+    for(PrimitiveType primitiveType : primitiveTypes()) {\n+      Schema currentSchema = new Schema(optional(1, \"aStruct\", Types.StructType.of()));\n+      Schema newSchema = new Schema(optional(1, \"aStruct\", Types.StructType.of(\n+          optional(2, \"primitive\", primitiveType))));\n+      Schema applied = new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+      Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+    }\n+  }\n+\n+  @Test\n+  public void testAddNestedPrimitives() {\n+    Schema currentSchema = new Schema(optional(1, \"aStruct\", Types.StructType.of()));\n+    Schema newSchema = new Schema(optional(1, \"aStruct\", Types.StructType.of(\n+        primitiveFields(1, primitiveTypes()))));\n+    Schema applied = new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testAddNestedLists() {\n+    Schema newSchema = new Schema(optional(1, \"aList\",\n+        Types.ListType.ofOptional(2,\n+            Types.ListType.ofOptional(3,\n+                Types.ListType.ofOptional(4,\n+                    Types.ListType.ofOptional(5,\n+                        Types.ListType.ofOptional(6,\n+                            Types.ListType.ofOptional(7,\n+                                Types.ListType.ofOptional(8,\n+                                    Types.ListType.ofOptional(9,\n+                                        Types.ListType.ofOptional(10,\n+                                            DecimalType.of(11, 20))))))))))));\n+    Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testAddNestedStruct() {\n+    Schema newSchema = new Schema(optional(1, \"struct1\", Types.StructType.of(\n+            optional(2, \"struct2\", Types.StructType.of(\n+                optional(3, \"struct3\", Types.StructType.of(\n+                    optional(4, \"struct4\", Types.StructType.of(\n+                        optional(5, \"struct5\", Types.StructType.of(\n+                            optional(6, \"struct6\", Types.StructType.of(\n+                                optional(7, \"aString\", StringType.get()))))))))))))));\n+    Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testAddNestedMaps() {\n+    Schema newSchema = new Schema(optional(1, \"struct\", Types.MapType.ofOptional(\n+        2, 3, StringType.get(), Types.MapType.ofOptional(\n+            4, 5, StringType.get(), Types.MapType.ofOptional(\n+                6, 7, StringType.get(), Types.MapType.ofOptional(\n+                    8 ,9, StringType.get(), Types.MapType.ofOptional(\n+                        10 ,11, StringType.get(), Types.MapType.ofOptional(\n+                            12, 13, StringType.get(), StringType.get()))))))));\n+    Schema applied = new SchemaUpdate(new Schema(), 0).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testDetectInvalidTopLevelList() {\n+    thrown.expect(IllegalArgumentException.class);\n+    thrown.expectMessage(\"Cannot change column type: aList.element: string -> long\");\n+\n+    Schema currentSchema = new Schema(optional(1, \"aList\",\n+        Types.ListType.ofOptional(2, StringType.get())));\n+    Schema newSchema = new Schema(optional(1, \"aList\",\n+        Types.ListType.ofOptional(2, LongType.get())));\n+    new SchemaUpdate(currentSchema, 2).upsertSchema(newSchema).apply();\n+  }\n+\n+  @Test\n+  public void testDetectInvalidTopLevelMapValue() {\n+    thrown.expect(IllegalArgumentException.class);\n+    thrown.expectMessage(\"Cannot change column type: aMap.value: string -> long\");\n+\n+    Schema currentSchema = new Schema(optional(1, \"aMap\",\n+        Types.MapType.ofOptional(2,3, StringType.get(), StringType.get())));\n+    Schema newSchema = new Schema(optional(1, \"aMap\",\n+        Types.MapType.ofOptional(2,3, StringType.get(), LongType.get())));\n+    Schema apply = new SchemaUpdate(currentSchema, 3).upsertSchema(newSchema).apply();\n+    System.out.println(apply.toString());\n+  }\n+\n+  @Test\n+  public void testDetectInvalidTopLevelMapKey() {\n+    thrown.expect(IllegalArgumentException.class);\n+    thrown.expectMessage(\"Cannot change column type: aMap.key: string -> uuid\");\n+\n+    Schema currentSchema = new Schema(optional(1, \"aMap\",\n+        Types.MapType.ofOptional(2,3 , StringType.get(), StringType.get())));\n+    Schema newSchema = new Schema(optional(1, \"aMap\",\n+        Types.MapType.ofOptional(2,3 , UUIDType.get(), StringType.get())));\n+    new SchemaUpdate(currentSchema, 3).upsertSchema(newSchema).apply();\n+  }\n+\n+  @Test\n+  // int\t32-bit signed integers -> Can promote to long\n+  public void testTypePromoteIntegerToLong() {\n+    Schema currentSchema = new Schema(required(1, \"aCol\", IntegerType.get()));\n+    Schema newSchema = new Schema(required(1, \"aCol\", LongType.get()));\n+\n+    Schema applied = new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(1, applied.asStruct().fields().size());\n+    Assert.assertEquals(LongType.get(), applied.asStruct().fields().get(0).type());\n+  }\n+\n+  @Test\n+  // float\t32-bit IEEE 754 floating point -> Can promote to double\n+  public void testTypePromoteFloatToDouble() {\n+    Schema currentSchema = new Schema(required(1, \"aCol\", FloatType.get()));\n+    Schema newSchema = new Schema(required(1, \"aCol\", DoubleType.get()));\n+\n+    Schema applied = new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(1, applied.asStruct().fields().size());\n+    Assert.assertEquals(DoubleType.get(), applied.asStruct().fields().get(0).type());\n+    // Doesn't work Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+    // java.lang.AssertionError:\n+    // Expected :struct<1: aCol: required double>\n+    // Actual   :struct<1: aCol: required double ()>\n+  }\n+\n+  @Test\n+  public void testInvalidTypePromoteDoubleToFloat() {\n+    thrown.expect(IllegalArgumentException.class);\n+    thrown.expectMessage(\"Cannot change column type: aCol: double -> float\");\n+\n+    Schema currentSchema = new Schema(required(1, \"aCol\", DoubleType.get()));\n+    Schema newSchema = new Schema(required(1, \"aCol\", FloatType.get()));\n+\n+    new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+  }\n+\n+  @Test\n+  // decimal(P,S)\tFixed-point decimal; precision P, scale S\t-> Scale is fixed [1], precision must be 38 or less\n+  public void testTypePromoteDecimalToFixedScaleWithWiderPrecision() {\n+    Schema currentSchema = new Schema(required(1, \"aCol\", DecimalType.of(20, 1)));\n+    Schema newSchema = new Schema(required(1, \"aCol\", DecimalType.of(22, 1)));\n+\n+    Schema applied = new SchemaUpdate(currentSchema, 1).upsertSchema(newSchema).apply();\n+    Assert.assertEquals(newSchema.asStruct(), applied.asStruct());\n+  }\n+\n+  @Test\n+  public void testAddPrimitiveToNestedStruct() {\n+    Schema schema = new Schema(\n+        required(1, \"struct1\", Types.StructType.of(\n+          optional(2, \"struct2\", Types.StructType.of(\n+                  optional(3, \"list\", Types.ListType.ofOptional(\n+                      4, Types.StructType.of(\n+                          optional(5, \"value\", StringType.get())))))))));\n+\n+    Schema newSchema = new Schema(\n+        required(1, \"struct1\", Types.StructType.of(\n+            optional(2, \"struct2\", Types.StructType.of(\n+                optional(3, \"list\", Types.ListType.ofOptional(\n+                    4, Types.StructType.of(\n+                        optional(5, \"time\", TimeType.get())))))))));", "originalCommit": "e74bdbd696c508d30b0f1cff7d6e61c3ab51c931", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTc1NTc5MA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r451755790", "bodyText": "Right, \"value\" is missing, however the expectation isn't to delete it, the main use-case for this API is to accommodate schema unions as @rdblue's summed it up during our chat  in the Iceberg sync-up today.\nThe use-case is as follows:\n\nthink a dataset with a large schema - call it effective schema\nwe get data that only contains particular columns - those columns make up only for a subset of the large schema - call it observed schema\nas these chunks of data and their respective observed schemas are being landed in the iceberg table we want to track the union of all observed schemas as the Iceberg schema\n\nSo in this particular expected is the union of schema and newSchema.\nDoes this make sense?\nDoes this resemble your use-case as well?", "author": "fbocse", "createdAt": "2020-07-08T18:48:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTQwNA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r453991404", "bodyText": "Yes, that use case makes sense to me! It will work for our use case too as we do not support deletes", "author": "rdsr", "createdAt": "2020-07-13T22:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTY2Ng==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r453991666", "bodyText": "What about renames?", "author": "rdsr", "createdAt": "2020-07-13T22:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDM3NDU2Mg==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r454374562", "bodyText": "Dunno really, do you account for renames in your use-case?\nIf so, do you have a plan on how to push those changes down to Iceberg APIs, do you know before committing to Iceberg what the effective columns you're renaming are? Would we rely on Iceberg to perform the renames implicitly, how would it differentiate between an add or a rename?\nIn the particular use-case I've described I didn't account for that requirement. Observed schemas don't require column renames.\nHowever I assume that the only way we could reliably implement this is to reconcile column name changes by relying on the field ids though, right?\nAlso for this particular use-case of sub-schemas getting unioned to support column renames the operations are additive so they can be running out of order - eventually the union schema is the same no matter the order in which the observed schemas were committed.\nBut for things like renames and deletes we'd need to account for order too, right?\nI hate building things that need to account for order cause most of the time I get them wrong.\nSo I'd say that I don't think that we can combine the two implementations into a single method...\nWdyt?", "author": "fbocse", "createdAt": "2020-07-14T13:55:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDU4MzIxMQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r460583211", "bodyText": "Yea, @rdblue had some thoughts on renames as well #759 (comment) . I'm not sure if that thinking has evolved in the last meetup.", "author": "rdsr", "createdAt": "2020-07-26T22:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDYyMDIwOQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r460620209", "bodyText": "I'll find time to look at this tomorrow, hopefully. Sorry for the delay.", "author": "rdblue", "createdAt": "2020-07-27T02:50:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg3NDgxOA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r463874818", "bodyText": "I just went back to the sync notes to refresh my memory and found that I hadn't posted them to the doc! I updated it. Sorry about that.\nJust catching up on this now. I think the main use case that we're trying to solve here is the union case, where you just need to produce a schema with a union of the fields from all of the observed schemas. I think focusing on that use case makes the choice of whether to support delete clear: just because a column is missing, doesn't mean it shouldn't be in the union. Renames are similar: if the field exists, do nothing and if it doesn't exist, add it.\nThe only case where we could detect a rename in a union operation is if both schemas have IDs. But then I would say that we should avoid unnecessary modification of the union schema. That's because we don't know which name is correct (the existing name or the observed name) but using the observed name is more likely to break existing queries for the table.", "author": "rdblue", "createdAt": "2020-07-31T22:39:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTI5ODA0NA=="}], "type": "inlineReview"}, {"oid": "aaca00e39df228145e20b497ed65787b4ee335c3", "url": "https://github.com/apache/iceberg/commit/aaca00e39df228145e20b497ed65787b4ee335c3", "message": "Add API for adding new fields and updating type (where applicable) and doc of existing fields by matching field names against a providede schema", "committedDate": "2020-07-09T13:04:19Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg4Nzg1Mw==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r463887853", "bodyText": "It seems odd to me that this is here. Does this support multiple calls to this method, or do we expect to mix this union operation with the others? If not, then I think we should consider how to separate the union logic from the API. We try to make sure that all of the configuration on table operations can be used at the same time, unless they logically conflict (like rename x -> y then delete y).\nIf this is going to be incompatible or even just not recommended with the other configuration methods, then we should consider moving it to either its own operation or a class that helps configure the normal UpdateSchema operation.", "author": "rdblue", "createdAt": "2020-07-31T23:39:42Z", "path": "api/src/main/java/org/apache/iceberg/UpdateSchema.java", "diffHunk": "@@ -361,4 +361,14 @@ default UpdateSchema updateColumn(String name, Type.PrimitiveType newType, Strin\n    *                                  change conflicts with other changes.\n    */\n   UpdateSchema moveAfter(String name, String afterName);\n+\n+\n+  /**\n+   * Applies all the additions and updates [type widening, field documentation]\n+   * from the input schema\n+   *\n+   * @param newSchema - Input schema from which updates are applied\n+   * @return this for method chaining\n+   */\n+  UpdateSchema upsertSchema(Schema newSchema);", "originalCommit": "fc938ea8cd7595672d6d269991d1aed5536afc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyMDY1NQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r464520655", "bodyText": "I had a hard time following the code and ended up using a debugger to figure out it wasn't trying to add columns in missing structs. It was good to see that there are test cases for this, but I think we can avoid the need for calling addColumn when it should not be added by using the visitor's return values.\nI prototyped a change that returns a Boolean that indicates whether a column is missing. That way, each method checks whether its equivalent is in the other struct. If it is not, the method simply returns true because the whole type should be added. If it is present, then containers may update the type, docs, and required boolean. I think that's easier to follow, so I'll post the changes for you.", "author": "rdblue", "createdAt": "2020-08-03T16:23:07Z", "path": "core/src/main/java/org/apache/iceberg/SchemaUpdate.java", "diffHunk": "@@ -308,6 +314,162 @@ public UpdateSchema moveAfter(String name, String afterName) {\n     return this;\n   }\n \n+  @Override\n+  public UpdateSchema upsertSchema(Schema newSchema) {\n+    TypeUtil.visit(newSchema, new ApplyUpdates(this, schema));\n+    return this;\n+  }\n+\n+  private static class ApplyUpdates extends TypeUtil.SchemaVisitor<Void> {\n+    private static final Joiner DOT = Joiner.on(\".\");\n+    private final Deque<String> fieldNames = Lists.newLinkedList();\n+    private NestedField currentField = null;\n+\n+    private final Schema baseSchema;\n+    private final UpdateSchema api;\n+    private final Map<String, Integer> indexByName;\n+\n+    private ApplyUpdates(UpdateSchema api, Schema baseSchema) {\n+      this.api = api;\n+      this.baseSchema = baseSchema;\n+      this.indexByName = TypeUtil.indexByName(baseSchema.asStruct());\n+    }\n+\n+    @Override\n+    public void beforeListElement(NestedField elementField) {\n+      beforeField(elementField);\n+    }\n+\n+    @Override\n+    public void afterListElement(NestedField elementField) {\n+      afterField(elementField);\n+    }\n+\n+    @Override\n+    public void beforeMapKey(Types.NestedField keyField) {\n+      beforeField(keyField);\n+    }\n+\n+    @Override\n+    public void afterMapKey(Types.NestedField keyField) {\n+      afterField(keyField);\n+    }\n+\n+    @Override\n+    public void beforeMapValue(Types.NestedField valueField) {\n+      beforeField(valueField);\n+    }\n+\n+    @Override\n+    public void afterMapValue(Types.NestedField valueField) {\n+      afterField(valueField);\n+    }\n+\n+    @Override\n+    public void beforeField(NestedField field) {\n+      fieldNames.push(field.name()); // we don't expect `element` to show up - it breaks\n+      currentField = field;\n+    }\n+\n+    @Override\n+    public void afterField(NestedField field) {\n+      fieldNames.pop();\n+    }\n+\n+    @Override\n+    public Void field(NestedField field, Void fieldResult) {\n+      return super.field(field, fieldResult);\n+    }\n+\n+    @Override\n+    public Void list(ListType list, Void elementResult) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.ListType.ofOptional(0,   list.elementType()), ancestors());\n+      } else if (!field.type().isListType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + fullName + \" of type: \" + field\n+                .type() + \" to type list\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void map(MapType map, Void keyResult, Void valueResult) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.MapType.ofOptional(0, 1, map.keyType(), map.valueType()), ancestors());\n+      } else if (!field.type().isMapType()) {\n+        throw new IllegalArgumentException(\n+            \"Cannot update existing field: \" + fullName + \" of type: \" + field\n+                .type() + \" to type map\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void struct(Types.StructType struct, List<Void> fieldResults) {\n+      if (fieldNames.isEmpty()) {\n+        return null; // this is the root struct\n+      }\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.StructType.of(struct.fields()), ancestors());\n+      } else if (!field.type().isStructType()) {\n+        throw new IllegalArgumentException(\"Cannot update existing field: \" + fullName + \" of type: \" + field.type() +\n+                \" to type struct\");\n+      }\n+      return null;\n+    }\n+\n+    @Override\n+    public Void primitive(PrimitiveType primitive) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      PrimitiveType newFieldType = Types.fromPrimitiveString(primitive.toString());\n+      if (field == null) {\n+        addColumn(currentField.name(), Types.fromPrimitiveString(primitive.toString()), ancestors());\n+      } else if (!field.type().isPrimitiveType()) {\n+        throw new IllegalArgumentException(\"Cannot update existing field: \" + field.name() + \" of type: \" +\n+                field.type() + \" to primitive type: \" + primitive.typeId().name());\n+      } else if (!newFieldType.equals(field.type())) {\n+        updateColumn(field.type().asPrimitiveType(), fullName, field.doc(), newFieldType, currentField.doc());\n+      }\n+      return null;\n+    }\n+\n+    private String ancestors() {\n+      if (fieldNames.isEmpty()) {\n+        return \"\";\n+      }\n+      String head = fieldNames.removeFirst();\n+      String join = DOT.join(fieldNames.descendingIterator());\n+      fieldNames.addFirst(head);\n+      return join;\n+    }\n+\n+    private void updateColumn(PrimitiveType fieldType, String fullName, String fieldDoc, PrimitiveType newFieldType,\n+                              String newDoc) {\n+      if (!fieldType.equals(newFieldType)) {\n+        api.updateColumn(fullName, newFieldType.asPrimitiveType());\n+      } else if (newDoc != null && !newDoc.equals(fieldDoc)) {\n+        api.updateColumnDoc(fullName, newDoc);\n+      }\n+    }\n+\n+    private void addColumn(String name, Type type, String ancestors) {\n+      if (ancestors.isEmpty()) {\n+        api.addColumn(null, name, type);\n+      } else if (indexByName.containsKey(ancestors)) {\n+        api.addColumn(ancestors, name, type);\n+      }\n+      // At this point the parent of this column hasn't been added to the schema, not yet visited", "originalCommit": "fc938ea8cd7595672d6d269991d1aed5536afc74", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2MTg1OQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482061859", "bodyText": "Indeed, this aspect of the implementation will greatly improve the efficiency for the union of distinct schemas.", "author": "fbocse", "createdAt": "2020-09-02T13:19:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyMDY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUyNTIyNA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r464525224", "bodyText": "This visitor includes quite a bit of logic for traversing two schemas at once, by keeping track of the current name and looking up the equivalent in the existing/base schema. This check is also primarily to validate structure.\nI think it would be good to separate the logic to traverse schemas into a different visitor class, like we've done with the other \"partner\" visitors. That way, the union visitor would just be handed two types at the same place in a schema and can decide whether the observed type needs to be added, used to update, or if no action is needed.\nIn addition, we should be able to construct that visitor so that it keeps track of the place in the existing schema, so that we don't need to keep track of ancestors.", "author": "rdblue", "createdAt": "2020-08-03T16:31:27Z", "path": "core/src/main/java/org/apache/iceberg/SchemaUpdate.java", "diffHunk": "@@ -308,6 +314,162 @@ public UpdateSchema moveAfter(String name, String afterName) {\n     return this;\n   }\n \n+  @Override\n+  public UpdateSchema upsertSchema(Schema newSchema) {\n+    TypeUtil.visit(newSchema, new ApplyUpdates(this, schema));\n+    return this;\n+  }\n+\n+  private static class ApplyUpdates extends TypeUtil.SchemaVisitor<Void> {\n+    private static final Joiner DOT = Joiner.on(\".\");\n+    private final Deque<String> fieldNames = Lists.newLinkedList();\n+    private NestedField currentField = null;\n+\n+    private final Schema baseSchema;\n+    private final UpdateSchema api;\n+    private final Map<String, Integer> indexByName;\n+\n+    private ApplyUpdates(UpdateSchema api, Schema baseSchema) {\n+      this.api = api;\n+      this.baseSchema = baseSchema;\n+      this.indexByName = TypeUtil.indexByName(baseSchema.asStruct());\n+    }\n+\n+    @Override\n+    public void beforeListElement(NestedField elementField) {\n+      beforeField(elementField);\n+    }\n+\n+    @Override\n+    public void afterListElement(NestedField elementField) {\n+      afterField(elementField);\n+    }\n+\n+    @Override\n+    public void beforeMapKey(Types.NestedField keyField) {\n+      beforeField(keyField);\n+    }\n+\n+    @Override\n+    public void afterMapKey(Types.NestedField keyField) {\n+      afterField(keyField);\n+    }\n+\n+    @Override\n+    public void beforeMapValue(Types.NestedField valueField) {\n+      beforeField(valueField);\n+    }\n+\n+    @Override\n+    public void afterMapValue(Types.NestedField valueField) {\n+      afterField(valueField);\n+    }\n+\n+    @Override\n+    public void beforeField(NestedField field) {\n+      fieldNames.push(field.name()); // we don't expect `element` to show up - it breaks\n+      currentField = field;\n+    }\n+\n+    @Override\n+    public void afterField(NestedField field) {\n+      fieldNames.pop();\n+    }\n+\n+    @Override\n+    public Void field(NestedField field, Void fieldResult) {\n+      return super.field(field, fieldResult);\n+    }\n+\n+    @Override\n+    public Void list(ListType list, Void elementResult) {\n+      String fullName = DOT.join(fieldNames.descendingIterator());\n+      Types.NestedField field = baseSchema.findField(fullName);\n+      if (field == null) {\n+        addColumn(fieldNames.peekFirst(), Types.ListType.ofOptional(0,   list.elementType()), ancestors());\n+      } else if (!field.type().isListType()) {\n+        throw new IllegalArgumentException(", "originalCommit": "fc938ea8cd7595672d6d269991d1aed5536afc74", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "55a74e540658ef3e197fd9f945b21195e9399cb3", "url": "https://github.com/apache/iceberg/commit/55a74e540658ef3e197fd9f945b21195e9399cb3", "message": "Update implementation using visitor pattern provided by @rdblue", "committedDate": "2020-09-02T13:09:50Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2NjU1NQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482066555", "bodyText": "@rdblue @rdsr pls weigh in on the naming of this new API - I went for something that's as accurate as possible but pls drop a note in case you have a better suggestion for it", "author": "fbocse", "createdAt": "2020-09-02T13:26:06Z", "path": "api/src/main/java/org/apache/iceberg/UpdateSchema.java", "diffHunk": "@@ -361,4 +361,14 @@ default UpdateSchema updateColumn(String name, Type.PrimitiveType newType, Strin\n    *                                  change conflicts with other changes.\n    */\n   UpdateSchema moveAfter(String name, String afterName);\n+\n+\n+  /**\n+   * Applies all the additions and updates [type widening, field documentation]\n+   * from the provided new schema\n+   *\n+   * @param newSchema - Input schema from which updates are applied\n+   * @return this for method chaining\n+   */\n+  UpdateSchema unionWithByFieldName(Schema newSchema);", "originalCommit": "55a74e540658ef3e197fd9f945b21195e9399cb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYxMDEyNQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482610125", "bodyText": "How about unionByName or unionByNameWith?\nWe'll also need to fill in the docs placeholder: [type widening, field documentation].", "author": "rdblue", "createdAt": "2020-09-03T00:08:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2NjU1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjgwOTg2MA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482809860", "bodyText": "sure, I like either one @rdsr you make the call pls :)", "author": "fbocse", "createdAt": "2020-09-03T08:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2NjU1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2ODQ0Mw==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482068443", "bodyText": "@rdblue I think this conditional here is pretty much the only change I've made to your poc code - tests are passing just fine - will add some more from past use-cases - I realise that an exhaustive test suite is pretty much impossible for this feature but I'll try to cover both basic and complex use-cases", "author": "fbocse", "createdAt": "2020-09-02T13:28:45Z", "path": "core/src/main/java/org/apache/iceberg/schema/UnionByNameVisitor.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.schema;\n+\n+import java.util.List;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.UpdateSchema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+/**\n+ * Visitor class that accumulates the set of changes needed to evolve an existing schema into the union of the\n+ * existing and a new schema. Changes are added to an {@link UpdateSchema} operation.\n+ */\n+public class UnionByNameVisitor extends SchemaWithPartnerVisitor<Integer, Boolean> {\n+\n+  private final UpdateSchema api;\n+  private final Schema partnerSchema;\n+\n+  private UnionByNameVisitor(UpdateSchema api, Schema partnerSchema) {\n+    this.api = api;\n+    this.partnerSchema = partnerSchema;\n+  }\n+\n+  /**\n+   * Adds changes needed to produce a union of two schemas to an {@link UpdateSchema} operation.\n+   * <p>\n+   * Changes are accumulated to evolve the existingSchema into a union with newSchema.\n+   *\n+   * @param api an UpdateSchema for adding changes\n+   * @param existingSchema an existing schema\n+   * @param newSchema a new schema to compare with the existing\n+   */\n+  public static void visit(UpdateSchema api, Schema existingSchema, Schema newSchema) {\n+    visit(newSchema, -1, new UnionByNameVisitor(api, existingSchema), new PartnerIdByNameAccessors(existingSchema));\n+  }\n+\n+  @Override\n+  public Boolean struct(Types.StructType struct, Integer partnerId, List<Boolean> missingPositions) {\n+    if (partnerId == null) {\n+      return true;\n+    }\n+\n+    List<Types.NestedField> fields = struct.fields();\n+    Types.StructType partnerStruct = findFieldType(partnerId).asStructType();\n+    IntStream.range(0, missingPositions.size())\n+        .forEach(pos -> {\n+          Boolean isMissing = missingPositions.get(pos);\n+          Types.NestedField field = fields.get(pos);\n+          if (isMissing) {\n+            addColumn(partnerId, field);\n+          } else {\n+            updateColumn(field, partnerStruct.field(field.name()));\n+          }\n+        });\n+\n+    return false;\n+  }\n+\n+  @Override\n+  public Boolean field(Types.NestedField field, Integer partnerId, Boolean isFieldMissing) {\n+    return partnerId == null;\n+  }\n+\n+  @Override\n+  public Boolean list(Types.ListType list, Integer partnerId, Boolean isElementMissing) {\n+    if (partnerId == null) {\n+      return true;\n+    }\n+\n+    Preconditions.checkState(!isElementMissing, \"Error traversing schemas: element is missing, but list is present\");\n+\n+    Types.ListType partnerList = findFieldType(partnerId).asListType();\n+    updateColumn(list.fields().get(0), partnerList.fields().get(0));\n+\n+    return false;\n+  }\n+\n+  @Override\n+  public Boolean map(Types.MapType map, Integer partnerId, Boolean isKeyMissing, Boolean isValueMissing) {\n+    if (partnerId == null) {\n+      return true;\n+    }\n+\n+    Preconditions.checkState(!isKeyMissing, \"Error traversing schemas: key is missing, but map is present\");\n+    Preconditions.checkState(!isValueMissing, \"Error traversing schemas: value is missing, but map is present\");\n+\n+    Types.MapType partnerMap = findFieldType(partnerId).asMapType();\n+    updateColumn(map.fields().get(0), partnerMap.fields().get(0));\n+    updateColumn(map.fields().get(1), partnerMap.fields().get(1));\n+\n+    return false;\n+  }\n+\n+  @Override\n+  public Boolean primitive(Type.PrimitiveType primitive, Integer partnerId) {\n+    return partnerId == null;\n+  }\n+\n+  private Type findFieldType(int fieldId) {\n+    if (fieldId == -1) {\n+      return partnerSchema.asStruct();\n+    } else {\n+      return partnerSchema.findField(fieldId).type();\n+    }\n+  }\n+\n+  private void addColumn(int parentId, Types.NestedField field) {\n+    String parentName = partnerSchema.findColumnName(parentId);\n+    api.addColumn(parentName, field.name(), field.type(), field.doc());\n+  }\n+\n+  private void updateColumn(Types.NestedField field, Types.NestedField existingField) {\n+    String fullName = partnerSchema.findColumnName(existingField.fieldId());\n+\n+    boolean needsOptionalUpdate = field.isOptional() && existingField.isRequired();\n+    boolean needsTypeUpdate = field.type().isPrimitiveType() && !field.type().equals(existingField.type());\n+    boolean needsDocUpdate = field.doc() != null && !field.doc().equals(existingField.doc());\n+\n+    if (needsOptionalUpdate) {\n+      api.makeColumnOptional(fullName);\n+    }\n+\n+    if (needsTypeUpdate) {\n+      api.updateColumn(fullName, field.type().asPrimitiveType());\n+    }\n+\n+    if (needsDocUpdate) {\n+      api.updateColumnDoc(fullName, field.doc());\n+    }\n+  }\n+\n+  private static class PartnerIdByNameAccessors implements PartnerAccessors<Integer> {\n+    private final Schema partnerSchema;\n+\n+    private PartnerIdByNameAccessors(Schema partnerSchema) {\n+      this.partnerSchema = partnerSchema;\n+    }\n+\n+    @Override\n+    public Integer fieldPartner(Integer partnerFieldId, int fieldId, String name) {\n+      Types.StructType struct;\n+      if (partnerFieldId == -1) {", "originalCommit": "55a74e540658ef3e197fd9f945b21195e9399cb3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjUwMDMxMQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482500311", "bodyText": "I think this is correct.", "author": "rdblue", "createdAt": "2020-09-02T21:40:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2ODQ0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjA2OTY0Mg==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482069642", "bodyText": "@rdblue you're right, the implementation, while a bit more complex than the previous one, feels less complicated.", "author": "fbocse", "createdAt": "2020-09-02T13:30:20Z", "path": "core/src/main/java/org/apache/iceberg/SchemaUpdate.java", "diffHunk": "@@ -308,6 +309,12 @@ public UpdateSchema moveAfter(String name, String afterName) {\n     return this;\n   }\n \n+  @Override\n+  public UpdateSchema unionWithByFieldName(Schema newSchema) {\n+    UnionByNameVisitor.visit(this, schema, newSchema);", "originalCommit": "55a74e540658ef3e197fd9f945b21195e9399cb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjQ5ODEzOA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r482498138", "bodyText": "Why extract TypeVisitor<P, R> from this? It isn't obvious to me how that's useful.", "author": "rdblue", "createdAt": "2020-09-02T21:37:33Z", "path": "core/src/main/java/org/apache/iceberg/schema/SchemaWithPartnerVisitor.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.schema;\n+\n+import java.util.List;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+public abstract class SchemaWithPartnerVisitor<P, R> implements TypeVisitor<P, R> {", "originalCommit": "55a74e540658ef3e197fd9f945b21195e9399cb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "72c43f5ee96772b142854c496e2734808c9413bb", "url": "https://github.com/apache/iceberg/commit/72c43f5ee96772b142854c496e2734808c9413bb", "message": "Add API for adding new fields and updating type (where applicable) and doc of existing fields by matching field names against a providede schema (uses a new implementation of visitor pattern for schema w/ partner)", "committedDate": "2020-09-03T13:58:42Z", "type": "commit"}, {"oid": "72c43f5ee96772b142854c496e2734808c9413bb", "url": "https://github.com/apache/iceberg/commit/72c43f5ee96772b142854c496e2734808c9413bb", "message": "Add API for adding new fields and updating type (where applicable) and doc of existing fields by matching field names against a providede schema (uses a new implementation of visitor pattern for schema w/ partner)", "committedDate": "2020-09-03T13:58:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE5OTQ5MA==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r483199490", "bodyText": "@rdblue is this javadoc overdoing it a bit?", "author": "fbocse", "createdAt": "2020-09-03T19:14:09Z", "path": "api/src/main/java/org/apache/iceberg/UpdateSchema.java", "diffHunk": "@@ -361,4 +361,27 @@ default UpdateSchema updateColumn(String name, Type.PrimitiveType newType, Strin\n    *                                  change conflicts with other changes.\n    */\n   UpdateSchema moveAfter(String name, String afterName);\n+\n+\n+  /**\n+   * Applies all field additions and updates from the provided new schema to the existing schema so", "originalCommit": "72c43f5ee96772b142854c496e2734808c9413bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3ODMzNQ==", "url": "https://github.com/apache/iceberg/pull/1177#discussion_r485078335", "bodyText": "Looks good to me.", "author": "rdblue", "createdAt": "2020-09-08T17:19:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE5OTQ5MA=="}], "type": "inlineReview"}]}