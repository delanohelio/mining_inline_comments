{"pr_number": 999, "pr_title": "Spark: Pass correct types to get data from InternalRow", "pr_createdAt": "2020-05-04T18:46:14Z", "pr_url": "https://github.com/apache/iceberg/pull/999", "timeline": [{"oid": "f6c6109c31e39f87cd728a2e77023658e93e83a5", "url": "https://github.com/apache/iceberg/commit/f6c6109c31e39f87cd728a2e77023658e93e83a5", "message": "Spark: Pass correct types to get data from InternalRow.", "committedDate": "2020-05-04T18:40:54Z", "type": "commit"}, {"oid": "65cfb2952480d0b89351375ac5088068bf2f97cf", "url": "https://github.com/apache/iceberg/commit/65cfb2952480d0b89351375ac5088068bf2f97cf", "message": "Add missing methods from the refactor in #950.", "committedDate": "2020-05-04T20:28:23Z", "type": "commit"}, {"oid": "65c341ea077171f6cd015dd031ef5b1de7d90bab", "url": "https://github.com/apache/iceberg/commit/65c341ea077171f6cd015dd031ef5b1de7d90bab", "message": "Fix errorprone problems.", "committedDate": "2020-05-04T21:31:49Z", "type": "commit"}, {"oid": "e6849265ce3d6031d913b3abc8f4090f956957fb", "url": "https://github.com/apache/iceberg/commit/e6849265ce3d6031d913b3abc8f4090f956957fb", "message": "Fix checkstyle problems.", "committedDate": "2020-05-05T15:59:55Z", "type": "commit"}, {"oid": "fbef50728d347ec3b695c42b3d6b54b7ab5b2ca0", "url": "https://github.com/apache/iceberg/commit/fbef50728d347ec3b695c42b3d6b54b7ab5b2ca0", "message": "Fix benchmarks.", "committedDate": "2020-05-05T16:12:08Z", "type": "commit"}, {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "url": "https://github.com/apache/iceberg/commit/d5d9afe092ce9d6bc496885785a8bdecc68b7261", "message": "Fix checkstyle.", "committedDate": "2020-05-05T16:32:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1MjI0Nw==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420852247", "bodyText": "I presume this will only be nullable unions", "author": "rdsr", "createdAt": "2020-05-06T14:48:49Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/AvroWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.avro.LogicalMap;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.StringType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+public abstract class AvroWithSparkSchemaVisitor<T> {\n+  public static <T> T visit(StructType struct, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    return visitRecord(struct, schema, visitor);\n+  }\n+\n+  public static <T> T visit(DataType type, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        Preconditions.checkArgument(type instanceof StructType, \"Invalid struct: %s is not a struct\", type);\n+        return visitRecord((StructType) type, schema, visitor);\n+\n+      case UNION:", "originalCommit": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk1MjYyNQ==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420952625", "bodyText": "This is validated in SparkAvroWriter, but I'll add a check in visitUnion as well.", "author": "rdblue", "createdAt": "2020-05-06T17:09:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1MjI0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1NTQ4Ng==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420855486", "bodyText": "Since we are traversing this with Spark schema, which does not support unions. Should we make sure that we are only processing nullable unions?", "author": "rdsr", "createdAt": "2020-05-06T14:52:59Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/AvroWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.avro.LogicalMap;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.StringType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+public abstract class AvroWithSparkSchemaVisitor<T> {\n+  public static <T> T visit(StructType struct, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    return visitRecord(struct, schema, visitor);\n+  }\n+\n+  public static <T> T visit(DataType type, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        Preconditions.checkArgument(type instanceof StructType, \"Invalid struct: %s is not a struct\", type);\n+        return visitRecord((StructType) type, schema, visitor);\n+\n+      case UNION:\n+        return visitUnion(type, schema, visitor);\n+\n+      case ARRAY:\n+        return visitArray(type, schema, visitor);\n+\n+      case MAP:\n+        Preconditions.checkArgument(type instanceof MapType, \"Invalid map: %s is not a map\", type);\n+        MapType map = (MapType) type;\n+        Preconditions.checkArgument(map.keyType() instanceof StringType,\n+            \"Invalid map: %s is not a string\", map.keyType());\n+        return visitor.map(map, schema, visit(map.valueType(), schema.getValueType(), visitor));\n+\n+      default:\n+        return visitor.primitive(type, schema);\n+    }\n+  }\n+\n+  private static <T> T visitRecord(StructType struct, Schema record, AvroWithSparkSchemaVisitor<T> visitor) {\n+    // check to make sure this hasn't been visited before\n+    String name = record.getFullName();\n+    Preconditions.checkState(!visitor.recordLevels.contains(name),\n+        \"Cannot process recursive Avro record %s\", name);\n+    StructField[] sFields = struct.fields();\n+    List<Schema.Field> fields = record.getFields();\n+    Preconditions.checkArgument(sFields.length == fields.size(),\n+        \"Structs do not match: %s != %s\", struct, record);\n+\n+    visitor.recordLevels.push(name);\n+\n+    List<String> names = Lists.newArrayListWithExpectedSize(fields.size());\n+    List<T> results = Lists.newArrayListWithExpectedSize(fields.size());\n+    for (int i = 0; i < sFields.length; i += 1) {\n+      StructField sField = sFields[i];\n+      Schema.Field field = fields.get(i);\n+      Preconditions.checkArgument(AvroSchemaUtil.makeCompatibleName(sField.name()).equals(field.name()),\n+          \"Structs do not match: field %s != %s\", sField.name(), field.name());\n+      results.add(visit(sField.dataType(), field.schema(), visitor));\n+    }\n+\n+    visitor.recordLevels.pop();\n+\n+    return visitor.record(struct, record, names, results);\n+  }\n+\n+  private static <T> T visitUnion(DataType type, Schema union, AvroWithSparkSchemaVisitor<T> visitor) {\n+    List<Schema> types = union.getTypes();\n+    List<T> options = Lists.newArrayListWithExpectedSize(types.size());\n+    for (Schema branch : types) {", "originalCommit": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk1NjEyMQ==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420956121", "bodyText": "Added a validation.", "author": "rdblue", "createdAt": "2020-05-06T17:14:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1NTQ4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4MTYzMQ==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420881631", "bodyText": "nit:  this can be on same line", "author": "rdsr", "createdAt": "2020-05-06T15:26:28Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/ParquetWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.OriginalType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Type.Repetition;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * Visitor for traversing a Parquet type with a companion Spark type.\n+ *\n+ * @param <T> the Java class returned by the visitor\n+ */\n+public class ParquetWithSparkSchemaVisitor<T> {\n+  private final Deque<String> fieldNames = Lists.newLinkedList();\n+\n+  public static <T> T visit(DataType sType, Type type, ParquetWithSparkSchemaVisitor<T> visitor) {\n+    Preconditions.checkArgument(sType != null, \"Invalid DataType: null\");\n+    if (type instanceof MessageType) {\n+      Preconditions.checkArgument(sType instanceof StructType, \"Invalid struct: %s is not a struct\", sType);\n+      StructType struct = (StructType) sType;\n+      return visitor.message(struct, (MessageType) type, visitFields(struct, type.asGroupType(), visitor));\n+\n+    } else if (type.isPrimitive()) {\n+      return visitor.primitive(sType, type.asPrimitiveType());\n+\n+    } else {\n+      // if not a primitive, the typeId must be a group\n+      GroupType group = type.asGroupType();\n+      OriginalType annotation = group.getOriginalType();\n+      if (annotation != null) {\n+        switch (annotation) {\n+          case LIST:\n+            Preconditions.checkArgument(!group.isRepetition(Repetition.REPEATED),\n+                \"Invalid list: top-level group is repeated: %s\", group);\n+            Preconditions.checkArgument(group.getFieldCount() == 1,\n+                \"Invalid list: does not contain single repeated field: %s\", group);\n+\n+            GroupType repeatedElement = group.getFields().get(0).asGroupType();\n+            Preconditions.checkArgument(repeatedElement.isRepetition(Repetition.REPEATED),\n+                \"Invalid list: inner group is not repeated\");\n+            Preconditions.checkArgument(repeatedElement.getFieldCount() <= 1,\n+                \"Invalid list: repeated group is not a single field: %s\", group);\n+\n+            Preconditions.checkArgument(sType instanceof ArrayType, \"Invalid list: %s is not an array\", sType);\n+            ArrayType array = (ArrayType) sType;\n+            StructField element = new StructField(\n+                \"element\", array.elementType(), array.containsNull(), Metadata.empty());\n+\n+            visitor.fieldNames.push(repeatedElement.getName());\n+            try {\n+              T elementResult = null;\n+              if (repeatedElement.getFieldCount() > 0) {\n+                elementResult = visitField(element, repeatedElement.getType(0), visitor);\n+              }\n+\n+              return visitor.list(array, group, elementResult);\n+\n+            } finally {\n+              visitor.fieldNames.pop();\n+            }\n+\n+          case MAP:\n+            Preconditions.checkArgument(!group.isRepetition(Repetition.REPEATED),\n+                \"Invalid map: top-level group is repeated: %s\", group);\n+            Preconditions.checkArgument(group.getFieldCount() == 1,\n+                \"Invalid map: does not contain single repeated field: %s\", group);\n+\n+            GroupType repeatedKeyValue = group.getType(0).asGroupType();\n+            Preconditions.checkArgument(repeatedKeyValue.isRepetition(Repetition.REPEATED),\n+                \"Invalid map: inner group is not repeated\");\n+            Preconditions.checkArgument(repeatedKeyValue.getFieldCount() <= 2,\n+                \"Invalid map: repeated group does not have 2 fields\");\n+\n+            Preconditions.checkArgument(sType instanceof MapType, \"Invalid map: %s is not a map\", sType);\n+            MapType map = (MapType) sType;\n+            StructField keyField = new StructField(\"key\", map.keyType(), false, Metadata.empty());\n+            StructField valueField = new StructField(\n+                \"value\", map.valueType(), map.valueContainsNull(), Metadata.empty());\n+\n+            visitor.fieldNames.push(repeatedKeyValue.getName());\n+            try {\n+              T keyResult = null;\n+              T valueResult = null;\n+              switch (repeatedKeyValue.getFieldCount()) {\n+                case 2:\n+                  // if there are 2 fields, both key and value are projected\n+                  keyResult = visitField(keyField, repeatedKeyValue.getType(0), visitor);\n+                  valueResult = visitField(valueField, repeatedKeyValue.getType(1), visitor);\n+                  break;\n+                case 1:\n+                  // if there is just one, use the name to determine what it is\n+                  Type keyOrValue = repeatedKeyValue.getType(0);\n+                  if (keyOrValue.getName().equalsIgnoreCase(\"key\")) {\n+                    keyResult = visitField(keyField, keyOrValue, visitor);\n+                    // value result remains null\n+                  } else {\n+                    valueResult = visitField(valueField, keyOrValue, visitor);\n+                    // key result remains null\n+                  }\n+                  break;\n+                default:\n+                  // both results will remain null\n+              }\n+\n+              return visitor.map(map, group, keyResult, valueResult);\n+\n+            } finally {\n+              visitor.fieldNames.pop();\n+            }\n+\n+          default:\n+        }\n+      }\n+\n+      Preconditions.checkArgument(sType instanceof StructType, \"Invalid struct: %s is not a struct\", sType);\n+      StructType struct = (StructType) sType;\n+      return visitor.struct(struct, group, visitFields(struct, group, visitor));\n+    }\n+  }\n+\n+  private static <T> T visitField(StructField sField, Type field, ParquetWithSparkSchemaVisitor<T> visitor) {\n+    visitor.fieldNames.push(field.getName());\n+    try {\n+      return visit(sField.dataType(), field, visitor);\n+    } finally {\n+      visitor.fieldNames.pop();\n+    }\n+  }\n+\n+  private static <T> List<T> visitFields(StructType struct, GroupType group,\n+                                         ParquetWithSparkSchemaVisitor<T> visitor) {\n+    StructField[] sFields = struct.fields();\n+    Preconditions.checkArgument(sFields.length == group.getFieldCount(),\n+        \"Structs do not match: %s and %s\", struct, group);\n+    List<T> results = Lists.newArrayListWithExpectedSize(group.getFieldCount());\n+    for (int i = 0; i < sFields.length; i += 1) {\n+      Type field = group.getFields().get(i);\n+      StructField sField = sFields[i];\n+      Preconditions.checkArgument(field.getName().equals(AvroSchemaUtil.makeCompatibleName(sField.name())),\n+          \"Structs do not match: field %s != %s\", field.getName(), sField.name());\n+      results.add(visitField(sField, field, visitor));\n+    }\n+\n+    return results;\n+  }\n+\n+  public T message(StructType sStruct, MessageType message, List<T> fields) {\n+    return null;\n+  }\n+\n+  public T struct(StructType sStruct, GroupType struct, List<T> fields) {\n+    return null;\n+  }\n+\n+  public T list(ArrayType sArray, GroupType array, T element) {\n+    return null;\n+  }\n+\n+  public T map(MapType sMap, GroupType map, T key, T value) {\n+    return null;\n+  }\n+\n+  public T primitive(DataType sPrimitive,\n+                     PrimitiveType primitive) {", "originalCommit": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk1NjgzOQ==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420956839", "bodyText": "Fixed.", "author": "rdblue", "createdAt": "2020-05-06T17:15:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4MTYzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4NTE1NQ==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420885155", "bodyText": "should we expose this functionality through the beforeField and afterField apis?", "author": "rdsr", "createdAt": "2020-05-06T15:31:08Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/ParquetWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.OriginalType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Type.Repetition;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * Visitor for traversing a Parquet type with a companion Spark type.\n+ *\n+ * @param <T> the Java class returned by the visitor\n+ */\n+public class ParquetWithSparkSchemaVisitor<T> {\n+  private final Deque<String> fieldNames = Lists.newLinkedList();", "originalCommit": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk1NTcyMg==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420955722", "bodyText": "Good question. I originally thought about doing this when refactoring Parquet visitors in #1001, but nearly ever Parquet visitor uses the currentPath or path functions, so it made more sense after #950 to keep the implementation in the base visitor.\nHere, we could add similar beforeField and afterField callbacks, but that introduces 10 more methods that wouldn't actually be used. I'm inclined to add them when and if we need them. Does that sound reasonable?", "author": "rdblue", "createdAt": "2020-05-06T17:13:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4NTE1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk2NjEzMw==", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420966133", "bodyText": "Sounds good to me!", "author": "rdsr", "createdAt": "2020-05-06T17:30:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4NTE1NQ=="}], "type": "inlineReview"}, {"oid": "05d6680b79ce9a8b3f0c3894f8afcc70ad788403", "url": "https://github.com/apache/iceberg/commit/05d6680b79ce9a8b3f0c3894f8afcc70ad788403", "message": "Fix issues from review.", "committedDate": "2020-05-06T17:16:22Z", "type": "commit"}, {"oid": "9f7ba7ab239fe9d244233b78025c700ffa985c29", "url": "https://github.com/apache/iceberg/commit/9f7ba7ab239fe9d244233b78025c700ffa985c29", "message": "Fix checkstyle.", "committedDate": "2020-05-06T17:31:46Z", "type": "commit"}]}