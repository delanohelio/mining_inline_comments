{"pr_number": 1481, "pr_title": "Core: Implement Catalogs.createTable and Catalogs.dropTable", "pr_createdAt": "2020-09-21T13:59:33Z", "pr_url": "https://github.com/apache/iceberg/pull/1481", "timeline": [{"oid": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "url": "https://github.com/apache/iceberg/commit/c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "message": "Javadoc warning fixed", "committedDate": "2020-09-23T07:12:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NTY3Mg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493965672", "bodyText": "Because this was protected, I think we should keep it and just delegate to where the method moved. We can also deprecated it and set a version when it will be removed:\n  /**\n   * ...\n   * @deprecated will be removed in 0.11.0; use CatalogUtil.dropTableData instead.\n   */", "author": "rdblue", "createdAt": "2020-09-24T00:07:30Z", "path": "core/src/main/java/org/apache/iceberg/BaseMetastoreCatalog.java", "diffHunk": "@@ -278,84 +268,6 @@ private Transaction newReplaceTableTransaction(boolean orCreate) {\n     }\n   }\n \n-  /**\n-   * Drops all data and metadata files referenced by TableMetadata.\n-   * <p>\n-   * This should be called by dropTable implementations to clean up table files once the table has been dropped in the\n-   * metastore.\n-   *\n-   * @param io a FileIO to use for deletes\n-   * @param metadata the last valid TableMetadata instance for a dropped table.\n-   */\n-  protected static void dropTableData(FileIO io, TableMetadata metadata) {", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE5NjM4Nw==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494196387", "bodyText": "Good point!\nDone", "author": "pvary", "createdAt": "2020-09-24T10:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NTY3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NTk5OA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493965998", "bodyText": "Nit: accidentally duplicated line?", "author": "rdblue", "createdAt": "2020-09-24T00:08:46Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopCatalog.java", "diffHunk": "@@ -196,9 +197,10 @@ public boolean dropTable(TableIdentifier identifier, boolean purge) {\n \n     try {\n       if (purge && lastMetadata != null) {\n+        // Since the data files and the metadata files may store in different locations,", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE5Njc1MQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494196751", "bodyText": "Removed. Thanks", "author": "pvary", "createdAt": "2020-09-24T10:10:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NTk5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NjcxOA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493966718", "bodyText": "I think this wasn't implemented before because it is not part of the Tables API, but now that this is the only implementation, maybe we should consider just deprecating the Tables API and making HadoopTables a stand-alone class.", "author": "rdblue", "createdAt": "2020-09-24T00:11:09Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files. Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location) {", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE5NzMzMA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494197330", "bodyText": "Maybe this would merit another discussion, and another PR", "author": "pvary", "createdAt": "2020-09-24T10:11:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NjcxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0MzA4OQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494443089", "bodyText": "Agreed.", "author": "rdblue", "createdAt": "2020-09-24T16:13:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NjcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2Njg2MA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493966860", "bodyText": "I think this should be a @throws instead of text.", "author": "rdblue", "createdAt": "2020-09-24T00:11:33Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files. Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location) {\n+    return dropTable(location, true);\n+  }\n+\n+  /**\n+   * Drop a table; optionally delete data and metadata files.\n+   * <p>\n+   * If purge is set to true the implementation should delete all data and metadata files.\n+   * Throws NoSuchTableException if the table does not exists.", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE5Nzk1MQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494197951", "bodyText": "Done", "author": "pvary", "createdAt": "2020-09-24T10:12:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2Njg2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NzUyNg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493967526", "bodyText": "The TableOperations created just below can tell you the same information. I think this should use that instead to avoid creating two.", "author": "rdblue", "createdAt": "2020-09-24T00:13:58Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files. Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location) {\n+    return dropTable(location, true);\n+  }\n+\n+  /**\n+   * Drop a table; optionally delete data and metadata files.\n+   * <p>\n+   * If purge is set to true the implementation should delete all data and metadata files.\n+   * Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @param purge if true, delete all data and metadata files in the table\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location, boolean purge) {\n+    // Just for checking if the table exists or not\n+    load(location);", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIwNjY3OA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494206678", "bodyText": "Thanks for the idea!\nDone", "author": "pvary", "createdAt": "2020-09-24T10:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NzUyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NzY0NQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493967645", "bodyText": "Since this is a new method, you can use UncheckedIOException directly.", "author": "rdblue", "createdAt": "2020-09-24T00:14:23Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files. Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location) {\n+    return dropTable(location, true);\n+  }\n+\n+  /**\n+   * Drop a table; optionally delete data and metadata files.\n+   * <p>\n+   * If purge is set to true the implementation should delete all data and metadata files.\n+   * Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @param purge if true, delete all data and metadata files in the table\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location, boolean purge) {\n+    // Just for checking if the table exists or not\n+    load(location);\n+\n+    TableOperations ops = newTableOps(location);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      if (purge && lastMetadata != null) {\n+        // Since the data files and the metadata files may store in different locations,\n+        // so it has to call dropTableData to force delete the data file.\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      }\n+      Path tablePath = new Path(location);\n+      Util.getFs(tablePath, conf).delete(tablePath, true /* recursive */);\n+      return true;\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Failed to delete file: %s\", location);", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIwNjc2MQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494206761", "bodyText": "Done", "author": "pvary", "createdAt": "2020-09-24T10:28:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2NzY0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2Nzk0MQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493967941", "bodyText": "Would it be faster to call this instead of calling dropTableData? There seems to be no need to read files to find what to delete, only to delete the remaining files afterward.", "author": "rdblue", "createdAt": "2020-09-24T00:15:14Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files. Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location) {\n+    return dropTable(location, true);\n+  }\n+\n+  /**\n+   * Drop a table; optionally delete data and metadata files.\n+   * <p>\n+   * If purge is set to true the implementation should delete all data and metadata files.\n+   * Throws NoSuchTableException if the table does not exists.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @param purge if true, delete all data and metadata files in the table\n+   * @return true if the table was dropped\n+   */\n+  public boolean dropTable(String location, boolean purge) {\n+    // Just for checking if the table exists or not\n+    load(location);\n+\n+    TableOperations ops = newTableOps(location);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      if (purge && lastMetadata != null) {\n+        // Since the data files and the metadata files may store in different locations,\n+        // so it has to call dropTableData to force delete the data file.\n+        CatalogUtil.dropTableData(ops.io(), lastMetadata);\n+      }\n+      Path tablePath = new Path(location);\n+      Util.getFs(tablePath, conf).delete(tablePath, true /* recursive */);", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2ODM4NQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493968385", "bodyText": "Nevermind, I just remembered. And there's already a comment for it.", "author": "rdblue", "createdAt": "2020-09-24T00:16:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2Nzk0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2ODY1Mg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493968652", "bodyText": "Normally, we would use ImmutableSet.of(...). That's simpler and creates a set that can't be modified.", "author": "rdblue", "createdAt": "2020-09-24T00:17:41Z", "path": "mr/src/main/java/org/apache/iceberg/mr/Catalogs.java", "diffHunk": "@@ -44,23 +61,31 @@\n   private static final String NAME = \"name\";\n   private static final String LOCATION = \"location\";\n \n+  private static final Set<String> PROPERTIES_TO_REMOVE = Stream\n+      .of(InputFormatConfig.TABLE_SCHEMA, InputFormatConfig.PARTITION_SPEC, LOCATION, NAME)\n+      .collect(Collectors.toCollection(HashSet::new));", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIwNzM5OQ==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494207399", "bodyText": "Done", "author": "pvary", "createdAt": "2020-09-24T10:29:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2ODY1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2OTM5OA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493969398", "bodyText": "Minor: Javadoc won't automatically break paragraphs, so you have to use <p> between them.", "author": "rdblue", "createdAt": "2020-09-24T00:20:16Z", "path": "mr/src/main/java/org/apache/iceberg/mr/Catalogs.java", "diffHunk": "@@ -44,23 +61,31 @@\n   private static final String NAME = \"name\";\n   private static final String LOCATION = \"location\";\n \n+  private static final Set<String> PROPERTIES_TO_REMOVE = Stream\n+      .of(InputFormatConfig.TABLE_SCHEMA, InputFormatConfig.PARTITION_SPEC, LOCATION, NAME)\n+      .collect(Collectors.toCollection(HashSet::new));\n+\n   private Catalogs() {\n   }\n \n   /**\n    * Load an Iceberg table using the catalog and table identifier (or table path) specified by the configuration.\n-   * Catalog resolution happens in this order:\n-   * 1. Custom catalog if specified by {@link InputFormatConfig#CATALOG_LOADER_CLASS}\n-   * 2. Hadoop or Hive catalog if specified by {@link InputFormatConfig#CATALOG}\n-   * 3. Hadoop Tables\n    * @param conf a Hadoop conf\n    * @return an Iceberg table\n    */\n   public static Table loadTable(Configuration conf) {\n     return loadTable(conf, conf.get(InputFormatConfig.TABLE_IDENTIFIER), conf.get(InputFormatConfig.TABLE_LOCATION));\n   }\n \n-  // For use in HiveIcebergSerDe and HiveIcebergStorageHandler\n+  /**\n+   * Load an Iceberg table using the catalog specified by the configuration.\n+   * The table identifier ({@link Catalogs#NAME}) or table path ({@link Catalogs#LOCATION}) should be specified by\n+   * the controlling properties.\n+   * Used by HiveIcebergSerDe and HiveIcebergStorageHandler", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIxMzEzMA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494213130", "bodyText": "Happily relearning javadoc formatting \ud83d\ude04\nDone", "author": "pvary", "createdAt": "2020-09-24T10:40:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk2OTM5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk3MDAxNg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493970016", "bodyText": "It looks like this is the reason why the examples specify a table property. Can we instead use Hive schema DDL and convert it to Iceberg? Similarly, can we get the identity partition fields that way to create a spec?", "author": "rdblue", "createdAt": "2020-09-24T00:22:15Z", "path": "mr/src/main/java/org/apache/iceberg/mr/Catalogs.java", "diffHunk": "@@ -77,6 +102,77 @@ private static Table loadTable(Configuration conf, String tableIdentifier, Strin\n     return new HadoopTables(conf).load(tableLocation);\n   }\n \n+  /**\n+   * Creates an Iceberg table using the catalog specified by the configuration.\n+   * The properties should contain the following values:\n+   * <p><ul>\n+   * <li>Table identifier ({@link Catalogs#NAME}) or table path ({@link Catalogs#LOCATION}) is required\n+   * <li>Table schema ({@link InputFormatConfig#TABLE_SCHEMA}) is required\n+   * <li>Partition specification ({@link InputFormatConfig#PARTITION_SPEC}) is optional. Table will be unpartitioned if\n+   *  not provided\n+   * </ul><p>\n+   * Other properties will be handled over to the Table creation. The controlling properties above will not be\n+   * propagated.\n+   * @param conf a Hadoop conf\n+   * @param props the controlling properties\n+   * @return the created Iceberg table\n+   */\n+  public static Table createTable(Configuration conf, Properties props) {\n+    String schemaString = props.getProperty(InputFormatConfig.TABLE_SCHEMA);\n+    Preconditions.checkNotNull(schemaString, \"Table schema not set\");\n+    Schema schema = SchemaParser.fromJson(props.getProperty(InputFormatConfig.TABLE_SCHEMA));", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIxNjE2MA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494216160", "bodyText": "I think we should keep the serialized schema for the Catalogs interface. Other systems like Impala, Presto, etc. might want to use it as well.\nI would like to tackle the Hive schema DDL in another PR. The data is available in HiveIcebergSerDe.initialize in a somewhat convoluted way. I would like to get it there and convert it to the Iceberg Schema string. From there I would only push the Iceberg related stuff down further.\nWhat do you think?", "author": "pvary", "createdAt": "2020-09-24T10:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk3MDAxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0Mjk3Ng==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494442976", "bodyText": "I think it's fine to do this in a separate PR. I just really don't want to require setting properties with JSON schema or spec representations as the way to use Iceberg. It's okay for a way to customize if there isn't syntax, but normal cases should just use DDL.", "author": "rdblue", "createdAt": "2020-09-24T16:12:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk3MDAxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk3MDU2Ng==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r493970566", "bodyText": "Somewhat out of scope: We might want to build a Catalog for this logic so that this class can avoid loading and checking the catalog in every method. The catalog would get created with the configuration and handle this delegation internally.", "author": "rdblue", "createdAt": "2020-09-24T00:24:20Z", "path": "mr/src/main/java/org/apache/iceberg/mr/Catalogs.java", "diffHunk": "@@ -77,6 +102,77 @@ private static Table loadTable(Configuration conf, String tableIdentifier, Strin\n     return new HadoopTables(conf).load(tableLocation);\n   }\n \n+  /**\n+   * Creates an Iceberg table using the catalog specified by the configuration.\n+   * The properties should contain the following values:\n+   * <p><ul>\n+   * <li>Table identifier ({@link Catalogs#NAME}) or table path ({@link Catalogs#LOCATION}) is required\n+   * <li>Table schema ({@link InputFormatConfig#TABLE_SCHEMA}) is required\n+   * <li>Partition specification ({@link InputFormatConfig#PARTITION_SPEC}) is optional. Table will be unpartitioned if\n+   *  not provided\n+   * </ul><p>\n+   * Other properties will be handled over to the Table creation. The controlling properties above will not be\n+   * propagated.\n+   * @param conf a Hadoop conf\n+   * @param props the controlling properties\n+   * @return the created Iceberg table\n+   */\n+  public static Table createTable(Configuration conf, Properties props) {\n+    String schemaString = props.getProperty(InputFormatConfig.TABLE_SCHEMA);\n+    Preconditions.checkNotNull(schemaString, \"Table schema not set\");\n+    Schema schema = SchemaParser.fromJson(props.getProperty(InputFormatConfig.TABLE_SCHEMA));\n+\n+    String specString = props.getProperty(InputFormatConfig.PARTITION_SPEC);\n+    PartitionSpec spec = PartitionSpec.unpartitioned();\n+    if (specString != null) {\n+      spec = PartitionSpecParser.fromJson(schema, specString);\n+    }\n+\n+    String location = props.getProperty(LOCATION);\n+\n+    // Create a table property map without the controlling properties\n+    Map<String, String> map = new HashMap<>(props.size());\n+    for (Object key : props.keySet()) {\n+      if (!PROPERTIES_TO_REMOVE.contains(key)) {\n+        map.put(key.toString(), props.get(key).toString());\n+      }\n+    }\n+\n+    Optional<Catalog> catalog = loadCatalog(conf);", "originalCommit": "c584198d44cfa3b49fe93e078b1be11b1e66b8f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDIyNDE3MA==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494224170", "bodyText": "HiveCatalog has a cache, but this might be useful for other Catalogs as well.\nThis seems like a good idea to pursue, but I do not promise anything here, as I have too much on my plate currently", "author": "pvary", "createdAt": "2020-09-24T11:01:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk3MDU2Ng=="}], "type": "inlineReview"}, {"oid": "514575eeed1ded9c4232462e568fbaf3b845fe49", "url": "https://github.com/apache/iceberg/commit/514575eeed1ded9c4232462e568fbaf3b845fe49", "message": "Implement dropTable for HadoopTables", "committedDate": "2020-09-24T10:07:56Z", "type": "commit"}, {"oid": "a1207f1b2dfc78ede59bc41825aab4c6374d79f8", "url": "https://github.com/apache/iceberg/commit/a1207f1b2dfc78ede59bc41825aab4c6374d79f8", "message": "Implement Catalogs.createTable, Catalogs.dropTable", "committedDate": "2020-09-24T10:07:56Z", "type": "commit"}, {"oid": "e21ad740a497b209a4ae7fcb082ce77bb31857e2", "url": "https://github.com/apache/iceberg/commit/e21ad740a497b209a4ae7fcb082ce77bb31857e2", "message": "Controlling properties should not be pushed to the actual table creation.\nJavadoc is revisited", "committedDate": "2020-09-24T10:07:56Z", "type": "commit"}, {"oid": "3df7efd418452c837ef566c39ecf17d40c9d1bcb", "url": "https://github.com/apache/iceberg/commit/3df7efd418452c837ef566c39ecf17d40c9d1bcb", "message": "Fixing comment formatting", "committedDate": "2020-09-24T10:07:56Z", "type": "commit"}, {"oid": "fc28ebf41301e49939b571811645458152190dc8", "url": "https://github.com/apache/iceberg/commit/fc28ebf41301e49939b571811645458152190dc8", "message": "Javadoc warning fixed", "committedDate": "2020-09-24T10:07:56Z", "type": "commit"}, {"oid": "1960cde82595ac31d5c2beee5e806ae6bb9c5eb6", "url": "https://github.com/apache/iceberg/commit/1960cde82595ac31d5c2beee5e806ae6bb9c5eb6", "message": "Addressed review comments", "committedDate": "2020-09-24T11:11:57Z", "type": "commit"}, {"oid": "1960cde82595ac31d5c2beee5e806ae6bb9c5eb6", "url": "https://github.com/apache/iceberg/commit/1960cde82595ac31d5c2beee5e806ae6bb9c5eb6", "message": "Addressed review comments", "committedDate": "2020-09-24T11:11:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0NDMwNg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494444306", "bodyText": "I should have caught this yesterday, but shouldn't this return false instead of throwing the exception? That's what all the other drop methods do. If the table doesn't exist, it isn't an exceptional case. It just returns false to signal that it nothing needed to be done.", "author": "rdblue", "createdAt": "2020-09-24T16:14:55Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -144,6 +147,52 @@ public Table create(Schema schema, PartitionSpec spec, SortOrder order,\n     return new BaseTable(ops, location);\n   }\n \n+  /**\n+   * Drop a table and delete all data and metadata files.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @return true if the table was dropped\n+   * @throws NoSuchTableException if the table does not exists.\n+   */\n+  public boolean dropTable(String location) {\n+    return dropTable(location, true);\n+  }\n+\n+  /**\n+   * Drop a table; optionally delete data and metadata files.\n+   * <p>\n+   * If purge is set to true the implementation should delete all data and metadata files.\n+   *\n+   * @param location a path URI (e.g. hdfs:///warehouse/my_table)\n+   * @param purge if true, delete all data and metadata files in the table\n+   * @return true if the table was dropped\n+   * @throws NoSuchTableException if the table does not exists.\n+   */\n+  public boolean dropTable(String location, boolean purge) {\n+    TableOperations ops = newTableOps(location);\n+    TableMetadata lastMetadata = null;\n+    if (ops.current() != null) {\n+      if (purge) {\n+        lastMetadata = ops.current();\n+      }\n+    } else {\n+      throw new NoSuchTableException(\"Table does not exist at location: %s, so it can not be dropped\", location);", "originalCommit": "1960cde82595ac31d5c2beee5e806ae6bb9c5eb6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDkxMzY0Mg==", "url": "https://github.com/apache/iceberg/pull/1481#discussion_r494913642", "bodyText": "I should have caught this yesterday, but shouldn't this return false instead of throwing the exception? That's what all the other drop methods do. If the table doesn't exist, it isn't an exceptional case. It just returns false to signal that it nothing needed to be done.\n\nGood point! Finding it now is better than finding it after pushing the PR \ud83d\ude04\nFixed.", "author": "pvary", "createdAt": "2020-09-25T11:04:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDQ0NDMwNg=="}], "type": "inlineReview"}, {"oid": "66bb2e8999c174579d7c4e48f1f4cd5f7dd4d987", "url": "https://github.com/apache/iceberg/commit/66bb2e8999c174579d7c4e48f1f4cd5f7dd4d987", "message": "Do not throw if the table did not exist", "committedDate": "2020-09-25T11:03:40Z", "type": "commit"}]}