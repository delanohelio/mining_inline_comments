{"pr_number": 1801, "pr_title": "Spark: Add RewriteManifestsProcedure", "pr_createdAt": "2020-11-20T23:13:21Z", "pr_url": "https://github.com/apache/iceberg/pull/1801", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r528019574", "bodyText": "I just realized that there are more configs we should probably expose as they are supported by the action. I think we can expose optional spec_id, use_caching. I am not convinced we want to expose stagingLocation, though.\n@rdblue @RussellSpitzer, thoughts?", "author": "aokolnychyi", "createdAt": "2020-11-20T23:16:10Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RewriteManifestsProcedure.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.actions.Actions;\n+import org.apache.iceberg.actions.RewriteManifestsActionResult;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+class RewriteManifestsProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{", "originalCommit": "757a6ea8bd9d1c75651a6cb6c9b920669b34947a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAyMDk4NA==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r528020984", "bodyText": "We will have more params to track min/max sizes, clustering ratio later on. I don't want to have too many params.", "author": "aokolnychyi", "createdAt": "2020-11-20T23:20:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAyMjM5Mw==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r528022393", "bodyText": "I think use_caching may be important, just because of the use case hitting us right now internally", "author": "RussellSpitzer", "createdAt": "2020-11-20T23:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0NTg2Ng==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r528045866", "bodyText": "Agree, I added those two.", "author": "aokolnychyi", "createdAt": "2020-11-21T01:12:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNjY1Mg==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529006652", "bodyText": "I would avoid staging location for now because it defaults to the table's metadata location. I'm also not convinced that we should expose spec_id because it is an internal identifier that we never show to users right now. It makes sense in the API, but I doubt a purely SQL user would ever know what to set it to.", "author": "rdblue", "createdAt": "2020-11-23T21:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAyMzI4Mw==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529023283", "bodyText": "Well, there is no easy way to find the spec id without using the Iceberg API directly so I agree we can skip it for now.", "author": "aokolnychyi", "createdAt": "2020-11-23T21:59:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA3MTAxOQ==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529071019", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-11-23T23:50:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxOTU3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAyMDE1Nw==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r528020157", "bodyText": "We have way more tests in the action itself.", "author": "aokolnychyi", "createdAt": "2020-11-20T23:18:14Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestRewriteManifestsProcedure.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+\n+import static org.apache.iceberg.TableProperties.SNAPSHOT_ID_INHERITANCE_ENABLED;\n+\n+public class TestRewriteManifestsProcedure extends SparkExtensionsTestBase {\n+\n+  public TestRewriteManifestsProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTable() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testRewriteManifestsInEmptyTable() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rewrite_manifests('%s', '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name());\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(0, 0)),\n+        output);\n+  }\n+\n+  @Test\n+  public void testRewriteLargeManifests() {", "originalCommit": "757a6ea8bd9d1c75651a6cb6c9b920669b34947a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNTg1MA==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529005850", "bodyText": "I think the cache still needs to be refreshed. A commit will refresh the table reference that is cached in Iceberg, pulling in all changes that happened since it was loaded. There could be changes unrelated to the manifest rewrite that get pulled in and would cause the cache to be stale compared with a new query. I think it is best to refresh Spark's cache whenever a procedure modifies or refreshes the table.", "author": "rdblue", "createdAt": "2020-11-23T21:24:49Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/BaseProcedure.java", "diffHunk": "@@ -56,7 +65,9 @@ protected BaseProcedure(TableCatalog tableCatalog) {\n \n     T result = func.apply(icebergTable);\n \n-    refreshSparkCache(ident, sparkTable);\n+    if (refreshSparkCache) {\n+      refreshSparkCache(ident, sparkTable);\n+    }", "originalCommit": "23480e7da19b50181fb6dcc9a6d2f4a021b6823a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAzMTU3OA==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529031578", "bodyText": "This raises a good point. I did not consider external modifications and my motivation was to keep data cached if procedures don't modify the underlying data as caching is usually expensive.\nDo we think external modifications should invalidate Spark's cache? It seems like a good idea but there is one concern: it does not match how things work right now. If I understand correctly, Spark's cache does not know anything about external modifications and stays valid even if someone modifies the underlying table in Presto or another Spark job. So the only case when the cache is invalidated is when an operation happens in a given session.\nI don't feel strongly about this but I want us to think through here.", "author": "aokolnychyi", "createdAt": "2020-11-23T22:17:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNTg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAzNDQzNg==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529034436", "bodyText": "For this PR, I think it is better to invalidate the cache.\nThe more general question is one for Spark, but I think that the answer is that Spark does not care about external changes. I think that Spark only cares about consistency with its operations. If a table is loaded, then all queries and cached dataframes should give consistent results. If Spark updates, refreshes, or invalidates a table then it should invalidate caches. Otherwise, Spark is simply using the current state as of when the table was loaded, which is a good thing. Spark can't be expected to invalidate a cache every time anything external changes.", "author": "rdblue", "createdAt": "2020-11-23T22:22:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNTg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA0Mjc0Mw==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529042743", "bodyText": "If a table is loaded, then all queries and cached dataframes should give consistent results.\n\nI am convinced.", "author": "aokolnychyi", "createdAt": "2020-11-23T22:41:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNTg1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA3MDkwMw==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529070903", "bodyText": "Updated.", "author": "aokolnychyi", "createdAt": "2020-11-23T23:50:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNTg1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNzU5MQ==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529007591", "bodyText": "Not sure if I already mentioned this, but we might want to add a helper method to create a generic row.", "author": "rdblue", "createdAt": "2020-11-23T21:28:07Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RewriteManifestsProcedure.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.actions.Actions;\n+import org.apache.iceberg.actions.RewriteManifestsAction;\n+import org.apache.iceberg.actions.RewriteManifestsActionResult;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+class RewriteManifestsProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.optional(\"spec_id\", DataTypes.IntegerType),\n+      ProcedureParameter.optional(\"use_caching\", DataTypes.BooleanType)\n+  };\n+\n+  // counts are not nullable since the action result is never null\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"num_rewritten_manifests\", DataTypes.IntegerType, false, Metadata.empty()),\n+      new StructField(\"num_added_manifests\", DataTypes.IntegerType, false, Metadata.empty())\n+  });\n+\n+  public static ProcedureBuilder builder() {\n+    return new BaseProcedure.Builder<RewriteManifestsProcedure>() {\n+      @Override\n+      protected RewriteManifestsProcedure doBuild() {\n+        return new RewriteManifestsProcedure(tableCatalog());\n+      }\n+    };\n+  }\n+\n+  private RewriteManifestsProcedure(TableCatalog tableCatalog) {\n+    super(tableCatalog);\n+  }\n+\n+  @Override\n+  public ProcedureParameter[] parameters() {\n+    return PARAMETERS;\n+  }\n+\n+  @Override\n+  public StructType outputType() {\n+    return OUTPUT_TYPE;\n+  }\n+\n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    Integer specId = args.isNullAt(2) ? null : args.getInt(2);\n+    Boolean useCaching = args.isNullAt(3) ? null : args.getBoolean(3);\n+\n+    return withIcebergTable(namespace, tableName, table -> {\n+      Actions actions = Actions.forTable(table);\n+\n+      RewriteManifestsAction action = actions.rewriteManifests();\n+\n+      if (specId != null) {\n+        action.specId(specId);\n+      }\n+\n+      if (useCaching != null) {\n+        action.useCaching(useCaching);\n+      }\n+\n+      RewriteManifestsActionResult result = action.execute();\n+\n+      Object[] outputValues = new Object[OUTPUT_TYPE.size()];\n+      outputValues[0] = result.deletedManifests().size();\n+      outputValues[1] = result.addedManifests().size();\n+      GenericInternalRow outputRow = new GenericInternalRow(outputValues);", "originalCommit": "23480e7da19b50181fb6dcc9a6d2f4a021b6823a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA3MDg0NQ==", "url": "https://github.com/apache/iceberg/pull/1801#discussion_r529070845", "bodyText": "Done in a separate PR.", "author": "aokolnychyi", "createdAt": "2020-11-23T23:50:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTAwNzU5MQ=="}], "type": "inlineReview"}, {"oid": "9d3c77ce7b0a771fd1de17081321c9745c7d16d1", "url": "https://github.com/apache/iceberg/commit/9d3c77ce7b0a771fd1de17081321c9745c7d16d1", "message": "Spark: Add RewriteManifestsProcedure", "committedDate": "2020-11-23T23:49:30Z", "type": "commit"}, {"oid": "9d3c77ce7b0a771fd1de17081321c9745c7d16d1", "url": "https://github.com/apache/iceberg/commit/9d3c77ce7b0a771fd1de17081321c9745c7d16d1", "message": "Spark: Add RewriteManifestsProcedure", "committedDate": "2020-11-23T23:49:30Z", "type": "forcePushed"}, {"oid": "94403cca6b5b4096d6a72d818343a79914f0fbe4", "url": "https://github.com/apache/iceberg/commit/94403cca6b5b4096d6a72d818343a79914f0fbe4", "message": "Add javadoc", "committedDate": "2020-11-23T23:52:24Z", "type": "commit"}]}